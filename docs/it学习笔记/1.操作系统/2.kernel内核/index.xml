<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 2.Kernel(内核)</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/</link><description>Recent content in 2.Kernel(内核) on 断念梦</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Linux Kernel</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/1.linux-kernel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/1.linux-kernel/</guid><description/></item><item><title>Docs: System Call</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/3.system-call/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/3.system-call/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;h2 id="参考">参考：&lt;/h2>
&lt;/blockquote></description></item><item><title>Docs: 4.CPU 管理</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/4.cpu-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/4.cpu-%E7%AE%A1%E7%90%86/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://time.geekbang.org/column/article/69859">极客时间，Linux 性能优化实战-03 基础篇：经常说的 CPU 上下文切换是什么意思&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://linuxperf.com/?p=209">LinuxPerformance 博客，进程切换：自愿与强制&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>在 Linux 中，CPU 的管理，绝大部分时间都是在进行任务的调度，所以很多时候也称为&lt;strong>调度管理&lt;/strong>。&lt;/p>
&lt;h2 id="cpu-多线程并发并行-概念">&lt;strong>CPU 多线程、并发、并行 概念&lt;/strong>&lt;/h2>
&lt;p>Node：在这里时间片只是一种描述，理解 CPU 的并行与并发概念就好&lt;/p>
&lt;p>1、CPU 时间分片、多线程？
如果线程数不多于 CPU 核心数，会把各个线程都分配一个核心，不需分片，而当线程数多于 CPU 核心数时才会分片。&lt;/p>
&lt;p>2、并发和并行的区别&lt;/p>
&lt;ul>
&lt;li>并发：当有多个线程在操作时,如果系统只有一个 CPU,把 CPU 运行时间划分成若干个时间片,分配给各个线程执行，在一个时间段的线程代码运行时，其它线程处于挂起状态。这种方式我们称之为_ _&lt;strong>Concurrent(并发)&lt;/strong>。并发=间隔发生&lt;/li>
&lt;li>并行：当系统有一个以上 CPU 时,则线程的操作有可能非并发。当一个 CPU 执行一个线程时，另一个 CPU 可以执行另一个线程，两个线程互不抢占 CPU 资源，可以同时进行，这种方式我们称之为 &lt;strong>Parallel(并行)&lt;/strong>。 并行=同时进行&lt;/li>
&lt;/ul>
&lt;p>区别：并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔内发生。&lt;/p>
&lt;p>并行是同时做多件事情。&lt;/p>
&lt;p>并发表示同时发生了多件事情，通过时间片切换，哪怕只有单一的核心，也可以实现“同时做多件事情”这个效果。&lt;/p>
&lt;p>根据底层是否有多处理器，并发与并行是可以等效的，这并不是两个互斥的概念。&lt;/p>
&lt;p>举个我们开发中会遇到的例子，我们说资源请求并发数达到了 1 万。这里的意思是有 1 万个请求同时过来了。但是这里很明显不可能真正的同时去处理这 1 万个请求的吧！&lt;/p>
&lt;p>如果这台机器的处理器有 4 个核心，不考虑超线程，那么我们认为同时会有 4 个线程在跑。也就是说，并发访问数是 1 万，而底层真实的并行处理的请求数是 4。如果并发数小一些只有 4 的话，又或者你的机器牛逼有 1 万个核心，那并发在这里和并行一个效果。也就是说，并发可以是虚拟的同时执行，也可以是真的同时执行。而并行的意思是真的同时执行。&lt;/p>
&lt;p>结论是：并行是我们物理时空观下的同时执行，而并发则是操作系统用线程这个模型抽象之后站在线程的视角上看到的“同时”执行。&lt;/p>
&lt;h3 id="time-slice时间片-概念">time slice(时间片) 概念&lt;/h3>
&lt;blockquote>
&lt;p>参考：&lt;a href="https://en.wikipedia.org/wiki/Preemption_(computing)#Time_slice">https://en.wikipedia.org/wiki/Preemption_(computing)#Time_slice&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>The period of time for which a process is allowed to run in a preemptive multitasking system is generally called the &lt;em>time slice&lt;/em> or &lt;em>quantum&lt;/em>.&lt;/p>
&lt;p>&lt;strong>time slice(时间片)&lt;/strong> 是一个程序运行在&lt;a href="https://en.wikipedia.org/wiki/Preemption_(computing)">抢占式多任务系统&lt;/a>中的一段时间。也可以称为 quantum(量子)。&lt;/p>
&lt;h2 id="cpu-使用率概念">CPU 使用率概念&lt;/h2>
&lt;p>CPU 不像硬盘、内存，并不具备逻辑上数量、大小、空间之类的概念。只要使用 CPU，就是使用了这个 CPU 的全部，也就无法通过大小之类的概念来衡量一个 CPU，所以我们日常所说的 CPU 的使用率 ，实际上是指的在一段时间范围内，CPU 执行 &lt;strong>Tasks(任务)&lt;/strong> 花费时间的百分比。比如 60 分钟内，一颗 CPU 执行各种任务花费了 6 分钟，则 CPU 在这一小时时间内的使用率为 10%。&lt;/p>
&lt;blockquote>
&lt;p>上文说的 &lt;strong>Tasks(任务)&lt;/strong>，即会指系统中的进程、线程，也代表各种硬件去请求 CPU 执行的各种事情，比如网卡接收到数据，就会告诉 CPU 需要处理(i.e.中断)。&lt;/p>
&lt;/blockquote>
&lt;p>在 Linux 系统中，CPU 的使用率一般可分为 4 大类：&lt;/p>
&lt;ol>
&lt;li>User Time(用户进程运行时间)&lt;/li>
&lt;li>System Time(系统内核运行时间)&lt;/li>
&lt;li>Idle Time(空闲时间)&lt;/li>
&lt;li>Steal Time(被抢占时间)&lt;/li>
&lt;/ol>
&lt;p>除了 Idle Time 外，CPU 在其余时间都处于工作运行状态。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/srucoz/1616168021555-68fba1de-f5d5-462d-bef6-a78b476521ad.png" alt="">&lt;/p>
&lt;p>通常而言，我们泛指的整体 CPU 使用率为 User Time 和 Systime 占比之和(例如 tsar 中 CPU util)，即：
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/srucoz/1616168021559-394ecaa6-59db-453a-b5b1-c5ab88193f49.png" alt="">&lt;/p>
&lt;p>为了便于定位问题，大多数性能统计工具都将这 4 类时间片进一步扩展成了 8 类，如下图，是在 top 命令的 man 手册中对 CPU 使用率的分类。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/srucoz/1616168021546-ebe53556-f50b-49f2-8477-c10cf2b8f2f5.png" alt="">&lt;/p>
&lt;ul>
&lt;li>us：用户进程空间中未改变过优先级的进程占用 CPU 百分比&lt;/li>
&lt;li>sy：内核空间占用 CPU 百分比&lt;/li>
&lt;li>ni：用户进程空间内改变过优先级的进程占用 CPU 百分比&lt;/li>
&lt;li>id：空闲时间百分比&lt;/li>
&lt;li>wa：等待 I/O 的时间百分比&lt;/li>
&lt;li>hi：硬中断时间百分比&lt;/li>
&lt;li>si：软中断时间百分比&lt;/li>
&lt;li>st：虚拟化时被其余 VM 窃取时间百分比&lt;/li>
&lt;/ul>
&lt;p>这 8 类分片中，除 wa 和 id 外，其余分片 CPU 都处于工作态。&lt;/p>
&lt;h1 id="调度算法">调度算法&lt;/h1>
&lt;blockquote>
&lt;p>详见：&lt;a href="https://www.yuque.com/go/doc/33222924">CPU 调度算法&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>首先明确一个概念：&lt;strong>Task(任务)&lt;/strong>，一个进程从处理到结束就算一个任务，处理网卡收到的数据包也算一个任务。一般来说，CPU 就是在处理一个个的 &lt;strong>Task(任务)&lt;/strong>，并度过其一生。&lt;/p>
&lt;p>在 Linux 内核中，进程和线程都是用 tark_struct 结构体表示的，区别在于线程的 tark_struct 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等，所以 Linux 中的线程也被称为轻量级进程，因为线程的 tark_struct 相比进程的 tark_struct 承载的 资源比较少，因此以「轻」得名。&lt;/p>
&lt;p>一般来说，没有创建线程的进程，是只有单个执行流，它被称为是主线程。如果想让进程处理更多的事情，可以创建多个线程分别去处理，但不管怎么样，它们对应到内核里都是 tark_struct。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/srucoz/1616168021545-596ecf70-ac19-4620-8845-bfe72ef7bdce.jpeg" alt="">&lt;/p>
&lt;p>所以，Linux 内核里的调度器，调度的对象就是 tark_struct，接下来我们就把这个数据结构统称为任务。&lt;/p>
&lt;p>在 Linux 系统中，根据任务的优先级以及响应要求，主要分为两种，其中优先级的数值越小，优先级越高：&lt;/p>
&lt;ul>
&lt;li>实时任务，对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在 0~99 范围内的就算实时任务；&lt;/li>
&lt;li>普通任务，响应时间没有很高的要求，优先级在 100~139 范围内都是普通任务级别；&lt;/li>
&lt;/ul>
&lt;p>也就是说，在 LInux 内核中，实时任务总是比普通任务的优先级要高。&lt;/p></description></item><item><title>Docs: 5.Memory 管理</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/5.memory-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/5.memory-%E7%AE%A1%E7%90%86/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/HJB_ATQFNqG82YBCRr97CA">公众号,小林 coding-真棒！ 20 张图揭开内存管理的迷雾，瞬间豁然开朗&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/0g3sS63yM2qbBja-blw5Dw">公众号，码农的荒岛求生-神秘！申请内存时底层发生了什么？&lt;/a>(malloc 简介)&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>对任何一台计算机而言，其内存以及其它资源都是有限的。为了让有限的&lt;strong>物理内存&lt;/strong>满足应用程序对内存的大需求量，Linux 采用了称为 **虚拟内存 **的内存管理方式。Linux 将内存划分为容易处理的“内存页”（对于大部分体系结构来说都是 4KB）。Linux 包括了管理可用内存的方式，以及物理和虚拟映射所使用的硬件机制。&lt;/p>
&lt;p>不过内存管理要管理的可不止 4KB 缓冲区。Linux 提供了对 4KB 缓冲区的抽象，例如 slab 分配器。这种内存管理模式使用 4KB 缓冲区为基数，然后从中分配结构，并跟踪内存页使用情况，比如哪些内存页是满的，哪些页面没有完全使用，哪些页面为空。这样就允许该模式根据系统需要来动态调整内存使用。&lt;/p>
&lt;p>为了支持多个用户使用内存，有时会出现可用内存被消耗光的情况。由于这个原因，页面可以移出内存并放入磁盘中。这个过程称为交换，因为页面会被从内存交换到硬盘上。内存管理的源代码可以在 ./linux/mm 中找到。&lt;/p>
&lt;h1 id="虚拟内存">虚拟内存&lt;/h1>
&lt;p>如果你是电子相关专业的，肯定在大学里捣鼓过单片机。&lt;/p>
&lt;p>单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。&lt;/p>
&lt;p>另外，单片机的 CPU 是直接操作内存的「物理地址」。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919093-db60b152-2475-49e7-8a9d-813007e27b8d.jpeg" alt="">&lt;/p>
&lt;p>在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。&lt;/p>
&lt;p>操作系统是如何解决这个问题呢？&lt;/p>
&lt;p>这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。&lt;/p>
&lt;p>我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「虚拟地址」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919100-24627511-d5f5-4663-9a2c-76b4b3b75664.jpeg" alt="">&lt;/p>
&lt;p>进程的中间层&lt;/p>
&lt;p>操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。&lt;/p>
&lt;p>如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。&lt;/p>
&lt;p>于是，这里就引出了两种地址的概念：&lt;/p>
&lt;ul>
&lt;li>我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address）&lt;/li>
&lt;li>实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。&lt;/li>
&lt;/ul>
&lt;p>操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919111-7b5c26a3-f885-4ae8-bb6b-2bfab9cef4c9.jpeg" alt="">&lt;/p>
&lt;p>操作系统是如何管理虚拟地址与物理地址之间的关系？&lt;/p>
&lt;p>主要有两种方式，分别是内存分段和内存分页，分段是比较早提出的，我们先来看看内存分段。&lt;/p>
&lt;h2 id="内存分段">内存分段&lt;/h2>
&lt;p>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。&lt;/p>
&lt;p>分段机制下，虚拟地址和物理地址是如何映射的？&lt;/p>
&lt;p>分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919128-c7568177-0bee-4534-84c6-694d268dd85d.jpeg" alt="">&lt;/p>
&lt;p>内存分段-寻址的方式&lt;/p>
&lt;ul>
&lt;li>段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。&lt;/li>
&lt;li>虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。&lt;/li>
&lt;/ul>
&lt;p>在上面了，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919115-2be6810a-fa1d-41f1-92f8-b6390209f15a.jpeg" alt="">&lt;/p>
&lt;p>内存分段-虚拟地址与物理地址&lt;/p>
&lt;p>如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。&lt;/p>
&lt;p>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：&lt;/p>
&lt;ul>
&lt;li>第一个就是内存碎片的问题。&lt;/li>
&lt;li>第二个就是内存交换的效率低的问题。&lt;/li>
&lt;/ul>
&lt;p>接下来，说说为什么会有这两个问题。&lt;/p>
&lt;p>我们先来看看，分段为什么会产生内存碎片的问题？&lt;/p>
&lt;p>我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：&lt;/p>
&lt;ul>
&lt;li>游戏占用了 512MB 内存&lt;/li>
&lt;li>浏览器占用了 128MB 内存&lt;/li>
&lt;li>音乐占用了 256 MB 内存。&lt;/li>
&lt;/ul>
&lt;p>这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。&lt;/p>
&lt;p>如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919115-056b2c69-14f1-48d7-8162-7915c80cd090.jpeg" alt="">&lt;/p>
&lt;p>内存碎片的问题&lt;/p>
&lt;p>这里的内存碎片的问题共有两处地方：&lt;/p>
&lt;ul>
&lt;li>外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；&lt;/li>
&lt;li>内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；&lt;/li>
&lt;/ul>
&lt;p>针对上面两种内存碎片的问题，解决的方式会有所不同。&lt;/p>
&lt;p>解决外部内存碎片的问题就是内存交换。&lt;/p>
&lt;p>可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。&lt;/p>
&lt;p>这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。&lt;/p>
&lt;p>再来看看，分段为什么会导致内存交换效率低的问题？&lt;/p>
&lt;p>对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。&lt;/p>
&lt;p>因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。&lt;/p>
&lt;p>所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。&lt;/p>
&lt;p>为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了内存分页。&lt;/p>
&lt;h2 id="内存分页">内存分页&lt;/h2>
&lt;p>分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。&lt;/p>
&lt;p>要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。&lt;/p>
&lt;p>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。&lt;/p>
&lt;p>虚拟地址与物理地址之间通过页表来映射，如下图：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919131-ca0a6877-5b8c-49fc-8982-ff9bd4f247a2.jpeg" alt="">&lt;/p>
&lt;p>内存映射&lt;/p>
&lt;p>页表实际上存储在 CPU 的内存管理单元 （MMU） 中，于是 CPU 就可以直接通过 MMU，找出要实际要访问的物理内存地址。&lt;/p>
&lt;p>而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。&lt;/p>
&lt;p>分页是怎么解决分段的内存碎片、内存交换效率低的问题？&lt;/p>
&lt;p>由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。&lt;/p>
&lt;p>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919157-7b5cfce7-6d02-4a53-8193-49982f06399f.jpeg" alt="">&lt;/p>
&lt;p>换入换出&lt;/p>
&lt;p>更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。&lt;/p>
&lt;p>分页机制下，虚拟地址和物理地址是如何映射的？&lt;/p>
&lt;p>在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919140-c0d128d7-0238-450c-981a-8477221071a4.jpeg" alt="">&lt;/p>
&lt;p>内存分页寻址&lt;/p>
&lt;p>总结一下，对于一个内存地址转换，其实就是这样三个步骤：&lt;/p>
&lt;ul>
&lt;li>把虚拟内存地址，切分成页号和偏移量；&lt;/li>
&lt;li>根据页号，从页表里面，查询对应的物理页号；&lt;/li>
&lt;li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。&lt;/li>
&lt;/ul>
&lt;p>下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919128-24ebe4f8-b4c8-407b-8dc5-98da804e5e0c.jpeg" alt="">&lt;/p>
&lt;p>虚拟页与物理页的映射&lt;/p>
&lt;p>这看起来似乎没什么毛病，但是放到实际中操作系统，这种简单的分页是肯定是会有问题的。&lt;/p>
&lt;p>简单的分页有什么缺陷吗？&lt;/p>
&lt;p>有空间上的缺陷。&lt;/p>
&lt;p>因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。&lt;/p>
&lt;p>在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。&lt;/p>
&lt;p>这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。&lt;/p>
&lt;p>那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。&lt;/p>
&lt;h3 id="多级页表">多级页表&lt;/h3>
&lt;p>要解决上面的问题，就需要采用的是一种叫作多级页表（Multi-Level Page Table）的解决方案。&lt;/p>
&lt;p>在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。&lt;/p>
&lt;p>我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919185-cc42b53c-b247-413b-b8ea-9545012c17a3.jpeg" alt="">&lt;/p>
&lt;p>二级分页&lt;/p>
&lt;p>你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？&lt;/p>
&lt;p>当然如果 4GB 的虚拟地址全部都映射到了物理内上的，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。&lt;/p>
&lt;p>其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的局部性原理么？&lt;/p>
&lt;p>每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。&lt;/p>
&lt;p>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB&lt;/p>
&lt;p>，这对比单级页表的 4MB 是不是一个巨大的节约？&lt;/p>
&lt;p>那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。&lt;/p>
&lt;p>我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。&lt;/p>
&lt;p>对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：&lt;/p>
&lt;ul>
&lt;li>全局页目录项 PGD（Page Global Directory）；&lt;/li>
&lt;li>上层页目录项 PUD（Page Upper Directory）；&lt;/li>
&lt;li>中间页目录项 PMD（Page Middle Directory）；&lt;/li>
&lt;li>页表项 PTE（Page Table Entry）；&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919165-47fbe1d8-e5a2-421b-9215-5152f9f6d457.jpeg" alt="">&lt;/p>
&lt;p>四级目录&lt;/p>
&lt;h3 id="tlb">TLB&lt;/h3>
&lt;p>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。&lt;/p>
&lt;p>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919150-0d7ed5fb-19de-4398-84ca-e77a4c67ab46.jpeg" alt="">&lt;/p>
&lt;p>程序的局部性&lt;/p>
&lt;p>我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 Translation Lookaside Buffer(转译后备缓冲器，简称 TLB、缓存、快表)等。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919151-684032a9-151a-4c86-be9a-7535abfc6444.jpeg" alt="">&lt;/p>
&lt;p>地址转换&lt;/p>
&lt;p>在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。&lt;/p>
&lt;p>有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。&lt;/p>
&lt;p>TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。&lt;/p>
&lt;h2 id="段页式内存管理">段页式内存管理&lt;/h2>
&lt;p>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919147-0a7f2b14-9364-4a8e-ba60-c48e8cdf65d0.jpeg" alt="">&lt;/p>
&lt;p>段页式地址空间&lt;/p>
&lt;p>段页式内存管理实现的方式：&lt;/p>
&lt;ul>
&lt;li>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；&lt;/li>
&lt;li>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；&lt;/li>
&lt;/ul>
&lt;p>这样，地址结构就由段号、段内页号和页内位移三部分组成。&lt;/p>
&lt;p>用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919172-07b25f4c-02c8-47f2-a784-d89ba249e13e.jpeg" alt="">&lt;/p>
&lt;p>段页式管理中的段表、页表与内存的关系&lt;/p>
&lt;p>段页式地址变换中要得到物理地址须经过三次内存访问：&lt;/p>
&lt;ul>
&lt;li>第一次访问段表，得到页表起始地址；&lt;/li>
&lt;li>第二次访问页表，得到物理页号；&lt;/li>
&lt;li>第三次将物理页号与页内位移组合，得到物理地址。&lt;/li>
&lt;/ul>
&lt;p>可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。&lt;/p>
&lt;h1 id="linux-内存管理">Linux 内存管理&lt;/h1>
&lt;p>那么，Linux 操作系统采用了哪种方式来管理内存呢？&lt;/p>
&lt;p>在回答这个问题前，我们得先看看 Intel 处理器的发展历史。&lt;/p>
&lt;p>早期 Intel 的处理器从 80286 开始使用的是段式内存管理。但是很快发现，光有段式内存管理而没有页式内存管理是不够的，这会使它的 X86 系列会失去市场的竞争力。因此，在不久以后的 80386 中就实现了对页式内存管理。也就是说，80386 除了完成并完善从 80286 开始的段式内存管理的同时还实现了页式内存管理。&lt;/p>
&lt;p>但是这个 80386 的页式内存管理设计时，没有绕开段式内存管理，而是建立在段式内存管理的基础上，这就意味着，页式内存管理的作用是在由段式内存管理所映射而成的的地址上再加上一层地址映射。&lt;/p>
&lt;p>由于此时段式内存管理映射而成的地址不再是“物理地址”了，Intel 就称之为“线性地址”（也称虚拟地址）。于是，段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919178-17fb261b-55fa-44ac-a553-ed8a842e9080.jpeg" alt="">&lt;/p>
&lt;p>Intel X86 逻辑地址解析过程&lt;/p>
&lt;p>这里说明下逻辑地址和线性地址：&lt;/p>
&lt;ul>
&lt;li>程序所使用的地址，通常是没被段式内存管理映射的地址，称为逻辑地址；&lt;/li>
&lt;li>通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址；&lt;/li>
&lt;/ul>
&lt;p>逻辑地址是「段式内存管理」转换前的地址，线性地址则是「页式内存管理」转换前的地址。&lt;/p>
&lt;p>了解完 Intel 处理器的发展历史后，我们再来说说 Linux 采用了什么方式管理内存？&lt;/p>
&lt;p>Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制。&lt;/p>
&lt;p>这主要是上面 Intel 处理器发展历史导致的，因为 Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射。既然 CPU 的硬件结构是这样，Linux 内核也只好服从 Intel 的选择。&lt;/p>
&lt;p>但是事实上，Linux 内核所采取的办法是使段式映射的过程实际上不起什么作用。也就是说，“上有政策，下有对策”，若惹不起就躲着走。&lt;/p>
&lt;p>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。&lt;/p>
&lt;p>我们再来瞧一瞧，Linux 的虚拟地址空间是如何分布的？&lt;/p>
&lt;p>在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919191-4099f869-9dbe-462c-90f6-ff02cec5a9a6.jpeg" alt="">&lt;/p>
&lt;p>用户空间与内存空间&lt;/p>
&lt;p>通过这里可以看出：&lt;/p>
&lt;ul>
&lt;li>32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；&lt;/li>
&lt;li>64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。&lt;/li>
&lt;/ul>
&lt;p>再来说说，内核空间与用户空间的区别：&lt;/p>
&lt;ul>
&lt;li>进程在用户态时，只能访问用户空间内存；&lt;/li>
&lt;li>只有进入内核态后，才可以访问内核空间的内存；&lt;/li>
&lt;/ul>
&lt;p>虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919223-81c46952-4cf1-4b83-a9a5-2bdd118168b6.jpeg" alt="">&lt;/p>
&lt;p>每个进程的内核空间都是一致的&lt;/p>
&lt;p>接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。&lt;/p>
&lt;p>我们看看用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/odexpg/1616167919192-30c3ec2b-724a-4146-9bc4-3c630ea69e13.jpeg" alt="">&lt;/p>
&lt;p>虚拟内存空间划分&lt;/p>
&lt;p>通过这张图你可以看到，用户空间内存，从低到高分别是 7 种不同的内存段：&lt;/p>
&lt;ul>
&lt;li>程序文件段，包括二进制可执行代码；&lt;/li>
&lt;li>已初始化数据段，包括静态常量；&lt;/li>
&lt;li>未初始化数据段，包括未初始化的静态变量；&lt;/li>
&lt;li>堆段，包括动态分配的内存，从低地址开始向上增长；&lt;/li>
&lt;li>文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关）&lt;/li>
&lt;li>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；&lt;/li>
&lt;/ul>
&lt;p>在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。&lt;/p>
&lt;h1 id="总结">总结&lt;/h1>
&lt;p>为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套的虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。&lt;/p>
&lt;p>每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。&lt;/p>
&lt;p>那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。&lt;/p>
&lt;p>那么对于虚拟地址与物理地址的映射关系，可以有分段和分页的方式，同时两者结合都是可以的。&lt;/p>
&lt;p>内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致内存碎片和内存交换效率低的问题。&lt;/p>
&lt;p>于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 4KB。由于分了页后，就不会产生细小的内存碎片。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。&lt;/p>
&lt;p>再来，为了解决简单分页产生的页表过大的问题，就有了多级页表，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的局部性原理，在 CPU 芯片中加入了 TLB，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。&lt;/p>
&lt;p>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理。于是 Linux 就把所有段的基地址设为 0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。&lt;/p>
&lt;p>另外，Linxu 系统中虚拟空间分布可分为用户态和内核态两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。&lt;/p></description></item><item><title>Docs: 6.File System 管理</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/6.file-system-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/6.file-system-%E7%AE%A1%E7%90%86/</guid><description/></item><item><title>Docs: 7.Process 管理</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/7.process-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/7.process-%E7%AE%A1%E7%90%86/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://blog.csdn.net/ljianhui/article/details/46718835">原文连接&lt;/a>，本文为 IBM RedBook 的 &lt;a href="http://users.polytech.unice.fr/~bilavarn/fichier/elec5_linux/linux_perf_and_tuning_IBM.pdf">Linux Performanceand Tuning Guidelines&lt;/a> 的 1.1 节的翻译&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/fzLcAkYwKhj-9hgoVkTzaw">阿里技术，CPU 飙高，系统性能问题如何排查？&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>进程管理是操作系统的最重要的功能之一。有效率的进程管理能保证一个程序平稳而高效地运行。它包括进程调度、中断处理、信号、进程优先级、上下文切换、进程状态、进度内存等。&lt;/p>
&lt;p>&lt;strong>Process(进程)&lt;/strong> 实际是运行在 CPU 中的一个** Program(应用程序) 的实体**。在 Linux 系统中，能够同时运行多个进程，Linux 通过在短的时间间隔内轮流运行这些进程而实现“多任务”。这一短的时间间隔称为“时间片”，让进程轮流运行的方法称为“进程调度” ，完成调度的程序称为调度程序。&lt;/p>
&lt;p>进程调度控制进程对 CPU 的访问。当需要选择下一个进程运行时，由调度程序选择最值得运行的进程。可运行进程实际上是仅等待 CPU 资源的进程，如果某个进程在等待其它资源，则该进程是不可运行进程。Linux 使用了比较简单的基于优先级的进程调度算法选择新的进程。&lt;/p>
&lt;p>通过多任务机制，每个进程可认为只有自己独占计算机，从而简化程序的编写。每个进程有自己单独的地址空间，并且只能由这一进程访问，这样，操作系统避免了进程之间的互相干扰以及“坏”程序对系统可能造成的危害。 为了完成某特定任务，有时需要综合两个程序的功能，例如一个程序输出文本，而另一个程序对文本进行排序。为此，操作系统还提供进程间的通讯机制来帮助完成这样的任务。Linux 中常见的进程间通讯机制有信号、管道、共享内存、信号量和套接字等。&lt;/p>
&lt;p>内核通过 SCI 提供了一个 API 来创建一个新进程(fork、exec 或 Portable Operating System Interface [POSⅨ] 函数)、停止进程(kill、exit)、并在它们之间进行通信和同步(signal 或者 POSⅨ 机制)。&lt;/p>
&lt;p>计算机实际上可以做的事情实质上非常简单，比如计算两个数的和，再比如在内存中寻找到某个地址等等。这些最基础的计算机动作被称为指令(instruction)。所谓的程序(program)，就是这样一系列指令的所构成的集合。通过程序，我们可以让计算机完成复杂的操作。程序大多数时候被存储为可执行的文件。这样一个可执行文件就像是一个菜谱，计算机可以按照菜谱作出可口的饭菜。&lt;/p>
&lt;p>Program(程序) 和 Process(进程) 的区别是什么呢?&lt;/p>
&lt;ol>
&lt;li>在很久很久以前，计算机刚出现的时候，是没有操作系统的，那时候一台机器只是运行一个程序，得出数据，后来人们为了同时运行多个程序从而研究出了操作系统，在操作系统之上可以运行多个程序&lt;/li>
&lt;li>进程是程序的一个具体实现。类似于按照食谱，真正去做菜的过程。同一个程序可以执行多次，每次都可以在内存中开辟独立的空间来装载，从而产生多个进程。不同的进程还可以拥有各自独立的 IO 接口。&lt;/li>
&lt;/ol>
&lt;p>操作系统的一个重要功能就是为进程提供方便，比如说为进程分配内存空间，管理进程的相关信息等等，就好像是为我们准备好了一个精美的厨房。&lt;/p>
&lt;h2 id="进程的生命周期">进程的生命周期&lt;/h2>
&lt;p>每一个进程都有其生命周期，例如创建、运行、终止和消除。这些阶段会在系统启动和运行中重复无数次。因此，进程的生命周期对于其性能的分析是非常重要的。下图展示了经典的进程生命周期。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507353-2f676d82-88da-483c-a939-399f284d6425.jpeg" alt="">
不会关闭的常驻进程可以称为 &lt;strong>Daemon Process(守护进程，简称 Daemon)&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>一般 daemon 的名称都会在进程名后加一个字母 d 作为 daemon 的 process，比如 vsftp 的 daemon 就是 vsftpd。&lt;/p>
&lt;/blockquote>
&lt;p>当一个进程创建一个新的进程，创建进程(父进程)的进程调用 一个 fork() 系统调用。当 fork() 系统调用被调用，它得到该新创建进程（子进程）的进程描述并调用一个新的进程 id。它复制该值到父进程进程描述到子进程中。此时整个的父进程的地址空间是没有被复制的；父子进程共享相同的地址空间。&lt;/p>
&lt;p>exec() 系统调用复制新的程序到子进程的地址空间。因为父子进程共享地址空间，写入一个新的程序的数据会引起一个分页错误。在这种情况下，内存会分配新的物理内存页给子进程。&lt;/p>
&lt;p>这个推迟的操作叫作写时复制。子进程通常运行他们自己的程序而不是与父进程运行相同的程序。这个操作避免了不必要的开销，因为复制整个地址空间是一个非常缓慢和效率低下的操作，它需要使用大量的处理器时间和资源。&lt;/p>
&lt;p>当程序已经执行完成，子进程通过调用 exit()系统调用终止。exit()系统调用释放进程大部分的数据并通过发送一个信号通知其父进程。此时，子进程是一个被叫作僵尸进程的进程（参阅 page 7 的“Zombie processes”）。&lt;/p>
&lt;p>子进程不会被完全移除直到其父进程知道其子进程的调用 wait()系统调用而终止。当父进程被通知子进程终止，它移除子进程的所有数据结构并释放它的进程描述。&lt;/p>
&lt;h2 id="父进程与子进程">父进程与子进程&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507409-d531245f-abbe-4a2a-b575-d2ae72c6949f.jpeg" alt="">&lt;/p>
&lt;ul>
&lt;li>用颜色的线标示的两列，左侧的为进程号(PID)右侧的为父进程号(PPID)&lt;/li>
&lt;li>子进程与父进程的环境变量相同&lt;/li>
&lt;li>老进程成为新进程的父进程(parent process)，而相应的，新进程就是老的进程的子进程(child process)。一个进程除了有一个 PID 之外，还会有一个 PPID(parent PID)来存储的父进程 PID。如果我们循着 PPID 不断向上追溯的话，总会发现其源头是 init 进程。所以说，所有的进程也构成一个以 init 为根的树状结构。&lt;/li>
&lt;li>如上图所示，我们查询当前 shell 下的进程：
&lt;ul>
&lt;li>我们可以看到，第二个进程 ps 是第一个进程 bash 的子进程。&lt;/li>
&lt;li>还可以用 &lt;code>pstree&lt;/code> 命令来显示整个进程树。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>fork() 通常作为一个函数被调用。这个函数会有两次返回，将子进程的 PID 返回给父进程，0 返回给子进程。实际上，子进程总可以查询自己的 PPID 来知道自己的父进程是谁，这样，一对父进程和子进程就可以随时查询对方。&lt;/li>
&lt;li>通常在调用 fork 函数之后，程序会设计一个 if 选择结构。当 PID 等于 0 时，说明该进程为子进程，那么让它执行某些指令,比如说使用 exec 库函数(library function)读取另一个程序文件，并在当前的进程空间执行 (这实际上是我们使用 fork 的一大目的: 为某一程序创建进程)；而当 PID 为一个正整数时，说明为父进程，则执行另外一些指令。由此，就可以在子进程建立之后，让它执行与父进程不同的功能。&lt;/li>
&lt;/ul>
&lt;h3 id="子进程的-termination终结">子进程的 termination(终结)&lt;/h3>
&lt;p>当子进程终结时，它会通知父进程，并清空自己所占据的内存，并在内核里留下自己的退出信息(exit code，如果顺利运行，为 0；如果有错误或异常状况，为&amp;gt;0 的整数)。在这个信息里，会解释该进程为什么退出。父进程在得知子进程终结时，有责任对该子进程使用 wait 系统调用。这个 wait 函数能从内核中取出子进程的退出信息，并清空该信息在内核中所占据的空间。但是，如果父进程早于子进程终结，子进程就会成为一个孤儿(orphand)进程。孤儿进程会被过继给 init 进程，init 进程也就成了该进程的父进程。init 进程负责该子进程终结时调用 wait 函数。&lt;/p>
&lt;p>当然，一个糟糕的程序也完全可能造成子进程的退出信息滞留在内核中的状况（父进程不对子进程调用 wait 函数），这样的情况下，子进程成为僵尸(zombie)进程。当大量僵尸进程积累时，内存空间会被挤占。&lt;/p>
&lt;h2 id="thread线程">Thread(线程)&lt;/h2>
&lt;p>一个线程是一个单独的进程生成的一个执行单元。它与其他的线程并行地运行在同一个进程中。各个线程可以共享进程的资源，例如内存、地址空间、打开的文件等等。它们能访问相同的程序数据集。线程也被叫作轻量级的进程（Light Weight Process，LWP）。因为它们共享资源，所以每个线程不应该在同一时间改变它们共享的资源。互斥的实现、锁、序列化等是用户程序的责任。&lt;/p>
&lt;p>从性能的角度来说，创建线程的开销比创建进程少，因数创建一个线程时不需要复制资源。另一方面，进程和线程拥在调度算法上有相似的特性。&lt;strong>内核以相似的方式处理它们&lt;/strong>。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507380-b6ae3b1e-b47c-454c-b3c7-9942dde4f480.jpeg" alt="">
所以，一个进程创建的线程，也是可以运行在多个 CPU 上的。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616645843002-c07df4a7-3d7a-4969-8203-4bc20169721a.png" alt="image.png">
在现在的 Linux 实现中，线程支持 UNIX 的可移植操作系统接口（POSIX）标准库。在 Linux 操作系统中有几种可用的线程实现。以下是广泛使用的线程库：&lt;/p>
&lt;p>Linux Threads 自从 Linux 内核 2.0 起就已经被作为默认的线程实现。Linux Threads 的一些实现并不符合 POSIX 标准。Native POSIX Thread Library（NPTL）正在取代 Linux Threads。Linux Threads 在将来的 Linux 企业发行版中将不被支持。&lt;/p>
&lt;p>Native POSIX Thread Libary（NPTL）&lt;/p>
&lt;p>NPTL 最初是由红帽公司开发的。NPTL 与 POSIX 更加兼容。通过 Linux 内核 2.6 的高级特性，例如，新的 clone()系统调用、信号处理的实现等等，它具有比 LinuxThreads 更高的性能和伸缩性。&lt;/p>
&lt;p>NPTL 与 LinuxThreads 有一些不兼容。一个依赖于 LinuxThreads 的应用可能不能在 NPTL 实现中工作。&lt;/p>
&lt;p>Next Generation POSIX Thread（NGPT）&lt;/p>
&lt;p>NGPT 是一个 IBM 开发的 POSIX 线程库。现在处于维护阶段并且在未来也没有开发计划。&lt;/p>
&lt;p>使用 LD_ASSUME_KERNEL 环境变量，你可以选择在应用中使用哪一个线程库。&lt;/p>
&lt;h2 id="linux-内核代码中的-process">Linux 内核代码中的 Process&lt;/h2>
&lt;p>在 Linux 中，&lt;strong>Process(进程) 属于&lt;/strong> &lt;strong>Task(任务)&lt;/strong> 的一种类型，都被 task_struct 结构管理，该结构同时被叫作进程描述。一个进程描述包含一个运行进程所有的必要信息，例如进程标识、进程属性和构建进程的资源。如果你了解该进程构造，你就能理解对于进程的运行和性能来说，什么是重要的。&lt;/p>
&lt;p>v5.14 代码：&lt;a href="https://github.com/torvalds/linux/blob/v5.14/include/linux/sched.h#L661">include/linux/sched.h&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">struct&lt;/span> task_struct {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#ifdef CONFIG_THREAD_INFO_IN_TASK
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">/*
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"> * For reasons of header soup (see current_thread_info()), this
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"> * must be the first element of task_struct.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"> */&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">struct&lt;/span> thread_info thread_info;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#endif
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> ......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 进程状态
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">unsigned&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> __state;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 进程唯一标识符
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">pid_t&lt;/span> pid;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pid_t&lt;/span> tgid;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 进程名称，上限 16 字符
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">char&lt;/span> comm[TASK_COMM_LEN];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// 打开的文件
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> files_struct &lt;span style="color:#f92672">*&lt;/span>files;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>下图展示了进程结构相关的进程信息概述。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507336-aaeec645-b9df-41c3-99ab-6bf39aed4f42.jpeg" alt="">
其实从这里能看出来，从某种角度来看，**对于内核来说并没有线程这个概念。Linux 把所有的线程都当做进程来实现，内核也没有特别的调度算法来处理线程。**线程仅仅被视为一个与其他进程共享某些资源的进程，和进程一样，每个线程也都是有自己的 &lt;code>task_struct&lt;/code>，所以在内核中，线程看起来就是一个普通的进程。线程也被称作轻量级进程，一个进程可以有多个线程，线程拥有自己独立的栈，切换也由操作系统调度。在 Linux 上可以通过 &lt;code>pthread_create()&lt;/code> 方法或者 &lt;code>clone()&lt;/code> 系统调用创建；&lt;/p>
&lt;h1 id="进程优先级和-nice-值">进程优先级和 nice 值&lt;/h1>
&lt;p>进程优先级是一个数值，它通过动态的优先级和静态的优先级来决定进程被 CPU 处理的顺序。一个拥有更高进程优先级的进程拥有更大的机率得到处理器的处理。&lt;/p>
&lt;p>内核根据进程的行为和特性使用试探算法，动态地调整调高或调低动态优先级。一个用户进程可以通过使用进程的 nice 值间接改变静态优先级。一个拥有更高静态优先级的进程将会拥有更长的时间片（进程能在处理上运行多长时间）。&lt;/p>
&lt;p>Linux 支持从 19（最低优先级）到-20（最高优先级）的 nice 值。默认值为 0。把程序的 nice 值修改为负数（使进程的优先级更高），需要以 root 身份登陆或使用 su 命令以 root 身份执行。&lt;/p>
&lt;h1 id="上下文切换">上下文切换&lt;/h1>
&lt;p>在进程运行过程中，进程的运行信息被保存于处理器的寄存器和它的缓存中。正在执行的进程加载到寄存器中的数据集被称为上下文。为了切换进程，运行中进程的上下文将会被保存，接下来的运行进程的上下文将被被恢复到寄存器中。进程描述和内核模式堆栈的区域将会用来保存上下文。这个切换被称为上下文切换。过多的上下文切换是不受欢迎的，因为处理器每次都必须清空刷新寄存器和缓存，为新的进程制造空间。它可能会引起性能问题。&lt;/p>
&lt;p>下图说明了上下文切换如何工作。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507475-6f5a9385-f033-4c00-8344-2953197b973c.jpeg" alt="">&lt;/p>
&lt;h1 id="中断处理">中断处理&lt;/h1>
&lt;p>中断处理是优先级最高的任务之一。中断通常由 I/O 设备产生，例如网络接口卡、键盘、磁盘控制器、串行适配器等等。中断处理器通过一个事件通知内核（例如，键盘输入、以太网帧到达等等）。它让内核中断进程的执行，并尽可能快地执行中断处理，因为一些设备需要快速的响应。它是系统稳定的关键。当一个中断信号到达内核，内核必须切换当前的进程到一个新的中断处理进程。这意味着中断引起了上下文切换，因此大量的中断将会引起性能的下降。&lt;/p>
&lt;p>在 Linux 的实现中，有两种类型的中断。硬中断是由请求响应的设备发出的（磁盘 I/O 中断、网络适配器中断、键盘中断、鼠标中断）。软中断被用于处理可以延迟的任务（TCP/IP 操作，SCSI 协议操作等等）。你可以在 &lt;code>/proc/interrupts&lt;/code> 文件中查看硬中断的相关信息。&lt;/p>
&lt;p>在多处理器的环境中，中断被每一个处理器处理。绑定中断到单个的物理处理中能提高系统的性能。更多的细节，请参阅 4.4.2，“CPU 的中断处理亲和力”。&lt;/p>
&lt;h1 id="进程的状态">进程的状态&lt;/h1>
&lt;p>每一个进程拥有自己的状态，状态表示了进程当前在发生什么。LINUX 2.6 以后的内核中，在进程的执行期间进程的状态会发生改变，进程一般存在 7 种基础状态：D-不可中断睡眠、R-可执行、S-可中断睡眠、T-暂停态、t-跟踪态、X-死亡态、Z-僵尸态，这几种状态在 ps 命令的 man 手册中有对应解释。&lt;/p>
&lt;ul>
&lt;li>**D **＃不间断的睡眠（通常是 IO）&lt;/li>
&lt;li>&lt;strong>R&lt;/strong> ＃正在运行或可运行（在运行队列上）&lt;/li>
&lt;li>&lt;strong>S&lt;/strong> ＃可中断的睡眠（等待事件完成）&lt;/li>
&lt;li>&lt;strong>T&lt;/strong> ＃被作业控制信号停止&lt;/li>
&lt;li>**t **＃在跟踪过程中被调试器停止&lt;/li>
&lt;li>&lt;strong>X&lt;/strong> ＃已死（永远都不会出现）&lt;/li>
&lt;li>&lt;strong>Z&lt;/strong> ＃已终止运行（“僵尸”）的进程，已终止但未由其父进程获得&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507456-ca89ed8d-d8a1-4cd6-96ab-c78372840f4a.jpeg" alt="">&lt;/p>
&lt;h2 id="d-task_uninterruptible不可中断睡眠态">D (TASK_UNINTERRUPTIBLE)，不可中断睡眠态。&lt;/h2>
&lt;p>顾名思义，位于这种状态的进程处于睡眠中，并且不允许被其他进程或中断(异步信号)打断。因此这种状态的进程，是无法使用 kill -9 杀死的(kill 也是一种信号)，除非重启系统(没错，就是这么头硬)。不过这种状态一般由 I/O 等待(比如磁盘 I/O、网络 I/O、外设 I/O 等)引起，出现时间非常短暂，大多很难被 PS 或者 TOP 命令捕获(除非 I/O HANG 死)。SLEEP 态进程不会占用任何 CPU 资源。&lt;/p>
&lt;h2 id="r-task_running可执行态">R (TASK_RUNNING)，可执行态。&lt;/h2>
&lt;p>这种状态的进程都位于 CPU 的可执行队列中，正在运行或者正在等待运行，即不是在上班就是在上班的路上。&lt;/p>
&lt;p>在此状态下，表示进程正在 CPU 中运行或在队列中等待运行（运行队列）。&lt;/p>
&lt;h2 id="s-task_interruptible可中断睡眠态">S (TASK_INTERRUPTIBLE)，可中断睡眠态。&lt;/h2>
&lt;p>不同于 D，这种状态的进程虽然也处于睡眠中，但是是允许被中断的。这种进程一般在等待某事件的发生（比如 socket 连接、信号量等），而被挂起。一旦这些时间完成，进程将被唤醒转为 R 态。如果不在高负载时期，系统中大部分进程都处于 S 态。SLEEP 态进程不会占用任何 CPU 资源。&lt;/p>
&lt;p>在此状态下，进程被暂停并等待一个某些条件状态的到达。如果一个进程处于 TASK_INTERRUPTIBLE 状态并接收到一个停止的信号，进程的状态将会被改变并中断操作。一个典型的 TASK_INTERRUPTIBLE 状态的进程的例子是一个进程等待键盘中断。&lt;/p>
&lt;h2 id="t--t-task_stopped--task_traced暂停-or-跟踪态">T &amp;amp; t (TASK_STOPPED &amp;amp; TASK_TRACED)，暂停 or 跟踪态。&lt;/h2>
&lt;p>这种两种状态的进程都处于运行停止的状态。不同之处是暂停态一般由于收到 SIGSTOP、SIGTSTP、SIGTTIN、SIGTTOUT 四种信号被停止，而跟踪态是由于进程被另一个进程跟踪引起(比如 gdb 断点）。暂停态进程会释放所有占用资源。&lt;/p>
&lt;p>TASK_STOPPED 在此状态下的进程被某些信号（如 SIGINT，SIGSTOP）暂停。进程正在等待通过一个信号恢复运行，例如 SIGCONT。&lt;/p>
&lt;h2 id="z-exit_zombietask_zombie-僵尸态">Z (EXIT_ZOMBIE/TASK_ZOMBIE), 僵尸态。&lt;/h2>
&lt;p>这种状态的进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。僵尸态进程会释放除进程入口之外的所有资源。&lt;/p>
&lt;p>当一个进程调用 exit()系统调用退出后，它的父进程应该知道该进程的终止。处于 TASK_ZOMBIE 状态的进程会等待其父进程通知其释放所有的数据结构。&lt;/p>
&lt;p>当一个进程接收到一个信号而终止，它在结束自己之前，通常需要一些时间来结束所有的任务（例如关闭打开的文件）。在这个通常非常短暂的时间内，该进程就是一个僵尸进程。&lt;/p>
&lt;p>进程已经完成所有的关闭任务后，它会向父进程报告其即将终止。有些时候，一个僵尸进程不能把自己终止，这将会引导它的状态显示为 z（zombie）。&lt;/p>
&lt;p>使用 kill 命令来关闭这样的一个进程是不可能的，因为该进程已经被认为已经死掉了。如果你不能清除僵尸进程，你可以结束其父进程，然后僵尸进程也随之消失。但是，如果父进程为 init 进程，你不能结束它。init 进程是一个非常重要的进程，因此可能需要重启系统来清除僵尸进程。&lt;/p>
&lt;h2 id="x-exit_dead-死亡态">X (EXIT_DEAD), 死亡态。&lt;/h2>
&lt;p>进程的真正结束态，这种状态一般在正常系统中捕获不到。&lt;/p>
&lt;h1 id="进程内存段">进程内存段&lt;/h1>
&lt;p>进程使用其自身的内存区域来执行工作。工作的变化根据情况和进程的使用而决定。进程可以拥有不同的工作量特性和不同的数据大小需求。进程必须处理各种数据大小。为了满足需求，Linux 内核为每个进程使用动态申请内存的机制。进程内存分配的数据结构如图 1-7 所示。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507458-2bbc9553-910c-4d66-9ad1-8f45893277da.jpeg" alt="">&lt;/p>
&lt;p>图 1-7 进程地址空间&lt;/p>
&lt;p>进程内存区由以下几部分组成：&lt;/p>
&lt;p>Text 段&lt;/p>
&lt;p>该区域用于存储运行代码。&lt;/p>
&lt;p>Data 段&lt;/p>
&lt;p>数据段包括三个区域。&lt;/p>
&lt;p>– Data：该区域存储已被初始化的数据，如静态变量。&lt;/p>
&lt;p>– BSS：该区域存储初始化为 0 的数据。数据被初始化为 0。&lt;/p>
&lt;p>– Heap：该区域用于根据需求使用 malloc()动态申请的内存。堆向高地址方向增长。&lt;/p>
&lt;p>Stack 段&lt;/p>
&lt;p>该区域用于存储局部变量、函数参数和返回函数的地址。栈向低地址方向增长。&lt;/p>
&lt;p>用户进程的地址空间内存分布可以使用 pmap 命令来查看。你可以使用 ps 命令来查看内存段的大小。可以参阅 2.3.10 的“pmap”，“ps 和 pstree”。&lt;/p>
&lt;h1 id="进程的-exit-code退出码">进程的 exit code(退出码)&lt;/h1>
&lt;p>在 Linux 系统中，程序可以在执行终止后传递值给其父进程，这个值被称为 &lt;strong>exit code(退出码)&lt;/strong> 或 **exit status(退出状态)**或 &lt;strong>reture status(返回码)&lt;/strong>。在 POSIX 系统中，惯例做法是当程序成功执行时 **exit code 为 0 **，当程序执行失败时 **exit code 非 0 **。&lt;/p>
&lt;p>传递状态码为何重要？如果你在命令行脚本上下文中查看状态码，答案显而易见。任何有用的脚本，它将不可避免地要么被其他脚本所使用，要么被 bash 单行脚本包裹所使用。特别是脚本被用来与自动化工具 SaltStack 或者监测工具 Nagios 配合使用。这些工具会执行脚本并检查它的状态，来确定脚本是否执行成功。&lt;/p>
&lt;p>其中最重要的原因是，即使你不定义状态码，它仍然存在于你的脚本中。如果你不定义恰当的退出码，执行失败的脚本可能会返回成功的状态，这样会导致问题，问题大小取决于你的脚本做了什么。&lt;/p>
&lt;p>Linux 提供了一个专门的变量$?来保存上个已执行命令的退出状态码。&lt;/p>
&lt;p>对于需要进行检查的命令，必须在其运行完毕后立刻查看或使用$?变量，它的值会变成由 shell 所执行的最后一条命令的退出状态码。&lt;/p>
&lt;p>一个成功结束的命令的退出状态码是 0，如果一个命令结束时有错误，退出状态码就是一个正数值（1-255）。&lt;/p>
&lt;p>Linux 上执行 exit 可使 shell 以指定的状态值退出。若不设置状态值参数，则 shell 以预设值退出。状态值 0 代表执行成功，其他值代表执行失败。exit 也可用在 script，离开正在执行的 script，回到 shell。&lt;/p>
&lt;p>Linux 错误退出状态码没有什么标准可循，但有一些可用的参考。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ld23ik/1616167507500-9f1aab01-171b-4ece-a6fa-9f576852a403.webp" alt="">&lt;/p>
&lt;p>关于具体的服务，相应的退出码，由开发者代码决定。&lt;/p>
&lt;p>&lt;strong>Linux 进程退出码&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://jin-yang.github.io/post/linux-process-exit-code-introduce.html">https://jin-yang.github.io/post/linux-process-exit-code-introduce.html&lt;/a>&lt;/p>
&lt;p>&lt;strong>Linux 退出状态码及 exit 命令&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://www.cnblogs.com/01-single/p/7206664.html">https://www.cnblogs.com/01-single/p/7206664.html&lt;/a>&lt;/p>
&lt;p>&lt;strong>理解 Exit Code 并学会如何在 Bash 脚本中使用&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://blog.jayxhj.com/2016/02/understanding-exit-codes-and-how-to-use-them-in-bash-scripts">http://blog.jayxhj.com/2016/02/understanding-exit-codes-and-how-to-use-them-in-bash-scripts&lt;/a>&lt;/p>
&lt;p>&lt;strong>Appendix E. Exit Codes With Special Meanings&lt;/strong>&lt;/p>
&lt;p>&lt;a href="http://www.tldp.org/LDP/abs/html/exitcodes.html">http://www.tldp.org/LDP/abs/html/exitcodes.html&lt;/a>&lt;/p>
&lt;p>&lt;strong>What is the authoritative list of Docker Run exit codes?&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://stackoverflow.com/questions/31297616/what-is-the-authoritative-list-of-docker-run-exit-codes">https://stackoverflow.com/questions/31297616/what-is-the-authoritative-list-of-docker-run-exit-codes&lt;/a>&lt;/p>
&lt;p>&lt;strong>Identifying Exit Codes and their meanings&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://support.circleci.com/hc/en-us/articles/360002341673-Identifying-Exit-Codes-and-their-meanings">https://support.circleci.com/hc/en-us/articles/360002341673-Identifying-Exit-Codes-and-their-meanings&lt;/a>&lt;/p>
&lt;p>&lt;strong>OpenShift Exit Status Codes&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://access.redhat.com/documentation/en-US/OpenShift_Online/2.0/html/Cartridge_Specification_Guide/Exit_Status_Codes.html">https://access.redhat.com/documentation/en-US/OpenShift_Online/2.0/html/Cartridge_Specification_Guide/Exit_Status_Codes.html&lt;/a>&lt;/p></description></item><item><title>Docs: 8.Network 管理</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/8.network-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/8.network-%E7%AE%A1%E7%90%86/</guid><description/></item><item><title>Docs: BPF</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/bpf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/bpf/</guid><description/></item><item><title>Docs: 微内核</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/%E5%BE%AE%E5%86%85%E6%A0%B8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.kernel%E5%86%85%E6%A0%B8/%E5%BE%AE%E5%86%85%E6%A0%B8/</guid><description/></item></channel></rss>