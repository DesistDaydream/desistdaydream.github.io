<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – Message Queue(消息队列)</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><description>Recent content in Message Queue(消息队列) on 断念梦</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Kafka原理详解</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;p>Kafka 原理详解&lt;/p>
&lt;p>原创 马哥企业教练团队 马哥 Linux 运维 3 天前&lt;/p>
&lt;p>Kafka 是什么？&lt;/p>
&lt;p>Kafka 是 Apache 旗下的一款分布式流媒体平台，Kafka 是一种高吞吐量、持久性、分布式的发布订阅的消息队列系统。它最初由 LinkedIn(领英)公司发布，使用 Scala 语言编写，与 2010 年 12 月份开源，成为 Apache 的顶级子项目。它主要用于处理消费者规模网站中的所有动作流数据。动作指(网页浏览、搜索和其它用户行动所产生的数据)。&lt;/p>
&lt;p>消息系统分类&lt;/p>
&lt;p>我们知道常见的消息系统有 Kafka、RabbitMQ、ActiveMQ 等等，但是这些消息系统中所使用的消息模式如下两种：&lt;/p>
&lt;p>Peer-to-Peer (Queue)&lt;/p>
&lt;p>简称 PTP 队列模式，也可以理解为点到点。例如单发邮件，我发送一封邮件给小徐，我发送过之后邮件会保存在服务器的云端，当小徐打开邮件客户端并且成功连接云端服务器后，可以自动接收邮件或者手动接收邮件到本地，当服务器云端的邮件被小徐消费过之后，云端就不再存储(这根据邮件服务器的配置方式而定)。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/takfzz/1616130276202-0f04f19a-eec4-44db-a3a5-4880460e16bd.jpeg" alt="">&lt;/p>
&lt;p>名词解释：&lt;/p>
&lt;p>Producer=生产者&lt;/p>
&lt;p>Queue=队列&lt;/p>
&lt;p>Consumer=消费者&lt;/p>
&lt;p>Peer-to-Peer 模式工作原理：&lt;/p>
&lt;p>1.消息生产者 Producer1 生产消息到 Queue，然后 Consumer1 从 Queue 中取出并且消费消息。2.消息被消费后，Queue 将不再存储消息，其它所有 Consumer 不可能消费到已经被其它 Consumer 消费过的消息。3.Queue 支持存在多个 Producer，但是对一条消息而言，只会有一个 Consumer 可以消费，其它 Consumer 则不能再次消费。4.但 Consumer 不存在时，消息则由 Queue 一直保存，直到有 Consumer 把它消费。&lt;/p>
&lt;p>Publish/Subscribe（Topic）&lt;/p>
&lt;p>简称发布/订阅模式。例如我微博有 30 万粉丝，我今天更新了一条微博，那么这 30 万粉丝都可以接收到我的微博更新，大家都可以消费我的消息。&lt;/p>
&lt;p>注：以下图示中的 Pushlisher 是错误的名词，正确的为 Publisher&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/takfzz/1616130276240-fca326b2-c114-47c9-92f9-a54b5e47dc99.jpeg" alt="">&lt;/p>
&lt;p>名词解释：&lt;/p>
&lt;p>Publisher=发布者&lt;/p>
&lt;p>Topic=主题&lt;/p>
&lt;p>Subscriber=订阅者&lt;/p>
&lt;p>Publish/Subscribe 模式工作原理：&lt;/p>
&lt;p>1.消息发布者 Publisher 将消息发布到主题 Topic 中，同时有多个消息消费者 Subscriber 消费该消息。2.和 PTP 方式不同，发布到 Topic 的消息会被所有订阅者消费。3.当发布者发布消息，不管是否有订阅者，都不会报错信息。4.一定要先有消息发布者，后有消息订阅者。&lt;/p>
&lt;p>注意：Kafka 所采用的就是发布/订阅模式，被称为一种高吞吐量、持久性、分布式的发布订阅的消息队列系统。&lt;/p>
&lt;p>常用消息系统对比&lt;/p>
&lt;p>•RabbitMQ Erlang 编写，支持多协议 AMQP，XMPP，SMTP，STOMP。支持负载均衡、数据持久化。同时 支持 Peer-to-Peer 和发布/订阅模式•Redis 基于 Key-Value 对的 NoSQL 数据库，同时支持 MQ 功能，可做轻量级队列服务使用。就入队操作而言， Redis 对短消息(小于 10KB)的性能比 RabbitMQ 好，长消息的性能比 RabbitMQ 差。•ZeroMQ 轻量级，不需要单独的消息服务器或中间件，应用程序本身扮演该角色，Peer-to-Peer。它实质上是 一个库，需要开发人员自己组合多种技术，使用复杂度高•ActiveMQ JMS 实现，Peer-to-Peer，支持持久化、XA 事务•Kafka/Jafka 高性能跨语言的分布式发布/订阅消息系统，数据持久化，全分布式，同时支持在线和离线处理•MetaQ/RocketMQ 纯 Java 实现，发布/订阅消息系统，支持本地事务和 XA 分布式事务&lt;/p>
&lt;p>Kafka 介绍&lt;/p>
&lt;p>Kafka 三大特点&lt;/p>
&lt;p>1.高吞吐量：可以满足每秒百万级别消息的生产和消费。&lt;/p>
&lt;p>2.持久性：有一套完善的消息存储机制，确保数据高效安全且持久化。&lt;/p>
&lt;p>3.分布式：基于分布式的扩展；Kafka 的数据都会复制到几台服务器上，当某台故障失效时，生产者和消费者转而使用其它的 Kafka。&lt;/p>
&lt;p>Kafka 的几个概念&lt;/p>
&lt;p>1.Kafka 作为一个集群运行在一个或多个服务器上，这些服务器可以跨多个机房，所以说 kafka 是分布式的发布订阅消息队列系统。&lt;/p>
&lt;p>2.Kafka 集群将记录流存储在称为 Topic 的类别中。&lt;/p>
&lt;p>3.每条记录由键值；&amp;ldquo;key value&amp;quot;和一个时间戳组成。&lt;/p>
&lt;p>Kafka 的四个核心 API：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/takfzz/1616130276252-1256f05d-0cf7-402b-867c-3ba5568c86b3.jpeg" alt="">&lt;/p>
&lt;p>1.Producer API：生产者 API 允许应用程序将一组记录发布到一个或多个 Kafka Topic 中。2.Consumer API：消费者 API 允许应用程序订阅一个或多个 Topic，并处理向他们传输的记录流。3.Streams API：流 API 允许应用程序充当流处理器，从一个或者多个 Topic 中消费输入流，并将输出流生成为一个或多个输出主题，从而将输入流有效地转换为输出流。4.Connector API：连接器 API 允许构建和运行可重用的生产者或消费者，这些生产者或消费者将 Kafka Topic 连接到现有的应用程序或数据系统。例如：连接到关系数据库的连接器可能会捕获对表的每次更改。&lt;/p>
&lt;p>在 Kafka 中，客户端和服务器之间的通信采用 TCP 协议完成，该协议经过版本控制，新版本与旧版本保存向后兼容性，我们为 Kafka 提供了一个 Java 客户端，但是客户端可以使用多种语言。&lt;/p>
&lt;p>Kafka 架构简介&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/takfzz/1616130276237-feaedd53-58e7-4d88-9693-a6c869df6110.jpeg" alt="">&lt;/p>
&lt;p>上图中画了一下 Kafka 的架构，较为凌乱，相同颜色的线条表示一种功能，但是希望大家能够仔细看下&lt;/p>
&lt;p>•Producer：消息和数据的生产者，主要负责生产 Push 消息到指定 Broker 的 Topic 中。•Broker：Kafka 节点就是被称为 Broker，Broker 主要负责创建 Topic，存储 Producer 所发布的消息，记录消息处理的过程，现是将消息保存到内存中，然后持久化到磁盘。•Topic：同一个 Topic 的消息可以分布在一个或多个 Broker 上，一个 Topic 包含一个或者多个 Partition 分区，数据被存储在多个 Partition 中。•replication-factor：复制因子；这个名词在上图中从未出现，在我们下一章节创建 Topic 时会指定该选项，意思为创建当前的 Topic 是否需要副本，如果在创建 Topic 时将此值设置为 1 的话，代表整个 Topic 在 Kafka 中只有一份，该复制因子数量建议与 Broker 节点数量一致。•Partition：分区；在这里被称为 Topic 物理上的分组，一个 Topic 在 Broker 中被分为 1 个或者多个 Partition，也可以说为每个 Topic 包含一个或多个 Partition，(一般为 kafka 节. 点数 CPU 的总核心数量)分区在创建 Topic 的时候可以指定。分区才是真正存储数据的单元。•Consumer：消息和数据的消费者，主要负责主动到已订阅的 Topic 中拉取消息并消费，为什么 Consumer 不能像 Producer 一样的由 Broker 去 push 数据呢？因为 Broker 不知道 Consumer 能够消费多少，如果 push 消息数据量过多，会造成消息阻塞，而由 Consumer 去主动 pull 数据的话，Consumer 可以根据自己的处理情况去 pull 消息数据，消费完多少消息再次去取。这样就不会造成 Consumer 本身已经拿到的数据成为阻塞状态。•ZooKeeper：ZooKeeper 负责维护整个 Kafka 集群的状态，存储 Kafka 各个节点的信息及状态，实现 Kafka 集群的高可用，协调 Kafka 的工作内容。&lt;/p>
&lt;p>我们可以看到上图，Broker 和 Consumer 有使用到 ZooKeeper，而 Producer 并没有使用到 ZooKeeper，因为 Kafka 从 0.8 版本开始，Producer 并不需要根据 ZooKeeper 来获取集群状态，而是在配置中指定多个 Broker 节点进行发送消息，同时跟指定的 Broker 建立连接，来从该 Broker 中获取集群的状态信息，这是 Producer 可以知道集群中有多少个 Broker 是否在存活状态，每个 Broker 上的 Topic 有多少个 Partition，Prodocuer 会讲这些元信息存储到 Producuer 的内存中。如果 Producoer 像集群中的一台 Broker 节点发送信息超时等故障，Producer 会主动刷新该内存中的元信息，以获取当前 Broker 集群中的最新状态，转而把信息发送给当前可用的 Broker，当然 Prodocuer 也可以在配置中指定周期性的去刷新 Broker 的元信息以更新到内存中。&lt;/p>
&lt;p>注意：只有 Broker 和 ZooKeeper 才是服务，而 Producer 和 Consumer 只是 Kafka 的 SDK 罢了&lt;/p>
&lt;p>主题和日志&lt;/p>
&lt;p>主题和日志官方被称为是 Topic and log。Topic 是记录发布到的类别或者订阅源的名称，Kafka 的 Topic 总是多用户的；也就是说，一个 Topic 可以有零个、一个或者多个消费者订阅写入它的数据。每个 Topic Kafka 集群都为一个 Partition 分区日志，如下图所示：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/takfzz/1616130276222-33e53691-f9e4-4eff-8871-5d6a56e51622.jpeg" alt="">&lt;/p>
&lt;p>每个 Partition 分区都是一个有序的记录序列(不可变),如果有新的日志会按顺序结构化添加到末尾，分区中的记录每个都按顺序的分配一个 ID 号，称之为偏移量，在整个 Partition 中具有唯一性。如上图所示，有 Partition、Partition1、Partition2，其中日志写入的顺序从 Old 到 New，ID 号从 0-12 等。&lt;/p>
&lt;p>Kafka 集群发布过的消息记录会被持久化到硬盘中，无论该消息是否被消费，发布记录都会被 Kafka 保留到硬盘当中，我们可以设置保留期限。例如，如果保留策略我们设置为两天，则在发布记录的两天内，该消息可供使用，之后则被 Kafka 丢弃以释放空间，Kafka 的性能在数据大小方面是非常出色的，可以长时间保留数据不成问题。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/takfzz/1616130276252-41c286e2-c058-45e1-8dbb-bd53b942b190.jpeg" alt="">&lt;/p>
&lt;p>实际上，以消费者为单位地保留的唯一元数据是消费者在日志中的偏移或位置。这个偏移量由消费者控制的：消费者通常会在读取记录时线性地推进偏移量，但事实上，由于消费者的位置时由消费者控制的，所以它可以按照自己喜欢的任何顺序进行消费记录。例如，消费者可以重置之前的偏移量来处理之前的数据，或者直接从最新的偏移量开始消费。这些功能的组合意味着 Kafka 消费者非常的不值一提，他们可以很随便，即使这样，对集群或者其他消费者没有太大影响。例如：可以使用命令工具来“tail”任何 Topic 的内容，而不会更改任何现有使用者所使用的内容。&lt;/p>
&lt;p>日志中分区有几个用途。首先，他们允许日志的大小超出适合单台服务器的大小，每个单独的分区必须适合托管它的服务器，但是一个主题可能有许多分区，因此它可以处理任意数量的数据，其次，他们作为并行的单位-更多的是在一点上。&lt;/p>
&lt;p>Distribution(分布)&lt;/p>
&lt;p>日志 Partition 分区分布在 Kafka 集群中的服务器上，每台服务器都处理数据并请求共享分区。为了实现容错，每个 Partition 分区被复制到多个可配置的 Kafka 集群中的服务器上。&lt;/p>
&lt;p>名词介绍：&lt;/p>
&lt;p>leader：领导者&lt;/p>
&lt;p>followers：追随者&lt;/p>
&lt;p>每个 Partition 分区都有一个 leader(领导者)服务器，是每个 Partition 分区，假如我们的 Partition1 分区分别被复制到了三台服务器上，其中第二台为这个 Partition 分区的领导者，其它两台服务器都会成为这个 Partition 的 followers(追随者)。其中 Partition 分片的 leader(领导者)处理该 Partition 分区的所有读和写请求，而 follower(追随者)被动地复制 leader(领导者)所发生的改变，如果该 Partition 分片的领导者发生了故障等，两个 follower(追随者)中的其中一台服务器将自动成为新的 leader 领导者。每台服务器都充当一些分区的 leader(领导者)和一些分区的 follower(追随者)，因此集群内的负载非常平衡。&lt;/p>
&lt;p>注意：上面讲的 leader 和 follower 仅仅是每个 Partition 分区的领导者和追随者，并不是我们之前学习到的整个集群的主节点和备节点，希望大家不要混淆。&lt;/p>
&lt;p>Geo-Replication(地域复制)&lt;/p>
&lt;p>Kafka Mirrormaker 为集群提供地域复制支持，使用 MirrorMaker，可以跨多个机房或云端来复制数据，可以在主动/被动方案中使用它进行备份和恢复；在主动方案中，可以使数据更接近用户，或支持数据位置要求。&lt;/p>
&lt;p>Producers(生产者)&lt;/p>
&lt;p>生产者将数据发布到他们选择的 Topic，生产者负责选择分配给 Topic 中的哪个分区的记录。这可以通过循环方式来完成，只是为了负载均衡，或者可以根据一些语义分区函数(比如基于记录中的某个键)来完成。&lt;/p>
&lt;p>Consumers(消费者)&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/takfzz/1616130276249-40cdfc85-7b14-4783-9add-ea99966847a1.jpeg" alt="">&lt;/p>
&lt;p>名词介绍&lt;/p>
&lt;p>Consumers：消费者&lt;/p>
&lt;p>Consumers Group：消费者组&lt;/p>
&lt;p>Consumers Group name：消费者组名&lt;/p>
&lt;p>Consumers 使用 Consumers Group name 标记自己，并且发布到 Topic 的每个记录被传递到每个订阅 Consumers Group 中的一个 Consumers 实例，Consumers 实例可以在单独的进程中，也可以在不同的机器，如果所有 Consumers 实例具有相同的 Consumers Group，则记录将有效地在 Consumers 上进行负载均衡。&lt;/p>
&lt;p>如果所有 Consumers 实例在不同的 Consumers Group 中，则每个记录将广播到所有 Consumers 进程中。&lt;/p>
&lt;p>两个 Kafka Cluster，托管了四个 Partition(分区)，从 P0-P3，包含两个 Consumers Group 分别是 Consumer Group A 和 Consumer Group B，Consumners Group A 有两个 Consumers 实例，B 有四个 Consumers 实例。也就是消费者 A 组有两个消费者，B 组有四个消费者。然后，更常见的是，我们发现 Topic 有少量的 Consumers Group，每个消费者对应一个用户组，每个组有许多消费者实例组成，用于可伸缩和容错，这只不过是发布/订阅语义，其中订阅者是一组消费者，而不是单个进程。&lt;/p>
&lt;p>在 Kfaka 中实现消费者的方式是通过在消费者实例上划分日志中的 Partition 分区，以便每个实例在任何时间点都是分配的“相同份额”，维护消费者组成功资格的过程由 Kafka 动态协议实现，如果新的消费者实例加入该消费者组，新消费者实例将从该组的其它成员手里接管一些分区；如果消费者实例故障，其分区将分发给其余消费者实例。&lt;/p>
&lt;p>Kafka 仅提供分区内记录的总顺序，而不是 Topic 中不同分区之间的记录。对于大多数应用程序而言，按分区排序和按键分许数据的能力已经足够，但是如果你需要记录总顺序，则可以使用只有一个分区的 Topic 来实现，尽管这意味着每个消费者组只有一个消费者进程。&lt;/p>
&lt;p>Consumer Group&lt;/p>
&lt;p>我们开始处有讲到消息系统分类：P-T-P 模式和发布/订阅模式，也有说到我们的 Kafka 采用的就是发布订阅模式，即一个消息产生者产生消息到 Topic 中，所有的消费者都可以消费到该条消息，采用异步模型；而 P-T-P 则是一个消息生产者生产的消息发不到 Queue 中，只能被一个消息消费者所消费，采用同步模型 其实发布订阅模式也可以实现 P-T-P 的模式，即将多个消费者加入一个消费者组中，例如有三个消费者组，每个组中有 3 个消息消费者实例，也就是共有 9 个消费者实例，如果当 Topic 中有消息要接收的时候，三个消费者组都会去接收消息，但是每个人都接收一条消息，然后消费者组再将这条消息发送给本组内的一个消费者实例，而不是所有消费者实例，到最后也就是只有三个消费者实例得到了这条消息，当然我们也可以将这些消费者只加入一个消费者组，这样就只有一个消费者能够获得到消息了。&lt;/p>
&lt;p>Guarantees(担保)&lt;/p>
&lt;p>在高级别的 Kafka 中提供了以下保证：&lt;/p>
&lt;p>•生产者发送到特定 Topic 分区的消息将按照其发送顺序附加。也就是说，如果一个 Producers 生产者发送了 M1 和 M2，一般根据顺序来讲，肯定是先发送的 M1，随后发送的 M2，如果是这样，假如 M1 的编号为 1，M2 的编号为 2，那么在日志中就会现有 M1，随后有 M2。•消费者实例按照他们存储在日志中的顺序查看记录。•对于具有复制因子 N 的 Topic，Kafka 最多容忍 N-1 个服务器故障，则不会丢失任何提交到日志的记录。&lt;/p></description></item><item><title>Docs: Message Queue(消息队列)</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid><description>
&lt;p>场景一：日志采集系统，拿 Loki 举例，采集器(promtail)采集数据后，存储到后端日志存储器(Loki)上，当需要采集多个节点，并且当日志大量产生时， Loki 的处理很有可能会出现瓶颈而无法处理写入请求，这时候，我们就想要在 采集器 和 存储中间添加一个缓冲，来减慢后端存储的压力&lt;/p>
&lt;p>而这就是 消息队列 的作用之一，采集器作为 MQ 的生产者，将日志数据传入队列，日志存储器作为 MQ 的消费者，从队列中逐步拿取日志数据并存储。有了这么一个缓冲，Loki 的压力将会得到很大缓和。&lt;/p>
&lt;p>这时候可能还会有这种想法：我直接限制 采集器 的处理逻辑不好么，为什么还要中间再加一层东西，增加故障点。这是为了解耦，采集器的处理逻辑就是采集日志并上传，不要过多关注此行为之外的东西，这样一个产品才能快速迭代，更好的处理逻辑。&lt;/p>
&lt;p>这种行为简称：消减波峰，保护后端(消费端)&lt;/p>
&lt;p>场景二：现代的互联网应用大量地使用了消息队列（Messaging）。消息队列不仅被用于系统内部组件之间的通信，同时也被用于系统跟其它服务之间的交互。消息队列的使用可以增加系统的可扩展性、灵活性和用户体验。非基于消息队列的系统，其运行速度取决于系统中最慢的组件的速度（注：短板效应）。而基于消息队列可以将系统中各组件解除耦合，这样系统就不再受最慢组件的束缚，各组件可以异步运行从而得以更快的速度完成各自的工作。&lt;/p>
&lt;p>总结：消息队列能够将业务逻辑解耦，调用方只需要下达命令而不用等待整个逻辑执行完毕。除此之外消息队列也可以抑制性能波峰的产生，在瞬时业务增长产生时保持性能曲线的平滑。&lt;/p></description></item><item><title>Docs: NSQ 消息队列</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/nsq-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/nsq-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/nsqio/nsq">GitHub 项目，nsqio/nsq&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://nsq.io/">官网&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote></description></item><item><title>Docs: RabbitMQ</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rabbitmq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rabbitmq/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>官方网址：&lt;a href="https://www.rabbitmq.com/">https://www.rabbitmq.com/&lt;/a>&lt;/li>
&lt;li>消息队列模拟器：&lt;a href="http://tryrabbitmq.com/">http://tryrabbitmq.com/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.yuque.com/noobwo/mq/hpiop0">https://www.yuque.com/noobwo/mq/hpiop0&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://m.6-km.com/next/quorum-queues.html">https://m.6-km.com/next/quorum-queues.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/63700605">https://zhuanlan.zhihu.com/p/63700605&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Rabbit Message Queue(Rabbit 消息队列，简称：RabbitMQ)。是一个在 AMQP 基础上实现的，可复用的消息队列服务。&lt;/p>
&lt;p>Advanced Message Queuing Protocol(高级消息队列协议，简称 AMQP) ，是一个提供统消息服务的应用层(7 层)协议。其设计目标是对于消息的排序、路由（包括点对点和订阅-发布）、保持可靠性、保证安全性[1]。AMQP 规范了消息传递方和接收方的行为，以使消息在不同的提供商之间实现互操作性，就像 SMTP，HTTP，FTP 等协议可以创建交互系统一样。与先前的中间件标准（如 Java 消息服务）不同的是，JMS 在特定的 API 接口层面和实现行为上进行了统一，而高级消息队列协议则关注于各种消息如何以字节流的形式进行传递。因此，使用了符合协议实现的任意应用程序之间可以保持对消息的创建、传递。&lt;/p>
&lt;h2 id="工作机制概述">工作机制概述&lt;/h2>
&lt;p>在了解消息通讯之前首先要了解 3 个概念：生产者、消费者和代理。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/vi79ye/1616130695655-d434cc0d-b15a-48c2-9fad-7fa971d2ffa4.jpeg" alt="">&lt;/p>
&lt;p>Publisher(生产者)：消息的创建者，负责创建和推送数据到消息服务器；&lt;/p>
&lt;p>Consumer(消费者)：消息的接收方，用于处理数据和确认消息；&lt;/p>
&lt;p>Broker(代理)：就是 RabbitMQ 本身，用于扮演“快递”的角色，本身不生产消息，只是扮演“快递”的角色。&lt;/p>
&lt;p>消息发送原理&lt;/p>
&lt;p>首先你必须连接到 Rabbit 才能发布和消费消息，那怎么连接和发送消息的呢？&lt;/p>
&lt;p>你的应用程序和 Rabbit Server 之间会创建一个 TCP 连接，一旦 TCP 打开，并通过了认证，认证就是你试图连接 Rabbit 之前发送的 Rabbit 服务器连接信息和用户名和密码，有点像程序连接数据库，使用 Java 有两种连接认证的方式，后面代码会详细介绍，一旦认证通过你的应用程序和 Rabbit 就创建了一条 AMQP 信道（Channel）。&lt;/p>
&lt;p>信道是创建在“真实”TCP 上的虚拟连接，AMQP 命令都是通过信道发送出去的，每个信道都会有一个唯一的 ID，不论是发布消息，订阅队列或者介绍消息都是通过信道完成的。&lt;/p>
&lt;p>为什么不通过 TCP 直接发送命令？&lt;/p>
&lt;p>对于操作系统来说创建和销毁 TCP 会话是非常昂贵的开销，假设高峰期每秒有成千上万条连接，每个连接都要创建一条 TCP 会话，这就造成了 TCP 连接的巨大浪费，而且操作系统每秒能创建的 TCP 也是有限的，因此很快就会遇到系统瓶颈。&lt;/p>
&lt;p>如果我们每个请求都使用一条 TCP 连接，既满足了性能的需要，又能确保每个连接的私密性，这就是引入信道概念的原因。&lt;/p>
&lt;p>其实在生活中，这种模型用得非常多，就比如我们都会接触的网购快递，可以说是一个典型的消息队列的 case 了：&lt;/p>
&lt;p>商家不断的把商品扔给快递公司（注意不是直接将商品给买家），而快递公司则将商品根据地质分发对应的买家&lt;/p>
&lt;p>对上面这个过程进行拆解，可以映射扮演的角色&lt;/p>
&lt;ul>
&lt;li>商品：Message，传递的消息，由商家投递给快递公司时，需要进行打包（一般 Producer 生产消息也会将实体数据进行封装）&lt;/li>
&lt;li>商家：Produer 生产者&lt;/li>
&lt;li>快递公司： Queue，消息的载体&lt;/li>
&lt;li>买家：Consumer 消费者&lt;/li>
&lt;/ul>
&lt;p>那么快递公司时怎么知道要把商品给对应的买家呢？根据包裹上的地址+电话&lt;/p>
&lt;ul>
&lt;li>同样消息队列也需要一个映射规则，实现 Message 和 Consumer 之间的路由&lt;/li>
&lt;/ul>
&lt;h1 id="rabbitmq-基本概念">RabbitMQ 基本概念&lt;/h1>
&lt;ol>
&lt;li>Exchange&lt;/li>
&lt;li>Queue&lt;/li>
&lt;li>Routing key # 一种规则，用于 Exchange 路由消息到匹配到规则的 Queue 上&lt;/li>
&lt;li>Binding # 交换器 与 队列(或另一个交换器) 的关联行为&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/vi79ye/1616130695576-789c9f61-914e-4f88-951c-b1a0915fdc4a.jpeg" alt="">&lt;/p>
&lt;h2 id="broker--指安装了-rabbitmq-的服务器">Broker # 指安装了 RabbitMQ 的服务器&lt;/h2>
&lt;h2 id="virtual-host虚拟主机--类似-rabbitmq-虚拟化的感觉">Virtual Host(虚拟主机) # 类似 RabbitMQ 虚拟化的感觉&lt;/h2>
&lt;p>每个 Rabbit 都能创建很多 vhost 我们称之为虚拟主机，每个虚拟主机其实都是 mini 版的 RabbitMQ，拥有自己的队列，交换器和绑定，拥有自己的权限机制。&lt;/p>
&lt;ol>
&lt;li>RabbitMQ 默认的 vhost 是 / 开箱即用；&lt;/li>
&lt;li>多个 vhost 是隔离的，多个 vhost 无法通讯，并且不用担心命名冲突（队列和交换器和绑定），实现了多层分离；&lt;/li>
&lt;li>创建用户的时候必须指定 vhost；&lt;/li>
&lt;/ol>
&lt;p>注意，从上层角度看，RabbitMQ 实现主要依靠 Exchange 与 Queue 来实现。&lt;/p>
&lt;h2 id="queue队列--用于存储消息">Queue(队列) # 用于存储消息&lt;/h2>
&lt;p>官方文档：&lt;a href="https://www.rabbitmq.com/queues.html">https://www.rabbitmq.com/queues.html&lt;/a>&lt;/p>
&lt;h2 id="exchange交换器--用于接受分配消息">Exchange(交换器) # 用于接受、分配消息&lt;/h2>
&lt;p>官方文档：未知&lt;/p>
&lt;p>客户端向 RebbitMQ 发送消息，并不会直接发送到 Queue 中，而是从 5674 端口到达 Exchange，然后根据路由规则，决定收到消息应该投递到哪个队列上，这些规则其中一部分称为 &lt;strong>Routing key(路由键)&lt;/strong>，另外一部分规则是根据 Exchange 的类型来决定。&lt;/p>
&lt;p>Queue 可以通过 Routing key 关联到 Exchange 上(也可以省略 Routing key 直接绑定)，这种关联行为称为 &lt;strong>Binding(绑定)&lt;/strong>。&lt;/p>
&lt;p>注意：&lt;/p>
&lt;ol>
&lt;li>绑定时所使用的 Routing key 可以使用通配符。&lt;/li>
&lt;li>为了与每个消息中的 Routing key 区分，我们一般称绑定时使用的 Routing key 为 &lt;strong>Binding key(绑定键)&lt;/strong>。&lt;/li>
&lt;/ol>
&lt;p>绑定完成后，当 Exchange 收到消息(&lt;strong>每个消息也可以指定 Routing key&lt;/strong>)后，凡是 Routing key 匹配 Binding key 条件的，则该消息会被发送到具有 Binding key 的队列中。如果匹配多分，则消息在 Exchange 中会复制多份。&lt;/p>
&lt;p>例如：现在发送一条消息，Routing key 为 test.1，两个队列绑定到交换器时，Binding key 分别为 &lt;em>.1 和 test.&lt;/em>，则该消息到达 Exchange 时，会复制为两份，分别发送到这两各队列中。&lt;/p>
&lt;p>&lt;strong>Exchange 的 4 种类型&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>direct # Routing key 与 Binding key 必须完全匹配，不接受通配符匹配。&lt;/li>
&lt;li>fanot # 不需要 routing key，收到消息后，自动将消息复制多份并发送给与自己绑定的队列上。&lt;/li>
&lt;li>headers&lt;/li>
&lt;li>topic # Routing key 与 Binding key 可以根据通配符匹配。匹配规则如下：
&lt;ol>
&lt;li>
&lt;ul>
&lt;li>匹配一个单词&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h1 id="匹配-0-个或多个字符">匹配 0 个或多个字符&lt;/h1>
&lt;/li>
&lt;li>*，# 只能写在.号左右，且不能挨着字符&lt;/li>
&lt;li>单词和单词之间需要用.隔开。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>特殊的 Exchange
&lt;ol>
&lt;li>如果不手动绑定 Exchange 与 Queue，发送消息时不指定 Exchange，但是消息依然可以路由到队列中。&lt;/li>
&lt;li>这是因为每个 vhost 下都有一个 default Exchange。默认的 Exchange 不可以手动绑定，没有名字，不可以删除，direct 类型。每个 Queue 都会与当前 vhost 下的 默认 Exchange 隐式绑定在一起，且 Binding key 为 Queue 名称。&lt;/li>
&lt;li>消息中的 Routing key 必须指定为 Queue 名称，这时消息通过默认的 Exchange 被路由到对应的 Queue 上。这保证了消息准确投递。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h2 id="connection连接--应用程序与-rabbit-之间建立的连接程序代码中使用">Connection(连接) # 应用程序与 Rabbit 之间建立的连接，程序代码中使用&lt;/h2>
&lt;h2 id="channel信道--消息推送使用的通道">Channel(信道) # 消息推送使用的通道&lt;/h2>
&lt;h1 id="rabbitmq-配置">RabbitMQ 配置&lt;/h1></description></item><item><title>Docs: RabbitMQ</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rabbitmq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rabbitmq/</guid><description/></item><item><title>Docs: RocketMQ</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rocketmq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rocketmq/</guid><description/></item><item><title>Docs: RocketMQ</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rocketmq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/message-queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/rocketmq/</guid><description/></item></channel></rss>