<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 5.数据存储</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</link><description>Recent content in 5.数据存储 on 断念梦</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 1.1.Redis 高可用概述</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/1.1.redis-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A6%82%E8%BF%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/1.1.redis-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A6%82%E8%BF%B0/</guid><description>
&lt;p>参考：&lt;a href="http://blog.jboost.cn/redis-cluster.html">原文&lt;/a>、&lt;a href="https://zhuanlan.zhihu.com/p/129640817">知乎&lt;/a>、&lt;a href="https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247492218&amp;amp;idx=1&amp;amp;sn=8e233cf3c3abd0e6821262d1c78b03d1&amp;amp;chksm=eac6c353ddb14a4535ae92f911ae846592066bf9250b9aca4d91287015de8b23347cb56838ce&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1123S90JeR1nwKagOdJBlQTz&amp;amp;sharer_sharetime=1606090661231&amp;amp;sharer_shareid=09464b4a0389b967659ba78076a1ef58&amp;amp;key=48765414c6ece973eab40bd813ac84f36f02f86a2b622e5efcf4fb98864fdb95a49286689ce7513bf3642cc2a2b6d4bd4235c0de418caee7320bf928f76e57b65a7c762b34b8e80ed88a847524e64e1d6e08271ee31db62eb4ff0bce50cdc03f2b4161ba26993d58b1f19972154a004ce4cadfca3a79f41936616473cacfeff7&amp;amp;ascene=1&amp;amp;uin=MTI5NTMzMzA0MQ%3D%3D&amp;amp;devicetype=Windows+10+x64&amp;amp;version=6300002f&amp;amp;lang=zh_CN&amp;amp;exportkey=AanBDsftQoVwZuEgK1A5lo8%3D&amp;amp;pass_ticket=S1%2BMQ7vYsbZSNuJMJOqmLPRlt4Y3dQwyWaD%2FAmp3sq1Yd7omWT6hEhxkL9s%2BaMxR&amp;amp;wx_header=0">微信公众号&lt;/a>&lt;/p>
&lt;p>&lt;strong>Redis 支持三种高可用方案&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.yuque.com/go/doc/33187771">Replication(复制) 模式&lt;/a>。
&lt;ul>
&lt;li>实际上，该模式并不是绝对的高可用，仅仅保证了数据的不丢失&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://www.yuque.com/go/doc/33187731">Sentinel(哨兵) 模式&lt;/a>&lt;/li>
&lt;li>Cluster(集群) 模式&lt;/li>
&lt;/ul>
&lt;h1 id="cluster集群">Cluster(集群)&lt;/h1>
&lt;p>&lt;a href="http://www.redis.cn/topics/cluster-tutorial.html">http://www.redis.cn/topics/cluster-tutorial.html&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://redis.io/topics/cluster-tutorial">https://redis.io/topics/cluster-tutorial&lt;/a>&lt;/p>
&lt;h2 id="客户端操作原理请求路由原理">客户端操作原理(请求路由原理)&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/gnlint/1616134822977-6bf24d85-a95a-4729-8807-b5c63d74e9a7.jpeg" alt="">&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/gnlint/1616134822986-56d8d02c-0433-4df5-a829-8e7fb0435fb0.jpeg" alt="">&lt;/p>
&lt;ol>
&lt;li>请求重定向&lt;/li>
&lt;/ol>
&lt;p>在集群模式下，Redis 接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点，如果节点是自身，则处理键命令；否则回复 MOVED 重定向错误，通知客户端请求正确的节点。这个过程称为 MOVED 重定向。&lt;/p>
&lt;pre>&lt;code># 如果key经过计算后，其分配的slot就在当前节点，那么可以请求成功，否则，回复重定向消息
[root@node01 redis]# redis-cli -h 10.0.0.100 -p 6379
10.0.0.100:6379&amp;gt; set name tom
OK
10.0.0.100:6379&amp;gt; set age 20
(error) MOVED 741 10.0.0.101:6379
&lt;/code>&lt;/pre>
&lt;p>重定向信息包含了键所对应的槽以及负责该槽的节点地址，根据这些信息客户端就可以向正确的节点发起请求。在 10.0.0.101:6379 节点上成功执行之前的命令：&lt;/p>
&lt;pre>&lt;code>[root@node02 redis]# redis-cli -h 10.0.0.101 -p 6379
10.0.0.101:6379&amp;gt; set age 20
OK
&lt;/code>&lt;/pre>
&lt;p>使用 redis-cli 命令时，可以加入-c 参数支持自动重定向，简化手动发起重定向的操作：&lt;/p>
&lt;pre>&lt;code>[root@node01 redis]# redis-cli -c -h 10.0.0.100 -p 6379
10.0.0.100:6379&amp;gt; set age 30
-&amp;gt; Redirected to slot [741] located at 10.0.0.101:6379
OK
&lt;/code>&lt;/pre>
&lt;p>redis-cli 自动帮我们连接到正确的节点执行命令，这个过程是在 redis-cli 内部维护，实质上是 client 端接到 MOVED 信息指定的节点之后再次发起请求，并不是在当前 Redis 节点中完成请求转发，节点对于不属于它的键命令只回复重定向响应，并不负责转发。&lt;/p>
&lt;p>键命令执行步骤主要分两步：&lt;/p>
&lt;ol>
&lt;li>计算槽&lt;/li>
&lt;/ol>
&lt;p>Redis 首先需要计算键所对应的槽，根据键的有效部分使用 CRC16 函数计算出散列值，再取对 16383 的余数，得到槽的编号，这样每个键都可以映射到 0~16383 槽范围内&lt;/p>
&lt;pre>&lt;code>10.0.0.101:6379&amp;gt; cluster keyslot age
(integer) 741
&lt;/code>&lt;/pre>
&lt;p>Redis 集群相对单机在功能上存在一些限制，限制如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>key 批量操作支持有限，如 mset、mget，目前只支持具有相同 slot 值的 key 执行批量操作。对于映射为不同 slot 值的 key 由于执行 mget、mget 等操作可能存在于多个节点上因此不被支持&lt;/p>
&lt;/li>
&lt;li>
&lt;p>key 事务操作支持有限，同理只支持多 key 在同一节点上的事务操作，当多个 key 分布在不同的节点上时无法使用事务功能&lt;/p>
&lt;/li>
&lt;li>
&lt;p>key 作为数据分区的最小粒度，因此不能将一个大的键值对象如 hash、list 等映射到不同的节点&lt;/p>
&lt;/li>
&lt;li>
&lt;p>不支持多数据库空间，单机下的 Redis 可以支持 16 个数据库，集群模式下只能使用一个数据库空间，即 db0&lt;/p>
&lt;/li>
&lt;li>
&lt;p>复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构&lt;/p>
&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>10.0.0.102:6379&amp;gt; mget name age
(error) CROSSSLOT Keys in request don't hash to the same slot
&lt;/code>&lt;/pre>
&lt;p>但通常会有这样的需求，例如把一个用户的信息存入到一个 slot 中，这是可以这样设置：&lt;/p>
&lt;pre>&lt;code>10.0.0.102:6379&amp;gt; set user:{user1}:name tony
-&amp;gt; Redirected to slot [8106] located at 10.0.0.100:6379
OK
10.0.0.100:6379&amp;gt; set user:{user1}:age 20
OK
10.0.0.100:6379&amp;gt; cluster keyslot user:{user1}:name
(integer) 8106
10.0.0.100:6379&amp;gt; cluster keyslot user:{user1}:age
(integer) 8106
10.0.0.100:6379&amp;gt; mget user:{user1}:name user:{user1}:age
1) &amp;quot;tony&amp;quot;
2) &amp;quot;20&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>这样，这两个 key 在计算 hash 值的时候，不会根据整个 key 来计算，而是只是拿{}中的内容的来计算，这样它们的 hash 值一定是相同的，就可以分配到同一个 slot 中，{}中的内容称为 hash_tag&lt;/p>
&lt;ol>
&lt;li>查找槽所对应的节点&lt;/li>
&lt;/ol>
&lt;p>Redis 计算得到键对应的槽后，需要查找槽所对应的节点。集群内通过消息交换每个节点都会知道所有节点的槽信息。&lt;/p>
&lt;p>根据 MOVED 重定向机制，客户端可以随机连接集群内任一 Redis 获取键所在节点，这种客户端又叫 Dummy(傀 儡)客户端，它优点是代码实现简单，对客户端协议影响较小，只需要根据重定向信息再次发送请求即可。但是它的弊端很明显，每次执行键命令前都要到 Redis 上进行重定向才能找到要执行命令的节点，额外增加了 IO 开销，这不是 Redis 集群高效的使用方式。正因为如此通常集群客户端都采用另一种实现：Smart 客户端&lt;/p>
&lt;h2 id="cluster-模式的优缺点">Cluster 模式的优缺点&lt;/h2>
&lt;p>优点：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>无中心架构，数据按照 slot 分布在多个节点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>集群中的每个节点都是平等的关系，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>可线性扩展到 1000 多个节点，节点可动态添加或删除&lt;/p>
&lt;/li>
&lt;li>
&lt;p>能够实现自动故障转移，节点之间通过 gossip 协议交换状态信息，用投票机制完成 slave 到 master 的角色转换&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>缺点：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>客户端实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更新，提高了开发难度。目前仅 JedisCluster 相对成熟，异常处理还不完善，比如常见的“max redirect exception”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>节点会因为某些原因发生阻塞（阻塞时间大于 cluster-node-timeout）被判断下线，这种 failover 是没有必要的&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据通过异步复制，不保证数据的强一致性&lt;/p>
&lt;/li>
&lt;li>
&lt;p>slave 充当“冷备”，不能缓解读压力&lt;/p>
&lt;/li>
&lt;li>
&lt;p>批量操作限制，目前只支持具有相同 slot 值的 key 执行批量操作，对 mset、mget、sunion 等操作支持不友好&lt;/p>
&lt;/li>
&lt;li>
&lt;p>key 事务操作支持有线，只支持多 key 在同一节点的事务操作，多 key 分布不同节点时无法使用事务功能&lt;/p>
&lt;/li>
&lt;li>
&lt;p>不支持多数据库空间，单机 redis 可以支持 16 个 db，集群模式下只能使用一个，即 db 0&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Redis Cluster 模式不建议使用 pipeline 和 multi-keys 操作，减少 max redirect 产生的场景。&lt;/p>
&lt;h1 id="sentinel-与-cluster-的区别">Sentinel 与 Cluster 的区别&lt;/h1>
&lt;p>……我感觉楼主自己对 redis 的理解是有一定问题的，但提的问题其实是个好问题，而回帖的大部分人没有回应准确楼主的疑问，少部分评论我看一眼就明白，但楼主可能是想不到的。&lt;/p>
&lt;p>那咱们把集群和哨兵能解决的问题列出来，就比较清楚了。&lt;/p>
&lt;p>哨兵： 哨兵仅仅提供故障切换能力，在这之上，对使用方来说，和单机的 redis 是完全一样的。&lt;/p>
&lt;p>集群： 集群最主要的，解决的是一个“数据分片”的问题，它能把 redis 的数据分散到不同的 slot 里，而不是都集中在一台机器的内存里。这样也就给单进程单线程、纯内存的 redis 提供了水平扩容的能力。&lt;/p>
&lt;p>但是这是有代价的， 一部分命令无法跨节点执行，比如 zunionstore 等一些命令，它涉及多个 key，因此在集群状态下，需要自行保证这些 key 都在一个 slot 上；&lt;/p>
&lt;p>再比如 watch exec， 在单节点或哨兵场景下可以用，但集群模式下是不能使用的。&lt;/p>
&lt;p>还有一些命令，在集群状态下虽能执行或有替代方案，但会丧失原子性。 比如 mget 等。&lt;/p>
&lt;p>所以楼主的疑问是为什么集群模式没有取代哨兵模式，是因为哨兵模式作为单节点+高可用的方案而言，确实有集群模式实现不了的功能。&lt;/p>
&lt;p>……想换行不小心发出去了。&lt;/p>
&lt;p>除了功能上的区别以外，集群模式显然比哨兵模式更重、需要更多的资源去运行；再就是部署运维复杂度也是更高的。&lt;/p>
&lt;p>而哨兵和单节点，一般来说除了配置稍有区别以外，绝大部分业务代码是可以相容的，无需特地修改。&lt;/p>
&lt;p>而现有的代码如果使用了集群模式不支持的那些命令，那么集群模式下是无法正常工作的。&lt;/p>
&lt;p>所以目前哨兵模式仍然被广泛使用，没有被集群模式彻底替代。&lt;/p>
&lt;p>我们公司就是用哨兵了。为什么不用 Cluster 。因为费钱。集群需要机器太多了。本身数据量就不大。分片功能不需要。 就只是想要一个高可用的 redis 。 用哨兵符合需求了。 只需要三台机器。而且三台机器还部署了 3 个 zookeeper 和 kafka 。都是数据量不大。 节约机器钱&lt;/p></description></item><item><title>Docs: 1.Redis</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/1.redis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/1.redis/</guid><description>
&lt;h1 id="redis-介绍">Redis 介绍&lt;/h1>
&lt;p>参考：&lt;a href="https://redis.io/">官网&lt;/a>&lt;/p>
&lt;p>Redis 是一个开源的、网络化的、内存中的、具有持久化的键值数据存储。(是否持久化根据配置决定)&lt;/p>
&lt;p>Redis 是一个内存数据库, 所有数据默认都存在于内存当中,可以配置“定时以追加或者快照”的方式储存到硬盘中. 由于 redis 是一个内存数据库, 所以读取写入的速度是非常快的, 所以经常被用来做数据, 页面等的缓存。&lt;/p>
&lt;p>Redis 的组件&lt;/p>
&lt;ol>
&lt;li>
&lt;p>redis-server # 服务端&lt;/p>
&lt;/li>
&lt;li>
&lt;p>redis-cli # 命令行客户端&lt;/p>
&lt;/li>
&lt;li>
&lt;p>redis-benchmark # 压测工具&lt;/p>
&lt;/li>
&lt;li>
&lt;p>redis-check-dump &amp;amp;&amp;amp; redis-check-aof # 检测工具&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Redis 的数据类型&lt;/p>
&lt;p>string(字符串)，hash(哈希)，list(列表)，set(集合) 及 zset(sorted set：有序集合)。&lt;/p>
&lt;p>后面增加了：&lt;/p>
&lt;p>Bit arrays (或者说 simply bitmaps)&lt;/p>
&lt;p>在 2.8.9 版本添加了 HyperLogLog 结构&lt;/p>
&lt;p>Redis 部署&lt;/p>
&lt;p>Docker 启动 Redis&lt;/p>
&lt;pre>&lt;code>docker run -d --name redis \
--network=host \
redis:5.0.10-alpine
&lt;/code>&lt;/pre>
&lt;p>Redis 配置&lt;/p>
&lt;p>**/etc/redis.conf **# Redis 主程序的配置文件&lt;/p>
&lt;p>&lt;strong>/var/lib/redis/*&lt;/strong> # 默认的数据存储目录&lt;/p>
&lt;p>Redis 数据持久化的方式&lt;/p>
&lt;p>Redis 的数据是保存在内存中的，如果设备宕机，则数据丢失，所以 Redis 提供两种可以将数据从内存中写入硬盘的方式，默认为 RDB，AOF 默认不开启&lt;/p>
&lt;p>RDB Redis Data Base&lt;/p>
&lt;p>相关配置在配置文件的 SNAPSHOT 配置环境中。&lt;/p>
&lt;p>在默认情况下， Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。可以对 Redis 进行设置， 让 Redis 在“ N 秒内数据集至少有 M 个 key 改动”这一条件被满足时， 自动保存一次数据集。也可以通过调用 SAVE 或者 BGSAVE ， 手动让 Redis 进行数据集保存操作。&lt;/p>
&lt;p>这种持久化的方式被称为快照（snapshotting），会将数据保存在一个指定的文件中。&lt;/p>
&lt;p>RDB 工作原理：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>触发 RDB 后，redis 会调用 fork(),产生一个与主程序同名的子进程。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>该子进程会将现有内存中的数据写入到一个临时的 RDB 文件中。(文件名一般为：temp-XXX.rdb)&lt;/p>
&lt;ol>
&lt;li>Redis 默认会使用 LZF 算法对数据进行压缩。该算法会消耗大量 CPU，可以在配置中关闭压缩功能，但是数据量写入到磁盘后，会占用大量磁盘空间。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>当子进程完成对临时 RDB 文件的写入时，Redis 用这个临时的 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。&lt;/p>
&lt;p>RDB 优点：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>RDB 文件是一个很简洁的单文件，它保存了某个时间点的 Redis 数据，很适合用于做备份。你可以设定一个时间点对 RDB 文件进行归档，这样就能在需要的时候很轻易的把数据恢复到不同的版本。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>基于上面所描述的特性，RDB 很适合用于灾备。单文件很方便就能传输到远程的服务器上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RDB 的性能很好，需要进行持久化时，主进程会 fork 一个子进程出来，然后把持久化的工作交给子进程，自己不会有相关的 I/O 操作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>比起 AOF，在数据量比较大的情况下，RDB 的启动速度更快。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>RDB 缺点：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>RDB 容易造成数据的丢失。假设每 5 分钟保存一次快照，如果 Redis 因为某些原因不能正常工作，那么从上次产生快照到 Redis 出现问题这段时间的数据就会丢失了。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RDB 使用 fork()产生子进程进行数据的持久化，如果数据比较大的话可能就会花费点时间，造成 Redis 停止服务几毫秒。如果数据量很大且 CPU 性能不是很好的时候，停止服务的时间甚至会到 1 秒。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="aof-append-only-file">AOF Append Only File&lt;/h2>
&lt;p>配置文件中配置环境 APPEND ONLY MOD E 可以进项相关配置。&lt;/p>
&lt;p>默认 redis 使用的是 rdb 方式持久化，这种方式在许多应用中已经足够用了。但是 redis 如果中途宕机，会导致可能有几分钟的数据丢失。&lt;/p>
&lt;p>Append Only File 是另一种持久化方式，可以提供更好的持久化特性。Redis 会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时 Redis 都会先把这个文件的数据读入内存里，先忽略 RDB 文件。&lt;/p>
&lt;p>AOF 工作方式：&lt;/p>
&lt;p>每当 Redis 执行一个改变数据集的命令时（比如 SET）， 这个命令就会被追加到 AOF 文件的末尾。这样的话， 当 Redis 重新启时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。AOF 重写和 RDB 创建快照一样，都巧妙地利用了写时复制机制:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Redis 执行 fork() ，现在同时拥有父进程和子进程。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>子进程开始将新 AOF 文件的内容写入到临时文件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾,这样样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>搞定！现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>AOF 优点：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>使用 AOF 会让你的 Redis 更加耐久: 你可以使用不同的 fsync 策略：无 fsync,每秒 fsync,每次写的时候 fsync.使用默认的每秒 fsync 策略,Redis 的性能依然很好(fsync 是由后台线程进行处理的,主线程会尽力处理客户端请求),一旦出现故障，你最多丢失 1 秒的数据.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>AOF 文件是一个只进行追加的日志文件,所以不需要写入 seek,即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令,你也也可使用 redis-check-aof 工具修复这些问题.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>AOF 缺点：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>下图是 redis 启动后读取本地存储文件的过程&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/gghosd/1616134974086-4020ec57-f508-4a12-b30e-aba72d1730e4.jpeg" alt="">&lt;/p></description></item><item><title>Docs: 1.Server Message Block</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/1.server-message-block/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/1.server-message-block/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block">Wiki,SMB&lt;/a>、&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block">Wiki,Samba&lt;/a>、&lt;a href="https://searchstorage.techtarget.com/definition/Common-Internet-File-System-CIFS">Techtarget&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Server Message Block(服务器消息块，简称 SMB)&lt;/strong> 是一个通信协议，该协议可以让网络中的各个节点可以共享访问 文件、打印机、串行端口，还可以提供经过身份验证的 &lt;a href="https://www.yuque.com/go/doc/33222674">IPC&lt;/a> 机制。&lt;/p>
&lt;p>现在，SMB 协议主要用来让 Windows 和 Linux 之间可以互相传输文件。&lt;/p>
&lt;h2 id="背景">背景&lt;/h2>
&lt;h3 id="smb--cifs--smb1edithttpsenwikipediaorgwindexphptitleserver_message_blockactioneditsection3smb--cifs--smb1-编辑">SMB / CIFS / SMB1[&lt;a href="https://en.wikipedia.org/w/index.php?title=Server_Message_Block&amp;amp;action=edit&amp;amp;section=3">edit&lt;/a>]SMB / CIFS / SMB1 [编辑]&lt;/h3>
&lt;p>&lt;a href="https://en.wikipedia.org/w/index.php?title=Barry_Feigenbaum&amp;amp;action=edit&amp;amp;redlink=1">Barry Feigenbaum&lt;/a> originally designed SMB at &lt;a href="https://en.wikipedia.org/wiki/IBM">IBM&lt;/a> in early 1983 with the aim of turning &lt;a href="https://en.wikipedia.org/wiki/DOS">DOS&lt;/a> &lt;a href="https://en.wikipedia.org/wiki/INT_21h">INT 21h&lt;/a> local file access into a networked file system.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-tridgemyths-9">[9]&lt;/a> &lt;a href="https://en.wikipedia.org/wiki/Microsoft">Microsoft&lt;/a> has made considerable modifications to the most commonly used version. Microsoft merged the SMB protocol with the &lt;a href="https://en.wikipedia.org/wiki/LAN_Manager">LAN Manager&lt;/a> product which it had started developing for &lt;a href="https://en.wikipedia.org/wiki/OS/2">OS/2&lt;/a> with &lt;a href="https://en.wikipedia.org/wiki/3Com">3Com&lt;/a> around 1990, and continued to add features to the protocol in &lt;a href="https://en.wikipedia.org/wiki/Windows_for_Workgroups">Windows for Workgroups&lt;/a> (c. 1992) and in later versions of Windows.Barry Feigenbaum 在 1983 年初在 IBM 设计了 SMB，目的是将 DOS INT 21H 本地文件访问转换为网络文件系统。[9] Microsoft 对最常用的版本进行了相当大的修改。 Microsoft 将 SMB 协议与 LAN Manager 产品合并，它已开始为 1990 年左右开始为 OS / 2 开发的 OS / 2，并继续向工作组（C.192）和更高版本的 Windows 中的 Windows 中的协议添加功能。
SMB was originally designed to run on top of the &lt;a href="https://en.wikipedia.org/wiki/NetBIOS">NetBIOS&lt;/a>/NetBEUI &lt;a href="https://en.wikipedia.org/wiki/Application_programming_interface">API&lt;/a> (typically implemented with &lt;a href="https://en.wikipedia.org/wiki/NetBIOS_Frames">NBF&lt;/a>, NetBIOS over &lt;a href="https://en.wikipedia.org/wiki/IPX/SPX">IPX/SPX&lt;/a>, or &lt;a href="https://en.wikipedia.org/wiki/NetBIOS_over_TCP/IP">NBT&lt;/a>). Since &lt;a href="https://en.wikipedia.org/wiki/Windows_2000">Windows 2000&lt;/a>, SMB runs, by default, with a thin layer, similar to the Session Message packet of NBT&amp;rsquo;s Session Service, on top of &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol">TCP&lt;/a>, using TCP port 445 rather than TCP port 139—a feature known as &amp;ldquo;direct host SMB&amp;rdquo;.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-direct-10">[10]&lt;/a>SMB 最初设计用于在 NetBIOS / NetBEUI API 之上（通常使用 NBF，NETBIOS 通过 IPX / SPX 或 NBT 实现）。由于 Windows 2000，SMB 默认情况下，使用 TCP 端口 445 而不是 TCP 端口 139-A 称为“Direct Host SMB”的特征。[10]
Windows Server 2003, and older &lt;a href="https://en.wikipedia.org/wiki/Network-attached_storage">NAS&lt;/a> devices use SMB1/CIFS natively. SMB1/CIFS is an extremely chatty protocol which is not such an issue on a local area network with low latency but becomes very slow on wide area networks as the back and forth handshake of the protocol magnifies the inherent high latency of such network. Later versions of the protocol reduced the high number of handshake exchanges. While Microsoft estimates that SMB1/CIFS comprises less than 10% of network traffic in the average Enterprise network, that is still a significant amount of traffic. One approach to mitigating the inefficiencies in the protocol is to use WAN Acceleration products such as those provided by Riverbed, Silver Peak, or Cisco Systems. A better approach is simply to eliminate SMB1/CIFS by upgrading the server infrastructure that uses it. This includes both NAS devices as well as Windows Server 2003. The most effective method in use currently to identify SMB1/CIFS traffic is to use a network analyzer tool such as Wireshark, etc., to identify SMB1/CIFS &amp;ldquo;talkers&amp;rdquo; and then decommission or upgrade them over time. Microsoft also provides an auditing tool in Windows Server 2016, which can be used to track down SMB1/CIFS talkers.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-messageanalyzer-11">[11]&lt;/a>Windows Server 2003 和旧的 NAS 设备本地使用 SMB1 / CIFS。 SMB1 / CIFS 是一种极其聊天协议，在局域网上并不具有低延迟的问题，但在广域网上变得非常慢，因为协议的后退握手放大了这种网络的固有高延迟。后来的协议版本减少了大量握手交换。虽然 Microsoft 估计 SMB1 / CIFS 在普通企业网络中不到 10％的网络流量，但仍然是大量流量。一种减轻协议低效率的一种方法是使用 WAN 加速产品，例如河床，银峰或思科系统提供的产品。更好的方法只是通过升级使用它的服务器基础架构来消除 SMB1 / CIFS。这包括 NAS 设备以及 Windows Server 2003.目前用于识别 SMB1 / CIFS 流量的最有效的方法是使用网络分析工具，如 Wireshark 等，以识别 SMB1 / CIFS“Talkers”，然后再次退役或随着时间的推移升级它们。 Microsoft 还在 Windows Server 2016 中提供了一个审计工具，可用于跟踪 SMB1 / CIFS Talkers。[11]
In 1996, when Sun Microsystems announced &lt;a href="https://en.wikipedia.org/wiki/WebNFS">WebNFS&lt;/a>,&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-WebNFS-12">[12]&lt;/a> Microsoft launched an initiative to rename SMB to Common Internet File System (CIFS)&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-tridgemyths-9">[9]&lt;/a> and added more features, including support for &lt;a href="https://en.wikipedia.org/wiki/Symbolic_link">symbolic links&lt;/a>, &lt;a href="https://en.wikipedia.org/wiki/Hard_link">hard links&lt;/a>, larger file sizes, and an initial attempt at supporting direct connections over TCP port 445 without requiring &lt;a href="https://en.wikipedia.org/wiki/NetBIOS">NetBIOS&lt;/a> as a transport (a largely experimental effort that required further refinement). Microsoft submitted some partial specifications as &lt;a href="https://en.wikipedia.org/wiki/Internet_Draft">Internet-Drafts&lt;/a> to the &lt;a href="https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force">IETF&lt;/a>,&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-IETF-13">[13]&lt;/a> though these submissions have expired.1996 年，当 Sun Microsystems 宣布 WebNFS，[12] Microsoft 推出了一项计划将 SMB 重命名为常见的 Internet 文件系统（CIFS）[9]并增加了更多功能，包括支持符号链接，硬链接，更大的文件大小和一个初步尝试在不需要 NetBIOS 作为运输的情况下支持直接连接的初步尝试（需要进一步改进的主要实验努力）。 Microsoft 将某些部分规格作为 IETF 提交了一些部分规范，[13]虽然这些提交已过期。
Microsoft &amp;ldquo;added SMB1 to the Windows Server 2012 R2 &lt;a href="https://en.wikipedia.org/wiki/Deprecation">deprecation&lt;/a> list in June 2013.&amp;rdquo;&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-14">[14]&lt;/a> Windows Server 2016 and some versions of Windows 10 Fall Creators Update do not have SMB1 installed by default.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-15">[15]&lt;/a>Microsoft 将于 2013 年 6 月添加到 Windows Server 2012 R2 弃用列表中的 SMB1。“[14] Windows Server 2016 和一些版本的 Windows 10 秋季创建者更新没有 SMB1 默认安装。[15]&lt;/p>
&lt;h3 id="smb-20edithttpsenwikipediaorgwindexphptitleserver_message_blockactioneditsection4smb-20-编辑">SMB 2.0[&lt;a href="https://en.wikipedia.org/w/index.php?title=Server_Message_Block&amp;amp;action=edit&amp;amp;section=4">edit&lt;/a>]SMB 2.0 [编辑]&lt;/h3>
&lt;p>Microsoft introduced a new version of the protocol (SMB 2.0 or SMB2) with &lt;a href="https://en.wikipedia.org/wiki/Windows_Vista">Windows Vista&lt;/a> in 2006&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-smb2-16">[16]&lt;/a> and &lt;a href="https://en.wikipedia.org/wiki/Windows_Server_2008">Server 2008&lt;/a>. Although the protocol is proprietary, its specification has been published to allow other systems to interoperate with Microsoft operating systems that use the new protocol.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-17">[17]&lt;/a>Microsoft 在 2006 年的 Windows Vista 引入了一个新版本的协议（SMB 2.0 或 SMB2）[16]和 Server 2008.虽然该协议是专有的，但它已发布其规范，以允许其他系统与使用使用的 Microsoft 操作系统互操作新协议。[17]
SMB2 reduces the &amp;lsquo;chattiness&amp;rsquo; of the SMB 1.0 protocol by reducing the number of commands and subcommands from over a hundred to just nineteen.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-barreto-18">[18]&lt;/a> It has mechanisms for &lt;a href="https://en.wikipedia.org/wiki/Pipelining">pipelining&lt;/a>, that is, sending additional requests before the response to a previous request arrives, thereby improving performance over high-&lt;a href="https://en.wikipedia.org/wiki/Latency_(engineering)">latency&lt;/a> links. It adds the ability to compound multiple actions into a single request, which significantly reduces the number of &lt;a href="https://en.wikipedia.org/wiki/Round-trip_delay_time">round-trips&lt;/a> the client needs to make to the server, improving performance as a result.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-barreto-18">[18]&lt;/a> SMB1 also has a compounding mechanism—known as AndX—to compound multiple actions, but Microsoft clients rarely use AndX.&lt;em>&lt;a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed">citation needed&lt;/a>&lt;/em> It also introduces the notion of &amp;ldquo;durable file handles&amp;rdquo;: these allow a connection to an SMB server to survive brief network outages, as are typical in a wireless network, without having to incur the overhead of re-negotiating a new session.SMB2 通过减少超过一百到十九岁的命令和子命令的数量来减少 SMB 1.0 协议的“干脆”。[18]它具有流水线的机制，即，在对先前请求到达之前发送附加请求，从而提高了高延迟链路的性能。它增加了将多个操作复制到单个请求中的能力，这显着减少了客户端需要对服务器所需的往返的数量，从而提高性能。[18] SMB1 还具有复合机制，称为 Andx-to Compase 多种动作，但 Microsoft 客户端很少使用 Andx。[所需的引用]它还介绍了“持久文件处理函数”的概念：这些概述允许与 SMB 服务器的连接来生存简介网络中断，正如无线网络中的典型版本，而不必触发重新协商新会话的开销。
SMB2 includes support for &lt;a href="https://en.wikipedia.org/wiki/Symbolic_link">symbolic links&lt;/a>. Other improvements include caching of file properties, improved message signing with &lt;a href="https://en.wikipedia.org/wiki/HMAC">HMAC&lt;/a> &lt;a href="https://en.wikipedia.org/wiki/SHA-256">SHA-256&lt;/a> hashing algorithm and better scalability by increasing the number of users, shares and open files per server among others.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-barreto-18">[18]&lt;/a> The SMB1 protocol uses 16-bit data sizes, which amongst other things, limits the maximum block size to 64K. SMB2 uses 32- or 64-bit wide storage fields, and 128 bits in the case of &lt;a href="https://en.wikipedia.org/wiki/File_handle">file-handles&lt;/a>, thereby removing previous constraints on block sizes, which improves performance with large file transfers over fast networks.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-barreto-18">[18]&lt;/a>SMB2 包括对符号链接的支持。其他改进包括缓存文件属性，通过增加每个服务器等用户的用户，共享和打开文件的数量，改进了 HMAC SHA-256 散列算法和更好的可扩展性。[18] SMB1 协议使用 16 位数据大小，其中包括其他内容，将最大块大小限制为 64K。 SMB2 使用 32 个或 64 位宽的存储字段，以及在文件处理的情况下使用 128 位，从而在块大小上移除先前的约束，从而提高了大文件传输的性能。[18]
Windows Vista/&lt;a href="https://en.wikipedia.org/wiki/Server_2008">Server 2008&lt;/a> and later operating systems use SMB2 when communicating with other machines also capable of using SMB2. SMB1 continues in use for connections with older versions of Windows, as well various vendors&amp;rsquo; &lt;a href="https://en.wikipedia.org/wiki/Network-attached_storage">NAS&lt;/a> solutions. Samba 3.5 also includes experimental support for SMB2.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-19">[19]&lt;/a> Samba 3.6 fully supports SMB2, except the modification of user quotas using the Windows quota management tools.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-20">[20]&lt;/a>Windows Vista / Server 2008 及更高版本的操作系统在与其他机器通信时使用 SMB2，该机器也能够使用 SMB2。 SMB1 继续用于与旧版本的 Windows 连接，以及各种供应商的 NAS 解决方案。 Samba 3.5 还包括对 SMB2 的实验支持。[19] Samba 3.6 完全支持 SMB2，除了使用 Windows 配额管理工具修改用户配额。[20]
When SMB2 was introduced it brought a number of benefits over SMB1 for third party implementers of SMB protocols. SMB1, originally designed by &lt;a href="https://en.wikipedia.org/wiki/IBM">IBM&lt;/a>, was &lt;a href="https://en.wikipedia.org/wiki/Reverse_engineering">reverse engineered&lt;/a>, and later became part of a wide variety of non-Windows operating systems such as &lt;a href="https://en.wikipedia.org/wiki/Xenix">Xenix&lt;/a>, &lt;a href="https://en.wikipedia.org/wiki/OS/2">OS/2&lt;/a> and &lt;a href="https://en.wikipedia.org/wiki/OpenVMS">VMS&lt;/a> (&lt;a href="https://en.wikipedia.org/wiki/Pathworks">Pathworks&lt;/a>). &lt;a href="https://en.wikipedia.org/wiki/X/Open">X/Open&lt;/a> standardized it partially; it also had draft &lt;a href="https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force">IETF&lt;/a> standards which lapsed. (See &lt;a href="http://ubiqx.org/cifs/Intro.html">http://ubiqx.org/cifs/Intro.html&lt;/a> for historical detail.) SMB2 is also a relatively clean break with the past. Microsoft&amp;rsquo;s SMB1 code has to work with a large variety of SMB clients and servers. SMB1 features many versions of information for commands (selecting what structure to return for a particular request) because features such as &lt;a href="https://en.wikipedia.org/wiki/Unicode">Unicode&lt;/a> support were retro-fitted at a later date. SMB2 involves significantly reduced compatibility-testing for implementers of the protocol. SMB2 code has considerably less complexity since far less variability exists (for example, non-Unicode code paths become redundant as SMB2 requires Unicode support).当 SMB2 引入时，它为 SMB 协议的第三方实施者带来了许多福利。最初由 IBM 设计的 SMB1 是反向设计的，后来成为 Xenix，OS / 2 和 VM（Pathworks）等各种非 Windows 操作系统的一部分。 X /开放部分地标准化;它还有 IETF 标准草案，退却。 （有关历史细节，请参阅http://ubiqx.org/cifs/intro.html。）SMB2也与过去相对干净。微软的SMB1代码必须使用各种SMB客户端和服务器。 SMB1 具有命令的许多信息版本（选择要返回的特定请求的结构），因为在以后的日期中重新装配诸如 Unicode 支持的功能。 SMB2 涉及对协议实施者的兼容性测试显着降低。 SMB2 代码具有很大的复杂性，因为存在较小的可变性（例如，当 SMB2 需要 Unicode 支持时，非 Unicode 代码路径变得冗余）。
Apple is also migrating to SMB2 (from their own &lt;a href="https://en.wikipedia.org/wiki/Apple_Filing_Protocol">Apple Filing Protocol&lt;/a>, now legacy) with OS X 10.9.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-ai2013-21">[21]&lt;/a> This transition was fraught with compatibility problems though.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-22">[22]&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-23">[23]&lt;/a> Non-default support for SMB2 appeared in fact in OS X 10.7, when Apple abandoned Samba in favor of its own SMB implementation called SMBX.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-ai2013-21">[21]&lt;/a> Apple switched to its own SMBX implementation after Samba adopted &lt;a href="https://en.wikipedia.org/wiki/GPLv3">GPLv3&lt;/a>.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-24">[24]&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-25">[25]&lt;/a>Apple 还与 OS X 10.9 迁移到 SMB2（从他们自己的 Apple 申请协议，现在遗留）。[21]这种转变充满了兼容性问题。[22] [23] SMB2 的非默认支持实际上出现在 OS X 10.7 中，当 Apple 废弃 Samba 有利于它自己的 SMB 实现，称为 SMBx。[21] Apple 在 Samba 采用 GPLv3 后切换到自己的 SMBX 实现。[24] [25]
The &lt;a href="https://en.wikipedia.org/wiki/Linux_kernel">Linux kernel&lt;/a>&amp;rsquo;s CIFS client file system has SMB2 support since version 3.7.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-26">[26]&lt;/a>自版本 3.7 以来，Linux 内核的 CIFS 客户端文件系统具有 SMB2 支持。[26]&lt;/p>
&lt;h3 id="smb-21edithttpsenwikipediaorgwindexphptitleserver_message_blockactioneditsection5smb-21-编辑">SMB 2.1[&lt;a href="https://en.wikipedia.org/w/index.php?title=Server_Message_Block&amp;amp;action=edit&amp;amp;section=5">edit&lt;/a>]SMB 2.1 [编辑]&lt;/h3>
&lt;p>SMB 2.1, introduced with Windows 7 and Server 2008 R2, introduced minor performance enhancements with a new opportunistic locking mechanism.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-27">[27]&lt;/a>使用 Windows 7 和 Server 2008 R2 引入的 SMB 2.1，带来了新的机会锁定机制的次要性能增强。[27]&lt;/p>
&lt;h3 id="smb-30edithttpsenwikipediaorgwindexphptitleserver_message_blockactioneditsection6smb-30-编辑">SMB 3.0[&lt;a href="https://en.wikipedia.org/w/index.php?title=Server_Message_Block&amp;amp;action=edit&amp;amp;section=6">edit&lt;/a>]SMB 3.0 [编辑]&lt;/h3>
&lt;p>SMB 3.0 (previously named SMB 2.2)&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-smb3-28">[28]&lt;/a> was introduced with &lt;a href="https://en.wikipedia.org/wiki/Windows_8">Windows 8&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-smb3-28">[28]&lt;/a> and &lt;a href="https://en.wikipedia.org/wiki/Windows_Server_2012">Windows Server 2012&lt;/a>.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-smb3-28">[28]&lt;/a> It brought several significant changes that are intended to add functionality and improve SMB2 performance,&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-29">[29]&lt;/a> notably in virtualized &lt;a href="https://en.wikipedia.org/wiki/Data_center">data centers&lt;/a>:使用 Windows 8 [28]和 Windows Server 2012 引入了 SMB 3.0（以前命名的 SMB 2.2）[28]。[28]它带来了几种重大变化，旨在添加功能并提高 SMB2 性能，[29]显着涉及虚拟化数据中心：&lt;/p>
&lt;ul>
&lt;li>the SMB Direct Protocol (SMB over &lt;a href="https://en.wikipedia.org/wiki/Remote_direct_memory_access">remote direct memory access&lt;/a> [RDMA])SMB 直接协议（SMB OVER 远程直接内存访问[RDMA]）&lt;/li>
&lt;li>SMB Multichannel (multiple connections per SMB session),&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-30">[30]&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-31">[31]&lt;/a>SMB MultiShannel（每个 SMB 会话的多个连接），[30] [31]&lt;/li>
&lt;li>SMB Transparent Failover&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-32">[32]&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-33">[33]&lt;/a>SMB 透明故障转移[32] [33]&lt;/li>
&lt;/ul>
&lt;p>It also introduces several security enhancements, such as &lt;a href="https://en.wikipedia.org/wiki/End-to-end_encryption">end-to-end encryption&lt;/a> and a new &lt;a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES&lt;/a> based signing algorithm.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-34">[34]&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-35">[35]&lt;/a>它还引入了几种安全增强功能，例如端到端加密和基于新的 AES 签名算法。[34] [35]&lt;/p>
&lt;h3 id="smb-302edithttpsenwikipediaorgwindexphptitleserver_message_blockactioneditsection7smb-302-编辑">SMB 3.0.2[&lt;a href="https://en.wikipedia.org/w/index.php?title=Server_Message_Block&amp;amp;action=edit&amp;amp;section=7">edit&lt;/a>]SMB 3.0.2 [编辑]&lt;/h3>
&lt;p>SMB 3.0.2 (known as 3.02 at the time) was introduced with Windows 8.1 and Windows Server 2012 R2;&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-36">[36]&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-37">[37]&lt;/a> in those and later releases, the earlier SMB version 1 can be optionally disabled to increase security.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-38">[38]&lt;/a>&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-barreto-smb3-links-ws2012r2-39">[39]&lt;/a>Windows 8.1 和 Windows Server 2012 R2 引入了 SMB 3.0.2（当时的 3.02）; [36] [37]在那些和稍后的版本中，早期的 SMB 版本 1 可以选择禁用以增加安全性。[38 ] [39]&lt;/p>
&lt;h3 id="smb-311edithttpsenwikipediaorgwindexphptitleserver_message_blockactioneditsection8smb-311-编辑">SMB 3.1.1[&lt;a href="https://en.wikipedia.org/w/index.php?title=Server_Message_Block&amp;amp;action=edit&amp;amp;section=8">edit&lt;/a>]SMB 3.1.1 [编辑]&lt;/h3>
&lt;p>SMB 3.1.1 was introduced with &lt;a href="https://en.wikipedia.org/wiki/Windows_10">Windows 10&lt;/a> and &lt;a href="https://en.wikipedia.org/wiki/Windows_Server_2016">Windows Server 2016&lt;/a>.&lt;a href="https://en.wikipedia.org/wiki/Server_Message_Block#cite_note-40">[40]&lt;/a> This version supports &lt;a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES-128&lt;/a> &lt;a href="https://en.wikipedia.org/wiki/Galois/Counter_Mode">GCM&lt;/a> encryption in addition to AES-128 &lt;a href="https://en.wikipedia.org/wiki/CCM_mode">CCM&lt;/a> encryption added in SMB3, and implements pre-authentication integrity check using &lt;a href="https://en.wikipedia.org/wiki/SHA-512">SHA-512&lt;/a> hash. SMB 3.1.1 also makes secure negotiation mandatory when connecting to clients using SMB 2.x and higher.使用 Windows 10 和 Windows Server 2016 引入了 SMB 3.1.1. [40]此版本还支持 AES-128 GCM 加密，除了在 SMB3 中添加的 AES-128 CCM 加密，使用 SHA-512 哈希实现预认证完整性检查。 SMB 3.1.1 还使用 SMB 2.x 和更高的客户端连接到客户端时强制使用安全协商。&lt;/p>
&lt;h2 id="cifs">CIFS&lt;/h2>
&lt;p>CIFS (Common Internet File System) is a protocol that gained popularity around the year 2000, as vendors worked to establish an Internet Protocol-based &lt;a href="https://searchmobilecomputing.techtarget.com/definition/file-sharing">file-sharing&lt;/a> protocol.CIFS（常见的 Internet 文件系统）是一项协议，它在 2000 年左右获得了普及的协议，因为供应商建立基于 Internet 协议的文件共享协议。
At its peak, CIFS was supported by operating systems (OSes) such as Windows, Linux and Unix. CIFS used the &lt;a href="https://searchnetworking.techtarget.com/definition/client-server">client-server&lt;/a> programming model in which a client program makes a request of a server program &amp;ndash; usually in another computer &amp;ndash; to access a file or pass a message to a program that runs in the server computer. The server takes the requested action and returns a response.在其峰值处，CIFS 由操作系统（OS）支持，例如 Windows，Linux 和 Unix。 CIFS 使用客户端 - 服务器编程模型，其中客户端程序使服务器程序的请求 - 通常在另一台计算机中 - 访问文件或将消息传递给在服务器计算机中运行的程序。服务器获取请求的操作并返回响应。
CIFS is now considered obsolete, because most modern data storage systems use the more robust Server Message Block (&lt;a href="https://searchnetworking.techtarget.com/definition/Server-Message-Block-Protocol">SMB&lt;/a>) 2.0 and 3.0 file-sharing protocols, which were major upgrades to CIFS.CIFS 现在被认为已过时，因为大多数现代数据存储系统使用更强大的服务器消息块（SMB）2.0 和 3.0 文件共享协议，这是 CIFS 的重大升级。
CIFS/SMB and the Network File System (&lt;a href="https://searchenterprisedesktop.techtarget.com/definition/Network-File-System">NFS&lt;/a>) are the two major protocols used in network-attached storage (&lt;a href="https://searchstorage.techtarget.com/definition/network-attached-storage">NAS&lt;/a>) systems.CIFS / SMB 和网络文件系统（NFS）是网络附加存储（NAS）系统中使用的两个主要协议。&lt;/p>
&lt;h3 id="cifs-vs-nfscifs-与-nfs">CIFS vs. NFSCIFS 与 NFS.&lt;/h3>
&lt;p>Developed by Sun Microsystems in the 1980s, NFS is now managed by the Internet Engineering Task Force (&lt;a href="https://whatis.techtarget.com/definition/IETF-Internet-Engineering-Task-Force">IETF&lt;/a>). NFS was originally used more in Unix and Linux OSes, while CIFS and SMB were used for Windows, but most major NAS vendors now support both protocols.由 Sun Microsystems 在 20 世纪 80 年代开发，NFS 现在由互联网工程任务组（IETF）管理。 NFS 最初在 UNIX 和 Linux OS 中使用更多，而 CIFS 和 SMB 用于 Windows，但大多数主要的 NAS 供应商现在支持这两个协议。
NFS is a client-server application that permits transparent file sharing between servers, desktops, laptops and other devices. Using NFS, users can store, view and update files remotely as though they were on their own computer. With CIFS/SMB, a client program requests a file from a server program located on another computer, and the server responds. This makes CIFS a &lt;a href="https://searchnetworking.techtarget.com/definition/chatty-protocol">chattier protocol&lt;/a> than NFS.NFS 是一个客户端 - 服务器应用程序，可允许服务器，桌面，笔记本电脑和其他设备之间的透明文件共享。使用 NFS，用户可以远程存储，查看和更新文件，好像它们在自己的计算机上。使用 CIFS / SMB，客户端程序请求来自位于另一台计算机上的服务器程序的文件，服务器响应。这使 CIFS 成为比 NFS 的淘汰的协议。&lt;/p>
&lt;h3 id="cifs-vs-smb-20-30cifs-与-smb-2030">CIFS vs. SMB 2.0, 3.0CIFS 与 SMB 2.0,3.0&lt;/h3>
&lt;p>The SMB &lt;a href="https://searchnetworking.techtarget.com/definition/Application-layer">application-layer&lt;/a> network protocol has been around since the 1980s. Developed at IBM, SMB allowed computers to read and write files over a local area network. Although CIFS and SMB are often used interchangeably, the CIFS protocol was introduced by Microsoft in early Windows OSes as an updated version of SMB.自 20 世纪 80 年代以来，SMB 应用层网络协议已经存在。在 IBM 开发，SMB 允许计算机通过局域网读取和写入文件。虽然 CIFS 和 SMB 通常互换使用，但 CIFS 协议由 Microsoft 在早期 Windows OS 中作为 SMB 的更新版本引入。
CIFS used the internet&amp;rsquo;s &lt;a href="https://searchnetworking.techtarget.com/definition/TCP-IP">TCP/IP&lt;/a> protocol and was viewed as a complement to existing internet application protocols, such as the File Transfer Protocol (&lt;a href="https://searchnetworking.techtarget.com/definition/File-Transfer-Protocol-FTP">FTP&lt;/a>) and the Hypertext Transfer Protocol (&lt;a href="https://whatis.techtarget.com/definition/HTTP-Hypertext-Transfer-Protocol">HTTP&lt;/a>). However, CIFS was considered a chatty protocol that was buggy and had issues with network latency. The protocol was also hard to maintain and not very secure because of the large number of commands and subcommands it processed. It was replaced when Microsoft introduced SMB in Windows 2000, Windows XP, Windows Server 2003 and Windows Server 2003 R2. Updated versions of the protocol were subsequently used in Windows Vista, Windows Server 2008, Windows 7 and Windows Server 2008.CIFS 使用 Internet 的 TCP / IP 协议，并被视为对现有的 Internet 应用程序协议的补充，例如文件传输协议（FTP）和超文本传输协议（HTTP）。但是，CIFS 被认为是一个笨拙的协议，它是错误的，并且具有网络延迟的问题。由于它处理了大量的命令和子命令，该协议也很难维护，而不是非常安全。当 Microsoft 在 Windows 2000，Windows XP，Windows Server 2003 和 Windows Server 2003 R2 中引入 SMB 时，它被替换。随后在 Windows Vista，Windows Server 2008，Windows 7 和 Windows Server 2008 中使用更新的协议版本。
SMB 2.0, introduced in the Windows OS in 2006, provided performance improvements over SMB 1.0 by reducing the number of commands and subcommands from more than 100 to 19. The 2.0 specification packs multiple actions into a single request &amp;ndash; to reduce the number of round-trip requests made between the client and server &amp;ndash; since the client may now &lt;a href="https://whatis.techtarget.com/definition/caching">cache&lt;/a> all changes to the file before committing it to the server.在 2006 年的 Windows OS 中引入的 SMB 2.0，通过减少超过 100 到 19 的命令和子命令的数量为 SMB 1.0 提供了性能改进。2.0 规范将多个操作包装为单个请求 - 以减少轮数 - 客户端和服务器之间的条件 - 由于客户端现在可以在向服务器提交到服务器之前缓存到文件的所有更改。
&lt;a href="https://searchwindowsserver.techtarget.com/definition/SMB-30-Server-Message-Block-30">SMB 3.0&lt;/a> was introduced in Windows 8 and Windows Server 2012, and launched SMB Direct, SMB Multichannel and SMB Transport Failover. It also introduced better security mechanisms, such as end-to-end encryption and the Advanced Encryption Standard (&lt;a href="https://searchsecurity.techtarget.com/definition/Advanced-Encryption-Standard">AES&lt;/a>) algorithm.SMB 3.0 是在 Windows 8 和 Windows Server 2012 中引入的，并推出了 SMB Direct，SMB MultiShannel 和 SMB 传输故障转移。它还引入了更好的安全机制，例如端到端加密和高级加密标准（AES）算法。
SMB 3.1.1, which became available in Windows 10 and Windows Server 2016, supports military-grade AES 128 GCM and AES 128 CCM encryption. It also uses the SHA-512 &lt;a href="https://searchsqlserver.techtarget.com/definition/hashing">hash&lt;/a> for preauthentication integrity checks.SMB 3.1.1 在 Windows 10 和 Windows Server 2016 中获得，支持军用 AEES 128 GCM 和 AES 128 CCM 加密。它还使用 SHA-512 散列进行预先认真完整性检查。
The &lt;a href="https://whatis.techtarget.com/definition/Samba">Samba&lt;/a> project played a major role in making SMB compatible with Unix. Samba is a free software implementation of the CIFS/SMB networking protocols that supports Microsoft Windows Server Domain, Active Directory and Microsoft Windows NT domains. With Samba, Unix-like OSes can interoperate with Windows and provided file and print services to Windows clients.Samba 项目在使 SMB 与 UNIX 兼容时发挥了重要作用。 Samba 是一个免费的软件实现，用于支持 Microsoft Windows Server 域，Active Directory 和 Microsoft Windows NT 域的 CIFS / SMB 网络协议。使用 Samba，Unix 类似的 oS 可以与 Windows 互操作，并为 Windows 客户端提供文件和打印服务。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/eysgyr/1618755274203-ef35cba6-f8d2-4371-8080-a9a8db101597.png" alt="">A comparison of CIFS, NFS and SMB file-sharing protocols.&lt;/p>
&lt;h3 id="cifs-protocol-featurescifs-协议功能">CIFS Protocol FeaturesCIFS 协议功能&lt;/h3>
&lt;p>The CIFS protocol includes a number of features as documented by Microsoft. These features include:CIFS 协议包括 Microsoft 记录的许多功能。这些功能包括：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Transport Intelligence&lt;/strong>: Although the CIFS protocol is normally used over top of a connection-oriented protocol, it can also make use of a connectionless protocol.传输智能：虽然 CIFS 协议通常在面向连接的协议之上使用，但它也可以使用无连接协议。&lt;/li>
&lt;li>&lt;strong>Flexible Connectivity&lt;/strong>: The CIFS protocol is extremely flexible with regard to client/server connectivity. A single client can connect to multiple servers, and can even make multiple connections to a single server if necessary.灵活的连接：CIFS 协议在客户端/服务器连接方面非常灵活。单个客户端可以连接到多个服务器，如果需要，甚至可以与单个服务器进行多次连接。&lt;/li>
&lt;li>&lt;strong>Feature Negotiation&lt;/strong>: The protocol&amp;rsquo;s dialect and supported features are negotiated on a connection-by-connection basis.功能协商：协议的方言和支持的功能在连接基础上协商。&lt;/li>
&lt;li>&lt;strong>Resource Access&lt;/strong>: The CIFS protocol does not limit the types of resources that clients are able to connect to. CIFS clients are able to concurrently connect to shared files, &lt;a href="https://whatis.techtarget.com/definition/named-pipe">named pipes&lt;/a>, print queues and other resources.资源访问：CIFS 协议不会限制客户端能够连接的资源类型。 CIFS 客户端能够同时连接到共享文件，命名为管道，打印队列和其他资源。&lt;/li>
&lt;li>&lt;strong>Security Context&lt;/strong>: The CIFS protocol does not limit the client to the use of a single security context. Multiple security contexts can be used over a connection if necessary.安全性上下文：CIFS 协议不会将客户端限制为使用单个安全上下文。如果需要，可以在连接上使用多个安全上下文。&lt;/li>
&lt;li>&lt;strong>File Access&lt;/strong>: A CIFS client is able to interact with multiple files simultaneously. Additionally, file sharing is a function of the server operating system and CIFS does not impose &lt;a href="https://whatis.techtarget.com/definition/lock">file locks&lt;/a>. This means that multiple clients can access a file simultaneously.文件访问：CIFS 客户端能够同时与多个文件进行交互。此外，文件共享是服务器操作系统的函数，并且 CIFS 不会强加文件锁定。这意味着多个客户端可以同时访问文件。&lt;/li>
&lt;li>&lt;strong>Extended Sub Protocols&lt;/strong>: The CIFS protocol allows the use of sub protocols, which can be used to extend functionality.扩展子协议：CIFS 协议允许使用子协议，该协议可用于扩展功能。&lt;/li>
&lt;li>&lt;strong>Named Pipe Interprocess Communication&lt;/strong>: CIFS allows named pipes to be used as a communication path between the client and the server.命名管道进程通信：CIFS 允许命名管道用作客户端和服务器之间的通信路径。&lt;/li>
&lt;li>&lt;strong>File and Record Locking and Safe Caching&lt;/strong>: Although the CIFS protocol allows multiple clients to simultaneously access a file, the protocol does support file and record locking, as well as file caching.文件和记录锁定和安全缓存：虽然 CIFS 协议允许多个客户端同时访问文件，但协议确实支持文件并记录锁定，以及文件缓存。&lt;/li>
&lt;li>&lt;strong>File, Directory and Volume Attributes&lt;/strong>: The CIFS protocol is designed to recognize and respect attributes that have been assigned at the file, folder and volume levels. The protocol is also compatible with Windows Access Control Lists (&lt;a href="https://searchsoftwarequality.techtarget.com/definition/access-control-list">ACL&lt;/a>).文件，目录和卷属性：CIFS 协议旨在识别并尊重已分配在文件，文件夹和卷级别的属性。该协议也与 Windows 访问控制列表（ACL）兼容。&lt;/li>
&lt;li>&lt;strong>File and Directory Change Notifications&lt;/strong>: The CIFS protocol includes a mechanism that allows clients to be notified when a change has been made to a shared resource. A Windows client that is accessing a shared folder through &lt;a href="https://searchenterprisedesktop.techtarget.com/definition/Microsoft-Windows-Explorer">File Explorer&lt;/a> for example, will generally display a current view of the shared folder&amp;rsquo;s contents because of this feature.文件和目录更改通知：CIFS 协议包括一种机制，该机制允许在对共享资源进行更改时通知客户端。例如，通过文件资源管理器访问共享文件夹的 Windows 客户端通常会因为此功能而显示共享文件夹内容的当前视图。&lt;/li>
&lt;li>&lt;strong>Batched Commands&lt;/strong>: The CIFS protocol allows messages to be linked together and processed in sequence.批量命令：CIFS 协议允许以序列链接在一起并处理消息。&lt;/li>
&lt;li>&lt;strong>Support for the Distributed File System&lt;/strong>: The Windows Server operating system supports the use of a Distributed File System (&lt;a href="https://searchwindowsserver.techtarget.com/definition/distributed-file-system-DFS">DFS&lt;/a>) which creates a global namespace that can include resources on multiple servers. The CIFS protocol fully supports the DFS feature.支持分布式文件系统：Windows Server 操作系统支持使用分布式文件系统（DFS），该文件系统（DFS）创建一个全局命名空间，可以在多个服务器上包含资源。 CIFS 协议完全支持 DFS 功能。&lt;/li>
&lt;li>&lt;strong>Remote Procedure Call Transport&lt;/strong>: The CIFS protocol supports the use of &lt;a href="https://searchapparchitecture.techtarget.com/definition/Remote-Procedure-Call-RPC">RPC&lt;/a> protocols such as MS-RPCE and MS-RAP.远程过程呼叫传输：CIFS 协议支持使用 RPC 协议，例如 MS-RPCE 和 MS-RAP。&lt;/li>
&lt;li>&lt;strong>Message Verification&lt;/strong>: Message signing can be used in conjunction with the CIFS protocol as a way of guaranteeing that messages have not been modified in transit.消息验证：消息签名可以与 CIFS 协议结合使用，作为保证在运输过程中未修改消息的方式。&lt;/li>
&lt;li>&lt;strong>Unicode File Name Support&lt;/strong>: The CIFS protocol supports the &lt;a href="https://whatis.techtarget.com/definition/ASCII-American-Standard-Code-for-Information-Interchange">ASCII&lt;/a> character set and &lt;a href="https://whatis.techtarget.com/definition/Unicode">Unicode&lt;/a> Legacy 8.3 filenames are supported, as are long file names.Unicode 文件名支持：CIFS 协议支持 ASCII 字符集，支持 Unicode 传统 8.3 文件名，也可以是长文件名。&lt;/li>
&lt;/ul>
&lt;h3 id="uses-of-cifs-用-cifs-的用途">Uses of CIFS 用 CIFS 的用途&lt;/h3>
&lt;p>The CIFS protocol was the genesis for the current generation SMB protocol that is used for file sharing in Windows systems. SMB is widely used for accessing files and folders on Windows networks.CIFS 协议是当前生成 SMB 协议的 Genesis，用于在 Windows 系统中共享文件共享。 SMB 广泛用于访问 Windows 网络上的文件和文件夹。
Although the CIFS protocol is probably most often associated with Microsoft, there are &lt;a href="https://whatis.techtarget.com/definition/open-source">open source&lt;/a> versions of the protocol available. CIFSD for example, is an open source CIFS/SMB protocol for Linux. Similarly, Samba &amp;ndash; the Windows interoperability suite for Linux and Unix &amp;ndash; includes an SMB/CIFS client. The CIFS/SMB protocol is also sometimes used to provide containers with connectivity to shared resources.虽然 CIFS 协议可能最常与 Microsoft 相关，但是有可用协议的开源版本。例如，CIFSD 是用于 Linux 的开源 CIFS / SMB 协议。同样，Samba - Linux 和 UNIX 的 Windows 互操作套件 - 包括 SMB / CIFS 客户端。 CIFS / SMB 协议有时也用于为包含与共享资源的连接提供的容器。&lt;/p>
&lt;h3 id="how-does-cifs-workcifs-如何工作">How Does CIFS Work?CIFS 如何工作？&lt;/h3>
&lt;p>When a CIFS client needs to communicate with a CIFS server, the action is almost always initiated at the application level. A user might, for example, open Windows File Explorer and attempt to access a shared folder.当 CIFS 客户端需要与 CIFS 服务器通信时，操作几乎始终在应用程序级别启动。例如，用户可能会打开 Windows 文件资源管理器并尝试访问共享文件夹。
The first step in accessing a shared resource is that the client establishes a &lt;a href="https://searchnetworking.techtarget.com/definition/NetBIOS">NetBIOS&lt;/a> session with the server (using a full duplex TCP session over port 139). CIFS messages can then be transmitted across this session.访问共享资源的第一步是客户端与服务器建立 NetBIOS 会话（使用端口 139 上的全双工 TCP 会话）。然后可以在本次会话中传输 CIFS 消息。
With the NetBIOS session in place, the client and server perform a negotiation process in which they determine which dialect will be used. This negotiation process is initiated by the client by way of the SMB_COM_Negotiate command. This command effectively transmits to the server a list of the dialects that the client understands. The server responds with the dialect that it will be using. This dialect must be one that is supported by both the client and the server.使用 NetBIOS 会话到位，客户端和服务器执行协商过程，其中它们确定将使用哪个方言。此协商过程由客户端发起 SMB_COM_NEGOTIET 命令。该命令有效地向服务器发送客户端理解的方言列表。服务器响应它将使用的方言。此方言必须是客户端和服务器支持的方言。
Once the client and server agree on a dialect, the client transmits authentication credentials (usually a username and password) to the server, and is furnished with a Unique Identifier (&lt;a href="https://internetofthingsagenda.techtarget.com/definition/unique-identifier-UID">UID&lt;/a>). When the client transmits its authentication credentials, it also sends a list of its capabilities. As such, this step is necessary even if the server does not require authentication.一旦客户端和服务器对方言达成一致，客户端将身份验证凭据（通常是用户名和密码）传输到服务器，并且具有唯一标识符（UID）。当客户端发送其认证凭据时，它还发送其功能列表。因此，即使服务器不需要认证，也必须执行此步骤。
On modern systems, the authentication process is generally handled by Active Directory. However, authentication is not a direct function of the CIFS protocol. As such, other authentication mechanisms, such as &lt;a href="https://searchsecurity.techtarget.com/definition/RADIUS">RADIUS&lt;/a>, could also be used. It is worth noting that CIFS can also be used for file sharing in a workgroup environment. Since a workgroup lacks a centralized authentication mechanism, the authentication process would utilize local user accounts on the workgroup computers.在现代系统上，身份验证过程通常由 Active Directory 处理。但是，身份验证不是 CIFS 协议的直接功能。因此，还可以使用其他认证机制，例如半径。值得注意的是，CIFS 也可以用于工作组环境中的文件共享。由于工作组缺乏集中式认证机制，因此认证过程将在工作组计算机上使用本地用户帐户。
If the authentication is successful, the server returns the assigned UID to the client. Now, the client transmits the Universal Naming Convention (&lt;a href="https://whatis.techtarget.com/definition/Universal-Naming-Convention-UNC">UNC&lt;/a>) name of the share that it wishes to attach to. The server checks to make sure that the share name is valid and that the client has the required permissions. If these checks are successful, the client is granted access to the share, and can then begin requesting access to resources within the share, such as files and folders.如果身份验证成功，则服务器将分配的 UID 返回给客户端。现在，客户端发送通用命名约定（UNC）所希望附加到的共享的名称。服务器检查以确保共享名称有效，并且客户端具有所需的权限。如果这些检查成功，则客户端被授予对共享的访问权限，然后可以开始请求访问共享中的资源，例如文件和文件夹。&lt;/p>
&lt;h3 id="downfalls-of-cifscifs-的垮台">Downfalls of CIFSCIFS 的垮台&lt;/h3>
&lt;p>Early on, Microsoft&amp;rsquo;s CIFS proposal held great potential. With CIFS, Microsoft sought to create a standard version of SMB. Among its benefits was support for direct communications over &lt;a href="https://searchnetworking.techtarget.com/definition/TCP">TCP&lt;/a> port 445, completely bypassing NetBIOS. In spite of this capability however, most CIFS clients and servers continued to be based on NetBIOS and LAN Manager (LanMan) authentication.早期，微软的 CIFS 提案持有巨大的潜力。使用 CIFS，Microsoft 试图创建一个标准版本的 SMB。它的好处是支持通过 TCP 端口 445 的直接通信，完全绕过 NetBIOS。然而，尽管这种能力，但大多数 CIFS 客户端和服务器都继续基于 NetBIOS 和 LAN Manager（Lanman）身份验证。
LAN Manager 1.0 was originally created to support various file system features and operating system functions within IBM&amp;rsquo;s OS/2. Subsequent versions of LAN Manager supported &lt;a href="https://searchsecurity.techtarget.com/definition/DOS">DOS&lt;/a> and Windows. The CIFS specification was based around the use of NT LAN Manager &amp;ndash; otherwise known as NTLM or NT LanMan 0.12.LAN Manager 1.0 最初创建，以支持 IBM 的 OS / 2 中的各种文件系统功能和操作系统功能。后续版本的 LAN Manager 支持 DOS 和 Windows。 CIFS 规范基于 NT LAN 管理器的使用 - 否则称为 NTLM 或 NT Lanman 0.12。
Over time, CIFS became obsolete as Microsoft released newer versions of its SMB protocol, with SMB 3.0 being the current version.随着时间的推移，CIFS 将随着 Microsoft 发布的新版本的 SMB 协议而变得过时，SMB 3.0 是当前版本。&lt;/p>
&lt;h3 id="how-to-configure-cifs-for-windows-如何为-windows-配置-cifs">How to Configure CIFS for Windows 如何为 Windows 配置 CIFS&lt;/h3>
&lt;p>The CIFS protocol is fully supported by Windows 10, but CIFS sharing is disabled by default (although Windows 10 is configured by default to act as a CIFS client). SMB is Microsoft&amp;rsquo;s preferred file sharing protocol, and supersedes CIFS, so it is unlikely that most admins will need to fully enable the CIFS protocol. Even so, the protocol is available for use if needed. Here is how the configuration process works.CIFS 协议由 Windows 10 完全支持，但默认情况下禁用 CIFS 共享（尽管默认情况下，Windows 10 配置为 CIFS 客户端）。 SMB 是 Microsoft 的首选文件共享协议，并取代了 CIFS，因此大多数管理员不太可能需要完全启用 CIFS 协议。即便如此，如果需要，协议可供使用。以下是配置过程的工作原理。
To enable the CIFS protocol, enter the Control command at the Windows Run prompt. This will cause Windows to open the &lt;a href="https://searchwindowsserver.techtarget.com/definition/Microsoft-Windows-Control-Panel">Control Panel&lt;/a>. Next, click on &lt;strong>Programs&lt;/strong>, and then click on the &lt;strong>Turn Windows Features On or Off&lt;/strong> link. This will cause Windows to display a dialog box within which features can be enabled or disabled by selecting the corresponding checkbox.要启用 CIFS 协议，请在 Windows 运行提示符下输入控制命令。这将导致 Windows 打开控制面板。接下来，单击“程序”，然后单击“或关闭”或“关闭”链接的“窗口”功能。这将导致窗口显示一个对话框，通过选择相应的复选框可以启用或禁用功能。
Scroll through the list of features until you locate SMB 1.0/CIFS File Sharing Support. By default, Windows 10 is configured to act as a CIFS client, but not as a CIFS server. Hence, some CIFS components are enabled by default. To fully enable CIFS, expand the &lt;strong>SMB 1.0/CIFS File Sharing Support&lt;/strong> container and then select the &lt;strong>SMB 1.0/CIFS Server&lt;/strong> checkbox. The other SMB 1.0/CIFS checkboxes (Automatic Removal and Client) should be selected by default. Click &lt;strong>OK&lt;/strong> to install the feature.滚动功能列表，直到找到 SMB 1.0 / CIFS 文件共享支持。默认情况下，Windows 10 被配置为充当 CIFS 客户端，但不是 CIFS 服务器。因此，默认情况下，某些 CIFS 组件将启用。要完全启用 CIFS，请展开 SMB 1.0 / CIFS 文件共享支持容器，然后选择 SMB 1.0 / CIFS 服务器复选框。默认情况下，应选择其他 SMB 1.0 / CIFS 复选框（自动删除和客户端）。单击“确定”以安装该功能。
In Windows 10, no additional CIFS configuration is necessary. Sharing a folder across a network works the same way, regardless if SMB or CIFS is being used. Right click on the folder that is to be shared and select the &lt;strong>Properties&lt;/strong> command from the shortcut menu. This will cause Windows to display the folder&amp;rsquo;s properties dialog box. Select the dialog box&amp;rsquo;s &lt;strong>Sharing&lt;/strong> tab and click the &lt;strong>Share&lt;/strong> button. Select the users with whom you wish to share the folder and adjust their permissions as necessary. If the folder needs to be shared among additional users, click the &lt;strong>Add&lt;/strong> button and then enter the name of the user or group with whom the folder should be shared. When you are done configuring the folder&amp;rsquo;s users and permissions, click the &lt;strong>Share&lt;/strong> button, followed by the &lt;strong>Close&lt;/strong> button.在 Windows 10 中，不需要额外的 CIFS 配置。在网络上共享文件夹以相同的方式运行，无论是否正在使用 SMB 或 CIFS。右键单击要共享的文件夹，然后从快捷菜单中选择“属性”命令。这将导致 Windows 显示文件夹的属性对话框。选择对话框的共享选项卡，然后单击“共享”按钮。选择与您希望共享该文件夹并根据需要调整其权限的用户。如果需要在其他用户之间共享文件夹，请单击“添加”按钮，然后输入应共享文件夹的用户或组的名称。完成文件夹的用户和权限时，单击“共享”按钮，然后单击“关闭”按钮。&lt;/p></description></item><item><title>Docs: 1.存储</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/</guid><description/></item><item><title>Docs: 2.1.Redis 高可用部署</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/2.1.redis-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/2.1.redis-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/</guid><description>
&lt;h1 id="docker-部署-redis-高可用">Docker 部署 Redis 高可用&lt;/h1>
&lt;p>Docker 部署 Redis Sentinel 模式&lt;/p>
&lt;p>Sentinel 模式至少需要 3 个节点，所以这里假设有如下三个节点&lt;/p>
&lt;ul>
&lt;li>
&lt;p>172.19.42.231&lt;/p>
&lt;/li>
&lt;li>
&lt;p>172.19.42.232&lt;/p>
&lt;/li>
&lt;li>
&lt;p>172.19.42.233&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="创建配置文件与存储所在路径xa">创建配置文件与存储所在路径
&lt;/h3>
&lt;pre>&lt;code>mkdir -p /opt/redis/config
mkdir -p /opt/redis/data
chmod 777 /opt/redis/data
&lt;/code>&lt;/pre>
&lt;h3 id="启动-redis-xa">启动 Redis
&lt;/h3>
&lt;p>master 节点配置&lt;/p>
&lt;pre>&lt;code>cat &amp;gt; /opt/redis/config/redis.conf &amp;lt;&amp;lt;EOF
save 900 1
maxmemory 1G
EOF
chmod 666 /opt/redis/config/redis.conf
&lt;/code>&lt;/pre>
&lt;p>replica 节点配置&lt;/p>
&lt;pre>&lt;code>cat &amp;gt; /opt/redis/config/redis.conf &amp;lt;&amp;lt;EOF
save 900 1
maxmemory 1G
replicaof 172.19.42.231 6379
EOF
chmod 666 /opt/redis/config/redis.conf
&lt;/code>&lt;/pre>
&lt;p>启动 Redis&lt;/p>
&lt;pre>&lt;code>docker run -d --name redis \
--network=host \
-v /opt/redis/config:/etc/redis \
-v /opt/redis/data:/data \
redis:5.0.10-alpine \
/etc/redis/redis.conf
&lt;/code>&lt;/pre>
&lt;h3 id="启动-redis-sentinelxa">启动 Redis Sentinel
&lt;/h3>
&lt;p>所有节点配置&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat &amp;gt; /opt/redis/config/sentinel.conf &lt;span style="color:#e6db74">&amp;lt;&amp;lt;EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">sentinel monitor mymaster 172.19.42.231 6379 2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">sentinel down-after-milliseconds mymaster 60000
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">sentinel failover-timeout mymaster 180000
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">sentinel parallel-syncs mymaster 1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chmod &lt;span style="color:#ae81ff">666&lt;/span> /opt/redis/config/sentinel.conf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>启动 Sentinel&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -d --name redis-sentinel &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --network&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -v /opt/redis/config:/etc/redis &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> redis:5.0.10-alpine &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /etc/redis/sentinel.conf &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --sentinel
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="kubernetes-中部署-redis-高可用">Kubernetes 中部署 Redis 高可用&lt;/h1>
&lt;h2 id="helm-官方维护的-redis-ha-chart">Helm 官方维护的 Redis-HA Chart&lt;/h2>
&lt;p>参考：&lt;a href="https://github.com/helm/charts/tree/master/stable/redis-ha">Helm 官方网站&lt;/a>、&lt;a href="https://github.com/DandyDeveloper/charts">GitHub&lt;/a>、&lt;a href="https://artifacthub.io/packages/helm/dandydev-charts/redis-ha">ArtifactHub&lt;/a>&lt;/p>
&lt;p>Grafana Dashboard:11835&lt;/p>
&lt;h2 id="第三方-redis-operator-部署-cluster-模式-redis">第三方 redis operator 部署 Cluster 模式 Redis&lt;/h2>
&lt;p>&lt;a href="https://github.com/ucloud/redis-cluster-operator">https://github.com/ucloud/redis-cluster-operator&lt;/a> ucloud 出品&lt;/p>
&lt;h2 id="第三方-redis-operator-部署-sentinel-模式-redis">第三方 redis operator 部署 Sentinel 模式 redis&lt;/h2>
&lt;p>&lt;a href="https://github.com/spotahome/redis-operator">https://github.com/spotahome/redis-operator&lt;/a>，通过 operator 可以简单得创建出 6 个 pod，3 个 redis 节点，3 个 sentinel 节点。&lt;/p>
&lt;p>ucloud 基于该项目推出了一个类似的：&lt;a href="https://github.com/ucloud/redis-operator">https://github.com/ucloud/redis-operator&lt;/a>&lt;/p>
&lt;p>部署所需 yaml 在 github 上&lt;/p>
&lt;p>创建 operator&lt;/p>
&lt;pre>&lt;code>kubectl apply -f https://raw.githubusercontent.com/spotahome/redis-operator/master/example/operator/all-redis-operator-resources.yaml
&lt;/code>&lt;/pre>
&lt;p>配置 redis 密码认证&lt;/p>
&lt;pre>&lt;code># “密码”修改为自己想设置的密码
echo -n &amp;quot;密码&amp;quot; &amp;gt; password
kubectl create -n redis secret generic redis-auth --from-file=password
&lt;/code>&lt;/pre>
&lt;p>部署 redis&lt;/p>
&lt;pre>&lt;code>kubectl create -f https://raw.githubusercontent.com/spotahome/redis-operator/master/example/redisfailover/basic.yaml
&lt;/code>&lt;/pre>
&lt;p>Bitnami 官方用于部署 redis 的 helm chart&lt;/p>
&lt;p>&lt;a href="https://github.com/bitnami/charts/tree/master/bitnami/redis/">https://github.com/bitnami/charts/tree/master/bitnami/redis/&lt;/a>&lt;/p>
&lt;p>获取 charts 文件&lt;/p>
&lt;ol>
&lt;li>
&lt;p>helm repo add bitnami &lt;a href="https://charts.bitnami.com/bitnami">https://charts.bitnami.com/bitnami&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>helm pull bitnami/redis&lt;/p>
&lt;/li>
&lt;li>
&lt;p>tar -zxvf redis-XX.X.X.tgz&lt;/p>
&lt;/li>
&lt;li>
&lt;p>修改值文件，参考：&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>部署 redis&lt;/p>
&lt;ol>
&lt;li>helm install redis -n redis &amp;ndash;set password=oc123 .&lt;/li>
&lt;/ol>
&lt;p>Bitnami 版问题：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>无法故障恢复，删除 pod 后， master 无法切换&lt;/p>
&lt;/li>
&lt;li>
&lt;p>是有了安全环境容器，导致容器内无法读取 /proc/sys/net/core/somaxconn 参数的值&lt;/p>
&lt;/li>
&lt;li>
&lt;p>问题跟踪：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/bitnami/charts/issues/3700">https://github.com/bitnami/charts/issues/3700&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/bitnami/charts/issues/4569">https://github.com/bitnami/charts/issues/4569&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: 2.Network File System</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/2.network-file-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/2.network-file-system/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;p>&lt;strong>Network File System(网络文件系统，简称 NFS)&lt;/strong> 是让客户端通过网络访问不同主机上磁盘里的数据，主要用在类 Unix 系统上实现文件共享的一种方法。 本例演示 CentOS 7 下安装和配置 NFS 的基本步骤。&lt;/p></description></item><item><title>Docs: 2.Redis 配置详解</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/2.redis-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/2.redis-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;a href="https://redis.io/topics/config">官方文档&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Redis 可以在不使用配置文件的情况下使用内置的默认配置启动。但是一般情况，都会使用一个 Redis 的配置文件(文件名通常是 redis.conf)来启动 Redis。Redis 启动后，会将 redis.conf 文件的内容加载到内存中，通过 Redis 客户端的 &lt;strong>config get *&lt;/strong> 命令，即可获取当前已经加载到内存中的配置。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>127.0.0.1:6379&amp;gt; config get *
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 1&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#e6db74">&amp;#34;dbfilename&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 2&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#e6db74">&amp;#34;dump.rdb&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 3&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#e6db74">&amp;#34;requirepass&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 4&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 5&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#e6db74">&amp;#34;masterauth&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 6&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>....... 后略
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>配置文件的写法非常简单。redis.conf 由 &lt;strong>Directives(指令)&lt;/strong> 组成，每条指令一行。而 Directives 分为两部分&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Keyword(关键字)&lt;/strong> # 该指令的含义&lt;/li>
&lt;li>&lt;strong>Arguments(参数)&lt;/strong> # Redis 执行该指令时的行为&lt;/li>
&lt;/ul>
&lt;p>格式如下：&lt;/p>
&lt;pre>&lt;code># 关键字 参数(多个参数以空格分隔)
Keyword Argument1 Argument2 ... ArugmentN
&lt;/code>&lt;/pre>
&lt;h2 id="通过命令函参数传递配置">通过命令函参数传递配置&lt;/h2>
&lt;p>通过命令行传递参数的格式与 redis.conf 文件中配置格式完全相同，只不过关键字前面有个 &lt;code>--&lt;/code> 前缀。比如：&lt;/p>
&lt;pre>&lt;code>redis-server --port 6380 --replicaof 127.0.0.1 6379
&lt;/code>&lt;/pre>
&lt;p>生成的内存中配置如下：&lt;/p>
&lt;pre>&lt;code>127.0.0.1:6380&amp;gt; config get &amp;quot;replicaof&amp;quot;
1) &amp;quot;replicaof&amp;quot;
2) &amp;quot;127.0.0.1 6379&amp;quot;
127.0.0.1:6380&amp;gt; config get &amp;quot;port&amp;quot;
1) &amp;quot;port&amp;quot;
2) &amp;quot;6380&amp;quot;
&lt;/code>&lt;/pre>
&lt;h3 id="其他基本示例">其他基本示例&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>Usage: ./redis-server &lt;span style="color:#f92672">[&lt;/span>/path/to/redis.conf&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">[&lt;/span>options&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server - &lt;span style="color:#f92672">(&lt;/span>read config from stdin&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server -v or --version
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server -h or --help
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server --test-memory &amp;lt;megabytes&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Examples:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server &lt;span style="color:#f92672">(&lt;/span>run the server with default conf&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server /etc/redis/6379.conf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server --port &lt;span style="color:#ae81ff">7777&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server --port &lt;span style="color:#ae81ff">7777&lt;/span> --replicaof 127.0.0.1 &lt;span style="color:#ae81ff">8888&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./redis-server /etc/myredis.conf --loglevel verbose
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="启动-redis-后修改配置">启动 Redis 后修改配置&lt;/h2>
&lt;p>Redis 支持在线热更新配置，可以通过 config set ARGUMENT 命令来更改当前配置，若想要配置永久生效，则使用 config rewrite 命令将内存中的配置重写到启动 Redis 时指定的 redis.conf 文件中。但是，并非配置中的所有指令都支持这种方式。&lt;/p>
&lt;h2 id="简单的配置文件示例">简单的配置文件示例&lt;/h2>
&lt;pre>&lt;code>dir &amp;quot;/data&amp;quot;
port 6379
maxmemory 1G
maxmemory-policy volatile-lru
min-replicas-max-lag 5
min-replicas-to-write 1
rdbchecksum yes
rdbcompression yes
repl-diskless-sync yes
save 900 1
requirepass redis
masterauth &amp;quot;redis&amp;quot;
replica-announce-port 6379
replica-announce-ip &amp;quot;10.105.180.122&amp;quot;
&lt;/code>&lt;/pre>
&lt;h1 id="redisconf-文件详解">redis.conf 文件详解&lt;/h1>
&lt;h2 id="includes-配置环境">Includes 配置环境&lt;/h2>
&lt;ul>
&lt;li>**include /PATH/TO/FILE **# Redis 启动时，除了加载 redis.conf 文件外，还会加载 include 指令指定的文件。&lt;/li>
&lt;/ul>
&lt;h2 id="network-配置环境">Network 配置环境&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>bind 127.0.0.1&lt;/strong> # 监听的地址&lt;/li>
&lt;li>&lt;strong>port 6379&lt;/strong> # redis 监听的端口，默认 6379&lt;/li>
&lt;li>&lt;strong>tcp-backlog 511&lt;/strong> # tcp 的等待队列&lt;/li>
&lt;li>&lt;strong>timeout 0&lt;/strong> # 客户端连接超时时长。&lt;code>默认值：0&lt;/code>，不会超时&lt;/li>
&lt;/ul>
&lt;h2 id="general-配置环境">General 配置环境&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>daemonize yes|no&lt;/strong> # 指定是否在后台运行&lt;/li>
&lt;li>&lt;strong>databases 16&lt;/strong> # 可使用的 databases，默认 16 个&lt;/li>
&lt;li>&lt;strong>logfile /PATH/TO/FILE&lt;/strong> # 指定 redis 记录日志文件位置&lt;/li>
&lt;/ul>
&lt;h2 id="snapshotting-配置环境-rdb-功能">Snapshotting 配置环境 RDB 功能&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>save TIME NUM&lt;/strong> # 在 TIME 秒内有 NUM 个键改变，就做一次快照&lt;/li>
&lt;li>&lt;strong>stop-writes-on-bgsave-error yes|no&lt;/strong> # 当 RDB 持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过 info 中的 rdb_last_bgsave_status 了解 RDB 持久化是否有错误&lt;/li>
&lt;li>&lt;strong>rdbcompression yes|no&lt;/strong> # 是否压缩 rdb 文件，rdb 文件压缩使用 LZF 压缩算法。压缩需要一些 cpu 的消耗；不压缩需要更多的磁盘空间&lt;/li>
&lt;li>&lt;strong>rdbchecksum yes|no&lt;/strong> # 是否校验 rdb 文件。从 rdb 格式的第五个版本开始，在 rdb 文件的末尾会带上 CRC64 的校验和。这跟有利于文件的容错性，但是在保存 rdb 文件的时候，会有大概 10%的性能损耗，所以如果你追求高性能，可以关闭该配置。&lt;/li>
&lt;li>&lt;strong>dbfilename FileName&lt;/strong> # 指定 snapshot 文件的文件名。默认为 dump.rbd&lt;/li>
&lt;li>&lt;strong>dir PATH&lt;/strong> # 指定 snapshot 文件的保存路径(注意：PATH 是目录，不是文件，具体文件名通过 dbfilename 关键字配置)。默认为 /var/lib/redis/ 目录&lt;/li>
&lt;/ul>
&lt;h2 id="replication-配置环境">Replication 配置环境&lt;/h2>
&lt;ul>
&lt;li>**replicof 192.168.1.2 6379 **# 启动主从模式，并设定自己为从服务器，主服务器 IP 为 192.168.1.2，主服务器端口为 6379&lt;/li>
&lt;li>&lt;strong>slave-read-only no&lt;/strong> # 作为从服务器是否只读，默认不只读&lt;/li>
&lt;/ul>
&lt;h2 id="security-配置环境">Security 配置环境&lt;/h2>
&lt;ul>
&lt;li>**requirepass PASSWORD **# 配置认证密码为 PASSWORD&lt;/li>
&lt;/ul>
&lt;h2 id="limits-配置环境">Limits 配置环境&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>maxmemory BYTES&lt;/strong> # 指定 redis 可使用的最大内存量，单位是 bytes。如果达到限额，则需要配合 maxmemory-policy 配置指定的策略删除 key。note：slave 的输出缓冲区是不计算在 maxmemory 内的。所以为了防止主机内存使用完，建议设置的 maxmemory 需要更小一些。&lt;/li>
&lt;li>&lt;strong>maxmemory-policy POLICY&lt;/strong> # 指定 redis 超过内存限额之后的策略，包括以下几种
&lt;ul>
&lt;li>volatile-lru：利用 LRU 算法移除设置过过期时间的 key。&lt;/li>
&lt;li>volatile-random：随机移除设置过过期时间的 key。&lt;/li>
&lt;li>volatile-ttl：移除即将过期的 key，根据最近过期时间来删除（辅以 TTL）&lt;/li>
&lt;li>allkeys-lru：利用 LRU 算法移除任何 key。&lt;/li>
&lt;li>allkeys-random：随机移除任何 key。&lt;/li>
&lt;li>noeviction：不移除任何 key，只是返回一个写错误。&lt;/li>
&lt;li>Note:上面的这些驱逐策略，如果 redis 没有合适的 key 驱逐，对于写命令，还是会返回错误。redis 将不再接收写请求，只接收 get 请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="append-only-mode-配置环境-aof-功能配置">Append Only Mode 配置环境 AOF 功能配置&lt;/h2>
&lt;h2 id="lua-scripting-配置环境">LUA Scripting 配置环境&lt;/h2>
&lt;h2 id="redis-cluster-配置环境">Redis Cluster 配置环境&lt;/h2>
&lt;h2 id="slow-log-配置环境">SLOW LOG 配置环境&lt;/h2>
&lt;h2 id="latency-monitor-配置环境">LATENCY MONITOR 配置环境&lt;/h2>
&lt;h2 id="event-notification-配置环境">EVENT NOTIFICATION 配置环境&lt;/h2>
&lt;h2 id="advanced-config-配置环境">ADVANCED CONFIG 配置环境&lt;/h2></description></item><item><title>Docs: 2.数据库</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://db-engines.com/en/article/Database">DB-Engines&lt;/a>(所有数据库的排名、状态等信息的观察网站)&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>数据库是由特定软件（所谓的数据库管理系统或 DBMS）管理的数据的逻辑集合。数据库和 DBMS 共同构成数据库系统。&lt;/p>
&lt;p>A database is a logical collection of data which is managed by a specific software (the so-called &lt;a href="https://db-engines.com/en/article/Database+Management+System">database management system&lt;/a> or DBMS). Database and DBMS together form the database system.&lt;/p>
&lt;p>数据库不仅包括用户数据，还包括对其进行管理所需的对象（例如索引或日志文件）。&lt;/p>
&lt;p>A database includes not only user data but also the objects necessary for its management (e.g. indexes or logfiles).&lt;/p>
&lt;p>数据库的类型&lt;/p>
&lt;ol>
&lt;li>RDBMS：关系型数据库
&lt;ol>
&lt;li>Oracle&lt;/li>
&lt;li>MariaDB/MySQL&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>NoSQL：非关系型数据库
&lt;ol>
&lt;li>Key/Val NoSQL：redis,etcd&lt;/li>
&lt;li>Column Family NoSQL 列族：HBase&lt;/li>
&lt;li>Documentation NoSQL：MongoDB&lt;/li>
&lt;li>Graph  NoSQL：Neo4j&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>NewSQL：分布式数据库&lt;/li>
&lt;/ol>
&lt;h1 id="relational-dbms">Relational DBMS&lt;/h1>
&lt;p>&lt;strong>Relational database management systems(关系数据库管理系统，简称 RDBMS)&lt;/strong> support the relational (=table-oriented) data model. The schema of a table (=relation schema) is defined by the table name and a fixed number of attributes with fixed data types. A record (=entity) corresponds to a row in the table and consists of the values of each attribute. A relation thus consists of a set of uniform records.&lt;/p>
&lt;p>The table schemas are generated by normalization in the process of data modeling.&lt;/p>
&lt;p>Certain basic operations are defined on the relations:&lt;/p>
&lt;ul>
&lt;li>classical set operations (union, intersection and difference)&lt;/li>
&lt;li>Selection (selection of a subset of records according to certain filter criteria for the attribute values)&lt;/li>
&lt;li>Projection (selecting a subset of attributes / columns of the table)&lt;/li>
&lt;li>Join: special conjunction of multiple tables as a combination of the Cartesian product with selection and projection.&lt;/li>
&lt;/ul>
&lt;p>These basic operations, as well as operations for creation, modification and deletion of table schemas, operations for controlling transactions and user management are performed by means of database languages, with SQL being a well established standard for such languages.&lt;/p>
&lt;p>The first relational database management systems appeared on the market at the beginning of the 1980s and since have been the most commonly used &lt;a href="https://db-engines.com/en/article/DBMS">DBMS&lt;/a> type.&lt;/p>
&lt;p>Over the years, many RDBMS have been expanded with non-relational concepts such as user-defined data types, not atomic attributes, inheritance and hierarchies, which is why they are sometimes referred to as object-relational DBMS.&lt;/p>
&lt;h2 id="most-popular-examples">Most popular examples&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://db-engines.com/en/system/Oracle">Oracle&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/system/MySQL">MySQL&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/system/Microsoft+SQL+Server">Microsoft SQL Server&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/system/PostgreSQL">PostgreSQL&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/system/IBM+Db2">IBM Db2&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Find more systems in our &lt;a href="https://db-engines.com/en/ranking/relational+dbms">relational DBMS ranking&lt;/a>.&lt;/p>
&lt;h1 id="nosql">NoSQL&lt;/h1>
&lt;p>NoSQL Database Systems are an alternative to the mainstream &lt;a href="https://db-engines.com/en/article/Relational+DBMS">Relational DBMS&lt;/a>. They don&amp;rsquo;t use a relational data model and typically have no SQL interface.&lt;/p>
&lt;p>Although this type of systems exists for many years (some even longer than relational systems), the term NoSQL was first introduced in 2009 when many new systems were developed in order to cope with the new requirements for database management systems at that time. E.g.  Big Data, scalability and fault tolerance for large web applications.&lt;/p>
&lt;p>The acronym NoSQL is often understood as &amp;ldquo;Not Only SQL&amp;rdquo;, implying that relational systems are a proven technology but not necessarily the optimal choice for each kind of intended use.&lt;/p>
&lt;h2 id="classification分类">Classification(分类)&lt;/h2>
&lt;p>NoSQL systems are a heterogenous group of very different database systems. Therefore each attempt for a classification fails in classifying one or another system. However, the following categegories are well accepted:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://db-engines.com/en/article/Key-value+Stores">Key-Value Stores&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/article/Wide+Column+Stores">Wide Column Stores&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/article/Document+Stores">Document Stores&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/article/Graph+DBMS">Graph DBMS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/article/RDF+Stores">RDF Stores&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/article/Native+XML+DBMS">Native XML DBMS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/article/Content+Stores">Content Stores&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://db-engines.com/en/article/Search+Engines">Search Engines&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="advantages优势">Advantages(优势)&lt;/h2>
&lt;p>Not all of the above mentioned classes have the same general advantages, but they benefit from a combination of the following aspects.&lt;/p>
&lt;ul>
&lt;li>higher performance&lt;/li>
&lt;li>easy distribution of data on different nodes (e.g. sharding), thereby achieving scalability and fault tolerance&lt;/li>
&lt;li>higher flexibility by using a schema-free data model.&lt;/li>
&lt;li>simpler administration&lt;/li>
&lt;/ul>
&lt;h3 id="methods">Methods&lt;/h3>
&lt;p>These advantages are achieved by means of one or more of the following approaches:&lt;/p>
&lt;ul>
&lt;li>No normalized relational data model&lt;/li>
&lt;li>Abandoning one or more of the ACID criteria&lt;/li>
&lt;li>Less powerful possibilities for querying the data&lt;/li>
&lt;/ul></description></item><item><title>Docs: 3.1.Replication(复制) 模式详解</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/3.1.replication%E5%A4%8D%E5%88%B6-%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/3.1.replication%E5%A4%8D%E5%88%B6-%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;p>参考：&lt;a href="https://redis.io/topics/replication">官方文档&lt;/a>&lt;/p>
&lt;ol>
&lt;li>基本原理&lt;/li>
&lt;/ol>
&lt;p>主从复制模式中包含 一个主数据库实例(master) 与 一个或多个从数据库实例(slave)，如下图&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/equ0le/1616134781068-8b8f1a94-6405-4bea-98b3-5627a9d8ff17.png" alt="">&lt;/p>
&lt;p>客户端可对主数据库进行读写操作，对从数据库进行读操作，主数据库写入的数据会实时自动同步给从数据库。&lt;/p>
&lt;p>具体工作机制为：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>slave 启动后，向 master 发送 SYNC 命令，master 接收到 SYNC 命令后通过 bgsave 保存快照(即上文所介绍的 RDB 持久化)，并使用缓冲区记录保存快照这段时间内执行的写命令&lt;/p>
&lt;/li>
&lt;li>
&lt;p>master 将保存的快照文件发送给 slave，并继续记录执行的写命令&lt;/p>
&lt;/li>
&lt;li>
&lt;p>slave 接收到快照文件后，加载快照文件，载入数据&lt;/p>
&lt;/li>
&lt;li>
&lt;p>master 快照发送完后开始向 slave 发送缓冲区的写命令，slave 接收命令并执行，完成复制初始化&lt;/p>
&lt;/li>
&lt;li>
&lt;p>此后 master 每次执行一个写命令都会同步发送给 slave，保持 master 与 slave 之间数据的一致性&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>2. 部署示例&lt;/strong>&lt;/p>
&lt;p>redis.conf 的主要配置&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">###网络相关###&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># bind 127.0.0.1 # 绑定监听的网卡IP，注释掉或配置成0.0.0.0可使任意IP均可访问&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>protected-mode no &lt;span style="color:#75715e"># 关闭保护模式，使用密码访问&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>port &lt;span style="color:#ae81ff">6379&lt;/span> &lt;span style="color:#75715e"># 设置监听端口，建议生产环境均使用自定义端口&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>timeout &lt;span style="color:#ae81ff">30&lt;/span> &lt;span style="color:#75715e"># 客户端连接空闲多久后断开连接，单位秒，0表示禁用&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">###通用配置###&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>daemonize yes &lt;span style="color:#75715e"># 在后台运行&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pidfile /var/run/redis_6379.pid &lt;span style="color:#75715e"># pid进程文件名&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>logfile /usr/local/redis/logs/redis.log &lt;span style="color:#75715e"># 日志文件的位置&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">###RDB持久化配置###&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>save &lt;span style="color:#ae81ff">900&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#75715e"># 900s内至少一次写操作则执行bgsave进行RDB持久化&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>save &lt;span style="color:#ae81ff">300&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>save &lt;span style="color:#ae81ff">60&lt;/span> &lt;span style="color:#ae81ff">10000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 如果禁用RDB持久化，可在这里添加 save &amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rdbcompression yes &lt;span style="color:#75715e">#是否对RDB文件进行压缩，建议设置为no，以（磁盘）空间换（CPU）时间&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dbfilename dump.rdb &lt;span style="color:#75715e"># RDB文件名称&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dir /usr/local/redis/datas &lt;span style="color:#75715e"># RDB文件保存路径，AOF文件也保存在这里&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">###AOF配置###&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>appendonly yes &lt;span style="color:#75715e"># 默认值是no，表示不使用AOF增量持久化的方式，使用RDB全量持久化的方式&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>appendfsync everysec &lt;span style="color:#75715e"># 可选值 always， everysec，no，建议设置为everysec&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">###设置密码###&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>requirepass &lt;span style="color:#ae81ff">123456&lt;/span> &lt;span style="color:#75715e"># 设置复杂一点的密码&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>部署主从复制模式只需稍微调整 slave 的配置，在 redis.conf 中添加&lt;/p>
&lt;pre>&lt;code>replicaof 127.0.0.1 6379 # master的ip，port
masterauth 123456 # master的密码
replica-serve-stale-data no # 如果slave无法与master同步，设置成slave不可读，方便监控脚本发现问题
&lt;/code>&lt;/pre>
&lt;p>本示例在单台服务器上配置 master 端口 6379，两个 slave 端口分别为 7001,7002，启动 master，再启动两个 slave&lt;/p>
&lt;pre>&lt;code>[root@dev-server-1 master-slave]# redis-server master.conf
[root@dev-server-1 master-slave]# redis-server slave1.conf
[root@dev-server-1 master-slave]# redis-server slave2.conf
&lt;/code>&lt;/pre>
&lt;p>进入 master 数据库，写入一个数据，再进入一个 slave 数据库，立即便可访问刚才写入 master 数据库的数据。如下所示&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@dev-server-1 master-slave&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># redis-cli&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>127.0.0.1:6379&amp;gt; auth &lt;span style="color:#ae81ff">123456&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>OK
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>127.0.0.1:6379&amp;gt; set site blog.jboost.cn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>OK
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>127.0.0.1:6379&amp;gt; get site
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;blog.jboost.cn&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>127.0.0.1:6379&amp;gt; info replication
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Replication&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>role:master
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>connected_slaves:2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>slave0:ip&lt;span style="color:#f92672">=&lt;/span>127.0.0.1,port&lt;span style="color:#f92672">=&lt;/span>7001,state&lt;span style="color:#f92672">=&lt;/span>online,offset&lt;span style="color:#f92672">=&lt;/span>13364738,lag&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>slave1:ip&lt;span style="color:#f92672">=&lt;/span>127.0.0.1,port&lt;span style="color:#f92672">=&lt;/span>7002,state&lt;span style="color:#f92672">=&lt;/span>online,offset&lt;span style="color:#f92672">=&lt;/span>13364738,lag&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>127.0.0.1:6379&amp;gt; exit
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@dev-server-1 master-slave&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># redis-cli -p 7001&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>127.0.0.1:7001&amp;gt; auth &lt;span style="color:#ae81ff">123456&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>OK
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>127.0.0.1:7001&amp;gt; get site
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;blog.jboost.cn&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行 info replication 命令可以查看连接该数据库的其它库的信息，如上可看到有两个 slave 连接到 master&lt;/p>
&lt;p>&lt;strong>主从复制的优缺点&lt;/strong>&lt;/p>
&lt;p>优点：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>master 能自动将数据同步到 slave，可以进行读写分离，分担 master 的读压力&lt;/p>
&lt;/li>
&lt;li>
&lt;p>master、slave 之间的同步是以非阻塞的方式进行的，同步期间，客户端仍然可以提交查询或更新请求&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>缺点：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>不具备自动容错与恢复功能，master 或 slave 的宕机都可能导致客户端请求失败，需要等待机器重启或手动切换客户端 IP 才能恢复&lt;/p>
&lt;/li>
&lt;li>
&lt;p>master 宕机，如果宕机前数据没有同步完，则切换 IP 后会存在数据不一致的问题&lt;/p>
&lt;/li>
&lt;li>
&lt;p>难以支持在线扩容，Redis 的容量受限于单机配置&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: 3.大数据</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/3.%E5%A4%A7%E6%95%B0%E6%8D%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/3.%E5%A4%A7%E6%95%B0%E6%8D%AE/</guid><description/></item><item><title>Docs: 4.1.Sentinel(哨兵) 模式详解</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/4.1.sentinel%E5%93%A8%E5%85%B5-%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/4.1.sentinel%E5%93%A8%E5%85%B5-%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;p>参考：&lt;a href="https://redis.io/topics/sentinel">官方文档&lt;/a>、&lt;a href="http://www.redis.cn/topics/sentinel.html">中文文档&lt;/a>、&lt;a href="https://www.cnblogs.com/kevingrace/p/9004460.html">博客园大佬&lt;/a>、&lt;a href="https://www.cnblogs.com/biglittleant/p/7770960.html">博客园大佬 2&lt;/a>&lt;/p>
&lt;p>&lt;strong>Redis Sentinel(哨兵) 基于 Redis 的 Replication(复制) 模式，增加了一个名为 Sentinel 的管理程序&lt;/strong>，用来保存 Redis Replication 模式的架构信息，以及对外提供该信息。同时 sentinel 程序监控多台 Redis 状态，当 Redis 不可用时，Sentinel 将自动下线该 Redis。&lt;/p>
&lt;p>注意：Sentinel(哨兵) 模式必须基于 Replication 模式，否则没有任何意义。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ep6g3m/1616134767001-d94ca9de-6764-40ef-977f-4af0f094154f.png" alt="">&lt;/p>
&lt;p>注意：一套 Sentinel 是可以监听多套 Replication 模式的 Redis 的组合，这样可以有效节省资源，其中每套 Replication 模式的 Redis 会使用一个 master-name 作为一个标识。&lt;/p>
&lt;p>&lt;strong>客户端操作 Redis 原理&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>client 访问 sentinel 集群，获取 redis 集群 master 的 ip&lt;/p>
&lt;/li>
&lt;li>
&lt;p>client 连接 redis 集群的 master 对数据进行读写操作。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Redis Sentinel 为 Redis 提供了高可用性。这意味着，可以使用 Sentinel 程序部署 Redis，这种部署可以在无需人工干预的情况下抵抗某些类型的故障。Sentinel 具有以下特性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>**Monitoring(监控) **# Sentinel 会不断检查指定的 master 和 replica 节点是否正常工作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>**Notification(通知) **# 当 Sentinel 监控的 Redis 出现问题时，可以通过 API 向 人或程序 发送通知。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>**Automatic failover(自动故障转移) **# 如果 master 节点未按预期工作，则 Sentinel 将会启动 &lt;strong>Failover(故障转移)&lt;/strong> 过程。在这个过程中，replica 节点将会升级为 master 节点，其他的 replica 节点将使用新的 master 信息。&lt;/p>
&lt;ul>
&lt;li>在故障转移期间，所有 Redis 节点的配置文件、所有 Sentinel 节点的配置文件，都会被自动更新。正是由于这种机制，Sentinel 才可以正常完整自动故障转移流程。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Configuration provider(配置提供器)&lt;/strong> # Sentinel 作为客户端服务发现的权威来源：客户端连接到 Sentinels，以便询问负责特定服务的当前 Redis Master 节点的地址。如果发生故障转移，Sentinels 将报告新的地址。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="sentinel-配置">Sentinel 配置&lt;/h1>
&lt;p>&lt;strong>/etc/sentinel.conf&lt;/strong> # Sentinel 主程序的配置文件&lt;/p>
&lt;h2 id="基本配置示例">基本配置示例&lt;/h2>
&lt;pre>&lt;code>sentinel monitor mymaster 172.19.42.231 6379 2
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1
&lt;/code>&lt;/pre>
&lt;h1 id="sentinel-和-replicas-的自动发现机制">Sentinel 和 Replicas 的自动发现机制&lt;/h1>
&lt;p>参考：&lt;a href="https://redis.io/topics/sentinel#sentinels-and-replicas-auto-discovery">官方文档&lt;/a>&lt;/p>
&lt;p>虽然 Sentinel 集群中各个 Sentinel 都互相连接彼此来检查对方的可用性以及互相发送消息。但是不用为任何一个 Sentinel 手动配置其它的 Sentinel 的信息。因为 Sentinel 利用了 Redis 的 &lt;a href="https://www.yuque.com/go/doc/33188044">&lt;strong>Pub/Sub(发布/订阅)&lt;/strong>&lt;/a>** **机制去自动发现，监控了相同的 master 和 replica 的其他 Sentinel 节点。&lt;/p>
&lt;blockquote>
&lt;p>通过向名为&lt;code>__sentinel__:hello&lt;/code>的频道中发送消息来实现自动发现 Sentinel 节点的功能。&lt;/p>
&lt;/blockquote>
&lt;p>同样，也不需要在 Sentinel 中配置某个 master 的所有 replica 的地址，Sentinel 会通过询问 master 来得到这些 replica 的地址的。&lt;/p>
&lt;p>所以，Sentinel 具有两个发现机制&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Sentinel 发现监控相同目标的其他 Sentinel 节点&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Sentinel 发现监控目标的 Replica 节点&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>自动发现流程&lt;/p>
&lt;ul>
&lt;li>
&lt;p>每隔 2 秒钟，每个 Sentinel 向每个 master 和 replica 中的&lt;code>__sentinel__:hello&lt;/code> 频道，&lt;strong>发布&lt;/strong>一条消息，消息内容为发布消息的 Sentinel 的 IP、PORT、runid。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个 Sentinel 也&lt;strong>订阅&lt;/strong>了每个 master 和 replica 中的 &lt;code>__sentinel__:hello&lt;/code> 频道，以便发现未知的 Sentinel ，当检测到了新的 Sentinel ，则将其加入到自身维护的 master 监控列表中。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个 Sentinel 发送的消息中也包含了其当前维护的最新的 master 配置。如果某个 Sentinel 发现自己的配置版本低于接收到的配置版本，则会用新的配置更新自己的 master 配置。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在添加一个新的 sentinel 前，sentinel 总是检查是否已经有 sentinel 与新的 sentinel 的进程号或者是地址是一样的。如果是那样，这个 sentinel 将会被删除，而把新的 sentinel 添加上去。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>自动发现后配置文件变化效果&lt;/p>
&lt;p>当我们想要启动 Sentienl 时，仅仅需要配置一些基本信息，以及要监控的目标 IP 与 PORT，即可使用该文件启动了。以该文件启动 Sentinel 后，Sentinel 将会根据自动发现功能，补全这些配置，效果如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 手动写的 Sentinel 运行时配置文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@master-1 config&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># cat sentinel.conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel monitor mymaster 172.19.42.231 &lt;span style="color:#ae81ff">6379&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel down-after-milliseconds mymaster &lt;span style="color:#ae81ff">60000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel failover-timeout mymaster &lt;span style="color:#ae81ff">180000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel parallel-syncs mymaster &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@master-1 config&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker restart redis-sentinel&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>redis-sentinel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Sentinel 启动后，配置文件变成如下样子&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 这就是根据自动发现机制，发现了其他的 sentinel 节点以及其他 replica 节点&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@master-1 config&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># cat sentinel.conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel myid c3463c1f451f766b13947ea315f4f38e7c7296f0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel deny-scripts-reconfig yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel monitor mymaster 172.19.42.231 &lt;span style="color:#ae81ff">6379&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel down-after-milliseconds mymaster &lt;span style="color:#ae81ff">60000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Generated by CONFIG REWRITE&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>port &lt;span style="color:#ae81ff">26379&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dir &lt;span style="color:#e6db74">&amp;#34;/data&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel config-epoch mymaster &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel leader-epoch mymaster &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel known-replica mymaster 172.19.42.232 &lt;span style="color:#ae81ff">6379&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel known-replica mymaster 172.19.42.233 &lt;span style="color:#ae81ff">6379&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel known-sentinel mymaster 172.19.42.233 &lt;span style="color:#ae81ff">26379&lt;/span> bda131accb328d1254cf95b8a918d85d262c72c2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel known-sentinel mymaster 172.19.42.232 &lt;span style="color:#ae81ff">26379&lt;/span> 0d4e5dffff14df5fb54b1a00b7d286f0f22eb74e
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sentinel current-epoch &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Sentinel 工作流程&lt;/p>
&lt;h2 id="名词解释">名词解释&lt;/h2>
&lt;p>&lt;strong>SDOWN(主观下线)&lt;/strong> 与** ODOWN(客观下线)** # 参考：&lt;a href="https://www.cnblogs.com/kevingrace/p/9004460.html">https://www.cnblogs.com/kevingrace/p/9004460.html&lt;/a>&lt;/p>
&lt;p>&lt;strong>Configuration Epochs(配置时代)&lt;/strong> # 类似 Raft 算法中的 term(任期) 概念。参考：&lt;a href="https://redis.io/topics/sentinel#configuration-epochs">官方文档&lt;/a>&lt;/p>
&lt;h2 id="monitoring监控">Monitoring(监控)&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>每个 Sentinel 以每秒钟一次的频率向它所知的 Master，Slave 以及其他 Sentinel 实例发送一个 PING 命令。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 own-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel 标记为主观下线。 &lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果一个 Master 被标记为主观下线，则正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认 Master 的确进入了主观下线状态。 &lt;/p>
&lt;/li>
&lt;li>
&lt;p>当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态，则 Master 会被标记为客观下线。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在一般情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当 Master 被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次。 &lt;/p>
&lt;/li>
&lt;li>
&lt;p>若没有足够数量的 Sentinel 同意 Master 已经下线，Master 的客观下线状态就会被移除。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复，Master 的主观下线状态就会被移除。&lt;strong>三个定时任务&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="sentinel-在内部有-3-个定时任务xa">Sentinel 在内部有 3 个定时任务
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>每 10 秒 sentinel 会对 master 和 slave 执行 info 命令，这个任务达到两个目的：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>发现 slave 节点&lt;/p>
&lt;/li>
&lt;li>
&lt;p>确认主从关系&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>每 2 秒 sentinel 通过 master 节点的 channel 交换信息（pub/sub）。master 节点上有一个发布订阅的频道(&lt;strong>sentinel&lt;/strong>:hello)。sentinel 节点通过 &lt;code>__sentinel__:hello&lt;/code> 频道进行信息交换(对节点的&amp;quot;看法&amp;quot;和自身的信息)，达成共识。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每 1 秒 sentinel 对其他 sentinel 和 redis 节点执行 ping 操作(相互监控)。这个其实是一个心跳检测，是失败判定的依据。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Failover(故障转移)&lt;/p>
&lt;p>一个 sentinel 发现 master 离线，争取 sentinel 集群大多数节点认可，认可成功则确认该 master 离线，开始故障转移。&lt;/p>
&lt;p>选出一个 slave 服务器，将其升级为 master&lt;/p>
&lt;p>向被选中的从服务器发送 REPLICAOF NO ONE 命令，让它变为主服务器。&lt;/p>
&lt;p>通过发布与订阅功能，将更新后的配置推送给其他 Sentinel。&lt;/p>
&lt;p>向已下线主服务器的从服务器发送 REPLICAOF host port 命令， 让它们去复制新的主服务器。&lt;/p>
&lt;p>所有 Sentinel 发送 sentinel flushconfig 命令刷新配置文件。所有 Redis master 和 replica 节点发送 config rewrite 命令刷新配置文件&lt;/p>
&lt;ul>
&lt;li>Configuration propagation(配置传播)。参考：&lt;a href="https://redis.io/topics/sentinel#configuration-propagation">官方文档&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>当所有从服务器都已经开始复制新的主服务器时， 领头 Sentinel 终止这次故障迁移操作。&lt;/p>
&lt;h1 id="哨兵模式的优缺点">哨兵模式的优缺点&lt;/h1>
&lt;p>优点：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>哨兵模式基于主从复制模式，所以主从复制模式有的优点，哨兵模式也有&lt;/p>
&lt;/li>
&lt;li>
&lt;p>哨兵模式下，master 挂掉可以自动进行切换，系统可用性更高&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>缺点：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>同样也继承了主从模式难以在线扩容的缺点，Redis 的容量受限于单机配置&lt;/p>
&lt;/li>
&lt;li>
&lt;p>需要额外的资源来启动 sentinel 进程，实现相对复杂一点，同时 slave 节点作为备份节点不提供服务&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Docs: 4.2.Sentinel 配置详解</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/4.2.sentinel-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E9%AB%98%E5%8F%AF%E7%94%A8/4.2.sentinel-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;p>参考：&lt;a href="https://redis.io/topics/sentinel#other-sentinel-options">官方文档 1&lt;/a>、&lt;/p>
&lt;p>Sentinel 的配置与 Redis 配置用法相同，当使用 &amp;ndash;sentinel 参数启动 redis 时，则 redis 程序加载配置文件时，将只会特定的配置信息&lt;/p>
&lt;h1 id="sentinel-配置环境">Sentinel 配置环境&lt;/h1>
&lt;h2 id="port-int--sentinel-监听的端口sentinel-之间使用该端口通讯">**port &lt;!-- raw HTML omitted --> **# Sentinel 监听的端口，Sentinel 之间使用该端口通讯&lt;/h2>
&lt;h2 id="sentinel-monitor-master-group-name-ip-port-quorum--指定-sentinel-要监听的-master">sentinel monitor &lt;!-- raw HTML omitted --> &lt;!-- raw HTML omitted --> &lt;!-- raw HTML omitted --> &lt;!-- raw HTML omitted --> # 指定 Sentinel 要监听的 MASTER&lt;/h2>
&lt;p>&lt;code>sentinel montior mymaster 192.168.50.101 6379 1&lt;/code> 这个配置意味着，Sentinel 监控的目标 master 节点的 IP 为 192.168.50.101、端口为 6379，最后一个数字表示投票需要的&amp;quot;最少法定人数&amp;quot;。&lt;/p>
&lt;blockquote>
&lt;p>最少法定人数的理解：比如有 10 个 sentinal 哨兵都在监控某一个 master 节点，如果需要至少 6 个哨兵发现 master 挂掉后，才认为 master 真正 down 掉，那么这里就配置为 6，最小配置 1 台 master，1 台 slave，在二个机器上都启动 sentinal 的情况下，哨兵数只有 2 个，如果一台机器物理挂掉，只剩一个 sentinal 能发现该问题，所以这里配置成 1。&lt;/p>
&lt;/blockquote>
&lt;p>至于 mymaster 只是一个名字，可以随便起，但要保证下面使用同一个名字&lt;/p>
&lt;h2 id="sentinel-down-after-milliseconds-target-duration--监控目标的-sdown-等待时长单位毫秒">sentinel down-after-milliseconds &lt;!-- raw HTML omitted --> &lt;!-- raw HTML omitted --> # 监控目标的 SDOWN 等待时长。单位：毫秒&lt;/h2>
&lt;p>持续 DURATION 时间 TARGET 没响应，就认为 SDOWN。&lt;/p>
&lt;h2 id="sentinel-parallel-syncs-target-int--与监控目标并行同步数据的节点数">sentinel parallel-syncs &lt;!-- raw HTML omitted --> &lt;!-- raw HTML omitted --> # 与监控目标并行同步数据的节点数&lt;/h2>
&lt;p>如果 master 重新选出来后，其它 replica 节点能同时并行从新 master 同步缓存的节点数有多少个。该值越大，所有 replica 节点完成同步切换的整体速度越快，但如果此时正好有人在访问这些 replica，可能造成读取失败，影响面会更广。最保定的设置为 1，只同一时间，只能有一台干这件事，这样其它 replica 还能继续服务，但是所有 replica 全部完成缓存更新同步的进程将变慢。&lt;/p>
&lt;h2 id="sentinel-failover-timeout-mymaster-duration--故障恢复超时时长单位毫秒">sentinel failover-timeout mymaster &lt;!-- raw HTML omitted --> # 故障恢复超时时长。单位：毫秒&lt;/h2>
&lt;p>在指定时间 DURATION 后，故障恢复如果没有成功，则再次进行 Failover 操作&lt;/p>
&lt;h1 id="配置示例">配置示例&lt;/h1>
&lt;pre>&lt;code>#
sentinel monitor mymaster 172.19.42.231 6379 2
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1
&lt;/code>&lt;/pre></description></item><item><title>Docs: API</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/api/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;h1 id="ceph-restful-api">Ceph RESTful API&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.ceph.com/en/latest/mgr/ceph_api/">官方文档，Ceph 管理器守护进程-Ceph RESTful API&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/ceph/ceph/blob/master/src/pybind/mgr/dashboard/openapi.yaml">GitHub，ceph/ceph/src/pybind/mgr/dashboard/openapi.yaml&lt;/a>(该 API 的 openapi 文件)&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>在 Dashboard 模块中，提供了一组用于管理集群的 RESTful 风格的 API 接口。这组 API 默认位于 &lt;code>https://localhost:8443/api&lt;/code> 路径下&lt;/p>
&lt;p>在 &lt;code>/docs&lt;/code> 端点下，可以查看 OpenAPI 格式的信息
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/fl1wmh/1630938180924-97cb2959-3cf0-48bf-b312-57be88e9471d.png" alt="image.png">
在 &lt;code>/dpcs/api.json&lt;/code> 端点可以获取 openapi 格式的 API 信息。&lt;/p>
&lt;h2 id="apiauth">/api/auth&lt;/h2>
&lt;p>&lt;code>/api/auth&lt;/code> 接口获取 Token&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl -X POST &lt;span style="color:#e6db74">&amp;#34;https://example.com:8443/api/auth&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -H &lt;span style="color:#e6db74">&amp;#34;Accept: application/vnd.ceph.api.v1.0+json&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -H &lt;span style="color:#e6db74">&amp;#34;Content-Type: application/json&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -d &lt;span style="color:#e6db74">&amp;#39;{&amp;#34;username&amp;#34;: &amp;lt;username&amp;gt;, &amp;#34;password&amp;#34;: &amp;lt;password&amp;gt;}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>获取 Token 后，其他接口，都可以使用该 Token 进行认证，比如：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl -H &lt;span style="color:#e6db74">&amp;#34;Authorization: Bearer &lt;/span>$TOKEN&lt;span style="color:#e6db74">&amp;#34;&lt;/span> ......
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="apiauthcheck">/api/auth/check&lt;/h2>
&lt;p>&lt;code>/api/auth/check&lt;/code> 接口可以检查 Token。通常还可以作为对 API 的健康检查接口。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl -k -XPOST &lt;span style="color:#e6db74">&amp;#39;https://example.com:8443/api/auth/check&amp;#39;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -H &lt;span style="color:#e6db74">&amp;#39;accept: */*&amp;#39;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -H &lt;span style="color:#e6db74">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -d &lt;span style="color:#e6db74">&amp;#34;{\&amp;#34;token\&amp;#34;: \&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>TOKEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">\&amp;#34;}&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Ceph</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://ceph.io/">官网&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.ceph.com/en/latest/">官方文档&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Ceph_(software)">Wiki,Ceph&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.csdn.net/younger_china/article/details/73410727">https://blog.csdn.net/younger_china/article/details/73410727&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Ceph 是一个开源的分布式存储系统，可以提供 对象存储、快存储、文件存储 能力。是一个 Software Defined Storage(软件定义存储) 的代表性产品。&lt;/p>
&lt;p>一个 Ceph 存储集群至少需要 Ceph Monitor、Ceph Manager、Ceph OSD 这三个组件；如果要运行 Ceph 文件系统客户端，则也需要 Ceph MDS。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Monitor&lt;/strong> # &lt;strong>Ceph Monitor(Ceph 监视器，简称 ceph-mon)&lt;/strong> 负责维护集群状态的映射关系。通常至少需要 3 个 ceph-mon 以实现高可用，多节点使用 Paxos 算法达成共识。
&lt;ul>
&lt;li>可以这么说，Ceph 集群就是指 ceph-mon 集群。ceph-mon 负责维护的集群状态，就是用来提供存储服务的。&lt;/li>
&lt;li>ceph-mon 映射、ceph-mgr 映射、ceph-osd 映射、ceph-mds 映射、ceph-crush 映射。这些映射是 Ceph 守护进程相互协调所需的关键集群状态，说白了，就是&lt;strong>映射关系&lt;/strong>。
&lt;ul>
&lt;li>这里的映射，英文用的是 Map，其实也有地图的意思，就是表示这个集群有多少个 ceph-mon、有多少个 ceph-mgr 等等，还有底层对象属于哪个 PG，等等等等，这些东西构成了一副 Ceph 的运行图。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ceph-mon 还负责管理守护进程和客户端之间的身份验证。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>**Manager **# &lt;strong>Ceph Manager(Ceph 管理器，简称 ceph-mgr)&lt;/strong> 负责跟踪运行时指标和 Ceph 集群的当前状态，包括存储利用率、性能、系统负载等。通常至少需要 2 个 ceph-mgr 以实现高可用。
&lt;ul>
&lt;li>ceph-mgr 可以提供 Web 管理页面、关于 Ceph 集群的 Prometheus 格式的监控指标&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>**OSD Daemon **# &lt;strong>Ceph OSD Daemon(Ceph OSD 守护进程，简称 ceph-osd)&lt;/strong> 负责向 OSD 读写数据、处理数据复制、恢复、重新平衡，并通过检查其他 ceph-osd 的心跳向 ceph-mon 和 ceph-mgr 提供一些监控信息。通常至少需要 3 个 ceph-osd 以实现高科用。
&lt;ul>
&lt;li>&lt;strong>Object Storage Device(对象存储设备，简称 OSD)&lt;/strong> 是一个物理或逻辑上的存储单元(比如一块硬盘)，这是 Ceph 得以运行的最基本的存储单元。
&lt;ul>
&lt;li>有的时候，人们容易把 OSD 理解为 Ceph OSD Daemon，这俩是有本质区别的。因为在最早的时候，OSD 有两种含义，一种是 &lt;code>Object Storage Device&lt;/code> 另一种是 &lt;code>Object Storage Daemon&lt;/code>。由于这种称呼的模糊性，后来就将 Object Storage daemon 扩展为 OSD Daemon。OSD 则仅仅代表 Object Storage Device。只不过运行 OSD Daemon 的程序名称，依然沿用了 osd 的名字。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>注意，为了让每一个 OSD 都可以被单独使用并管理，所以每个 OSD 都有一个对应的 ceph-osd 进程来管理。一般情况，Ceph 集群中每个节点，除了系统盘做 Raid 以外，其他硬盘都会单独作为 OSD 使用，且一个节点会有大量磁盘来对应 OSD。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>**MDS **# &lt;strong>Ceph Metadata Server(Ceph 元数据服务器，简称 ceph-mds)&lt;/strong> 代表 Ceph 文件系统元数据。ceph-mds 允许 POSIX 文件系统用户执行基本命令(比如 ls、find 等)，而不会给 Ceph 集群带来巨大负担。
&lt;ul>
&lt;li>注意，Ceph 提供的 块存储 和 对象存储 功能并不使用 ceph-mds。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="架构httpsdocscephcomenlatestarchitecture">&lt;a href="https://docs.ceph.com/en/latest/architecture/">架构&lt;/a>&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sakrws/1630769971104-82bcc0c6-1dbd-4c47-b986-3e5b8321aac0.png" alt="image.png">
&lt;strong>其实 Ceph 本身就是一个对象存储&lt;/strong>，基于&lt;strong>RADOS&lt;/strong> 实现，并通过 Ceph Client 为上层应用提供了通用的 块存储、文件存储、对象存储 的调用接口。&lt;/p>
&lt;ul>
&lt;li>**RADOS **# **Reliable Autonomic Distributed Object Store(可靠的、自动化的分布式对象存储，简称 RADOS) **是一种由多个主机组成、由 CRUSH 算法实现数据路由的，分布式对象存储系统。是 Ceph 的底层存储系统。
&lt;ul>
&lt;li>OSD 是组成 RADOS 的基本存储单元。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Ceph Client&lt;/strong> # &lt;strong>Ceph 客户端&lt;/strong>。是可以访问 Ceph 存储集群(即 RADOS) 的 Ceph 组件的集合。
&lt;ul>
&lt;li>**LIBRADOS **# **Library RADOS(RADOS 库，简称 librados)。**应用程序可以调用 librados 以直接访问 RADOS。当我们使用 Ceph 时，Ceph 实际上是调用 librados 的 API(这是一个 rpc 接口)，将提交的文件切分为固定大小的数据，存放到 RADOS 中。
&lt;ul>
&lt;li>同时，我们自己也可以使用 librados 开发出类似 ceph-rgw、ceph-rbd 这种应用程序以实现个性化需求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>**RADOSGW **# &lt;strong>RADOS Gateway(RADOS 网关，简称 radosgw)&lt;/strong>。使用 librados 实现的应用程序，可以提供兼容 S3 和 Swift 对象存储的接口&lt;/li>
&lt;li>**RBD **# &lt;strong>RADOS Block Device(RADOS 块设备，简称 RBD)&lt;/strong>。使用 librados 实现的应用程序，为 Linux 内核 和 QEMU/KVM 提供一个可靠且完全分布式的块存储设备。&lt;/li>
&lt;li>&lt;strong>CEPH FS&lt;/strong> # &lt;strong>Ceph File System(Ceph 文件系统，简称 CFS)&lt;/strong>。直接使用 RADOS 实现一个符合 POSIX 的分布式文件系统，带有 Linux 内核客户端并支持 FUSE，可以直接挂载使用。甚至可以进一步抽象，实现 NFS 功能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="ceph-数据写入流程">Ceph 数据写入流程&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sakrws/1630834243384-b650e1e5-1c84-4846-bdc5-9180a361fb09.png" alt="image.png">
Ceph 集群从 Ceph 的客户端接收到的数据后，将会切分为一个或多个固定大小的 &lt;strong>RADOS Object(RADOS 对象)&lt;/strong>。Ceph 使用 **Controlled Replication Under Scalable Hashing(简称 CRUSH) **算法计算出 RADOS 对象应该放在哪个 &lt;strong>Placement Group(归置组，简称 PG)&lt;/strong>，并进一步计算出，应该由哪个 ceph-osd 来处理这个 PG 并将 PG 存储到指定的 OSD 中。ceph-osd 会通过存储驱动器处理 RADOS 对象的 读、写 和 复制操作。&lt;/p>
&lt;blockquote>
&lt;p>注意：当创建完 Ceph 集群后，会有一个默认的 Pool，Pool 是用来对 PG 进行分组的，且 PG 必须属于一个组，不可独立存在。&lt;/p>
&lt;/blockquote>
&lt;p>RADOS 对象有如下几个部分组成&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Object Identify(对象标识符，简称 OID)&lt;/strong> # OID 在整个 Ceph 集群中是唯一。&lt;/li>
&lt;li>&lt;strong>Binary Data(二进制数据数据)&lt;/strong> # 对象的数据&lt;/li>
&lt;li>&lt;strong>Metadata(元数据)&lt;/strong> # 元数据的语义完全取决于 Ceph 客户端。例如，CephFS 使用元数据来存储文件属性，如文件所有者、创建日期、上次修改日期等。&lt;/li>
&lt;/ul>
&lt;p>ceph-osd 将数据作为对象存储在平坦的命名空间中 (例如，没有目录层次结构)。对象具有标识符，二进制数据和由一组名称/值对组成的元数据。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sakrws/1630808425695-75766062-7570-47f0-9ae4-916c7819d113.png" alt="image.png">&lt;/p>
&lt;h1 id="rados">RADOS&lt;/h1>
&lt;p>与传统分布式存储不同，传统分布式存储中的 NameNode 极易形成性能瓶颈。基于此，RADOS 设计了一种新的方式来快速找到对象数据。RADOS 中并不需要 NameNode 来存储每个对象的元数据，RADOS 中的对象，都是通过 **Controlled Replication Under Scalable Hashing(简称 CRUSH) **算法来快速定位的。&lt;/p>
&lt;h2 id="bluestore">bluestore&lt;/h2>
&lt;p>这是 Ceph 所管理的 OSD 的文件系统类型&lt;/p>
&lt;h1 id="ceph-的存储能力">Ceph 的存储能力&lt;/h1>
&lt;h2 id="块存储">块存储&lt;/h2>
&lt;p>Ceph 通过 RDB 提供块存储能力&lt;/p>
&lt;h2 id="文件存储">文件存储&lt;/h2>
&lt;p>Ceph 通过 CEPHFS 提供文件存储能力&lt;/p>
&lt;h2 id="对象存储">对象存储&lt;/h2>
&lt;p>RADOS Gateway 简称 radosgw，Ceph 通过 radosgw 程序，可以对外提供标准的 S3 或 swift 接口，以实现主流对象存储功能。很多时候，radosgw 程序运行的进程称为 ceph-rgw&lt;/p>
&lt;h1 id="ceph-manager">Ceph Manager&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.ceph.com/en/latest/mgr/">官方文档,Ceph 管理器&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Ceph Manager 是通过一个名为 ceph-mgr 的二进制程序以守护进程运行的管理器。ceph-mgr 可以向外部监控和管理系统提供额外的监控和接口。&lt;/p>
&lt;p>ceph-mgr 曾经是 ceph-mon 的一部分，自 luinous(12.x) 版本依赖，ceph-mgr 独立出来，成为 Ceph 集群的必选组件。&lt;/p>
&lt;h2 id="dashboard-模块">Dashboard 模块&lt;/h2>
&lt;p>Dashboard 模块是一个内置的基于 Web 的 Ceph 管理和监控程序，通过它可以检查和管理 Ceph 集群中的各个方面和资源。默认监听 &lt;code>8443&lt;/code> 端口&lt;/p>
&lt;p>在 Dashboard 模块中，提供了一组用于管理集群的 RESTful 风格的 API 接口。这组 API 位于 &lt;code>/api&lt;/code> 路径下。详见《[API](&amp;lt;✏IT 学习笔记/📼5.数据存储/1.存储/存储的基础设施架构/Distributed%20Storage(分布式存储)/Ceph/API.md&amp;raquo;)》章节&lt;/p>
&lt;h3 id="heading">&lt;/h3>
&lt;h2 id="prometheus-模块">Prometheus 模块&lt;/h2>
&lt;p>启动 Prometheus 模块后，ceph-mgr 默认在 &lt;code>9283&lt;/code> 端口上暴露 Prometheus 格式的监控指标。&lt;/p>
&lt;h1 id="ceph-radosgw">Ceph RADOSGW&lt;/h1>
&lt;p>默认监听 &lt;code>7480&lt;/code> 端口&lt;/p></description></item><item><title>Docs: Ceph 部署</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/ceph-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/ceph-%E9%83%A8%E7%BD%B2/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.ceph.com/en/latest/cephadm/">官方文档, Cephadm&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="以-pacific-版本为例">以 pacific 版本为例&lt;/h1>
&lt;h2 id="安装-cephadm">安装 cephadm&lt;/h2>
&lt;p>在所有节点安装 cephadm，这是一个 python 程序，当通过第一个节点让其他节点加入集群时，会调用待加入节点中的 cephadm 程序。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl --silent --remote-name --location https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chmod +x cephadm
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./cephadm add-repo --release pacific
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./cephadm install
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cephadm install ceph-common
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="引导第一个节点">引导第一个节点&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cephadm bootstrap --mon-ip 192.168.1.201
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="配置-ceph-cli">配置 ceph CLI&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cephadm install ceph-common
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="其他">其他&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 开启遥测，发送数据给官方&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph telemetry on
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="添加其他节点">添加其他节点&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 添加认证信息&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ssh-copy-id -f -i /etc/ceph/ceph.pub root@192.168.1.202
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ssh-copy-id -f -i /etc/ceph/ceph.pub root@192.168.1.203
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 添加节点&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch host add hw-cloud-xngy-ecs-test-0002 192.168.1.202
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch host add hw-cloud-xngy-ecs-test-0003 192.168.1.203
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 为节点添加 _admin 标签&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch host label add hw-cloud-xngy-ecs-test-0002 _admin
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch host label add hw-cloud-xngy-ecs-test-0003 _admin
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>节点添加完成后，在 1 和 2 上活动 ceph-mgr，1，2，3 上启动了 ceph-mon 和 ceph-crash&lt;/p>
&lt;h2 id="添加存储设备">添加存储设备&lt;/h2>
&lt;p>注意：如下所示，当一块磁盘具有 GPT 分区表时，是无法作为 Ceph 的 OSD 使用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0001:~# ceph orch device ls --wide
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Hostname Path Type Transport RPM Vendor Model Serial Size Health Ident Fault Available Reject Reasons
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hw-cloud-xngy-ecs-test-0001 /dev/vdb hdd Unknown Unknown 0x1af4 N/A 4afb2ab1-9244-45bf-a 107G Unknown N/A N/A No Has GPT headers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hw-cloud-xngy-ecs-test-0002 /dev/vdb hdd Unknown Unknown 0x1af4 N/A 74321443-d05c-4803-9 107G Unknown N/A N/A No Has GPT headers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hw-cloud-xngy-ecs-test-0003 /dev/vdb hdd Unknown Unknown 0x1af4 N/A f9c0ddbb-7ede-4958-8 107G Unknown N/A N/A No Has GPT headers
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行命令 &lt;code>parted /dev/vdb mklabel msdos&lt;/code> 删除 GPT 分区表，即可。也可以使用 &lt;code>sgdisk&lt;/code> 命令进行磁盘清理。&lt;/p>
&lt;p>清理完成后，开始在所有节点上添加 OSD&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ceph orch apply osd --all-available-devices
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="基本部署完成">基本部署完成&lt;/h2>
&lt;p>组成了一个三节点的 Ceph 集群效果如下：
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sx1zt0/1630850693982-c0ecf1f3-1f37-4f61-8b7c-84c1447ac04f.png" alt="image.png">
Ceph 集群中，除了监控套件以外，有 3 个 ceph-mon、2 个 ceph-mgr、3 个 ceph-crash、6 个 ceph-osd。从服务角度看，当前有三个服务：mon、mgr、osd，使用 &lt;code>ceph -s&lt;/code> 命令查看：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0001:~# ceph -s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> id: 24750534-0e45-11ec-9849-7bf16e3e2cb9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> health: HEALTH_OK
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> services:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mon: &lt;span style="color:#ae81ff">3&lt;/span> daemons, quorum hw-cloud-xngy-ecs-test-0001,hw-cloud-xngy-ecs-test-0002,hw-cloud-xngy-ecs-test-0003 &lt;span style="color:#f92672">(&lt;/span>age 10h&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mgr: hw-cloud-xngy-ecs-test-0001.afnavu&lt;span style="color:#f92672">(&lt;/span>active, since 10h&lt;span style="color:#f92672">)&lt;/span>, standbys: hw-cloud-xngy-ecs-test-0002.jucqwq
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> osd: &lt;span style="color:#ae81ff">6&lt;/span> osds: &lt;span style="color:#ae81ff">6&lt;/span> up &lt;span style="color:#f92672">(&lt;/span>since 10h&lt;span style="color:#f92672">)&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span> in &lt;span style="color:#f92672">(&lt;/span>since 10h&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pools: &lt;span style="color:#ae81ff">7&lt;/span> pools, &lt;span style="color:#ae81ff">145&lt;/span> pgs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> objects: &lt;span style="color:#ae81ff">253&lt;/span> objects, &lt;span style="color:#ae81ff">10&lt;/span> KiB
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> usage: &lt;span style="color:#ae81ff">343&lt;/span> MiB used, &lt;span style="color:#ae81ff">600&lt;/span> GiB / &lt;span style="color:#ae81ff">600&lt;/span> GiB avail
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pgs: &lt;span style="color:#ae81ff">145&lt;/span> active+clean
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="添加-rgw-服务">添加 RGW 服务&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 为集群中两个节点添加标签，以准备后续将 radosgw 部署到具有 rgw 标签的节点上&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch host label add hw-cloud-xngy-ecs-test-0001 rgw
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch host label add hw-cloud-xngy-ecs-test-0001 rgw
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 部署 rgw&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch apply rgw foo &lt;span style="color:#e6db74">&amp;#39;--placement=label:rgw count-per-host:2&amp;#39;&lt;/span> --port&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8000&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时，节点 1 和节点 2 上，每个节点都有运行有两个 ceph-rgw 实例，可以对外提供服务&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0001:~# docker ps -a | grep rgw
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>9ad5fe363abd ceph/ceph &lt;span style="color:#e6db74">&amp;#34;/usr/bin/radosgw -n…&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">24&lt;/span> seconds ago Up &lt;span style="color:#ae81ff">24&lt;/span> seconds ceph-24750534-0e45-11ec-9849-7bf16e3e2cb9-rgw.foo.hw-cloud-xngy-ecs-test-0001.rqcvxl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>519d6a07f001 ceph/ceph &lt;span style="color:#e6db74">&amp;#34;/usr/bin/radosgw -n…&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">26&lt;/span> seconds ago Up &lt;span style="color:#ae81ff">26&lt;/span> seconds ceph-24750534-0e45-11ec-9849-7bf16e3e2cb9-rgw.foo.hw-cloud-xngy-ecs-test-0001.hsjpqq
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0001:~# ss -ntlp | grep gw
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> 0.0.0.0:8000 0.0.0.0:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>16598,fd&lt;span style="color:#f92672">=&lt;/span>57&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> 0.0.0.0:8001 0.0.0.0:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>17447,fd&lt;span style="color:#f92672">=&lt;/span>57&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:8000 &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>16598,fd&lt;span style="color:#f92672">=&lt;/span>58&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:8001 &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>17447,fd&lt;span style="color:#f92672">=&lt;/span>58&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0002:~# docker ps -a | grep rgw
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>1ab21ec662de ceph/ceph &lt;span style="color:#e6db74">&amp;#34;/usr/bin/radosgw -n…&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">23&lt;/span> seconds ago Up &lt;span style="color:#ae81ff">23&lt;/span> seconds ceph-24750534-0e45-11ec-9849-7bf16e3e2cb9-rgw.foo.hw-cloud-xngy-ecs-test-0002.zsrkkp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>10ad804e541d ceph/ceph &lt;span style="color:#e6db74">&amp;#34;/usr/bin/radosgw -n…&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">25&lt;/span> seconds ago Up &lt;span style="color:#ae81ff">25&lt;/span> seconds ceph-24750534-0e45-11ec-9849-7bf16e3e2cb9-rgw.foo.hw-cloud-xngy-ecs-test-0002.giyyjf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0002:~# ss -ntlp | grep gw
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> 0.0.0.0:8000 0.0.0.0:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>14294,fd&lt;span style="color:#f92672">=&lt;/span>57&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> 0.0.0.0:8001 0.0.0.0:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>15152,fd&lt;span style="color:#f92672">=&lt;/span>57&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:8000 &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>14294,fd&lt;span style="color:#f92672">=&lt;/span>58&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LISTEN &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span> &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:8001 &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:* users:&lt;span style="color:#f92672">((&lt;/span>&lt;span style="color:#e6db74">&amp;#34;radosgw&amp;#34;&lt;/span>,pid&lt;span style="color:#f92672">=&lt;/span>15152,fd&lt;span style="color:#f92672">=&lt;/span>58&lt;span style="color:#f92672">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>当访问这些端口时，显示如下内容，则说明已经可以提供 S3 服务了&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0001:~# curl 192.168.1.201:8000
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;?xml version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;1.0&amp;#34;&lt;/span> encoding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;UTF-8&amp;#34;&lt;/span>?&amp;gt;&amp;lt;ListAllMyBucketsResult xmlns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;http://s3.amazonaws.com/doc/2006-03-01/&amp;#34;&lt;/span>&amp;gt;&amp;lt;Owner&amp;gt;&amp;lt;ID&amp;gt;anonymous&amp;lt;/ID&amp;gt;&amp;lt;DisplayName&amp;gt;&amp;lt;/DisplayName&amp;gt;&amp;lt;/Owner&amp;gt;&amp;lt;Buckets&amp;gt;&amp;lt;/Buckets&amp;gt;&amp;lt;/ListAllMyBucketsResult&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>创建一个系统用户并记录下 ak 与 sk。通过这个用户的信息，可以使用 blemmenes/radosgw_usage_exporter 导出对象存储监控指标&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>root@hw-cloud-xngy-ecs-test-0001:~# radosgw-admin user create --uid&lt;span style="color:#f92672">=&lt;/span>lichenhao --display-name&lt;span style="color:#f92672">=&lt;/span>lichenhao --system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;user_id&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;lichenhao&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;display_name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;lichenhao&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;keys&amp;#34;&lt;/span>: &lt;span style="color:#f92672">[&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;user&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;lichenhao&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;access_key&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;4O23LGQI3UAUKSSO50UK&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;secret_key&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;JQLul4q2r2qo1vyOLpQ4FVUnh3LWfiNyuiZHQDT6&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">]&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;a href="https://docs.ceph.com/en/pacific/mgr/dashboard/#enabling-the-object-gateway-management-frontend">启动对象网关的管理前端&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>radosgw-admin user info --uid&lt;span style="color:#f92672">=&lt;/span>lichenhao | jq .keys&lt;span style="color:#f92672">[&lt;/span>0&lt;span style="color:#f92672">]&lt;/span>.access_key &amp;gt; ak
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>radosgw-admin user info --uid&lt;span style="color:#f92672">=&lt;/span>lichenhao | jq .keys&lt;span style="color:#f92672">[&lt;/span>0&lt;span style="color:#f92672">]&lt;/span>.secret_key &amp;gt; sk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph dashboard set-rgw-api-access-key -i ak
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph dashboard set-rgw-api-secret-key -i sk
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时从 Ceph 的 Web 页面中，可以从 Object Gateway 标签中看到内容了：
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sx1zt0/1630856235488-d2d2e334-a0a9-4d41-aa17-06522f30d11a.png" alt="image.png">
使用 192.168.1.202:8000 作为 Endpoint，以及 lichenhao 用户的 ak、sk，可以通过 S3 Brower 访问 Ceph 提供的对象存储。注意：由于此时没有开启 SSL，所以 S3 Brower 也要关闭 SSL。&lt;/p>
&lt;h2 id="添加监控服务可选">添加监控服务(可选)&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ceph orch apply node-exporter
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch apply alertmanager
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch apply prometheus
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ceph orch apply grafana
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sx1zt0/1630835511543-fb85907a-97d5-4f99-80d5-2214a0236810.png" alt="image.png">&lt;/p>
&lt;h1 id="其他-1">其他&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run --rm --network host --name ceph-rgw-exporter &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>blemmenes/radosgw_usage_exporter:latest &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-H 172.38.30.2:7480 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-a F52JL32RD8NWI78XT3A9 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-s jjs3uAIGJYFMyprkHov6D85D1YGSo0HowisHZmJl &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-p &lt;span style="color:#ae81ff">9243&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run --rm --network host --name ceph-rgw-exporter &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>blemmenes/radosgw_usage_exporter:latest &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-H 192.168.1.202:8000 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-a 4O23LGQI3UAUKSSO50UK &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-s JQLul4q2r2qo1vyOLpQ4FVUnh3LWfiNyuiZHQDT6 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-p &lt;span style="color:#ae81ff">9243&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>异常
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sx1zt0/1630750629528-40ac128e-4c7c-4ccf-9aa4-d64741aae089.png" alt="image.png">
正常
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/sx1zt0/1630835261055-137daaea-90de-4045-a62f-5a0e28077860.png" alt="image.png">&lt;/p></description></item><item><title>Docs: Ceph 故障排查笔记</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/ceph-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E7%AC%94%E8%AE%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/ceph-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E7%AC%94%E8%AE%B0/</guid><description>
&lt;p>参考：&lt;a href="https://mp.weixin.qq.com/s/k5-gkm78KXmty7F2qerZ6g">公众号,云原声实验室-Ceph 故障排查笔记 | 万字经验总结&lt;/a>&lt;/p>
&lt;h3 id="ceph-osd-异常无法正常启动">Ceph OSD 异常无法正常启动&lt;/h3>
&lt;p>当某个 OSD 无法正常启动时：&lt;/p>
&lt;pre>&lt;code>$ ceph -s
cluster:
id: b313ec26-5aa0-4db2-9fb5-a38b207471ee
health: HEALTH_WARN
Degraded data redundancy: 177597/532791 objects degraded (33.333%), 212 pgs degraded, 212 pgs undersized
application not enabled on 3 pool(s)
mon master003 is low on available space
1/3 mons down, quorum master002,master003
services:
mon: 3 daemons, quorum master002,master003, out of quorum: master001
mgr: master003(active), standbys: master002
mds: kubernetes-1/1/1 up {0=master002=up:active}, 1 up:standby
osd: 2 osds: 2 up, 2 in
data:
pools: 5 pools, 212 pgs
objects: 177.6 k objects, 141 GiB
usage: 297 GiB used, 2.8 TiB / 3.0 TiB avail
pgs: 177597/532791 objects degraded (33.333%)
212 active+undersized+degraded
io:
client: 170 B/s rd, 127 KiB/s wr, 0 op/s rd, 5 op/s wr
&lt;/code>&lt;/pre>
&lt;p>查看状态信息：&lt;/p>
&lt;pre>&lt;code>$ ceph health detail
HEALTH_WARN Degraded data redundancy: 177615/532845 objects degraded (33.333%), 212 pgs degraded, 212 pgs undersized; application not enabled on 3 pool(s); mon master003 is low on available space
PG_DEGRADED Degraded data redundancy: 177615/532845 objects degraded (33.333%), 212 pgs degraded, 212 pgs undersized
pg 1.15 is active+undersized+degraded, acting [1,2]
pg 1.2e is stuck undersized for 12701595.129535, current state active+undersized+degraded, last acting [1,2]
pg 1.2f is stuck undersized for 12701595.110228, current state active+undersized+degraded, last acting [2,1]
pg 1.30 is stuck undersized for 12701595.128371, current state active+undersized+degraded, last acting [1,2]
pg 1.31 is stuck undersized for 12701595.129981, current state active+undersized+degraded, last acting [1,2]
pg 1.32 is stuck undersized for 12701595.122298, current state active+undersized+degraded, last acting [2,1]
pg 1.33 is stuck undersized for 12701595.129509, current state active+undersized+degraded, last acting [2,1]
pg 1.34 is stuck undersized for 12701595.116494, current state active+undersized+degraded, last acting [2,1]
pg 1.35 is stuck undersized for 12701595.132276, current state active+undersized+degraded, last acting [2,1]
pg 1.36 is stuck undersized for 12701595.131601, current state active+undersized+degraded, last acting [1,2]
pg 1.37 is stuck undersized for 12701595.126213, current state active+undersized+degraded, last acting [1,2]
pg 1.38 is stuck undersized for 12701595.119082, current state active+undersized+degraded, last acting [2,1]
pg 1.39 is stuck undersized for 12701595.127812, current state active+undersized+degraded, last acting [1,2]
pg 1.3a is stuck undersized for 12701595.117611, current state active+undersized+degraded, last acting [2,1]
pg 1.3b is stuck undersized for 12701595.125454, current state active+undersized+degraded, last acting [2,1]
pg 1.3c is stuck undersized for 12701595.131540, current state active+undersized+degraded, last acting [1,2]
pg 1.3d is stuck undersized for 12701595.130465, current state active+undersized+degraded, last acting [1,2]
pg 1.3e is stuck undersized for 12701595.120532, current state active+undersized+degraded, last acting [2,1]
pg 1.3f is stuck undersized for 12701595.129921, current state active+undersized+degraded, last acting [1,2]
pg 1.40 is stuck undersized for 12701595.115146, current state active+undersized+degraded, last acting [2,1]
pg 1.41 is stuck undersized for 12701595.132582, current state active+undersized+degraded, last acting [1,2]
pg 1.42 is stuck undersized for 12701595.122272, current state active+undersized+degraded, last acting [2,1]
pg 1.43 is stuck undersized for 12701595.132359, current state active+undersized+degraded, last acting [1,2]
pg 1.44 is stuck undersized for 12701595.129082, current state active+undersized+degraded, last acting [2,1]
pg 1.45 is stuck undersized for 12701595.118952, current state active+undersized+degraded, last acting [2,1]
pg 1.46 is stuck undersized for 12701595.129618, current state active+undersized+degraded, last acting [1,2]
pg 1.47 is stuck undersized for 12701595.112277, current state active+undersized+degraded, last acting [2,1]
pg 1.48 is stuck undersized for 12701595.131721, current state active+undersized+degraded, last acting [1,2]
pg 1.49 is stuck undersized for 12701595.130365, current state active+undersized+degraded, last acting [1,2]
pg 1.4a is stuck undersized for 12701595.126070, current state active+undersized+degraded, last acting [1,2]
pg 1.4b is stuck undersized for 12701595.113785, current state active+undersized+degraded, last acting [2,1]
pg 1.4c is stuck undersized for 12701595.129074, current state active+undersized+degraded, last acting [1,2]
pg 1.4d is stuck undersized for 12701595.115487, current state active+undersized+degraded, last acting [2,1]
pg 1.4e is stuck undersized for 12701595.131307, current state active+undersized+degraded, last acting [1,2]
pg 1.4f is stuck undersized for 12701595.132162, current state active+undersized+degraded, last acting [2,1]
pg 1.50 is stuck undersized for 12701595.129346, current state active+undersized+degraded, last acting [2,1]
pg 1.51 is stuck undersized for 12701595.131897, current state active+undersized+degraded, last acting [1,2]
pg 1.52 is stuck undersized for 12701595.126480, current state active+undersized+degraded, last acting [2,1]
pg 1.53 is stuck undersized for 12701595.116500, current state active+undersized+degraded, last acting [2,1]
pg 1.54 is stuck undersized for 12701595.122930, current state active+undersized+degraded, last acting [2,1]
pg 1.55 is stuck undersized for 12701595.116566, current state active+undersized+degraded, last acting [2,1]
pg 1.56 is stuck undersized for 12701595.130017, current state active+undersized+degraded, last acting [1,2]
pg 1.57 is stuck undersized for 12701595.129217, current state active+undersized+degraded, last acting [1,2]
pg 1.58 is stuck undersized for 12701595.124121, current state active+undersized+degraded, last acting [2,1]
pg 1.59 is stuck undersized for 12701595.127802, current state active+undersized+degraded, last acting [1,2]
pg 1.5a is stuck undersized for 12701595.131028, current state active+undersized+degraded, last acting [1,2]
pg 1.5b is stuck undersized for 12701595.114646, current state active+undersized+degraded, last acting [2,1]
pg 1.5c is stuck undersized for 12701595.109604, current state active+undersized+degraded, last acting [2,1]
pg 1.5d is stuck undersized for 12701595.126384, current state active+undersized+degraded, last acting [2,1]
pg 1.5e is stuck undersized for 12701595.129456, current state active+undersized+degraded, last acting [1,2]
pg 1.5f is stuck undersized for 12701595.126573, current state active+undersized+degraded, last acting [2,1]
POOL_APP_NOT_ENABLED application not enabled on 3 pool(s)
application not enabled on pool 'nextcloud'
application not enabled on pool 'gitlab-ops'
application not enabled on pool 'kafka-ops'
use 'ceph osd pool application enable &amp;lt;pool-name&amp;gt; &amp;lt;app-name&amp;gt;', where &amp;lt;app-name&amp;gt; is 'cephfs', 'rbd', 'rgw', or freeform for custom applications.
MON_DISK_LOW mon master003 is low on available space
mon.master003 has 22% avail
&lt;/code>&lt;/pre>
&lt;p>并且通过 log 也无法完全定位问题时，可以通过如下方式解决。&lt;/p>
&lt;h3 id="删除-osd-重新加载">删除 osd 重新加载&lt;/h3>
&lt;p>删除当前的 osd 重新让其进行加载，此方式适合于异常重启后的操作。
首先删除这个 osd：&lt;/p>
&lt;pre>&lt;code>$ ceph osd out osd.0
$ systemctl stop ceph-osd@0
$ ceph osd crush remove osd.0
$ ceph auth del osd.0
$ ceph osd rm 0
&lt;/code>&lt;/pre>
&lt;p>重新加载 osd：&lt;/p>
&lt;pre>&lt;code>$ ceph osd create 0
$ ceph auth add osd.0 osd 'allow *' mon 'allow rwx' -i /var/lib/ceph/osd/ceph-0/keyring
$ ceph osd crush add 0 1.0 host=master001
$ systemctl start ceph-osd@0
&lt;/code>&lt;/pre>
&lt;h3 id="清除当前-osd-所有数据重新添加">清除当前 osd 所有数据重新添加&lt;/h3>
&lt;p>删除当前 osd 的所有数据，并且重新加载 osd，此操作一定要保证有冗余可用的 osd，否则会造成整个 osd 数据损坏。
删除当前 osd：&lt;/p>
&lt;pre>&lt;code>$ ceph osd out osd.0
$ systemctl stop ceph-osd@0
$ ceph osd crush remove osd.0
$ ceph auth del osd.0
$ ceph osd rm 0
&lt;/code>&lt;/pre>
&lt;p>卸载：&lt;/p>
&lt;pre>&lt;code>$ umount -l /var/lib/ceph/osd/ceph-0
&lt;/code>&lt;/pre>
&lt;p>清空磁盘数据：&lt;/p>
&lt;pre>&lt;code>$ wipefs -af /dev/mapper/VolGroup-lv_data1
$ ceph-volume lvm zap /dev/mapper/VolGroup-lv_data1
&lt;/code>&lt;/pre>
&lt;p>重新添加 osd：&lt;/p>
&lt;pre>&lt;code>$ ceph-deploy --overwrite-conf osd create master001 --data /dev/mapper/VolGroup-lv_data1
&lt;/code>&lt;/pre>
&lt;h3 id="删除当前节点所有服务">删除当前节点所有服务&lt;/h3>
&lt;p>删除当前节点的所有服务，让其重新加载数据：&lt;/p>
&lt;pre>&lt;code>$ ceph-deploy purge master001
$ ceph-deploy purgedata master001
&lt;/code>&lt;/pre>
&lt;p>创建数据目录：&lt;/p>
&lt;pre>&lt;code>$ rm -rf /var/lib/ceph
$ mkdir -p /var/lib/ceph
$ mkdir -p /var/lib/ceph/osd/ceph-0
$ chown ceph:ceph /var/lib/ceph
&lt;/code>&lt;/pre>
&lt;p>然后安装 ceph：&lt;/p>
&lt;pre>&lt;code>$ ceph-deploy install master001
&lt;/code>&lt;/pre>
&lt;p>同步配置：&lt;/p>
&lt;pre>&lt;code>$ ceph-deploy --overwrite-conf admin master001
&lt;/code>&lt;/pre>
&lt;p>添加 osd：&lt;/p>
&lt;pre>&lt;code>$ ceph-deploy osd create master001 --data /dev/mapper/VolGroup-lv_data1
&lt;/code>&lt;/pre>
&lt;h3 id="查看当前系统-ceph-服务状态">查看当前系统 ceph 服务状态&lt;/h3>
&lt;p>查看当前系统 ceph 服务状态&lt;/p>
&lt;pre>&lt;code>$ systemctl list-units |grep ceph
&lt;/code>&lt;/pre>
&lt;h3 id="重启当前系统-ceph-服务">重启当前系统 ceph 服务&lt;/h3>
&lt;p>重启当前系统 ceph 服务&lt;/p>
&lt;pre>&lt;code>$ systemctl restart ceph*.service ceph*.target
&lt;/code>&lt;/pre>
&lt;h3 id="初始化-ceph-volume">初始化 ceph-volume&lt;/h3>
&lt;p>初始化 ceph-volume&lt;/p>
&lt;pre>&lt;code>$ ceph-volume lvm activate --bluestore --all
&lt;/code>&lt;/pre>
&lt;h3 id="修改-client-keyring-和修复">修改 Client keyring 和修复&lt;/h3>
&lt;p>修改 Client keyring 和修复，首先通过 ceph 命令进行查看：
然后把内容复制到：&lt;/p>
&lt;pre>&lt;code>$ cat /var/lib/ceph/osd/ceph-0/keyring
[osd.0]
key = AQCzhrpeLRK+MhAAbjAgSsE7O81Q+8h8OwA92A==
&lt;/code>&lt;/pre>
&lt;h3 id="pool-开启-enabled">Pool 开启 enabled&lt;/h3>
&lt;p>pool 的 enabled 开启：&lt;/p>
&lt;pre>&lt;code>$ ceph -s
cluster:
id: b313ec26-5aa0-4db2-9fb5-a38b207471ee
health: HEALTH_WARN
application not enabled on 3 pool(s)
$ ceph health detail
HEALTH_WARN application not enabled on 3 pool(s); mon master003 is low on available space
POOL_APP_NOT_ENABLED application not enabled on 3 pool(s)
application not enabled on pool 'nextcloud'
application not enabled on pool 'gitlab-ops'
application not enabled on pool 'kafka-ops'
use 'ceph osd pool application enable &amp;lt;pool-name&amp;gt; &amp;lt;app-name&amp;gt;', where &amp;lt;app-name&amp;gt; is 'cephfs', 'rbd', 'rgw', or freeform for custom applications.
MON_DISK_LOW mon master003 is low on available space
mon.master003 has 24% avail
&lt;/code>&lt;/pre>
&lt;p>执行 enabled：&lt;/p>
&lt;pre>&lt;code>$ ceph osd pool application enable nextcloud rbd
$ ceph osd pool application enable gitlab-ops rbd
$ ceph osd pool application enable kafka-ops rbd
&lt;/code>&lt;/pre>
&lt;h3 id="rbd-无法删除">Rbd 无法删除&lt;/h3>
&lt;p>rbd 无法删除，错误如下：&lt;/p>
&lt;pre>&lt;code>$ rbd rm nextcloud/mysql
2020-05-13 16:27:46.155 7f024bfff700 -1 librbd::image::RemoveRequest: 0x557a7af027a0 check_image_watchers: image has watchers - not removing
Removing image: 0% complete...failed.
rbd: error: image still has watchers
This means the image is still open or the client using it crashed. Try again after closing/unmapping it or waiting 30s for the crashed client to timeout.
$ rbd info nextcloud/mysql
rbd image 'mysql':
size 40 GiB in 10240 objects
order 22 (4 MiB objects)
id: 17e006b8b4567
block_name_prefix: rbd_data.17e006b8b4567
format: 2
features: layering
op_features:
flags:
create_timestamp: Tue Oct 15 10:47:34 2019
&lt;/code>&lt;/pre>
&lt;p>查看当前 rbd 状态：&lt;/p>
&lt;pre>&lt;code>$ rbd status nextcloud/mysql
Watchers:
watcher=10.100.21.95:0/115493307 client.67866 cookie=7
&lt;/code>&lt;/pre>
&lt;p>发现有节点正在挂载，登入到相应机器进行查看：&lt;/p>
&lt;pre>&lt;code>$ rbd showmapped
id pool image snap device
...
3 nextcloud mysql - /dev/rbd3
&lt;/code>&lt;/pre>
&lt;p>取消映射：&lt;/p>
&lt;pre>&lt;code>$ rbd unmap nextcloud/mysql
&lt;/code>&lt;/pre>
&lt;p>重新执行删除操作即可：&lt;/p>
&lt;pre>&lt;code>$ rbd rm nextcloud/mysql
Removing image: 100% complete...done.
&lt;/code>&lt;/pre>
&lt;p>暴力解决方案，直接对其添加黑名单，忽略挂载节点：&lt;/p>
&lt;pre>&lt;code>$ ceph osd blacklist add 10.100.21.95:0/115493307
$ rbd rm nextcloud/mysql
&lt;/code>&lt;/pre>
&lt;h3 id="osd-延迟">OSD 延迟&lt;/h3>
&lt;p>查看是否有 osd 延迟：&lt;/p>
&lt;pre>&lt;code>$ ceph osd perf
osd commit_latency(ms) apply_latency(ms)
2 0 0
1 0 0
0 0 0
&lt;/code>&lt;/pre>
&lt;h3 id="碎片整理">碎片整理&lt;/h3>
&lt;p>查看碎片：&lt;/p>
&lt;pre>&lt;code>$ xfs_db -c frag -r /dev/mapper/VolGroup-lv_data1
&lt;/code>&lt;/pre>
&lt;p>整理碎片：&lt;/p>
&lt;h3 id="查看通电时长">查看通电时长&lt;/h3>
&lt;p>查看磁盘通电时长：&lt;/p>
&lt;pre>&lt;code>$ smartctl -A /dev/mapper/VolGroup-lv_data1
&lt;/code>&lt;/pre>
&lt;h3 id="修改副本数量">修改副本数量&lt;/h3>
&lt;p>修改副本数量：&lt;/p>
&lt;pre>&lt;code>$ ceph osd pool set fs_data2 min_size 1
$ ceph osd pool set fs_data2 size 2
&lt;/code>&lt;/pre>
&lt;h3 id="添加--删除-pool">添加 / 删除 pool&lt;/h3>
&lt;p>添加 / 删除 pool：&lt;/p>
&lt;pre>&lt;code>$ ceph fs add_data_pool fs fs_data2
$ ceph fs rm_data_pool fs fs_data2
&lt;/code>&lt;/pre>
&lt;h3 id="osd-数据均衡分布">osd 数据均衡分布&lt;/h3>
&lt;p>osd 数据均衡分布：&lt;/p>
&lt;pre>&lt;code>$ ceph balancer status
$ ceph balancer on
$ ceph balancer mode crush-compat
&lt;/code>&lt;/pre>
&lt;h3 id="mds-无法查询">mds 无法查询&lt;/h3>
&lt;p>mds 无法查询:&lt;/p>
&lt;pre>&lt;code>$ ceph fs status
Error EINVAL: Traceback (most recent call last):
File &amp;quot;/usr/lib64/ceph/mgr/status/module.py&amp;quot;, line 311, in handle_command
return self.handle_fs_status(cmd)
File &amp;quot;/usr/lib64/ceph/mgr/status/module.py&amp;quot;, line 177, in handle_fs_status
mds_versions[metadata.get('ceph_version', &amp;quot;unknown&amp;quot;)].append(info['name'])
AttributeError: 'NoneType' object has no attribute 'get'
$ ceph mds metadata
[
{
&amp;quot;name&amp;quot;: &amp;quot;BJ-YZ-CEPH-94-54&amp;quot;
},
{
&amp;quot;name&amp;quot;: &amp;quot;BJ-YZ-CEPH-94-53&amp;quot;,
&amp;quot;addr&amp;quot;: &amp;quot;10.100.94.53:6825/4233274463&amp;quot;,
&amp;quot;arch&amp;quot;: &amp;quot;x86_64&amp;quot;,
&amp;quot;ceph_release&amp;quot;: &amp;quot;mimic&amp;quot;,
&amp;quot;ceph_version&amp;quot;: &amp;quot;ceph version 13.2.10 (564bdc4ae87418a232fc901524470e1a0f76d641) mimic (stable)&amp;quot;,
&amp;quot;ceph_version_short&amp;quot;: &amp;quot;13.2.10&amp;quot;,
&amp;quot;cpu&amp;quot;: &amp;quot;Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz&amp;quot;,
&amp;quot;distro&amp;quot;: &amp;quot;centos&amp;quot;,
&amp;quot;distro_description&amp;quot;: &amp;quot;CentOS Linux 7 (Core)&amp;quot;,
&amp;quot;distro_version&amp;quot;: &amp;quot;7&amp;quot;,
&amp;quot;hostname&amp;quot;: &amp;quot;BJ-YZ-CEPH-94-53&amp;quot;,
&amp;quot;kernel_description&amp;quot;: &amp;quot;#1 SMP Sat Dec 10 18:16:05 EST 2016&amp;quot;,
&amp;quot;kernel_version&amp;quot;: &amp;quot;4.4.38-1.el7.elrepo.x86_64&amp;quot;,
&amp;quot;mem_swap_kb&amp;quot;: &amp;quot;67108860&amp;quot;,
&amp;quot;mem_total_kb&amp;quot;: &amp;quot;131914936&amp;quot;,
&amp;quot;os&amp;quot;: &amp;quot;Linux&amp;quot;
},
{
&amp;quot;name&amp;quot;: &amp;quot;BJ-YZ-CEPH-94-52&amp;quot;,
&amp;quot;addr&amp;quot;: &amp;quot;10.100.94.52:6800/3956121270&amp;quot;,
&amp;quot;arch&amp;quot;: &amp;quot;x86_64&amp;quot;,
&amp;quot;ceph_release&amp;quot;: &amp;quot;mimic&amp;quot;,
&amp;quot;ceph_version&amp;quot;: &amp;quot;ceph version 13.2.10 (564bdc4ae87418a232fc901524470e1a0f76d641) mimic (stable)&amp;quot;,
&amp;quot;ceph_version_short&amp;quot;: &amp;quot;13.2.10&amp;quot;,
&amp;quot;cpu&amp;quot;: &amp;quot;Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz&amp;quot;,
&amp;quot;distro&amp;quot;: &amp;quot;centos&amp;quot;,
&amp;quot;distro_description&amp;quot;: &amp;quot;CentOS Linux 7 (Core)&amp;quot;,
&amp;quot;distro_version&amp;quot;: &amp;quot;7&amp;quot;,
&amp;quot;hostname&amp;quot;: &amp;quot;BJ-YZ-CEPH-94-52&amp;quot;,
&amp;quot;kernel_description&amp;quot;: &amp;quot;#1 SMP Sat Dec 10 18:16:05 EST 2016&amp;quot;,
&amp;quot;kernel_version&amp;quot;: &amp;quot;4.4.38-1.el7.elrepo.x86_64&amp;quot;,
&amp;quot;mem_swap_kb&amp;quot;: &amp;quot;67108860&amp;quot;,
&amp;quot;mem_total_kb&amp;quot;: &amp;quot;131914936&amp;quot;,
&amp;quot;os&amp;quot;: &amp;quot;Linux&amp;quot;
}
]
&lt;/code>&lt;/pre>
&lt;p>重启 mds 解决。&lt;/p>
&lt;h3 id="cephfs-显示状态正常但无法写入数据">cephfs 显示状态正常但无法写入数据&lt;/h3>
&lt;p>cephfs 显示正常无法使用，一般是有异常 client 导致的，首先查找 mds 是否存在链接，尝试删除链接解决：&lt;/p>
&lt;pre>&lt;code>$ ceph tell mds.BJ-YZ-CEPH-94-52 session ls
$ ceph tell mds.BJ-YZ-CEPH-94-52 session evict id=834283
&lt;/code>&lt;/pre>
&lt;p>每一个 mds 的 id 号不通用，不能跨节点删除。&lt;/p>
&lt;h3 id="fs-增加-mds">fs 增加 mds&lt;/h3>
&lt;p>fs 增加 mds:&lt;/p>
&lt;pre>&lt;code>$ ceph fs set fs max_mds 2
&lt;/code>&lt;/pre>
&lt;h3 id="mon-时区异常">mon 时区异常&lt;/h3>
&lt;p>mon 因为时区有部分异常导致报错如下：&lt;/p>
&lt;pre>&lt;code>$ ceph -s
cluster:
id: 2f77b028-ed2a-4010-9b79-90fd3052afc6
health: HEALTH_WARN
9 slow ops, oldest one blocked for 211643 sec, daemons [mon.BJ-YZ-CEPH-94-53,mon.BJ-YZ-CEPH-94-54] have slow ops.
services:
mon: 3 daemons, quorum BJ-YZ-CEPH-94-52,BJ-YZ-CEPH-94-53,BJ-YZ-CEPH-94-54
mgr: BJ-YZ-CEPH-94-52(active), standbys: BJ-YZ-CEPH-94-54, BJ-YZ-CEPH-94-53
mds: fs-2/2/2 up {0=BJ-YZ-CEPH-94-52=up:active,1=BJ-YZ-CEPH-94-53=up:active}, 1 up:standby-replay
osd: 36 osds: 36 up, 36 in
data:
pools: 7 pools, 1152 pgs
objects: 37.66 M objects, 67 TiB
usage: 136 TiB used, 126 TiB / 262 TiB avail
pgs: 1148 active+clean
4 active+clean+scrubbing+deep
io:
client: 13 KiB/s rd, 27 MiB/s wr, 2 op/s rd, 19 op/s wr
&lt;/code>&lt;/pre>
&lt;p>配置 npt sever：&lt;/p>
&lt;pre>&lt;code>$ systemctl status ntpd
$ systemctl start ntpd
&lt;/code>&lt;/pre>
&lt;p>重启异常的 mon.targe 解决：&lt;/p>
&lt;pre>&lt;code>$ systemctl status ceph-mon.target
$ systemctl restart ceph-mon.target
&lt;/code>&lt;/pre>
&lt;h3 id="1-mdss-report-slow-requests">1 MDSs report slow requests&lt;/h3>
&lt;p>报错如下：&lt;/p>
&lt;pre>&lt;code>$ ceph -s
cluster:
id: b313ec26-5aa0-4db2-9fb5-a38b207471ee
health: HEALTH_WARN
1 MDSs report slow requests
Reduced data availability: 38 pgs inactive
Degraded data redundancy: 122006/1192166 objects degraded (10.234%), 102 pgs degraded, 116 pgs undersized
101 slow ops, oldest one blocked for 81045 sec, daemons [osd.1,osd.2] have slow ops.
&lt;/code>&lt;/pre>
&lt;p>重启 mon 即可解决：&lt;/p>
&lt;pre>&lt;code>$ systemctl restart ceph-mon.target
&lt;/code>&lt;/pre>
&lt;p>如果无法解决需要重启 mds 解决：&lt;/p>
&lt;pre>&lt;code>$ systemctl restart ceph-mds@${HOSTNAME}
&lt;/code>&lt;/pre>
&lt;h3 id="reduced-data-availability-38-pgs-inactive">Reduced data availability: 38 pgs inactive&lt;/h3>
&lt;p>报错如下：&lt;strong>&lt;a href="https://zhuanlan.zhihu.com/p/74323736">https://zhuanlan.zhihu.com/p/74323736&lt;/a>&lt;/strong>&lt;/p>
&lt;pre>&lt;code>$ ceph -s
cluster:
id: b313ec26-5aa0-4db2-9fb5-a38b207471ee
health: HEALTH_WARN
1 MDSs report slow requests
Reduced data availability: 38 pgs inactive
145 slow ops, oldest one blocked for 184238 sec, daemons [osd.1,osd.2] have slow ops.
services:
mon: 3 daemons, quorum master001,master002,master003
mgr: master001(active), standbys: master002, master003
mds: kubernetes-2/2/2 up {0=master001=up:active,1=master002=up:active}, 1 up:standby
osd: 3 osds: 3 up, 3 in
rgw: 1 daemon active
data:
pools: 9 pools, 244 pgs
objects: 535.1 k objects, 177 GiB
usage: 470 GiB used, 4.1 TiB / 4.6 TiB avail
pgs: 15.574% pgs unknown
206 active+clean
38 unknown
io:
client: 35 KiB/s wr, 0 op/s rd, 2 op/s wr
&lt;/code>&lt;/pre>
&lt;p>此问题属于 pg 丢失数据并且无法自动回复造成的。解决办法是清除 pg 数据让其自动修复，但这样可能会造成数据丢失（如果 size 为 1 则肯定丢失数据）
首先查看异常的 pg：
然后执行 query 查看信息：&lt;/p>
&lt;pre>&lt;code>$ ceph pg 1.6e query
Error ENOENT: i don't have pgid 1.6e
&lt;/code>&lt;/pre>
&lt;p>上述无法查到 pg，通过如下命令查看异常的 pg：&lt;/p>
&lt;pre>&lt;code>$ ceph pg dump_stuck unclean
ok
PG_STAT STATE UP UP_PRIMARY ACTING ACTING_PRIMARY
1.74 unknown [] -1 [] -1
1.70 unknown [] -1 [] -1
1.6a unknown [] -1 [] -1
1.2d unknown [] -1 [] -1
1.20 unknown [] -1 [] -1
1.1e unknown [] -1 [] -1
1.1c unknown [] -1 [] -1
1.17 unknown [] -1 [] -1
1.9 unknown [] -1 [] -1
1.29 unknown [] -1 [] -1
1.56 unknown [] -1 [] -1
1.72 unknown [] -1 [] -1
1.45 unknown [] -1 [] -1
1.4e unknown [] -1 [] -1
1.46 unknown [] -1 [] -1
1.22 unknown [] -1 [] -1
1.53 unknown [] -1 [] -1
1.59 unknown [] -1 [] -1
1.24 unknown [] -1 [] -1
1.55 unknown [] -1 [] -1
1.3f unknown [] -1 [] -1
1.38 unknown [] -1 [] -1
1.a unknown [] -1 [] -1
1.7 unknown [] -1 [] -1
1.34 unknown [] -1 [] -1
1.64 unknown [] -1 [] -1
1.6 unknown [] -1 [] -1
1.32 unknown [] -1 [] -1
1.4 unknown [] -1 [] -1
1.2e unknown [] -1 [] -1
1.31 unknown [] -1 [] -1
1.5e unknown [] -1 [] -1
1.0 unknown [] -1 [] -1
1.42 unknown [] -1 [] -1
1.15 unknown [] -1 [] -1
1.6e unknown [] -1 [] -1
1.41 unknown [] -1 [] -1
1.10 unknown [] -1 [] -1
&lt;/code>&lt;/pre>
&lt;p>执行如下命令强制清除 pg 的数据：&lt;strong>&lt;a href="https://docs.ceph.com/docs/mimic/rados/troubleshooting/troubleshooting-pg/">https://docs.ceph.com/docs/mimic/rados/troubleshooting/troubleshooting-pg/&lt;/a>&lt;/strong>&lt;/p>
&lt;pre>&lt;code>$ ceph osd force-create-pg 1.74 --yes-i-really-mean-it
# 批量执行
# ceph pg dump_stuck unclean|awk '{print $1}'|xargs -i ceph osd force-create-pg {} --yes-i-really-mean-it
&lt;/code>&lt;/pre>
&lt;p>执行完成后即可恢复。&lt;/p>
&lt;h3 id="1-clients-failing-to-respond-to-capability-release">1 clients failing to respond to capability release&lt;/h3>
&lt;p>报错如下：&lt;/p>
&lt;pre>&lt;code>$ ceph health detail
HEALTH_WARN 1 clients failing to respond to capability release
MDS_CLIENT_LATE_RELEASE 1 clients failing to respond to capability release
mdsmaster001(mds.0): Client master003.k8s.shileizcc-ops.com: failing to respond to capability release client_id: 284951
&lt;/code>&lt;/pre>
&lt;p>清除次 ID 即可：&lt;strong>&lt;a href="https://blog.csdn.net/zuoyang1990/article/details/98530070">https://blog.csdn.net/zuoyang1990/article/details/98530070&lt;/a>&lt;/strong>&lt;/p>
&lt;pre>&lt;code>$ ceph daemon mds.master003 session ls|grep 284951
$ ceph tell mds.master003 session evict id=284951
&lt;/code>&lt;/pre>
&lt;p>如果报错如下：&lt;/p>
&lt;pre>&lt;code>$ ceph tell mds.master003 session evict id=284951
2020-08-13 10:45:03.869 7f271b7fe700 0 client.306366 ms_handle_reset on 10.100.21.95:6800/1646216103
2020-08-13 10:45:03.881 7f2730ff9700 0 client.316415 ms_handle_reset on 10.100.21.95:6800/1646216103
Error EAGAIN: MDS is replaying log
&lt;/code>&lt;/pre>
&lt;p>需要到 mds.0 节点执行，否则无法找到次 client。&lt;/p>
&lt;h3 id="内核优化">内核优化&lt;/h3>
&lt;p>内核优化：&lt;strong>&lt;a href="https://blog.csdn.net/fuzhongfaya/article/details/80932766">https://blog.csdn.net/fuzhongfaya/article/details/80932766&lt;/a>&lt;/strong>&lt;/p>
&lt;pre>&lt;code>$ echo &amp;quot;8192&amp;quot; &amp;gt; /sys/block/sda/queue/read_ahead_kb
$ echo &amp;quot;vm.swappiness = 0&amp;quot; | tee -a /etc/sysctl.conf
$ sysctl -p
$ echo &amp;quot;deadline&amp;quot; &amp;gt; /sys/block/sd[x]/queue/scheduler
# ssd
# echo &amp;quot;noop&amp;quot; &amp;gt; /sys/block/sd[x]/queue/scheduler
&lt;/code>&lt;/pre>
&lt;p>swap 最好是直接关闭，配置内存参数在一定程度上不会生效。
配置文件
40 核心 128 GB 配置文件：&lt;/p>
&lt;pre>&lt;code>[global]
fsid = 2f77b028-ed2a-4010-9b79-90fd3052afc6
mon_initial_members = BJ-YZ-CEPH-94-52, BJ-YZ-CEPH-94-53, BJ-YZ-CEPH-94-54
mon_host = 10.100.94.52,10.100.94.53,10.100.94.54
auth_cluster_required = cephx
auth_service_required = cephx
auth_client_required = cephx
public network = 10.100.94.0/24
cluster network = 10.100.94.0/24
[mon.a]
host = BJ-YZ-CEPH-94-52
mon addr = 10.100.94.52:6789
[mon.b]
host = BJ-YZ-CEPH-94-53
mon addr = 10.100.94.53:6789
[mon.c]
host = BJ-YZ-CEPH-94-54
mon addr = 10.100.94.54:6789
[mon]
mon data = /var/lib/ceph/mon/ceph-$id
# monitor 间的 clock drift，默认值 0.05
mon clock drift allowed = 1
# 向 monitor 报告 down 的最小 OSD 数，默认值 1
mon osd min down reporters = 1
# 标记一个OSD状态为down和out之前ceph等待的秒数，默认值300
mon osd down out interval = 600
mon_allow_pool_delete = true
[osd]
# osd 数据路径
osd data = /var/lib/ceph/osd/ceph-$id
# 默认 pool pg,pgp 数量
osd pool default pg num = 1200
osd pool default pgp num = 1200
# osd 的 journal 写日志时的大小默认 5120
osd journal size = 20000
# 格式化文件系统类型
osd mkfs type = xfs
# 格式化文件系统时附加参数
osd mkfs options xfs = -f
# 为 XATTRS 使用 object map，EXT4 文件系统时使用，XFS 或者 btrf 也可以使用，默认 false
filestore xattr use omap = true
# 从日志到数据盘最小同步间隔(seconds)，默认值 0.1
filestore min sync interval = 10
# 从日志到数据盘最大同步间隔(seconds)，默认值 5
filestore max sync interval = 15
# 数据盘最大接受的操作数，默认值 500
filestore queue max ops = 25000
# 数据盘能够 commit 的最大字节数(bytes)，默认值 100
filestore queue max bytes = 10485760
# 数据盘能够 commit 的操作数，500
filestore queue committing max ops = 5000
# 数据盘能够 commit 的最大字节数(bytes)，默认值 100
filestore queue committing max bytes = 10485760000
# 前一个子目录分裂成子目录中的文件的最大数量，默认值 2
filestore split multiple = 8
# 前一个子类目录中的文件合并到父类的最小数量，默认值10
filestore merge threshold = 40
# 对象文件句柄缓存大小，默认值 128
filestore fd cache size = 1024
# 并发文件系统操作数，默认值 2
filestore op threads = 32
# journal 一次性写入的最大字节数(bytes)，默认值 1048560
journal max write bytes = 1073714824
# journal一次性写入的最大记录数，默认值 100
journal max write entries = 10000
# journal一次性最大在队列中的操作数，默认值 50
journal queue max ops = 50000
# journal一次性最大在队列中的字节数(bytes)，默认值 33554432
journal queue max bytes = 10485760000
# # OSD一次可写入的最大值(MB), 默认 90
osd max write size = 512
# 客户端允许在内存中的最大数据(bytes), 默认值100
osd client message size cap = 2147483648
# 在 Deep Scrub 时候允许读取的字节数(bytes), 默认值524288
osd deep scrub stride = 1310720
# 并发文件系统操作数, 默认值 2
osd op threads = 32
# OSD 密集型操作例如恢复和 Scrubbing 时的线程, 默认值1
osd disk threads = 10
# 保留 OSD Map 的缓存(MB), 默认 500
osd map cache size = 10240
# OSD 进程在内存中的 OSD Map 缓存(MB), 默认 50
osd map cache bl size = 1280
# 默认值rw,noatime,inode64, Ceph OSD xfs Mount选项
osd mount options xfs = &amp;quot;rw,noexec,nodev,noatime,nodiratime,nobarrier&amp;quot;
# 恢复操作优先级，取值 1-63，值越高占用资源越高, 默认值 10
osd recovery op priority = 20
# 同一时间内活跃的恢复请求数, 默认值 15
osd recovery max active = 15
# 一个 OSD 允许的最大 backfills 数, 默认值 10
osd max backfills = 10
# 开启严格队列降级操作
osd op queue cut off = high
osd_deep_scrub_large_omap_object_key_threshold = 800000
osd_deep_scrub_large_omap_object_value_sum_threshold = 10737418240
[mds]
# mds 缓存大小设置 60GB
mds cache memory limit = 62212254726
# 超时时间默认 60 秒
mds_revoke_cap_timeout = 360
mds log max segments = 51200
mds log max expiring = 51200
mds_beacon_grace = 300
# 对目录碎片大小的硬限制 默认 100000
# https://docs.ceph.com/docs/master/cephfs/dirfrags/
mds_bal_fragment_size_max = 500000
## 官方配置 https://ceph.readthedocs.io/en/latest/cephfs/mds-config-ref/
[client]
# RBD缓存, 默认 true
rbd cache = true
# RBD缓存大小(bytes), 默认 335544320（320M）
rbd cache size = 268435456
# 缓存为 write-back 时允许的最大 dirty 字节数(bytes)，如果为0，使用 write-through，默认值为 25165824
rbd cache max dirty = 134217728
# 在被刷新到存储盘前 dirty 数据存在缓存的时间(seconds), 默认值为 1
rbd cache max dirty age = 5
client_try_dentry_invalidate = false
[mgr]
mgr modules = dashboard
# 华为云调优指南 https://support.huaweicloud.com/tngg-kunpengsdss/kunpengcephobject_05_0008.html
# https://poph163.com/2020/02/18/ceph-crushmap%E4%B8%8E%E8%B0%83%E4%BC%98/
&lt;/code>&lt;/pre>
&lt;h3 id="full-osd">full osd&lt;/h3>
&lt;p>full osd 每个 osd 已经写满上限:&lt;strong>&lt;a href="https://docs.ceph.com/en/latest/rados/troubleshooting/troubleshooting-osd/#no-free-drive-space">https://docs.ceph.com/en/latest/rados/troubleshooting/troubleshooting-osd/#no-free-drive-space&lt;/a>&lt;/strong>&lt;/p>
&lt;pre>&lt;code>$ ceph osd dump | grep full_ratio
full_ratio 0.95
backfillfull_ratio 0.9
nearfull_ratio 0.85
&lt;/code>&lt;/pre>
&lt;p>集群状态:&lt;/p>
&lt;pre>&lt;code>$ ceph -s
cluster:
id: 2f77b028-ed2a-4010-9b79-90fd3052afc6
health: HEALTH_ERR
2 backfillfull osd(s)
1 full osd(s)
2 nearfull osd(s)
7 pool(s) full
&lt;/code>&lt;/pre>
&lt;p>执行 osd 磁盘状态时，如果已经有超过 95% 使用率时则会报错 full osd 则会造成 cluster 无法正常使用：&lt;/p>
&lt;pre>&lt;code>$ ceph osd df
ID CLASS WEIGHT REWEIGHT SIZE USE DATA OMAP META AVAIL %USE VAR PGS
0 hdd 7.27689 1.00000 7.3 TiB 4.7 TiB 4.7 TiB 918 MiB 9.1 GiB 2.5 TiB 65.15 0.84 68
1 hdd 7.27689 1.00000 7.3 TiB 6.1 TiB 6.1 TiB 327 MiB 11 GiB 1.2 TiB 84.07 1.09 67
2 hdd 7.27689 1.00000 7.3 TiB 4.3 TiB 4.3 TiB 924 MiB 8.4 GiB 2.9 TiB 59.70 0.77 67
3 hdd 7.27689 1.00000 7.3 TiB 5.1 TiB 5.1 TiB 807 MiB 9.8 GiB 2.1 TiB 70.57 0.91 66
4 hdd 7.27689 1.00000 7.3 TiB 6.7 TiB 6.7 TiB 770 MiB 13 GiB 583 GiB 92.18 1.19 66
5 hdd 7.27689 1.00000 7.3 TiB 5.5 TiB 5.5 TiB 623 MiB 10 GiB 1.8 TiB 75.87 0.98 66
6 hdd 7.27689 1.00000 7.3 TiB 5.7 TiB 5.7 TiB 602 MiB 11 GiB 1.6 TiB 78.67 1.02 64
7 hdd 7.27689 1.00000 7.3 TiB 5.3 TiB 5.3 TiB 1.1 GiB 10 GiB 1.9 TiB 73.35 0.95 65
8 hdd 7.27689 1.00000 7.3 TiB 5.9 TiB 5.9 TiB 498 MiB 11 GiB 1.4 TiB 81.29 1.05 68
9 hdd 7.27689 1.00000 7.3 TiB 5.1 TiB 5.1 TiB 1.1 GiB 9.8 GiB 2.1 TiB 70.59 0.91 65
10 hdd 7.27689 1.00000 7.3 TiB 6.3 TiB 6.3 TiB 297 MiB 12 GiB 985 GiB 86.78 1.12 61
11 hdd 7.27689 1.00000 7.3 TiB 5.1 TiB 5.1 TiB 923 MiB 9.7 GiB 2.1 TiB 70.56 0.91 67
12 hdd 7.27689 1.00000 7.3 TiB 5.9 TiB 5.9 TiB 203 MiB 11 GiB 1.4 TiB 81.39 1.05 65
13 hdd 7.27689 1.00000 7.3 TiB 5.3 TiB 5.3 TiB 799 MiB 10 GiB 1.9 TiB 73.29 0.95 66
14 hdd 7.27689 1.00000 7.3 TiB 4.9 TiB 4.9 TiB 873 MiB 9.4 GiB 2.3 TiB 67.77 0.88 71
15 hdd 0.29999 1.00000 7.3 TiB 6.9 TiB 6.9 TiB 191 MiB 13 GiB 387 GiB 94.81 1.23 39
16 hdd 7.27689 1.00000 7.3 TiB 5.5 TiB 5.5 TiB 548 MiB 11 GiB 1.8 TiB 75.91 0.98 69
17 hdd 7.27689 1.00000 7.3 TiB 6.7 TiB 6.7 TiB 806 MiB 13 GiB 581 GiB 92.20 1.20 66
18 hdd 7.27689 1.00000 7.3 TiB 4.5 TiB 4.5 TiB 1.4 GiB 8.5 GiB 2.7 TiB 62.43 0.81 66
19 hdd 7.27689 1.00000 7.3 TiB 5.3 TiB 5.3 TiB 1.4 GiB 10 GiB 1.9 TiB 73.28 0.95 65
20 hdd 7.27689 1.00000 7.3 TiB 5.5 TiB 5.5 TiB 705 MiB 11 GiB 1.8 TiB 75.91 0.98 64
21 hdd 7.27689 1.00000 7.3 TiB 6.1 TiB 6.1 TiB 911 MiB 11 GiB 1.2 TiB 84.11 1.09 62
22 hdd 7.27689 1.00000 7.3 TiB 6.1 TiB 6.1 TiB 301 MiB 11 GiB 1.2 TiB 84.03 1.09 66
23 hdd 7.27689 1.00000 7.3 TiB 5.5 TiB 5.5 TiB 401 MiB 9.8 GiB 1.7 TiB 75.96 0.98 67
24 hdd 7.27689 1.00000 7.3 TiB 5.1 TiB 5.1 TiB 1.3 GiB 9.6 GiB 2.1 TiB 70.58 0.91 63
25 hdd 7.27689 1.00000 7.3 TiB 5.1 TiB 5.1 TiB 1.1 GiB 9.7 GiB 2.1 TiB 70.56 0.91 65
26 hdd 7.27689 1.00000 7.3 TiB 5.3 TiB 5.3 TiB 730 MiB 10 GiB 1.9 TiB 73.32 0.95 68
27 hdd 7.27689 1.00000 7.3 TiB 6.1 TiB 6.1 TiB 818 MiB 12 GiB 1.2 TiB 84.08 1.09 62
28 hdd 7.27689 1.00000 7.3 TiB 4.9 TiB 4.9 TiB 587 MiB 9.3 GiB 2.3 TiB 67.84 0.88 68
29 hdd 7.27689 1.00000 7.3 TiB 6.1 TiB 6.1 TiB 215 MiB 11 GiB 1.2 TiB 84.09 1.09 66
30 hdd 7.27689 1.00000 7.3 TiB 6.1 TiB 6.1 TiB 690 MiB 12 GiB 1.2 TiB 84.15 1.09 64
31 hdd 7.27689 1.00000 7.3 TiB 5.5 TiB 5.5 TiB 1020 MiB 10 GiB 1.8 TiB 75.94 0.98 64
32 hdd 7.27689 1.00000 7.3 TiB 6.5 TiB 6.5 TiB 616 MiB 12 GiB 786 GiB 89.45 1.16 66
33 hdd 7.27689 1.00000 7.3 TiB 4.9 TiB 4.9 TiB 622 MiB 8.9 GiB 2.3 TiB 67.84 0.88 66
34 hdd 7.27689 1.00000 7.3 TiB 5.7 TiB 5.7 TiB 102 MiB 11 GiB 1.6 TiB 78.56 1.02 65
35 hdd 7.27689 1.00000 7.3 TiB 5.9 TiB 5.9 TiB 723 MiB 11 GiB 1.4 TiB 81.31 1.05 63
TOTAL 262 TiB 202 TiB 202 TiB 25 GiB 381 GiB 60 TiB 77.15
&lt;/code>&lt;/pre>
&lt;p>可以手动修改权重解决:&lt;/p>
&lt;pre>&lt;code>$ ceph osd crush reweight osd.4 0.3
&lt;/code>&lt;/pre>
&lt;h3 id="pg-均衡">pg 均衡&lt;/h3>
&lt;p>pg 在默认分配有不合理的地方。&lt;strong>&lt;a href="https://cloud.tencent.com/developer/article/1664655">https://cloud.tencent.com/developer/article/1664655&lt;/a>&lt;/strong>&lt;/p>
&lt;pre>&lt;code>$ ceph osd df tree | awk '/osd\./{print $NF&amp;quot; &amp;quot;$(NF-1)&amp;quot; &amp;quot;$(NF-3) }'
osd.0 89 71.20
osd.1 38 94.80
osd.2 92 68.44
osd.3 92 72.36
osd.4 28 76.86
osd.5 64 81.37
osd.6 62 87.90
osd.7 89 78.78
osd.8 52 86.18
osd.9 89 75.44
osd.10 37 96.33
osd.11 102 75.26
osd.12 33 91.41
osd.13 34 95.98
osd.14 59 84.97
osd.15 20 70.92
osd.16 113 89.46
osd.17 30 77.12
osd.18 124 77.11
osd.19 44 95.23
osd.20 65 84.63
osd.21 98 96.71
osd.22 34 95.93
osd.23 62 84.56
osd.24 110 76.63
osd.25 64 82.32
osd.26 59 88.26
osd.27 38 95.83
osd.28 105 79.19
osd.29 36 94.94
osd.30 94 90.79
osd.31 91 81.74
osd.32 12 42.44
osd.33 94 81.32
osd.34 46 86.51
osd.35 37 92.68
&lt;/code>&lt;/pre>
&lt;p>reweight-by-pg 按归置组分布情况调整 OSD 的权重:&lt;/p>
&lt;pre>&lt;code>$ ceph osd reweight-by-pg
moved 0 / 2336 (0%)
avg 64.8889
stddev 58.677 -&amp;gt; 58.677 (expected baseline 7.9427)
min osd.1 with 0 -&amp;gt; 0 pgs (0 -&amp;gt; 0 * mean)
max osd.18 with 168 -&amp;gt; 168 pgs (2.58904 -&amp;gt; 2.58904 * mean)
oload 120
max_change 0.05
max_change_osds 4
average_utilization 18.2677
overload_utilization 21.9212
osd.19 weight 1.0000 -&amp;gt; 0.9500
osd.1 weight 1.0000 -&amp;gt; 0.9500
osd.27 weight 1.0000 -&amp;gt; 0.9500
osd.10 weight 1.0000 -&amp;gt; 0.9500
&lt;/code>&lt;/pre>
&lt;p>reweight-by-utilization 按利用率调整 OSD 的权重:&lt;/p>
&lt;pre>&lt;code>$ ceph osd reweight-by-pg
moved 0 / 2336 (0%)
avg 64.8889
stddev 58.677 -&amp;gt; 58.677 (expected baseline 7.9427)
min osd.1 with 0 -&amp;gt; 0 pgs (0 -&amp;gt; 0 * mean)
max osd.18 with 168 -&amp;gt; 168 pgs (2.58904 -&amp;gt; 2.58904 * mean)
oload 120
max_change 0.05
max_change_osds 4
average_utilization 18.2677
overload_utilization 21.9212
osd.19 weight 1.0000 -&amp;gt; 0.9500
osd.1 weight 1.0000 -&amp;gt; 0.9500
osd.27 weight 1.0000 -&amp;gt; 0.9500
osd.10 weight 1.0000 -&amp;gt; 0.9500
&lt;/code>&lt;/pre>
&lt;p>调整写入权重：&lt;/p>
&lt;pre>&lt;code>$ ceph osd reweight osd.35 0.001
&lt;/code>&lt;/pre>
&lt;p>查看当前 osd 信息：&lt;/p>
&lt;pre>&lt;code>$ ceph osd df
ID CLASS WEIGHT REWEIGHT SIZE USE DATA OMAP META AVAIL %USE VAR PGS
0 hdd 7.27689 1.00000 7.3 TiB 5.2 TiB 5.2 TiB 1.0 GiB 9.4 GiB 2.0 TiB 71.96 0.86 39
1 hdd 0.00999 0.90002 7.3 TiB 6.9 TiB 6.9 TiB 604 MiB 12 GiB 382 GiB 94.88 1.13 37
2 hdd 7.27689 1.00000 7.3 TiB 5.1 TiB 5.1 TiB 1.2 GiB 8.8 GiB 2.2 TiB 69.55 0.83 34
3 hdd 7.27689 1.00000 7.3 TiB 5.3 TiB 5.3 TiB 812 MiB 9.9 GiB 2.0 TiB 73.15 0.87 34
4 hdd 0.29999 1.00000 7.3 TiB 5.6 TiB 5.6 TiB 185 MiB 12 GiB 1.7 TiB 77.01 0.92 26
5 hdd 3.00000 1.00000 7.3 TiB 6.0 TiB 5.9 TiB 443 MiB 11 GiB 1.3 TiB 81.90 0.98 36
6 hdd 3.00000 1.00000 7.3 TiB 6.5 TiB 6.5 TiB 499 MiB 11 GiB 809 GiB 89.14 1.06 38
7 hdd 7.27689 1.00000 7.3 TiB 5.8 TiB 5.8 TiB 1.2 GiB 11 GiB 1.4 TiB 80.10 0.96 43
8 hdd 3.00000 1.00000 7.3 TiB 6.3 TiB 6.3 TiB 502 MiB 11 GiB 992 GiB 86.69 1.03 36
9 hdd 7.27689 1.00000 7.3 TiB 5.6 TiB 5.6 TiB 1.5 GiB 9.8 GiB 1.7 TiB 76.57 0.91 42
10 hdd 0.00999 0.00099 7.3 TiB 7.0 TiB 7.0 TiB 295 MiB 12 GiB 267 GiB 96.41 1.15 37
11 hdd 7.27689 1.00000 7.3 TiB 5.5 TiB 5.5 TiB 1.2 GiB 9.8 GiB 1.7 TiB 76.13 0.91 37
12 hdd 0.00999 1.00000 7.3 TiB 6.7 TiB 6.6 TiB 95 MiB 12 GiB 635 GiB 91.48 1.09 32
13 hdd 0.00999 1.00000 7.3 TiB 7.0 TiB 7.0 TiB 584 MiB 12 GiB 315 GiB 95.78 1.14 34
14 hdd 3.00000 1.00000 7.3 TiB 6.2 TiB 6.2 TiB 974 MiB 11 GiB 1.0 TiB 85.86 1.02 40
15 hdd 0.00999 1.00000 7.3 TiB 5.1 TiB 5.1 TiB 116 KiB 10 GiB 2.2 TiB 70.43 0.84 20
16 hdd 7.27689 1.00000 7.3 TiB 6.6 TiB 6.6 TiB 1.2 GiB 11 GiB 697 GiB 90.64 1.08 43
17 hdd 0.29999 1.00000 7.3 TiB 5.6 TiB 5.6 TiB 40 KiB 12 GiB 1.7 TiB 76.75 0.92 26
18 hdd 7.27689 1.00000 7.3 TiB 5.7 TiB 5.7 TiB 1.9 GiB 9.3 GiB 1.6 TiB 78.01 0.93 53
19 hdd 0.00999 0.00099 7.3 TiB 6.9 TiB 6.9 TiB 1.5 GiB 13 GiB 371 GiB 95.02 1.13 40
20 hdd 3.00000 1.00000 7.3 TiB 6.2 TiB 6.2 TiB 744 MiB 12 GiB 1.0 TiB 85.86 1.02 37
21 hdd 7.27689 0.00099 7.3 TiB 7.0 TiB 7.0 TiB 913 MiB 12 GiB 239 GiB 96.79 1.15 40
22 hdd 0.00999 0.00099 7.3 TiB 7.0 TiB 7.0 TiB 283 MiB 12 GiB 298 GiB 96.00 1.14 34
23 hdd 3.00000 1.00000 7.3 TiB 6.2 TiB 6.2 TiB 515 MiB 11 GiB 1.1 TiB 85.30 1.02 35
24 hdd 7.27689 1.00000 7.3 TiB 5.6 TiB 5.6 TiB 1.4 GiB 9.8 GiB 1.6 TiB 77.63 0.93 42
25 hdd 3.00000 1.00000 7.3 TiB 6.0 TiB 6.0 TiB 1.2 GiB 10 GiB 1.3 TiB 82.66 0.99 40
26 hdd 2.00000 1.00000 7.3 TiB 6.5 TiB 6.5 TiB 737 MiB 11 GiB 823 GiB 88.95 1.06 36
27 hdd 0.00999 0.00099 7.3 TiB 7.0 TiB 6.9 TiB 822 MiB 12 GiB 327 GiB 95.61 1.14 37
28 hdd 7.27689 1.00000 7.3 TiB 5.8 TiB 5.8 TiB 859 MiB 10 GiB 1.4 TiB 80.23 0.96 40
29 hdd 0.00999 0.00099 7.3 TiB 6.9 TiB 6.9 TiB 215 MiB 12 GiB 371 GiB 95.02 1.13 36
30 hdd 7.27689 1.00000 7.3 TiB 6.7 TiB 6.7 TiB 1.0 GiB 12 GiB 607 GiB 91.85 1.10 47
31 hdd 7.27689 1.00000 7.3 TiB 6.0 TiB 6.0 TiB 1.2 GiB 10 GiB 1.3 TiB 82.81 0.99 41
32 hdd 0.29999 1.00000 7.3 TiB 3.0 TiB 3.0 TiB 32 KiB 7.1 GiB 4.3 TiB 41.47 0.49 10
33 hdd 7.27689 1.00000 7.3 TiB 6.0 TiB 6.0 TiB 827 MiB 9.7 GiB 1.3 TiB 82.06 0.98 41
34 hdd 2.00000 1.00000 7.3 TiB 6.3 TiB 6.3 TiB 308 MiB 11 GiB 976 GiB 86.90 1.04 33
35 hdd 0.00999 0.00099 7.3 TiB 6.7 TiB 6.7 TiB 613 MiB 12 GiB 540 GiB 92.75 1.11 36
TOTAL 262 TiB 220 TiB 219 TiB 27 GiB 391 GiB 42 TiB 83.87
MIN/MAX VAR: 0.49/1.15 STDDEV: 10.62
&lt;/code>&lt;/pre>
&lt;p>删除 Cephfs
关闭所有 mds 服务, 需要登入服务器手动关闭:&lt;/p>
&lt;pre>&lt;code>$ systemctl stop ceph-mds@${HOSTNAME}
&lt;/code>&lt;/pre>
&lt;p>删除所需 fs:&lt;/p>
&lt;pre>&lt;code>$ ceph fs ls
$ ceph fs rm data --yes-i-really-mean-it
&lt;/code>&lt;/pre>
&lt;p>SSD 使用
查看当前 OSD 状态: (相关文档:&lt;strong>&lt;a href="https://blog.csdn.net/kozazyh/article/details/79904219">https://blog.csdn.net/kozazyh/article/details/79904219&lt;/a>&lt;/strong>)&lt;/p>
&lt;pre>&lt;code>$ ceph osd crush class ls
[
&amp;quot;ssd&amp;quot;
]
&lt;/code>&lt;/pre>
&lt;p>如果使用的 SSD 标识错误，请自定义修改，命令如下, 移除 osd 1 ~ 3 的标识:&lt;/p>
&lt;pre>&lt;code>$ for i in 0 1 2;do ceph osd crush rm-device-class osd.$i;done
&lt;/code>&lt;/pre>
&lt;p>设置 1 ~ 3 标识为 ssd：&lt;/p>
&lt;pre>&lt;code>$ for i in 0 1 2;do ceph osd crush set-device-class ssd osd.$i;done
&lt;/code>&lt;/pre>
&lt;p>创建一个 crush rule:&lt;/p>
&lt;pre>&lt;code>$ ceph osd crush rule create-replicated rule-ssd default host ssd
$ ceph osd crush rule ls
&lt;/code>&lt;/pre>
&lt;p>然后创建 pool 时附带 rule 的名称：&lt;/p>
&lt;pre>&lt;code>$ ceph osd pool create fs_data 96 rule-ssd
$ ceph osd pool create fs_metadata 16 rule-ssd
$ ceph fs new fs fs_data fs_metadata
&lt;/code>&lt;/pre>
&lt;h3 id="crushmap-查看">crushmap 查看&lt;/h3>
&lt;p>执行命令如下:&lt;/p>
&lt;pre>&lt;code>$ ceph osd getcrushmap -o crushmap
$ crushtool -d crushmap -o crushmap
$ cat crushmap
&lt;/code>&lt;/pre>
&lt;h3 id="3-monitors-have-not-enabled-msgr2">3 monitors have not enabled msgr2&lt;/h3>
&lt;p>解决如下：&lt;/p>
&lt;pre>&lt;code>$ ceph mon enable-msgr2
&lt;/code>&lt;/pre>
&lt;h3 id="2-daemons-have-recently-crashed">2 daemons have recently crashed&lt;/h3>
&lt;p>解决如下：&lt;strong>&lt;a href="https://blog.csdn.net/QTM_Gitee/article/details/106004435">https://blog.csdn.net/QTM_Gitee/article/details/106004435&lt;/a>&lt;/strong>&lt;/p>
&lt;pre>&lt;code>$ ceph crash ls
$ ceph crash archive-all
&lt;/code>&lt;/pre>
&lt;h3 id="脚注">脚注&lt;/h3>
&lt;p>[1]
&lt;a href="https://zhuanlan.zhihu.com/p/74323736:">https://zhuanlan.zhihu.com/p/74323736:&lt;/a> &lt;em>&lt;a href="https://zhuanlan.zhihu.com/p/74323736">https://zhuanlan.zhihu.com/p/74323736&lt;/a>&lt;/em>
[2]
&lt;a href="https://docs.ceph.com/docs/mimic/rados/troubleshooting/troubleshooting-pg/:">https://docs.ceph.com/docs/mimic/rados/troubleshooting/troubleshooting-pg/:&lt;/a> &lt;em>&lt;a href="https://docs.ceph.com/docs/mimic/rados/troubleshooting/troubleshooting-pg/">https://docs.ceph.com/docs/mimic/rados/troubleshooting/troubleshooting-pg/&lt;/a>&lt;/em>
[3]
&lt;a href="https://blog.csdn.net/zuoyang1990/article/details/98530070:">https://blog.csdn.net/zuoyang1990/article/details/98530070:&lt;/a> &lt;em>&lt;a href="https://blog.csdn.net/zuoyang1990/article/details/98530070">https://blog.csdn.net/zuoyang1990/article/details/98530070&lt;/a>&lt;/em>
[4]
&lt;a href="https://blog.csdn.net/fuzhongfaya/article/details/80932766:">https://blog.csdn.net/fuzhongfaya/article/details/80932766:&lt;/a> &lt;em>&lt;a href="https://blog.csdn.net/fuzhongfaya/article/details/80932766">https://blog.csdn.net/fuzhongfaya/article/details/80932766&lt;/a>&lt;/em>
[5]
&lt;a href="https://docs.ceph.com/en/latest/rados/troubleshooting/troubleshooting-osd/#no-free-drive-space:">https://docs.ceph.com/en/latest/rados/troubleshooting/troubleshooting-osd/#no-free-drive-space:&lt;/a> &lt;em>&lt;a href="https://docs.ceph.com/en/latest/rados/troubleshooting/troubleshooting-osd/#no-free-drive-space">https://docs.ceph.com/en/latest/rados/troubleshooting/troubleshooting-osd/#no-free-drive-space&lt;/a>&lt;/em>
[6]
&lt;a href="https://cloud.tencent.com/developer/article/1664655:">https://cloud.tencent.com/developer/article/1664655:&lt;/a> &lt;em>&lt;a href="https://cloud.tencent.com/developer/article/1664655">https://cloud.tencent.com/developer/article/1664655&lt;/a>&lt;/em>
[7]
&lt;a href="https://blog.csdn.net/kozazyh/article/details/79904219:">https://blog.csdn.net/kozazyh/article/details/79904219:&lt;/a> &lt;em>&lt;a href="https://blog.csdn.net/kozazyh/article/details/79904219">https://blog.csdn.net/kozazyh/article/details/79904219&lt;/a>&lt;/em>
[8]
&lt;a href="https://blog.csdn.net/QTM_Gitee/article/details/106004435:">https://blog.csdn.net/QTM_Gitee/article/details/106004435:&lt;/a> &lt;em>&lt;a href="https://blog.csdn.net/QTM_Gitee/article/details/106004435">https://blog.csdn.net/QTM_Gitee/article/details/106004435&lt;/a>&lt;/em>&lt;/p></description></item><item><title>Docs: Ceph 命令行工具</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/ceph-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/ceph/ceph-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.ceph.com/en/latest/rados/man/">官方文档,Ceph 存储集群-手册页&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.ceph.com/en/latest/man/8/radosgw-admin/#">官方文档,Ceph 对象网关-radosgw-admin 手册页&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="ceph--ceph-管理工具">ceph # Ceph 管理工具&lt;/h1>
&lt;p>一个 Python 实现的脚本工具，用于手动部署和似乎 Ceph 集群。通过很多的子命令，允许部署 ceph-mon、ceph-osd、PG、ceph-mds 等，并可以对集群整体进行维护和管理。&lt;/p>
&lt;h2 id="orch">orch&lt;/h2>
&lt;p>Orchestrator(编排器，简称 orch)&lt;/p>
&lt;h3 id="syntax语法">Syntax(语法)&lt;/h3>
&lt;p>COMMAND&lt;/p>
&lt;ul>
&lt;li>**host **# 对集群中的节点进行管理
&lt;ul>
&lt;li>&lt;strong>add &lt;!-- raw HTML omitted --> [ADDR] [LABELs&amp;hellip;] [&amp;ndash;maintenance]&lt;/strong> # 向集群中添加一个节点&lt;/li>
&lt;li>&lt;strong>label add &lt;!-- raw HTML omitted --> &lt;!-- raw HTML omitted -->&lt;/strong> # 为节点添加一个标签&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>ls&lt;/strong> # 列出 Orch 已知的服务&lt;/li>
&lt;li>**rm &lt;!-- raw HTML omitted --> **# 移除一个服务&lt;/li>
&lt;/ul>
&lt;p>EXAMPLE&lt;/p>
&lt;h1 id="radosgw-admin--rados-网关的用户管理工具">radosgw-admin # RADOS 网关的用户管理工具&lt;/h1>
&lt;p>radosgw-admin 是一个 RADOS 网关用户的管理工具。可以增删改查用户。该工具通过非常多的子命令进行管理，并且每个子命令可用的选项也各不相同，Ceph 官方对这个工具的提示做的非常不好，子命令需要带的选项并不提示，只能自己尝试~~~&lt;/p>
&lt;h2 id="user">user&lt;/h2>
&lt;h3 id="syntax语法-1">Syntax(语法)&lt;/h3>
&lt;p>&lt;strong>radosgw-admin user COMMAND [OPTIONS]&lt;/strong>&lt;/p>
&lt;p>COMMAND&lt;/p>
&lt;ul>
&lt;li>&lt;strong>user create &amp;ndash;display-name=&lt;!-- raw HTML omitted --> &amp;ndash;uid=&lt;!-- raw HTML omitted -->&lt;/strong> # 创建一个新用户&lt;/li>
&lt;li>&lt;strong>user info [&amp;ndash;uid=&lt;!-- raw HTML omitted --> | &amp;ndash;access-key=&lt;!-- raw HTML omitted -->]&lt;/strong> # 显示一个用户的信息，包括其子用户和密钥。通过 uid 或 ak 指定要显示的用户。&lt;/li>
&lt;li>&lt;strong>user list&lt;/strong> # 列出所有用户&lt;/li>
&lt;li>&lt;strong>user modify &amp;ndash;uid=&lt;!-- raw HTML omitted -->&lt;/strong> # 修改指定的用户&lt;/li>
&lt;/ul>
&lt;p>OPTIONS&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&amp;ndash;admin&lt;/strong> # 为指定用户设定 admin 标志&lt;/li>
&lt;li>&lt;strong>&amp;ndash;display-name=&lt;!-- raw HTML omitted -->&lt;/strong> # 为指定用户设定对外显示的名称&lt;/li>
&lt;li>&lt;strong>&amp;ndash;email=&lt;!-- raw HTML omitted -->&lt;/strong> # 为用户设定邮箱&lt;/li>
&lt;li>&lt;strong>&amp;ndash;uid=&lt;!-- raw HTML omitted -->&lt;/strong> # 指定用户的 ID。在执行绝大部分与用户相关的命令时，都需要指定该选项，以确定操作的用户。比如 查看用户信息、查看属于指定用户的桶的信息 等等等等&lt;/li>
&lt;li>&lt;strong>&amp;ndash;system&lt;/strong> # 为指定用户设定 system 标志&lt;/li>
&lt;/ul>
&lt;h3 id="exapmel">EXAPMEL&lt;/h3>
&lt;p>创建一个名为 lichenhao 的用户，并添加 system 标志&lt;/p>
&lt;ul>
&lt;li>&lt;strong>radosgw-admin user create &amp;ndash;uid=lichenhao &amp;ndash;display-name=lichenhao &amp;ndash;system&lt;/strong>&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;p>COMMAND&lt;/p>
&lt;ul>
&lt;li>**bucket stats [OPTIONS] **# 显示桶的统计信息。可以通过选项指定用户下的桶或指定的桶。&lt;/li>
&lt;/ul>
&lt;p>OPTIONS&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&amp;ndash;bucket=&lt;!-- raw HTML omitted -->&lt;/strong> # 指定桶的名称。可以被 quota 子命令使用。&lt;/li>
&lt;li>&lt;strong>&amp;ndash;uid=&lt;!-- raw HTML omitted -->&lt;/strong> # 指定用户的 ID。查看桶信息时，将会显示该用户下所有桶的信息。&lt;/li>
&lt;/ul></description></item><item><title>Docs: cluster 命令</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/cluster-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/cluster-%E5%91%BD%E4%BB%A4/</guid><description>
&lt;p>一、以下命令是Redis Cluster集群所独有的，执行下面命令需要先登录redis：&lt;/p>
&lt;p>[root@manage redis]# redis-cli -c -p 6382 -h 192.168.10.12 （客户端命令：redis-cli -c -p port -h ip）&lt;/p>
&lt;p>192.168.10.12:6382&amp;gt; 登录redis后，在里面可以进行下面命令操作&lt;/p>
&lt;p>集群&lt;/p>
&lt;p>cluster info ：打印集群的信息&lt;/p>
&lt;p>cluster nodes ：列出集群当前已知的所有节点（ node），以及这些节点的相关信息。&lt;/p>
&lt;p>节点&lt;/p>
&lt;p>cluster meet ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。&lt;/p>
&lt;p>cluster forget ：从集群中移除 node_id 指定的节点。&lt;/p>
&lt;p>cluster replicate ：将当前从节点设置为 node_id 指定的master节点的slave节点。只能针对slave节点操作。&lt;/p>
&lt;p>cluster saveconfig ：将节点的配置文件保存到硬盘里面。&lt;/p>
&lt;p>槽(slot)&lt;/p>
&lt;p>cluster addslots [slot &amp;hellip;] ：将一个或多个槽（ slot）指派（ assign）给当前节点。&lt;/p>
&lt;p>cluster delslots [slot &amp;hellip;] ：移除一个或多个槽对当前节点的指派。&lt;/p>
&lt;p>cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。&lt;/p>
&lt;p>cluster setslot node ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给&lt;/p>
&lt;p>另一个节点，那么先让另一个节点删除该槽&amp;gt;，然后再进行指派。&lt;/p>
&lt;p>cluster setslot migrating ：将本节点的槽 slot 迁移到 node_id 指定的节点中。&lt;/p>
&lt;p>cluster setslot importing ：从 node_id 指定的节点中导入槽 slot 到本节点。&lt;/p>
&lt;p>cluster setslot stable ：取消对槽 slot 的导入（ import）或者迁移（ migrate）。&lt;/p>
&lt;p>键&lt;/p>
&lt;p>cluster keyslot ：计算键 key 应该被放置在哪个槽上。&lt;/p>
&lt;p>cluster countkeysinslot ：返回槽 slot 目前包含的键值对数量。&lt;/p>
&lt;p>cluster getkeysinslot ：返回 count 个 slot 槽中的键 。&lt;/p></description></item><item><title>Docs: Data Storage(数据存储)</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/data-storage%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/data-storage%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</guid><description>
&lt;h1 id="metadata元数据">Metadata(元数据)&lt;/h1>
&lt;p>又称中介数据、中继数据，为描述数据的数据（data about data），主要是描述数据属性（property）的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能。元数据算是一种电子式目录，为了达到编制目录的目的，必须在描述并收藏数据的内容或特色，进而达成协助数据检索的目的。都柏林核心集（Dublin Core Metadata Initiative，DCMI）是元数据的一种应用，是 1995 年 2 月由国际图书馆电脑中心（OCLC）和美国国家超级计算应用中心（National Center for Supercomputing Applications，NCSA）所联合赞助的研讨会，在邀请 52 位来自图书馆员、电脑专家，共同制定规格，创建一套描述网络上电子文件之特征。&lt;/p>
&lt;p>例：一个文件的创建日期，所在位置等，除了文件内容以外的东西都可以称之为元数据。&lt;/p>
&lt;h1 id="备份和归档的区别">备份和归档的区别&lt;/h1>
&lt;ol>
&lt;li>
&lt;p>不同的过程会导致不同的结果。归档最通用的定义是存储有组织的数据。归档的目的是长时间存放有组织的数据集，确保其将来能够被精细地检索。改进的磁带是这种应用最理想的方式。FujiFilm 对它的新一代 BaFe 磁带产品的弹性测试证明其数据保存能力很强，可以存储 30 年以上。 相比之下，磁盘的故障率比其制造商说的还要高，几年前 Carnegie Mellon University 和 Google 的研究记录证明了这一点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>备份是短时间存储那些频繁更换或更新的数据的副本。这相当于一批廉价的离线介质上的数据副本。通过这种方式，可以把数据与那些基于磁盘的数据中断事件隔离开，以免同时遭到损坏，这样，如果原始数据或存储平台损坏的话，数据就可以恢复到任何磁盘阵列。在磁盘到磁盘复制解决方案中，复制只能发生在两个完全相同的设备中。此外，复制过程还可以中断，这样你就可以检查在主数据存储和镜像仓库之间的增量或差异。不过，最好别这样做，因为它可能会导致在磁盘到磁盘的复制过程中产生很多不易察觉的错误。 很遗憾，我发现你在努力保护你的数据时，它已经在阵列之间移动了，而你只镜像复制了一个空白空间&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>TechTarget 中国原创内容，原文链接： &lt;a href="https://searchstorage.techtarget.com.cn/6-23590/">https://searchstorage.techtarget.com.cn/6-23590/&lt;/a>&lt;/p></description></item><item><title>Docs: Distributed Storage(分布式存储)</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Google_File_System">Wiki,GFS&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Distributed Storage(分布式存储)&lt;/strong> 最早可追溯到 &lt;strong>Google File System(谷歌文件系统，GFS)&lt;/strong>，GFS 是由 Google 开发，旨在使用大型低廉的商用硬件集群提供高效、可靠的数据访问。在不可追溯的年月，Google 发布了这种文件系统的论文，其中就有公司，基于这个论文所描述的设计架构，使用 Java 实现了 HDFS，也就是红极一时的 Hadoop 所使用的文件系统。但是随着时代的发展，Hadoop 臃肿的设计，并不适用于云原生的环境而被逐渐淘汰了，但是基于 GFS 的设计理念，一直延续至今。&lt;/p>
&lt;p>分布式存储首先需要解决的就是文件路由问题，在一个分布式存储中，数据分散到各个节点，客户端想要读取时，如何快速得找到数据所在位置呢？这就需要一个元数据服务器，来记录数据存放位置。但是数据存储位置的规则，一直是分布式存储的热门话题之一。一般来说，系统中所有角色（Clients、Servers）需要有一个统一的数据寻址算法 Locator，满足：&lt;code>Locator(ID) -&amp;gt; [Device_1, Device_2, Device_3, ...]&lt;/code>&lt;/p>
&lt;p>其中输入 ID 是数据的唯一标识符，输出 Device 列表是一系列存储设备（多设备冗余以达到多份数据保护或切分提高并发等效果）。早期的直观方案是维护一张全局的 Key-Value 表，任何角色操作数据时查询该表即可。显然，随着数据量的增多和集群规模的扩大，要在整个系统中维护这么一张不断扩大的表变得越来越困难。Ceph 的 &lt;strong>CRUSH&lt;/strong>(Controlled Replication Under Scalable Hashing) 算法即为解决此问题而生，她仅需要一份描述集群物理架构的信息和预定义的规则（均包含在&lt;strong>CRUSH map&lt;/strong>中），便可实现确定数据存储位置的功能。&lt;/p>
&lt;h1 id="分布式基础学习">分布式基础学习&lt;/h1>
&lt;p>详见：&lt;a href="https://www.yuque.com/go/doc/33184360">分布式系统&lt;/a>&lt;/p>
&lt;p>所谓分布式，在这里，很狭义的指代以 Google 的三驾马车，GFS、Map/Reduce、BigTable 为框架核心的分布式存储和计算系统。通常如我一样初学的人，会以 Google 这几份经典的论文作为开端的。它们勾勒出了分布式存储和计算的一个基本蓝图，已可窥见其几分风韵，但终究还是由于缺少一些实现的代码和示例，色彩有些斑驳，缺少了点感性。幸好我们还有 Open Source，还有 Hadoop。Hadoop 是一个基于 Java 实现的，开源的，分布式存储和计算的项目。作为这个领域最富盛名的开源项目之一，它的使用者也是大牌如云，包括了 Yahoo，Amazon，Facebook 等等（好吧，还可能有校内，不过这真的没啥分量&amp;hellip;）。Hadoop 本身，实现的是分布式的文件系统 HDFS，和分布式的计算（Map/Reduce）框架，此外，它还不是一个人在战斗，Hadoop 包含一系列扩展项目，包括了分布式文件数据库 HBase（对应 Google 的 BigTable），分布式协同服务 ZooKeeper（对应 Google 的 Chubby），等等。。。&lt;/p>
&lt;p>如此，一个看上去不错的黄金搭档浮出水面，Google 的论文 + Hadoop 的实现，顺着论文的框架看具体的实现，用实现来进一步理解论文的逻辑，看上去至少很美。网上有很多前辈们，做过 Hadoop 相关的源码剖析工作，我关注最多的是这里，目前博主已经完成了 HDFS 的剖析工作，Map/Reduce 的剖析正火热进行中，更新频率之高，剖析之详尽，都是难得一见的，所以，走过路过一定不要错过了。此外，还有很多 Hadoop 的关注者和使用者贴过相关的文章，比如：这里，这里。也可以去 Hadoop 的中文站点（不知是民间还是官方&amp;hellip;），搜罗一些学习资料。。。&lt;/p>
&lt;p>我个人从上述资料中受益匪浅，而我自己要做的整理，与原始的源码剖析有些不同，不是依照实现的模块，而是基于论文的脉络和实现这样系统的基本脉络来进行的，也算，从另一个角度给出一些东西吧。鉴于个人对于分布式系统的理解非常的浅薄，缺少足够的实践经验，深入的问题就不班门弄斧了，仅做梳理和解析，大牛至此，可绕路而行了。。。&lt;/p>
&lt;h1 id="分布式文件系统简介">分布式文件系统简介&lt;/h1>
&lt;p>相对于设备本身的文件系统而言，分布式文件系统(Distributed File System,DFS)，或者网络文件系统(Network File System,NFS)，是一种允许文件通过网络，在多台设备上分享的文件系统，可以让多个客户端设备、多用户分享同一个文件和存储空空间。DFS 一般为 C/S 模式。在这样的文件系统中，客户端并非直接访问 DFS 服务端的底层数据存储区块，而是通过网络，以特定的通信协议和服务端通信。&lt;/p>
&lt;ul>
&lt;li>用实际情况举例来说
&lt;ul>
&lt;li>node1 与 node2 是一个分布式文件系统，使用/block 目录作为 DFS 服务端底层存储数据的目录，这时候，DFS 服务端会通过某 DFS 服务将两个节点的该目录抽象成一个磁盘。&lt;/li>
&lt;li>node3 是客户端，需要挂载一个磁盘，这时候，可以直接挂载上面 DFS 服务端抽象成的磁盘，但是需要使用 DFS 服务端对应的客户端，来进行数据交互。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>总结来说，就是通过网络，把很多台设备集合起来，使用一个服务，生成一块存储空间。这块存储空间，可以在网络上给任意一台设备当做物理磁盘使用。&lt;/li>
&lt;/ul>
&lt;p>借由通信协议的设计，可以让客户端与服务端都能根据访问控制清单或授权，来限制对文件系统的访问&lt;/p>
&lt;p>CAP 定理指出：在一个分布式数据存储架构中，数据的一致性（Consistency）、可用性（Availability）、和网络分隔的容忍程度（Partition tolerance）只能取二来做最优化，无法三者兼具。当代的分布式数据存储服务均是各自针对服务的内容和性质来作取舍，很难说有哪一个是通用的最佳解。&lt;/p>
&lt;p>分布式文件系统，在整个分布式系统体系中处于最低层最基础的地位，存储嘛，没了数据，再好的计算平台，再完善的数据库系统，都成了无水之舟了。那么，什么是分布式文件系统，顾名思义，就是分布式+文件系统。它包含这两个方面的内涵，从文件系统的客户使用的角度来看，它就是一个标准的文件系统，提供了一系列 API，由此进行文件或目录的创建、移动、删除，以及对文件的读写等操作。从内部实现来看，分布式的系统则不再和普通文件系统一样负责管理本地磁盘，它的文件内容和目录结构都不是存储在本地磁盘上，而是通过网络传输到远端系统上。并且，同一个文件存储不只是在一台机器上，而是在一簇机器上分布式存储，协同提供服务，正所谓分布式。。。&lt;/p>
&lt;p>因此，考量一个分布式文件系统的实现，其实不妨可以从这两方面来分别剖析，而后合二为一。首先，看它如何去实现文件系统所需的基本增删改查的功能。然后，看它如何考虑分布式系统的特点，提供更好的容错性，负载平衡，等等之类的。这二者合二为一，就明白了一个分布式文件系统，整体的实现模式。。。&lt;/p>
&lt;p>I. 术语对照
说任何东西，都需要统一一下语言先，不然明明说的一个意思，却容易被理解到另一个地方去。Hadoop 的分布式文件系统 HDFS，基本是按照 Google 论文中的 GFS 的架构来实现的。但是，HDFS 为了彰显其不走寻常路的本性，其中的大量术语，都与 GFS 截然不同。明明都是一个枝上长的土豆，它偏偏就要叫山药蛋，弄得水火不容的，苦了我们看客。秉承老好人，谁也不得罪的方针，文中，既不采用 GFS 的叫法，也不采用 Hadoop 的称谓，而是另辟蹊径，自立门户，搞一套自己的中文翻译，为了避免不必要的痛楚，特此先来一帖术语对照表，要不懂查一查，包治百病。。。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>文中所用翻译&lt;/th>
&lt;th>HDFS 中的术语&lt;/th>
&lt;th>GFS 中的术语&lt;/th>
&lt;th>术语解释&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>主控服务器&lt;/td>
&lt;td>NameNode&lt;/td>
&lt;td>Master&lt;/td>
&lt;td>整个文件系统的大脑，它提供整个文件系统的目录信息，并且管理各个数据服务器。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据服务器&lt;/td>
&lt;td>DataNode&lt;/td>
&lt;td>Chunk Server&lt;/td>
&lt;td>分布式文件系统中的每一个文件，都被切分成若干个数据块，每一个数据块都被存储在不同的服务器上，此服务器称之为数据服务器。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据块&lt;/td>
&lt;td>Block&lt;/td>
&lt;td>Chunk&lt;/td>
&lt;td>每个文件都会被切分成若干个块，每一块都有连续的一段文件内容，是存储的基恩单位，在这里统一称做数据块。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据包&lt;/td>
&lt;td>Packet&lt;/td>
&lt;td>无&lt;/td>
&lt;td>客户端写文件的时候，不是一个字节一个字节写入文件系统的，而是累计到一定数量后，往文件系统中写入一次，每发送一次的数据，都称为一个数据包。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>传输块&lt;/td>
&lt;td>Chunk&lt;/td>
&lt;td>无&lt;/td>
&lt;td>在每一个数据包中，都会将数据切成更小的块，每一个块配上一个奇偶校验码，这样的块，就是传输块。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>备份主控服务器&lt;/td>
&lt;td>SecondaryNameNode&lt;/td>
&lt;td>无&lt;/td>
&lt;td>备用的主控服务器，在身后默默的拉取着主控服务器 的日志，等待主控服务器牺牲后被扶正。&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>II. 基本架构&lt;/p>
&lt;ol>
&lt;li>服务器介绍&lt;/li>
&lt;/ol>
&lt;p>与单机的文件系统不同，分布式文件系统不是将这些数据放在一块磁盘上，由上层操作系统来管理。而是存放在一个服务器集群上，由集群中的服务器，各尽其责，通力合作，提供整个文件系统的服务。其中重要的服务器包括：主控服务器（Master/NameNode），数据服务器（ChunkServer/DataNode），和客户服务器。HDFS 和 GFS 都是按照这个架构模式搭建的。个人觉得，其中设计的最核心内容是：文件的目录结构独立存储在一个主控服务器上，而具体文件数据，拆分成若干块，冗余的存放在不同的数据服务器上。&lt;/p>
&lt;p>存储目录结构的主控服务器，在 GFS 中称为 Master，在 HDFS 中称为 NameNode。这两个名字，叫得都有各自的理由，是瞎子摸象各表一面。Master 是之于数据服务器来叫的，它做为数据服务器的领导同志存在，管理各个数据服务器，收集它们的信息，了解所有数据服务器的生存现状，然后给它们分配任务，指挥它们齐心协力为系统服务；而 NameNode 是针对客户端来叫的，对于客户端而言，主控服务器上放着所有的文件目录信息，要找一个文件，必须问问它，由此而的此名。。。&lt;/p>
&lt;p>主控服务器在整个集群中，同时提供服务的只存在一个，如果它不幸牺牲的话，会有后备军立刻前赴后继的跟上，但，同一时刻，需要保持一山不容二虎的态势。这种设计策略，避免了多台服务器间即时同步数据的代价，而同时，它也使得主控服务器很可能成为整个架构的瓶颈所在。因此，尽量为主控服务器减负，不然它做太多的事情，就自然而然的晋升成了一个分布式文件系统的设计要求。。。&lt;/p>
&lt;p>每一个文件的具体数据，被切分成若干个数据块，冗余的存放在数据服务器。通常的配置，每一个数据块的大小为 64M，在三个数据服务器上冗余存放（这个 64M，不是随便得来的，而是经过反复实践得到的。因为如果太大，容易造成热点的堆叠，大量的操作集中在一台数据服务器上，而如果太小的话，附加的控制信息传输成本，又太高了。因此没有比较特定的业务需求，可以考虑维持此配置&amp;hellip;）。数据服务器是典型的四肢发达头脑简单的苦力，其主要的工作模式就是定期向主控服务器汇报其状况，然后等待并处理命令，更快更安全的存放好数据。。。&lt;/p>
&lt;p>此外，整个分布式文件系统还有一个重要角色是客户端。它不和主控服务和数据服务一样，在一个独立的进程中提供服务，它只是以一个类库（包）的模式存在，为用户提供了文件读写、目录操作等 APIs。当用户需要使用分布式文件系统进行文件读写的时候，把客户端相关包给配置上，就可以通过它来享受分布式文件系统提供的服务了。。。&lt;/p>
&lt;ol start="2">
&lt;li>数据分布&lt;/li>
&lt;/ol>
&lt;p>一个文件系统中，最重要的数据，其实就是整个文件系统的目录结构和具体每个文件的数据。具体的文件数据被切分成数据块，存放在数据服务器上。每一个文件数据块，在数据服务器上都表征为出双入队的一对文件（这是普通的 Linux 文件），一个是数据文件，一个是附加信息的元文件，在这里，不妨把这对文件简称为数据块文件。数据块文件存放在数据目录下，它有一个名为 current 的根目录，然后里面有若干个数据块文件和从 dir0-dir63 的最多 64 个的子目录，子目录内部结构等同于 current 目录，依次类推（更详细的描述，参见这里）。个人觉得，这样的架构，有利于控制同一目录下文件的数量，加快检索速度。。。&lt;/p>
&lt;p>这是磁盘上的物理结构，与之对应的，是内存中的数据结构，用以表征这样的磁盘结构，方便读写操作的进行。Block 类用于表示数据块，而 FSDataset 类是数据服务器管理文件块的数据结构，其中，FSDataset.FSDir 对应着数据块文件和目录，FSDataset.FSVolume 对应着一个数据目录，FSDataset.FSVolumeSet 是 FSVolume 的集合，每一个 FSDataset 有一个 FSVolumeSet。多个数据目录，可以放在不同的磁盘上，这样有利于加快磁盘操作的速度。相关的类图，可以参看这里 。。。&lt;/p>
&lt;p>此外，与 FSVolume 对应的，还有一个数据结构，就是 DataStorage，它是 Storage 的子类，提供了升级、回滚等支持。但与 FSVolume 不一样，它不需要了解数据块文件的具体内容，它只知道有这么一堆文件放这里，会有不同版本的升级需求，它会处理怎么把它们升级回滚之类的业务（关于 Storage，可以参见这里）。而 FSVolume 提供的接口，都基本上是和 Block 相关的。。。&lt;/p>
&lt;p>相比数据服务器，主控服务器的数据量不大，但逻辑更为复杂。主控服务器主要有三类数据：文件系统的目录结构数据，各个文件的分块信息，数据块的位置信息（就数据块放置在哪些数据服务器上&amp;hellip;）。在 GFS 和 HDFS 的架构中，只有文件的目录结构和分块信息才会被持久化到本地磁盘上，而数据块的位置信息则是通过动态汇总过来的，仅仅存活在内存数据结构中，机器挂了，就灰飞烟灭了。每一个数据服务器启动后，都会向主控服务器发送注册消息，将其上数据块的状况都告知于主控服务器。俗话说，简单就是美，根据 DRY 原则，保存的冗余信息越少，出现不一致的可能性越低，付出一点点时间的代价，换取了一大把逻辑上的简单性，绝对应该是一个包赚不赔的买卖。。。&lt;/p>
&lt;p>在 HDFS 中，FSNamespacesystem 类就负责保管文件系统的目录结构以及每个文件的分块状况的，其中，前者是由 FSDirectory 类来负责，后者是各个 INodeFile 本身维护。在 INodeFile 里面，有一个 BlockInfo 的数组，保存着与该文件相关的所有数据块信息，BlockInfo 中包含了从数据块到数据服务器的映射，INodeFile 只需要知道一个偏移量，就可以提供相关的数据块，和数据块存放的数据服务器信息。。。&lt;/p>
&lt;p>3、服务器间协议&lt;/p>
&lt;p>在 Hadoop 的实现中，部署了一套 RPC 机制，以此来实现各服务间的通信协议。在 Hadoop 中，每一对服务器间的通信协议，都定义成为一个接口。服务端的类实现该接口，并且建立 RPC 服务，监听相关的接口，在独立的线程处理 RPC 请求。客户端则可以实例化一个该接口的代理对象，调用该接口的相应方法，执行一次同步的通信，传入相应参数，接收相应的返回值。基于此 RPC 的通信模式，是一个消息拉取的流程，RPC 服务器等待 RPC 客户端的调用，而不会先发制人主动把相关信息推送到 RPC 客户端去。。。&lt;/p>
&lt;p>其实 RPC 的模式和原理，实在是没啥好说的，之所以说，是因为可以通过把握好这个，彻底理顺 Hadoop 各服务器间的通信模式。Hadoop 会定义一些列的 RPC 接口，只需要看谁实现，谁调用，就可以知道谁和谁通信，都做些啥事情，图中服务器的基本架构、各服务所使用的协议、调用方向、以及协议中的基本内容。。。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ynavf0/1616133332241-7377f672-ffd7-4456-93e5-15375d811257.jpeg" alt="">&lt;/p>
&lt;p>III. 基本的文件操作&lt;/p>
&lt;p>基本的文件操作，可以分成两类，一个是对文件目录结构的操作，比如文件和目录的创建、删除、移动、更名等等；另一个是对文件数据流的操作，包括读取和写入文件数据。当然，文件读和写，是有本质区别的，尤其是在数据冗余的情况下，因此，当成两类操作也不足为过。此外，要具体到读写的类别，也是可以再继续分类下去的。在 GFS 的论文中，对于分布式文件系统的读写场景有一个重要的假定（其实是从实际业务角度得来的&amp;hellip;）：就是文件的读取是由大数据量的连续读取和小数据量的随机读取组成，文件的写入则基本上都是批量的追加写，和偶尔的插入写（GFS 中还有大量的假设，它们构成了分布式文件系统架构设计的基石。每一个系统架构都是搭建在一定假设上的，这些假设有些来自于实际业务的状况，有些是因为天生的条件约束，不基于假设理解设计，肯定会有失偏颇&amp;hellip;）。在 GFS 中，对文件的写入分成追加写和插入写都有所支持，但是，在 HDFS 中仅仅支持追加写，这大大降低了复杂性。关于 HDFS 与 GFS 的一些不同，可以参看这里。。。&lt;/p>
&lt;ol>
&lt;li>文件和目录的操作&lt;/li>
&lt;/ol>
&lt;p>文件目录的信息，全部囤积在主控服务器上，因此，所有对文件目录的操作，只会直接涉及到客户端和主控服务器。整个目录相关的操作流程基本都是这样的：客户端 DFSClient 调用 ClientProtocol 定义的相关函数，该操作通过 RPC 传送到其实现者主控服务器 NameNode 那里，NameNode 做相关的处理后（很少&amp;hellip;），调用 FSNamesystem 的相关函数。在 FSNamesystem 中，往往是做一些验证和租约操作，具体的目录结构操作交由 FSDirectory 的相应函数来操作。最后，依次返回，经由 RPC 传送回客户端。具体各操作涉及到的函数和具体步骤，参见下表：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>相关操作&lt;/td>
&lt;td>ClientProtocol / NameNode&lt;/td>
&lt;td>FSNamesystem&lt;/td>
&lt;td>FSDirectory&lt;/td>
&lt;td>关键步骤&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>创建文件&lt;/td>
&lt;td>create&lt;/td>
&lt;td>startFile&lt;/td>
&lt;td>addFile&lt;/td>
&lt;td>1. 检查是否有写权限；&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>2. 检查是否已经存在此文件，如果是覆写，则先进行删除操作；
3. 在指定路径下添加 INodeFileUnderConstruction 的文件实例；
4. 写日志；
5. 签订租约。 |
| 创建目录 | mkdirs | mkdirs | mkdirs | 1. 检查指定目录是否是目录；
2. 检查是否有相关权限；
3. 在指定路径的 INode 下，添加子节点；
4. 写日志。 |
| 改名操作 | rename | renameTo | renameTo | 1. 检查相关路径的权限；
2. 从老路径下移除，在新路径下添加；
3. 修改相关父路径的修改时间；
4. 写日志；
5. 将租约从老路径移动到新路径下。 |
| 删除操作 | delete | delete | delete | 1. 如果不是递归删除，确认指定路径是否是空目录；
2. 检查相关权限；
3. 在目录结构上移除相关 INode；
4. 修改父路径的修改时间；
5. 将相关的数据块，放入到废弃队列中去，等待处理；
6. 写日志；
7. 废弃相关路径的租约。 |
| 设置权限 | setPermission | setPermission | setPermission | 1. 检查 owner 判断是否有操作权限；
2. 修改指定路径下 INode 的权限；
3. 写日志。 |
| 设置用户 | setOwner | setOwner | setOwner | 1. 检查是否有操作权限；
2. 修改指定路径下 INode 的权限；
3. 写日志。 |
| 设置时间 | setTimes | setTimes | setTimes | 1. 检查是否有写权限；
2. 修改指定路径 INode 的时间信息；
3. 写日志。 |&lt;/p>
&lt;p>从上表可以看到，其实有的操作本质上还是涉及到了数据服务器，比如文件创建和删除操作。但是，之前提到，主控服务器只于数据服务器是一个等待拉取的地位，它们不会主动联系数据服务器，将指令传输给它们，而是放到相应的数据结构中，等待数据服务器来取。这样的设计，可以减少通信的次数，加快操作的执行速度。。。&lt;/p>
&lt;p>另，上述步骤中，有些日志和租约相关的操作，从概念上来说，和目录操作其实没有任何联系，但是，为了满足分布式系统的需求，这些操作是非常有必要的，在此，按下不表。。。&lt;/p>
&lt;p>2、文件的读取&lt;/p>
&lt;p>不论是文件读取，还是文件的写入，主控服务器扮演的都是中介的角色。客户端把自己的需求提交给主控服务器，主控服务器挑选合适的数据服务器，介绍给客户端，让客户端和数据服务器单聊，要读要写随你们便。这种策略类似于 DMA，降低了主控服务器的负载，提高了效率。。。&lt;/p>
&lt;p>因此，在文件读写操作中，最主要的通信，发生在客户端与数据服务器之间。它们之间跑的协议是 ClientDatanodeProtocol。从这个协议中间，你无法看到和读写相关的接口，因为，在 Hadoop 中，读写操作是不走 RPC 机制的，而是另立门户，独立搭了一套通信框架。在数据服务器一端，DataNode 类中有一个 DataXceiverServer 类的实例，它在一个单独的线程等待请求，一旦接到，就启动一个 DataXceiver 的线程，处理此次请求。一个请求一个线程，对于数据服务器来说，逻辑上很简单。当下，DataXceiver 支持的请求类型有六种，具体的请求包和回复包格式，请参见这里，这里，这里。在 Hadoop 的实现中，并没有用类来封装这些请求，而是按流的次序写下来，这给代码阅读带来挺多的麻烦，也对代码的维护带来一定的困难，不知道是出于何种考虑。。。&lt;/p>
&lt;p>相比于写，文件的读取实在是一个简单的过程。在客户端 DFSClient 中，有一个 DFSClient.DFSInputStream 类。当需要读取一个文件的时候，会生成一个 DFSInputStream 的实例。它会先调用 ClientProtocol 定义 getBlockLocations 接口，提供给 NameNode 文件路径、读取位置、读取长度信息，从中取得一个 LocatedBlocks 类的对象，这个对象包含一组 LocatedBlock，那里面有所规定位置中包含的所有数据块信息，以及数据块对应的所有数据服务器的位置信息。当读取开始后，DFSInputStream 会先尝试从某个数据块对应的一组数据服务器中选出一个，进行连接。这个选取算法，在当下的实现中，非常简单，就是选出第一个未挂的数据服务器，并没有加入客户端与数据服务器相对位置的考量。读取的请求，发送到数据服务器后，自然会有 DataXceiver 来处理，数据被一个包一个包发送回客户端，等到整个数据块的数据都被读取完了，就会断开此链接，尝试连接下一个数据块对应的数据服务器，整个流程，依次如此反复，直到所有想读的都读取完了为止。。。&lt;/p>
&lt;p>3、文件的写入&lt;/p>
&lt;p>文件读取是一个一对一的过程，一个客户端，只需要与一个数据服务器联系，就可以获得所需的内容。但是，写入操作，则是一个一对多的流程。一次写入，需要在所有存放相关数据块的数据服务器都保持同步的更新，有任何的差池，整个流程就告失败。。。&lt;/p>
&lt;p>在分布式系统中，一旦涉及到写入操作，并发处理难免都会沦落成为一个变了相的串行操作。因为，如果不同的客户端如果是任意时序并发写入的话，整个写入的次序无法保证，可能你写半条记录我写半条记录，最后出来的结果乱七八糟不可估量。在 HDFS 中，并发写入的次序控制，是由主控服务器来把握的。当创建、续写一个文件的时候，该文件的节点类，由 INodeFile 升级成为 INodeFileUnderConstruction，INodeFileUnderConstruction 是 INodeFile 的子类，它起到一个锁的作用。如果当一个客户端想创建或续写的文件是 INodeFileUnderConstruction，会引发异常，因为这说明这个此处有爷，请另寻高就，从而保持了并发写入的次序性。同时，INodeFileUnderConstruction 有包含了此时正在操作它的客户端的信息以及最后一个数据块的数据服务器信息，当追加写的时候可以更快速的响应。。。&lt;/p>
&lt;p>与读取类似，DFSClient 也有一个 DFSClient.DFSOutputStream 类，写入开始，会创建此类的实例。DFSOutputStream 会从 NameNode 上拿一个 LocatedBlock，这里面有最后一个数据块的所有数据服务器的信息。这些数据服务器每一个都需要能够正常工作（对于读取，只要还有一个能工作的就可以实现&amp;hellip;），它们会依照客户端的位置被排列成一个有着最近物理距离和最小的序列（物理距离，是根据机器的位置定下来的&amp;hellip;），这个排序问题类似于著名旅行商问题，属于 NP 复杂度，但是由于服务器数量不多，所以用最粗暴的算法，也并不会看上去不美。。。&lt;/p>
&lt;p>文件写入，就是在这一组数据服务器上构造成数据流的双向流水线。DFSOutputStream，会与序列的第一个数据服务器建立 Socket 连接，发送请求头，然后等待回应。DataNode 同样是建立 DataXceiver 来处理写消息，DataXceiver 会依照包中传过来的其他服务器的信息，建立与下一个服务器的连接，并生成类似的头，发送给它，并等待回包。此流程依次延续，直到最后一级，它发送回包，反向着逐级传递，再次回到客户端。如果一切顺利，那么此时，流水线建立成功，开始正式发送数据。数据是分成一个个数据包发送的，所有写入的内容，被缓存在客户端，当写满 64K，会被封装成 DFSOutputStream.Packet 类实例，放入 DFSOutputStream 的 dataQueue 队列。DFSOutputStream.DataStreamer 会时刻监听这个队列，一旦不为空，则开始发送，将位于 dataQueue 队首的包移动到 ackQueue 队列的队尾，表示已发送但尚未接受回复的包队列。同时启动 ResponseProcessor 线程监听回包，直到收到相应回包，才将发送包从 ackQueue 中移除，表示成功。每一个数据服务器的 DataXceiver 收到了数据包，一边写入到本地文件中去，一边转发给下一级的数据服务器，等待回包，同前面建立流水线的流程。。。&lt;/p>
&lt;p>当一个数据块写满了之后，客户端需要向主控服务器申请追加新的数据块。这个会引起一次数据块的分配，成功后，会将新的数据服务器组返还给客户端。然后重新回到上述流程，继续前行。。。&lt;/p>
&lt;p>关于写入的流程，还可以参见这里。此外，写入涉及到租约问题，后续会仔细的来说。。。&lt;/p>
&lt;p>IV. 分布式支持&lt;/p>
&lt;p>如果单机的文件系统是田里勤恳的放牛娃，那么分布式文件系统就是刀尖上讨饭吃的马贼了。在分布式环境中，有太多的意外，数据随时传输错误，服务器时刻准备牺牲，很多平常称为异常的现象，在这里都需要按照平常事来对待。因此，对于分布式文件系统而言，仅仅是满足了正常状况下文件系统各项服务还不够，还需要保证分布式各种意外场景下健康持续的服务，否则，将一无是处。。。&lt;/p>
&lt;p>1、服务器的错误恢复&lt;/p>
&lt;p>在分布式环境中，哪台服务器牺牲都是常见的事情，牺牲不可怕，可怕的是你都没有时刻准备好它们会牺牲。作为一个合格的分布式系统，HDFS 当然时刻准备好了前赴后继奋勇向前。HDFS 有三类服务器，每一类服务器出错了，都有相应的应急策略。。。&lt;/p>
&lt;p>a. 客户端&lt;/p>
&lt;p>生命最轻如鸿毛的童鞋，应该就是客户端了。毕竟，做为一个文件系统的使用者，在整个文件系统中的地位，难免有些归于三流。而作为客户端，大部分时候，牺牲了就牺牲了，没人哀悼，无人同情，只有在在辛勤写入的时候，不幸辞世（机器挂了，或者网络断了，诸如此类&amp;hellip;），才会引起些恐慌。因为，此时此刻，在主控服务器上对应的文件，正作为 INodeFileUnderConstruction 活着，仅仅为占有它的那个客户端服务者，做为一个专一的文件，它不允许别的客户端染指。这样的话，一旦占有它的客户端服务者牺牲了，此客户端会依然占着茅坑不拉屎，让如花似玉 INodeFileUnderConstruction 孤孤单单守寡终身。这种事情当然无法容忍，因此，必须有办法解决这个问题，办法就是：租约。。。&lt;/p>
&lt;p>租约，顾名思义，就是当客户端需要占用某文件的时候，与主控服务器签订的一个短期合同。这个合同有一个期限，在这个期限内，客户端可以延长合同期限，一旦超过期限，主控服务器会强行终止此租约，将这个文件的享用权，分配给他人。。。&lt;/p>
&lt;p>在打开或创建一个文件，准备追加写之前，会调用 LeaseManager 的 addLease 方法，在指定的路径下与此客户端签订一份租约。客户端会启动 DFSClient.LeaseChecker 线程，定时轮询调用 ClientProtocol 的 renewLease 方法，续签租约。在主控服务器一端，有一个 LeaseManager.Monitor 线程，始终在轮询检查所有租约，查看是否有到期未续的租约。如果一切正常，该客户端完成写操作，会关闭文件，停止租约，一旦有所意外，比如文件被删除了，客户端牺牲了，主控服务器都会剥夺此租约，如此，来避免由于客户端停机带来的资源被长期霸占的问题。。。&lt;/p>
&lt;p>b. 数据服务器&lt;/p>
&lt;p>当然，会挂的不只是客户端，海量的数据服务器是一个更不稳定的因素。一旦某数据服务器牺牲了，并且主控服务器被蒙在鼓中，主控服务器就会变相的欺骗客户端，给它们无法连接的读写服务器列表，导致它们处处碰壁无法工作。因此，为了整个系统的稳定，数据服务器必须时刻向主控服务器汇报，保持主控服务器对其的完全了解，这个机制，就是心跳消息。在 HDFS 中，主控服务器 NameNode 实现了 DatanodeProtocol 接口，数据服务器 DataNode 会在主循环中，不停的调用该协议中的 sendHeartbeat 方法，向 NameNode 汇报状况。在此调用中，DataNode 会将其整体运行状况告知 NameNode，比如：有多少可用空间、用了多大的空间，等等之类。NameNode 会记住此 DataNode 的运行状况，作为新的数据块分配或是负载均衡的依据。当 NameNode 处理完成此消息后，会将相关的指令封装成一个 DatanodeCommand 对象，交还给 DataNode，告诉数据服务器什么数据块要删除什么数据块要新增等等之类，数据服务器以此为自己的行动依据。。。&lt;/p>
&lt;p>但是，sendHeartbeat 并没有提供本地的数据块信息给 NameNode，那么主控服务器就无法知道此数据服务器应该分配什么数据块应该删除什么数据块，那么它是如何决定的呢？答案就是 DatanodeProtocol 定义的另一个方法，blockReport。DataNode 也是在主循环中定时调用此方法，只是，其周期通常比调用 sendHeartbeat 的更长。它会提交本地的所有数据块状况给 NameNode，NameNode 会和本地保存的数据块信息比较，决定什么该删除什么该新增，并将相关结果缓存在本地对应的数据结构中，等待此服务器再发送 sendHeartbeat 消息过来的时候，依照这些数据结构中的内容，做出相应的 DatanodeCommand 指令。blockReport 方法同样也会返回一个 DatanodeCommand 给 DataNode，但通常，只是为空（只有出错的时候不为空），我想，增加缓存，也许是为了确保每个指令都可以重复发送并确定被执行。。。&lt;/p>
&lt;p>c. 主控服务器&lt;/p>
&lt;p>当然，作为整个系统的核心和单点，含辛茹苦的主控服务器含泪西去，整个分布式文件服务集群将彻底瘫痪**。如何在主控服务器牺牲后，提拔新的主控服务器并迅速使其进入工作角色，就成了系统必须考虑的问题。解决策略就是：日志。。。&lt;/p>
&lt;p>其实这并不是啥新鲜东西，一看就知道是从数据库那儿偷师而来的。在主控服务器上，所有对文件目录操作的关键步骤（具体文件内容所处的数据服务器，是不会被写入日志的，因为这些内容是动态建立的&amp;hellip;），都会被写入日志。另外，主控服务器会在某些时刻，将当下的文件目录完整的序列化到本地，这称为镜像。一旦存有镜像，镜像前期所写的日志和其他镜像，都纯属冗余，其历史使命已经完成，可以报废删除了。在主控服务器不幸牺牲，或者是战略性的停机修整结束，并重新启动后，主控服务器会根据最近的镜像 + 镜像之后的所有日志，重建整个文件目录，迅速将服务能力恢复到牺牲前的水准。。。&lt;/p>
&lt;p>对于数据服务器而言，它们会通过一些手段，迅速得知顶头上司的更迭消息。它们会立刻转投新东家的名下，在新东家旗下注册，并开始向其发送心跳消息，这个机制，可能用分布式协同服务来实现，这里不说也罢。。。&lt;/p>
&lt;p>在 HDFS 的实现中，FSEditLog 类是整个日志体系的核心，提供了一大堆方便的日志写入 API，以及日志的恢复存储等功能。目前，它支持若干种日志类型，都冠以 OP_XXX，并提供相关 API，具体可以参见这里。为了保证日志的安全性，FSEditLog 提供了 EditLogFileOutputStream 类作为写入的承载类，它会同时开若干个本地文件，然后依次写入，防止日志的损坏导致不可估量的后果。在 FSEditLog 上面，有一个 FSImage 类，存储文件镜像并调用 FSEditLog 对外提供相关的日志功能。FSImage 是 Storage 类的子类，如果对数据块的讲述有所印象的话，你可以回忆起来，凡事从此类派生出来的东西，都具有版本性质，可以进行升级和回滚等等，以此，来实现产生镜像是对原有日志和镜像处理的复杂逻辑。。。&lt;/p>
&lt;p>目前，在 HDFS 的日志系统中，有些地方与 GFS 的描述有所不同。在 HDFS 中，所有日志文件和镜像文件都是本地文件，这就相当于，把日志放在自家的保险箱中，一旦主控服务器挂了，别的后继而上的服务器也无法拿到这些日志和镜像，用于重振雄风。因此，在 HDFS 中，运行着一个 SecondaryNameNode 服务器，它做为主控服务器的替补，隐忍厚积薄发为篡位做好准备，其中，核心内容就是：定期下载并处理日志和镜像。SecondaryNameNode 看上去像客户端一样，与 NameNode 之间，走着 NamenodeProtocol 协议。它会不停的查看主控服务器上面累计日志的大小，当达到阈值后，调用 doCheckpoint 函数，此函数的主要步骤包括：&lt;/p>
&lt;p>首先是调用 startCheckpoint 做一些本地的初始化工作；&lt;/p>
&lt;p>然后调用 rollEditLog，将 NameNode 上此时操作的日志文件从 edit 切到 edit.new 上来，这个操作瞬间完成，上层写日志的函数完全感觉不到差别；&lt;/p>
&lt;p>接着，调用 downloadCheckpointFiles，将主控服务器上的镜像文件和日志文件都下载到此候补主控服务器上来；&lt;/p>
&lt;p>并调用 doMerge，打开镜像和日志，将日志生成新的镜像，保存覆盖；&lt;/p>
&lt;p>下一步，调用 putFSImage 把新的镜像上传回 NameNode；&lt;/p>
&lt;p>再调用 rollFsImage，将镜像换成新的，在日志从 edit.new 改名为 edit；&lt;/p>
&lt;p>最后，调用 endCheckpoint 做收尾工作。&lt;/p>
&lt;p>整个算法涉及到 NameNode 和 SecondaryNameNode 两个服务器，最终结果是 NameNode 和 SecondaryNameNode 都依照算法进行前的日志生成了镜像。而两个服务器上日志文件的内容，前者是整个算法进行期间所写的日志，后者始终不会有任何日志。当主控服务器牺牲的时候，运行 SecondaryNameNode 的服务器立刻被扶正，在其上启动主控服务，利用其日志和镜像，恢复文件目录，并逐步接受各数据服务器的注册，最终向外提供稳定的文件服务。。。&lt;/p>
&lt;p>同样的事情，GFS 采用的可能是另外一个策略，就是在写日志的时候，并不局限在本地，而是同时书写网络日志，即在若干个远程服务器上生成同样的日志。然后，在某些时机，主控服务器自己，生成镜像，降低日志规模。当主控服务器牺牲，可以在拥有网络日志的服务器上启动主控服务，升级成为主控服务器。。。&lt;/p>
&lt;p>GFS 与 HDFS 的策略相比较，前者是化整为零，后者则是批量处理，通常我们认为，批量处理的平均效率更高一些，且相对而言，可能实现起来容易一些，但是，由于有间歇期，会导致日志的丢失，从而无法 100%的将备份主控服务器的状态与主控服务器完全同步。。。&lt;/p>
&lt;p>2、数据的正确性保证&lt;/p>
&lt;p>在复杂纷繁的分布式环境中，我们坚定的相信，万事皆有可能。哪怕各个服务器都舒舒服服的活着，也可能有各种各样的情况导致网络传输中的数据丢失或者错误。并且在分布式文件系统中，同一份文件的数据，是存在大量冗余备份的，系统必须要维护所有的数据块内容完全同步，否则，一人一言，不同客户端读同一个文件读出不同数据，用户非得疯了不可。。。&lt;/p>
&lt;p>在 HDFS 中，为了保证数据的正确性和同一份数据的一致性，做了大量的工作。首先，每一个数据块，都有一个版本标识，在 Block 类中，用一个长整型的数 generationStamp 来表示版本信息（Block 类是所有表示数据块的数据结构的基类），一旦数据块上的数据有所变化，此版本号将向前增加。在主控服务器上，保存有此时每个数据块的版本，一旦出现数据服务器上相关数据块版本与其不一致，将会触发相关的恢复流程。这样的机制保证了各个数据服务器器上的数据块，在基本大方向上都是一致的。但是，由于网络的复杂性，简单的版本信息无法保证具体内容的一致性（因为此版本信息与内容无关，可能会出现版本相同，但内容不同的状况）。因此，为了保证数据内容上的一致，必须要依照内容，作出签名。。。&lt;/p>
&lt;p>当客户端向数据服务器追加写入数据包时，每一个数据包的数据，都会切分成 512 字节大小的段，作为签名验证的基本单位，在 HDFS 中，把这个数据段称为 Chunk，即传输块（注意，在 GFS 中，Chunk 表达的是数据块&amp;hellip;）。在每一个数据包中，都包含若干个传输块以及每一个传输块的签名，当下，这个签名是根据 Java SDK 提供的 CRC 算法算得的，其实就是一个奇偶校验。当数据包传输到流水线的最后一级，数据服务器会对其进行验证（想一想，为什么只在最后一级做验证，而不是每级都做&amp;hellip;），一旦发现当前的传输块签名与在客户端中的签名不一致，整个数据包的写入被视为无效，Lease Recover（租约恢复）算法被触发。。。&lt;/p>
&lt;p>从基本原理上看，这个算法很简单，就是取所有数据服务器上此数据块的最小长度当作正确内容的长度，将其他数据服务器上此数据块超出此长度的部分切除。从正确性上看，此算法无疑是正确的，因为至少有一个数据服务器会发现此错误，并拒绝写入，那么，如果写入了的，都是正确的；从效率上看，此算法也是高效的，因为它避免了重复的传输和复杂的验证，仅仅是各自删除尾部的一些内容即可。但从具体实现上来看，此算法稍微有些绕，因为，为了降低本已不堪重负的主控服务器的负担，此算法不是由主控服务器这个大脑发起的，而是通过选举一个数据服务器作为 Primary，由 Primary 发起，通过调用与其他各数据服务器间的 InterDatanodeProtocol 协议，最终完成的。具体的算法流程，参见 LeaseManager 类上面的注释。需要说明的是此算法的触发时机和发起者。此算法可以由客户端或者是主控服务器发起，当客户端在写入一个数据包失败后，会发起租约恢复。因为，一次写入失败，不论是何种原因，很有可能就会导致流水线上有的服务器写了，有的没写，从而造成不统一。而主控服务器发起的时机，则是在占有租约的客户端超出一定时限没有续签，这说明客户端可能挂了，在临死前可能干过不利于数据块统一的事情，作为监督者，主控服务器需要发起一场恢复运动，确保一切正确。。。&lt;/p>
&lt;p>3、负载均衡&lt;/p>
&lt;p>负载的均衡，是分布式系统中一个永恒的话题，要让大家各尽其力齐心干活，发挥各自独特的优势，不能忙得忙死闲得闲死，影响战斗力。而且，负载均衡也是一个复杂的问题，什么是均衡，是一个很模糊的概念。比如，在分布式文件系统中，总共三百个数据块，平均分配到十个数据服务器上，就算均衡了么？其实不一定，因为每一个数据块需要若干个备份，各个备份的分布应该充分考虑到机架的位置，同一个机架的服务器间通信速度更快，而分布在不同机架则更具有安全性，不会在一棵树上吊死。。。&lt;/p>
&lt;p>在这里说的负载均衡，是宽泛意义上的均衡过程，主要涵盖两个阶段的事务，一个是在任务初始分配的时候尽可能合理分配，另一个是在事后时刻监督及时调整。。。&lt;/p>
&lt;p>在 HDFS 中，ReplicationTargetChooser 类，是负责实现为新分配的数据块寻找婆家的。基本上来说，数据块的分配工作和备份的数量、申请的客户端地址（也就是写入者）、已注册的数据服务器位置，密切相关。其算法基本思路是只考量静态位置信息，优先照顾写入者的速度，让多份备份分配到不同的机架去。具体算法，自行参见源码。此外，HDFS 的 Balancer 类，是为了实现动态的负载调整而存在的。Balancer 类派生于 Tool 类，这说明，它是以一个独立的进程存在的，可以独立的运行和配置。它运行有 NamenodeProtocol 和 ClientProtocol 两个协议，与主控服务器进行通信，获取各个数据服务器的负载状况，从而进行调整。主要的调整其实就是一个操作，将一个数据块从一个服务器搬迁到另一个服务器上。Balancer 会向相关的目标数据服务器发出一个 DataTransferProtocol.OP_REPLACE_BLOCK 消息，接收到这个消息的数据服务器，会将数据块写入本地，成功后，通知主控服务器，删除早先的那个数据服务器上的同一块数据块。具体的算法请自行参考源码。。。&lt;/p>
&lt;p>4、垃圾回收&lt;/p>
&lt;p>对于垃圾，大家应该耳熟能详了，在分布式文件系统而言，没有利用价值的数据块备份，就是垃圾。在现实生活中，我们提倡垃圾分类，为了更好的理解分布式文件系统的垃圾收集，搞个分类也是很有必要的。基本上，所有的垃圾都可以视为两类，一类是由系统正常逻辑产生的，比如某个文件被删除了，所有相关的数据块都沦为垃圾了，某个数据块被负载均衡器移动了，原始数据块也不幸成了垃圾了。此类垃圾最大的特点，就是主控服务器是生成垃圾的罪魁祸首，也就是说主控服务器完全了解有哪些垃圾需要处理。另外还有一类垃圾，是由于系统的一些异常症状产生的，比如某个数据服务器停机了一段，重启之后发现其上的某个数据块已经在其他服务器上重新增加了此数据块的备份，它上面的那个备份过期了失去价值了，需要被当作垃圾来处理了。此类垃圾的特点恰恰相反，主控服务器无法直接了解到垃圾状况，需要曲线救国。。。&lt;/p>
&lt;p>在 HDFS 中，第一类垃圾的判定自然很容易，在一些正常的逻辑中产生的垃圾，全部被塞进了 FSNamesystem 的 recentInvalidateSets 这个 Map 中。而第二类垃圾的判定，则放在数据服务器发送其数据块信息来的过程中，经过与本地信息的比较，可以断定，此数据服务器上有哪些数据块已经不幸沦为垃圾。同样，这些垃圾也被塞到 recentInvalidateSets 中去。在与数据服务器进行心跳交流的过程中，主控服务器会将它上面有哪些数据块需要删除，数据服务器对这些数据块的态度是，直接物理删除。在 GFS 的论文中，对如何删除一个数据块有着不同的理解，它觉着应该先缓存起来，过几天没人想恢复它了再删除。在 HDFS 的文档中，则明确表示，在现行的应用场景中，没有需要这个需求的地方，因此，直接删除就完了。这说明，理念是一切分歧的根本：）。。。&lt;/p>
&lt;p>V. 总结&lt;/p>
&lt;p>整个分布式文件系统，计算系统，数据库系统的设计理念，基本是一脉相承的。三类服务器、作为单点存在的核心控制服务器、基于日志的恢复机制、基于租约的保持联系机制、等等，在后续分布式计算系统和分布式数据库中都可以看到类似的影子，在分布式文件系统这里，我详述了这些内容，可能在后续就会默认知道而说的比较简略了。而刨去这一些，分布式文件系统中最大特点，就是文件块的冗余存储，它直接导致了较为复杂的写入流程。当然，虽说分布式文件系统在分布式计算和数据库中都有用到，但如果对其机理没有兴趣，只要把它当成是一个可以在任何机器上使用的文件系统，就不会对其他上层建筑的理解产生障碍。。。&lt;/p></description></item><item><title>Docs: Etcd</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io/">官网&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://etcd.io/docs/">官方文档&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://juejin.cn/post/6844904031186321416">掘金 etcd 万字长文&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.tencent.com/developer/article/1754878">腾讯云社区上的 etcd 万字长文&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Etcd 是 CoreOS 基于&lt;a href="https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95.md"> Raft 共识算法&lt;/a> 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障(如数据库选主、分布式锁等)。&lt;/p>
&lt;ul>
&lt;li>基本的 key-value 存储，后端存储采用的是 BBolt 存储引擎，其前身是 BoltDB ，这是一款 golang 实现的嵌入式 KV 存储引擎，参考的是 LMDB，支持事务、ACID、MVCC、ZeroCopy、BTree 等特性。&lt;/li>
&lt;li>监听机制&lt;/li>
&lt;li>key 的过期及续约机制，用于监控和服务发现&lt;/li>
&lt;li>原子 CAS 和 CAD，用于分布式锁和 leader 选举
&lt;ul>
&lt;li>选举机制详见：[Etcd 基于 RAFT 的一致性](✏IT 学习笔记/📼5.数据存储/2.数据库/键值数据/Etcd/Etcd%20 基于%20RAFT%20 的一致性.md 基于 RAFT 的一致性.md)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="glossary术语">Glossary(术语)&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>官方文档：&lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/glossary.md">https://github.com/etcd-io/etcd/blob/master/Documentation/learning/glossary.md&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;ul>
&lt;li>&lt;strong>Raft&lt;/strong> # etcd 所采用的保证分布式系统强一致性的算法。&lt;/li>
&lt;li>**Endpoint(端点) **# 指向 etcd 服务或资源的 URL 。比如 &lt;a href="http://172.38.40.212:2379">http://172.38.40.212:2379&lt;/a> 就是 etcd 中的一个 endpoint ，这个 endpoint 指向了 172.38.40.212 设备的 2379 端口上的 etcd&lt;/li>
&lt;li>&lt;strong>Node&lt;/strong> # 一个 Raft 状态机实例。&lt;/li>
&lt;li>&lt;strong>Member(成员)&lt;/strong> # 一个 etcd 实例。它管理着一个 Node，并且可以为客户端请求提供服务。
&lt;ul>
&lt;li>Member 是组成 etcd cluster 的一部分。一个逻辑概念，是集群中提供服务的 etcd 服务器。可以为一个 member 单独定义一个名字和描述等信息。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Cluster(集群)&lt;/strong> # 由多个 Member 构成可以协同工作的 etcd 集群。&lt;/li>
&lt;li>&lt;strong>Peer&lt;/strong> # 对同一个 etcd 集群中另外一个 Member 的称呼。&lt;/li>
&lt;li>&lt;strong>Client&lt;/strong> # 向 etcd 集群发送 HTTP 请求的客户端。&lt;/li>
&lt;li>&lt;strong>WAL&lt;/strong> # 预写式日志，etcd 用于持久化存储的日志格式。&lt;/li>
&lt;li>&lt;strong>snapshot&lt;/strong> # etcd 防止 WAL 文件过多而设置的快照，存储 etcd 数据状态。&lt;/li>
&lt;li>&lt;strong>Proxy&lt;/strong> # etcd 的一种模式，为 etcd 集群提供反向代理服务。&lt;/li>
&lt;li>&lt;strong>Leader&lt;/strong> # Raft 算法中通过竞选而产生的处理所有数据提交的节点。&lt;/li>
&lt;li>&lt;strong>Follower&lt;/strong> # 竞选失败的节点作为 Raft 中的从属节点，为算法提供强一致性保证。&lt;/li>
&lt;li>&lt;strong>Candidate&lt;/strong> # 当 Follower 超过一定时间接收不到 Leader 的心跳时转变为 Candidate 开始竞选。&lt;/li>
&lt;li>&lt;strong>Term&lt;/strong> # Raft 算法中的概念。某个节点成为 Leader 到下一次竞选时间，称为一个 Term。&lt;/li>
&lt;li>&lt;strong>Index&lt;/strong> # 数据项编号。Raft 中通过 Term 和 Index 来定位数据。&lt;/li>
&lt;/ul>
&lt;h1 id="etcd-工作方式简述">Etcd 工作方式简述&lt;/h1>
&lt;p>每个 etcd 一般使用两个端口进行工作，一个端口面向客户端提供服务(2379)，另一个端口集群内部通信(2380)。可以将 etcd 端口设置为接受 TLS 流量，非 TLS 流量，或同时接受 TLS 和非 TLS 流量。&lt;/p>
&lt;h3 id="数据读写顺序">数据读写顺序&lt;/h3>
&lt;p>为了保证数据的强一致性，etcd 集群中所有的数据流向都是一个方向，从 Leader （主节点）流向 Follower，也就是所有 Follower 的数据必须与 Leader 保持一致，如果不一致会被覆盖。&lt;/p>
&lt;p>用户对于 etcd 集群所有节点进行读写&lt;/p>
&lt;ul>
&lt;li>读取：由于集群所有节点数据是强一致性的，读取可以从集群中随便哪个节点进行读取数据&lt;/li>
&lt;li>写入：etcd 集群有 leader，如果写入往 leader 写入，可以直接写入，然后然后 Leader 节点会把写入分发给所有 Follower，如果往 follower 写入，然后 Leader 节点会把写入分发给所有 Follower&lt;/li>
&lt;/ul>
&lt;h3 id="leader-选举">leader 选举&lt;/h3>
&lt;p>假设三个节点的集群，三个节点上均运行 Timer（每个 Timer 持续时间是随机的），Raft 算法使用随机 Timer 来初始化 Leader 选举流程，第一个节点率先完成了 Timer，随后它就会向其他两个节点发送成为 Leader 的请求，其他节点接收到请求后会以投票回应然后第一个节点被选举为 Leader。&lt;/p>
&lt;p>成为 Leader 后，该节点会以固定时间间隔向其他节点发送通知，确保自己仍是 Leader。有些情况下当 Follower 们收不到 Leader 的通知后，比如说 Leader 节点宕机或者失去了连接，其他节点会重复之前选举过程选举出新的 Leader。&lt;/p>
&lt;h3 id="判断数据是否写入">判断数据是否写入&lt;/h3>
&lt;p>etcd 认为写入请求被 Leader 节点处理并分发给了多数节点后，就是一个成功的写入。那么多少节点如何判定呢，假设总结点数是 N，那么多数节点 &lt;code>Quorum=N/2+1&lt;/code>。关于如何确定 etcd 集群应该有多少个节点的问题，上图的左侧的图表给出了集群中节点总数(Instances)对应的 Quorum 数量，用 Instances 减去 Quorom 就是集群中容错节点（允许出故障的节点）的数量。&lt;/p>
&lt;p>所以在集群中推荐的最少节点数量是 3 个，因为 1 和 2 个节点的容错节点数都是 0，一旦有一个节点宕掉整个集群就不能正常工作了。&lt;/p>
&lt;h2 id="etcd-监控指标">Etcd 监控指标：&lt;/h2>
&lt;p>官方文档：&lt;a href="https://etcd.io/docs/latest/op-guide/monitoring/">https://etcd.io/docs/latest/op-guide/monitoring/&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>ID：3070 是一个不错的 grafana dashboard&lt;/p>
&lt;/blockquote>
&lt;p>每个 etcd 服务器在 /metrics 路径下暴露 metrics 。默认在 http://ETCDIP:2379/metrics 下。&lt;/p>
&lt;p>可以使用 &amp;ndash;listen-metrics-urls 参数单独指定 etcd 要暴露 metrics 的 ip 和 port。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#f92672">]&lt;/span>$ curl -L http://localhost:2379/metrics | grep -v debugging &lt;span style="color:#75715e"># ignore unstable debugging metrics&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># HELP etcd_disk_backend_commit_duration_seconds The latency distributions of commit called by backend.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># TYPE etcd_disk_backend_commit_duration_seconds histogram&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>etcd_disk_backend_commit_duration_seconds_bucket&lt;span style="color:#f92672">{&lt;/span>le&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.002&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#ae81ff">72756&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>etcd_disk_backend_commit_duration_seconds_bucket&lt;span style="color:#f92672">{&lt;/span>le&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.004&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#ae81ff">401587&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>etcd_disk_backend_commit_duration_seconds_bucket&lt;span style="color:#f92672">{&lt;/span>le&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.008&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#ae81ff">405979&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>etcd_disk_backend_commit_duration_seconds_bucket&lt;span style="color:#f92672">{&lt;/span>le&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.016&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#ae81ff">406464&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="健康检查">健康检查&lt;/h3>
&lt;p>从 v3.3.0 开始，除了响应 /metrics 端点之外，&amp;ndash;listen-metrics-urls 参数指定的任何位置也将响应 /health 端点。如果标准端点配置了相互（客户机）TLS 身份验证，但负载平衡器或监视服务仍需要访问运行状况检查，则此功能非常有用。&lt;/p>
&lt;h1 id="etcd-关联文件与配置">Etcd 关联文件与配置&lt;/h1>
&lt;p>/var/lib/etcd/* # Etcd 数据存储目录。该目录为默认目录，可以在配置文件的 ETCD_DATA_DIR 字段中修改路径
/etc/etcd/etcd.conf # 基本配置文件
/etc/etcd/etcd.conf.yaml # 与基本配置文件类似，可以已 yaml 的形式写配置文件。&lt;/p>
&lt;p>下面是基本配置文件的示例&lt;/p>
&lt;pre>&lt;code>#[Member]
ETCD_DATA_DIR=&amp;quot;/PATH&amp;quot; #etcd中的数据是基于内存的Key/Val存储，持久化之后，需要保存的目录即在此配置中定义
ETCD_LISTEN_PEER_URLS=&amp;quot;Protocol://IP:PORT,....&amp;quot; #指定etcd集群内互相通信时所监听的端口，默认2380
ETCD_LISTEN_CLIENT_URLS=&amp;quot;Protocol://IP:PORT,...&amp;quot; #指定etcd与其客户端(apiserver)通信时所监听的端口，默认2379
ETCD_NAME=&amp;quot;HostName&amp;quot; #指定etcd所在节点的主机名
ETCD_SNAPSHOT_COUNT=&amp;quot;NUM&amp;quot; #指定可以快照多少次，默认100000,
#[Clustering]
ETCD_INITAL_ADVERTISE_PEER_URLS=&amp;quot;Protocol://{IP|HostName}:PORT,....&amp;quot; #一个声明，指定对外广告的etcd集群内互相通信时所监听的端口
ETCD_ADVERTISE_CLIENT_URLS=&amp;quot;Protocol://{IP|HostName}:PORT,....&amp;quot; #一个声明，指定对外广告的etcd与其客户端(apiserver)通信时所监听的端口
ETCD_INITIAL_CLUSTER=&amp;quot;HostName1=Protocol://HostName1:PORT,HostName2=Protocol://HostName2:PORT,.......&amp;quot; #指定etcd集群初始成员信息，集群中有几个etcd就用写几个
#[Proxy]
#ETCD_PROXY=&amp;quot;off&amp;quot;
#ETCD_PROXY_FAILURE_WAIT=&amp;quot;5000&amp;quot; #
#ETCD_PROXY_REFRESH_INTERVAL=&amp;quot;30000&amp;quot; #
#ETCD_PROXY_DIAL_TIMEOUT=&amp;quot;1000&amp;quot; #
#ETCD_PROXY_WRITE_TIMEOUT=&amp;quot;5000&amp;quot; #
#ETCD_PROXY_READ_TIMEOUT=&amp;quot;0&amp;quot; #
#[Security]
ETCD_CERT_FILE=&amp;quot;/PATH/FILE&amp;quot; #指定集群与客户端通信时所用的服务端证书
ETCD_KEY_FILE=&amp;quot;/PATH/FILE&amp;quot; #指定集群与客户端通信时所用的服务端证书的私钥
ETCD_CLIENT_CERT_AUTH=&amp;quot;false|ture&amp;quot; #指明是否验证客户端证书
ETCD_TRUSTED_CA_FILE=&amp;quot;/PATH/FILE&amp;quot; ##指定签署服务端证书的CA证书
ETCD_AUTO_TLS=&amp;quot;false|ture&amp;quot; #是否让etcd自动生成服务端证书
ETCD_PEER_CERT_FILE=&amp;quot;/PATH/FILE&amp;quot; #指定集群间通信时所用的证书
ETCD_PEER_KEY_FILE=&amp;quot;/PATH/FILE&amp;quot; #指定集群间通信时所用的证书的私钥
ETCD_PEER_CLIENT_CERT_AUTH=&amp;quot;false|ture&amp;quot; #指明是否验证客户端(即apiserver)的证书(peer模式中各节点互为服务端和客户端)
ETCD_PEER_TRUSTED_CA_FILE=&amp;quot;/PATH/FILE&amp;quot; #指定签署peer证书的CA证书
ETCD_PEER_AUTO_TLS=&amp;quot;false|ture&amp;quot; #是否让etcd自动生成peer证书
#[Logging]
#ETCD_DEBUG=&amp;quot;false&amp;quot; #
#ETCD_LOG_PACKAGE_LEVELS=&amp;quot;&amp;quot; #
#ETCD_LOG_OUTPUT=&amp;quot;default&amp;quot; #
#[Unsafe]
#ETCD_FORCE_NEW_CLUSTER=&amp;quot;false&amp;quot; #
#[Version]
#ETCD_VERSION=&amp;quot;false&amp;quot; #
#ETCD_AUTO_COMPACTION_RETENTION=&amp;quot;0&amp;quot; #
#[Profiling]
#ETCD_ENABLE_PPROF=&amp;quot;false&amp;quot; #
#ETCD_METRICS=&amp;quot;basic&amp;quot; #
#[Auth]
#ETCD_AUTH_TOKEN=&amp;quot;simple&amp;quot; #
&lt;/code>&lt;/pre>
&lt;h1 id="etcd-架构">Etcd 架构&lt;/h1>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796826-e3ea264c-885a-49c9-b416-06f0bf2f90ed.png" alt="">&lt;/p>
&lt;p>从 etcd 的架构图中我们可以看到，etcd 主要分为四个部分。&lt;/p>
&lt;ul>
&lt;li>HTTP Server：用于处理用户发送的 API 请求以及其它 etcd 节点的同步与心跳信息请求。&lt;/li>
&lt;li>Store：用于处理 etcd 支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等等，是 etcd 对用户提供的大多数 API 功能的具体实现。&lt;/li>
&lt;li>Raft：Raft 强一致性算法的具体实现，是 etcd 的核心。&lt;/li>
&lt;li>WAL：Write Ahead Log（预写式日志），是 etcd 的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd 就通过 WAL 进行持久化存储。WAL 中，所有的数据提交前都会事先记录日志。
&lt;ul>
&lt;li>Snapshot 是为了防止数据过多而进行的状态快照；&lt;/li>
&lt;li>Entry 表示存储的具体日志内容。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>通常，一个用户的请求发送过来，会经由 HTTP Server 转发给 Store 进行具体的事务处理，如果涉及到节点的修改，则交给 Raft 模块进行状态的变更、日志的记录，然后再同步给别的 etcd 节点以确认数据提交，最后进行数据的提交，再次同步。&lt;/p>
&lt;h1 id="etcd-应用场景">Etcd 应用场景&lt;/h1>
&lt;h2 id="31-服务注册与发现">3.1 服务注册与发现&lt;/h2>
&lt;p>etcd 可以用于服务的注册与发现&lt;/p>
&lt;ul>
&lt;li>前后端业务注册发现&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796808-e6ed3149-9eed-470a-9087-57aceb2dae5f.webp" alt="">&lt;/p>
&lt;p>中间价已经后端服务在 etcd 中注册，前端和中间价可以很轻松的从 etcd 中发现相关服务器然后服务器之间根据调用关系相关绑定调用&lt;/p>
&lt;ul>
&lt;li>多组后端服务器注册发现&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796829-3feff5ec-d633-4d98-94c9-586dff97110b.webp" alt="">&lt;/p>
&lt;p>后端多个无状态相同副本的 app 可以同事注册到 etcd 中，前端可以通过 haproxy 从 etcd 中获取到后端的 ip 和端口组，然后进行请求转发，可以用来故障转移屏蔽后端端口已经后端多组 app 实例。&lt;/p>
&lt;h2 id="32-消息发布与订阅">3.2 消息发布与订阅&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796813-0167a273-8ea1-4594-84d6-7453ecaafbda.webp" alt="">&lt;/p>
&lt;p>etcd 可以充当消息中间件，生产者可以往 etcd 中注册 topic 并发送消息，消费者从 etcd 中订阅 topic，来获取生产者发送至 etcd 中的消息。&lt;/p>
&lt;h2 id="33-负载均衡">3.3 负载均衡&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796852-c515c4de-effd-4a85-b3e6-67aa0ff98665.webp" alt="">&lt;/p>
&lt;p>后端多组相同的服务提供者可以经自己服务注册到 etcd 中，etcd 并且会与注册的服务进行监控检查，服务请求这首先从 etcd 中获取到可用的服务提供者真正的 ip:port，然后对此多组服务发送请求，etcd 在其中充当了负载均衡的功能&lt;/p>
&lt;h2 id="34-分部署通知与协调">3.4 分部署通知与协调&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796815-22640fce-a1d8-4364-bfbc-f138d85a04df.webp" alt="">&lt;/p>
&lt;ul>
&lt;li>当 etcd watch 服务发现丢失，会通知服务检查&lt;/li>
&lt;li>控制器向 etcd 发送启动服务，etcd 通知服务进行相应操作&lt;/li>
&lt;li>当服务完成 work 会讲状态更新至 etcd，etcd 对应会通知用户&lt;/li>
&lt;/ul>
&lt;h2 id="35-分布式锁">3.5 分布式锁&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796823-f19aa84e-8a3e-4e0a-85f2-a464b8faf1e6.webp" alt="">&lt;/p>
&lt;p>当有多个竞争者 node 节点，etcd 作为总控，在分布式集群中与一个节点成功分配 lock&lt;/p>
&lt;h2 id="36-分布式队列">3.6 分布式队列&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796858-7ab4d693-a873-4932-b5c2-74fe5cb92fe8.webp" alt="">&lt;/p>
&lt;p>有对个 node，etcd 根据每个 node 来创建对应 node 的队列，根据不同的队列可以在 etcd 中找到对应的 competitor&lt;/p>
&lt;h2 id="37-集群与监控与-leader-选举">3.7 集群与监控与 Leader 选举&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ummz3n/1616136796814-3cb985e2-3fb5-4778-b8d7-06453c189268.webp" alt="">&lt;/p>
&lt;p>etcd 可以根据 raft 算法在多个 node 节点来选举出 leader&lt;/p>
&lt;h1 id="重大变化">重大变化&lt;/h1>
&lt;p>2022 年 8 月 22 日
众所周知，etcd 是 Kubernetes 的核心组件之一，同时它也被大量其他的开源项目所依赖，比如 Apache APISIX 也是使用 etcd 作为其默认的数据存储的。
但是 etcd 最早的两个维护者，基本上都由于工作变动的原因已经不在 etcd 项目中积极活跃了。后来社区中剩余的一些贡献者开始承担起了该项目的维护工作。
在几个月之前，etcd 项目现有的维护者们，由于难以达到大多数人的同意，也发起了一次社区治理方案的调整，在决策时改成了惰性共识 &lt;a href="https://github.com/etcd-io/etcd/pull/14053">https://github.com/etcd-io/etcd/pull/14053&lt;/a>
当前 CNCF TOC 正在讨论 etcd 项目的健康度问题，也许我们可以做点什么，让这个项目变的更好。&lt;/p></description></item><item><title>Docs: Etcd API 文档</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-api-%E6%96%87%E6%A1%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-api-%E6%96%87%E6%A1%A3/</guid><description>
&lt;p>&lt;a href="https://github.com/etcd-io/website/blob/master/static/apispec/swagger/rpc.swagger.json">https://github.com/etcd-io/website/blob/master/static/apispec/swagger/rpc.swagger.json&lt;/a>&lt;/p></description></item><item><title>Docs: Etcd Maintenacne(维护) 指南</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-maintenacne%E7%BB%B4%E6%8A%A4-%E6%8C%87%E5%8D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-maintenacne%E7%BB%B4%E6%8A%A4-%E6%8C%87%E5%8D%97/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/maintenance.md">GitHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://etcd.io/docs/latest/op-guide/maintenance/">官方文档,-运维指南-维护&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Etcd 集群需要定期维护才能保持可靠性。根据 etcd 应用程序的需求，通常可以自动执行该维护，而无需停机或性能显着降低。&lt;/p>
&lt;p>所有 etcd 维护都管理 etcd 键空间消耗的存储资源。存储空间配额可以防止无法充分控制键空间大小；如果 etcd 成员的空间不足，则配额将触发群集范围的警报，这将使系统进入有限操作维护模式。为了避免空间不足以写入键空间，必须压缩 etcd 键空间历史记录。可以通过对 etcd 成员进行碎片整理来回收存储空间本身。最后，etcd 成员状态的定期快照备份使恢复由于操作错误引起的意外逻辑数据丢失或损坏成为可能。&lt;/p>
&lt;h1 id="raft-log-retentionraft-日志保留">Raft Log Retention(Raft 日志保留)&lt;/h1>
&lt;h1 id="defragmentation碎片整理">Defragmentation(碎片整理)&lt;/h1>
&lt;h1 id="etcd-space-quotaetcd-空间配额">Etcd Space Quota(Etcd 空间配额)&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io/docs/v3.5/op-guide/maintenance/#space-quota">官方文档，运维指南-维护-空间配额&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>etcd 通过 &lt;strong>Space Quota(空间配额)&lt;/strong> 确保集群以可靠的方式运行，空间配额指的是 etcd 可以储存的数据量上限。没有空间配额，如果密钥空间过大，etcd 可能会遭受性能不佳的影响，或者它可能只是用尽了存储空间，从而导致了不可预测的集群行为。&lt;/p>
&lt;p>默认情况下，etcd 的空间配额适合大多数应用程序的使用情况。不过，可以通过 quota-backend-bytes 命令行参数修改配额的值&lt;/p>
&lt;p>注意如果 etcd 中的数据超&lt;strong>过了配额的值&lt;/strong>，则&lt;strong>无法再写入新数据&lt;/strong>。并且 etcd 会在集群中发出一个 alarm(警报)，该警报会告诉各节点，并且集群将会变为 maintenance mode(维护模式)，处于维护模式的集群仅接受 key 的读取和删除操作。并且如果想让集群恢复正常运行，需要进行如下操作&lt;/p>
&lt;h3 id="测试用写入数据触发告警">(测试用)写入数据触发告警&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 使用一个循环填满 keyspace(键空间)，空间爆满后，触发了告警&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># while [ 1 ]; do dd if=/dev/urandom bs=1024 count=1024 | etcdctl put key || break; done&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">1048576&lt;/span> bytes &lt;span style="color:#f92672">(&lt;/span>1.0 MB, 1.0 MiB&lt;span style="color:#f92672">)&lt;/span> copied, 0.0132167 s, 79.3 MB/s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;level&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;warn&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;ts&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2020-11-19T22:20:16.018+0800&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;caller&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;clientv3/retry_interceptor.go:62&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;msg&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;retrying of unary invoker failed&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;target&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;endpoint://client-e3fb4b20-987e-4de7-b6d4-bb41ceb2ff59/127.0.0.1:2379&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;attempt&amp;#34;&lt;/span>:0,&lt;span style="color:#e6db74">&amp;#34;error&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;rpc error: code = ResourceExhausted desc = etcdserver: mvcc: database space exceeded&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Error: etcdserver: mvcc: database space exceeded
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 查看 etcd 状态，也可以看到告警，告警内容 alarm: NOSPACE&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># etcdctl endpoint status -wtable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------------------------------+
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------------------------------+
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| 127.0.0.1:2379 | 656f8f6ebad83496 | 3.4.13 | 2.2 GB | true | false | &lt;span style="color:#ae81ff">2&lt;/span> | &lt;span style="color:#ae81ff">28412&lt;/span> | &lt;span style="color:#ae81ff">28412&lt;/span> | memberID:7309218425989510294 |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| | | | | | | | | | alarm:NOSPACE |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------------------------------+
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 此时已经无法向 etcd 中写入数据&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># etcdctl put /hello world&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;level&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;warn&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;ts&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2020-11-19T22:35:16.870+0800&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;caller&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;clientv3/retry_interceptor.go:62&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;msg&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;retrying of unary invoker failed&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;target&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;endpoint://client-ed96eb23-4bc4-41e9-84bf-1a357fde2b6f/127.0.0.1:2379&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;attempt&amp;#34;&lt;/span>:0,&lt;span style="color:#e6db74">&amp;#34;error&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;rpc error: code = ResourceExhausted desc = etcdserver: mvcc: database space exceeded&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Error: etcdserver: mvcc: database space exceeded
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="释放足够的空间并对数据库进行碎片整理">释放足够的空间并对数据库进行碎片整理&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 获取当前 revision&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># rev=$(etcdctl endpoint status --write-out=&amp;#34;json&amp;#34; | egrep -o &amp;#39;&amp;#34;revision&amp;#34;:[0-9]*&amp;#39; | egrep -o &amp;#39;[0-9].*&amp;#39;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 压缩所有旧的 revisions&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># etcdctl compaction $rev&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>compacted revision &lt;span style="color:#ae81ff">28406&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 使用碎片整理，处理多余的空间&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># etcdctl defrag&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Finished defragmenting etcd member&lt;span style="color:#f92672">[&lt;/span>127.0.0.1:2379&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="清除警报">清除警报&lt;/h3>
&lt;pre>&lt;code># 解除告警
[root@lichenhao ~]# etcdctl alarm disarm
memberID:7309218425989510294 alarm:NOSPACE
&lt;/code>&lt;/pre>
&lt;p>etcd_mvcc_db_total_size_in_use_in_bytes 指标指示历史记录压缩后的实际数据库使用情况 etcd_mvcc_db_total_size_in_bytes 指标则显示数据库大小，包括等待进行碎片整理的可用空间。后者仅在前者接近时才增加，这意味着当这两个指标都接近配额时，需要进行历史压缩以避免触发空间配额告警。&lt;/p></description></item><item><title>Docs: Etcd 部署</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E9%83%A8%E7%BD%B2/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io/docs/latest/op-guide/container/">官方文档&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>etcd 可以通过多种方式部署。如果要启动 etcd 集群，则每种部署方式，都需要配置最基本标志为以下几个：&lt;/p>
&lt;ul>
&lt;li>--name # etcd 集群中的节点名，这里可以随意，可区分且不重复就行&lt;/li>
&lt;li>--listen-peer-urls # 监听的用于节点之间通信的 url，可监听多个，集群内部将通过这些 url 进行数据交互(如选举，数据同步等)&lt;/li>
&lt;li>--initial-advertise-peer-urls # 建议用于节点之间通信的 url，节点间将以该值进行通信。&lt;/li>
&lt;li>--listen-client-urls # 监听的用于客户端通信的 url，同样可以监听多个。&lt;/li>
&lt;li>--advertise-client-urls # 建议使用的客户端通信 url，该值用于 etcd 代理或 etcd 成员与 etcd 节点通信。&lt;/li>
&lt;li>--initial-cluster-token etcd-cluster-1 # 节点的 token 值，设置该值后集群将生成唯一 id，并为每个节点也生成唯一 id，当使用相同配置文件再启动一个集群时，只要该 token 值不一样，etcd 集群就不会相互影响。&lt;/li>
&lt;li>--initial-cluster # 也就是集群中所有的 initial-advertise-peer-urls 的合集。&lt;/li>
&lt;li>--initial-cluster-state new # 新建集群的标志&lt;/li>
&lt;/ul>
&lt;p>如果是单节点部署，则直接启动即可。&lt;/p>
&lt;h1 id="使用二进制文件部署-etcd">使用二进制文件部署 etcd&lt;/h1>
&lt;p>直接使用 yum install etcd -y 命令即可安装&lt;/p>
&lt;h1 id="在容器内运行-etcd">在容器内运行 etcd&lt;/h1>
&lt;p>运行一个单节点的 etcd&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>export NODE1&lt;span style="color:#f92672">=&lt;/span>192.168.1.21
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 配置Docker卷以存储etcd数据：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker volume create --name etcd-data
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export DATA_DIR&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;etcd-data&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 运行最新版本的etcd：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>REGISTRY&lt;span style="color:#f92672">=&lt;/span>quay.io/coreos/etcd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># available from v3.2.5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>REGISTRY&lt;span style="color:#f92672">=&lt;/span>gcr.io/etcd-development/etcd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2379:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2380:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --volume&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>DATA_DIR&lt;span style="color:#e6db74">}&lt;/span>:/etcd-data &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --name etcd &lt;span style="color:#e6db74">${&lt;/span>REGISTRY&lt;span style="color:#e6db74">}&lt;/span>:latest &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /usr/local/bin/etcd &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --data-dir&lt;span style="color:#f92672">=&lt;/span>/etcd-data --name node1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-advertise-peer-urls http://&lt;span style="color:#e6db74">${&lt;/span>NODE1&lt;span style="color:#e6db74">}&lt;/span>:2380 --listen-peer-urls http://0.0.0.0:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --advertise-client-urls http://&lt;span style="color:#e6db74">${&lt;/span>NODE1&lt;span style="color:#e6db74">}&lt;/span>:2379 --listen-client-urls http://0.0.0.0:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-cluster node1&lt;span style="color:#f92672">=&lt;/span>http://&lt;span style="color:#e6db74">${&lt;/span>NODE1&lt;span style="color:#e6db74">}&lt;/span>:2380
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="部署-3-节点-etcd-集群">部署 3 节点 etcd 集群&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>REGISTRY&lt;span style="color:#f92672">=&lt;/span>quay.io/coreos/etcd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># available from v3.2.5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>REGISTRY&lt;span style="color:#f92672">=&lt;/span>gcr.io/etcd-development/etcd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># For each machine&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ETCD_VERSION&lt;span style="color:#f92672">=&lt;/span>latest
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>TOKEN&lt;span style="color:#f92672">=&lt;/span>my-etcd-token
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CLUSTER_STATE&lt;span style="color:#f92672">=&lt;/span>new
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME_1&lt;span style="color:#f92672">=&lt;/span>etcd-node-0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME_2&lt;span style="color:#f92672">=&lt;/span>etcd-node-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME_3&lt;span style="color:#f92672">=&lt;/span>etcd-node-2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>HOST_1&lt;span style="color:#f92672">=&lt;/span>10.20.30.1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>HOST_2&lt;span style="color:#f92672">=&lt;/span>10.20.30.2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>HOST_3&lt;span style="color:#f92672">=&lt;/span>10.20.30.3
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CLUSTER&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>NAME_1&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#f92672">=&lt;/span>http://&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span>:2380,&lt;span style="color:#e6db74">${&lt;/span>NAME_2&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#f92672">=&lt;/span>http://&lt;span style="color:#e6db74">${&lt;/span>HOST_2&lt;span style="color:#e6db74">}&lt;/span>:2380,&lt;span style="color:#e6db74">${&lt;/span>NAME_3&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#f92672">=&lt;/span>http://&lt;span style="color:#e6db74">${&lt;/span>HOST_3&lt;span style="color:#e6db74">}&lt;/span>:2380
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>DATA_DIR&lt;span style="color:#f92672">=&lt;/span>/var/lib/etcd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># For node 1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>THIS_NAME&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>NAME_1&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>THIS_IP&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2379:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2380:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --volume&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>DATA_DIR&lt;span style="color:#e6db74">}&lt;/span>:/etcd-data &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --name etcd &lt;span style="color:#e6db74">${&lt;/span>REGISTRY&lt;span style="color:#e6db74">}&lt;/span>:&lt;span style="color:#e6db74">${&lt;/span>ETCD_VERSION&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /usr/local/bin/etcd &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --data-dir&lt;span style="color:#f92672">=&lt;/span>/etcd-data --name &lt;span style="color:#e6db74">${&lt;/span>THIS_NAME&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-advertise-peer-urls http://&lt;span style="color:#e6db74">${&lt;/span>THIS_IP&lt;span style="color:#e6db74">}&lt;/span>:2380 --listen-peer-urls http://0.0.0.0:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --advertise-client-urls http://&lt;span style="color:#e6db74">${&lt;/span>THIS_IP&lt;span style="color:#e6db74">}&lt;/span>:2379 --listen-client-urls http://0.0.0.0:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-cluster &lt;span style="color:#e6db74">${&lt;/span>CLUSTER&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-cluster-state &lt;span style="color:#e6db74">${&lt;/span>CLUSTER_STATE&lt;span style="color:#e6db74">}&lt;/span> --initial-cluster-token &lt;span style="color:#e6db74">${&lt;/span>TOKEN&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># For node 2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>THIS_NAME&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>NAME_2&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>THIS_IP&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_2&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2379:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2380:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --volume&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>DATA_DIR&lt;span style="color:#e6db74">}&lt;/span>:/etcd-data &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --name etcd &lt;span style="color:#e6db74">${&lt;/span>REGISTRY&lt;span style="color:#e6db74">}&lt;/span>:&lt;span style="color:#e6db74">${&lt;/span>ETCD_VERSION&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /usr/local/bin/etcd &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --data-dir&lt;span style="color:#f92672">=&lt;/span>/etcd-data --name &lt;span style="color:#e6db74">${&lt;/span>THIS_NAME&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-advertise-peer-urls http://&lt;span style="color:#e6db74">${&lt;/span>THIS_IP&lt;span style="color:#e6db74">}&lt;/span>:2380 --listen-peer-urls http://0.0.0.0:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --advertise-client-urls http://&lt;span style="color:#e6db74">${&lt;/span>THIS_IP&lt;span style="color:#e6db74">}&lt;/span>:2379 --listen-client-urls http://0.0.0.0:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-cluster &lt;span style="color:#e6db74">${&lt;/span>CLUSTER&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-cluster-state &lt;span style="color:#e6db74">${&lt;/span>CLUSTER_STATE&lt;span style="color:#e6db74">}&lt;/span> --initial-cluster-token &lt;span style="color:#e6db74">${&lt;/span>TOKEN&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># For node 3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>THIS_NAME&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>NAME_3&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>THIS_IP&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_3&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2379:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 2380:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --volume&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>DATA_DIR&lt;span style="color:#e6db74">}&lt;/span>:/etcd-data &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --name etcd &lt;span style="color:#e6db74">${&lt;/span>REGISTRY&lt;span style="color:#e6db74">}&lt;/span>:&lt;span style="color:#e6db74">${&lt;/span>ETCD_VERSION&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /usr/local/bin/etcd &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --data-dir&lt;span style="color:#f92672">=&lt;/span>/etcd-data --name &lt;span style="color:#e6db74">${&lt;/span>THIS_NAME&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-advertise-peer-urls http://&lt;span style="color:#e6db74">${&lt;/span>THIS_IP&lt;span style="color:#e6db74">}&lt;/span>:2380 --listen-peer-urls http://0.0.0.0:2380 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --advertise-client-urls http://&lt;span style="color:#e6db74">${&lt;/span>THIS_IP&lt;span style="color:#e6db74">}&lt;/span>:2379 --listen-client-urls http://0.0.0.0:2379 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-cluster &lt;span style="color:#e6db74">${&lt;/span>CLUSTER&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --initial-cluster-state &lt;span style="color:#e6db74">${&lt;/span>CLUSTER_STATE&lt;span style="color:#e6db74">}&lt;/span> --initial-cluster-token &lt;span style="color:#e6db74">${&lt;/span>TOKEN&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="使用证书部署一个安全的-etcd-集群">使用证书部署一个安全的 ETCD 集群&lt;/h1>
&lt;h2 id="生成自签名证书">生成自签名证书&lt;/h2>
&lt;p>官方文档：&lt;/p>
&lt;p>make 自动生成：&lt;a href="https://github.com/etcd-io/etcd/tree/master/hack/tls-setup">https://github.com/etcd-io/etcd/tree/master/hack/tls-setup&lt;/a>&lt;/p>
&lt;p>使用 cfssl 工具：&lt;a href="https://github.com/coreos/docs/blob/master/os/generate-self-signed-certificates.md">https://github.com/coreos/docs/blob/master/os/generate-self-signed-certificates.md&lt;/a>&lt;/p>
&lt;h2 id="部署-etcd">部署 etcd&lt;/h2>
&lt;p>在上面的部署示例中，每个 etcd 节点添加如下命令行标志即可&lt;/p>
&lt;p>客户端到服务端通信认证所需配置&lt;/p>
&lt;p>--client-cert-auth=true #设置此选项后，etcd 将检查所有传入的 HTTPS 请求以查找由受信任的 CA 签名的客户端证书，未提供有效客户端证书的请求将失败。如果启用了&lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/authentication.md">身份验证&lt;/a>，则证书将为“公用名”字段提供的用户名提供凭据。&lt;/p>
&lt;p>--cert-file=/etc/kubernetes/pki/etcd/server.crt # 用于与 etcd 的 SSL / TLS 连接的证书。设置此选项后，advertise-client-urls 可以使用 HTTPS 模式。&lt;/p>
&lt;p>--key-file=/etc/kubernetes/pki/etcd/server.key #证书密钥。必须未加密。&lt;/p>
&lt;p>--trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt #受信任的证书颁发机构。&lt;/p>
&lt;p>服务端到服务端通信认证所需配置&lt;/p>
&lt;p>--peer-client-cert-auth=true # 设置后，etcd 将检查来自集群的所有传入对等请求，以查找由提供的 CA 签名的有效客户端证书。&lt;/p>
&lt;p>--peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt # 对等体之间用于 SSL / TLS 连接的证书。这将用于侦听对等方地址以及向其他对等方发送请求。&lt;/p>
&lt;p>--peer-key-file=/etc/kubernetes/pki/etcd/peer.key # 证书密钥。必须未加密。&lt;/p>
&lt;p>--peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt # 受信任的证书颁发机构。&lt;/p></description></item><item><title>Docs: Etcd 调优</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E8%B0%83%E4%BC%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E8%B0%83%E4%BC%98/</guid><description>
&lt;h1 id="etcd-tuning调优概述">Etcd Tuning(调优)概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io/docs/current/tuning/">官方文档&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://skyao.gitbooks.io/learning-etcd3/content/documentation/op-guide/performance.html">官方文档译文&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>决定 etcd 性能的关键因素，包括：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>延迟 (latency)&lt;/strong>：延迟是完成操作的时间。&lt;/li>
&lt;li>&lt;strong>吞吐量 (throughput)&lt;/strong>：吞吐量是在某个时间期间之内完成操作的总数量。当 etcd 接收并发客户端请求时，通常平均延迟随着总体吞吐量增加而增加。&lt;/li>
&lt;/ul>
&lt;p>在通常的云环境，比如 Google Compute Engine (GCE) 标准的 n-4 或者 AWS 上相当的机器类型，一个三成员 etcd 集群在轻负载下可以在低于 1 毫秒内完成一个请求，并在重负载下可以每秒完成超过 30000 个请求。&lt;/p>
&lt;p>etcd 使用 Raft 一致性算法来在成员之间复制请求并达成一致。一致性性能，特别是提交延迟，受限于两个物理约束：网络 IO 延迟和磁盘 IO 延迟。完成一个 etcd 请求的最小时间是成员之间的网络往返时延 (Round Trip Time / RTT)，加需要提交数据到持久化存储的 fdatasync 时间。在一个数据中心内的 RTT 可能有数百毫秒。在美国典型的 RTT 是大概 50ms, 而在大陆之间可以慢到 400ms。旋转硬盘(注：指传统机械硬盘) 的典型 fdatasync 延迟是大概 10ms。对于 SSD 硬盘, 延迟通常低于 1ms。为了提高吞吐量, etcd 将多个请求打包在一起并提交给 Raft。这个批量策略让 etcd 在重负载试获得高吞吐量。也有其他子系统影响到 etcd 的整体性能。每个序列化的 etcd 请求必须通过 etcd 的 boltdb 支持的(boltdb-backed) MVCC 存储引擎, 它通常需要 10 微秒来完成。etcd 定期递增快照它最近实施的请求，将他们和之前在磁盘上的快照合并。这个过程可能导致延迟尖峰(latency spike)。虽然在 SSD 上这通常不是问题，在 HDD 上它可能加倍可观察到的延迟。而且，进行中的压缩可以影响 etcd 的性能。幸运的是，压缩通常无足轻重，因为压缩是错开的，因此它不和常规请求竞争资源。RPC 系统，gRPC，为 etcd 提供定义良好，可扩展的 API，但是它也引入了额外的延迟，尤其是本地读取。&lt;/p>
&lt;p>Etcd 的默认配置在本地网络环境（localhost）下通常能够运行的很好，因为延迟很低。然而，当跨数据中心部署 Etcd 或网络延时很高时，etcd 的心跳间隔或选举超时时间等参数需要根据实际情况进行调整。&lt;/p>
&lt;p>网络并不是导致延时的唯一来源。不论是 Follower 还是 Leader，其请求和响应都受磁盘 I/O 延时的影响。每个 timeout 都代表从请求发起到成功返回响应的总时间。&lt;/p>
&lt;h2 id="时间参数">时间参数&lt;/h2>
&lt;p>Etcd 底层的分布式一致性协议依赖两个时间参数来保证节点之间能够在部分节点掉钱的情况下依然能够正确处理主节点的选举。第一个参数就是所谓的心跳间隔，即主节点通知从节点它还是领导者的频率。实践数据表明，该参数应该设置成节点之间 RTT 的时间。Etcd 的心跳间隔默认是 100 毫秒。第二个参数是选举超时时间，即从节点等待多久没收到主节点的心跳就尝试去竞选领导者。Etcd 的选举超时时间默认是 1000 毫秒。&lt;/p>
&lt;p>调整这些参数值是有条件的，此消波长。心跳间隔值推荐设置为临近节点间 RTT 的最大值，通常是 0.5~1.5 倍 RTT 值。如果心跳间隔设得太短，那么 Etcd 就会发送没必要的心跳信息，从而增加 CPU 和网络资源的消耗；如果设得太长，就会导致选举等待时间的超时。如果选举等待时间设置的过长，就会导致节点异常检测时间过长。评估 RTT 值的最简单的方法是使用 ping 的操作。&lt;/p>
&lt;p>选举超时时间应该基于心跳间隔和节点之间的平均 RTT 值。选举超时必须至少是 RTT 10 倍的时间以便对网络波动。例如，如果 RTT 的值是 10 毫秒，那么选举超时时间必须至少是 100 毫秒。选举超时时间的上线是 50000 毫秒（50 秒），这个时间只能只用于全球范围内分布式部署的 Etcd 集群。美国大陆的一个 RTT 的合理时间大约是 130 毫秒，美国和日本的 RTT 大约是 350~400 毫秒。如果算上网络波动和重试的时间，那么 5 秒是一次全球 RTT 的安全上线。因为选举超时时间应该是心跳包广播时间的 10 倍，所以 50 秒的选举超时时间是全局分布式部署 Etcd 的合理上线值。&lt;/p>
&lt;p>心跳间隔和选举超时时间的值对同一个 Etcd 集群的所有节点都生效，如果各个节点都不同的话，就会导致集群发生不可预知的不稳定性。Etcd 启动时通过传入启动参数或环境变量覆盖默认值，单位是毫秒。示例代码具体如下：&lt;/p>
&lt;pre>&lt;code>$ etcd --heartbeat-interval=100 --election-timeout=500
# 环境变量值
$ ETCD_HEARTBEAT_INTERVAL=100 ETCD_ELECTION_TIMEOUT=500 etcd
&lt;/code>&lt;/pre>
&lt;h2 id="快照">快照&lt;/h2>
&lt;p>Etcd 总是向日志文件中追加 key，这样一来，日志文件会随着 key 的改动而线性增长。当 Etcd 集群使用较少时，保存完整的日志历史记录是没问题的，但如果 Etcd 集群规模比较大时，那么集群就会携带很大的日志文件。为了避免携带庞大的日志文件，Etcd 需要做周期性的快照。快照提供了一种通过保存系统的当前状态并移除旧日志文件的方式来压缩日志文件。&lt;/p>
&lt;p>快照调优&lt;/p>
&lt;p>为 v2 后端存储创建快照的代价是很高的，所以只用当参数累积到一定的数量时，Etcd 才会创建快照文件。默认情况下，修改数量达到 10000 时才会建立快照。如果 Etcd 的内存使用和磁盘使用过高，那么应该尝试调低快照触发的阈值，具体请参考如下命令。&lt;/p>
&lt;p>启动参数：&lt;/p>
&lt;pre>&lt;code>etcd --snapshot-count=5000
&lt;/code>&lt;/pre>
&lt;p>环境变量：&lt;/p>
&lt;pre>&lt;code>ETCD_SNAPSHOT_COUNT=5000 etcd
&lt;/code>&lt;/pre>
&lt;h2 id="磁盘">磁盘&lt;/h2>
&lt;p>除了网络延迟，磁盘 IO 也严重影响 etcd 的稳定性， etcd 需要持久化数据，对磁盘速度很敏感，强烈建议对 ETCD 的数据挂 SSD。&lt;/p>
&lt;p>另外，要确认机器上没有其他高 IO 操作，否则会影响 etcd 的 fsync，导致 etcd 丢失心跳，leader 更换等。一般磁盘有问题时，报错的关键字类似于：&lt;/p>
&lt;pre>&lt;code>XXXXX took too long (1.483848046s) to execute
etcdserver: failed to send out heartbeat on time
&lt;/code>&lt;/pre>
&lt;p>磁盘 IO 可以通过监控手段提前发现，并预防这类问题的出现&lt;/p>
&lt;p>etcd 的存储目录分为 snapshot 和 wal，他们写入的方式是不同的，snapshot 是内存直接 dump file。而 wal 是顺序追加写，对于这两种方式系统调优的方式是不同的，snapshot 可以通过增加 io 平滑写来提高磁盘 io 能力，而 wal 可以通过降低 pagecache 的方式提前写入时序。因此对于不同的场景，可以考虑将 snap 与 wal 进行分盘，放在两块 SSD 盘上，提高整体的 IO 效率，这种方式可以提升 etcd 20% 左右的性能。&lt;/p>
&lt;p>etcd 集群对磁盘 I/O 的延时非常敏感，因为 Etcd 必须持久化它的日志，当其他 I/O 密集型的进程也在占用磁盘 I/O 的带宽时，就会导致 fsync 时延非常高。这将导致 Etcd 丢失心跳包、请求超时或暂时性的 Leader 丢失。这时可以适当为 Etcd 服务赋予更高的磁盘 I/O 权限，让 Etcd 更稳定的运行。在 Linux 系统中，磁盘 I/O 权限可以通过 ionice 命令进行调整。&lt;/p>
&lt;p>nux 默认 IO 调度器使用 CFQ 调度算法，支持用 ionice 命令为程序指定 IO 调度策略和优先级，IO 调度策略分为三种：&lt;/p>
&lt;ul>
&lt;li>Idle ：其他进程没有磁盘 IO 时，才进行磁盘 IO&lt;/li>
&lt;li>Best Effort：缺省调度策略，可以设置 0-7 的优先级，数值越小优先级越高，同优先级的进程采用 round-robin 算法调度；&lt;/li>
&lt;li>Real Time ：立即访问磁盘，无视其它进程 IO&lt;/li>
&lt;li>None 即 Best Effort，进程未指定策略和优先级时显示为 none，会使用依据 cpu nice 设置计算出优先级&lt;/li>
&lt;/ul>
&lt;p>Linux 中 etcd 的磁盘优先级可以使用 &lt;code>ionice -c2 -n0 -p &lt;/code>pgrep etcd` 命令进行配置(经过 benchmark 的测试，该调整有效果，但很小)&lt;/p>
&lt;h2 id="网络">网络&lt;/h2>
&lt;p>etcd 中比较复杂的是网络的调优，因此大量的网络请求会在 peer 节点之间转发，而且整体网络吞吐也很大，但是还是再次强调不建议大家调整系统参数，大家可以通过修改 etcd 的 &amp;ndash;heartbeat-interval 与 &amp;ndash;election-timeout 启动参数来适当提高高吞吐网络下 etcd 的集群鲁棒性，通常同步吞吐在 100MB 左右的集群可以考虑将 &amp;ndash;heartbeat-interval 设置为 300ms-500ms，&amp;ndash;election-timeout 可以设置在 5000ms 左右。此外官方还有基于 TC 的网络优先传输方案，也是一个比较适用的调优手段。&lt;/p>
&lt;p>如果 etcd 的 Leader 服务大量并发客户端，这就会导致 follower 的请求的处理被延迟因为网络延迟。follower 的 send buffer 中能看到错误的列表，如下所示：&lt;/p>
&lt;pre>&lt;code>dropped MsgProp to 247ae21ff9436b2d since streamMsg's sending buffer is full
dropped MsgAppResp to 247ae21ff9436b2d since streamMsg's sending buffer is full
&lt;/code>&lt;/pre>
&lt;p>这些错误可以通过提高 Leader 的网络优先级来提高 follower 的请求的响应。可以通过流量控制机制来提高:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 针对 2379、2380 端口放行&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tc qdisc add dev eth0 root handle 1: prio bands &lt;span style="color:#ae81ff">3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tc filter add dev eth0 parent 1: protocol ip prio &lt;span style="color:#ae81ff">1&lt;/span> u32 match ip sport &lt;span style="color:#ae81ff">2380&lt;/span> 0xffff flowid 1:1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tc filter add dev eth0 parent 1: protocol ip prio &lt;span style="color:#ae81ff">1&lt;/span> u32 match ip dport &lt;span style="color:#ae81ff">2380&lt;/span> 0xffff flowid 1:1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tc filter add dev eth0 parent 1: protocol ip prio &lt;span style="color:#ae81ff">2&lt;/span> u32 match ip sport &lt;span style="color:#ae81ff">2379&lt;/span> 0xffff flowid 1:1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tc filter add dev eth0 parent 1: protocol ip prio &lt;span style="color:#ae81ff">2&lt;/span> u32 match ip dport &lt;span style="color:#ae81ff">2379&lt;/span> 0xffff flowid 1:1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 查看现有的队列&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tc -s qdisc ls dev enp0s8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>qdisc prio 1: root refcnt &lt;span style="color:#ae81ff">2&lt;/span> bands &lt;span style="color:#ae81ff">3&lt;/span> priomap &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Sent &lt;span style="color:#ae81ff">258578&lt;/span> bytes &lt;span style="color:#ae81ff">923&lt;/span> pkt &lt;span style="color:#f92672">(&lt;/span>dropped 0, overlimits &lt;span style="color:#ae81ff">0&lt;/span> requeues 0&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backlog 0b 0p requeues &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 删除队列&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tc qdisc del dev enp0s8 root
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="数据规模">数据规模&lt;/h2>
&lt;p>etcd 的硬盘存储上限（默认是 2GB）, 当 etcd 数据量超过默认 quota 值后便不再接受写请求，可以通过设置 &amp;ndash;quota-backend-bytes 参数来增加存储大小,quota-backend-bytes 默认值为 0，即使用默认 quota 为 2GB，上限值为 8 GB，具体说明可参考官方文档：dev-guide/limit.md。&lt;/p>
&lt;pre>&lt;code> The default storage size limit is 2GB, configurable with `--quota-backend-bytes` flag. 8GB is a suggested maximum size for normal environments and etcd warns at startup if the configured value exceeds it.
&lt;/code>&lt;/pre>
&lt;p>以下摘自 当 K8s 集群达到万级规模，阿里巴巴如何解决系统各组件性能问题？&lt;/p>
&lt;blockquote>
&lt;p>阿里进行了深入研究了 etcd 内部的实现原理，并发现了影响 etcd 扩展性的一个关键问题在底层 bbolt db 的 page 页面分配算法上：随着 etcd 中存储的数据量的增长，bbolt db 中线性查找 “连续长度为 n 的 page 存储页面” 的性能显著下降。
为了解决该问题，我们设计了基于 segregrated hashmap 的空闲页面管理算法，hashmap 以连续 page 大小为 key, 连续页面起始 page id 为 value。通过查这个 segregrated hashmap 实现 O(1) 的空闲 page 查找，极大地提高了性能。在释放块时，新算法尝试和地址相邻的 page 合并，并更新 segregrated hashmap。更详细的算法分析可以见已发表在 CNCF 博客的博文。
通过这个算法改进，我们可以将 etcd 的存储空间从推荐的 2GB 扩展到 100GB，极大地提高了 etcd 存储数据的规模，并且读写无显著延迟增长。
pull request ：&lt;a href="https://github.com/etcd-io/bbolt/pull/141">https://github.com/etcd-io/bbolt/pull/141&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>目前社区已发布的 v3.4 系列版本并没有说明支持数据规模可达 100 G。&lt;/p></description></item><item><title>Docs: Etcd 高可用</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E9%AB%98%E5%8F%AF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E9%AB%98%E5%8F%AF%E7%94%A8/</guid><description>
&lt;h1 id="etcd-集群介绍">Etcd 集群介绍&lt;/h1>
&lt;p>官方文档：&lt;a href="https://etcd.io/docs/latest/op-guide/clustering/">https://etcd.io/docs/latest/op-guide/clustering/&lt;/a>&lt;/p></description></item><item><title>Docs: Etcd 管理</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/</guid><description/></item><item><title>Docs: Etcd 基于 RAFT 的一致性</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%9F%BA%E4%BA%8E-raft-%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%9F%BA%E4%BA%8E-raft-%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</guid><description>
&lt;h1 id="etcd-基于-raft-的一致性">Etcd 基于 RAFT 的一致性&lt;/h1>
&lt;p>选举方法&lt;/p>
&lt;ul>
&lt;li>
&lt;ol>
&lt;li>初始启动时，节点处于 follower 状态并被设定一个 election timeout，如果在这一时间周期内没有收到来自 leader 的 heartbeat，节点将发起选举：将自己切换为 candidate 之后，向集群中其它 follower 节点发送请求，询问其是否选举自己成为 leader。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;ol start="2">
&lt;li>当收到来自集群中过半数节点的接受投票后，节点即成为 leader，开始接收保存 client 的数据并向其它的 follower 节点同步日志。如果没有达成一致，则 candidate 随机选择一个等待间隔（150ms ~ 300ms）再次发起投票，得到集群中半数以上 follower 接受的 candidate 将成为 leader&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;ol start="3">
&lt;li>leader 节点依靠定时向 follower 发送 heartbeat 来保持其地位。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;ol start="4">
&lt;li>任何时候如果其它 follower 在 election timeout 期间都没有收到来自 leader 的 heartbeat，同样会将自己的状态切换为 candidate 并发起选举。每成功选举一次，新 leader 的任期（Term）都会比之前 leader 的任期大 1。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>日志复制&lt;/p>
&lt;p>当前 Leader 收到客户端的日志（事务请求）后先把该日志追加到本地的 Log 中，然后通过 heartbeat 把该 Entry 同步给其他 Follower，Follower 接收到日志后记录日志然后向 Leader 发送 ACK，当 Leader 收到大多数（n/2+1）Follower 的 ACK 信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个 heartbeat 中 Leader 将通知所有的 Follower 将该日志存储在自己的本地磁盘中。&lt;/p>
&lt;p>安全性&lt;/p>
&lt;p>安全性是用于保证每个节点都执行相同序列的安全机制，如当某个 Follower 在当前 Leader commit Log 时变得不可用了，稍后可能该 Follower 又会被选举为 Leader，这时新 Leader 可能会用新的 Log 覆盖先前已 committed 的 Log，这就是导致节点执行不同序列；Safety 就是用于保证选举出来的 Leader 一定包含先前 committed Log 的机制；&lt;/p>
&lt;ul>
&lt;li>
&lt;p>选举安全性（Election Safety）：每个任期（Term）只能选举出一个 Leader&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Leader 完整性（Leader Completeness）：指 Leader 日志的完整性，当 Log 在任期 Term1 被 Commit 后，那么以后任期 Term2、Term3… 等的 Leader 必须包含该 Log；Raft 在选举阶段就使用 Term 的判断用于保证完整性：当请求投票的该 Candidate 的 Term 较大或 Term 相同 Index 更大则投票，否则拒绝该请求。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>失效处理&lt;/p>
&lt;ul>
&lt;li>
&lt;ol>
&lt;li>Leader 失效：其他没有收到 heartbeat 的节点会发起新的选举，而当 Leader 恢复后由于步进数小会自动成为 follower（日志也会被新 leader 的日志覆盖）&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>2）follower 节点不可用：follower 节点不可用的情况相对容易解决。因为集群中的日志内容始终是从 leader 节点同步的，只要这一节点再次加入集群时重新从 leader 节点处复制日志即可。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>3）多个 candidate：冲突后 candidate 将随机选择一个等待间隔（150ms ~ 300ms）再次发起投票，得到集群中半数以上 follower 接受的 candidate 将成为 leader&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>wal 日志&lt;/p>
&lt;p>Etcd 实现 raft 的时候，充分利用了 go 语言 CSP 并发模型和 chan 的魔法，想更进行一步了解的可以去看源码，这里只简单分析下它的 wal 日志。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/lb3mb0/1616136460766-77609f41-c735-4349-b1ed-064ea78ed0ae.jpeg" alt="">&lt;/p>
&lt;p>etcdv3&lt;/p>
&lt;p>wal 日志是二进制的，解析出来后是以上数据结构 LogEntry。其中第一个字段 type，只有两种，一种是 0 表示 Normal，1 表示 ConfChange（ConfChange 表示 Etcd 本身的配置变更同步，比如有新的节点加入等）。第二个字段是 term，每个 term 代表一个主节点的任期，每次主节点变更 term 就会变化。第三个字段是 index，这个序号是严格有序递增的，代表变更序号。第四个字段是二进制的 data，将 raft request 对象的 pb 结构整个保存下。Etcd 源码下有个 tools/etcd-dump-logs，可以将 wal 日志 dump 成文本查看，可以协助分析 raft 协议。&lt;/p>
&lt;p>raft 协议本身不关心应用数据，也就是 data 中的部分，一致性都通过同步 wal 日志来实现，每个节点将从主节点收到的 data apply 到本地的存储，raft 只关心日志的同步状态，如果本地存储实现的有 bug，比如没有正确的将 data apply 到本地，也可能会导致数据不一致。&lt;/p>
&lt;p>Etcd v2 与 v3&lt;/p>
&lt;p>Etcd v2 和 v3 本质上是共享同一套 raft 协议代码的两个独立的应用，接口不一样，存储不一样，数据互相隔离。也就是说如果从 Etcd v2 升级到 Etcd v3，原来 v2 的数据还是只能用 v2 的接口访问，v3 的接口创建的数据也只能访问通过 v3 的接口访问。所以我们按照 v2 和 v3 分别分析。&lt;/p>
&lt;p>推荐在 Kubernetes 集群中使用 Etcd v3，v2 版本已在 Kubernetes v1.11 中弃用。&lt;/p>
&lt;p>Etcd v2 存储，Watch 以及过期机制&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/lb3mb0/1616136460787-f5c53c06-f976-4d02-a992-a60abe753ec9.jpeg" alt="">&lt;/p>
&lt;p>etcdv2&lt;/p>
&lt;p>Etcd v2 是个纯内存的实现，并未实时将数据写入到磁盘，持久化机制很简单，就是将 store 整合序列化成 json 写入文件。数据在内存中是一个简单的树结构。比如以下数据存储到 Etcd 中的结构就如图所示。&lt;/p>
&lt;p>/nodes/1/name node1&lt;/p>
&lt;p>/nodes/1/ip 192.168.1.1&lt;/p>
&lt;p>store 中有一个全局的 currentIndex，每次变更，index 会加 1. 然后每个 event 都会关联到 currentIndex.&lt;/p>
&lt;p>当客户端调用 watch 接口（参数中增加 wait 参数）时，如果请求参数中有 waitIndex，并且 waitIndex 小于 currentIndex，则从 EventHistroy 表中查询 index 大于等于 waitIndex，并且和 watch key 匹配的 event，如果有数据，则直接返回。如果历史表中没有或者请求没有带 waitIndex，则放入 WatchHub 中，每个 key 会关联一个 watcher 列表。 当有变更操作时，变更生成的 event 会放入 EventHistroy 表中，同时通知和该 key 相关的 watcher。&lt;/p>
&lt;p>这里有几个影响使用的细节问题：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>EventHistroy 是有长度限制的，最长 1000。也就是说，如果你的客户端停了许久，然后重新 watch 的时候，可能和该 waitIndex 相关的 event 已经被淘汰了，这种情况下会丢失变更。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果通知 watcher 的时候，出现了阻塞（每个 watcher 的 channel 有 100 个缓冲空间），Etcd 会直接把 watcher 删除，也就是会导致 wait 请求的连接中断，客户端需要重新连接。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Etcd store 的每个 node 中都保存了过期时间，通过定时机制进行清理。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>从而可以看出，Etcd v2 的一些限制：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>过期时间只能设置到每个 key 上，如果多个 key 要保证生命周期一致则比较困难。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>watcher 只能 watch 某一个 key 以及其子节点（通过参数 recursive)，不能进行多个 watch。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>很难通过 watch 机制来实现完整的数据同步（有丢失变更的风险），所以当前的大多数使用方式是通过 watch 得知变更，然后通过 get 重新获取数据，并不完全依赖于 watch 的变更 event。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Etcd v3 存储，Watch 以及过期机制&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/lb3mb0/1616136460746-e9c93537-e374-4227-a464-765260bc4f75.jpeg" alt="">&lt;/p>
&lt;p>etcdv3&lt;/p>
&lt;p>Etcd v3 将 watch 和 store 拆开实现，我们先分析下 store 的实现。&lt;/p>
&lt;p>Etcd v3 store 分为两部分，一部分是内存中的索引，kvindex，是基于 google 开源的一个 golang 的 btree 实现的，另外一部分是后端存储。按照它的设计，backend 可以对接多种存储，当前使用的 boltdb。boltdb 是一个单机的支持事务的 kv 存储，Etcd 的事务是基于 boltdb 的事务实现的。Etcd 在 boltdb 中存储的 key 是 revision，value 是 Etcd 自己的 key-value 组合，也就是说 Etcd 会在 boltdb 中把每个版本都保存下，从而实现了多版本机制。&lt;/p>
&lt;p>举个例子： 用 etcdctl 通过批量接口写入两条记录：&lt;/p>
&lt;p>etcdctl txn &amp;laquo;&amp;lt;'&lt;/p>
&lt;p>put key1 &amp;ldquo;v1&amp;rdquo;&lt;/p>
&lt;p>put key2 &amp;ldquo;v2&amp;rdquo;&lt;/p>
&lt;p>'&lt;/p>
&lt;p>再通过批量接口更新这两条记录：&lt;/p>
&lt;p>etcdctl txn &amp;laquo;&amp;lt;'&lt;/p>
&lt;p>put key1 &amp;ldquo;v12&amp;rdquo;&lt;/p>
&lt;p>put key2 &amp;ldquo;v22&amp;rdquo;&lt;/p>
&lt;p>'&lt;/p>
&lt;p>boltdb 中其实有了 4 条数据：&lt;/p>
&lt;p>rev={3 0}, key=key1, value=&amp;ldquo;v1&amp;rdquo;&lt;/p>
&lt;p>rev={3 1}, key=key2, value=&amp;ldquo;v2&amp;rdquo;&lt;/p>
&lt;p>rev={4 0}, key=key1, value=&amp;ldquo;v12&amp;rdquo;&lt;/p>
&lt;p>rev={4 1}, key=key2, value=&amp;ldquo;v22&amp;rdquo;&lt;/p>
&lt;p>revision 主要由两部分组成，第一部分 main rev，每次事务进行加一，第二部分 sub rev，同一个事务中的每次操作加一。如上示例，第一次操作的 main rev 是 3，第二次是 4。当然这种机制大家想到的第一个问题就是空间问题，所以 Etcd 提供了命令和设置选项来控制 compact，同时支持 put 操作的参数来精确控制某个 key 的历史版本数。&lt;/p>
&lt;p>了解了 Etcd 的磁盘存储，可以看出如果要从 boltdb 中查询数据，必须通过 revision，但客户端都是通过 key 来查询 value，所以 Etcd 的内存 kvindex 保存的就是 key 和 revision 之前的映射关系，用来加速查询。&lt;/p>
&lt;p>然后我们再分析下 watch 机制的实现。Etcd v3 的 watch 机制支持 watch 某个固定的 key，也支持 watch 一个范围（可以用于模拟目录的结构的 watch），所以 watchGroup 包含两种 watcher，一种是 key watchers，数据结构是每个 key 对应一组 watcher，另外一种是 range watchers, 数据结构是一个 IntervalTree（不熟悉的参看文文末链接），方便通过区间查找到对应的 watcher。&lt;/p>
&lt;p>同时，每个 WatchableStore 包含两种 watcherGroup，一种是 synced，一种是 unsynced，前者表示该 group 的 watcher 数据都已经同步完毕，在等待新的变更，后者表示该 group 的 watcher 数据同步落后于当前最新变更，还在追赶。&lt;/p>
&lt;p>当 Etcd 收到客户端的 watch 请求，如果请求携带了 revision 参数，则比较请求的 revision 和 store 当前的 revision，如果大于当前 revision，则放入 synced 组中，否则放入 unsynced 组。同时 Etcd 会启动一个后台的 goroutine 持续同步 unsynced 的 watcher，然后将其迁移到 synced 组。也就是这种机制下，Etcd v3 支持从任意版本开始 watch，没有 v2 的 1000 条历史 event 表限制的问题（当然这是指没有 compact 的情况下）。&lt;/p>
&lt;p>另外我们前面提到的，Etcd v2 在通知客户端时，如果网络不好或者客户端读取比较慢，发生了阻塞，则会直接关闭当前连接，客户端需要重新发起请求。Etcd v3 为了解决这个问题，专门维护了一个推送时阻塞的 watcher 队列，在另外的 goroutine 里进行重试。&lt;/p>
&lt;p>Etcd v3 对过期机制也做了改进，过期时间设置在 lease 上，然后 key 和 lease 关联。这样可以实现多个 key 关联同一个 lease id，方便设置统一的过期时间，以及实现批量续约。&lt;/p>
&lt;p>相比 Etcd v2, Etcd v3 的一些主要变化：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>接口通过 grpc 提供 rpc 接口，放弃了 v2 的 http 接口。优势是长连接效率提升明显，缺点是使用不如以前方便，尤其对不方便维护长连接的场景。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>废弃了原来的目录结构，变成了纯粹的 kv，用户可以通过前缀匹配模式模拟目录。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>内存中不再保存 value，同样的内存可以支持存储更多的 key。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>watch 机制更稳定，基本上可以通过 watch 机制实现数据的完全同步。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>提供了批量操作以及事务机制，用户可以通过批量事务请求来实现 Etcd v2 的 CAS 机制（批量事务支持 if 条件判断）。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Etcd，Zookeeper，Consul 比较&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Etcd 和 Zookeeper 提供的能力非常相似，都是通用的一致性元信息存储，都提供 watch 机制用于变更通知和分发，也都被分布式系统用来作为共享信息存储，在软件生态中所处的位置也几乎是一样的，可以互相替代的。二者除了实现细节，语言，一致性协议上的区别，最大的区别在周边生态圈。Zookeeper 是 apache 下的，用 java 写的，提供 rpc 接口，最早从 hadoop 项目中孵化出来，在分布式系统中得到广泛使用（hadoop, solr, kafka, mesos 等）。Etcd 是 coreos 公司旗下的开源产品，比较新，以其简单好用的 rest 接口以及活跃的社区俘获了一批用户，在新的一些集群中得到使用（比如 kubernetes）。虽然 v3 为了性能也改成二进制 rpc 接口了，但其易用性上比 Zookeeper 还是好一些。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>而 Consul 的目标则更为具体一些，Etcd 和 Zookeeper 提供的是分布式一致性存储能力，具体的业务场景需要用户自己实现，比如服务发现，比如配置变更。而 Consul 则以服务发现和配置变更为主要目标，同时附带了 kv 存储。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Etcd 的周边工具&lt;/p>
&lt;ol>
&lt;li>Confd&lt;/li>
&lt;/ol>
&lt;p>在分布式系统中，理想情况下是应用程序直接和 Etcd 这样的服务发现 / 配置中心交互，通过监听 Etcd 进行服务发现以及配置变更。但我们还有许多历史遗留的程序，服务发现以及配置大多都是通过变更配置文件进行的。Etcd 自己的定位是通用的 kv 存储，所以并没有像 Consul 那样提供实现配置变更的机制和工具，而 Confd 就是用来实现这个目标的工具。&lt;/p>
&lt;p>Confd 通过 watch 机制监听 Etcd 的变更，然后将数据同步到自己的一个本地存储。用户可以通过配置定义自己关注哪些 key 的变更，同时提供一个配置文件模板。Confd 一旦发现数据变更就使用最新数据渲染模板生成配置文件，如果新旧配置文件有变化，则进行替换，同时触发用户提供的 reload 脚本，让应用程序重新加载配置。&lt;/p>
&lt;p>Confd 相当于实现了部分 Consul 的 agent 以及 consul-template 的功能，作者是 kubernetes 的 Kelsey Hightower，但大神貌似很忙，没太多时间关注这个项目了，很久没有发布版本，我们着急用，所以 fork 了一份自己更新维护，主要增加了一些新的模板函数以及对 metad 后端的支持。confd&lt;/p>
&lt;ol>
&lt;li>Metad&lt;/li>
&lt;/ol>
&lt;p>服务注册的实现模式一般分为两种，一种是调度系统代为注册，一种是应用程序自己注册。调度系统代为注册的情况下，应用程序启动后需要有一种机制让应用程序知道『我是谁』，然后发现自己所在的集群以及自己的配置。Metad 提供这样一种机制，客户端请求 Metad 的一个固定的接口 /self，由 Metad 告知应用程序其所属的元信息，简化了客户端的服务发现和配置变更逻辑。&lt;/p>
&lt;p>Metad 通过保存一个 ip 到元信息路径的映射关系来做到这一点，当前后端支持 Etcd v3，提供简单好用的 http rest 接口。 它会把 Etcd 的数据通过 watch 机制同步到本地内存中，相当于 Etcd 的一个代理。所以也可以把它当做 Etcd 的代理来使用，适用于不方便使用 Etcd v3 的 rpc 接口或者想降低 Etcd 压力的场景。 metad&lt;/p>
&lt;p>Etcd 使用注意事项&lt;/p>
&lt;ol>
&lt;li>Etcd cluster 初始化的问题&lt;/li>
&lt;/ol>
&lt;p>如果集群第一次初始化启动的时候，有一台节点未启动，通过 v3 的接口访问的时候，会报告 Error: Etcdserver: not capable 错误。这是为兼容性考虑，集群启动时默认的 API 版本是 2.3，只有当集群中的所有节点都加入了，确认所有节点都支持 v3 接口时，才提升集群版本到 v3。这个只有第一次初始化集群的时候会遇到，如果集群已经初始化完毕，再挂掉节点，或者集群关闭重启（关闭重启的时候会从持久化数据中加载集群 API 版本），都不会有影响。&lt;/p>
&lt;ol>
&lt;li>Etcd 读请求的机制&lt;/li>
&lt;/ol>
&lt;p>v2 quorum=true 的时候，读取是通过 raft 进行的，通过 cli 请求，该参数默认为 true。&lt;/p>
&lt;p>v3 &amp;ndash;consistency=“l” 的时候（默认）通过 raft 读取，否则读取本地数据。sdk 代码里则是通过是否打开：WithSerializable option 来控制。&lt;/p>
&lt;p>一致性读取的情况下，每次读取也需要走一次 raft 协议，能保证一致性，但性能有损失，如果出现网络分区，集群的少数节点是不能提供一致性读取的。但如果不设置该参数，则是直接从本地的 store 里读取，这样就损失了一致性。使用的时候需要注意根据应用场景设置这个参数，在一致性和可用性之间进行取舍。&lt;/p>
&lt;ol>
&lt;li>Etcd 的 compact 机制&lt;/li>
&lt;/ol>
&lt;p>Etcd 默认不会自动 compact，需要设置启动参数，或者通过命令进行 compact，如果变更频繁建议设置，否则会导致空间和内存的浪费以及错误。Etcd v3 的默认的 backend quota 2GB，如果不 compact，boltdb 文件大小超过这个限制后，就会报错：”Error: etcdserver: mvcc: database space exceeded”，导致数据无法写入。&lt;/p>
&lt;p>etcd 的问题&lt;/p>
&lt;p>当前 Etcd 的 raft 实现保证了多个节点数据之间的同步，但明显的一个问题就是扩充节点不能解决容量问题。要想解决容量问题，只能进行分片，但分片后如何使用 raft 同步数据？只能实现一个 multiple group raft，每个分片的多个副本组成一个虚拟的 raft group，通过 raft 实现数据同步。当前实现了 multiple group raft 的有 TiKV 和 Cockroachdb，但尚未一个独立通用的。理论上来说，如果有了这套 multiple group raft，后面挂个持久化的 kv 就是一个分布式 kv 存储，挂个内存 kv 就是分布式缓存，挂个 lucene 就是分布式搜索引擎。当然这只是理论上，要真实现复杂度还是不小。&lt;/p>
&lt;p>注： 部分转自 jolestar 和 infoq.&lt;/p>
&lt;p>参考文档&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Etcd website&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Etcd github&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Projects using etcd&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://jolestar.com/etcd-architecture/">http://jolestar.com/etcd-architecture/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>etcd 从应用场景到实现原理的全方位解读&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: Etcd 命令行工具</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description/></item><item><title>Docs: Etcd 配置详解</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io/docs/current/op-guide/configuration/">官方文档&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Etcd 运行时的行为可以通过三种方式进行配置&lt;/p>
&lt;ol>
&lt;li>配置文件&lt;/li>
&lt;li>命令行标志&lt;/li>
&lt;li>环境变量&lt;/li>
&lt;/ol>
&lt;p>而一般情况，配置文件中的关键字 与 命令行标志 和 环境变量 是 一一对应的。比如：&lt;/p>
&lt;ol>
&lt;li>配置文件中关键字：ETCD_DATA_DIR&lt;/li>
&lt;li>对应的环境变量中的变量名：ETCD_DATA_DIR&lt;/li>
&lt;li>对应的 flag： &amp;ndash;data-dir&lt;/li>
&lt;/ol>
&lt;p>优先级：配置文件 &amp;gt; 命令行标志 &amp;gt; 环境变量&lt;/p>
&lt;h2 id="member-成员相关标志">Member 成员相关标志&lt;/h2>
&lt;p>--name # member 的名称。&lt;code>默认值：default&lt;/code>
--data-dir # etcd 数据存储路径。&lt;code>默认值：${name}.etcd&lt;/code>。一般大家都修改到 /var/lib/etcd 下。
--wal-dir
--snapshot-count
--heartbeat-interval # 心跳检测的间隔时间，时间单位是 milliseconds(毫秒)。&lt;code>默认值：100&lt;/code>&lt;/p>
&lt;ul>
&lt;li>注意：修改心跳值的同时要修改 election-timeout 标志。因为 选举超时 时间至少需要是 心跳检测间隔的 5 倍，如果达不到 5 倍，则 etcd 启动失败&lt;/li>
&lt;/ul>
&lt;p>--election-timeout # 选举超时时间，时间单位是 milliseconds(毫秒)。&lt;code>默认值：1000&lt;/code>
--listen-peer-urls # 监听的用于节点之间通信的 url，可监听多个，集群内部将通过这些 url 进行数据交互(如选举，数据同步等)
--listen-client-urls # 监听的用于客户端通信的 url，同样可以监听多个。
--max-snapshots
--max-wals
--cors
--quota-backend-bytes # etcd 可储存的数据配额上限。&lt;code>默认值：0&lt;/code>。&lt;/p>
&lt;blockquote>
&lt;p>默认值 0 表示最低配额。在 3.4 版本时，最低配额是 2G，也就是说 etcd 最多可以保存 2G 的数据。&lt;/p>
&lt;/blockquote>
&lt;p>--backend-batch-limit
--backend-bbolt-freelist-type
--backend-batch-interval
--max-txn-ops
--max-request-bytes
--grpc-keepalive-min-time
--grpc-keepalive-interval
--grpc-keepalive-timeout&lt;/p>
&lt;h2 id="clustering-集群相关标志">Clustering 集群相关标志&lt;/h2>
&lt;blockquote>
&lt;p>注意：
--initial-advertise-peer-urls，-initial-cluster，-initial-cluster-state 和 &amp;ndash;initial-cluster-token 这 4 个标志是比较特殊的存在。只在 etcd 第一次启动并加入集群之前生效。
上面这 4 个标志用于引导（静态引导，服务发现引导 or 运行时配置）新成员，并且已经在集群中的成员重新启动时，将忽略这些标志。
使用发现服务时，需要设置 &amp;ndash;discovery 前缀标志。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>&amp;ndash;initial-advertise-peer-urls&lt;/strong> # 用于节点间通信的 URL，节点间以该值进行通信。&lt;/p>
&lt;ul>
&lt;li>默认值： http://localhost:2380&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>&amp;ndash;initial-cluster&lt;/strong> # 用来引导初始集群的配置。一般是集群中所有 &amp;ndash;initial-advertise-peer-urls 标志值的合集，每个值以逗号分隔&lt;/p>
&lt;ul>
&lt;li>默认值：default=http://localhost:2380&lt;/li>
&lt;li>default 是每个节点的 etcd 的 &amp;ndash;name 标志的值。&amp;ndash;name 标志的默认值就是 default&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>&amp;ndash;initial-cluster-state&lt;/strong> # 初始群集状态(两种状态：new 或 existing)。&lt;/p>
&lt;ul>
&lt;li>默认值： new&lt;/li>
&lt;li>new # 对于在初始静态或 DNS 引导过程中存在的所有成员，将其设置为 new。&lt;/li>
&lt;li>existing # 设为 existing 状态的 etcd 将尝试加入 &amp;ndash;initial-cluster 标志指定的集群。如果设置了错误的值，则 etcd 将尝试启动但安全失败。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>&amp;ndash;initial-cluster-token&lt;/strong> # 初始集群引导时所使用的 token。设置该值后集群将生成唯一 id，并为每个节点也生成唯一 id，当使用相同配置文件再启动一个集群时，只要该 token 值不一样，etcd 集群就不会相互影响。&lt;/p>
&lt;ul>
&lt;li>默认值：etcd-cluster&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>&amp;ndash;advertise-client-urls&lt;/strong> # 建议使用的客户端通信 url，该值用于 etcd 代理或 etcd 成员与 etcd 节点通信。&lt;/p>
&lt;ul>
&lt;li>默认值：http://localhost:2379&lt;/li>
&lt;/ul>
&lt;p>--discovery #
--discovery-srv #
--discovery-srv-name #
--discovery-fallback #
--discovery-proxy #
--strict-reconfig-check #
--auto-compaction-retention #
--auto-compaction-mode #
--enable-v2 #&lt;/p>
&lt;h2 id="proxy-代理相关标志">Proxy 代理相关标志&lt;/h2>
&lt;p>--proxy&lt;/p>
&lt;p>--proxy-failure-wait&lt;/p>
&lt;p>--proxy-refresh-interval&lt;/p>
&lt;p>--proxy-dial-timeout&lt;/p>
&lt;p>--proxy-write-timeout&lt;/p>
&lt;p>--proxy-read-timeout&lt;/p>
&lt;h2 id="security-安全相关标志">Security 安全相关标志&lt;/h2>
&lt;p>安全相关的标志用来帮助&lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md">建立一个安全的 etcd 集群&lt;/a>&lt;/p>
&lt;p>--ca-file&lt;/p>
&lt;p>--cert-file&lt;/p>
&lt;p>--key-file&lt;/p>
&lt;p>--client-cert-auth&lt;/p>
&lt;p>--client-crl-file&lt;/p>
&lt;p>--client-cert-allowed-hostname&lt;/p>
&lt;p>--trusted-ca-file&lt;/p>
&lt;p>--auto-tls&lt;/p>
&lt;p>--peer-ca-file&lt;/p>
&lt;p>--peer-cert-file&lt;/p>
&lt;p>--peer-key-file&lt;/p>
&lt;p>--peer-client-cert-auth&lt;/p>
&lt;p>--peer-crl-file&lt;/p>
&lt;p>--peer-trusted-ca-file&lt;/p>
&lt;p>--peer-auto-tls&lt;/p>
&lt;p>--peer-cert-allowed-cn&lt;/p>
&lt;p>--peer-cert-allowed-hostname&lt;/p>
&lt;p>--cipher-suites&lt;/p>
&lt;h2 id="logging-flags">Logging flags&lt;/h2>
&lt;p>--logger&lt;/p>
&lt;p>--log-outputs&lt;/p>
&lt;p>--log-level&lt;/p>
&lt;p>--debug&lt;/p>
&lt;p>--log-package-levels&lt;/p>
&lt;h2 id="unsafe-flags">Unsafe flags&lt;/h2>
&lt;p>--force-new-cluster&lt;/p>
&lt;h2 id="miscellaneous-flags">Miscellaneous flags&lt;/h2>
&lt;p>--version&lt;/p>
&lt;p>--config-file&lt;/p>
&lt;h2 id="profiling-flags">Profiling flags&lt;/h2>
&lt;p>--enable-pprof&lt;/p>
&lt;p>--metrics&lt;/p>
&lt;p>--listen-metrics-urls&lt;/p>
&lt;h2 id="auth-flags">Auth flags&lt;/h2>
&lt;p>--auth-token&lt;/p>
&lt;p>--bcrypt-cost&lt;/p>
&lt;h2 id="experimental-flags">Experimental flags&lt;/h2>
&lt;p>-experimental-corrupt-check-time&lt;/p>
&lt;p>--experimental-compaction-batch-limit&lt;/p>
&lt;p>--experimental-peer-skip-client-san-verification&lt;/p></description></item><item><title>Docs: Etcd 数据模型</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io/docs/latest/learning/data_model/">官方文档&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="wal">WAL&lt;/h1>
&lt;p>数据库通常使用 &lt;a href="https://en.wikipedia.org/wiki/Write-ahead_logging">预写日志记录&lt;/a>； etcd 也使用它。有关预写日志记录的详细信息不在本文讨论范围之内，但是出于此目的，我们需要知道的是-每个 etcd 集群成员都在持久性存储上保留一个预写日志（WAL）。 etcd 在将某些操作（例如更新）写入键值存储之前，将其写入 WAL。如果成员崩溃并在快照之间重新启动，则可以通过查看 WAL 的内容在本地恢复自上次快照以来完成的事务。&lt;/p>
&lt;p>因此，每当客户将密钥添加到键值存储或更新现有密钥的值时，客户端都会 etcd 在 WAL 上附加一个记录操作的条目，WAL 是持久性存储上的普通文件。在继续进行之前， etcd 必须 100％确信 WAL 条目已被实际保留。要在 Linux 上实现此目的，仅使用 write 系统调用是不够的， 因为实际写入物理存储的时间可能会延迟。例如，Linux 可能会将写入的 WAL 条目在内核内存高速缓存（例如页面高速缓存）中保留一段时间。为了确保将数据写入持久性存储中，您必须在“”之后调用 fdatasync 系统调用，write 这正是该 etcd 操作（如以下 strace 所示） 输出，其中 8 是 WAL 文件的文件描述符）：&lt;/p>
&lt;pre>&lt;code>21:23:09.894875 lseek(8, 0, SEEK_CUR) = 12808 &amp;lt;0.000012&amp;gt;
21:23:09.894911 write(8, &amp;quot;.\0\0\0\0\0\0\202\10\2\20\361\223\255\266\6\32$\10\0\20\10\30\26\&amp;quot;\34\&amp;quot;\r\n\3fo&amp;quot;..., 2296) = 2296 &amp;lt;0.000130&amp;gt;
21:23:09.895041 fdatasync(8) = 0 &amp;lt;0.008314&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>不幸的是，写入持久性存储需要时间。如果 fdatasync 花费太长时间，则 etcd 系统性能会降低。 &lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md#what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean">etcd 文档建议&lt;/a> 为了使存储足够快，fdatasync 写入 WAL 文件时调用的第 99 个百分点 &lt;strong>必须小于 10ms&lt;/strong>。还有其他与存储相关的指标，但这是本文的重点。&lt;/p>
&lt;h1 id="bbolt">bbolt&lt;/h1>
&lt;p>&lt;a href="https://github.com/DesistDaydream/go-library/tree/master/bbolt">https://github.com/DesistDaydream/go-library/tree/master/bbolt&lt;/a> 代码练习&lt;/p></description></item><item><title>Docs: etcd 问题处理案例</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description>
&lt;h1 id="heading">&lt;/h1>
&lt;h2 id="what-does-the-etcd-warning-apply-entries-took-too-long-mean">What does the etcd warning “apply entries took too long” mean?&lt;/h2>
&lt;p>官方文档：&lt;/p>
&lt;p>&lt;a href="https://etcd.io/docs/v3.4.0/faq/#what-does-the-etcd-warning-apply-entries-took-too-long-mean">https://etcd.io/docs/v3.4.0/faq/#what-does-the-etcd-warning-apply-entries-took-too-long-mean&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md#what-does-the-etcd-warning-apply-entries-took-too-long-mean">https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md#what-does-the-etcd-warning-apply-entries-took-too-long-mean&lt;/a>&lt;/p>
&lt;h2 id="what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean">What does the etcd warning “failed to send out heartbeat on time” mean?&lt;/h2>
&lt;p>官方文档：&lt;/p>
&lt;p>&lt;a href="https://etcd.io/docs/v3.4.0/faq/#what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean">https://etcd.io/docs/v3.4.0/faq/#what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md#what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean">https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md#what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean&lt;/a>&lt;/p>
&lt;h1 id="其他">其他&lt;/h1>
&lt;p>&lt;a href="http://blog.itpub.net/31559758/viewspace-2704804/">http://blog.itpub.net/31559758/viewspace-2704804/&lt;/a>&lt;/p></description></item><item><title>Docs: Etcd 性能测试</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io/docs/current/op-guide/performance/">官方文档,运维指南-性能&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>安装 etcd 压测工具 benchmark：&lt;/p>
&lt;pre>&lt;code>$ go get go.etcd.io/etcd/tools/benchmark
# GOPATH should be set
$ ls $GOPATH/bin
benchmark
&lt;/code>&lt;/pre>
&lt;h1 id="官方推荐的-etcd-性能数据">官方推荐的 etcd 性能数据&lt;/h1>
&lt;p>其中官方使用的设备信息为：&lt;/p>
&lt;ul>
&lt;li>Google Cloud Compute Engine&lt;/li>
&lt;li>3 machines of 8 vCPUs + 16GB Memory + 50GB SSD&lt;/li>
&lt;li>1 machine(client) of 16 vCPUs + 30GB Memory + 50GB SSD&lt;/li>
&lt;li>Ubuntu 17.04&lt;/li>
&lt;li>etcd 3.2.0, go 1.8.3&lt;/li>
&lt;/ul>
&lt;h3 id="etcd-写性能">etcd 写性能&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Key 数量&lt;/td>
&lt;td>每个 Key 的大小&lt;/td>
&lt;td>每个值的大小&lt;/td>
&lt;td>连接数量&lt;/td>
&lt;td>客户端数量&lt;/td>
&lt;td>目标 etcd 节点数&lt;/td>
&lt;td>写性能的平均 QPS&lt;/td>
&lt;td>每个请求的平均延迟&lt;/td>
&lt;td>服务器 RRS 的平均值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>10,000&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>256 bytes&lt;/td>
&lt;td>1&lt;/td>
&lt;td>1&lt;/td>
&lt;td>只有一个 leader&lt;/td>
&lt;td>583&lt;/td>
&lt;td>1.6ms&lt;/td>
&lt;td>48 MB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>100,000&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>256 bytes&lt;/td>
&lt;td>100&lt;/td>
&lt;td>1000&lt;/td>
&lt;td>只有一个 leader&lt;/td>
&lt;td>44,341&lt;/td>
&lt;td>22ms&lt;/td>
&lt;td>124MB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>100,000&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>256 bytes&lt;/td>
&lt;td>100&lt;/td>
&lt;td>1000&lt;/td>
&lt;td>所有 etcd 节点&lt;/td>
&lt;td>50,104&lt;/td>
&lt;td>20ms&lt;/td>
&lt;td>126MB&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="etcd-读性能">etcd 读性能&lt;/h3>
&lt;p>该测试的 &amp;ndash;endpoint 参数指定所有节点。&lt;/p>
&lt;p>Linearizable(线性化) 读请求经过集群仲裁达成共识以获取最新数据，Serializable(串行化)读取请求比线性化读取要廉价一些，因为他们是通过任意一台 etcd 成员来相应请求，而不是具有法定人数的成员，这种请求获取到的数据有可能是过期的。由于 etcd 是强一致性的，其默认读取测试就是线性化读取。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>请求数&lt;/td>
&lt;td>每个 Key 的大小&lt;/td>
&lt;td>每个值的大小&lt;/td>
&lt;td>连接数量&lt;/td>
&lt;td>客户端数量&lt;/td>
&lt;td>Consistency(一致性)&lt;/td>
&lt;td>读性能的平均 QPS&lt;/td>
&lt;td>每个请求的平均延迟&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>10,000&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>256 bytes&lt;/td>
&lt;td>1&lt;/td>
&lt;td>1&lt;/td>
&lt;td>Linearizable&lt;/td>
&lt;td>1,353&lt;/td>
&lt;td>0.7ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>10,000&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>256 bytes&lt;/td>
&lt;td>1&lt;/td>
&lt;td>1&lt;/td>
&lt;td>Serializable&lt;/td>
&lt;td>2,909&lt;/td>
&lt;td>0.3ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>100,000&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>256 bytes&lt;/td>
&lt;td>100&lt;/td>
&lt;td>1000&lt;/td>
&lt;td>Linearizable&lt;/td>
&lt;td>141,578&lt;/td>
&lt;td>5.5ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>100,000&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>256 bytes&lt;/td>
&lt;td>100&lt;/td>
&lt;td>1000&lt;/td>
&lt;td>Serializable&lt;/td>
&lt;td>185,758&lt;/td>
&lt;td>2.2ms&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>官方鼓励在新环境中首次设置 etcd 集群时运行基准测试，以确保该集群获得足够的性能；群集延迟和吞吐量可能会对较小的环境差异敏感。&lt;/p>
&lt;h1 id="etcdctl-check-perf-官方测试工具">etcdctl check perf 官方测试工具&lt;/h1>
&lt;p>直接使用 etcdctl 命令行工具的子命令，即可进行简单的测试&lt;/p>
&lt;pre>&lt;code>root@lichenhao:~# etcdctl check perf
60 / 60 Booooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo! 100.00% 1m0s
PASS: Throughput is 150 writes/s
PASS: Slowest request took 0.101178s
PASS: Stddev is 0.002695s
PASS
&lt;/code>&lt;/pre>
&lt;h1 id="benchmarks-官方测试工具">benchmarks 官方测试工具&lt;/h1>
&lt;p>对于写入测试，按照官方文档的测试方法指定不同数量的客户端和连接数以及 key 的大小，对于读取操作，分别测试了线性化读取以及串行化读取，由于 etcd 是强一致性的，其默认读取测试就是线性化读取。&lt;/p>
&lt;p>Note:&lt;/p>
&lt;ol>
&lt;li>下面的测试环境为 etcd 3.4.3 版本，k8s 集群已部署完成。测试命令就是根据上文官方的测试结果所使用的命令，一共测试 7 次&lt;/li>
&lt;li>先后创建 benchmark 别名，在别名中加指定证书和 endpoint。
&lt;ol>
&lt;li>echo &amp;lsquo;alias benchmark=&amp;ldquo;benchmark &amp;ndash;key=/etc/kubernetes/pki/etcd/peer.key &amp;ndash;cert=/etc/kubernetes/pki/etcd/peer.crt &amp;ndash;cacert=/etc/kubernetes/pki/etcd/ca.crt &amp;ndash;endpoints=172.40.0.3:2379,172.40.0.4:2379,172.40.0.5:2379&amp;rdquo;&amp;rsquo; &amp;raquo; /etc/bashrc&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>测试结果中，关于延迟数据的单位是 secs，是秒的意思，1 秒=1000 毫秒(ms)&lt;/li>
&lt;/ol>
&lt;h3 id="写入测试">写入测试&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># write to leader&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark --endpoints&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span> --target-leader --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> put --key-size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span> --sequential-keys --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10000&lt;/span> --val-size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">256&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark --endpoints&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span> --target-leader --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1000&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> put --key-size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span> --sequential-keys --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100000&lt;/span> --val-size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">256&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># write to all members&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark --endpoints&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_2&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_3&lt;span style="color:#e6db74">}&lt;/span> --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1000&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> put --key-size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span> --sequential-keys --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100000&lt;/span> --val-size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">256&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="读取测试">读取测试&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Single connection read requests&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark --endpoints&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_2&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_3&lt;span style="color:#e6db74">}&lt;/span> --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> range YOUR_KEY --consistency&lt;span style="color:#f92672">=&lt;/span>l --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark --endpoints&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_2&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_3&lt;span style="color:#e6db74">}&lt;/span> --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> range YOUR_KEY --consistency&lt;span style="color:#f92672">=&lt;/span>s --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Many concurrent read requests&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark --endpoints&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_2&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_3&lt;span style="color:#e6db74">}&lt;/span> --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1000&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> range YOUR_KEY --consistency&lt;span style="color:#f92672">=&lt;/span>l --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark --endpoints&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>HOST_1&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_2&lt;span style="color:#e6db74">}&lt;/span>,&lt;span style="color:#e6db74">${&lt;/span>HOST_3&lt;span style="color:#e6db74">}&lt;/span> --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1000&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> range YOUR_KEY --consistency&lt;span style="color:#f92672">=&lt;/span>s --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100000&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ benchmark --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>range foo --consistency&lt;span style="color:#f92672">=&lt;/span>l --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ benchmark --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>range foo --consistency&lt;span style="color:#f92672">=&lt;/span>s --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ benchmark --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1000&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>range foo --consistency&lt;span style="color:#f92672">=&lt;/span>l --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ benchmark --conns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span> --clients&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1000&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>range foo --consistency&lt;span style="color:#f92672">=&lt;/span>s --total&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100000&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="第三方-fio-工具测试">第三方 fio 工具测试&lt;/h1>
&lt;p>参考：&lt;a href="https://www.chenshaowen.com/blog/the-use-of-etcd-and-etcdctl.html">https://www.chenshaowen.com/blog/the-use-of-etcd-and-etcdctl.html&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.ibm.com/cloud/blog/using-fio-to-tell-whether-your-storage-is-fast-enough-for-etcd?mhsrc=ibmsearch_a&amp;amp;mhq=fio%2520etcd">https://www.ibm.com/cloud/blog/using-fio-to-tell-whether-your-storage-is-fast-enough-for-etcd?mhsrc=ibmsearch_a&amp;amp;mhq=fio%20etcd&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/etcd-io/etcd/issues/10577">https://github.com/etcd-io/etcd/issues/10577&lt;/a>&lt;/p>
&lt;p>etcd 的一些 Prometheus 指标。其中之一是 wal_fsync_duration_seconds。 etcd docs 建议该度量标准的第 99 个百分位数应小于 10 毫秒。如果您正在考虑 etcd 在 Linux 机器上运行 集群，并且需要评估存储（例如 SSD）是否足够快，那么一种选择是使用流行的 I/O 测试工具 fio。为此，您可以运行以下命令(其中 /var/lib/etcd 是要测试的存储设备的安装点下的目录,根据 etcd 存储路径进行修改)&lt;/p>
&lt;p>fio &amp;ndash;rw=write &amp;ndash;ioengine=sync &amp;ndash;fdatasync=1 &amp;ndash;directory=/var/lib/etcd &amp;ndash;size=22m &amp;ndash;bs=2300 &amp;ndash;name=mytest&lt;/p>
&lt;p>然后，您要做的就是查看输出并检查 fdatasync 持续时间的第 99 个百分位数 是否小于 10ms。如果真是这样，则您的存储空间足够快。这是示例输出：&lt;/p>
&lt;pre>&lt;code>fsync/fdatasync/sync_file_range:
sync (usec): min=534, max=15766, avg=1273.08, stdev=1084.70
sync percentiles (usec):
| 1.00th=[ 553], 5.00th=[ 578], 10.00th=[ 594], 20.00th=[ 627],
| 30.00th=[ 709], 40.00th=[ 750], 50.00th=[ 783], 60.00th=[ 1549],
| 70.00th=[ 1729], 80.00th=[ 1991], 90.00th=[ 2180], 95.00th=[ 2278],
| 99.00th=[ 2376], 99.50th=[ 9634], 99.90th=[15795], 99.95th=[15795],
| 99.99th=[15795]
&lt;/code>&lt;/pre>
&lt;p>一些注意事项：&lt;/p>
&lt;ul>
&lt;li>在上面的示例中，我们针对特定情况调整了&amp;ndash;size 和 &amp;ndash;bs 参数的值 。为了从中获得有意义的见解 fio，您应该使用最适合您的案例的值。要学习如何派生它们，请阅读我们 如何发现如何配置 fio 的信息。&lt;/li>
&lt;li>在测试过程中，fio 生成的 I / O 负载 是唯一的 I / O 活动。在实际情况下，除与 wal_fsync_duration_seconds 相关的写入外，可能还会对存储进行其他写入。这样的额外负载会使 wal_fsync_duration_seconds 更大。因此，如果您观察到的第 99 个百分位数 fio 仅略低于 10 毫秒，则可能是存储速度不够快。&lt;/li>
&lt;li>您需要的 Fio 版本至少应为 3.5， 因为较旧的版本不会报告 fdatasync 持续时间百分位数。&lt;/li>
&lt;li>上面的输出只是来自的整个输出的一小部分摘录 fio。&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>fio --randrepeat=1 \
--ioengine=libaio \
--direct=1 \
--gtod_reduce=1 \
--name=etcd-disk-io-test \
--filename=etcd_read_write.io \
--bs=4k --iodepth=64 --size=4G \
--readwrite=randrw --rwmixread=75
&lt;/code>&lt;/pre>
&lt;h1 id="etcd-官方推荐的硬件配置">etcd 官方推荐的硬件配置&lt;/h1>
&lt;p>官方文档：&lt;a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md">https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md&lt;/a>&lt;/p>
&lt;pre>&lt;code>etcd通常在开发或测试的时候用很少的资源就可以了，比如说使用普通的笔记本或者是廉价的云主机就可以，但是在生产环境上，还是需要按推荐的硬件配置进行部署，虽然这不是必须的，但是这样做可以增加集群的健壮性。一如既往，在上生产环境之前，需要先进行负载模拟测试。
&lt;/code>&lt;/pre>
&lt;p>CPUs&lt;/p>
&lt;pre>&lt;code>很少有etcd部署需要大量的CPU资源。典型的etcd部署节点，需要2-4个CPU就可以顺利运行。负载很高的etcd集群，比如上千客户端或者每秒超过上万请求，倾向于CPU绑定，可以直接从内存获取请求。即便这样重的负载，通常需要8-16个CPU就可以了。
&lt;/code>&lt;/pre>
&lt;p>内存&lt;/p>
&lt;pre>&lt;code>etcd占用的内存相对比较小，但是etcd性能仍然取决于是否拥有足够的内存。一个etcd服务器会积极的缓存key-value数据和大部分的跟踪watcher。通常8GB内存就够了，对于负载高的集群，比如有上千watcher和超过百万的keys，相应的就需要16GB-64GB内存。
&lt;/code>&lt;/pre>
&lt;p>磁盘&lt;/p>
&lt;p>高速磁盘是保证 etcd 部署性能和稳定性的关键因素。&lt;/p>
&lt;p>缓慢的磁盘会增加 etcd 请求的延迟，并有可能损害群集的稳定性。由于 etcd 的共识协议依赖于将元数据持久存储在日志中，因此大多数 etcd 集群成员必须将每个请求写入磁盘。另外，etcd 还将以增量方式将其状态检查到磁盘，以便可以截断该日志。如果这些写入花费的时间太长，则心跳可能会超时并触发选举，从而破坏了群集的稳定性。通常，要判断磁盘是否足够快用于 etcd，可以使用诸如 fio 之类的基准测试工具。阅读此处的示例&lt;/p>
&lt;pre>&lt;code>etcd对磁盘写入延时非常敏感。通常稳定达到50 IOPS（比如：一个7200转的磁盘）是必须的，对于负载很高的集群，推荐能稳定达到500 IOPS（比如：一个典型的本地SSD盘或者高性能的虚拟块设备盘）。注意，大多数云服务提供商发布的是瞬时并发IOPS，并不是稳定的IOPS，瞬时并发IOPS可能十倍于稳定连续的IOPS（说明：因为瞬时并发IOPS可能会写缓存，或者测试时无其他用户竞争磁盘资源，所以会很高，当测试时间很长后，就会测试出设备的真实IOPS能力，这个在国内云厂商基本没有这个问题）。测试稳定连续IOPS，我们建议使用磁盘基准测试工具，比如 diskbench 或者 fio。
etcd对磁盘带宽没什么要求，但是更大的磁盘带宽可以在失败节点加入集群时，更快的完成恢复操作。通常10MB/s带宽的磁盘15s可以恢复100MB的数据，对于大型集群，100MB/s或更高带宽的磁盘可以在15s内恢复1GB数据。
如果有可能，etcd后端存储就用SSD。一个SSD磁盘和机械盘相比，通常会提供更低的写入延时和更少的数据跳变（variance），因此可以提高etcd集群的稳定性和可靠性。如果使用机械盘，尽可能使用最快的（15000转）。使用RAID 0也是一种有效提高磁盘性能的方法，不管是机械盘还是SSD都可以。etcd集群至少有3个节点，磁盘使用RAID做镜像或者做奇偶校验都是不必要的，因为etcd自身的一致性复制已经保证了数据的高可用。
&lt;/code>&lt;/pre>
&lt;p>网络&lt;/p>
&lt;pre>&lt;code>多节点部署的etcd集群会受益于快速和可靠的网络。为了满足etcd集群的一致性和分区容忍，一个不可靠网络出现网络分区会导致部分节点无效。低延时可以保证etcd成员之间快速通信，高带宽可以减少etcd故障节点的恢复时间。1Gb网络就可以满足常见的etcd部署场景，对于大型etcd集群，使用10Gb网络可以减少平均故障恢复时间。
如果有可能，尽量将所有etcd成员节点部署在同一个数据中心，这样可以避免网络延时开销，降低发生网络分区的可能性。如果需要另外的数据中心级故障域，尽量选择和当前数据中心离得比较近的。也可以阅读性能调优文档，了解跨数据中心部署的更多信息。
&lt;/code>&lt;/pre>
&lt;h2 id="示例硬件配置">示例硬件配置&lt;/h2>
&lt;pre>&lt;code>这有一些在AWS和GCE环境上的硬件配置例子。如上所述，但是还是有必要再强调一下，无论如何，管理员在将etcd集群投入生产环境使用之前，都应该做一下模拟负载测试。
请注意：这些配置假设这些服务器只用来跑etcd服务。如果在这些服务器上还跑其他服务，可能会导致其他服务和etcd抢资源，存在资源竞争问题，导致etcd集群不稳定。
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>小型集群&lt;/strong>&lt;/p>
&lt;pre>&lt;code>一个小型集群服务少于100个客户端，访问请求小于每秒200，并且存储不超过100MB的数据。
&lt;/code>&lt;/pre>
&lt;p>示例应用负载：一个 50 节点的 kubernetes 集群&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>提供商&lt;/td>
&lt;td>类型&lt;/td>
&lt;td>vCPUs&lt;/td>
&lt;td>内存 (GB)&lt;/td>
&lt;td>最大并发 IOPS&lt;/td>
&lt;td>磁盘带宽 (MB/s)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>AWS&lt;/td>
&lt;td>m4.large&lt;/td>
&lt;td>2&lt;/td>
&lt;td>8&lt;/td>
&lt;td>3600&lt;/td>
&lt;td>56.25&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GCE&lt;/td>
&lt;td>n1-standard-2 + 50GB PD SSD&lt;/td>
&lt;td>2&lt;/td>
&lt;td>7.5&lt;/td>
&lt;td>1500&lt;/td>
&lt;td>25&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>中型集群&lt;/strong>&lt;/p>
&lt;pre>&lt;code>一个中型集群服务少于500个客户端，访问请求小于每秒1000，并且存储不超过500MB的数据。
&lt;/code>&lt;/pre>
&lt;p>示例应用负载：一个 250 节点的 kubernetes 集群&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>提供商&lt;/td>
&lt;td>类型&lt;/td>
&lt;td>vCPUs&lt;/td>
&lt;td>内存 (GB)&lt;/td>
&lt;td>最大并发 IOPS&lt;/td>
&lt;td>磁盘带宽 (MB/s)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>AWS&lt;/td>
&lt;td>m4.xlarge&lt;/td>
&lt;td>4&lt;/td>
&lt;td>16&lt;/td>
&lt;td>6000&lt;/td>
&lt;td>93.75&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GCE&lt;/td>
&lt;td>n1-standard-4 + 150GB PD SSD&lt;/td>
&lt;td>4&lt;/td>
&lt;td>15&lt;/td>
&lt;td>4500&lt;/td>
&lt;td>75&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>大型集群&lt;/strong>&lt;/p>
&lt;pre>&lt;code>一个大型集群服务少于1500个客户端，访问请求小于每秒10000，并且存储不超过1GB的数据。
&lt;/code>&lt;/pre>
&lt;p>示例应用负载：一个 1000 节点的 kubernetes 集群&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>提供商&lt;/td>
&lt;td>类型&lt;/td>
&lt;td>vCPUs&lt;/td>
&lt;td>内存 (GB)&lt;/td>
&lt;td>最大并发 IOPS&lt;/td>
&lt;td>磁盘带宽 (MB/s)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>AWS&lt;/td>
&lt;td>m4.2xlarge&lt;/td>
&lt;td>8&lt;/td>
&lt;td>32&lt;/td>
&lt;td>8000&lt;/td>
&lt;td>125&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GCE&lt;/td>
&lt;td>n1-standard-8 + 250GB PD SSD&lt;/td>
&lt;td>8&lt;/td>
&lt;td>30&lt;/td>
&lt;td>7500&lt;/td>
&lt;td>125&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>超大型集群&lt;/strong>&lt;/p>
&lt;pre>&lt;code>一个超大型集群服务超过1500个客户端，访问请求超过每秒10000，并且存储超过1GB的数据。
&lt;/code>&lt;/pre>
&lt;p>示例应用负载：一个 3000 节点的 kubernetes 集群&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>提供商&lt;/td>
&lt;td>类型&lt;/td>
&lt;td>vCPUs&lt;/td>
&lt;td>内存 (GB)&lt;/td>
&lt;td>最大并发 IOPS&lt;/td>
&lt;td>磁盘带宽 (MB/s)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>AWS&lt;/td>
&lt;td>m4.4xlarge&lt;/td>
&lt;td>16&lt;/td>
&lt;td>64&lt;/td>
&lt;td>16,000&lt;/td>
&lt;td>250&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GCE&lt;/td>
&lt;td>n1-standard-16 + 500GB PD SSD&lt;/td>
&lt;td>16&lt;/td>
&lt;td>60&lt;/td>
&lt;td>15,000&lt;/td>
&lt;td>250&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Docs: etcdctl user命令</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl-user%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl-user%E5%91%BD%E4%BB%A4/</guid><description>
&lt;h1 id="etcdctl-user-command-options-arguments--用户添加授予和撤消子命令">etcdctl user COMMAND [OPTIONS] [Arguments&amp;hellip;] # 用户添加，授予和撤消子命令&lt;/h1>
&lt;p>SubCommand 包括&lt;/p>
&lt;ul>
&lt;li>add # add a new user for the etcd cluster&lt;/li>
&lt;li>get # get details for a user&lt;/li>
&lt;li>list #list all current users&lt;/li>
&lt;li>remove #remove a user for the etcd cluster&lt;/li>
&lt;li>grant # grant roles to an etcd user&lt;/li>
&lt;li>revoke # revoke roles for an etcd user&lt;/li>
&lt;li>passwd # change password for a user&lt;/li>
&lt;/ul>
&lt;h2 id="etcdctl-user-add-user--为-etcd-集群添加用户">etcdctl user add USER # 为 etcd 集群添加用户&lt;/h2></description></item><item><title>Docs: etcdctl 命令行工具</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>官方文档：&lt;a href="https://github.com/etcd-io/etcd/tree/master/etcdctl">https://github.com/etcd-io/etcd/tree/master/etcdctl&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://etcd.io/docs/latest/integrations/">etcd 可用的库和客户端&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="etcdctl-globaloptions-command-commandoptions-arguments">etcdctl [GlobalOptions] COMMAND [CommandOptions] [Arguments&amp;hellip;]&lt;/h1>
&lt;p>使用说明：&lt;/p>
&lt;ol>
&lt;li>export ETCDCTL_API=3 使用该命令使得 etcdctl 通过 v3 版本来进行操作&lt;/li>
&lt;li>如果在 etcd 的配置文件中的 Security 段落，开启了验证证书，则在使用命令时，需要使用&amp;ndash;cert、&amp;ndash;key、&amp;ndash;cacert 选项来指定验证所需证书，否则无法操纵服务器
&lt;ol>
&lt;li>v2 版本中使用如下方式 etcdctl &amp;ndash;key-file=/etc/kubernetes/pki/etcd/peer.key &amp;ndash;cert-file=/etc/kubernetes/pki/etcd/peer.crt &amp;ndash;ca-file=/etc/kubernetes/pki/etcd/ca.crt &amp;ndash;endpoints=&amp;ldquo;https://IP:PORT&amp;rdquo; COMMAND&lt;/li>
&lt;li>v3 版本中使用如下方式 etcdctl &amp;ndash;key=/etc/kubernetes/pki/etcd/peer.key &amp;ndash;cert=/etc/kubernetes/pki/etcd/peer.crt &amp;ndash;cacert=/etc/kubernetes/pki/etcd/ca.crt &amp;ndash;endpoints=&amp;ldquo;https://IP:PORT&amp;rdquo; COMMAND&lt;/li>
&lt;li>在下面的 EXAMPLE 则不再输入认证相关参数，以便查阅方便。但是实际使用中需要使用，否则无法连接 etcd 服务端&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h2 id="global-options">GLOBAL OPTIONS:&lt;/h2>
&lt;ul>
&lt;li>** &amp;ndash;cacert=/PATH/FILE** # 使用此 CA 包验证启用 TLS 的安全服务器的证书。即 etcd 的 ca，用该 ca 来验证 cert 选项中提供的证书是否正确&lt;/li>
&lt;li>**&amp;ndash;cert=/PATH/FILE **# 使用指定的 TLS 证书文件鉴定客户端是否安全。即 etcd 的 peer 证书，peer 证书对于 etcdctl 来说就是与它交互的服务端的证书&lt;/li>
&lt;li>&lt;strong>&amp;ndash;key=/PATH/FILE&lt;/strong> # 使用指定的 TLS 证书的密钥文件鉴定客户端是否安全。即 etcd 的 peer 证书的私钥&lt;/li>
&lt;li>**&amp;ndash;endpoints=[IP1:PORT1,IP2:PORT2,&amp;hellip;..] **# 指定后端服务器的 IP 和 Port&lt;/li>
&lt;li>--command-timeout=5s # timeout for short running command (excluding dial timeout)&lt;/li>
&lt;li>--debug[=false] # enable client-side debug logging&lt;/li>
&lt;li>--dial-timeout=2s # dial timeout for client connections&lt;/li>
&lt;li>--hex[=false] # print byte strings as hex encoded strings&lt;/li>
&lt;li>--insecure-skip-tls-verify[=false # skip server certificate verification&lt;/li>
&lt;li>--insecure-transport[=true] # disable transport security for client connections&lt;/li>
&lt;li>--user=&amp;quot;&amp;quot; # username[:password] for authentication (prompt if password is not supplied)&lt;/li>
&lt;li>-w, &amp;ndash;write-out=&amp;ldquo;simple&amp;rdquo; # 指定输出内容的格式，格式可有有这么几个 (fields, json, protobuf, simple, table)(一般常用 json)
&lt;ul>
&lt;li>Note：输出的 json 格式只有一行，可以使用 jq 程序来对 json 进行格式化，可以把每个{}分行，以便人类阅读，下图为样例&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/miobxe/1616136392283-c0b50823-df6d-49d3-8d85-2aed1c7de3e0.jpeg" alt="">&lt;/p>
&lt;h1 id="子命令详解">子命令详解&lt;/h1>
&lt;h1 id="base-基本">Base 基本&lt;/h1>
&lt;h2 id="get--获取键或者键的范围gets-the-key-or-a-range-of-keys">get # 获取键或者键的范围。Gets the key or a range of keys&lt;/h2>
&lt;p>&lt;strong>etcdctl get [OPTIONS] [Range-End]&lt;/strong>
OPTIONS&lt;/p>
&lt;ul>
&lt;li>--consistency=&amp;ldquo;l&amp;rdquo; Linearizable(l) or Serializable(s)&lt;/li>
&lt;li>--from-key[=false] Get keys that are greater than or equal to the given key using byte compare&lt;/li>
&lt;li>**&amp;ndash;keys-only[=false] **# 仅获取键而不显示该键所对应的值&lt;/li>
&lt;li>--limit=0 #Maximum number of results&lt;/li>
&lt;li>--order=&amp;quot;&amp;quot; #Order of results; ASCEND or DESCEND (ASCEND by default)&lt;/li>
&lt;li>&lt;strong>&amp;ndash;prefix[=false]&lt;/strong> # 获取 KEY 前缀匹配到的所有的键。前缀就是键名的从开头开始的的字符串。可以指定&lt;code>''&lt;/code>匹配所有 KEY&lt;/li>
&lt;li>--print-value-only[=false] Only write values when using the &amp;ldquo;simple&amp;rdquo; output format&lt;/li>
&lt;li>--rev=0 Specify the kv revision&lt;/li>
&lt;li>--sort-by=&amp;quot;&amp;quot; Sort target; CREATE, KEY, MODIFY, VALUE, or VERSION&lt;/li>
&lt;/ul>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>etcdctl get &amp;ndash;prefix &amp;ndash;keys-only &amp;rsquo;&amp;rsquo; #获取所有键，并且只显示键名。&lt;/li>
&lt;li>etcdctl get &amp;ndash;prefix &amp;ndash;keys-only / #获取以&lt;code>/&lt;/code>开头的所有键，并且只显示键名。&lt;/li>
&lt;li>etcdv3 get /registry/events/kube-system/kube-flannel-ds-amd64-47cnw.15966b23d2027e45 -w=json | jq . #以 json 格式输出指定键的值，并使用 jq 命令对 json 内容进行格式化输出以便人类阅读&lt;/li>
&lt;/ul>
&lt;p>put # 写入一个 key/value 到 etcd 存储中。&lt;/p>
&lt;p>del # 删除指定的 key 或一个范围的 keys&lt;/p>
&lt;p>txn Txn processes all the requests in one transaction&lt;/p>
&lt;p>compaction Compacts the event history in etcd&lt;/p>
&lt;h1 id="alarm--etcd-中告警相关命令">alarm # etcd 中告警相关命令&lt;/h1>
&lt;h2 id="alerm-disarm--解除所有告警">alerm disarm # 解除所有告警&lt;/h2>
&lt;h2 id="alarm-list--列出-etcd-中所有的告警">alarm list # 列出 etcd 中所有的告警&lt;/h2>
&lt;h1 id="check--检查-etcd-的性能">check # 检查 etcd 的性能&lt;/h1>
&lt;h2 id="check-datascale--check-the-memory-usage-of-holding-data-for-different-workloads-on-a-given-server-endpoint">check datascale # Check the memory usage of holding data for different workloads on a given server endpoint.&lt;/h2>
&lt;h2 id="check-perf--检查-etcd-的性能">check perf # 检查 etcd 的性能&lt;/h2>
&lt;p>检查 60 秒的 etcd 群集性能。经常运行检查性能可以创建一个较大的键空间历史记录，可以使用&amp;ndash;auto-compact 和&amp;ndash;auto-defrag 选项（如下所述）对其进行自动压缩和碎片整理。&lt;/p>
&lt;p>OPTIONS&lt;/p>
&lt;ol>
&lt;li>--load # 性能检查的工作负载模型。可接受的工作负载：s(small 小)，m(medium 中)，l(large 大)，xl(x 大)&lt;/li>
&lt;/ol>
&lt;h1 id="defrag--对指定-endpoints-的-etcd-成员的存储空间进行碎片整理">defrag # 对指定 endpoints 的 etcd 成员的存储空间进行碎片整理&lt;/h1>
&lt;h1 id="endpoint--用于查询-etcd-中各个端点的信息">endpoint # 用于查询 etcd 中各个端点的信息&lt;/h1>
&lt;p>endpoint health #Checks the healthiness of endpoints specified in &lt;code>--endpoints&lt;/code> flag&lt;/p>
&lt;p>endpoint status # 打印出 &amp;ndash;endpoints 标志中指定的 endpoints 状态&lt;/p>
&lt;p>endpoint hashkv #Prints the KV history hash for each endpoint in &amp;ndash;endpoints&lt;/p>
&lt;h1 id="lease-相关命令">lease 相关命令&lt;/h1>
&lt;p>lease grant Creates leases&lt;/p>
&lt;p>lease revoke Revokes leases&lt;/p>
&lt;p>lease timetolive Get lease information&lt;/p>
&lt;p>lease keep-alive Keeps leases alive (renew)&lt;/p>
&lt;h1 id="member--用于管理-etcd-集群中的成员">member # 用于管理 etcd 集群中的成员&lt;/h1>
&lt;p>member add # 将新成员作为新对等方引入 etcd 集群中。&lt;/p>
&lt;p>member remove # 从参与集群共识的成员中删除 etcd 集群的成员。&lt;/p>
&lt;p>member update # 为 etcd 集群中现有成员设置对等 URL。&lt;/p>
&lt;p>member list # 列出集群中的所有成员&lt;/p>
&lt;p>EXAMPLE&lt;/p>
&lt;ol>
&lt;li>etcdctl member list #列出 etcd 集群中的成员&lt;/li>
&lt;li>etcdctl member list &amp;ndash;write-out=json | jq . #通过 json 可以看到 etcd 集群中，哪个是节点是 leader&lt;/li>
&lt;/ol>
&lt;h1 id="snapshot-快照相关命令用来让用户对-etcd-的数据进行备份与恢复">snapshot 快照相关命令。用来让用户对 etcd 的数据进行备份与恢复。&lt;/h1>
&lt;p>&lt;strong>etcdctl snapshot save&lt;/strong> # 存储一个 etcd 节点后端快照到指定文件。Stores an etcd node backend snapshot to a given file
EXAMPLE&lt;/p>
&lt;ul>
&lt;li>etcdctl snapshot save snapshot.db #备份指定后端节点的 etcd 数据到 snapshot.db 文件&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>etcdctl snapshot restore [OPTIONS]&lt;/strong> # 恢复一个 etcd 成员的快照到一个 etcd 的文件夹中。
OPTIONS&lt;/p>
&lt;ul>
&lt;li>**&amp;ndash;data-dir=/PATH/FILE **# 把指定的路径作为 snapshot 文件的恢复目录，会把数据写到指定的目录下。Path to the data directory&lt;/li>
&lt;/ul>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>etcdctl snapshot restore snapshot.db &amp;ndash;data-dir=/var/lib/etcd/ #从 snapshot.db 文件中恢复数据到/var/lib/etcd/目录下&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>etcdctl snapshot status&lt;/strong> # 取指定文件的后端快照状态。Gets backend snapshot status of a given file
EXAMPLE&lt;/p>
&lt;ul>
&lt;li>etcdv3 snapshot status snapshot.db #获取 snapshot.db 的状态，包括键/值对有多少，占多少空间&lt;/li>
&lt;/ul>
&lt;h1 id="其他">其他&lt;/h1>
&lt;p>make-mirror Makes a mirror at the destination etcd cluster&lt;/p>
&lt;p>migrate Migrates keys in a v2 store to a mvcc store&lt;/p>
&lt;p>lock Acquires a named lock&lt;/p>
&lt;p>elect Observes and participates in leader election&lt;/p>
&lt;p>auth enable Enables authentication&lt;/p>
&lt;p>auth disable Disables authentication&lt;/p>
&lt;h2 id="user--etcd-用户相关的命令">user # etcd 用户相关的命令&lt;/h2>
&lt;p>详见：&lt;a href="https://www.yuque.com/go/doc/33190532">etcdctl user 命令&lt;/a>&lt;/p>
&lt;h2 id="role--etcd-的-role-相关的命令">role # etcd 的 role 相关的命令&lt;/h2>
&lt;p>role add #Adds a new role&lt;/p>
&lt;p>role delete #Deletes a role&lt;/p>
&lt;p>role get #Gets detailed information of a role&lt;/p>
&lt;p>role list #Lists all roles&lt;/p>
&lt;p>role grant-permission #Grants a key to a role&lt;/p>
&lt;p>role revoke-permission #Revokes a key from a role&lt;/p>
&lt;p>watch Watches events stream on keys or prefixes&lt;/p></description></item><item><title>Docs: etcdserver: read-only range request took too long to execute</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/etcdserver_-read-only-range-request-took-too-long-to-execute/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/etcd/etcd-%E7%AE%A1%E7%90%86/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/etcdserver_-read-only-range-request-took-too-long-to-execute/</guid><description>
&lt;h1 id="heading">&lt;/h1>
&lt;p>错误信息： etcdserver: read-only range request took too long to execute&lt;/p>
&lt;p>问题原因：&lt;/p>
&lt;p>有可能是磁盘性能导致，当磁盘性能只有 2，3 十兆的读写速度，那么有很大机率会出现此错误。&lt;/p>
&lt;p>参考：&lt;/p>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/issues/70082">https://github.com/kubernetes/kubernetes/issues/70082&lt;/a>&lt;/p></description></item><item><title>Docs: generic 组</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/generic-%E7%BB%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/redis/redis-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/generic-%E7%BB%84/</guid><description>
&lt;h2 id="del-key-key---删除一个-key">DEL key [key &amp;hellip;] # 删除一个 key&lt;/h2>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>EXAMPLE&lt;/p>
&lt;p>DUMP key&lt;/p>
&lt;p>summary: Return a serialized version of the value stored at the specified key.&lt;/p>
&lt;p>since: 2.6.0&lt;/p>
&lt;h2 id="exists-key-key---判断指定的-key-是否存在">EXISTS key [key &amp;hellip;] # 判断指定的 key 是否存在&lt;/h2>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>EXPIRE key seconds&lt;/p>
&lt;p>summary: Set a key&amp;rsquo;s time to live in seconds&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>EXPIREAT key timestamp&lt;/p>
&lt;p>summary: Set the expiration for a key as a UNIX timestamp&lt;/p>
&lt;p>since: 1.2.0&lt;/p>
&lt;h2 id="keys-pattern--查找与指定-pattern-匹配到的所有-keys">KEYS pattern # 查找与指定 pattern 匹配到的所有 keys。&lt;/h2>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>EXAMPLE&lt;/p>
&lt;ol>
&lt;li>keys * # 获取所有的键&lt;/li>
&lt;/ol>
&lt;p>MIGRATE host port key| destination-db timeout [COPY] [REPLACE] [KEYS key]&lt;/p>
&lt;p>summary: Atomically transfer a key from a Redis instance to another one.&lt;/p>
&lt;p>since: 2.6.0&lt;/p>
&lt;p>MOVE key db&lt;/p>
&lt;p>summary: Move a key to another database&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>OBJECT subcommand [arguments [arguments &amp;hellip;]]&lt;/p>
&lt;p>summary: Inspect the internals of Redis objects&lt;/p>
&lt;p>since: 2.2.3&lt;/p>
&lt;p>PERSIST key&lt;/p>
&lt;p>summary: Remove the expiration from a key&lt;/p>
&lt;p>since: 2.2.0&lt;/p>
&lt;p>PEXPIRE key milliseconds&lt;/p>
&lt;p>summary: Set a key&amp;rsquo;s time to live in milliseconds&lt;/p>
&lt;p>since: 2.6.0&lt;/p>
&lt;p>PEXPIREAT key milliseconds-timestamp&lt;/p>
&lt;p>summary: Set the expiration for a key as a UNIX timestamp specified in milliseconds&lt;/p>
&lt;p>since: 2.6.0&lt;/p>
&lt;p>PTTL key&lt;/p>
&lt;p>summary: Get the time to live for a key in milliseconds&lt;/p>
&lt;p>since: 2.6.0&lt;/p>
&lt;p>RANDOMKEY -&lt;/p>
&lt;p>summary: Return a random key from the keyspace&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>RENAME key newkey&lt;/p>
&lt;p>summary: Rename a key&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>RENAMENX key newkey&lt;/p>
&lt;p>summary: Rename a key, only if the new key does not exist&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>RESTORE key ttl serialized-value [REPLACE]&lt;/p>
&lt;p>summary: Create a key using the provided serialized value, previously obtained using DUMP.&lt;/p>
&lt;p>since: 2.6.0&lt;/p>
&lt;p>SCAN cursor [MATCH pattern] [COUNT count]&lt;/p>
&lt;p>summary: Incrementally iterate the keys space&lt;/p>
&lt;p>since: 2.8.0&lt;/p>
&lt;p>SORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern &amp;hellip;]] [ASC|DESC] [ALPHA] [STORE destination]&lt;/p>
&lt;p>summary: Sort the elements in a list, set or sorted set&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>TTL key&lt;/p>
&lt;p>summary: Get the time to live for a key&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>TYPE key&lt;/p>
&lt;p>summary: Determine the type stored at key&lt;/p>
&lt;p>since: 1.0.0&lt;/p>
&lt;p>WAIT numslaves timeout&lt;/p>
&lt;p>summary: Wait for the synchronous replication of all the write commands sent in the context of the current connection&lt;/p>
&lt;p>since: 3.0.0&lt;/p>
&lt;p>XRANGE key arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XGROUP arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>LOLWUT arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XREADGROUP key arg arg arg arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>PFDEBUG arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>GEORADIUS_RO key arg arg arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>HOST: arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XCLAIM key arg arg arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XPENDING key arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XACK key arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XDEL key arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XTRIM key arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>REPLCONF arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XREVRANGE key arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>BZPOPMIN key arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>LATENCY arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>TOUCH key arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XLEN key arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>RESTORE-ASKING key arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>GEORADIUSBYMEMBER_RO key arg arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>ZPOPMIN key arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>POST arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XREAD key arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>PSYNC arg arg arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XINFO arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>BZPOPMAX key arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>ASKING arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>SWAPDB arg arg arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>SUBSTR key arg arg arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XSETID key arg arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>UNLINK key arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>MODULE arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>PFSELFTEST arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>REPLICAOF arg arg arg&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>MEMORY arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>XADD key arg arg arg arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p>
&lt;p>ZPOPMAX key arg &amp;hellip;options&amp;hellip;&lt;/p>
&lt;p>summary: Help not available&lt;/p>
&lt;p>since: not known&lt;/p></description></item><item><title>Docs: GlusterFS</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/glusterfs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/glusterfs/</guid><description/></item><item><title>Docs: GlusterFS 的部署与使用</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/glusterfs/glusterfs-%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/glusterfs/glusterfs-%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>
&lt;h1 id="glusterfs-的部署与使用">GlusterFS 的部署与使用&lt;/h1>
&lt;p>初始化 yum 源配置&lt;/p>
&lt;p>yum install centos-release-gluster6 -y&lt;/p>
&lt;p>分区、格式化、挂载使用 bricks 的磁盘&lt;/p>
&lt;p>Assuming you have a brick at /dev/sdb:&lt;/p>
&lt;p>fdisk /dev/sdb&lt;/p>
&lt;p>Create a single partition on the brick that uses the whole capacity.&lt;/p>
&lt;p>格式化分区&lt;/p>
&lt;p>mkfs.xfs -i size=512 /dev/sdb&lt;/p>
&lt;p>将分区挂载为 gluster 的 brick&lt;/p>
&lt;p>mkdir -p /data/brick1 &amp;amp;&amp;amp; mount /dev/sdb /data/brick1 &amp;amp;&amp;amp; mkdir -p /data/brick1brick&lt;/p>
&lt;p>在/etc/fstab 文件中添加条目使得目录自动挂载&lt;/p>
&lt;p>echo &amp;ldquo;/dev/sdb /data/brick1 xfs defaults 0 0&amp;rdquo; &amp;raquo; /etc/fstab&lt;/p>
&lt;p>在所有节点安装 glusterfs 所用的包&lt;/p>
&lt;p>yum install glusterfs{,-server,-fuse,-geo-replication,-client} -y&lt;/p>
&lt;p>Note: This example assumes Fedora 18 or later, where gluster packages are included in the official repository&lt;/p>
&lt;p>启动 glusterd 服务&lt;/p>
&lt;p>systemctl start glusterd &amp;amp;&amp;amp; systemctl status glusterd &amp;amp;&amp;amp; systemctl enable glusterd&lt;/p>
&lt;p>从一个节点添加另一个节点，使之组成集群&lt;/p>
&lt;p>Note! From node01 to the other nodes (do not peer probe the first node)&lt;/p>
&lt;p>gluster peer probe&lt;/p>
&lt;p>创建一个 volume，指定卷名、类型、以及各节点所用目录&lt;/p>
&lt;p>gluster volume create testvol rep 2 transport tcp node1:/data/brick1/brick node2:/data/brick1/brick&lt;/p>
&lt;p>启动新添加的卷&lt;/p>
&lt;p>gluster volume start testvol&lt;/p>
&lt;p>在其他节点挂载 glusterfs 服务端上的卷到本地&lt;/p>
&lt;p>mkdir /mnt/gluster&lt;/p>
&lt;p>mount -t glusterfs node1:/testvol /mnt/gluster&lt;/p>
&lt;p>挂载完成后，该挂载目录就是 guluster 服务端远程的卷目录，写入该目录的文件会同时写到 volume 所定义的所有节点下的目录&lt;/p>
&lt;p>Done!&lt;/p></description></item><item><title>Docs: gluster命令</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/glusterfs/gluster%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/glusterfs/gluster%E5%91%BD%E4%BB%A4/</guid><description/></item><item><title>Docs: Hadoop</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/3.%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/3.%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/</guid><description/></item><item><title>Docs: mc 工具</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/minio/mc-%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/minio/mc-%E5%B7%A5%E5%85%B7/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.min.io/minio/baremetal/reference/minio-cli/minio-mc.html">官方文档,MinIO 客户端&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="配置">配置&lt;/h1>
&lt;p>~/.mc/config.json # mc 从该文件中获取将要操作的 host 信息。可以通过 mc config host 命令管理该文件，也可以直接手动编辑。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#960050;background-color:#1e0010">root@nfs&lt;/span>&lt;span style="color:#ae81ff">-1&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">~&lt;/span>]&lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">cat&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">~/.mc/config.json&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;version&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;10&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;aliases&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;gcs&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;url&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;https://storage.googleapis.com&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;accessKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;YOUR-ACCESS-KEY-HERE&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;secretKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;YOUR-SECRET-KEY-HERE&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;api&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;S3v2&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;dns&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;local&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;url&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;http://0.0.0.0:9000&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;accessKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;minioadmin&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;secretKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;ehl@1234&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;api&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;S3v4&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;auto&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;play&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;url&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;https://play.min.io&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;accessKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Q3AM3UQ867SPQQA43P2F&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;secretKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;api&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;S3v4&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;auto&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;s3&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;url&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;https://s3.amazonaws.com&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;accessKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;YOUR-ACCESS-KEY-HERE&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;secretKey&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;YOUR-SECRET-KEY-HERE&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;api&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;S3v4&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;dns&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="syntax语法">Syntax(语法)&lt;/h1>
&lt;p>&lt;strong>mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS&amp;hellip;]&lt;/strong>&lt;/p>
&lt;p>COMMAND&lt;/p>
&lt;ul>
&lt;li>&lt;strong>alias&lt;/strong> # set, remove and list aliases in configuration file&lt;/li>
&lt;li>&lt;strong>ls&lt;/strong> # 列出桶和对象&lt;/li>
&lt;li>mb         make a bucket&lt;/li>
&lt;li>rb         remove a bucket&lt;/li>
&lt;li>cp         copy objects&lt;/li>
&lt;li>mirror     synchronize object(s) to a remote site&lt;/li>
&lt;li>cat        display object contents&lt;/li>
&lt;li>head       display first &amp;rsquo;n&amp;rsquo; lines of an object&lt;/li>
&lt;li>pipe       stream STDIN to an object&lt;/li>
&lt;li>share      generate URL for temporary access to an object&lt;/li>
&lt;li>find       search for objects&lt;/li>
&lt;li>sql        run sql queries on objects&lt;/li>
&lt;li>stat       show object metadata&lt;/li>
&lt;li>mv         move objects&lt;/li>
&lt;li>tree       list buckets and objects in a tree format&lt;/li>
&lt;li>du         summarize disk usage recursively&lt;/li>
&lt;li>retention  set retention for object(s)&lt;/li>
&lt;li>legalhold  manage legal hold for object(s)&lt;/li>
&lt;li>diff       list differences in object name, size, and date between two buckets&lt;/li>
&lt;li>&lt;strong>rm&lt;/strong> # 移除桶&lt;/li>
&lt;li>version    manage bucket versioning&lt;/li>
&lt;li>&lt;strong>ilm&lt;/strong> # 管理桶的生命周期&lt;/li>
&lt;li>encrypt    manage bucket encryption config&lt;/li>
&lt;li>event      manage object notifications&lt;/li>
&lt;li>watch      listen for object notification events&lt;/li>
&lt;li>undo       undo PUT/DELETE operations&lt;/li>
&lt;li>policy     manage anonymous access to buckets and objects&lt;/li>
&lt;li>tag        manage tags for bucket and object(s)&lt;/li>
&lt;li>replicate  configure server side bucket replication&lt;/li>
&lt;li>admin      manage MinIO servers&lt;/li>
&lt;li>update     update mc to latest release&lt;/li>
&lt;/ul>
&lt;h1 id="子命令语法">子命令语法&lt;/h1>
&lt;h2 id="config">config&lt;/h2>
&lt;p>&lt;strong>mc config host COMMAND [COMMAND FLAGS | -h] [ARGUMENTS&amp;hellip;]&lt;/strong>&lt;/p>
&lt;p>COMMAND:&lt;/p>
&lt;ul>
&lt;li>add, a # 添加一个新的主机到配置文件。&lt;/li>
&lt;li>remove, rm # 从配置文件中删除一个主机。&lt;/li>
&lt;li>list, ls # 列出配置文件中的主机。&lt;/li>
&lt;/ul>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>添加一个 host
&lt;ul>
&lt;li>&lt;strong>mc config host add miniodev130 http://10.8.208.130:9000 minioadmin minioadmin&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="ilm">ilm&lt;/h2>
&lt;p>管理桶的生命周期&lt;/p>
&lt;p>&lt;strong>mc ilm COMMAND [COMMAND FLAGS | -h] [ARGUMENTS&amp;hellip;]&lt;/strong>&lt;/p>
&lt;p>COMMAND&lt;/p>
&lt;ul>
&lt;li>&lt;strong>add&lt;/strong> # 为一个桶添加生命周期配置规则&lt;/li>
&lt;li>&lt;strong>edit&lt;/strong> # 修改指定 ID 的生命周期配置规则&lt;/li>
&lt;li>&lt;strong>ls&lt;/strong> # 列出设置在一个桶上的生命周期配置规则集&lt;/li>
&lt;li>&lt;strong>rm&lt;/strong> # 删除生命周期配置规则&lt;/li>
&lt;li>export  export lifecycle configuration in JSON format&lt;/li>
&lt;li>import  import lifecycle configuration in JSON format&lt;/li>
&lt;/ul>
&lt;h3 id="add">add&lt;/h3>
&lt;p>&lt;strong>mc ilm add [FLAGS] TARGET&lt;/strong>&lt;/p>
&lt;p>FLAGS&lt;/p>
&lt;ul>
&lt;li>**&amp;ndash;expiry-days VALUE **# 创建对象后保留的天数。MinIO 在经过指定的天数后标记要删除的对象&lt;/li>
&lt;/ul>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>local/loki-bj-net 这个桶中创建的对象将在 7 天后过期
&lt;ul>
&lt;li>&lt;strong>mc ilm add &amp;ndash;expiry-days 7 local/loki-bj-net&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="ls">ls&lt;/h3>
&lt;p>列出设置在一个 bucket 上的生命周期配置规则集，效果如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@nfs-1 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># mc ilm ls local/loki-bj-net&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ID | Prefix | Enabled | Expiry | Date/Days | Transition | Date/Days | Storage-Class | Tags
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>----------------------|----------------|------------|--------|--------------|--------------|------------------|------------------|------------------------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> c36rknaqqqm9ds69f5fg | | ✓ | ✓ | &lt;span style="color:#ae81ff">7&lt;/span> day&lt;span style="color:#f92672">(&lt;/span>s&lt;span style="color:#f92672">)&lt;/span> | ✗ | | |
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>----------------------|----------------|------------|--------|--------------|--------------|------------------|------------------|------------------------
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="rm">rm&lt;/h3>
&lt;p>&lt;strong>mc ilm rm [FLAGS] TARGET&lt;/strong>&lt;/p>
&lt;p>&lt;strong>FLAGS&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>**&amp;ndash;id VALUE **# 指定要删除的生命周期规则的 ID&lt;/li>
&lt;/ul>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>删除 local/chunks 桶中 id 为 cbod0cqqqqm5tvms1svg 的生命周期规则
&lt;ul>
&lt;li>&lt;strong>mc ilm rm &amp;ndash;id cbod0cqqqqm5tvms1svg local/chunks&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="rm-1">rm&lt;/h2>
&lt;p>&lt;strong>mc rm [FLAGS] TARGET [TARGET &amp;hellip;]&lt;/strong>&lt;/p>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>删除 local 环境下 thanos 桶中的所有对象
&lt;ul>
&lt;li>&lt;strong>mc rm &amp;ndash;recursive &amp;ndash;force local/thanos&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>删除 local 环境下 thanos-bj-test 桶中 24 小时前的所有对象
&lt;ul>
&lt;li>&lt;strong>mc rm &amp;ndash;recursive &amp;ndash;force &amp;ndash;older-than 24h local/thanos-bj-test&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: MinIO</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/minio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/distributed-storage%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/minio/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://min.io/">官网&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/minio/minio">GitHub 项目&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/aRTE_UUQ0GMXhqiemxQnsg">https://mp.weixin.qq.com/s/aRTE_UUQ0GMXhqiemxQnsg&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="minio-部署">MinIO 部署&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.min.io/minio/baremetal/tutorials/minio-installation.html">官方文档,安装&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="docker-启动单点-minio">docker 启动单点 MinIO&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -p 9000:9000 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-e &lt;span style="color:#e6db74">&amp;#34;MINIO_ACCESS_KEY=minioadmin&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-e &lt;span style="color:#e6db74">&amp;#34;MINIO_SECRET_KEY=minioadmin&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-v /mnt/disk1:/disk1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-v /mnt/disk2:/disk2 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-v /mnt/disk3:/disk3 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-v /mnt/disk4:/disk4 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>minio/minio server /disk&lt;span style="color:#f92672">{&lt;/span>1...4&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>MINIO_ACCESS_KEY 与 MINIO_SECRET_KEY 指定连接 MinIO 时所需的认证信息，AK、SK
本地 /mnt 下的 4 个目录&lt;/p></description></item><item><title>Docs: MySQL</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.mysql.com/">官网&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>MySQL 的社区版本 MariaDB ，使用安装 MySQL 的 时候，会自动安装 MariaDB 。同时安装 mariadb-server ，即可开始使用了&lt;/p>
&lt;h1 id="mysql-部署">MySQL 部署&lt;/h1>
&lt;h2 id="docker-启动-mysql">docker 启动 MySQL&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mkdir -p /opt/mysql/config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir -p /opt/mysql/data
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker run -d --name mysql --restart always &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--network host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-v /opt/mysql/data:/var/lib/mysql
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-v /opt/mysql/config:/etc/mysql/conf.d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-e MYSQL_ROOT_PASSWORD&lt;span style="color:#f92672">=&lt;/span>mysql &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>mysql:8
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于 5.7+ 版本，推荐设置 SQL Mode，去掉默认的 ONLY_FULL_GROUP_BY。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>tee /opt/mysql/config/mysql.cnf &amp;gt; /dev/null &lt;span style="color:#e6db74">&amp;lt;&amp;lt;EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">[mysqld]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果不去掉这个模式，当我们使用 &lt;code>group by&lt;/code> 时，&lt;code>select&lt;/code> 中选择的列如果不在 group by 中，将会报错：
&lt;code>ERROR 1055 (42000): Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column 'kalacloud.user_id' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by&lt;/code>
如果想解决该错误，除了修改 SQL 模式外，还可以使用 &lt;code>ANY_VALUE()&lt;/code> 函数处理每一个 select 选中的列但是没有参与 group by 分组的字段。详见：&lt;a href="https://dev.mysql.com/doc/refman/5.7/en/group-by-handling.html">官方文档，函数和运算符-聚合函数-MySQL 对 GROUP BY 的处理&lt;/a>&lt;/p>
&lt;h2 id="kubernetes-中部署-mysql">Kubernetes 中部署 MySQL&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/C0EYTBJ7sLw823-qE5TjTA">阳明公众号&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="mysql-关联文件与配置">MySQL 关联文件与配置&lt;/h1>
&lt;p>**/etc/my.cnf **# MariaDB 基础配置文件
&lt;strong>/var/lib/myql/*&lt;/strong> # 数据存储路径&lt;/p>
&lt;h1 id="mysql-数据类型">MySQL 数据类型&lt;/h1>
&lt;p>MySQL 中定义数据字段的类型对你数据库的优化是非常重要的。
MySQL 支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。&lt;/p>
&lt;h2 id="数值类型">数值类型&lt;/h2>
&lt;p>MySQL 支持所有标准 SQL 数值数据类型。&lt;/p>
&lt;p>这些类型包括严格数值数据类型(INTEGER、SMALLINT、DECIMAL 和 NUMERIC)，以及近似数值数据类型(FLOAT、REAL 和 DOUBLE PRECISION)。&lt;/p>
&lt;p>关键字 INT 是 INTEGER 的同义词，关键字 DEC 是 DECIMAL 的同义词。&lt;/p>
&lt;p>BIT 数据类型保存位字段值，并且支持 MyISAM、MEMORY、InnoDB 和 BDB 表。&lt;/p>
&lt;p>作为 SQL 标准的扩展，MySQL 也支持整数类型 TINYINT、MEDIUMINT 和 BIGINT。下面的表显示了需要的每个整数类型的存储和范围。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>类型&lt;/th>
&lt;th>大小&lt;/th>
&lt;th>范围（有符号）&lt;/th>
&lt;th>范围（无符号）&lt;/th>
&lt;th>用途&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>TINYINT&lt;/td>
&lt;td>1 byte&lt;/td>
&lt;td>(-128，127)&lt;/td>
&lt;td>(0，255)&lt;/td>
&lt;td>小整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SMALLINT&lt;/td>
&lt;td>2 bytes&lt;/td>
&lt;td>(-32 768，32 767)&lt;/td>
&lt;td>(0，65 535)&lt;/td>
&lt;td>大整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MEDIUMINT&lt;/td>
&lt;td>3 bytes&lt;/td>
&lt;td>(-8 388 608，8 388 607)&lt;/td>
&lt;td>(0，16 777 215)&lt;/td>
&lt;td>大整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT 或 INTEGER&lt;/td>
&lt;td>4 bytes&lt;/td>
&lt;td>(-2 147 483 648，2 147 483 647)&lt;/td>
&lt;td>(0，4 294 967 295)&lt;/td>
&lt;td>大整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BIGINT&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>(-9,223,372,036,854,775,808，9 223 372 036 854 775 807)&lt;/td>
&lt;td>(0，18 446 744 073 709 551 615)&lt;/td>
&lt;td>极大整数值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FLOAT&lt;/td>
&lt;td>4 bytes&lt;/td>
&lt;td>(-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38)&lt;/td>
&lt;td>0，(1.175 494 351 E-38，3.402 823 466 E+38)&lt;/td>
&lt;td>单精度&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>浮点数值&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DOUBLE&lt;/td>
&lt;td>8 bytes&lt;/td>
&lt;td>(-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)&lt;/td>
&lt;td>0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)&lt;/td>
&lt;td>双精度&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>浮点数值&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DECIMAL&lt;/td>
&lt;td>对 DECIMAL(M,D) ，如果 M&amp;gt;D，为 M+2 否则为 D+2&lt;/td>
&lt;td>依赖于 M 和 D 的值&lt;/td>
&lt;td>依赖于 M 和 D 的值&lt;/td>
&lt;td>小数值&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="日期和时间类型">日期和时间类型&lt;/h2>
&lt;p>表示时间值的日期和时间类型为 DATETIME、DATE、TIMESTAMP、TIME 和 YEAR。&lt;/p>
&lt;p>每个时间类型有一个有效值范围和一个&amp;quot;零&amp;quot;值，当指定不合法的 MySQL 不能表示的值时使用&amp;quot;零&amp;quot;值。&lt;/p>
&lt;p>TIMESTAMP 类型有专有的自动更新特性，将在后面描述。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>类型&lt;/th>
&lt;th>大小( bytes)&lt;/th>
&lt;th>范围&lt;/th>
&lt;th>格式&lt;/th>
&lt;th>用途&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>DATE&lt;/td>
&lt;td>3&lt;/td>
&lt;td>1000-01-01/9999-12-31&lt;/td>
&lt;td>YYYY-MM-DD&lt;/td>
&lt;td>日期值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TIME&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&amp;lsquo;-838:59:59&amp;rsquo;/&amp;lsquo;838:59:59&amp;rsquo;&lt;/td>
&lt;td>HH:MM:SS&lt;/td>
&lt;td>时间值或持续时间&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>YEAR&lt;/td>
&lt;td>1&lt;/td>
&lt;td>1901/2155&lt;/td>
&lt;td>YYYY&lt;/td>
&lt;td>年份值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DATETIME&lt;/td>
&lt;td>8&lt;/td>
&lt;td>1000-01-01 00:00:00/9999-12-31 23:59:59&lt;/td>
&lt;td>YYYY-MM-DD HH:MM:SS&lt;/td>
&lt;td>混合日期和时间值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TIMESTAMP&lt;/td>
&lt;td>4&lt;/td>
&lt;td>1970-01-01 00:00:00/2038&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038 年 1 月 19 日 凌晨 03:14:07&lt;/td>
&lt;td>YYYYMMDD HHMMSS&lt;/td>
&lt;td>混合日期和时间值，时间戳&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="字符串类型">字符串类型&lt;/h2>
&lt;p>字符串类型指 CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM 和 SET。该节描述了这些类型如何工作以及如何在查询中使用这些类型。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>类型&lt;/th>
&lt;th>大小&lt;/th>
&lt;th>用途&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>CHAR&lt;/td>
&lt;td>0-255 bytes&lt;/td>
&lt;td>定长字符串&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VARCHAR&lt;/td>
&lt;td>0-65535 bytes&lt;/td>
&lt;td>变长字符串&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TINYBLOB&lt;/td>
&lt;td>0-255 bytes&lt;/td>
&lt;td>不超过 255 个字符的二进制字符串&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TINYTEXT&lt;/td>
&lt;td>0-255 bytes&lt;/td>
&lt;td>短文本字符串&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BLOB&lt;/td>
&lt;td>0-65 535 bytes&lt;/td>
&lt;td>二进制形式的长文本数据&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TEXT&lt;/td>
&lt;td>0-65 535 bytes&lt;/td>
&lt;td>长文本数据&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MEDIUMBLOB&lt;/td>
&lt;td>0-16 777 215 bytes&lt;/td>
&lt;td>二进制形式的中等长度文本数据&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MEDIUMTEXT&lt;/td>
&lt;td>0-16 777 215 bytes&lt;/td>
&lt;td>中等长度文本数据&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LONGBLOB&lt;/td>
&lt;td>0-4 294 967 295 bytes&lt;/td>
&lt;td>二进制形式的极大文本数据&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LONGTEXT&lt;/td>
&lt;td>0-4 294 967 295 bytes&lt;/td>
&lt;td>极大文本数据&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>注意：char(n) 和 varchar(n) 中括号中 n 代表字符的个数，并不代表字节个数，比如 CHAR(30) 就可以存储 30 个字符。&lt;/p>
&lt;p>CHAR 和 VARCHAR 类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。&lt;/p>
&lt;p>BINARY 和 VARBINARY 类似于 CHAR 和 VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值值。&lt;/p>
&lt;p>BLOB 是一个二进制大对象，可以容纳可变数量的数据。有 4 种 BLOB 类型：TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB。它们区别在于可容纳存储范围不同。&lt;/p>
&lt;p>有 4 种 TEXT 类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。对应的这 4 种 BLOB 类型，可存储的最大长度不同，可根据实际情况选择。&lt;/p>
&lt;h1 id="mysql-命令行工具">mysql 命令行工具&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://dev.mysql.com/doc/refman/8.0/en/mysql.html">官方文档，MySQL 程序-客户端程序-mysql&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>mysql 是一个简单的 SQL Shell。 它支持交互和非交互使用。 交互使用时，查询结果以 ASCII 表格式显示。 非交互使用（例如，用作过滤器）时，结果以制表符分隔的格式显示。 可以使用命令选项更改输出格式。&lt;/p>
&lt;h2 id="syntax语法">Syntax(语法)&lt;/h2>
&lt;p>&lt;strong>mysql [OPTIONS] [DATABASE]&lt;/strong>
**DATABASE **# 指定连接 mysql 后要操作的数据库。若不指定，则需要在交互模式下使用 &lt;code>use&lt;/code> 指令选择数据库，否则对数据库的操作将会报 &lt;code>No database selected&lt;/code> 错误：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mysql&amp;gt; show tables;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ERROR &lt;span style="color:#ae81ff">1046&lt;/span> &lt;span style="color:#f92672">(&lt;/span>3D000&lt;span style="color:#f92672">)&lt;/span>: No database selected
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>OPTIONS：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>**-h, &amp;ndash;host &lt;!-- raw HTML omitted --> **# 指定要连接的 mysql 主机。如果链接本机 mysql，可以省略。&lt;/li>
&lt;li>**-P, &amp;ndash;port &lt;!-- raw HTML omitted --> **# 指定要连接的 mysql 的端口。默认值：&lt;code>3306&lt;/code>&lt;/li>
&lt;li>**-u, &amp;ndash;user &lt;!-- raw HTML omitted --> **# 指定要登录 mysql 的用户名&lt;/li>
&lt;li>&lt;strong>-p, &amp;ndash;password &lt;!-- raw HTML omitted -->&lt;/strong> # 使用密码来登录。如果指定要登录 mysql 的用户密码为空，则该选项可省&lt;/li>
&lt;/ul>
&lt;h2 id="命令行模式">命令行模式&lt;/h2>
&lt;p>略&lt;/p>
&lt;h2 id="交互模式">交互模式&lt;/h2>
&lt;h3 id="斜线命令">斜线命令&lt;/h3>
&lt;p>在 mysql 的交互模式中有一组 mysql 程序自带的命令，用以 控制输出格式、检查、获取数据信息 等等，这些命令以 &lt;code>\&lt;/code> 开头，不过也有与之相对应的字符串命令&lt;/p>
&lt;ul>
&lt;li>**\u, use &lt;!-- raw HTML omitted --> **# 选择想要操作的数据库&lt;/li>
&lt;/ul>
&lt;h3 id="基础示例">基础示例&lt;/h3>
&lt;ul>
&lt;li>grant select,insert,update,delete,create,drop ON mysql.* TO &amp;rsquo;lichenhao&amp;rsquo;@&amp;rsquo;localhost&amp;rsquo; identified by &amp;rsquo;lichenhao&amp;rsquo;; # 为名为 mysql 的数据库创建名为 lichenhao 的用户，密码为 lichenhao，具有 select、insert、update、delete、create、drop 这些命令的执行权限。&lt;/li>
&lt;li>flush privileges; # 刷新权限。由权限账号信息是在 MYSQLD 服务启动的时候就加载到内存中的，所以你在原权限表中的任何直接修改都不会直接生效。用 flush privileges 把中表中的信息更新到内存。&lt;/li>
&lt;li>select user(); # 查看当前登录的用户。&lt;/li>
&lt;li>show databases; # 列出所有已经存在的数据库&lt;/li>
&lt;li>use mysql; # 切换当前要操作的数据库为 mysql&lt;/li>
&lt;li>show tables; # 显示当前数据库中所有的表&lt;/li>
&lt;li>show columns from db; # 显示当前数据库中名为 db 的表的属性。效果如下
&lt;ul>
&lt;li>desc test; # 与该命令效果相同&lt;/li>
&lt;li>Field # 该表中都有哪些列&lt;/li>
&lt;li>Type # 该列的数据类型&lt;/li>
&lt;li>Null # 该列是否可以插入 null&lt;/li>
&lt;li>Key # 索引类型&lt;/li>
&lt;li>Default # 该列插入空值时。默认插入什么值。&lt;/li>
&lt;li>Extra # 该列额外的参数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>MariaDB [mysql]&amp;gt; SHOW COLUMNS FROM db;
+-----------------------+---------------+------+-----+---------+-------+
| Field | Type | Null | Key | Default | Extra |
+-----------------------+---------------+------+-----+---------+-------+
| Host | char(60) | NO | PRI | | |
| Db | char(64) | NO | PRI | | |
| User | char(16) | NO | PRI | | |
| Select_priv | enum('N','Y') | NO | | N | |
.......
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>select Host,db from db; #显示 db 表中，Host 和 Db 列及其内容，效果如下&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>MariaDB [mysql]&amp;gt; SELECT Host,db from db;
+-----------+---------+
| Host | db |
+-----------+---------+
| % | test |
| % | test\_% |
| localhost | mysql |
+-----------+---------+
&lt;/code>&lt;/pre>
&lt;h1 id="mysqladmin">mysqladmin&lt;/h1>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>mysqladmin -u root -p password &amp;ldquo;my_password&amp;rdquo; #修改 root 密码，密码为：my_password。如果默认密码为空，则可以不加-p。&lt;/li>
&lt;/ul></description></item><item><title>Docs: MySQL 命令行工具</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/mysql-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/mysql-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;h2 id="参考">参考：&lt;/h2>
&lt;/blockquote>
&lt;h1 id="mysql">mysql&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://dev.mysql.com/doc/refman/8.0/en/mysql.html">官方文档，MySQL 程序-客户端程序-mysql&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>mysql 是一个简单的 SQL Shell。 它支持交互和非交互使用。 交互使用时，查询结果以 ASCII 表格式显示。 非交互使用（例如，用作过滤器）时，结果以制表符分隔的格式显示。 可以使用命令选项更改输出格式。&lt;/p>
&lt;h2 id="syntax语法">Syntax(语法)&lt;/h2>
&lt;p>&lt;strong>mysql [OPTIONS] [DATABASE]&lt;/strong>
**DATABASE **# 指定连接 mysql 后要操作的数据库。若不指定，则需要在交互模式下使用 &lt;code>use&lt;/code> 指令选择数据库，否则对数据库的操作将会报 &lt;code>No database selected&lt;/code> 错误：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mysql&amp;gt; show tables;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ERROR &lt;span style="color:#ae81ff">1046&lt;/span> &lt;span style="color:#f92672">(&lt;/span>3D000&lt;span style="color:#f92672">)&lt;/span>: No database selected
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>OPTIONS：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>**-h, &amp;ndash;host &lt;!-- raw HTML omitted --> **# 指定要连接的 mysql 主机。如果链接本机 mysql，可以省略。&lt;/li>
&lt;li>**-P, &amp;ndash;port &lt;!-- raw HTML omitted --> **# 指定要连接的 mysql 的端口。默认值：&lt;code>3306&lt;/code>&lt;/li>
&lt;li>**-u, &amp;ndash;user &lt;!-- raw HTML omitted --> **# 指定要登录 mysql 的用户名&lt;/li>
&lt;li>&lt;strong>-p, &amp;ndash;password &lt;!-- raw HTML omitted -->&lt;/strong> # 使用密码来登录。如果指定要登录 mysql 的用户密码为空，则该选项可省&lt;/li>
&lt;/ul>
&lt;h2 id="命令行模式">命令行模式&lt;/h2>
&lt;p>我们可以通过 &lt;code>mysql db_name &amp;lt;FILE.sql &amp;gt; output.tab&lt;/code> 命令直接执行写在文件中的 SQL 语句&lt;/p>
&lt;h2 id="交互模式">交互模式&lt;/h2>
&lt;h3 id="斜线命令">斜线命令&lt;/h3>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://dev.mysql.com/doc/refman/8.0/en/mysql-commands.html">官方文档，MySQL 程序-客户端程序-myslq 客户端命令&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>在 mysql 的交互模式中有一组 mysql 程序自带的命令，用以 控制输出格式、检查、获取数据信息 等等，这些命令以 &lt;code>\&lt;/code> 开头，不过也有与之相对应的字符串命令&lt;/p>
&lt;ul>
&lt;li>**\u, use &lt;!-- raw HTML omitted --> **# 选择想要操作的数据库。与 MySQL 的 SQL 中的 use 语句功能一致&lt;/li>
&lt;/ul>
&lt;h3 id="基础示例">基础示例&lt;/h3>
&lt;ul>
&lt;li>grant select,insert,update,delete,create,drop ON mysql.* TO &amp;rsquo;lichenhao&amp;rsquo;@&amp;rsquo;localhost&amp;rsquo; identified by &amp;rsquo;lichenhao&amp;rsquo;; # 为名为 mysql 的数据库创建名为 lichenhao 的用户，密码为 lichenhao，具有 select、insert、update、delete、create、drop 这些命令的执行权限。&lt;/li>
&lt;li>flush privileges; # 刷新权限。由权限账号信息是在 MYSQLD 服务启动的时候就加载到内存中的，所以你在原权限表中的任何直接修改都不会直接生效。用 flush privileges 把中表中的信息更新到内存。&lt;/li>
&lt;li>select user(); # 查看当前登录的用户。&lt;/li>
&lt;li>show databases; # 列出所有已经存在的数据库&lt;/li>
&lt;li>use mysql; # 切换当前要操作的数据库为 mysql&lt;/li>
&lt;li>show tables; # 显示当前数据库中所有的表&lt;/li>
&lt;li>show columns from db; # 显示当前数据库中名为 db 的表的属性。效果如下
&lt;ul>
&lt;li>desc test; # 与该命令效果相同&lt;/li>
&lt;li>Field # 该表中都有哪些列&lt;/li>
&lt;li>Type # 该列的数据类型&lt;/li>
&lt;li>Null # 该列是否可以插入 null&lt;/li>
&lt;li>Key # 索引类型&lt;/li>
&lt;li>Default # 该列插入空值时。默认插入什么值。&lt;/li>
&lt;li>Extra # 该列额外的参数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>MariaDB [mysql]&amp;gt; SHOW COLUMNS FROM db;
+-----------------------+---------------+------+-----+---------+-------+
| Field | Type | Null | Key | Default | Extra |
+-----------------------+---------------+------+-----+---------+-------+
| Host | char(60) | NO | PRI | | |
| Db | char(64) | NO | PRI | | |
| User | char(16) | NO | PRI | | |
| Select_priv | enum('N','Y') | NO | | N | |
.......
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>select Host,db from db; #显示 db 表中，Host 和 Db 列及其内容，效果如下&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>MariaDB [mysql]&amp;gt; SELECT Host,db from db;
+-----------+---------+
| Host | db |
+-----------+---------+
| % | test |
| % | test\_% |
| localhost | mysql |
+-----------+---------+
&lt;/code>&lt;/pre>
&lt;h1 id="mysqladmin">mysqladmin&lt;/h1>
&lt;p>EXAMPLE&lt;/p>
&lt;ul>
&lt;li>mysqladmin -u root -p password &amp;ldquo;my_password&amp;rdquo; #修改 root 密码，密码为：my_password。如果默认密码为空，则可以不加-p。&lt;/li>
&lt;/ul></description></item><item><title>Docs: MySQL 配置文件详解</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/mysql-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/mysql-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;h2 id="参考">参考：&lt;/h2>
&lt;/blockquote>
&lt;h1 id="mycnf">my.cnf&lt;/h1>
&lt;p>[mysqld]
skip-grant-tables # 登录时跳过权限检查&lt;/p>
&lt;h1 id="default-time_zone800">设置时区
default-time_zone=&amp;rsquo;+8:00'&lt;/h1>
&lt;p>#  开启 binlog
log-bin=mysql-bin
binlog-format=Row
server-id=1
expire_logs_days=7
max_binlog_size=10m&lt;/p>
&lt;p>binlog
&lt;a href="https://dev.mysql.com/doc/refman/5.7/en/replication-howto-masterbaseconfig.html">https://dev.mysql.com/doc/refman/5.7/en/replication-howto-masterbaseconfig.html&lt;/a>&lt;/p></description></item><item><title>Docs: MySQL 批量SQL插入性能优化</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/mysql-%E6%89%B9%E9%87%8Fsql%E6%8F%92%E5%85%A5%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/mysql-%E6%89%B9%E9%87%8Fsql%E6%8F%92%E5%85%A5%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>
&lt;p>对于一些数据量较大的系统，数据库面临的问题除了查询效率低下，还有就是数据入库时间长。特别像报表系统，每天花费在数据导入上的时间可能会长达几个小时或十几个小时之久。因此，优化数据库插入性能是很有意义的。&lt;/p>
&lt;p>经过对 MySQL InnoDB 的一些性能测试，发现一些可以提高 insert 效率的方法，供大家参考参考。&lt;/p>
&lt;h2 id="1一条-sql-语句插入多条数据">1、一条 SQL 语句插入多条数据&lt;/h2>
&lt;p>常用的插入语句如：&lt;/p>
&lt;pre>&lt;code>INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('1', 'userid_1', 'content_1', 1);
&lt;/code>&lt;/pre>
&lt;p>修改成：&lt;/p>
&lt;pre>&lt;code>INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('0', 'userid_0', 'content_0', 0), ('1', 'userid_1', 'content_1', 1);
&lt;/code>&lt;/pre>
&lt;p>修改后的插入操作能够提高程序的插入效率。这里第二种 SQL 执行效率高的主要原因是合并后日志量（MySQL 的 binlog 和 innodb 的事务让日志）减少了，&lt;strong>降低日志刷盘的数据量和频率，从而提高效率。通过合并 SQL 语句，同时也能减少 SQL 语句解析的次数，减少网络传输的 IO&lt;/strong>。&lt;/p>
&lt;p>这里提供一些测试对比数据，分别是进行单条数据的导入与转化成一条 SQL 语句进行导入，分别测试 1 百、1 千、1 万条数据记录。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/osqpuu/1616133530263-c38130ab-121b-4b17-a60a-cfab979b341d.png" alt="">&lt;/p>
&lt;h2 id="2在事务中进行插入处理">2、在事务中进行插入处理。&lt;/h2>
&lt;p>把插入修改成：&lt;/p>
&lt;pre>&lt;code>START TRANSACTION;
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('1', 'userid_1', 'content_1', 1);
...
COMMIT;
&lt;/code>&lt;/pre>
&lt;p>使用事务可以提高数据的插入效率，这是因为进行一个 INSERT 操作时，MySQL 内部会建立一个事务，在事务内才进行真正插入处理操作。通过使用事务可以减少创建事务的消耗，&lt;code>所有插入都在执行后才进行提交操作&lt;/code>。&lt;/p>
&lt;p>这里也提供了测试对比，分别是不使用事务与使用事务在记录数为 1 百、1 千、1 万的情况。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/osqpuu/1616133530313-c27041f7-5ee1-40ad-b700-39240dcf2a81.png" alt="">&lt;/p>
&lt;h2 id="3数据有序插入">3、数据有序插入。&lt;/h2>
&lt;p>数据有序的插入是指插入记录在主键上是有序排列，例如 datetime 是记录的主键：&lt;/p>
&lt;pre>&lt;code>INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('1', 'userid_1', 'content_1', 1);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('2', 'userid_2', 'content_2',2);
&lt;/code>&lt;/pre>
&lt;p>修改成：&lt;/p>
&lt;pre>&lt;code>INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('1', 'userid_1', 'content_1', 1);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`)
VALUES ('2', 'userid_2', 'content_2',2);
&lt;/code>&lt;/pre>
&lt;p>由于数据库插入时，需要维护索引数据，&lt;code>无序的记录会增大维护索引的成本&lt;/code>。我们可以参照 InnoDB 使用的 B+tree 索引，如果每次插入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要 B+tree 进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。&lt;/p>
&lt;p>下面提供随机数据与顺序数据的性能对比，分别是记录为 1 百、1 千、1 万、10 万、100 万。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/osqpuu/1616133530291-b48ef56b-2dff-401b-8ede-bf3dc7e64b61.png" alt="">&lt;/p>
&lt;p>从测试结果来看，该优化方法的性能有所提高，但是提高并不是很明显。&lt;/p>
&lt;h2 id="4性能综合测试">4、性能综合测试&lt;/h2>
&lt;p>这里提供了同时使用上面三种方法进行 INSERT 效率优化的测试。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/osqpuu/1616133530367-110c58c4-622e-41ff-8096-d1c640627053.png" alt="">&lt;/p>
&lt;p>从测试结果可以看到，合并数据+事务的方法在较小数据量时，性能提高是很明显的，数据量较大时（1 千万以上），性能会急剧下降，这是由于此时数据量超过了 innodb_buffer 的容量，每次定位索引涉及较多的磁盘读写操作，性能下降较快。而使用合并数据+事务+有序数据的方式在数据量达到千万级以上表现依旧是良好，在数据量较大时，有序数据索引定位较为方便，不需要频繁对磁盘进行读写操作，所以可以维持较高的性能。&lt;/p>
&lt;p>&lt;strong>注意事项：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;code>SQL语句是有长度限制&lt;/code>，在进行数据合并在同一 SQL 中务必不能超过 SQL 长度限制，通过 max_allowed_packet 配置可以修改，默认是 1M，测试时修改为 8M。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>事务需要控制大小&lt;/code>，事务太大可能会影响执行的效率。MySQL 有 innodb_log_buffer_size 配置项，超过这个值会把 innodb 的数据刷到磁盘中，这时，效率会有所下降。所以比较好的做法是，在数据达到这个这个值前进行事务提交。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>参考文档：MySQL 批量 SQL 插入性能优化&lt;/p></description></item><item><title>Docs: Network Attached Storage(网络附加存储)</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/</guid><description>
&lt;h1 id="nas-的实现">NAS 的实现&lt;/h1>
&lt;p>CIFS/SMB 和 NFS 是实现 NAS 架构的主要协议。&lt;/p></description></item><item><title>Docs: NFS 部署</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/2.network-file-system/nfs-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/1.%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/network-attached-storage%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/2.network-file-system/nfs-%E9%83%A8%E7%BD%B2/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;a href="https://ubuntu.com/server/docs/service-nfs">Ubuntu 官方文档&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="服务端部署">服务端部署&lt;/h1>
&lt;h2 id="安装-nfs-server">安装 NFS Server&lt;/h2>
&lt;h3 id="通过-linux-的包管理器部署">通过 Linux 的包管理器部署&lt;/h3>
&lt;p>&lt;strong>CentOS&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>yum install -y nfs-utils
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Ubuntu&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt install nfs-kernel-server
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="配置并启动-nfs-服务">配置并启动 NFS 服务&lt;/h2>
&lt;h3 id="配置共享目录">配置共享目录&lt;/h3>
&lt;p>服务启动之后，我们在服务端配置一个共享目录&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mkdir /data
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chmod &lt;span style="color:#ae81ff">755&lt;/span> /data
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>为 NFS 配置共享目录&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat &amp;gt; /etc/exports &lt;span style="color:#e6db74">&amp;lt;&amp;lt;EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">/data/ 172.19.42.0/24(rw,sync,no_root_squash,no_all_squash)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>/data # 共享目录位置。&lt;/li>
&lt;li>172.19.42.0/24 # 客户端 IP 范围，* 代表所有，即没有限制。&lt;/li>
&lt;li>rw # 权限设置，可读可写。&lt;/li>
&lt;li>sync # 同步共享目录。&lt;/li>
&lt;li>no_root_squash # 可以使用 root 授权。&lt;/li>
&lt;li>no_all_squash # 可以使用普通用户授权。&lt;/li>
&lt;/ul>
&lt;h3 id="启动-nfs">启动 nfs&lt;/h3>
&lt;p>&lt;strong>CentOS&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>systemctl enable nfs --now
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Ubuntu&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>systemctl enable nfs-server --now
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="检查一下本地的共享目录">检查一下本地的共享目录&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>root@common-test:~# showmount -e localhost
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Export list &lt;span style="color:#66d9ef">for&lt;/span> localhost:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/data 172.19.42.0/24
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="客户端部署">客户端部署&lt;/h1>
&lt;h2 id="安装-nfs-client">安装 NFS Client&lt;/h2>
&lt;h3 id="通过-linux-的包管理器部署-1">通过 Linux 的包管理器部署&lt;/h3>
&lt;p>&lt;strong>CetnOS&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>yum install -y nfs-utils
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Ubuntu&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt install nfs-common
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="客户端连接-nfs-测试">客户端连接 NFS 测试&lt;/h2>
&lt;p>先查服务端的共享目录&lt;/p>
&lt;pre>&lt;code>[root@node-1 ~]# showmount -e 172.19.42.215
Export list for 172.19.42.215:
/data 172.19.42.0/24
&lt;/code>&lt;/pre>
&lt;p>在客户端创建目录&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mkdir /data_client
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>挂载&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span> mount -t nfs 172.19.42.247:/data /data/nfs_client
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>挂载之后，可以使用 mount 命令查看一下&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ mount
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>172.19.42.247:/data on /data/nfs_client type nfs4 &lt;span style="color:#f92672">(&lt;/span>rw,relatime,vers&lt;span style="color:#f92672">=&lt;/span>4.2,rsize&lt;span style="color:#f92672">=&lt;/span>524288,wsize&lt;span style="color:#f92672">=&lt;/span>524288,namlen&lt;span style="color:#f92672">=&lt;/span>255,hard,proto&lt;span style="color:#f92672">=&lt;/span>tcp,timeo&lt;span style="color:#f92672">=&lt;/span>600,retrans&lt;span style="color:#f92672">=&lt;/span>2,sec&lt;span style="color:#f92672">=&lt;/span>sys,clientaddr&lt;span style="color:#f92672">=&lt;/span>172.19.42.248,local_lock&lt;span style="color:#f92672">=&lt;/span>none,addr&lt;span style="color:#f92672">=&lt;/span>172.19.42.247&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这说明已经挂载成功了。&lt;/p>
&lt;p>测试一下，在客户端向共享目录创建一个文件&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cd /data
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>touch a
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>之后去 NFS 服务端查看一下&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cd /data
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ll
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total 0-rw-r--r--. &lt;span style="color:#ae81ff">1&lt;/span> root root &lt;span style="color:#ae81ff">0&lt;/span> Aug &lt;span style="color:#ae81ff">8&lt;/span> 18:46 a
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到，共享目录已经写入了。&lt;/p>
&lt;p>自动挂载很常用，客户端设置一下即可。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>vi /etc/fstab
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在结尾添加类似如下配置&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># /etc/fstab: static file system information.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Use &amp;#39;blkid&amp;#39; to print the universally unique identifier for a&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># device; this may be used with UUID= as a more robust way to name devices&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># that works even if disks are added and removed. See fstab(5).&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># &amp;lt;file system&amp;gt; &amp;lt;mount point&amp;gt; &amp;lt;type&amp;gt; &amp;lt;options&amp;gt; &amp;lt;dump&amp;gt; &amp;lt;pass&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#/dev/disk/by-id/dm-uuid-LVM-cmpKu0oh3CgDAAKsHGzU9AoEaWd9j8meFhd8PLCvGucV6WUB3F5au6gLhIOy0oYc none swap sw 0 0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># / was on /dev/vg0/lv-1 during curtin installation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/dev/disk/by-id/dm-uuid-LVM-cmpKu0oh3CgDAAKsHGzU9AoEaWd9j8meWCfiPw8kOhZvahcm3RCAT3sjPa0ialPd / xfs defaults &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#/swap.img none swap sw 0 0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>172.19.42.247:/data /data nfs defaults &lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Percona Monitoring and Management</title><link>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/percona-monitoring-and-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/it%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2.%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/mysql/percona-monitoring-and-management/</guid><description>
&lt;p>参考：&lt;a href="https://www.percona.com/software/database-tools/percona-monitoring-and-management">官网介绍&lt;/a>，&lt;a href="https://www.percona.com/doc/percona-monitoring-and-management/2.x/index.html">官方文档&lt;/a>、&lt;a href="https://www.cnblogs.com/okchy/p/13605701.html">原文链接&lt;/a>&lt;/p>
&lt;p>分析慢查询的:&lt;a href="https://www.percona.com/blog/2020/10/07/how-to-find-query-slowdowns-using-percona-monitoring-and-management/">https://www.percona.com/blog/2020/10/07/how-to-find-query-slowdowns-using-percona-monitoring-and-management/&lt;/a>&lt;/p>
&lt;p>基于 pmm2 去排查故障的官方文档:&lt;a href="https://www.percona.com/blog/2020/07/15/mysql-query-performance-troubleshooting-resource-based-approach/">https://www.percona.com/blog/2020/07/15/mysql-query-performance-troubleshooting-resource-based-approach/&lt;/a>&lt;/p>
&lt;p>**Percona Monitoring and Management(简称 PMM) **是一个用于管理和监控 MySQL、PostgreSQL、MongoDB 和 ProxySQL 性能的开源平台。它是由 Percona 与管理数据库服务、支助和咨询领域的专家合作开发的。&lt;/p>
&lt;p>PMM 是一种免费的开源解决方案，您可以在自己的环境中运行它，以获得最大的安全性和可靠性。它为 MySQL、PostgreSQL 和 MongoDB 服务器提供了全面的基于时间的分析，以确保您的数据尽可能高效地工作。&lt;/p>
&lt;p>PMM 平台基于支持可伸缩性的客户机-服务器模型。它包括以下模块:&lt;/p>
&lt;p>PMM 客户机安装在您想要监视的每个数据库主机上。它收集服务器指标、一般系统指标和查询分析数据，以获得完整的性能概述。&lt;/p>
&lt;p>PMM 服务器是 PMM 的中心部分，它聚合收集到的数据，并在 web 界面中以表格、仪表板和图形的形式显示这些数据。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512427-90c73526-d534-4d64-a402-c2c42373abb2.png" alt="">&lt;/p>
&lt;p>模块被打包以便于安装和使用。假设用户不需要了解组成每个模块的具体工具是什么，以及它们如何交互。然而，如果您想充分利用 PMM 的潜力，内部结构是重要的。&lt;/p>
&lt;p>PMM 是一种工具的集合，它被设计成可以无缝地协同工作。有些是由 Percona 开发的，有些是第三方开源工具。&lt;/p>
&lt;p>PMM Server&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512441-02d3d028-1588-42fc-a8a4-4d1736674427.png" alt="">&lt;/p>
&lt;p>PMM 服务器在作为中央监视主机的机器上运行。它通过以下方式作为设备分发:&lt;/p>
&lt;p>*可用于运行容器的 Docker 映像&lt;/p>
&lt;p>*可以在 VirtualBox 或其他管理程序中运行的 OVA(打开虚拟设备)&lt;/p>
&lt;p>*您可以通过 Amazon Web 服务运行的 AMI (Amazon Machine Image)&lt;/p>
&lt;p>PMM 服务器包括以下工具:&lt;/p>
&lt;p>*查询分析(QAN)允许您在一段时间内分析 MySQL 查询性能。除客户端 QAN 代理外，还包括:&lt;/p>
&lt;p>QAN API 是存储和访问运行在 PMM 客户机上的 QAN 代理收集的查询数据的后端。&lt;/p>
&lt;p>QAN Web App 是一个可视化收集查询分析数据的 Web 应用程序。&lt;/p>
&lt;p>*Metrics Monitor 提供了对 MySQL 或 MongoDB 服务器实例至关重要的指标的历史视图。它包括以下内容:&lt;/p>
&lt;p>Prometheus 是一个第三方时间序列数据库，它连接到运行在 PMM 客户机上的出口商，并汇总出口商收集的指标。&lt;/p>
&lt;p>ClickHouse 是一个第三方的面向列的数据库，它促进了查询分析功能。有关更多信息，请参见 ClickHouse 文档。&lt;/p>
&lt;p>Grafana 是一个第三方的仪表盘和图形生成器，用于将普罗米修斯在直观的 web 界面中聚合的数据可视化。&lt;/p>
&lt;p>Percona 仪表板是由 Percona 为 Grafana 开发的一套仪表板。&lt;/p>
&lt;p>所有工具都可以从 PMM 服务器的 web 界面(登录页面)访问。&lt;/p>
&lt;p>PMM Client&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512448-678fe0f9-6e67-49e3-bd57-f740c4f96042.png" alt="">&lt;/p>
&lt;p>每个 PMM 客户机收集关于一般系统和数据库性能的各种数据，并将这些数据发送到相应的 PMM 服务器。&lt;/p>
&lt;p>PMM 客户端包括以下内容:&lt;/p>
&lt;p>PMM -admin 是用于管理 PMM 客户机的命令行工具，例如，用于添加和删除您想要监视的数据库实例。&lt;/p>
&lt;p>PMM -agent 是一个客户端组件，一个最小的命令行接口，它是负责提供客户端功能的中心入口点:它进行客户端身份验证，获取存储在 PMM 服务器上的客户端配置，管理导出程序和其他代理。&lt;/p>
&lt;p>node_exporters 是一个收集一般系统指标的 Prometheus 端口。&lt;/p>
&lt;p>mysqld_exporters 是一个收集 MySQL 服务器指标的 Prometheus 端口。&lt;/p>
&lt;p>mongodb_exporters 是一个收集 MongoDB 服务器指标的 Prometheus 端口。&lt;/p>
&lt;p>postgres_端口是一个收集 PostgreSQL 性能指标的 Prometheus 端口。&lt;/p>
&lt;p>proxysql_exporters 是一个收集 ProxySQL 性能指标的 Prometheus 端口。&lt;/p>
&lt;p>为了使从 PMM 客户机到 PMM 服务器的数据传输更加安全，所有端口都能够使用 SSL/TLS 加密的连接，并且它们与 PMM 服务器的通信受到 HTTP 基本身份验证的保护。&lt;/p>
&lt;p>参考：&lt;/p>
&lt;p>端口：以下端口必须在 pmm server 和 client 之间开放;&lt;/p>
&lt;p>pmm server 需要开放 80 或 443 端口用于 pmm client 访问 pmm web。&lt;/p>
&lt;p>pmm client 端必须开放以下默认端口采集数据，可以通过 pmm-admin addc 命令进行修改。&lt;/p>
&lt;p>42000 For PMM to collect genenal system metrics.&lt;/p>
&lt;p>42001 This port is used by a service which collects query performance data and makes it available to QAN.&lt;/p>
&lt;p>42002 For PMM to collect MySQL server metrics.&lt;/p>
&lt;p>42003 For PMM to collect MongoDB server metrics.&lt;/p>
&lt;p>42004 For PMM to collect ProxySQL server metrics.&lt;/p>
&lt;h1 id="部署-pmm">部署 PMM&lt;/h1>
&lt;p>参考：官方文档&lt;/p>
&lt;p>安装步骤&lt;/p>
&lt;p>docker 部署 pmm 与 mysql 监控&lt;/p>
&lt;p>安装 docker&lt;/p>
&lt;p>yum install -y yum-utils device-mapper-persistent-data lvm2&lt;/p>
&lt;p>yum-config-manager &amp;ndash;add-repo &lt;a href="http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo&lt;/a>&lt;/p>
&lt;p>yum makecache fast&lt;/p>
&lt;p>yum -y install docker-ce&lt;/p>
&lt;p>systemctl start docker&lt;/p>
&lt;p>docker run hello-world&lt;/p>
&lt;p>PMM Server：192.168.24.90&lt;/p>
&lt;p>PMM Client：192.168.24.92&lt;/p>
&lt;p>1.Docker 安装 PMM Server&lt;/p>
&lt;p>这里使用的 Docker 标签适用于最新版本的 PMM 2(2.9.1)，但是您可以指定任何可用的标签来使用相应版本的 PMM 服务器。&lt;/p>
&lt;p>度量收集消耗磁盘空间。PMM 需要为每个被监视的数据库节点提供大约 1GB 的存储空间，数据保留时间设置为一周。(默认情况下，数据保留时间为 30 天。)要减小 Prometheus 数据库的大小，可以考虑禁用表统计信息。&lt;/p>
&lt;p>尽管一个受监控的数据库节点的最小内存量为 2 GB，但内存使用不会随着节点数量的增加而增加。例如，16GB 足够用于 20 个节点。&lt;/p>
&lt;p>#版本可自选&lt;/p>
&lt;p>docker create -v /opt/prometheus/data -v /opt/consul-data -v /var/lib/mysql -v /var/lib/grafana &amp;ndash;name pmm-data percona/pmm-server:2 /bin/true&lt;/p>
&lt;p>2.启动&lt;/p>
&lt;p>#必须开启防火墙&lt;/p>
&lt;p>docker run -d -p 80:80 -p 443:443 &amp;ndash;volumes-from pmm-data &amp;ndash;name pmm-server &amp;ndash;restart always percona/pmm-server:2&lt;/p>
&lt;p>端口默认是 80 ，如果 80 端口被占用，可改为其它端口号 比如 81&lt;/p>
&lt;p>3.查看 docker 运行状态&lt;/p>
&lt;p>docker ps -a&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512459-b4a07422-0748-4be5-bbdd-db952ae5cad9.png" alt="">&lt;/p>
&lt;p>4.浏览器访问，地址一般是 http://ip 地址:端口，也可以直接输 ip 地址； 注意，一般端口默认为 80，默认用户名：admin，默认密码：admin&lt;/p>
&lt;p>例：&lt;a href="http://192.168.24.90:80">http://192.168.24.90:80&lt;/a>&lt;/p>
&lt;p>5.安装 pmm-client 客户端。&lt;/p>
&lt;p>yum install &lt;a href="https://repo.percona.com/yum/percona-release-latest.noarch.rpm">https://repo.percona.com/yum/percona-release-latest.noarch.rpm&lt;/a> -y&lt;/p>
&lt;p>yum install pmm2-client -y&lt;/p>
&lt;p>6.连接 PMM Server。&lt;/p>
&lt;p>pmm-admin config &amp;ndash;server-insecure-tls &amp;ndash;server-url=https://admin:admin@&lt;!-- raw HTML omitted -->:443&lt;/p>
&lt;p>例：pmm-admin config &amp;ndash;server-insecure-tls &amp;ndash;server-url=https://admin:admin@192.168.24.90:443&lt;/p>
&lt;p>注：PMM2 不需要像 PMM1 输入指定命令添加 Linux 主机监控&lt;/p>
&lt;p>当你使用 pmm-admin config 配置了要监控的节点时，PMM2 从那时自动开始收集 Linux 指标。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512457-0d30d8f9-e92b-4ea3-b25a-2b7da2d86621.png" alt="">&lt;/p>
&lt;p>7.登陆浏览器访问主机监控数据&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512459-6f938df2-c730-4504-bf71-e101ced88649.png" alt="">&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512488-8a3a80a1-199f-451b-a1ef-b8915f8d5e15.png" alt="">&lt;/p>
&lt;p>#pmm-admin 管理命令&lt;/p>
&lt;p>annotate [&lt;!-- raw HTML omitted -->] &lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>在 Grafana 图表中添加注释&lt;/p>
&lt;p>config [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>配置本地 pmm-agent&lt;/p>
&lt;p>list [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>显示在此节点上运行的服务和代理&lt;/p>
&lt;p>status&lt;/p>
&lt;p>显示关于本地 pmm 代理的信息&lt;/p>
&lt;p>summary [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>获取系统数据以进行诊断&lt;/p>
&lt;p>add external &amp;ndash;listen-port=LISTEN-PORT [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>将外部监视添加&lt;/p>
&lt;p>add mongodb [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>监控 MongoDB&lt;/p>
&lt;p>add mysql [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>监控 MySQL&lt;/p>
&lt;p>add postgresql [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>监控 PostgreSQL&lt;/p>
&lt;p>add proxysql [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>监控 ProxySQL&lt;/p>
&lt;p>register [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->] [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>注册当前节点到 PMM 服务器&lt;/p>
&lt;p>remove [&lt;!-- raw HTML omitted -->] &lt;!-- raw HTML omitted --> [&lt;!-- raw HTML omitted -->]&lt;/p>
&lt;p>从监控中删除服务&lt;/p>
&lt;p>7.添加 mysql 监控。&lt;/p>
&lt;p>MySQL 服务器添加指定权限用户&lt;/p>
&lt;p>create user pmm@&amp;rsquo;%&amp;rsquo; identified by &amp;lsquo;pmmpassword&amp;rsquo;;&lt;/p>
&lt;p>grant select,process,super,replication client on &lt;em>.&lt;/em> to &amp;lsquo;pmm&amp;rsquo;@&amp;rsquo;%&amp;rsquo;;&lt;/p>
&lt;p>grant update,delete,drop on performance_schema.* to &amp;lsquo;pmm&amp;rsquo;@&amp;rsquo;%&amp;rsquo;;&lt;/p>
&lt;p>flush privileges;&lt;/p>
&lt;p>#授权密码如报错：Your password does not satisfy the current policy requirements&lt;/p>
&lt;p>set global validate_password_policy=LOW;&lt;/p>
&lt;p>MySQL8.0 版本设置：set global validate_password.policy=LOW;&lt;/p>
&lt;p>查询分析获得从 MySQL 中获取指标数据有两种可能的来源：慢查询日志和 Performance Schema&lt;/p>
&lt;p>添加 Performance Schema 数据字典监控&lt;/p>
&lt;p>pmm-admin add mysql &amp;ndash;query-source=perfschema &amp;ndash;username=pmm &amp;ndash;password=pmmpassword ps-mysql&lt;/p>
&lt;p>添加慢日志监控&lt;/p>
&lt;p>pmm-admin add mysql &amp;ndash;query-source=slowlog &amp;ndash;username=pmm &amp;ndash;password=pmmpassword sl-mysql&lt;/p>
&lt;p>查看运行的服务&lt;/p>
&lt;p>pmm-admin list&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512489-86f410ae-d99d-49a2-a505-2a9826ff1172.png" alt="">&lt;/p>
&lt;p>9.pmm 服务器页面查看&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512483-5837728e-5d7e-4102-b343-9935ee58ac83.png" alt="">&lt;/p>
&lt;p>点击 Query Analytics 进入 SQL 语句分析&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxu3v9/1616133512502-b408704d-70af-4efe-97b1-db073b551516.png" alt="">&lt;/p>
&lt;p>10.MySQL 最佳配置&lt;/p>
&lt;p>慢日志设置&lt;/p>
&lt;p>如果你使用 Percona 分支版本，正确的慢查询日志配置将以最小的开销提供最多的信息。否则，如果支持请使用 PerformanceSchema。&lt;/p>
&lt;p>按定义，慢查询日志应该只记录慢查询。这些查询的执行时间超过了特定的阈值。这个阈值由参数 long_query_time 指定。&lt;/p>
&lt;p>在高负载的应用中，频繁快速的查询比罕见的慢速查询对性能的影响要大的多。为全面分析你的查询流量，设置 long_query_time 为 0，这样所有的查询语句都将被记录。&lt;/p>
&lt;p>然而，记录所有的查询将消耗 I/O 带宽，并导致慢查询日志增长很快。为了限制记录到慢查询日志中的查询数量，使用 Percona 分支版本中的查询采样功能。&lt;/p>
&lt;p>查询采样可能导致一些罕见的慢查询无法被记录到慢查询日志中。为了避免这种情况，使用 slow_query_long_always_write_time 参数指定哪类查询应该被忽略采样。也就是说，长时间的慢查询应该始终记录到慢查询日志中。&lt;/p>
&lt;p>Performance Schema 设置&lt;/p>
&lt;p>PMM 查询数据的默认源是慢查询日志。这在 MySQL5.1 及以后的版本中可用。从 MySQL5.6 版本（包括 Percona 分支版本 5.6 及以后版本），你可以选择从 Performance Schema 中解析查询数据，而不是慢查询日志。从 MySQL5.6.6 开始，默认启用 Performance Schema。&lt;/p>
&lt;p>Performance Schema 不像慢查询日志那样有丰富的数据，但是它具有所有关键的数据，并且通常解析很快。如果您没有使用 Percona 分支版本（支持对慢查询日志采样），Performance Schema 是更好的选择。&lt;/p>
&lt;p>启用 Performance Schema ，要将 performance_schema 参数设置为 ON:&lt;/p>
&lt;p>SHOW VARIABLES LIKE &amp;lsquo;performance_schema&amp;rsquo;;&lt;/p>
&lt;p>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;-+&lt;/p>
&lt;p>| Variable_name | Value |&lt;/p>
&lt;p>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;-+&lt;/p>
&lt;p>| performance_schema | ON |&lt;/p>
&lt;p>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;-+&lt;/p>
&lt;p>如果这个参数没有设置为 ON，在 my.cnf 配置文件中添加以下内容并重启 MySQL 服务。&lt;/p>
&lt;p>[mysql]&lt;/p>
&lt;p>performance_schema=ON&lt;/p>
&lt;p>如果您使用了自定义的 Performance Schema 配置，确认 statement_digest 消费者已经启用：&lt;/p>
&lt;p>select * from setup_consumers;&lt;/p>
&lt;p>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p>
&lt;p>| NAME | ENABLED |&lt;/p>
&lt;p>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p>
&lt;p>| events_stages_current | NO |&lt;/p>
&lt;p>| events_stages_history | NO |&lt;/p>
&lt;p>| events_stages_history_long | NO |&lt;/p>
&lt;p>| events_statements_current | YES |&lt;/p>
&lt;p>| events_statements_history | YES |&lt;/p>
&lt;p>| events_statements_history_long | NO |&lt;/p>
&lt;p>| events_transactions_current | NO |&lt;/p>
&lt;p>| events_transactions_history | NO |&lt;/p>
&lt;p>| events_transactions_history_long | NO |&lt;/p>
&lt;p>| events_waits_current | NO |&lt;/p>
&lt;p>| events_waits_history | NO |&lt;/p>
&lt;p>| events_waits_history_long | NO |&lt;/p>
&lt;p>| global_instrumentation | YES |&lt;/p>
&lt;p>| thread_instrumentation | YES |&lt;/p>
&lt;p>| statements_digest | YES |&lt;/p>
&lt;p>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;+&lt;/p>
&lt;p>15 rows in set (0.00 sec)&lt;/p>
&lt;p>重要&lt;/p>
&lt;p>Performance Schema 生产者在 MySQL5.6.6 及之后的版本中默认启用。它在 MySQL5.6 之前的版本中完全不可用。如果某些生产者没有被启用，您在 MySQLPerformanceSchemaDashboard 的 dashboard 中看不到相应的图。启用所有的生产者，在启动 MySQL 服务时设置 &amp;ndash;performance_schema_instrument 选项为 &amp;lsquo;%=on&amp;rsquo;。&lt;/p>
&lt;p>mysqld &amp;ndash;performance-schema-instrument=&amp;rsquo;%=on&amp;rsquo;&lt;/p>
&lt;p>这个选项会带来额外的负载，请小心使用。&lt;/p>
&lt;p>如果实例已经在运行，配置 QAN agent 从 Performance Schema 中收集数据：&lt;/p>
&lt;p>1.打开 PMM Query Analytics dashboard。&lt;/p>
&lt;p>2.点击 Settings 按钮。&lt;/p>
&lt;p>3.打开 Settings 部分。&lt;/p>
&lt;p>4.从收集下拉列表中选择 PerformanceSchema。&lt;/p>
&lt;p>5.点击 Apply 保存更改。&lt;/p>
&lt;p>如果您使用 pmm-admin 工具添加一个新的监控实例，使用 &amp;ndash;query-sourceperfschema 选项：&lt;/p>
&lt;p>使用 root 用户或者 sudo 命令执行以下命令&lt;/p>
&lt;p>pmm-admin add mysql &amp;ndash;username=pmm &amp;ndash;password=pmmpassword &amp;ndash;query-source=&amp;lsquo;perfschema&amp;rsquo; ps-mysql 127.0.0.1:3306&lt;/p>
&lt;p>更多信息，请执行 pmm-admin add mysql&amp;ndash;help。&lt;/p>
&lt;p>MySQL InnoDB 指标&lt;/p>
&lt;p>为图形收集指标和统计信息会增加开销。您可以使用收集和绘制低开销的指标，在故障排除时启用高开销的指标。&lt;/p>
&lt;p>InnoDB 指标提供了有关 InnoDB 操作的详细信息。尽管您可以选择捕获指定的计数器，但是即使始终启用它们，它们的开销也很低。启用所有的 InnoDB 指标，设置全局参数 innodb_monitor_enable 为 all:&lt;/p>
&lt;p>SET GLOBAL innodb_monitor_enable&lt;/p>
&lt;p>Percona 分支版本的特殊设置&lt;/p>
&lt;p>默认情况下，并非所有 Metrics Monitor 的 dashboard 都可以用于所有 MySQL 分支和配置：Oracle 版，Percona 版或者 MariaDB。一些图形适用于 Percona 版本和专有的插件和额外的配置。&lt;/p>
&lt;p>MySQL 用户统计信息（userstat）&lt;/p>
&lt;p>用户统计信息是 Percona 分支版本和 MariaDB 分支版本的功能。它提供了用户活动、单个表和索引访问的信息。在某些情况下，收集用户统计信息可能会带来高昂的开销，所以请谨慎使用此功能。&lt;/p>
&lt;p>启用收集用户统计信息，设置 userstat 参数为 1。&lt;/p>
&lt;p>查询相应时间插件&lt;/p>
&lt;p>查询响应时间分布是 Percona 分支版的可用功能。它提供了不同查询组的查询响应时间变化的信息，通常可以在导致严重问题之前发现性能问题。&lt;/p>
&lt;p>启用收集查询响应时间：&lt;/p>
&lt;p>1.安装 QUERY_RESPONSE_TIME 插件 mysql&amp;gt;INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME&amp;rsquo;query_response_time.so&amp;rsquo;;mysql&amp;gt;INSTALL PLUGIN QUERY_RESPONSE_TIME SONAME&amp;rsquo;query_response_time.so&amp;rsquo;;mysql&amp;gt;INSTALL PLUGIN QUERY_RESPONSE_TIME_READ SONAME&amp;rsquo;query_response_time.so&amp;rsquo;;mysql&amp;gt;INSTALL PLUGIN QUERY_RESPONSE_TIME_WRITE SONAME&amp;rsquo;query_response_time.so&amp;rsquo;;&lt;/p>
&lt;p>2.设置全局参数 query_response_time_stats 为 ON。 mysql&amp;gt;SET GLOBAL query_response_time_stats=ON;&lt;/p>
&lt;p>相关信息：Percona 分支版官方文档&lt;/p>
&lt;p>query_response_time_stats: &lt;a href="https://www.percona.com/doc/percona-server/5.7/diagnostics/responsetimedistribution.html#queryresponsetime_stats">https://www.percona.com/doc/percona-server/5.7/diagnostics/responsetimedistribution.html#queryresponsetime_stats&lt;/a>&lt;/p>
&lt;p>Response time 介绍: &lt;a href="https://www.percona.com/doc/percona-server/5.7/diagnostics/responsetimedistribution.html#installing-the-plugins">https://www.percona.com/doc/percona-server/5.7/diagnostics/responsetimedistribution.html#installing-the-plugins&lt;/a>&lt;/p>
&lt;p>logslowrate_limit&lt;/p>
&lt;p>log_slow_rate_limit 参数定义了慢查询日志记录查询的比例。一个好的经验是每秒记录 100 个查询。例如如果您的 Percona 实例 QPS 为 10000，您应该设 log_slow_rate_limit 为 100,这样慢日志会记录每 100 个查询。&lt;/p>
&lt;p>注意&lt;/p>
&lt;p>当使用查询采样时，设置 log_slow_rate_type 为 query，以便它应用的是查询而不是会话。最好设置 log_slow_verbosity 为 full，以便在慢查询日志中记录每个记录的查询语句的最大的信息量。&lt;/p>
&lt;p>logslowverbosity&lt;/p>
&lt;ul>
&lt;li>log_slow_verbosity 参数指定了慢查询日志中包含多少信息。最好设置 log_slow_verbosity 为 full，以便存储有关每个记录的查询语句的最大信息量。&lt;/li>
&lt;/ul>
&lt;p>slowqueryloguseglobal_control&lt;/p>
&lt;p>默认情况下，慢查询日志只适用于新会话。如果希望调整慢查询日志设置并将这些设置应用于现有连接，请将 slow_query_log_use_global_control 设置为 all。&lt;/p>
&lt;p>为 PMM 配置 MySQL8.0&lt;/p>
&lt;p>MySQL8（在 8.0.4 版本中）改变了对客户端身份验证的方式。 default_authentication_pluging 参数设置为 caching_sha2_password。默认值的改变意味着 MySQL 的驱动需要支持 SHA-256 身份验证。另外，在使用 caching_sha2_password 时，必须对 MySQL8 的加密通道进行加密。&lt;/p>
&lt;p>PMM 使用的 MySQL 驱动还不支持 SHA-256 身份验证。&lt;/p>
&lt;p>为支持当前 MySQL 的版本，PMM 需要设置专有的 MySQL 用户。该 MySQL 用户应该使用 mysql_native_password 插件。虽然 MySQL 被配置支持 SSL 客户端，但是到 MySQL 服务器的连接没有加密。&lt;/p>
&lt;p>有两种解决方法监控 MySQL8.0.4 及以上版本&lt;/p>
&lt;p>1.更改你打算用于 PMM 的 MySQL 用户&lt;/p>
&lt;p>2.改变 MySQL 的全局配置&lt;/p>
&lt;p>更改 MySQL 用户&lt;/p>
&lt;p>假设你已经创建了你打算用于 PMM 的 MySQL 用户，请使用以下方法更改：&lt;/p>
&lt;p>然后，将此用户传递给 pmm-admin add 作为 &amp;ndash;username 的参数值&lt;/p>
&lt;p>这是首选的方法，因为这只会降低一个用户的安全性。&lt;/p>
&lt;p>更改全局 MySQL 的配置&lt;/p>
&lt;p>一种不太安全的方法是在添加监控前将 default_authentication_plugin 设置为 mysql_native_password。然后，重启 MySQL 服务，应用这个更改。&lt;/p></description></item></channel></rss>