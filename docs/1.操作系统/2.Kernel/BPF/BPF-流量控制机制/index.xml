<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – BPF 流量控制机制</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/</link><description>Recent content in BPF 流量控制机制 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: BPF 流量控制机制</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>Kernel 网络官方文档：&lt;a href="https://www.kernel.org/doc/html/latest/networking/filter.html#">LInux Socket Filtering aka Berkeley Packet Filter&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote></description></item><item><title>Docs: 【BPF网络篇系列-2】容器网络延时之 ipvs 定时器篇 | 深入浅出 eBPF</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF%E7%BD%91%E7%BB%9C%E7%AF%87%E7%B3%BB%E5%88%97-2%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%BB%B6%E6%97%B6%E4%B9%8B-ipvs-%E5%AE%9A%E6%97%B6%E5%99%A8%E7%AF%87-_-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-eBPF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF%E7%BD%91%E7%BB%9C%E7%AF%87%E7%B3%BB%E5%88%97-2%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%BB%B6%E6%97%B6%E4%B9%8B-ipvs-%E5%AE%9A%E6%97%B6%E5%99%A8%E7%AF%87-_-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-eBPF/</guid><description>
&lt;h2 id="1-前言">1. 前言&lt;a class="td-heading-self-link" href="#1-%e5%89%8d%e8%a8%80" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>趣头条的容器化已经开展了一年有余，累计完成了近 1000 个服务的容器化工作，微服务集群的规模也达到了千台以上的规模。随着容器化服务数量和集群规模的不断增大，除了常规的 API Server 参数优化、Scheduler 优化等常规优化外，近期我们还碰到了 kubernetes 底层负载均衡 ipvs 模块导致的网络抖动问题，在此把整个问题的分析、排查和解决的思路进行总结，希望能为有类似问题场景解决提供一种思路。&lt;/p>
&lt;p>涉及到的 k8s 集群和机器操作系统版本如下：&lt;/p>
&lt;ul>
&lt;li>k8s 阿里云 ACK 14.8 版本，网络模型为 CNI 插件 &lt;a href="https://github.com/AliyunContainerService/terway">terway&lt;/a> 中的 terway-eniip 模式；&lt;/li>
&lt;li>操作系统为 CentOS 7.7.1908，内核版本为 3.10.0-1062.9.1.el7.x86_64；&lt;/li>
&lt;/ul>
&lt;h2 id="2-网络抖动问题">2. 网络抖动问题&lt;a class="td-heading-self-link" href="#2-%e7%bd%91%e7%bb%9c%e6%8a%96%e5%8a%a8%e9%97%ae%e9%a2%98" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在容器集群中新部署的服务 A，在测试初期发现通过服务注册发现访问下游服务 B（在同一个容器集群） 调用延时 999 线偶发抖动，测试 QPS 比较小，从业务监控上看起来比较明显，最大的延时可以达到 200 ms。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/service_latency_high.png" alt="">&lt;/p>
&lt;p>图 2-1 服务调用延时&lt;/p>
&lt;p>服务间的访问通过 gRPC 接口访问，节点发现基于 consul 的服务注册发现。通过在服务 A 容器内的抓包分析和排查，经过了以下分析和排查：&lt;/p>
&lt;ul>
&lt;li>服务 B 部分异常注册节点，排除异常节点后抖动情况依然存在；&lt;/li>
&lt;li>HTTP 接口延时测试， 抖动情况没有改善；&lt;/li>
&lt;li>服务 A 在 VM（ECS）上部署测试，抖动情况没有改善；&lt;/li>
&lt;/ul>
&lt;p>经过上述的对比测试，我们逐步把范围缩小至服务 B 所在的主机上的底层网络抖动。&lt;/p>
&lt;p>经过多次 ping 包测试，我们寻找到了某台主机 A 与 主机 B 两者之间的 ping 延时抖动与服务调用延时抖动规律比较一致，由于 ping 包 的分析比 gRPC 的分析更加简单直接，因此我们将目标转移至底层网络的 ping 包测试的轨道上。&lt;/p>
&lt;p>能够稳定复现的主机环境如下图，通过主机 A ping 主机 B 中的容器实例 172.23.14.144 实例存在 ping 延时抖动。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 主机 B 中的 Pod IP 地址&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># ip route|grep 172.23.14.144&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>172.23.14.144 dev cali95f3fd83a87 scope link
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>图 2-2 ping 测试涉及到的主机和容器拓扑图&lt;/p>
&lt;p>基于主机 B 网络 eth1 和容器网络 cali-xxx 进行 ping 的对比结果如图：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/ping_host_container_detail.png" alt="">&lt;/p>
&lt;p>图 2-3 ping 主机与容器网络详情&lt;/p>
&lt;p>通过多次测试我们发现至 Node 主机 B 主机网络的 ping 未有抖动，容器网络 cali-xx 存在比较大的抖动，最高达到 133 ms。&lt;/p>
&lt;p>在 ping 测试过程中分别在主机 A 和主机 B 上使用 tcpdump 抓包分析，发现在主机 B 上的 eth1 与网卡 cali95f3fd83a87 之间的延时达 133 ms。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/ping_server_pcap.png" alt="">&lt;/p>
&lt;p>图 2-4 主机 B 上的 ping 包延时&lt;/p>
&lt;p>到此为止问题已经逐步明确，在主机 B 上接收到 ping 包在转发过程中有 100 多 ms 的延时，那么是什么原因导致的 ping 数据包在主机 B 转发的延时呢？&lt;/p>
&lt;h2 id="3-问题分析">3. 问题分析&lt;a class="td-heading-self-link" href="#3-%e9%97%ae%e9%a2%98%e5%88%86%e6%9e%90" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在分析 ping 数据包转发延时的情况之前，我们首先简单回顾一下网络数据包在内核中工作机制和数据流转路径。&lt;/p>
&lt;h3 id="31-网络数据包内核中的处理流程">3.1 网络数据包内核中的处理流程&lt;a class="td-heading-self-link" href="#31-%e7%bd%91%e7%bb%9c%e6%95%b0%e6%8d%ae%e5%8c%85%e5%86%85%e6%a0%b8%e4%b8%ad%e7%9a%84%e5%a4%84%e7%90%86%e6%b5%81%e7%a8%8b" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>在内核中，网络设备驱动是通过中断的方式来接受和处理数据包。当网卡设备上有数据到达的时候，会触发一个硬件中断来通知 CPU 来处理数据，此类处理中断的程序一般称作 ISR (Interrupt Service Routines)。ISR 程序不宜处理过多逻辑，否则会它设备的中断处理无法及时响应。因此 Linux 中将中断处理函数分为上半部和下半部。上半部是只进行最简单的工作，快速处理然后释放 CPU。剩下将绝大部分的工作都放到下半部中，下半部中逻辑有内核线程选择合适时机进行处理。&lt;/p>
&lt;p>Linux 2.4 以后内核版本采用的下半部实现方式是软中断，由 ksoftirqd 内核线程全权处理， 正常情况下每个 CPU 核上都有自己的软中断处理数队列和 &lt;code>ksoftirqd&lt;/code> 内核线程。软中断实现只是通过给内存中设置一个对应的二进制值来标识，软中断处理的时机主要为以下 2 种：&lt;/p>
&lt;ul>
&lt;li>硬件中断 &lt;code>irq_exit&lt;/code>退出时；&lt;/li>
&lt;li>被唤醒 &lt;code>ksoftirqd&lt;/code> 内核线程进行处理软中断；&lt;/li>
&lt;/ul>
&lt;p>常见的软中断类型如下：&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
3
4
5
6
7
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">enum&lt;/span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">HI_SOFTIRQ&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">TIMER_SOFTIRQ&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">NET_TX_SOFTIRQ&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 网络数据包发送软中断
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#000">NET_RX_SOFTIRQ&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 网络数据包接受软中断
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#8f5902;font-style:italic">//...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000;font-weight:bold">};&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>代码 3-1 Linux 软中断类型&lt;/p>
&lt;p>优先级自上而下，HI_SOFTIRQ 的优先级最高。其中 &lt;code>NET_TX_SOFTIRQ&lt;/code> 对应于网络数据包的发送， &lt;code>NET_RX_SOFTIRQ&lt;/code> 对应于网络数据包接受，两者共同完成网络数据包的发送和接收。&lt;/p>
&lt;p>网络相关的中断程序在网络子系统初始化的时候进行注册， &lt;code>NET_RX_SOFTIRQ&lt;/code> 的对应函数为 &lt;code>net_rx_action()&lt;/code> ，在 &lt;code>net_rx_action()&lt;/code> 函数中会调用网卡设备设置的 &lt;code>poll&lt;/code> 函数，批量收取网络数据包并调用上层注册的协议函数进行处理，如果是为 ip 协议，则会调用 &lt;code>ip_rcv&lt;/code>，上层协议为 icmp 的话，继续调用 &lt;code>icmp_rcv&lt;/code> 函数进行后续的处理。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/netcard_dev_softirq.png" alt="">&lt;/p>
&lt;p>图 3-1 网卡设备数据包接收示意图&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code> 1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">//net/core/dev.c
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">static&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#000">__init&lt;/span> &lt;span style="color:#000">net_dev_init&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">void&lt;/span>&lt;span style="color:#000;font-weight:bold">){&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000;font-weight:bold">......&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">for_each_possible_cpu&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">i&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">softnet_data&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">sd&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">per_cpu&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">softnet_data&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">i&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">memset&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">sd&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#204a87;font-weight:bold">sizeof&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">sd&lt;/span>&lt;span style="color:#000;font-weight:bold">));&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">skb_queue_head_init&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">sd&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">input_pkt_queue&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">skb_queue_head_init&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">sd&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">process_queue&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">sd&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">completion_queue&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#204a87">NULL&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">INIT_LIST_HEAD&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">sd&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">poll_list&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 软中断的处理中的 poll 函数列表
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// ......
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000;font-weight:bold">......&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">open_softirq&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">NET_TX_SOFTIRQ&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">net_tx_action&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 注册网络数据包发送的软中断
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#000">open_softirq&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">NET_RX_SOFTIRQ&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">net_rx_action&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 注册网络数据包接受的软中断
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">subsys_initcall&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">net_dev_init&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>代码 3-2 软中断数据及网络软中断注册&lt;/p>
&lt;p>网络数据的收发的延时，多数场景下都会和系统软中断处理相关，这里我们将重点分析 ping 包抖动时的软中断情况。这里我们采用基于 &lt;a href="https://github.com/iovisor/bcc">BCC&lt;/a> 的 &lt;a href="https://gist.github.com/DavadDi/62ee75228f03631c845c51af292c2b17">&lt;strong>traceicmpsoftirq.py&lt;/strong>&lt;/a> 来协助定位 ping 包处理的内核情况。&lt;/p>
&lt;blockquote>
&lt;p>BCC 为 Linux 内核 BPF 技术的前端程序，主要提供 Python 语言的绑定，&lt;code>traceicmpsoftirq.py&lt;/code> 脚本依赖于 BCC 库，需要先安装 BCC 项目，各操作系统安装参见 &lt;a href="https://github.com/iovisor/bcc/blob/master/INSTALL.md">INSTALL.md&lt;/a>。
&lt;code>traceicmpsoftirq.py&lt;/code> 脚本在 Linux 3.10 内核与 Linux 4.x 内核上的读写方式有差异，需要根据内核略有调整。&lt;/p>
&lt;/blockquote>
&lt;p>使用 &lt;code>traceicmpsoftirq.py&lt;/code> 在主机 B 上运行，我们发现出现抖动延时的时内核运行的内核线程都为 &lt;code>ksoftirqd/0&lt;/code>。&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code> 1
2
3
4
5
6
7
8
9
10
11
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">#主机 主机 A#A&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># ping -c 150 -i 0.01 172.23.14.144 |grep -E &amp;#34;[0-9]{2,}[\.0-9]+ ms&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 主机 B&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># ./traceicmpsoftirq.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tgid pid comm icmp_seq
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> swapper/0 &lt;span style="color:#0000cf;font-weight:bold">128&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">6&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span> ksoftirqd/0 &lt;span style="color:#0000cf;font-weight:bold">129&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">6&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span> ksoftirqd/0 &lt;span style="color:#0000cf;font-weight:bold">130&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>代码 3-3 &lt;code>traceicmpsoftirq.py&lt;/code> ping 主机 B 容器 IP 抖动时的详情&lt;/p>
&lt;p>&lt;code>[ksoftirqd/0]&lt;/code> 这个给了我们两个重要的信息：&lt;/p>
&lt;ul>
&lt;li>从主机 A ping 主机 B 中容器 IP 的地址，每次处理包的处理都会固定落到 CPU#0 上；&lt;/li>
&lt;li>出现延时的时候该 CPU#0 都在运行软中断处理内核线程 &lt;code>ksoftirqd/0&lt;/code>，即在处理软中断的过程中调用的数据包处理，软中断另外一种处理时机如上所述 &lt;code>irq_exit&lt;/code> 硬中断退出时；&lt;/li>
&lt;/ul>
&lt;p>如果 ping 主机 B 中的容器 IP 地址落在 CPU#0 核上，那么按照我们的测试过程， ping 主机 B 的宿主机 IP 地址没有抖动，那么处理的 CPU 一定不在 #0 号上，才能符合测试场景，我们继续使用主机 B 主机 IP 地址进行测试：&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code> 1
2
3
4
5
6
7
8
9
10
11
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 主机 A&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># ping -c 150 -i 0.01 172.23.14.144 |grep -E &amp;#34;[0-9]{2,}[\.0-9]+ ms&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 主机 B&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># ./traceicmpsoftirq.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tgid pid comm icmp_seq
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> swapper/19 &lt;span style="color:#0000cf;font-weight:bold">55&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> swapper/19 &lt;span style="color:#0000cf;font-weight:bold">56&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> swapper/19 &lt;span style="color:#0000cf;font-weight:bold">57&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>代码 3-4 &lt;code>traceicmpsoftirq.py&lt;/code> ping 主机 B 主机 IP 详情&lt;/p>
&lt;p>通过实际的测试验证，ping 主机 B 宿主机 IP 地址时候，全部都落在了 CPU#19 上。问题排查至此处，我们可以断定是 CPU#0 与 CPU#19 在软中断处理的负载上存在差异，但是此处我们有带来另外一个疑问，为什么我们的 ping 包的处理总是固定落到同一个 CPU 核上呢？ 通过查询资料和主机配置确认，主机上默认启用了 RPS 的技术。RPS 全称是 Receive Packet Steering，这是 Google 工程师 Tom Herbert 提交的内核补丁, 在 2.6.35 进入 Linux 内核，采用软件模拟的方式，实现了多队列网卡所提供的功能，分散了在多 CPU 系统上数据接收时的负载，把软中断分到各个 CPU 处理，而不需要硬件支持，大大提高了网络性能。简单点讲，就是在软中断的处理函数 &lt;code>net_rx_action()&lt;/code> 中依据 RPS 的配置，使用接收到的数据包头部（比如源 IP 地址端口等信息）信息进行作为 key 进行 Hash 到对应的 CPU 核上去处理，算法具体参见 &lt;a href="https://elixir.bootlin.com/linux/v5.8/source/net/core/dev.c#L4305">get_rps_cpu&lt;/a> 函数。&lt;/p>
&lt;p>Linux 环境下的 RPS 配置，可以通过下面的命令检查：&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># cat /sys/class/net/*/queues/rx-*/rps_cpus&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>通过对上述情况的综合分析，我们把问题定位在 CPU#0 在内核线程中对于软中断处理的问题上。&lt;/p>
&lt;h3 id="32-cpu-软中断处理排查">3.2 CPU 软中断处理排查&lt;a class="td-heading-self-link" href="#32-cpu-%e8%bd%af%e4%b8%ad%e6%96%ad%e5%a4%84%e7%90%86%e6%8e%92%e6%9f%a5" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>问题排查到这里，我们将重点开始排查 CPU#0 上的 CPU 内核态的性能指标，看看是否有运行的函数导致了软中断处理的延期。&lt;/p>
&lt;p>首先我们使用 &lt;code>perf&lt;/code> 命令对于 CPU#0 进行内核态使用情况进行分析。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/perf_kernel_cpu0.png" alt="">&lt;/p>
&lt;p>图 3-2 perf top CPU#0 内核性能数据&lt;/p>
&lt;p>通过 &lt;code>perf top&lt;/code> 命令我们注意到 CPU#0 的内核态中，&lt;code>estimation_timer&lt;/code> 这个函数的使用率一直占用比较高，同样我们通过对于 CPU#0 上的火焰图分析，也基本与 &lt;code>perf top&lt;/code> 的结果一致。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/estimation_timer_flamgraph.png" alt="">&lt;/p>
&lt;p>图 3-3 &lt;code>estimation_timer&lt;/code> 在内核 CPU#0 上的火焰图&lt;/p>
&lt;p>为了弄清楚 &lt;code>estimation_timer&lt;/code> 的内核占用情况，我们继续使用 开源项目 &lt;a href="https://github.com/brendangregg/perf-tools">perf-tools&lt;/a>（作者为 Brendan Gregg）中的 &lt;a href="https://github.com/brendangregg/perf-tools/blob/master/bin/funcgraph">funcgraph&lt;/a> 工具分析函数 &lt;code>estimation_timer&lt;/code> 在内核中的调用关系图和占用延时。&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># -m 1最大堆栈为 1 层，-a 显示全部信息 -d 6 跟踪 6秒&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">#./funcgraph -m 1 -a -d 6 estimation_timer&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/estimation_timer_funcgraph.png" alt="">&lt;/p>
&lt;p>图 3-4 &lt;code>estimation_timer&lt;/code> 函数在内核函数调用&lt;/p>
&lt;p>同时我们注意到 &lt;code>estimation_timer&lt;/code> 函数在 CPU#0 内核中的遍历一次遍历时间为 119 ms，在内核处理软中断的情况中占用过长的时间，这一定会影响到其他软中断的处理。&lt;/p>
&lt;p>为了进一步确认 CPU#0 上的软中断处理情况，我们基于 BCC 项目中的 &lt;a href="https://github.com/iovisor/bcc/blob/master/tools/softirqs.py">softirqs.py&lt;/a> 脚本（本地略有修改），观察 CPU#0 上的软中断数量变化和整体耗时分布，发现 CPU#0 上的软中断数量增长并不是太快，但是 timer 的直方图却又异常点数据， 通过 timer 在持续 10s 内的 timer 数据分析，我们发现执行的时长分布在 [65 - 130] ms 区间的记录有 5 条。这个结论完全与通过 &lt;code>funcgraph&lt;/code> 工具抓取到的 &lt;code>estimation_timer&lt;/code> 在 CPU#0 上的延时一致。。&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># -d 采用直方图 10 表示 10s 做一次聚合， 1 显示一次 -C 0 为我们自己修改的功能，用于过滤 CPU#0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># /usr/share/bcc/tools/softirqs -d 10 1 -C 0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/a705eb8d-74c1-4b40-bb71-60999d58cfc8/timer_softirq_hist.png" alt="">&lt;/p>
&lt;p>图 3-5 CPU#0 软中断之 timer 的执行时长直方图&lt;/p>
&lt;p>通过上述分析我们得知 &lt;code>estimation_timer&lt;/code> 来自于 ipvs 模块（参见图 3-4），kubernets 中 kube-proxy 组件负载均衡器正是基于 ipvs 模块，那么问题基本上出现在 kube-proxy 进程上。&lt;/p>
&lt;p>我们在主机 B 上仅保留测试的容器实例，在停止 kubelet 服务后，手工停止 kube-proxy 容器进程，经过重新测试，ping 延时抖动的问题果然消失了。&lt;/p>
&lt;p>到此问题的根源我们可以确定是 kube-proxy 中使用的 ipvs 内核模块中的 &lt;code>estimation_timer&lt;/code> 函数执行时间过长，导致网络软中断处理延迟，从而使 ping 包的出现抖动，那么 &lt;code>estimation_timer[ipvs]&lt;/code> 的作用是什么？ 什么情况下导致的该函数执行如此之长呢？&lt;/p>
&lt;h3 id="33-ipvs-estimation_timer-定时器">3.3 ipvs estimation_timer 定时器&lt;a class="td-heading-self-link" href="#33-ipvs-estimation_timer-%e5%ae%9a%e6%97%b6%e5%99%a8" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>谜底终将揭晓！&lt;/p>
&lt;p>我们通过阅读 ipvs 相关的源码，发现 &lt;code>estimation_timer()[ipvs]&lt;/code> 函数针对每个 Network Namespace 创建时候的通过 &lt;a href="https://elixir.bootlin.com/linux/v5.8/source/net/netfilter/ipvs/ip_vs_core.c#L2469">ip_vs_core.c&lt;/a> 中的 &lt;code>__ip_vs_init&lt;/code> 初始化的，&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code> 1
2
3
4
5
6
7
8
9
10
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">/*
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"> * Initialize IP Virtual Server netns mem.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"> */&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">static&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#000">__net_init&lt;/span> &lt;span style="color:#000">__ip_vs_init&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">net&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">net&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">netns_ipvs&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#8f5902;font-style:italic">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">ip_vs_estimator_net_init&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;lt;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 初始化
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#204a87;font-weight:bold">goto&lt;/span> &lt;span style="color:#000">estimator_fail&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>代码 3-5 ipvs 初始化函数&lt;/p>
&lt;p>&lt;code>ip_vs_estimator_net_init&lt;/code> 函数在文件 &lt;a href="https://elixir.bootlin.com/linux/v5.8/source/net/netfilter/ipvs/ip_vs_est.c#L187">ip_vs_est.c&lt;/a> 中，定义如下：&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
3
4
5
6
7
8
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#000">__net_init&lt;/span> &lt;span style="color:#000">ip_vs_estimator_net_init&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">netns_ipvs&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">INIT_LIST_HEAD&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_list&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">spin_lock_init&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_lock&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">timer_setup&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">estimation_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 设置定时器函数 estimation_timer
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#000">mod_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">jiffies&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span> &lt;span style="color:#000">HZ&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 启动第一次计时器，2秒启动
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>代码 3-6 ipvs estimator 初始化函数&lt;/p>
&lt;p>&lt;code>estimation_timer&lt;/code> 也定义在 &lt;a href="https://elixir.bootlin.com/linux/v5.8/source/net/netfilter/ipvs/ip_vs_est.c#L96">ip_vs_est.c&lt;/a> 文件中。&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code> 1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">static&lt;/span> &lt;span style="color:#204a87;font-weight:bold">void&lt;/span> &lt;span style="color:#000">estimation_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">timer_list&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">t&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#8f5902;font-style:italic">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#000">spin_lock&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_lock&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">list_for_each_entry&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">e&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_list&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">list&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">s&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">container_of&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">e&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">ip_vs_stats&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">est&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">spin_lock&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">s&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">lock&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">ip_vs_read_cpu_stats&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">s&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">kstats&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">s&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">cpustats&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#8f5902;font-style:italic">/* scaled by 2^10, but divided 2 seconds */&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">rate&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">s&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">kstats&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">conns&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span> &lt;span style="color:#000">e&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">last_conns&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;lt;&amp;lt;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">9&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">e&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">last_conns&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">s&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">kstats&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">conns&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">e&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">cps&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000;font-weight:bold">((&lt;/span>&lt;span style="color:#000">s64&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>&lt;span style="color:#000">rate&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">s64&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>&lt;span style="color:#000">e&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">cps&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#8f5902;font-style:italic">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">spin_unlock&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_lock&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">mod_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ipvs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&amp;gt;&lt;/span>&lt;span style="color:#000">est_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">jiffies&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">HZ&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// 2 秒后启动新的一轮统计
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>代码 3-7 ipvs estimation_timer 函数&lt;/p>
&lt;p>从 &lt;code>estimation_timer&lt;/code> 的函数实现来看，会首先调用 spin_lock 进行锁的操作，然后遍历当前 Network Namespace 下的全部 ipvs 规则。由于我们集群的某些历史原因导致生产集群中的 Service 比较多，因此导致一次遍历的时候会占用比较长的时间。&lt;/p>
&lt;p>该函数的统计最终体现在 &lt;code>ipvsadm --stat&lt;/code> 的结果中（Conns InPkts OutPkts InBytes OutBytes）：&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
3
4
5
6
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># ipvsadm -Ln --stats&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>IP Virtual Server version 1.2.1 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>4096&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes &lt;span style="color:#8f5902;font-style:italic"># 相关统计&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> -&amp;gt; RemoteAddress:Port
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>TCP 10.85.0.10:9153 &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> -&amp;gt; 172.22.34.187:9153 &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>对于我们集群中的 &lt;code>ipvs&lt;/code> 规则进行统计，我们发现大概在 30000 左右。&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># ipvsadm -Ln --stats|wc -l&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>既然每个 Network Namespace 下都会有 &lt;code>estimation_timer&lt;/code> 的遍历，为什么只有 CPU#0 上的规则如此多呢？&lt;/p>
&lt;p>这是因为只有主机的 Host Network Namespace 中才会有全部的 ipvs 规则，这个我们也可以通过 &lt;code>ipvsadm -Ln&lt;/code> (执行在 Host Network Namespace 下) 验证。从现象来看，CPU#0 是 ipvs 模块加载的时候用于处理宿主机 Host Network Namespace 中的 ipvs 规则，当然这个核的加载完全是随机的。&lt;/p>
&lt;h2 id="4-问题解决">4. 问题解决&lt;a class="td-heading-self-link" href="#4-%e9%97%ae%e9%a2%98%e8%a7%a3%e5%86%b3" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="41-解决方案">4.1 解决方案&lt;a class="td-heading-self-link" href="#41-%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>到此，问题已经彻底定位，由于我们服务早期部署的历史原因，短期内调整 Service 的数目会导致大量的迁移工作，中间还有云厂商 SLB 产生的大量规则，也没有办法彻底根除，单从技术上解决的话，我们可以采用的方式有以下 3 种：&lt;/p>
&lt;ol>
&lt;li>动态感知到宿主机 Network Namespace 中 ipvs &lt;code>estimation_timer&lt;/code> 函数的函数，在 RPS 中设置关闭该 CPU 映射；
该方式需要调整 RPS 的配置，而且 ipvs 处理主机 Network Namespace 的核数不固定，需要识别并调整配置，还需要处理重启时候的 ipvs 主机 Network Namespace 的变动；&lt;/li>
&lt;li>由于我们不需要 ipvs 这种统计的功能，可以通过修改 ipvs 驱动的方式来规避该问题；
修改 ipvs 的驱动模块，需要重新加载该内核模块，也会导致主机服务上的短暂中断；&lt;/li>
&lt;li>ipvs 模块将内核遍历统计调整成一个独立的内核线程进行统计；&lt;/li>
&lt;/ol>
&lt;p>ipvs 规则在内核 timer 中遍历是 ipvs 移植到 k8s 上场景未适配的问题，社区应该需要把在 timer 中的遍历独立出去，但是这个方案需要社区的推动解决，远水解不了近渴。&lt;/p>
&lt;p>通过上述 3 种方案的对比，解决我们当前抖动的问题都不太容易实施，为了保证生产环境的稳定和实施的难易程度，最终我们把眼光定位在 Linux Kernel 热修的 &lt;a href="https://github.com/dynup/kpatch">kpatch&lt;/a> 方案上， kpath 实现的 livepatch 功能可以实时为正在运行的内核提供功能增强，无需重新启动系统。&lt;/p>
&lt;h3 id="42-kpatch-livepatch">4.2 kpatch livepatch&lt;a class="td-heading-self-link" href="#42-kpatch-livepatch" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Kpatch 是给 Linux 内核 livepatch 的工具，由 Redhat 公司出品。最早出现的打热补丁工具是 Ksplice。但是 Ksplice 被 Oracle 收购后，一些发行版生产商就不得不开发自己的热补丁工具，分别是 Redhat 的 Kpatch 和 Suse 的 KGraft。同时，在这两家厂商的推进下，kernel 4.0 开始，开始集成了 livepatch 技术。 Kpatch 虽然是 Redhat 研发，但其也支持 Ubuntu、Debian、Oracle Linux 等的发行版。&lt;/p>
&lt;p>这里我们简单同步一下实施的步骤，更多的文档可以从 kpath 项目中获取。&lt;/p>
&lt;h4 id="421-获取-kpath-编译和安装">4.2.1 获取 kpath 编译和安装&lt;a class="td-heading-self-link" href="#421-%e8%8e%b7%e5%8f%96-kpath-%e7%bc%96%e8%af%91%e5%92%8c%e5%ae%89%e8%a3%85" aria-label="Heading self-link">&lt;/a>&lt;/h4>
&lt;p>|&lt;/p>
&lt;pre>&lt;code> 1
2
3
4
5
6
7
8
9
10
11
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ git clone https://github.com/dynup/kpatch.git
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ &lt;span style="color:#204a87">source&lt;/span> test/integration/lib.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 中间会使用 yum 安装相关的依赖包，安装时间视网络情况而定，在阿里云的环境下需要的时间比较长&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ sudo kpatch_dependencies
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ &lt;span style="color:#204a87">cd&lt;/span> kpatch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 进行编译&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ make
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 默认安装到 /usr/local，需要注意 kpatch-build 在目录 /usr/local/bin/ 下，而 kpatch 在 /usr/local/sbin/ 目录&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ sudo make install
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;h4 id="422-生成内核源码-patch">4.2.2 生成内核源码 patch&lt;a class="td-heading-self-link" href="#422-%e7%94%9f%e6%88%90%e5%86%85%e6%a0%b8%e6%ba%90%e7%a0%81-patch" aria-label="Heading self-link">&lt;/a>&lt;/h4>
&lt;p>在 kpatch 的使用过程中，需要使用到内核的源码，源码拉取的方式可以参考这里&lt;a href="https://wiki.centos.org/zh/HowTos/I_need_the_Kernel_Source?highlight=(kernel)%7C(src)">我需要内核的源代码&lt;/a>。&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
3
4
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ rpm2cpio kernel-3.10.0-1062.9.1.el7.src.rpm &lt;span style="color:#000;font-weight:bold">|&lt;/span>cpio -div
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ xz -d linux-3.10.0-1062.9.1.el7.tar.xz
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ tar -xvf linux-3.10.0-1062.9.1.el7.tar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cp -ra linux-3.10.0-1062.9.1.el7/ linux-3.10.0-1062.9.1.el7-patch
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>此处我们将 &lt;code>estimation_timer&lt;/code> 函数的实现设置为空&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
3
4
5
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">static&lt;/span> &lt;span style="color:#204a87;font-weight:bold">void&lt;/span> &lt;span style="color:#000">estimation_timer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">unsigned&lt;/span> &lt;span style="color:#204a87;font-weight:bold">long&lt;/span> &lt;span style="color:#000">arg&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">printk&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;hotfix estimation_timer patched&lt;/span>&lt;span style="color:#4e9a06">\n&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#204a87;font-weight:bold">return&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>并生成对应的 patch 文件&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># diff -u linux-3.10.0-1062.9.1.el7/net/netfilter/ipvs/ip_vs_est.c linux-3.10.0-1062.9.1.el7-patch/net/netfilter/ipvs/ip_vs_est.c &amp;gt; ip_vs_timer_v1.patch&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;h4 id="423-生产内核补丁并-livepatch">4.2.3 生产内核补丁并 livepatch&lt;a class="td-heading-self-link" href="#423-%e7%94%9f%e4%ba%a7%e5%86%85%e6%a0%b8%e8%a1%a5%e4%b8%81%e5%b9%b6-livepatch" aria-label="Heading self-link">&lt;/a>&lt;/h4>
&lt;p>然后生成相关的 patch ko 文件并应用到内核：&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
3
4
5
6
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># /usr/local/bin/kpatch-build ip_vs_timer_v1.patch --skip-gcc-check --skip-cleanup -r /root/kernel-3.10.0-1062.9.1.el7.src.rpm&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 编译成功后会在当前目录生成 livepatch-ip_vs_timer_v1.ko 文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 应用到内核中.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># /usr/local/sbin/kpatch load livepatch-ip_vs_timer_v1.ko&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>通过内核日志查看确认&lt;/p>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
3
4
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ dmesg -T
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>Thu Dec &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span> 19:50:50 2020&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> livepatch: enabling patch &lt;span style="color:#4e9a06">&amp;#39;livepatch_ip_vs_timer_v1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>Thu Dec &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span> 19:50:50 2020&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> livepatch: &lt;span style="color:#4e9a06">&amp;#39;livepatch_ip_vs_timer_v1&amp;#39;&lt;/span>: starting patching transition
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>Thu Dec &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span> 19:50:50 2020&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> hotfix estimation_timer patched
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;p>至此通过我们的 livepatch 成功修订了 &lt;code>estimation_timer&lt;/code> 的调用，一切看起来很成功。然后通过 &lt;code>funcgraph&lt;/code> 工具查看 &lt;code>estimation_timer&lt;/code> 函数不再出现在调用关系中。&lt;/p>
&lt;blockquote>
&lt;p>如果仅仅把函数设置为空的实现，等于是关闭了 &lt;code>estimation_timer&lt;/code> 的调用，即使通过命令 unload 掉 livepatch，该函数的也不会恢复，因此在生产环境中建议将函数的 2s 调用设置成个可以接受的时间范围内，比如 5 分钟，这样在 unload 以后，可以在 5 分钟以后恢复 &lt;code>estimation_timer&lt;/code> 的继续调用。&lt;/p>
&lt;/blockquote>
&lt;h3 id="43-使用-kpatch-注意事项">4.3 使用 kpatch 注意事项&lt;a class="td-heading-self-link" href="#43-%e4%bd%bf%e7%94%a8-kpatch-%e6%b3%a8%e6%84%8f%e4%ba%8b%e9%a1%b9" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>kpatch 是基于内核版本生成的 ko 内核模块，必须保证后续 livepatch 的内核版本与编译机器的内核完全一致。&lt;/li>
&lt;li>通过手工 livepatch 的方式修复，如果保证机器在重启以后仍然生效需要通过 &lt;code>install&lt;/code> 来启用 kpathc 服务进行保证。&lt;/li>
&lt;/ul>
&lt;p>|&lt;/p>
&lt;pre>&lt;code>1
2
&lt;/code>&lt;/pre>
&lt;p>|&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># /usr/local/sbin/kpatch install livepatch-ip_vs_timer_v1.ko&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># systemctl start kpatch&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>|&lt;/p>
&lt;ul>
&lt;li>在其他的机器上进行 livepatch 需要文件&lt;code>kpatch&lt;/code>、&lt;code>livepatch-ip_vs_timer_v1.ko&lt;/code> 和 &lt;code>kpatch.service&lt;/code>（用于 install 后重启生效） 3 个文件即可。&lt;/li>
&lt;/ul>
&lt;h2 id="5-总结">5. 总结&lt;a class="td-heading-self-link" href="#5-%e6%80%bb%e7%bb%93" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>网络抖动问题的排查，涉及应用层、网络协议栈和内核中运作机制等多方面的协调，排查过程中需要逐层排查、逐步缩小范围，在整个过程中，合适的工具至关重要，在我们本次问题的排查过程中， BPF 技术为我们排查的方向起到了至关重要的作用。BPF 技术的出现为我们观测和跟踪内核中的事件，提供了更加灵活的数据采集和数据分析的能力，在生产环境中我们已经将其广泛用于了监控网络底层的重传和抖动等维度，极大提升提升我们在偶发场景下的问题排查效率，希望更多的人能够从 BPF 技术中受益。
&lt;a href="https://www.ebpf.top/post/ebpf_network_kpath_ipvs/">https://www.ebpf.top/post/ebpf_network_kpath_ipvs/&lt;/a>&lt;/p></description></item><item><title>Docs: 10.2.深入理解 Cilium 的 eBPF 收发包路径</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/10.2.%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Cilium-%E7%9A%84-eBPF-%E6%94%B6%E5%8F%91%E5%8C%85%E8%B7%AF%E5%BE%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/10.2.%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Cilium-%E7%9A%84-eBPF-%E6%94%B6%E5%8F%91%E5%8C%85%E8%B7%AF%E5%BE%84/</guid><description>
&lt;h1 id="heading">&lt;a class="td-heading-self-link" href="#heading" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="深入理解-cilium-的-ebpf-收发包路径">深入理解 Cilium 的 eBPF 收发包路径&lt;a class="td-heading-self-link" href="#%e6%b7%b1%e5%85%a5%e7%90%86%e8%a7%a3-cilium-%e7%9a%84-ebpf-%e6%94%b6%e5%8f%91%e5%8c%85%e8%b7%af%e5%be%84" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>本文翻译自 2019 年 DigitalOcean 的工程师 Nate Sweet 在 KubeCon 的一篇分享: Understanding (and Troubleshooting) the eBPF Datapath in Cilium[1] 。&lt;/p>
&lt;p>由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。&lt;/p>
&lt;p>以下是译文。&lt;/p>
&lt;ol>
&lt;li>为什么要关注 eBPF？&lt;/li>
&lt;/ol>
&lt;p>网络成为瓶颈&lt;/p>
&lt;p>大家已经知道网络成为瓶颈，但我是从下面这个角度考虑的：近些年业界使用网络的方式 ，使其成为瓶颈（it is the bottleneck in a way that is actually pretty recent） 。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>网络一直都是 I/O 密集型的，但直到最近，这件事情才变得尤其重要。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>分布式任务（workloads）业界一直都在用，但直到近些年，这种模型才成为主流。虽然何时成为主流众说纷纭，但我认为最早不会早于 90 年代晚期。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>公有云的崛起，我认为可能是网络成为瓶颈的最主要原因。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这种情况下，用于管理依赖和解决瓶颈的工具都已经过时了。&lt;/p>
&lt;p>但像 eBPF 这样的技术使得网络调优和整流（tune and shape this traffic）变得简单很多。eBPF 提供的许多能力是其他工具无法提供的，或者即使提供了，其代价也要比 eBPF 大 的多。&lt;/p>
&lt;p>eBPF 无处不在&lt;/p>
&lt;p>eBPF 正在变得无处不在，我们可能会争论这到底是一件好事还是坏事（eBPF 也确实带了一 些安全问题），但当前无法忽视的事实是：Linux 内核的网络开发者们正在将 eBPF 应用 于各种地方（putting it everywhere）。其结果是，eBPF 与内核的默认收发包路径（ datapath）耦合得越来越紧（more and more tightly coupled with the default datapath）。&lt;/p>
&lt;p>性能就是金钱&lt;/p>
&lt;p>“Metrics are money”[2]， 这是今年 Paris Kernel Recipes 峰会上，来自 Synthesio 的 Aurelian Rougemont 的 精彩分享。&lt;/p>
&lt;p>他展示了一些史诗级的调试（debugging）案例，感兴趣的可以去看看；但更重要的是，他 从更高层次提出了这样一个观点：理解这些东西是如何工作的，最终会产生资本收益（ understanding how this stuff works translates to money）。为客户节省金钱，为 自己带来收入。&lt;/p>
&lt;p>如果你能从更少的资源中榨取出更高的性能，使软件运行更快，那 显然你对公司的贡献就更大。Cilium 就是这样一个能让你带来更大价值的工具。&lt;/p>
&lt;p>在进一步讨论之前，我先简要介绍一下 eBPF 是什么，以及为什么它如此强大。&lt;/p>
&lt;ol start="2">
&lt;li>eBPF 是什么？&lt;/li>
&lt;/ol>
&lt;p>BPF 程序有多种类型，图 2.1 是其中一种，称为 XDP BPF 程序。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>XDP 是 eXpress DataPath（特快数据路径）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>XDP 程序可以直接加载到网络设备上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>XDP 程序在数据包收发路径上很前面的位置就开始执行，下面会看到例子。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>BPF 程序开发方式：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>编写一段 BPF 程序&lt;/p>
&lt;/li>
&lt;li>
&lt;p>编译这段 BPF 程序&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用一个特殊的系统调用将编译后的代码加载到内核&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>这实际上就是编写了一段内核代码，并动态插入到了内核（written kernel code and dynamically inserted it into the kernel）。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781351-8a096334-1fbf-483b-96ee-8759c09df60d.jpeg" alt="">&lt;/p>
&lt;p>图 2.1. eBPF 代码示例：丢弃源 IP 命中黑名单的 ARP 包&lt;/p>
&lt;p>图 2.1 中的程序使用了一种称为 map 的东西，这是一种特殊的数据结构，可用于 在内核和用户态之间传递数据，例如通过一个特殊的系统从用户态向 map 里插入数据。&lt;/p>
&lt;p>这段程序的功能：丢弃所有源 IP 命中黑名单的 ARP 包。右侧四个框内的代码功能：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>初始化以太帧结构体（ethernet packet）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果不是 ARP 包，直接退出，将包交给内核继续处理。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>至此已确定是 ARP，因此初始化一个 ARP 数据结构，对包进行下一步处理。例 如，提取出 ARP 中的源 IP，去之前创建好的黑名单中查询该 IP 是否存在。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果存在，返回丢弃判决（XDP_DROP）；否则，返回允许通行判决（ XDP_PASS），内核会进行后续处理。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>你可能不会相信，就这样一段简单的程序，会让服务器性能产生质的飞跃，因为它此时已 经拥有了一条极为高效的网络路径（an extremely efficient network path）。&lt;/p>
&lt;ol start="3">
&lt;li>为什么 eBPF 如此强大？&lt;/li>
&lt;/ol>
&lt;p>三方面原因：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>快速（fast）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>灵活（flexible）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据与功能分离（separates data from functionality）&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>快速&lt;/p>
&lt;p>eBPF 几乎总是比 iptables 快，这是有技术原因的。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>eBPF 程序本身并不比 iptables 快，但 eBPF 程序更短。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>iptables 基于一个非常庞大的内核框架（Netfilter），这个框架出现在内核 datapath 的多个地方，有很大冗余。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>因此，同样是实现 ARP drop 这样的功能，基于 iptables 做冗余就会非常大，导致性能很低。&lt;/p>
&lt;p>灵活&lt;/p>
&lt;p>这可能是最主要的原因。你可以用 eBPF 做几乎任何事情。&lt;/p>
&lt;p>eBPF 基于内核提供的一组接口，运行 JIT 编译的字节码，并将计算结果返回给内核。例如 内核只关心 XDP 程序的返回是 PASS, DROP 还是 REDIRECT。至于在 XDP 程序里做什么， 完全看你自己。&lt;/p>
&lt;p>数据与功能分离&lt;/p>
&lt;p>eBPF separates data from functionality.&lt;/p>
&lt;p>nftables 和 iptables 也能干这个事情，但功能没有 eBPF 强大。例如，eBPF 可以使 用 per-cpu 的数据结构，因此能取得更极致的性能。&lt;/p>
&lt;p>eBPF 真正的优势是将 “数据与功能分离” 这件事情做地非常干净（clean separation）：可以在 eBPF 程序不中断的情况下修改它的运行方式。具体方式是修改它访 问的配置数据或应用数据，例如黑名单里规定的 IP 列表和域名。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781318-616b3cfa-ef39-48c2-a3bc-b237c8f14596.jpeg" alt="">&lt;/p>
&lt;ol start="4">
&lt;li>eBPF 简史&lt;/li>
&lt;/ol>
&lt;p>这里是简单介绍几句，后面 datapath 才是重点。&lt;/p>
&lt;p>两篇论文，可读性还是比较好的，感兴趣的自行阅读：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Steven McCanne, et al, in 1993 - The BSD Packet Filter&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Jeffrey C. Mogul, et al, in 1987 - first open source implementation of a packet filter.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol start="5">
&lt;li>Cilium 是什么，为什么要关注它？&lt;/li>
&lt;/ol>
&lt;p>我认为理解 eBPF 代码还比较简单，多看看内核代码就行了，但配置和编写 eBPF 就要难多了。&lt;/p>
&lt;p>Cilium 是一个很好的 eBPF 之上的通用抽象，覆盖了分布式系统的绝大多数场景。Cilium 封装了 eBPF，提供一个更上层的 API。如果你使用的是 Kubernetes，那你至少应该听说过 Cilium。&lt;/p>
&lt;p>Cilium 提供了 CNI 和 kube-proxy replacement 功能，相比 iptables 性能要好很多。&lt;/p>
&lt;p>接下来开始进入本文重点。&lt;/p>
&lt;ol start="6">
&lt;li>内核默认 datapath&lt;/li>
&lt;/ol>
&lt;p>本节将介绍数据包是如何穿过 network datapath（网络数据路径）的：包括从硬件到 内核，再到用户空间。&lt;/p>
&lt;p>这里将只介绍 Cilium 所使用的 eBPF 程序，其中有 Cilium logo 的地方，都是 datapath 上 Cilium 重度使用 BPF 程序的地方。&lt;/p>
&lt;p>本文不会过多介绍硬件相关内容，因为理解 eBPF 基本不需要硬件知识，但显然理解了硬件 原理也并无坏处。另外，由于时间限制，我将只讨论接收部分。&lt;/p>
&lt;p>L1 -&amp;gt; L2（物理层 -&amp;gt; 数据链路层）&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781303-b3b39b25-bc79-4cc3-aac9-6aa9b8474ffd.jpeg" alt="">&lt;/p>
&lt;p>网卡收包简要流程：&lt;/p>
&lt;ol>
&lt;li>网卡驱动初始化。&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>网卡获得一块物理内存，作用收发包的缓冲区（ring-buffer）。这种方式成为 DMA（直接内存访问）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>驱动向内核 NAPI（New API）注册一个轮询（poll ）方法。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>
&lt;p>网卡从云上收到一个包，将包放到 ring-buffer。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果此时 NAPI 没有在执行，网卡就会触发一个硬件中断（HW IRQ），告诉处理器 DMA 区域中有包等待处理。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>收到硬中断信号后，处理器开始执行 NAPI。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NAPI 执行网卡注册的 poll 方法开始收包。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>关于 NAPI poll 机制：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>这是 Linux 内核中的一种通用抽象，任何等待不可抢占状态发生（wait for a preemptible state to occur）的模块，都可以使用这种注册回调函数的方式。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>驱动注册的这个 poll 是一个主动式 poll（active poll），一旦执行就会持续处理 ，直到没有数据可供处理，然后进入 idle 状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在这里，执行 poll 方法的是运行在某个或者所有 CPU 上的内核线程（kernel thread）。虽然这个线程没有数据可处理时会进入 idle 状态，但如前面讨论的，在当前大部分分布 式系统中，这个线程大部分时间内都是在运行的，不断从驱动的 DMA 区域内接收数据包。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>poll 会告诉网卡不要再触发硬件中断，使用软件中断（softirq）就行了。此后这些 内核线程会轮询网卡的 DMA 区域来收包。之所以会有这种机制，是因为硬件中断代价太 高了，因为它们比系统上几乎所有东西的优先级都要高。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>我们接下来还将多次看到这个广义的 NAPI 抽象，因为它不仅仅处理驱动，还能处理许多 其他场景。内核用 NAPI 抽象来做驱动读取（driver reads）、epoll 等等。&lt;/p>
&lt;p>NAPI 驱动的 poll 机制将数据从 DMA 区域读取出来，对数据做一些准备工作，然后交给比 它更上一层的内核协议栈。&lt;/p>
&lt;p>L2 续（数据链路层 - 续）&lt;/p>
&lt;p>同样，这里不会深入展开驱动层做的事情，而主要关注内核所做的一些更上层的事情，例如&lt;/p>
&lt;ul>
&lt;li>
&lt;p>分配 socket buffers（skb）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>BPF&lt;/p>
&lt;/li>
&lt;li>
&lt;p>iptables&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将包送到网络栈（network stack）和用户空间&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Step 1：NAPI poll&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781309-125b38ab-2e65-40ef-aa15-62f61eb13ceb.jpeg" alt="">&lt;/p>
&lt;p>首先，NAPI poll 机制不断调用驱动实现的 poll 方法，后者处理 RX 队列内的包，并最终 将包送到正确的程序。这就到了我们前面的 XDP 类型程序。&lt;/p>
&lt;p>Step 2：XDP 程序处理&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781326-521284ff-d334-4b96-aedb-b33d0b2de4bc.jpeg" alt="">&lt;/p>
&lt;p>如果驱动支持 XDP，那 XDP 程序将在 poll 机制内执行。如果不支持，那 XDP 程序将只能在更后面执行（run significantly upstack，见 Step 6），性能会变差， 因此确定你使用的网卡是否支持 XDP 非常重要。&lt;/p>
&lt;p>XDP 程序返回一个判决结果给驱动，可以是 PASS, TRANSMIT, 或 DROP。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Transmit 非常有用，有了这个功能，就可以用 XDP 实现一个 TCP/IP 负载均衡器。XDP 只适合对包进行较小修改，如果是大动作修改，那这样的 XDP 程序的性能 可能并不会很高，因为这些操作会降低 poll 函数处理 DMA ring-buffer 的能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更有趣的是 DROP 方法，因为一旦判决为 DROP，这个包就可以直接原地丢弃了，而 无需再穿越后面复杂的协议栈然后再在某个地方被丢弃，从而节省了大量资源。如果本次 分享我只能给大家一个建议，那这个建议就是：在 datapath 越前面做 tuning 和 dropping 越好，这会显着增加系统的网络吞吐。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果返回是 PASS，内核会继续沿着默认路径处理包，到达 clean_rx() 方法。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Step 3：clean_rx()：创建 skb&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781362-6a9e47a1-27b7-4c04-9561-20c8e31f36ac.jpeg" alt="">&lt;/p>
&lt;p>如果返回是 PASS，内核会继续沿着默认路径处理包，到达 clean_rx() 方法。&lt;/p>
&lt;p>这个方法创建一个 socket buffer（skb）对象，可能还会更新一些统计信息，对 skb 进行硬件校验和检查，然后将其交给 gro_receive() 方法。&lt;/p>
&lt;p>Step 4：gro_receive()&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781355-174a04b7-6899-4edb-b03e-f367bb5964f8.jpeg" alt="">&lt;/p>
&lt;p>GRO 是一种较老的硬件特性（LRO）的软件实现，功能是对分片的包进行重组然后交给更 上层，以提高吞吐。&lt;/p>
&lt;p>GRO 给协议栈提供了一次将包交给网络协议栈之前，对其检查校验和 、修改协议头和发送应答包（ACK packets）的机会。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>如果 GRO 的 buffer 相比于包太小了，它可能会选择什么都不做。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果当前包属于某个更大包的一个分片，调用 enqueue_backlog 将这个分片放到某个 CPU 的包队列。当包重组完成后，会交给 receive_skb() 方法处理。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果当前包不是分片包，直接调用 receive_skb()，进行一些网络栈最底层的处理。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Step 5：receive_skb()&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781356-3ece92df-59d7-4c45-a9e1-d2c93c7ed8c8.jpeg" alt="">&lt;/p>
&lt;p>receive_skb() 之后会再次进入 XDP 程序点。&lt;/p>
&lt;p>L2 -&amp;gt; L3（数据链路层 -&amp;gt; 网络层）&lt;/p>
&lt;p>Step 6：通用 XDP 处理（gXDP）&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781340-de37c24f-f1a6-4301-ba6d-9714dcbd4441.jpeg" alt="">&lt;/p>
&lt;p>receive_skb() 之后，我们又来到了另一个 XDP 程序执行点。这里可以通过 receive_xdp() 做一些通用（generic）的事情，因此我在图中将其标注为 (g)XDP&lt;/p>
&lt;p>Step 2 中提到，如果网卡驱动不支持 XDP，那 XDP 程序将延迟到更后面执行，这个 “更后面” 的位置指的就是这里的 (g)XDP。&lt;/p>
&lt;p>Step 7：Tap 设备处理&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781402-cd7bbf78-f5ef-4707-9fc9-f07c344a9cd5.jpeg" alt="">&lt;/p>
&lt;p>图中有个 *check_taps 框，但其实并没有这个方法：receive_skb() 会轮询所有的 socket tap，将包放到正确的 tap 设备的缓冲区。&lt;/p>
&lt;p>tap 设备监听的是三层协议（L3 protocols），例如 IPv4、ARP、IPv6 等等。如果 tap 设 备存在，它就可以操作这个 skb 了。&lt;/p>
&lt;p>Step 8：tc（traffic classifier）处理&lt;/p>
&lt;p>接下来我们遇到了第二种 eBPF 程序：tc eBPF。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781385-cf6fb476-67e1-460a-a67b-ca69a3c7f29b.jpeg" alt="">&lt;/p>
&lt;p>tc（traffic classifier，流量分类器）是 Cilium 依赖的最基础的东西，它提供了多种功 能，例如修改包（mangle，给 skb 打标记）、重路由（reroute）、丢弃包（drop），这 些操作都会影响到内核的流量统计，因此也影响着包的排队规则（queueing discipline ）。&lt;/p>
&lt;p>Cilium 控制的网络设备，至少被加载了一个 tc eBPF 程序。&lt;/p>
&lt;p>译者注：如何查看已加载的 eBPF 程序，可参考 Cilium Network Topology and Traffic Path on AWS[3]。&lt;/p>
&lt;p>Step 9：Netfilter 处理&lt;/p>
&lt;p>如果 tc BPF 返回 OK，包会再次进入 Netfilter。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781357-7af070a5-c730-43b3-a4d5-a9dc8c2a9f6b.jpeg" alt="">&lt;/p>
&lt;p>Netfilter 也会对入向的包进行处理，这里包括 nftables 和 iptables 模块。&lt;/p>
&lt;p>有一点需要记住的是：Netfilter 是网络栈的下半部分（the “bottom half” of the network stack），因此 iptables 规则越多，给网络栈下半部分造成的瓶颈就越大。&lt;/p>
&lt;p>*def_dev_protocol 框是二层过滤器（L2 net filter），由于 Cilium 没有用到任何 L2 filter，因此这里我就不展开了。&lt;/p>
&lt;p>Step 10：L3 协议层处理：ip_rcv()&lt;/p>
&lt;p>最后，如果包没有被前面丢弃，就会通过网络设备的 ip_rcv() 方法进入协议栈的三层（ L3）—— 即 IP 层 —— 进行处理。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781390-e8226b64-65b0-480a-8269-62782e6d97b0.jpeg" alt="">&lt;/p>
&lt;p>接下来我们将主要关注这个函数，但这里需要提醒大家的是，Linux 内核也支持除了 IP 之 外的其他三层协议，它们的 datapath 会与此有些不同。&lt;/p>
&lt;p>L3 -&amp;gt; L4（网络层 -&amp;gt; 传输层）&lt;/p>
&lt;p>Step 11：Netfilter L4 处理&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781353-857fa1b3-fcd0-4052-9b4c-a7539b7a2907.jpeg" alt="">&lt;/p>
&lt;p>ip_rcv() 做的第一件事情是再次执行 Netfilter 过滤，因为我们现在是从四层（L4）的 视角来处理 socker buffer。因此，这里会执行 Netfilter 中的任何四层规则（L4 rules ）。&lt;/p>
&lt;p>Step 12：ip_rcv_finish() 处理&lt;/p>
&lt;p>Netfilter 执行完成后，调用回调函数 ip_rcv_finish()。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781360-4b6933f0-7d4c-4d95-bc21-fe4217382495.jpeg" alt="">&lt;/p>
&lt;p>ip_rcv_finish() 立即调用 ip_routing() 对包进行路由判断。&lt;/p>
&lt;p>Step 13：ip_routing() 处理&lt;/p>
&lt;p>ip_routing() 对包进行路由判断，例如看它是否是在 lookback 设备上，是否能 路由出去（could egress），或者能否被路由，能否被 unmangle 到其他设备等等。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781356-e2454884-0357-4e17-8154-094f13cf535f.jpeg" alt="">&lt;/p>
&lt;p>在 Cilium 中，如果没有使用隧道模式（tunneling），那就会用到这里的路由功能。相比 隧道模式，路由模式会的 datapath 路径更短，因此性能更高。&lt;/p>
&lt;p>Step 14：目的是本机：ip_local_deliver() 处理&lt;/p>
&lt;p>根据路由判断的结果，如果包的目的端是本机，会调用 ip_local_deliver() 方法。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781519-8415d07c-c86d-47c4-aa3a-ce840006eab8.jpeg" alt="">&lt;/p>
&lt;p>ip_local_deliver() 会调用 xfrm4_policy()。&lt;/p>
&lt;p>Step 15：xfrm4_policy() 处理&lt;/p>
&lt;p>xfrm4_policy() 完成对包的封装、解封装、加解密等工作。例如，IPSec 就是在这里完成的。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781375-3453d8c9-b62b-4ba8-9621-ffb3496bf618.jpeg" alt="">&lt;/p>
&lt;p>最后，根据四层协议的不同，ip_local_deliver() 会将最终的包送到 TCP 或 UDP 协议 栈。这里必须是这两种协议之一，否则设备会给源 IP 地址回一个 ICMP destination unreachable 消息。&lt;/p>
&lt;p>接下来我将拿 UDP 协议作为例子，因为 TCP 状态机太复杂了，不适合这里用于理解 datapath 和数据流。但不是说 TCP 不重要，Linux TCP 状态机还是非常值得好好学习的。&lt;/p>
&lt;p>L4（传输层，以 UDP 为例）&lt;/p>
&lt;p>Step 16：udp_rcv() 处理&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781393-aae801ea-ac79-4dad-bae2-ddbbd8f0ac19.jpeg" alt="">&lt;/p>
&lt;p>udp_rcv() 对包的合法性进行验证，检查 UDP 校验和。然后，再次将包送到 xfrm4_policy() 进行处理。&lt;/p>
&lt;p>Step 17：xfrm4_policy() 再次处理&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781393-80815a9b-7c61-4644-911e-bff8f08b31e3.jpeg" alt="">&lt;/p>
&lt;p>这里再次对包执行 transform policies 是因为，某些规则能指定具体的四层协议，所以只 有到了协议层之后才能执行这些策略。&lt;/p>
&lt;p>Step 18：将包放入 socket_receive_queue&lt;/p>
&lt;p>这一步会拿端口（port）查找相应的 socket，然后将 skb 放到一个名为 socket_receive_queue 的链表。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781401-cafb7408-4dc8-4338-9a75-5fef6714b75b.jpeg" alt="">&lt;/p>
&lt;p>Step 19：通知 socket 收数据：sk_data_ready()&lt;/p>
&lt;p>最后，udp_rcv() 调用 sk_data_ready() 方法，标记这个 socket 有数据待收。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781394-3ce9c54f-b38e-4c77-a8f6-7b2095b7c51d.jpeg" alt="">&lt;/p>
&lt;p>本质上，一个 socket 就是 Linux 中的一个文件描述符，这个描述符有一组相关的文件操 作抽象，例如 read、write 等等。&lt;/p>
&lt;p>网络栈下半部分小结&lt;/p>
&lt;p>以上 Step 1~19 就是 Linux 网络栈下半部分（bottom half of the network stack）的全部内容。&lt;/p>
&lt;p>接下来我们还会介绍几个内核函数，但它们都是与进程上下文相关的。&lt;/p>
&lt;p>L4 - User Space&lt;/p>
&lt;p>下图左边是一段 socket listening 程序，这里省略了错误检查，而且 epoll 本质上也 是不需要的，因为 UDP 的 recv 方法以及在帮我们 poll 了。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/mvtx1i/1616164781397-a531fb3e-8a78-4628-8e1a-5be07d06b5c6.jpeg" alt="">&lt;/p>
&lt;p>由于大家还是对 TCP 熟悉一些，因此在这里我假设这是一段 TCP 代码。事实上当我们调 用 recvmsg() 方法时，内核所做的事情就和上面这段代码差不多。对照右边的图：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>首先初始化一个 epoll 实例和一个 UDP socket，然后告诉 epoll 实例我们想 监听这个 socket 上的 receive 事件，然后等着事件到来。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当 socket buffer 收到数据时，其 wait queue 会被上一节的 sk_data_ready() 方法置位（标记）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>epoll 监听在 wait queue，因此 epoll 收到事件通知后，提取事件内容，返回给用户空间。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用户空间程序调用 recv 方法，它接着调用 udp_recv_msg 方法，后者又会 调用 cgroup eBPF 程序 —— 这是本文出现的第三种 BPF 程序。Cilium 利用 cgroup eBPF 实现 socket level 负载均衡，这非常酷：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>一般的客户端负载均衡对客户端并不是透明的，即，客户端应用必须将负载均衡逻辑内置到应用里。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>有了 cgroup BPF，客户端根本感知不到负载均衡的存在。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>本文介绍的最后一种 BPF 程序是 sock_ops BPF，用于 socket level 整流（traffic shaping ），这对某些功能至关重要，例如客户端级别的限速（rate limiting）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>最后，我们有一个用户空间缓冲区，存放收到的数据。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>以上就是 Cilium 基于 eBPF 的内核收包之旅（traversing the kernel’s datapath）。太壮观了！&lt;/p>
&lt;ol start="7">
&lt;li>Kubernets、Cilium 和 Kernel：原子对象对应关系&lt;/li>
&lt;/ol>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Kubernetes&lt;/td>
&lt;td>Cilium&lt;/td>
&lt;td>Kernel&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Endpoint (includes Pods)&lt;/td>
&lt;td>Endpoint&lt;/td>
&lt;td>tc, cgroup socket BPF, sock_ops BPF, XDP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Network Policy&lt;/td>
&lt;td>Cilium Network Policy&lt;/td>
&lt;td>XDP, tc, sock-ops&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Service (node ports, cluster ips, etc)&lt;/td>
&lt;td>Service&lt;/td>
&lt;td>XDP, tc&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Node&lt;/td>
&lt;td>Node&lt;/td>
&lt;td>ip-xfrm (for encryption), ip tables for initial decapsulation routing (if vxlan), veth-pair, ipvlan&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>以上就是 Kubernetes 的所有网络对象（the only artificial network objects）。什么意思？这就是 k8s CNI 所依赖的全部网络原语（network primitives）。例如，LoadBalancer 对象只是 ClusterIP 和 NodePort 的组合，而后二者都属于 Service 对象，所以他们并不 是一等对象。&lt;/p>
&lt;p>这张图非常有价值，但不幸的是，实际情况要比这里列出的更加复杂，因为 Cilium 本身的 实现是很复杂的。这有两个主要原因，我觉得值得拿出来讨论和体会：&lt;/p>
&lt;p>首先，内核 datapath 要远比我这里讲的复杂。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>前面只是非常简单地介绍了协议栈每个位置（Netfilter、iptables、eBPF、XDP）能执行的动作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这些位置提供的处理能力是不同的。例如&lt;/p>
&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>XDP 可能是能力最受限的，因为它只是设计用来做快速丢包（fast dropping）和 非本地重定向（non-local redirecting）；但另一方面，它又是最快的程序，因为 它在整个 datapath 的最前面，具备对整个 datapath 进行短路处理（short circuit the entire datapath）的能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>tc 和 iptables 程序能方便地 mangle 数据包，而不会对原来的转发流程产生显着影响。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>理解这些东西非常重要，因为这是 Cilium 乃至广义 datapath 里非常核心的东西。如 果遇到底层网络问题，或者需要做 Cilium/kernel 调优，那你必须要理解包的收发 / 转发 路径，有时你会发现包的某些路径非常反直觉。&lt;/p>
&lt;p>第二个原因是，eBPF 还非常新，某些最新特性只有在 5.x 内核中才有。尤其是 XDP BPF， 可能一个节点的内核版本支持，调度到另一台节点时，可能就不支持。&lt;/p>
&lt;p>略，视频见 油管[4]。&lt;/p>
&lt;p>参考资料&lt;/p>
&lt;p>[1]&lt;/p>
&lt;p>Understanding (and Troubleshooting) the eBPF Datapath in Cilium: &lt;a href="https://kccncna19.sched.com/event/Uae7/understanding-and-troubleshooting-the-ebpf-datapath-in-cilium-nathan-sweet-digitalocean">https://kccncna19.sched.com/event/Uae7/understanding-and-troubleshooting-the-ebpf-datapath-in-cilium-nathan-sweet-digitalocean&lt;/a>&lt;/p>
&lt;p>[2]&lt;/p>
&lt;p>“Metrics are money”: &lt;a href="https://kernel-recipes.org/en/2019/metrics-are-money/">https://kernel-recipes.org/en/2019/metrics-are-money/&lt;/a>&lt;/p>
&lt;p>[3]&lt;/p>
&lt;p>Cilium Network Topology and Traffic Path on AWS: &lt;a href="http://arthurchiao.art/blog/cilium-network-topology-on-aws/">http://arthurchiao.art/blog/cilium-network-topology-on-aws/&lt;/a>&lt;/p>
&lt;p>[4]&lt;/p>
&lt;p>油管: &lt;a href="https://www.youtube.com/watch?v=Kmm8Hl57WDU">https://www.youtube.com/watch?v=Kmm8Hl57WDU&lt;/a>&lt;/p></description></item><item><title>Docs: BPF 相关文章</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/</guid><description>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/KnNcM2OaBqOgfVDghaHy8g">[译] 利用 eBPF 支撑大规模 K8S Service&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/ZCprEJi9zrHxRSO1XNRsqQ">为容器时代设计的高级 eBPF 内核特性（FOSDEM, 2021）&lt;/a>&lt;/p></description></item><item><title>Docs: BPF 在网络领域的实现</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E5%9C%A8%E7%BD%91%E7%BB%9C%E9%A2%86%E5%9F%9F%E7%9A%84%E5%AE%9E%E7%8E%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E5%9C%A8%E7%BD%91%E7%BB%9C%E9%A2%86%E5%9F%9F%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考： &lt;a href="http://arthurchiao.art/index.html">arthurchiao.art 的文章&lt;/a>：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://arthurchiao.art/blog/advanced-bpf-kernel-features-for-container-age-zh/">[译] 为容器时代设计的高级 eBPF 内核特性（FOSDEM, 2021)&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h2 id="ebpf-架构">eBPF 架构&lt;a class="td-heading-self-link" href="#ebpf-%e6%9e%b6%e6%9e%84" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/gt3mhv/1617851739655-d700e4b4-2880-4a5f-afbf-182baaba18f3.png" alt="">&lt;/p>
&lt;p>eBPF 能够让你**在内核中****创建新的 DataPath**。eBPF 就是内核本身的代码，想象空间无限，并且热加载到内核；换句话说，一旦加载到内核，内核的行为就变了。在 eBPF 之前，改变内核行为这件事情，只能通过修改内核再重新编译，或者开发内 核模块才能实现。&lt;/p>
&lt;p>由于上述原因，真正的 eBPF，应该是基于 eBPF 实现的数据路径，由于 eBPF 可以修改内核，所以可以在内核创建新的类似 Netfilter 的 Hook 点，以便跳过复杂的 Netfilter。甚至可以直接在网卡驱动中运行 eBPF 代码，而无需将数据包送到复杂的协议栈进行处理。&lt;/p></description></item><item><title>Docs: XDP eBPF 与 TC eBPF</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/XDP-eBPF-%E4%B8%8E-TC-eBPF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/XDP-eBPF-%E4%B8%8E-TC-eBPF/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>参考：&lt;a href="https://en.wikipedia.org/wiki/Express_Data_Path">Wiki&lt;/a>&lt;/p>
&lt;p>&lt;strong>eXpress Data Path(特快数据路径，简称 XDP)&lt;/strong> 是从 4.8 版开始在 Linux 内核中合并的基于 eBPF 的高性能数据路径。[1]&lt;/p>
&lt;p>XDP 背后的想法是在内核的 RX 路径中添加一个早期钩子，然后让用户提供的 eBPF 程序来决定数据包的命运。该挂钩刚好在中断处理之后，在网络堆栈本身需要的任何内存分配之前放置在 NIC 驱动程序中，因为内存分配可能是一项昂贵的操作。由于这种设计，使用商用硬件，XDP 可以每秒每核心丢弃 2 千 6 百万个数据包。[2]&lt;/p>
&lt;p>eBPF 程序在加载之前必须通过预验证器测试[3]，以避免在内核空间中执行恶意代码。预验证器检查程序是否不包含越界访问，循环或全局变量。&lt;/p>
&lt;p>Linux 内核中的数据包流路径。XDP 绕过了网络堆栈和数据包元数据的内存分配。&lt;/p>
&lt;p>允许程序编辑数据包数据，并且在 eBPF 程序返回后，操作代码确定如何处理数据包：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>XDP_PASS&lt;/code>：让数据包继续通过网络堆栈&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>XDP_DROP&lt;/code>：静默丢弃数据包&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>XDP_ABORTED&lt;/code>：丢弃具有跟踪点异常的数据包&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>XDP_TX&lt;/code>：将数据包弹回到达的同一网卡&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>XDP_REDIRECT&lt;/code>：通过 AF_XDP 地址族将数据包重定向到另一个 NIC 或用户空间套接字&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>XDP 需要 NIC 驱动程序的支持，但由于并非所有驱动程序都支持 XDP，因此它可以回退到通用实现，该通用实现在网络堆栈中执行 eBPF 处理，但性能较慢。[4]&lt;/p>
&lt;p>XDP 具有将 eBPF 程序卸载到支持它的 NIC 卡的基础结构，从而减少了 CPU 负载。当时只有 Netronome 卡支持它，[5]由 Intel 和 Mellanox 共同开发。[6]&lt;/p>
&lt;p>AF_XDP [编辑]&lt;/p>
&lt;p>与 XDP 一起，从 4.18 开始在 Linux 内核中输入了一个新的地址族。[7] AF_XDP，以前称为 AF_PACKETv4（从未包含在主线内核中），[8]是针对高性能数据包处理进行了优化的原始套接字，并允许内核与应用程序之间的零复制。由于套接字可用于接收和发送，因此它仅在用户空间中支持高性能网络应用程序。[9]&lt;/p></description></item></channel></rss>