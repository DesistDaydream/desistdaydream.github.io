<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>网络性能优化 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><description>Recent content in 网络性能优化 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><item><title>网络性能优化</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>概述 参考：
一台 Linux 服务器最多能支撑多少个 TCP 连接？ 原文链接: https://mp.weixin.qq.com/s/BwddYkVLSYlkKFNeA-NUVg
困惑很多人的并发问题 在网络开发中，我发现有很多同学对一个基础问题始终是没有彻底搞明白。那就是一台服务器最大究竟能支持多少个网络连接？我想我有必要单独发一篇文章来好好说一下这个问题。
很多同学看到这个问题的第一反应是 65535。原因是：“听说端口号最多有 65535 个，那长连接就最多保持 65535 个了”。是这样的吗？还有的人说：“应该受 TCP 连接里四元组的空间大小限制，算起来是 200 多万亿个！”
如果你对这个问题也是理解的不够彻底，那么今天讲个故事讲给你听！
一次关于服务器端并发的聊天 &amp;ldquo;TCP 连接四元组是源 IP 地址、源端口、目的 IP 地址和目的端口。任意一个元素发生了改变，那么就代表的是一条完全不同的连接了。拿我的 Nginx 举例，它的端口是固定使用 80。另外我的 IP 也是固定的，这样目的 IP 地址、目的端口都是固定的。剩下源 IP 地址、源端口是可变的。所以理论上我的 Nginx 上最多可以建立 2 的 32 次方（ip 数）×2 的 16 次方（port 数）个连接。这是两百多万亿的一个大数字！！&amp;rdquo;
&amp;ldquo;进程每打开一个文件（linux 下一切皆文件，包括 socket），都会消耗一定的内存资源。如果有不怀好心的人启动一个进程来无限的创建和打开新的文件，会让服务器崩溃。所以 linux 系统出于安全角度的考虑，在多个位置都限制了可打开的文件描述符的数量，包括系统级、用户级、进程级。这三个限制的含义和修改方式如下：&amp;rdquo;
系统级：当前系统可打开的最大数量，通过 fs.file-max 参数可修改 用户级：指定用户可打开的最大数量，修改/etc/security/limits.conf 进程级：单个进程可打开的最大数量，通过 fs.nr_open 参数可修改 &amp;ldquo;我的接收缓存区大小是可以配置的，通过 sysctl 命令就可以查看。&amp;rdquo;
$ sysctl -a | grep rmem net.</description></item><item><title>C10K 与 C100K 问题</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/C10K-%E4%B8%8E-C100K-%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/C10K-%E4%B8%8E-C100K-%E9%97%AE%E9%A2%98/</guid><description>你好，我是倪朋飞。
前面内容，我们学习了 Linux 网络的基础原理以及性能观测方法。简单回顾一下，Linux 网络基于 TCP/IP 模型，构建了其网络协议栈，把繁杂的网络功能划分为应用层、传输层、网络层、网络接口层等四个不同的层次，既解决了网络环境中设备异构的问题，也解耦了网络协议的复杂性。
基于 TCP/IP 模型，我们还梳理了 Linux 网络收发流程和相应的性能指标。在应用程序通过套接字接口发送或者接收网络包时，这些网络包都要经过协议栈的逐层处理。我们通常用带宽、吞吐、延迟、PPS 等来衡量网络性能。
今天，我们主要来回顾下经典的 C10K 和 C1000K 问题，以更好理解 Linux 网络的工作原理，并进一步分析，如何做到单机支持 C10M。
注意，C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接 1 万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接 100 万）的问题。
C10K C10K 问题最早由 Dan Kegel 在 1999 年提出。那时的服务器还只是 32 位系统，运行着 Linux 2.2 版本（后来又升级到了 2.4 和 2.6，而 2.6 才支持 x86_64），只配置了很少的内存（2GB）和千兆网卡。
怎么在这样的系统中支持并发 1 万的请求呢？
从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以。所以，物理资源是足够的，接下来自然是软件的问题，特别是网络的 I/O 模型问题。</description></item></channel></rss>