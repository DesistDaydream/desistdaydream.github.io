<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Linux 网络设备 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/</link><description>Recent content in Linux 网络设备 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/index.xml" rel="self" type="application/rss+xml"/><item><title>Linux 网络设备</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/</guid><description>概述 参考：
Linux 内核文档，管理员指南 - ABI -sysfs-class-net Manual(手册)，netdevice(7) 脚注在文末
Linux 网络设备归属于 PCI 总线类型。
关联文件 sysfs 中的网络设备信息 每个网络设备，都会在 sysfs 中注册（主要是与 PCI 相关），有一系列文件用来描述或定义这些网络设备。
在 /sys/class/net/${NetDeviceName}/ 目录下可以找到已在内核注册的关于网络设备的信息
Note: ${NetDeviceName} 是指向 /sys/devices/pciXXX/XXX/.../XXX/${NetDeviceName}/ 的 Symbolic link
./type # 网络设备的类型。文件内容是 10 进制数字。从 if_arp.h1 代码中（stackoverflow 也有相关问题）找到数字对应的设备类型表和该设备的定义（e.g. 1 表示 ARPHRD_ETHER），这个 C 的头文件将网络设备分为如下几大块
ARP 协议硬件定义 # ARP 的 RFC 标准中，定义了这些，并且 IANA2 中也维护了这些注册信息。 比如 #define ARPHRD_ETHER 1 这行代码意味着，type 文件的内容为 1 的话，表示该网络设备是 ARPHRD_ETHER（也就是常见的网卡设备） 非 ARP 硬件的虚拟网络设备 # Linux 自身实现的一些虚拟网络设备 TODO: 其他信息待整理 .</description></item><item><title>Bridge</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bridge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bridge/</guid><description>概述 参考：
在 /sys/class/net/*/ 目录下，如果有 bridge 目录，则说明这是 Bridge 类型的网络设备。
for dev in /sys/class/net/*; do if [ -d &amp;#34;$dev/bridge&amp;#34; ]; then echo &amp;#34;$(basename $dev) is a bridge device&amp;#34; fi done 聊聊 Linux 上软件实现的 “交换机” - Bridge 参考：
原文：聊聊 Linux 上软件实现的 “交换机” - Bridge！ Linux 中的 veth 是一对儿能互相连接、互相通信的虚拟网卡。通过使用它，我们可以让 Docker 容器和母机通信，或者是在两个 Docker 容器中进行交流。参见《轻松理解 Docker 网络虚拟化基础之 veth 设备！》。
不过在实际中，我们会想在一台物理机上我们虚拟出来几个、甚至几十个容器，以求得充分压榨物理机的硬件资源。但这样带来的问题是大量的容器之间的网络互联。很明显上面简单的 veth 互联方案是没有办法直接工作的，我们该怎么办？？？
回头想一下，在物理机的网络环境中，多台不同的物理机之间是如何连接一起互相通信的呢？没错，那就是以太网交换机。同一网络内的多台物理机通过交换机连在一起，然后它们就可以相互通信了。
在我们的网络虚拟化环境里，和物理网络中的交换机一样，也需要这样的一个软件实现的设备。它需要有很多个虚拟端口，能把更多的虚拟网卡连接在一起，通过自己的转发功能让这些虚拟网卡之间可以通信。在 Linux 下这个软件实现交换机的技术就叫做 bridge（再强调下，这是纯软件实现的）。
各个 Docker 容器都通过 veth 连接到 bridge 上，bridge 负责在不同的 “端口” 之间转发数据包。这样各个 Docker 之间就可以互相通信了！</description></item><item><title>TUN and TAP</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/TUN-and-TAP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/TUN-and-TAP/</guid><description>概述 参考：
网络虚拟化技术（二）: TUN/TAP MACVLAN MACVTAP Wiki, TUN/TAP TUN/TAP 类型的设备会利用 /dev/net/tun 文件, 基于 tun.ko 模块实现(TODO).
TUN 设备 TUN 设备是一种虚拟网络设备，通过此设备，程序可以方便地模拟网络行为。TUN 模拟的是一个三层设备,也就是说,通过它可以处理来自网络层的数据，更通俗一点的说，通过它，我们可以处理 IP 数据包。
先来看看物理设备是如何工作的：
上图中的 eth0 表示我们主机已有的真实的网卡接口 (interface)。
网卡接口 eth0 所代表的真实网卡通过网线(wire)和外部网络相连，该物理网卡收到的数据包会经由接口 eth0 传递给内核的网络协议栈(Network Stack)。然后协议栈对这些数据包进行进一步的处理。
对于一些错误的数据包,协议栈可以选择丢弃；对于不属于本机的数据包，协议栈可以选择转发；而对于确实是传递给本机的数据包,而且该数据包确实被上层的应用所需要，协议栈会通过 Socket API 告知上层正在等待的应用程序。
下面看看 TUN 的工作方式：
我们知道，普通的网卡是通过网线来收发数据包的话，而 TUN 设备比较特殊，它通过一个文件收发数据包。
如上图所示，tunX 和上面的 eth0 在逻辑上面是等价的， tunX 也代表了一个网络接口,虽然这个接口是系统通过软件所模拟出来的.
网卡接口 tunX 所代表的虚拟网卡通过文件 /dev/tunX 与我们的应用程序(App) 相连，应用程序每次使用 write 之类的系统调用将数据写入该文件，这些数据会以网络层数据包的形式，通过该虚拟网卡，经由网络接口 tunX 传递给网络协议栈，同时该应用程序也可以通过 read 之类的系统调用，经由文件 /dev/tunX 读取到协议栈向 tunX 传递的所有数据包。
此外，协议栈可以像操纵普通网卡一样来操纵 tunX 所代表的虚拟网卡。比如说，给 tunX 设定 IP 地址，设置路由，总之，在协议栈看来，tunX 所代表的网卡和其他普通的网卡区别不大，当然，硬要说区别，那还是有的,那就是 tunX 设备不存在 MAC 地址，这个很好理解，tunX 只模拟到了网络层，要 MAC 地址没有任何意义。当然，如果是 tapX 的话，在协议栈的眼中，tapX 和真是网卡没有任何区别。</description></item><item><title>Bond 与 Team</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bond-%E4%B8%8E-Team/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bond-%E4%B8%8E-Team/</guid><description>概述 参考：
Wiki, Link Aggregation Wiki, MII Linux 内核文档,Linux 网络文档-Linux 以太网 Bonding 驱动入门指南(这里可以看到所有 Bonding 参数) Linux 基金会 Wiki,网络-bonding 红帽官方的 bond 说明文档：https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/networking_guide/ch-configure_network_bonding https://www.ibm.com/docs/en/linux-on-systems?topic=recommendations-link-monitoring Link Aggregation(链路聚合) 技术就是将多条物理链路聚合成一条带宽更高的逻辑链路，该逻辑链路的带宽等于被聚合在一起的多条物理链路的带宽之和。聚合在一起的物理链路的条数可以根据业务的带宽需求来配置。因此链路聚合具有成本低，配置灵活的优点，此外，链路聚合还具有链路冗余备份的功能，聚合在一起的链路彼此动态备份，提高了网络的稳定性。早期链路聚合技术的实现没有统一的标准，各厂商都有自己私有的解决方案，功能不完全相同，也互不兼容。因此，IEEE 专门制定了链路聚合的标准，目前链路聚合技术的正式标准为 IEEE Standard 802.3ad，而 Link Aggregation Control Protocol(链路汇聚控制协议,LACP) 是该标准的主要内容之一，是一种实现链路动态聚合的协议。
Link Aggregation Control Protocol Link Aggregation Control Protocol(链路汇聚控制协议，简称 LACP) 在 IEEE 以太网标准中，提供了一种方法，可以将多个物理链路捆绑在一起以形成单个逻辑链路。LACP 允许网络设备通过将 LACP 数据包发送到 Peer(对等方) 以 negotiate(协商) 链路状态，并实现自动捆绑。
Peer(对等方) 指的是与本网络设备直连的可以实现 LACP 的对端网络设备 LACP 数据包通常称为 Link Aggregation Control Protocol Data Unit(链路汇聚控制协议数据单元，简称 LACPDU)
Bond，网卡绑定 Bond 类型的网络设备是通过把多个网络设备绑定为一个逻辑网络设备，实现本地网络设备的冗余、带宽扩容和负载均衡。在应用部署中是一种常用的技术。
Linux 中使用 bonding 模块实现 bonding 驱动程序。</description></item></channel></rss>