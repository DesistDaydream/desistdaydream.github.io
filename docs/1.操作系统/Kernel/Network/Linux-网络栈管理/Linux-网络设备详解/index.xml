<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – Linux 网络设备详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/</link><description>Recent content in Linux 网络设备详解 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Bond 与 Team</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/Bond-%E4%B8%8E-Team/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/Bond-%E4%B8%8E-Team/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Link_aggregation">Wiki，Link Aggregation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Media-independent_interface">Wiki，MII&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.kernel.org/doc/html/latest/networking/bonding.html">Linux 内核文档,Linux 网络文档-Linux 以太网 Bonding 驱动入门指南&lt;/a>(这里可以看到所有 Bonding 参数)&lt;/li>
&lt;li>&lt;a href="https://wiki.linuxfoundation.org/networking/bonding">Linux 基金会 Wiki,网络-bonding&lt;/a>&lt;/li>
&lt;li>红帽官方的 bond 说明文档：&lt;a href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/networking_guide/ch-configure_network_bonding">https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/networking_guide/ch-configure_network_bonding&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.ibm.com/docs/en/linux-on-systems?topic=recommendations-link-monitoring">https://www.ibm.com/docs/en/linux-on-systems?topic=recommendations-link-monitoring&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Link Aggregation(链路聚合)&lt;/strong> 技术就是将多条物理链路聚合成一条带宽更高的逻辑链路，该逻辑链路的带宽等于被聚合在一起的多条物理链路的带宽之和。聚合在一起的物理链路的条数可以根据业务的带宽需求来配置。因此链路聚合具有成本低，配置灵活的优点，此外，链路聚合还具有链路冗余备份的功能，聚合在一起的链路彼此动态备份，提高了网络的稳定性。早期链路聚合技术的实现没有统一的标准，各厂商都有自己私有的解决方案，功能不完全相同，也互不兼容。因此，IEEE 专门制定了链路聚合的标准，目前链路聚合技术的正式标准为 IEEE Standard 802.3ad，而 &lt;strong>Link Aggregation Control Protocol(链路汇聚控制协议,LACP)&lt;/strong> 是该标准的主要内容之一，是一种实现链路动态聚合的协议。&lt;/p>
&lt;h2 id="link-aggregation-control-protocol">Link Aggregation Control Protocol&lt;a class="td-heading-self-link" href="#link-aggregation-control-protocol" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;strong>Link Aggregation Control Protocol(链路汇聚控制协议，简称 LACP)&lt;/strong> 在 IEEE 以太网标准中，提供了一种方法，可以将多个物理链路捆绑在一起以形成单个逻辑链路。LACP 允许网络设备通过将 LACP 数据包发送到 &lt;strong>Peer(对等方)&lt;/strong> 以 &lt;strong>negotiate(协商)&lt;/strong> 链路状态，并实现自动捆绑。&lt;/p>
&lt;blockquote>
&lt;p>Peer(对等方) 指的是与本网络设备直连的可以实现 LACP 的对端网络设备
LACP 数据包通常称为 &lt;strong>Link Aggregation Control Protocol Data Unit(链路汇聚控制协议数据单元，简称 LACPDU)&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;h1 id="bond网卡绑定">Bond，网卡绑定&lt;a class="td-heading-self-link" href="#bond%e7%bd%91%e5%8d%a1%e7%bb%91%e5%ae%9a" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Bond 类型的网络设备是通过把多个网络设备绑定为一个逻辑网络设备，实现本地网络设备的冗余、带宽扩容和负载均衡。在应用部署中是一种常用的技术。&lt;/p>
&lt;p>Linux 中使用 bonding 模块实现 bonding 驱动程序。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>lichenhao@hw-cloud-xngy-jump-server-linux-2 ~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>$ modinfo bonding
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>filename: /lib/modules/5.4.0-88-generic/kernel/drivers/net/bonding/bonding.ko
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>author: Thomas Davis, tadavis@lbl.gov and many others
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>description: Ethernet Channel Bonding Driver, v3.7.1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>version: 3.7.1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>license: GPL
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>alias: rtnl-link-bond
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>srcversion: B95AF01257E8C745F584C8F
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>depends:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>retpoline: Y
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>intree: Y
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>name: bonding
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>vermagic: 5.4.0-88-generic SMP mod_unload modversions
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sig_id: PKCS#7
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>signer: Build &lt;span style="color:#204a87">time&lt;/span> autogenerated kernel key
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sig_key: 2D:2D:71:A0:22:44:6D:60:C8:49:CB:0E:D7:43:D0:D2:7A:5C:0E:F1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sig_hashalgo: sha512
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>signature: AE:16:69:2D:17:C0:36:10:F4:52:73:EB:A4:CB:CB:FC:68:78:DE:3A:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: max_bonds:Max number of bonded devices &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: tx_queues:Max number of transmit queues &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>&lt;span style="color:#000">default&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> 16&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: num_grat_arp:Number of peer notifications to send on failover event &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87">alias&lt;/span> of num_unsol_na&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: num_unsol_na:Number of peer notifications to send on failover event &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87">alias&lt;/span> of num_grat_arp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: miimon:Link check interval in milliseconds &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: updelay:Delay before considering link up, in milliseconds &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: downdelay:Delay before considering link down, in milliseconds &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: use_carrier:Use netif_carrier_ok &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>vs MII ioctls&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> in miimon&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> off, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> on &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: mode:Mode of operation&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> balance-rr, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> active-backup, &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> balance-xor, &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> broadcast, &lt;span style="color:#0000cf;font-weight:bold">4&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> 802.3ad, &lt;span style="color:#0000cf;font-weight:bold">5&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> balance-tlb, &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> balance-alb &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: primary:Primary network device to use &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: primary_reselect:Reselect primary slave once it comes up&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> always &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> only &lt;span style="color:#204a87;font-weight:bold">if&lt;/span> speed of primary is better, &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> only on active slave failure &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: lacp_rate:LACPDU tx rate to request from 802.3ad partner&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> slow, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> fast &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: ad_select:802.3ad aggregation selection logic&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> stable &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> bandwidth, &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> count &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: min_links:Minimum number of available links before turning on carrier &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: xmit_hash_policy:balance-alb, balance-tlb, balance-xor, 802.3ad hashing method&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> layer &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> layer 3+4, &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> layer 2+3, &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> encap layer 2+3, &lt;span style="color:#0000cf;font-weight:bold">4&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> encap layer 3+4 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: arp_interval:arp interval in milliseconds &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: arp_ip_target:arp targets in n.n.n.n form &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>array of charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: arp_validate:validate src/dst of ARP probes&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> none &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> active, &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> backup, &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> all &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: arp_all_targets:fail on any/all arp targets timeout&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> any &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> all &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: fail_over_mac:For active-backup, &lt;span style="color:#204a87;font-weight:bold">do&lt;/span> not &lt;span style="color:#204a87">set&lt;/span> all slaves to the same MAC&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> none &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> active, &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> follow &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>charp&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: all_slaves_active:Keep all frames received on an interface by setting active flag &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> all slaves&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> never &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> always. &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: resend_igmp:Number of IGMP membership reports to send on link failure &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: packets_per_slave:Packets to send per slave in balance-rr mode&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> a random slave, &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> packet per slave &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>default&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>, &amp;gt;1 packets per slave. &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>int&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parm: lp_interval:The number of seconds between instances where the bonding driver sends learning packets to each slaves peer switch. The default is 1. &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>uint&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="bond-参数">Bond 参数&lt;a class="td-heading-self-link" href="#bond-%e5%8f%82%e6%95%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="arp-监控参数">ARP 监控参数&lt;a class="td-heading-self-link" href="#arp-%e7%9b%91%e6%8e%a7%e5%8f%82%e6%95%b0" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>ARP 监控参数与 MII 监控参数不可同时使用&lt;/p>
&lt;p>&lt;strong>arp_interval&lt;/strong> # ARP 监控模式的监控频率，单位 毫秒。&lt;code>默认值：0&lt;/code>。0 值表示禁用 ARP 监控
&lt;strong>arp_ip_target&lt;/strong> #&lt;/p>
&lt;h2 id="mii-监控参数">MII 监控参数&lt;a class="td-heading-self-link" href="#mii-%e7%9b%91%e6%8e%a7%e5%8f%82%e6%95%b0" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;strong>Media Independent Interface(介质无关接口，简称 MII)&lt;/strong>，通过该接口可以检测聚合链路的状态，当某个网络设备故障时，bonding 驱动会将这个故障设备标记为关闭。虽然不会将设备踢出聚合组，但是数据不在通过故障设备传输&lt;/p>
&lt;p>MII 监控参数与 ARP 监控参数不可同时使用&lt;/p>
&lt;p>&lt;strong>miimon&lt;/strong> # MII 监控模式的监控频率，单位 毫秒。这决定了每个备链路状态的故障检查频率。&lt;code>默认值：0&lt;/code>。0 值表示禁用 MII 链路监控&lt;/p>
&lt;ul>
&lt;li>通常设置为 100&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>use_carrier&lt;/strong> # 指定 miimon 是否应使用 MII 或 ETHTOOL ioctls 与 netif_carrier_ok() 来确定链接状态。 默认值是 1，这使得可以使用 netif_carrier_ok（）。 这由 Linux on Z 上的 qeth 设备驱动程序支持。&lt;/p>
&lt;p>&lt;strong>downdelay&lt;/strong># 检测到网络设备故障后，持续 downdelay 毫秒后，关闭该设备。&lt;/p>
&lt;p>&lt;strong>updelay&lt;/strong> # 检测到网络设备恢复后，持续 updelay 毫秒后，启用该设备&lt;/p>
&lt;h2 id="bond-模式参数">Bond 模式参数&lt;a class="td-heading-self-link" href="#bond-%e6%a8%a1%e5%bc%8f%e5%8f%82%e6%95%b0" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;strong>mode&lt;/strong> # 指定 bonding 策略。&lt;code>默认值：balance-rr&lt;/code>。常见的 bond 模式有七种：括号中是该模式所对应的数字，使用 nmcli 命令时，不要使用数字代替，NetworkManager 无法识别数字。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>balance-rr(0)&lt;/strong> # 表示负载分担 round-robin，和交换机的聚合强制不协商的方式配合。&lt;/li>
&lt;li>&lt;strong>active-backup(1)&lt;/strong> # 表示主备模式，只有一块网卡是 active,另外一块是备的 standby，这时如果交换机配的是捆绑，将不能正常工作，因为交换机往两块网卡发包，有一半包是丢弃的。
&lt;ul>
&lt;li>注意：vmwork 的虚拟机中只能做 mode=1 的实验，其它的工作模式得用真机来实践，并且需要添加额外参数(fail_over_mac=1)才能实现主备模式&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>balance-xor(2)&lt;/strong> # 表示 XOR Hash 负载分担，和交换机的聚合强制不协商方式配合(需要 xmit_hash_policy)
&lt;ul>
&lt;li>推荐 bond 参数：mode=balance-xor,miimon=100,xmit_hash_policy=layer3+4&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>broadcast(3)&lt;/strong> # 表示所有包从所有 interface 发出，这个不均衡，只有冗余机制&amp;hellip;和交换机的聚合强制不协商方式配合。&lt;/li>
&lt;li>&lt;strong>802.3ad(4)&lt;/strong> # 表示支持 802.3ad 协议，动态链路聚合，需要和交换机的聚合 LACP 方式配合(需要 xmit_hash_policy)
&lt;ul>
&lt;li>推荐 bond 参数：mode=802.3ad,miimon=100,lacp_rate=1,xmit_hash_policy=layer3+4&lt;/li>
&lt;li>802.3ad 模式的 Bond 网络设备的最大带宽是所有 Slave 设备最大带宽之和&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>balance-tlb(5)&lt;/strong> # 是根据每个 slave 的负载情况选择 slave 进行发送，接收时使用当前轮到的 slave&lt;/li>
&lt;li>&lt;strong>balance-alb(6)&lt;/strong> # 在 5 的 tlb 基础上增加了 rlb。Adaptive Load Balancing(简称 ALB) 协议，可以根据网络状态和物理网卡的带宽来动态地将数据包分配到每个物理网卡上。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>注意：&lt;/p>
&lt;ul>
&lt;li>active-backup、balance-tlb 和 balance-alb 模式不需要交换机的任何特殊配置。其他绑定模式需要配置交换机以便整合链接。例如：Cisco 交换机需要在模式 0、2 和 3 中使用 EtherChannel，但在模式 4 中需要 LACP 和 EtherChannel。有关交换机附带文档，请查看 &lt;a href="https://www.kernel.org/doc/Documentation/networking/bonding.txt">https://www.kernel.org/doc/Documentation/networking/bonding.txt&lt;/a>。&lt;/li>
&lt;li>若想 bond 功能生效，关闭 NetworkManager 服务 或者 在配置文件中的 BONDING_OPTS 中 MODE 的值不要用数字，而是直接使用模式名称来作为值&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>每种模式的理论最大带宽：&lt;/p>
&lt;ul>
&lt;li>0 和 2 模式是所有网络设备的带宽之和&lt;/li>
&lt;li>1 和 3 模式是单个网络设备的带宽&lt;/li>
&lt;li>4 模式也是带宽之和，但是会动态分配，有时候最大值可能会超过带宽之和的上限&lt;/li>
&lt;li>5 和 6 与 4 类似，都是带宽之和，且可能超过上限。&lt;/li>
&lt;/ul>
&lt;h2 id="其他参数">其他参数&lt;a class="td-heading-self-link" href="#%e5%85%b6%e4%bb%96%e5%8f%82%e6%95%b0" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;strong>lacp_rate&lt;/strong> # 作用于 802.3ad 模式。向聚合链路的对端(通常来说都是交换机)传输&lt;strong>LACPDU&lt;/strong> 包的速率。可用的值有如下几个：&lt;/p>
&lt;ul>
&lt;li>slow # 每 30 秒传输一次 LACPDU，即每 30 秒协商一次&lt;/li>
&lt;li>fast # 每秒传输一次 LACPDU，即每秒协商一次&lt;/li>
&lt;li>max_bonds # 指定要为此绑定驱动程序实例创建的绑定设备数。例如，如果 max_bonds 为 3，并且绑定驱动程序尚未加载，则将创建 bond0、bond1 和 bond2。默认值为 1&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>xmit_hash_policy&lt;/strong> # 作用于 balance-xor 和 802.3ad 模式。配置传输 hash 策略。&lt;code>默认值：layer2&lt;/code>。&lt;/p>
&lt;ul>
&lt;li>layer2 # 该策略支持 802.3ad。使用 XOR 或硬件 MAC 地址生成 hash。&lt;/li>
&lt;li>layer2+3 # 该策略支持 802.3ad。使用 XOR 或硬件 MAC 地址与 IP 地址一起生成 hash。&lt;/li>
&lt;li>layer3+4 # 该策略不完全支持 802.3ad&lt;/li>
&lt;li>说明：
&lt;ul>
&lt;li>这里面的 2，3，4 其实就是指的 ISO 模型里的层，2 层就是用 MAC 进行计算，2+3 就是用 MAC 加 IP 进行计算，3+4 就是用 IP 加 PORT 进行计算。&lt;/li>
&lt;li>只使用 2 层的 MAC 进行计算时，会导致同一个网关的数据流将完全从一个端口发送，但是如果使用 2+3 或 3+4，虽然负载更均衡了，但是由于使用了上层协议进行计算，则增加了 hash 的开销。&lt;/li>
&lt;li>计算越负责，负载均衡效果越好，但是资源开销越大。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="bond-关联文件与配置">Bond 关联文件与配置&lt;a class="td-heading-self-link" href="#bond-%e5%85%b3%e8%81%94%e6%96%87%e4%bb%b6%e4%b8%8e%e9%85%8d%e7%bd%ae" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>/sys/class/net/BondName/&lt;/strong> # Bond 类型网络设备的运行时信息，这里面某些信息是可以被修改的。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>./statistics/&lt;/strong> # 网络设备的状态信息，比如 发送/接受 了多少数据包、多少数据量 等等，&lt;code>ip -s&lt;/code> 参数可以从这里获取到信息&lt;/li>
&lt;li>&lt;strong>./bonding/&lt;/strong> # Bond 参数&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>/proc/net/bonding/&lt;/strong> # bond 运行时状态信息保存路径。其内文件名为 Bond 的名称。查看文件内容解析详见&lt;a href="#Bond%20%E5%9C%A8%E5%86%85%E6%A0%B8%E4%B8%AD%E7%9A%84%E4%BF%A1%E6%81%AF%E8%A7%A3%E6%9E%90">《Bond 在内核中的信息解析》&lt;/a>部分&lt;/p>
&lt;h2 id="bond-基本配置文件详解">Bond 基本配置文件详解&lt;a class="td-heading-self-link" href="#bond-%e5%9f%ba%e6%9c%ac%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6%e8%af%a6%e8%a7%a3" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>首先是配置一个 bond 网络设备，IP 等相关信息配置在 bond 网络设备上。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># cat /etc/sysconfig/network-scripts/ifcfg-bond0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">BONDING_OPTS&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;mode=balance-rr&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">TYPE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>Bond
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">BONDING_MASTER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">BOOTPROTO&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>dhcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">DEFROUTE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>bond0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">DEVICE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>bond0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">ONBOOT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其次配置让一个物理网络设备绑定到该 bond 设备上&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># cat /etc/sysconfig/network-scripts/ifcfg-bond-slave-em1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">TYPE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>Ethernet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>bond-slave-em1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">DEVICE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>em1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">ONBOOT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">MASTER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>bond0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">SLAVE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="bond-在内核中的信息解析">Bond 在内核中的信息解析&lt;a class="td-heading-self-link" href="#bond-%e5%9c%a8%e5%86%85%e6%a0%b8%e4%b8%ad%e7%9a%84%e4%bf%a1%e6%81%af%e8%a7%a3%e6%9e%90" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>/proc/net/bonding/BondNAME&lt;/strong> # 文件中保存了当前系统中已启动的 Bond 类型的网络设备的信息
这些信息分为多个部分&lt;/p>
&lt;ul>
&lt;li>Bond 类型的网络设备通用信息&lt;/li>
&lt;li>Bond 类型的网络设备特定信息，比如 802.3ad 类型的 Bond 就有独自的信息&lt;/li>
&lt;li>Bond 下 Slave 网络设备通用信息&lt;/li>
&lt;/ul>
&lt;h2 id="balance-rr">balance-rr&lt;a class="td-heading-self-link" href="#balance-rr" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>Bonding Mode: load balancing &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>round-robin&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Polling Interval &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Up Delay &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Down Delay &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave Interface: enp6s0f0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Speed: &lt;span style="color:#0000cf;font-weight:bold">10000&lt;/span> Mbps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Duplex: full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Link Failure Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Permanent HW addr: 40:a6:b7:25:f2:3c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave queue ID: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave Interface: enp6s0f1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Speed: &lt;span style="color:#0000cf;font-weight:bold">10000&lt;/span> Mbps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Duplex: full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Link Failure Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Permanent HW addr: 40:a6:b7:25:f2:3d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave queue ID: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Bond 设备&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Bonding Mode&lt;/strong> # Bond 模式的名称&lt;/li>
&lt;li>&lt;strong>MII Status&lt;/strong> # 链路监控状态&lt;/li>
&lt;li>&lt;strong>MII Polling Interval&lt;/strong> #&lt;/li>
&lt;li>&lt;strong>Up Delay&lt;/strong> # 检测到 Slave 网络设备恢复后，持续 updelay 毫秒后，启用 Slave 设备&lt;/li>
&lt;li>&lt;strong>Down Delay&lt;/strong> # 检测到 Slave 网络设备故障后，持续 downdelay 毫秒后，关闭 Slave 设备。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Slave 设备&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Slave Interface&lt;/strong> # 与 Bond 设备关联的 Slave 网络设备的名称&lt;/li>
&lt;li>&lt;strong>MII Status&lt;/strong> # 链路监控状态&lt;/li>
&lt;li>&lt;strong>Speed&lt;/strong># 最大传输速度，即网卡的带宽&lt;/li>
&lt;li>&lt;strong>Duplex&lt;/strong> # 双工模式&lt;/li>
&lt;li>&lt;strong>Link Failure Count&lt;/strong> # 失联总次数&lt;/li>
&lt;li>&lt;strong>Permanent HW addr&lt;/strong> # 关联的物理网卡的硬件地址，即网卡的 MAC 地址&lt;/li>
&lt;li>&lt;strong>Slave queue ID&lt;/strong> # 队列 ID&lt;/li>
&lt;/ul>
&lt;h2 id="balance-xor">balance-xor&lt;a class="td-heading-self-link" href="#balance-xor" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># cat /proc/net/bonding/bond0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Ethernet Channel Bonding Driver: v3.7.1 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>April 27, 2011&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Bonding Mode: load balancing &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>xor&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#8f5902;font-style:italic"># 此 bond 的模式&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Transmit Hash Policy: layer3+4 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>1&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#8f5902;font-style:italic"># 此 bond 模式的参数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Polling Interval &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Up Delay &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Down Delay &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Peer Notification Delay &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave Interface: eno1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Speed: &lt;span style="color:#0000cf;font-weight:bold">1000&lt;/span> Mbps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Duplex: full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Link Failure Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Permanent HW addr: f0:d4:e2:ea:28:54
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave queue ID: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave Interface: eno2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Speed: &lt;span style="color:#0000cf;font-weight:bold">1000&lt;/span> Mbps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Duplex: full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Link Failure Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Permanent HW addr: f0:d4:e2:ea:28:55
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave queue ID: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="8023ad">802.3ad&lt;a class="td-heading-self-link" href="#8023ad" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;ul>
&lt;li>&lt;a href="https://stackoverflow.com/questions/62173444/churn-state-meaning-in-lacp-bonding">StackOverflow,bonding LACP 模式下 Churn 的含义&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mlog.club/article/2693580">https://mlog.club/article/2693580&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1295423">https://bugzilla.redhat.com/show_bug.cgi?id=1295423&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=ea53abfab960909d622ca37bcfb8e1c5378d21cc">https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=ea53abfab960909d622ca37bcfb8e1c5378d21cc&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://access.redhat.com/solutions/4122011">https://access.redhat.com/solutions/4122011&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/systemd/systemd/issues/15208">https://github.com/systemd/systemd/issues/15208&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># cat /proc/net/bonding/bond1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Ethernet Channel Bonding Driver: v3.7.1 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>April 27, 2011&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Bonding Mode: IEEE 802.3ad Dynamic link aggregation
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Transmit Hash Policy: layer3+4 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>1&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Polling Interval &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Up Delay &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Down Delay &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>802.3ad info
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LACP rate: slow
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Min links: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Aggregator selection policy &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ad_select&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>: stable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>System priority: &lt;span style="color:#0000cf;font-weight:bold">65535&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>System MAC address: 32:1c:0d:e9:ca:e9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Active Aggregator Info:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Aggregator ID: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Number of ports: &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Actor Key: &lt;span style="color:#0000cf;font-weight:bold">15&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Partner Key: &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Partner Mac Address: 00:00:00:00:00:06
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave Interface: enp6s0f0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Speed: &lt;span style="color:#0000cf;font-weight:bold">10000&lt;/span> Mbps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Duplex: full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Link Failure Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Permanent HW addr: 40:a6:b7:26:60:b4
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave queue ID: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Aggregator ID: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Actor Churn State: none
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Partner Churn State: none
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Actor Churned Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Partner Churned Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>details actor lacp pdu:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system priority: &lt;span style="color:#0000cf;font-weight:bold">65535&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system mac address: 32:1c:0d:e9:ca:e9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port key: &lt;span style="color:#0000cf;font-weight:bold">15&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port priority: &lt;span style="color:#0000cf;font-weight:bold">255&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port number: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port state: &lt;span style="color:#0000cf;font-weight:bold">61&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>details partner lacp pdu:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system priority: &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system mac address: 00:00:00:00:00:06
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> oper key: &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port priority: &lt;span style="color:#0000cf;font-weight:bold">32768&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port number: &lt;span style="color:#0000cf;font-weight:bold">33862&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port state: &lt;span style="color:#0000cf;font-weight:bold">63&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave Interface: enp6s0f1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>MII Status: up
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Speed: &lt;span style="color:#0000cf;font-weight:bold">10000&lt;/span> Mbps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Duplex: full
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Link Failure Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Permanent HW addr: 40:a6:b7:26:60:b5
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Slave queue ID: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Aggregator ID: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Actor Churn State: none
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Partner Churn State: none
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Actor Churned Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Partner Churned Count: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>details actor lacp pdu:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system priority: &lt;span style="color:#0000cf;font-weight:bold">65535&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system mac address: 32:1c:0d:e9:ca:e9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port key: &lt;span style="color:#0000cf;font-weight:bold">15&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port priority: &lt;span style="color:#0000cf;font-weight:bold">255&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port number: &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port state: &lt;span style="color:#0000cf;font-weight:bold">61&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>details partner lacp pdu:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system priority: &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> system mac address: 00:00:00:00:00:06
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> oper key: &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port priority: &lt;span style="color:#0000cf;font-weight:bold">32768&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port number: &lt;span style="color:#0000cf;font-weight:bold">33862&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port state: &lt;span style="color:#0000cf;font-weight:bold">63&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>802.3ad 模式的 Bond 需要与交换机交互 LACP 信息，这里对 服务器 和 交换机 的称呼如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Actor&lt;/strong> # 指主机，即服务器&lt;/li>
&lt;li>&lt;strong>Partner&lt;/strong> # 指交换机&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Aggregator ID&lt;/strong> #
&lt;strong>Actor Churn State 与 Partner Churn State&lt;/strong> # 务器与交换机的 Churn 状态&lt;/p>
&lt;ul>
&lt;li>Churn State # Churn 状态共有三种，先是 monitoring，然后是 churned，最后 none 就正常了。
&lt;ul>
&lt;li>monitoring # 等待其他 PDUs 达成共识
&lt;ul>
&lt;li>The bond slave interface is in the process of the initial LACP communication with the LACP peer.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>churned # 扰动、流逝
&lt;ul>
&lt;li>One of the peer&amp;rsquo;s LACP (etherchannel) interfaces is suspended or is otherwise no longer active as an LACP interface&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>none # 链路已同步&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Actor Churned Count 与 Partner Churned Count&lt;/strong> #
&lt;strong>details actor lacp pdu 与 details partner lacp pdu&lt;/strong> # 服务器与交换机的 LACPDU 信息细节&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ggzysy/1644663197947-87aaf3c3-d762-4682-8747-059014f1a7bc.png" alt="image.png">&lt;/p>
&lt;h1 id="team类似于-bond比-bond-更优秀">Team，类似于 Bond，比 Bond 更优秀&lt;a class="td-heading-self-link" href="#team%e7%b1%bb%e4%bc%bc%e4%ba%8e-bond%e6%af%94-bond-%e6%9b%b4%e4%bc%98%e7%a7%80" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="rhel7-中网卡绑定-team-和-bond-的区别">RHEL7 中网卡绑定 team 和 bond 的区别&lt;a class="td-heading-self-link" href="#rhel7-%e4%b8%ad%e7%bd%91%e5%8d%a1%e7%bb%91%e5%ae%9a-team-%e5%92%8c-bond-%e7%9a%84%e5%8c%ba%e5%88%ab" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>red hat 官方给出的 team 和 bond 特性对比&lt;/p>
&lt;p>A Comparison of Features in Bonding and Team&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Feature&lt;/td>
&lt;td>Bonding&lt;/td>
&lt;td>Team&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>broadcast Tx policy&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>round-robin Tx policy&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>active-backup Tx policy&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LACP (802.3ad) support&lt;/td>
&lt;td>Yes (active only)&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Hash-based Tx policy&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>User can set hash function&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tx load-balancing support (TLB)&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>LACP hash port select&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>load-balancing for LACP support&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ethtool link monitoring&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ARP link monitoring&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NS/NA (IPv6) link monitoring&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ports up/down delays&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>port priorities and stickiness (“primary”option enhancement)&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>separate per-port link monitoring setup&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>multiple link monitoring setup&lt;/td>
&lt;td>Limited&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>lockless Tx/Rx path&lt;/td>
&lt;td>No (rwlock)&lt;/td>
&lt;td>Yes (RCU)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VLAN support&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>user-space runtime control&lt;/td>
&lt;td>Limited&lt;/td>
&lt;td>Full&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Logic in user-space&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Extensibility&lt;/td>
&lt;td>Hard&lt;/td>
&lt;td>Easy&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Modular design&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Performance overhead&lt;/td>
&lt;td>Low&lt;/td>
&lt;td>Very Low&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>D-Bus interface&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>multiple device stacking&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>zero config using LLDP&lt;/td>
&lt;td>No&lt;/td>
&lt;td>(in planning)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NetworkManager support&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Docs: Bridge</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/Bridge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/Bridge/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>原文链接：&lt;a href="https://mp.weixin.qq.com/s/JnKz1fUgZmGdvfxOm2ehZg">聊聊 Linux 上软件实现的 “交换机” - Bridge！&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>大家好，我是飞哥！&lt;/p>
&lt;p>Linux 中的 veth 是一对儿能互相连接、互相通信的虚拟网卡。通过使用它，我们可以让 Docker 容器和母机通信，或者是在两个 Docker 容器中进行交流。参见&lt;a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;amp;mid=2247486424&amp;amp;idx=1&amp;amp;sn=d66fe4ebf1cd9e5079606f71a0169697&amp;amp;scene=21#wechat_redirect">《轻松理解 Docker 网络虚拟化基础之 veth 设备！》&lt;/a>。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>不过在实际中，我们会想在一台物理机上我们虚拟出来几个、甚至几十个容器，以求得充分压榨物理机的硬件资源。但这样带来的问题是大量的容器之间的网络互联。很明显上面简单的 veth 互联方案是没有办法直接工作的，我们该怎么办？？？&lt;/p>
&lt;p>回头想一下，在物理机的网络环境中，多台不同的物理机之间是如何连接一起互相通信的呢？没错，那就是以太网交换机。同一网络内的多台物理机通过交换机连在一起，然后它们就可以相互通信了。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>在我们的网络虚拟化环境里，和物理网络中的交换机一样，也需要这样的一个软件实现的设备。它需要有很多个虚拟端口，能把更多的虚拟网卡连接在一起，通过自己的转发功能让这些虚拟网卡之间可以通信。在 Linux 下这个软件实现交换机的技术就叫做 bridge（再强调下，这是纯软件实现的）。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>各个 Docker 容器都通过 veth 连接到 bridge 上，bridge 负责在不同的 “端口” 之间转发数据包。这样各个 Docker 之间就可以互相通信了！&lt;/p>
&lt;p>今天我们来展开聊聊 bridge 的详细工作过程。&lt;/p>
&lt;h2 id="一如何使用-bridge">一、如何使用 bridge&lt;a class="td-heading-self-link" href="#%e4%b8%80%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8-bridge" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在分析它的工作原理之前，很有必要先来看一看网桥是如何使用的。&lt;/p>
&lt;p>为了方便大家理解，接下来我们通过动手实践的方式，在一台 Linux 上创建一个小型的虚拟网络出来，并让它们之间互相通信。&lt;/p>
&lt;h3 id="11-创建两个不同的网络">1.1 创建两个不同的网络&lt;a class="td-heading-self-link" href="#11-%e5%88%9b%e5%bb%ba%e4%b8%a4%e4%b8%aa%e4%b8%8d%e5%90%8c%e7%9a%84%e7%bd%91%e7%bb%9c" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Bridge 是用来连接两个不同的虚拟网络的，所以在准备实验 bridge 之前我们得先需要用 net namespace 构建出两个不同的网络空间来。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>具体的创建过程如下。我们通过 ip netns 命令创建 net namespace。首先创建一个 net1：&lt;/p>
&lt;p>&lt;code># ip netns add net1&lt;/code>&lt;/p>
&lt;p>接下来创建一对儿 veth 出来，设备名分别是 veth1 和 veth1_p。并把其中的一头 veth1 放到这个新的 netns 中。&lt;/p>
&lt;p>&lt;code># ip link add veth1 type veth peer name veth1_p # ip link set veth1 netns net1&lt;/code>&lt;/p>
&lt;p>因为我们打算是用这个 veth1 来通信，所以需要为其配置上 ip，并把它启动起来。&lt;/p>
&lt;p>&lt;code># ip netns exec net1 ip addr add 192.168.0.101/24 dev veth1 # ip netns exec net1 ip link set veth1 up&lt;/code>&lt;/p>
&lt;p>查看一下，上述的配置是否成功。&lt;/p>
&lt;p>&lt;code># ip netns exec net1 ip link list # ip netns exec net1 ifconfig&lt;/code>&lt;/p>
&lt;p>重复上述步骤，在创建一个新的 netns 出来，命名分别为。&lt;/p>
&lt;ul>
&lt;li>netns: net2&lt;/li>
&lt;li>veth pair: veth2, veth2_p&lt;/li>
&lt;li>ip: 192.168.0.102&lt;/li>
&lt;/ul>
&lt;p>好了，这样我们就在一台 Linux 就创建出来了两个虚拟的网络环境。&lt;/p>
&lt;h3 id="12-把两个网络连接到一起">1.2 把两个网络连接到一起&lt;a class="td-heading-self-link" href="#12-%e6%8a%8a%e4%b8%a4%e4%b8%aa%e7%bd%91%e7%bb%9c%e8%bf%9e%e6%8e%a5%e5%88%b0%e4%b8%80%e8%b5%b7" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>在上一个步骤中，我们只是创建出来了两个独立的网络环境而已。这个时候这两个环境之间还不能互相通信。我们需要创建一个虚拟交换机 - bridge， 来把这两个网络环境连起来。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>创建过程如下。创建一个 bridge 设备, 把刚刚创建的两对儿 veth 中剩下的两头 “插” 到 bridge 上来。&lt;/p>
&lt;p>&lt;code># brctl addbr br0 # ip link set dev veth1_p master br0 # ip link set dev veth2_p master br0 # ip addr add 192.168.0.100/24 dev br0&lt;/code>&lt;/p>
&lt;p>再为 bridge 配置上 IP，并把 bridge 以及插在其上的 veth 启动起来。&lt;/p>
&lt;p>&lt;code># ip link set veth1_p up # ip link set veth2_p up # ip link set br0 up&lt;/code>&lt;/p>
&lt;p>查看一下当前 bridge 的状态，确认刚刚的操作是成功了的。&lt;/p>
&lt;p>&lt;code># brctl show bridge name     bridge id               STP enabled     interfaces br0             8000.4e931ecf02b1       no              veth1_p                                                         veth2_p&lt;/code>&lt;/p>
&lt;h3 id="13-网络连通测试">1.3 网络连通测试&lt;a class="td-heading-self-link" href="#13-%e7%bd%91%e7%bb%9c%e8%bf%9e%e9%80%9a%e6%b5%8b%e8%af%95" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>激动人心的时刻就要到了，我们在 net1 里（通过指定 ip netns exec net1 以及 -I veth1），ping 一下 net2 里的 IP（192.168.0.102）试试。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;pre>&lt;code># ip netns exec net1 ping 192.168.0.102 -I veth1PING 192.168.0.102 (192.168.0.102) from 192.168.0.101 veth1: 56(84) bytes of data.64 bytes from 192.168.0.102: icmp_seq=1 ttl=64 time=0.037 ms64 bytes from 192.168.0.102: icmp_seq=2 ttl=64 time=0.008 ms64 bytes from 192.168.0.102: icmp_seq=3 ttl=64 time=0.005 ms
&lt;/code>&lt;/pre>
&lt;p>哇塞，通了通了！！&lt;/p>
&lt;p>这样，我们就在一台 Linux 上虚拟出了 net1 和 net2 两个不同的网络环境。我们还可以按照这种方式创建更多的网络，都可以通过一个 bridge 连接到一起。这就是 Docker 中网络系统工作的基本原理。&lt;/p>
&lt;h2 id="二bridge-是如何创建出来的">二、Bridge 是如何创建出来的&lt;a class="td-heading-self-link" href="#%e4%ba%8cbridge-%e6%98%af%e5%a6%82%e4%bd%95%e5%88%9b%e5%bb%ba%e5%87%ba%e6%9d%a5%e7%9a%84" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在内核中，bridge 是由两个相邻存储的内核对象来表示的。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>我们先看下它是如何被创建出来的。内核中创建 bridge 的关键代码在 br_add_bridge 这个函数里。&lt;/p>
&lt;p>`//file:net/bridge/br_if.c
int br_add_bridge(struct net _net, const char _name)
{
 // 申请网桥设备，并用  br_dev_setup  来启动它
 dev = alloc_netdev(sizeof(struct net_bridge), name,
      br_dev_setup);&lt;/p>
&lt;p>dev_net_set(dev, net);
 dev-&amp;gt;rtnl_link_ops = &amp;amp;br_link_ops;&lt;/p>
&lt;p>// 注册网桥设备
 res = register_netdev(dev);
 if (res)
  free_netdev(dev);
 return res;
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>上述代码中注册网桥的关键代码是 alloc_netdev 这一行。在这个函数里，将申请网桥的内核对象 net_device。在这个函数调用里要注意两点。&lt;/p>
&lt;ul>
&lt;li>
&lt;ol>
&lt;li>第一个参数传入了 struct net_bridge 的大小&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;ol start="2">
&lt;li>第三个参数传入的 br_dev_setup 是一个函数。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>带着这两点注意事项，我们进入到 alloc_netdev 的实现中。&lt;/p>
&lt;p>&lt;code>//file: include/linux/netdevice.h #define alloc_netdev(sizeof_priv, name, setup) \  alloc_netdev_mqs(sizeof_priv, name, setup, 1, 1)&lt;/code>&lt;/p>
&lt;p>好吧，竟然是个宏。那就得看 alloc_netdev_mqs 了。&lt;/p>
&lt;p>`//file: net/core/dev.c
struct net_device _alloc_netdev_mqs(int sizeof_priv, &amp;hellip;，void (_setup)(struct net_device *))
{
 // 申请网桥设备
 alloc_size = sizeof(struct net_device);
 if (sizeof_priv) {
  alloc_size = ALIGN(alloc_size, NETDEV_ALIGN);
  alloc_size += sizeof_priv;
 }&lt;/p>
&lt;p>p = kzalloc(alloc_size, GFP_KERNEL);
 dev = PTR_ALIGN(p, NETDEV_ALIGN);&lt;/p>
&lt;p>// 网桥设备初始化
 dev-&amp;gt;&amp;hellip; = &amp;hellip;;
 setup(dev); //setup 是一个函数指针，实际使用的是  br_dev_setup&lt;/p>
&lt;p>&amp;hellip;
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>在上述代码中。kzalloc 是用来在内核态申请内核内存的。需要注意的是，申请的内存大小是一个 struct net_device 再加上一个 struct net_bridge（第一个参数传进来的）。一次性就申请了两个内核对象，这说明&lt;strong>bridge 在内核中是由两个内核数据结构来表示的，分别是 struct net_device 和 struct net_bridge。&lt;/strong>&lt;/p>
&lt;p>申请完了一家紧接着调用 setup，这实际是外部传入的 br_dev_setup 函数。在这个函数内部进行进一步的初始化。&lt;/p>
&lt;p>&lt;code>//file: net/bridge/br_device.c void br_dev_setup(struct net_device *dev) {  struct net_bridge *br = netdev_priv(dev);  dev-&amp;gt;... = ...;  br-&amp;gt;... = ...;  ... }&lt;/code>&lt;/p>
&lt;p>&lt;strong>总之，brctl addbr br0 命令主要就是完成了 bridge 内核对象（struct net_device 和 struct net_bridge）的申请以及初始化。&lt;/strong>&lt;/p>
&lt;h2 id="三添加设备">三、添加设备&lt;a class="td-heading-self-link" href="#%e4%b8%89%e6%b7%bb%e5%8a%a0%e8%ae%be%e5%a4%87" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>调用 &lt;code>brctl addif br0 veth0&lt;/code> 给网桥添加设备的时候，会将 veth 设备以虚拟的方式连到网桥上。当添加了若干个 veth 以后，内核中对象的大概逻辑图如下。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>其中 veth 是由 struct net_device 来表示，bridge 的虚拟插口是由 struct net_bridge_port 来表示。我们接下来看看源码，是如何达成上述的逻辑结果的。&lt;/p>
&lt;p>添加设备会调用到 net/bridge/br_if.c 下面的 br_add_if。&lt;/p>
&lt;p>`//file: net/bridge/br_if.c
int br_add_if(struct net_bridge _br, struct net_device _dev)
{
 //  申请一个  net_bridge_port
 struct net_bridge_port *p;
 p = new_nbp(br, dev);&lt;/p>
&lt;p>//  注册设备帧接收函数
 err = netdev_rx_handler_register(dev, br_handle_frame, p);&lt;/p>
&lt;p>//  添加到  bridge  的已用端口列表里
 list_add_rcu(&amp;amp;p-&amp;gt;list, &amp;amp;br-&amp;gt;port_list);&lt;/p>
&lt;p>&amp;hellip;&amp;hellip;
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>这个函数中的第二个参数 dev 传入的是要添加的设备。在本文中，就可以认为是 veth 的其中一头。比较关键的是 net_bridge_port 这个结构体，它模拟的是物理交换机上的一个插口。它起到一个连接的作用，把 veth 和 bridge 给连接了起来。见 new_nbp 源码如下：&lt;/p>
&lt;p>`//file: net/bridge/br_if.c
static struct net_bridge_port _new_nbp(struct net_bridge _br,
           struct net_device _dev)
{
 // 申请插口对象
 struct net_bridge_port _p;
 p = kzalloc(sizeof(*p), GFP_KERNEL);&lt;/p>
&lt;p>// 初始化插口
 index = find_portno(br);
 p-&amp;gt;br = br;
 p-&amp;gt;dev = dev;
 p-&amp;gt;port_no = index;
 &amp;hellip;
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>在 new_nbp 中，先是申请了代表插口的内核对象。find_portno 是在当前 bridge 下寻找一个可用的端口号。接下来插口对象通过 &lt;code>p-&amp;gt;br = br&lt;/code> 和 bridge 设备关联了起来，通过 &lt;code>p-&amp;gt;dev = dev&lt;/code> 和代表 veth 设备的 dev 对象也建立了联系。&lt;/p>
&lt;p>在 br_add_if 中还调用 netdev_rx_handler_register 注册了设备帧接收函数，设置 veth 上的 rx_handler 为 br_handle_frame。&lt;strong>后面在接收包的时候会回调到它&lt;/strong>。&lt;/p>
&lt;p>&lt;code>//file: int netdev_rx_handler_register(struct net_device *dev,           rx_handler_func_t *rx_handler,           void *rx_handler_data) {  ...   rcu_assign_pointer(dev-&amp;gt;rx_handler_data, rx_handler_data);  rcu_assign_pointer(dev-&amp;gt;rx_handler, rx_handler); }&lt;/code>&lt;/p>
&lt;h2 id="四数据包处理过程">四、数据包处理过程&lt;a class="td-heading-self-link" href="#%e5%9b%9b%e6%95%b0%e6%8d%ae%e5%8c%85%e5%a4%84%e7%90%86%e8%bf%87%e7%a8%8b" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在&lt;a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;amp;mid=2247484058&amp;amp;idx=1&amp;amp;sn=a2621bc27c74b313528eefbc81ee8c0f&amp;amp;scene=21#wechat_redirect">图解 Linux 网络包接收过程&lt;/a>中我们讲到过接收包的完整流程。数据包会被网卡先从到 RingBuffer 中，然后依次经过硬中断、软中断处理。在软中断中再依次把包送到设备层、协议栈，最后唤醒应用程序。&lt;/p>
&lt;p>不过，拿 veth 设备来举例，如果它连接到了网桥上的话，在设备层的 __netif_receive_skb_core 函数中和上述过程有所不同。连在 bridge 上的 veth 在收到数据包的时候，不会进入协议栈，而是会进入网桥处理。网桥找到合适的转发口（另一个 veth），通过这个 veth 把数据转发出去。工作流程如下图。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>我们从 veth1_p 设备的接收看起，所有的设备的接收都一样，都会进入 __netif_receive_skb_core 设备层的关键函数。&lt;/p>
&lt;p>`//file: net/core/dev.c
static int __netif_receive_skb_core(struct sk_buff *skb, bool pfmemalloc)
{
 &amp;hellip;&lt;/p>
&lt;p>// tcpdump  抓包点
 list_for_each_entry_rcu(&amp;hellip;);&lt;/p>
&lt;p>//  执行设备的  rx_handler（也就是  br_handle_frame）
 rx_handler = rcu_dereference(skb-&amp;gt;dev-&amp;gt;rx_handler);
 if (rx_handler) {
  switch (rx_handler(&amp;amp;skb)) { 
  case RX_HANDLER_CONSUMED:
   ret = NET_RX_SUCCESS;
   goto unlock;
  }
 }&lt;/p>
&lt;p>//  送往协议栈
 //&amp;hellip;&lt;/p>
&lt;p>unlock:
 rcu_read_unlock();
out:
 return ret;
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>在 __netif_receive_skb_core 中先是过了 tcpdump 的抓包点，然后查找和执行了 rx_handler。在上面小节中我们看到，把 veth 连接到网桥上的时候，veth 对应的内核对象 dev 中的 rx_handler 被设置成了 br_handle_frame。&lt;strong>所以连接到网桥上的 veth 在收到包的时候，会将帧送入到网桥处理函数 br_handle_frame 中&lt;/strong>。&lt;/p>
&lt;p>另外要注意的是网桥函数处理完的话，一般来说就 goto unlock 退出了。和普通的网卡数据包接收相比，并不会往下再送到协议栈了。&lt;/p>
&lt;p>接着来看下网桥是咋工作的吧，进入到 br_handle_frame 中来搜寻。&lt;/p>
&lt;p>`//file: net/bridge/br_input.c
rx_handler_result_t br_handle_frame(struct sk_buff **pskb)
{
 &amp;hellip;&lt;/p>
&lt;p>forward:
 NF_HOOK(NFPROTO_BRIDGE, NF_BR_PRE_ROUTING, skb, skb-&amp;gt;dev, NULL,
   br_handle_frame_finish);
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>上面我对 br_handle_frame 的逻辑进行了充分的简化，简化后它的核心就是调用 br_handle_frame_finish。同样 br_handle_frame_finish 也有点小复杂。本文中，我们主要想了解的 Docker 场景下 bridge 上的 veth 设备转发。所以根据这个场景，我又对该函数进行了充分的简化。&lt;/p>
&lt;p>`//file: net/bridge/br_input.c
int br_handle_frame_finish(struct sk_buff _skb)
{  
 //  获取  veth  所连接的网桥端口、以及网桥设备
 struct net_bridge_port _p = br_port_get_rcu(skb-&amp;gt;dev);
 br = p-&amp;gt;br;&lt;/p>
&lt;p>//  更新和查找转发表
 struct net_bridge_fdb_entry *dst;
 br_fdb_update(br, p, eth_hdr(skb)-&amp;gt;h_source, vid);
 dst = __br_fdb_get(br, dest, vid)&lt;/p>
&lt;p>//  转发
 if (dst) {
  br_forward(dst-&amp;gt;dst, skb, skb2);
 } 
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>在硬件中，交换机和集线器的主要区别就是它会智能地把数据送到正确的端口上去，而不会像集线器那样给所有的端口都群发一遍。所以在上面的函数中，我们看到了更新和查找转发表的逻辑。这就是网桥在学习，它会根据它的自学习结果来工作。&lt;/p>
&lt;p>在找到要送往的端口后，下一步就是调用 br_forward =&amp;gt; __br_forward 进入真正的转发流程。&lt;/p>
&lt;p>`//file: net/bridge/br_forward.c
static void __br_forward(const struct net_bridge_port _to, struct sk_buff _skb)
{
 //  将  skb  中的  dev  改成新的目的  dev
 skb-&amp;gt;dev = to-&amp;gt;dev;&lt;/p>
&lt;p>NF_HOOK(NFPROTO_BRIDGE, NF_BR_FORWARD, skb, indev, skb-&amp;gt;dev,
  br_forward_finish);
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>在 __br_forward 中，将 skb 上的设备 dev 改为了新的目的 dev。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>然后调用 br_forward_finish 进入发送流程。在 br_forward_finish 里会依次调用 br_dev_queue_push_xmit、dev_queue_xmit。&lt;/p>
&lt;p>&lt;code>//file: net/bridge/br_forward.c int br_forward_finish(struct sk_buff *skb) {  return NF_HOOK(NFPROTO_BRIDGE, NF_BR_POST_ROUTING, skb, NULL, skb-&amp;gt;dev,          br_dev_queue_push_xmit); } int br_dev_queue_push_xmit(struct sk_buff *skb) {  dev_queue_xmit(skb);  ... }&lt;/code>&lt;/p>
&lt;p>dev_queue_xmit 就是发送函数，在上一篇&lt;a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&amp;amp;mid=2247486424&amp;amp;idx=1&amp;amp;sn=d66fe4ebf1cd9e5079606f71a0169697&amp;amp;scene=21#wechat_redirect">《轻松理解 Docker 网络虚拟化基础之 veth 设备！》&lt;/a>中我们介绍过，后续的发送过程就是 dev_queue_xmit =&amp;gt; dev_hard_start_xmit =&amp;gt; veth_xmit。在 veth_xmit 中会获取到当前 veth 的对端，然后把数据给它发送过去。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>至此，bridge 上的转发流程就算是完毕了。要注意到的是，整个 bridge 的工作的源码都是在 net/core/dev.c 或 net/bridge 目录下。都是在设备层工作的。这也就充分印证了我们经常说的 bridge（物理交换机也一样） 是二层上的设备。&lt;/p>
&lt;p>接下来，收到网桥发过来数据的 veth 会把数据包发送给它的对端 veth2，veth2 再开始自己的数据包接收流程。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;h2 id="五总结">五、总结&lt;a class="td-heading-self-link" href="#%e4%ba%94%e6%80%bb%e7%bb%93" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>所谓网络虚拟化，其实用一句话来概括就是&lt;strong>用软件来模拟实现真实的物理网络连接&lt;/strong>。&lt;/p>
&lt;p>Linux 内核中的 bridge 模拟实现了物理网络中的交换机的角色。和物理网络类似，可以将虚拟设备插入到 bridge 上。不过和物理网络有点不一样的是，一对儿 veth 插入 bridge 的那端其实就不是设备了，可以理解为退化成了一个网线插头。&lt;/p>
&lt;p>当 bridge 接入了多对儿 veth 以后，就可以通过自身实现的网络包转发的功能来让不同的 veth 之间互相通信了。&lt;/p>
&lt;p>回到 Docker 的使用场景上来举例，完整的 Docker 1 和 Docker 2 通信的过程是这样的：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>大致步骤是：&lt;/p>
&lt;ul>
&lt;li>1.Docker1 往 veth1 上发送数据&lt;/li>
&lt;li>
&lt;ol start="2">
&lt;li>由于 veth1_p 是 veth1 的 pair， 所以这个虚拟设备上可以收到包&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>3.veth 收到包以后发现自己是连在网桥上的，于是乎进入网桥处理。在网桥设备上寻找要转发到的端口，这时找到了 veth2_p 开始发送。网桥完成了自己的转发工作&lt;/li>
&lt;li>4.veth2 作为 veth2_p 的对端，收到了数据包&lt;/li>
&lt;li>5.Docker2 里的就可以从 veth2 设备上收到数据了&lt;/li>
&lt;/ul>
&lt;p>觉得这个流程图还不过瘾？那我们再继续拉大视野，从两个 Docker 的用户态来开始看一看。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p>
&lt;p>Docker 1 在需要发送数据的时候，先通过 send 系统调用发送，这个发送会执行到协议栈进行协议头的封装等处理。经由邻居子系统找到要使用的设备（veth1）后，从这个设备将数据发送出去，veth1 的对端 veth1_p 会收到数据包。&lt;/p>
&lt;p>收到数据的 veth1_p 是一个连接在 bridge 上的设备，这时候 bridge 会接管该 veth 的数据接收过程。从自己连接的所有设备中查找目的设备。找到 veth2_p 以后，调用该设备的发送函数将数据发送出去。同样 veth2_p 的对端 veth2 即将收到数据。&lt;/p>
&lt;p>其中 veth2 收到数据后，将和 lo、eth0 等设备一样，进入正常的数据接收处理过程。Docker 2 中的用户态进程将能够收到 Docker 1 发送过来的数据了就。&lt;/p>
&lt;p>怎么样，今天你有没有更深入地理解了 Docker 的工作原理呢？最后转发到朋友圈，让你的朋友们也一起来学学吧~~~&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/50a2c4de-0e0a-4411-b386-112edd0a3fdf/640" alt="">&lt;/p></description></item><item><title>Docs: Linux 网络设备详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;/blockquote>
&lt;h1 id="虚拟网络设备">虚拟网络设备&lt;a class="td-heading-self-link" href="#%e8%99%9a%e6%8b%9f%e7%bd%91%e7%bb%9c%e8%ae%be%e5%a4%87" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#">https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#&lt;/a>&lt;/li>
&lt;li>[本知识库虚拟化网络章节](/docs/10.云原生/1.1.虚拟化/Network%20Virtual(网络虚拟化).md Virtual(网络虚拟化).md)&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Linux 具有丰富的虚拟网络功能，可用作托管 VM 和容器以及云环境的基础。在这篇文章中，我将简要介绍所有常用的虚拟网络接口类型。没有代码分析，只简单介绍了接口及其在 Linux 上的使用。任何有网络背景的人都可能对这篇博文感兴趣。可以使用命令 ip link help 获取接口列表。&lt;/p>
&lt;p>这篇文章涵盖了以下常用网络设备和一些容易相互混淆的网络设备：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#bridge">Bridge&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#bonded">Bond&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#team">Team device&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#vlan">VLAN (Virtual LAN)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#vxlan">VXLAN (Virtual eXtensible Local Area Network)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#macvlan">MACVLAN&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#ipvlan">IPVLAN&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#macvtap">MACVTAP/IPVTAP&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#macsec">MACsec (Media Access Control Security)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#veth">VETH (Virtual Ethernet)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#vcan">VCAN (Virtual CAN)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#vxcan">VXCAN (Virtual CAN tunnel)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#ipoib">IPOIB (IP-over-InfiniBand)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#nlmon">NLMON (NetLink MONitor)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#dummy">Dummy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#ifb">IFB (Intermediate Functional Block)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#netdevsim">netdevsim&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="bridge">Bridge&lt;a class="td-heading-self-link" href="#bridge" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Bridge 网络设备的行为类似于网络交换机。它在连接到它的网络设备之间转发数据包。通常用于在 路由器、网关、虚拟机、网络名称空间之间转发数据包。同时 Bridge 设备还支持 STP、VLAN 过滤和组播侦听。&lt;/p>
&lt;p>当我们想要在 虚拟机、容器、宿主机 之间建立通信时，Bridge 设备是必不可少的。
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bridge.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493495381-a7c7e048-4783-45a6-a1d1-c44526401132.png" alt="image.png">&lt;/a>
下面是一个是创建 Brdige 并连接其他网络设备的示例：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ip link add br0 &lt;span style="color:#204a87">type&lt;/span> bridge
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ip link &lt;span style="color:#204a87">set&lt;/span> eth0 master br0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ip link &lt;span style="color:#204a87">set&lt;/span> tap1 master br0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ip link &lt;span style="color:#204a87">set&lt;/span> tap2 master br0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ip link &lt;span style="color:#204a87">set&lt;/span> veth1 master br0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>上面的例子将会创建一个名为 &lt;code>br0&lt;/code> 的 Bridge 设备，并将两个 TAP 设备和一个 VETH 设备作为其从属设备。&lt;/p>
&lt;h2 id="bond">Bond&lt;a class="td-heading-self-link" href="#bond" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The Linux bonding driver provides a method for aggregating multiple network interfaces into a single logical &amp;ldquo;bonded&amp;rdquo; interface. The behavior of the bonded interface depends on the mode; generally speaking, modes provide either hot standby or load balancing services.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bond.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493495394-4aaea4bd-34d9-4987-9873-38af16247d1b.png" alt="image.png">&lt;/a>
Use a bonded interface when you want to increase your link speed or do a failover on your server.
Here&amp;rsquo;s how to create a bonded interface:
ip link add bond1 type bond miimon 100 mode active-backup ip link set eth0 master bond1 ip link set eth1 master bond1
This creates a bonded interface named bond1 with mode active-backup. For other modes, please see the &lt;a href="https://www.kernel.org/doc/Documentation/networking/bonding.txt">kernel documentation&lt;/a>.&lt;/p>
&lt;h2 id="team">Team&lt;a class="td-heading-self-link" href="#team" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Similar a bonded interface, the purpose of a team device is to provide a mechanism to group multiple NICs (ports) into one logical one (teamdev) at the L2 layer.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/team.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493495378-cdc041c4-6321-49b7-b532-63f2cded7392.png" alt="image.png">&lt;/a>
The main thing to realize is that a team device is not trying to replicate or mimic a bonded interface. What it does is to solve the same problem using a different approach, using, for example, a lockless (RCU) TX/RX path and modular design.
But there are also some functional differences between a bonded interface and a team. For example, a team supports LACP load-balancing, NS/NA (IPV6) link monitoring, D-Bus interface, etc., which are absent in bonding. For further details about the differences between bonding and team, see &lt;a href="https://github.com/jpirko/libteam/wiki/Bonding-vs.-Team-features">Bonding vs. Team features&lt;/a>.
Use a team when you want to use some features that bonding doesn&amp;rsquo;t provide.
Here&amp;rsquo;s how to create a team:
# teamd -o -n -U -d -t team0 -c &amp;lsquo;{&amp;ldquo;runner&amp;rdquo;: {&amp;ldquo;name&amp;rdquo;: &amp;ldquo;activebackup&amp;rdquo;},&amp;ldquo;link_watch&amp;rdquo;: {&amp;ldquo;name&amp;rdquo;: &amp;ldquo;ethtool&amp;rdquo;}}&amp;rsquo; # ip link set eth0 down # ip link set eth1 down # teamdctl team0 port add eth0 # teamdctl team0 port add eth1
This creates a team interface named team0 with mode active-backup, and it adds eth0 and eth1 as team0&amp;rsquo;s sub-interfaces.
A new driver called &lt;a href="https://www.kernel.org/doc/html/latest/networking/net_failover.html">net_failover&lt;/a> has been added to Linux recently. It&amp;rsquo;s another failover master net device for virtualization and manages a primary (&lt;a href="https://wiki.libvirt.org/page/Networking#PCI_Passthrough_of_host_network_devices">passthru/VF [Virtual Function]&lt;/a> device) slave net device and a standby (the original paravirtual interface) slave net device.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/net_failover.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493495395-cb9efff7-7595-4750-b0a0-18f0ef15f765.png" alt="image.png">&lt;/a>&lt;/p>
&lt;h2 id="vlan">VLAN&lt;a class="td-heading-self-link" href="#vlan" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>A VLAN, aka virtual LAN, separates broadcast domains by adding tags to network packets. VLANs allow network administrators to group hosts under the same switch or between different switches.
The VLAN header looks like:
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/vlan_01.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493495406-ba20c202-7aec-4f2d-8e4a-718c8db481ad.png" alt="image.png">&lt;/a>
Use a VLAN when you want to separate subnet in VMs, namespaces, or hosts.
Here&amp;rsquo;s how to create a VLAN:
# ip link add link eth0 name eth0.2 type vlan id 2 # ip link add link eth0 name eth0.3 type vlan id 3
This adds VLAN 2 with name eth0.2 and VLAN 3 with name eth0.3. The topology looks like this:
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/vlan.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493496104-953046d4-0fac-4ca7-908d-45785c3a097d.png" alt="image.png">&lt;/a>
&lt;strong>&lt;em>Note&lt;/em>&lt;/strong>: When configuring a VLAN, you need to make sure the switch connected to the host is able to handle VLAN tags, for example, by setting the switch port to trunk mode.&lt;/p>
&lt;h2 id="vxlan">VXLAN&lt;a class="td-heading-self-link" href="#vxlan" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>VXLAN (Virtual eXtensible Local Area Network) is a tunneling protocol designed to solve the problem of limited VLAN IDs (4,096) in IEEE 802.1q. It is described by &lt;a href="https://tools.ietf.org/html/rfc7348">IETF RFC 7348&lt;/a>.
With a 24-bit segment ID, aka VXLAN Network Identifier (VNI), VXLAN allows up to 2^24 (16,777,216) virtual LANs, which is 4,096 times the VLAN capacity.
VXLAN encapsulates Layer 2 frames with a VXLAN header into a UDP-IP packet, which looks like this:
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/vxlan_01.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493496161-ef228755-9102-427a-b3fa-f9d8f5cae248.png" alt="image.png">&lt;/a>
VXLAN is typically deployed in data centers on virtualized hosts, which may be spread across multiple racks.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/vxlan.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493496231-8fa6bbd6-045f-43f3-a2f9-58039a973086.png" alt="image.png">&lt;/a>
Here&amp;rsquo;s how to use VXLAN:
# ip link add vx0 type vxlan id 100 local 1.1.1.1 remote 2.2.2.2 dev eth0 dstport 4789
For reference, you can read the &lt;a href="https://www.kernel.org/doc/Documentation/networking/vxlan.txt">VXLAN kernel documentation&lt;/a> or &lt;a href="https://vincent.bernat.ch/en/blog/2017-vxlan-linux">this VXLAN introduction&lt;/a>.&lt;/p>
&lt;h2 id="macvlan">MACVLAN&lt;a class="td-heading-self-link" href="#macvlan" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>With VLAN, you can create multiple interfaces on top of a single one and filter packages based on a VLAN tag. With MACVLAN, you can create multiple interfaces with different Layer 2 (that is, Ethernet MAC) addresses on top of a single one.
Before MACVLAN, if you wanted to connect to physical network from a VM or namespace, you would have needed to create TAP/VETH devices and attach one side to a bridge and attach a physical interface to the bridge on the host at the same time, as shown below.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/br_ns.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493496373-bba2ae90-3c29-497b-9cf2-9707146ab063.png" alt="image.png">&lt;/a>
Now, with MACVLAN, you can bind a physical interface that is associated with a MACVLAN directly to namespaces, without the need for a bridge.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macvlan.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493496402-8b2910b5-780c-4a7b-885d-e1ae96f70a20.png" alt="image.png">&lt;/a>
There are five MACVLAN types:
1. Private: doesn&amp;rsquo;t allow communication between MACVLAN instances on the same physical interface, even if the external switch supports hairpin mode.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macvlan_01.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493496672-ece58d6f-86b8-4bb6-bfdc-4877583cf2a8.png" alt="image.png">&lt;/a>
2. VEPA: data from one MACVLAN instance to the other on the same physical interface is transmitted over the physical interface. Either the attached switch needs to support hairpin mode or there must be a TCP/IP router forwarding the packets in order to allow communication.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macvlan_02.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493497664-fcf059dc-8d97-4d85-83dc-79e35d8a0502.png" alt="image.png">&lt;/a>
3. Bridge: all endpoints are directly connected to each other with a simple bridge via the physical interface.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macvlan_03.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493497742-be699130-38ef-45a2-a657-a7d90bcbbe81.png" alt="image.png">&lt;/a>
4. Passthru: allows a single VM to be connected directly to the physical interface.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macvlan_04.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493497676-73e85ca2-4f2a-47b9-b14b-1d5fb34c877b.png" alt="image.png">&lt;/a>
5. Source: the source mode is used to filter traffic based on a list of allowed source MAC addresses to create MAC-based VLAN associations. Please see the &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/davem/net.git/commit/?id=79cf79abce71">commit message&lt;/a>.
The type is chosen according to different needs. Bridge mode is the most commonly used.
Use a MACVLAN when you want to connect directly to a physical network from containers.
Here&amp;rsquo;s how to set up a MACVLAN:
# ip link add macvlan1 link eth0 type macvlan mode bridge # ip link add macvlan2 link eth0 type macvlan mode bridge # ip netns add net1 # ip netns add net2 # ip link set macvlan1 netns net1 # ip link set macvlan2 netns net2
This creates two new MACVLAN devices in bridge mode and assigns these two devices to two different namespaces.&lt;/p>
&lt;h2 id="ipvlan">IPVLAN&lt;a class="td-heading-self-link" href="#ipvlan" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>IPVLAN is similar to MACVLAN with the difference being that the endpoints have the same MAC address.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/ipvlan.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493497707-c70596b7-5689-41be-a5b3-94b69d978090.png" alt="image.png">&lt;/a>
IPVLAN supports L2 and L3 mode. IPVLAN L2 mode acts like a MACVLAN in bridge mode. The parent interface looks like a bridge or switch.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/ipvlan_01.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493497736-65194dad-9ecb-4e91-af55-b16fae98721f.png" alt="image.png">&lt;/a>
In IPVLAN L3 mode, the parent interface acts like a router and packets are routed between endpoints, which gives better scalability.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/ipvlan_02.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493498348-d23366af-ed6b-46f0-8bcc-4997dacca461.png" alt="image.png">&lt;/a>
Regarding when to use an IPVLAN, the &lt;a href="https://www.kernel.org/doc/Documentation/networking/ipvlan.txt">IPVLAN kernel documentation&lt;/a> says that MACVLAN and IPVLAN &amp;ldquo;are very similar in many regards and the specific use case could very well define which device to choose. if one of the following situations defines your use case then you can choose to use ipvlan -
(a) The Linux host that is connected to the external switch / router has policy configured that allows only one mac per port.
(b) No of virtual devices created on a master exceed the mac capacity and puts the NIC in promiscuous mode and degraded performance is a concern.
(c) If the slave device is to be put into the hostile / untrusted network namespace where L2 on the slave could be changed / misused.&amp;rdquo;
Here&amp;rsquo;s how to set up an IPVLAN instance:
# ip netns add ns0 # ip link add name ipvl0 link eth0 type ipvlan mode l2 # ip link set dev ipvl0 netns ns0
This creates an IPVLAN device named ipvl0 with mode L2, assigned to namespace ns0.&lt;/p>
&lt;h2 id="macvtapipvtap">MACVTAP/IPVTAP&lt;a class="td-heading-self-link" href="#macvtapipvtap" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>MACVTAP/IPVTAP is a new device driver meant to simplify virtualized bridged networking. When a MACVTAP/IPVTAP instance is created on top of a physical interface, the kernel also creates a character device/dev/tapX to be used just like a &lt;a href="https://en.wikipedia.org/wiki/TUN/TAP">TUN/TAP&lt;/a> device, which can be directly used by KVM/QEMU.
With MACVTAP/IPVTAP, you can replace the combination of TUN/TAP and bridge drivers with a single module:
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macvtap.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493498407-337b9bb8-cbee-4990-8283-55a3f5c36e66.png" alt="image.png">&lt;/a>
Typically, MACVLAN/IPVLAN is used to make both the guest and the host show up directly on the switch to which the host is connected. The difference between MACVTAP and IPVTAP is same as with MACVLAN/IPVLAN.
Here&amp;rsquo;s how to create a MACVTAP instance:
# ip link add link eth0 name macvtap0 type macvtap&lt;/p>
&lt;h2 id="macsec">MACsec&lt;a class="td-heading-self-link" href="#macsec" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>MACsec (Media Access Control Security) is an IEEE standard for security in wired Ethernet LANs. Similar to IPsec, as a layer 2 specification, MACsec can protect not only IP traffic but also ARP, neighbor discovery, and DHCP. The MACsec headers look like this:
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macsec_01.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493498628-bcdf3cf6-08f5-4bd3-bac8-ef3412bea0d3.png" alt="image.png">&lt;/a>
The main use case for MACsec is to secure all messages on a standard LAN including ARP, NS, and DHCP messages.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/macsec.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493498641-f72e7987-0e5b-438c-959d-6d0397b337d6.png" alt="image.png">&lt;/a>
Here&amp;rsquo;s how to set up a MACsec configuration:
# ip link add macsec0 link eth1 type macsec
&lt;strong>&lt;em>Note&lt;/em>&lt;/strong>: This only adds a MACsec device called macsec0 on interface eth1. For more detailed configurations, please see the &amp;ldquo;Configuration example&amp;rdquo; section in this &lt;a href="https://developers.redhat.com/blog/2016/10/14/macsec-a-different-solution-to-encrypt-network-traffic/">MACsec introduction by Sabrina Dubroca&lt;/a>.&lt;/p>
&lt;h2 id="veth">VETH&lt;a class="td-heading-self-link" href="#veth" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The VETH (virtual Ethernet) device is a local Ethernet tunnel. Devices are created in pairs, as shown in the diagram below.
Packets transmitted on one device in the pair are immediately received on the other device. When either device is down, the link state of the pair is down.
&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/veth.png">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493498671-cf9ff7ff-0ee0-469e-adff-620edf2a237a.png" alt="image.png">&lt;/a>
Use a VETH configuration when namespaces need to communicate to the main host namespace or between each other.
Here&amp;rsquo;s how to set up a VETH configuration:
# ip netns add net1 # ip netns add net2 # ip link add veth1 netns net1 type veth peer name veth2 netns net2
This creates two namespaces, net1 and net2, and a pair of VETH devices, and it assigns veth1 to namespace net1 and veth2 to namespace net2. These two namespaces are connected with this VETH pair. Assign a pair of IP addresses, and you can ping and communicate between the two namespaces.&lt;/p>
&lt;h2 id="vcan">VCAN&lt;a class="td-heading-self-link" href="#vcan" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Similar to the network loopback devices, the VCAN (virtual CAN) driver offers a virtual local CAN (Controller Area Network) interface, so users can send/receive CAN messages via a VCAN interface. CAN is mostly used in the automotive field nowadays.
For more CAN protocol information, please refer to the &lt;a href="https://www.kernel.org/doc/Documentation/networking/can.txt">kernel CAN documentation&lt;/a>.
Use a VCAN when you want to test a CAN protocol implementation on the local host.
Here&amp;rsquo;s how to create a VCAN:
# ip link add dev vcan1 type vcan&lt;/p>
&lt;h2 id="vxcan">VXCAN&lt;a class="td-heading-self-link" href="#vxcan" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Similar to the VETH driver, a VXCAN (Virtual CAN tunnel) implements a local CAN traffic tunnel between two VCAN network devices. When you create a VXCAN instance, two VXCAN devices are created as a pair. When one end receives the packet, the packet appears on the device&amp;rsquo;s pair and vice versa. VXCAN can be used for cross-namespace communication.
Use a VXCAN configuration when you want to send CAN message across namespaces.
Here&amp;rsquo;s how to set up a VXCAN instance:
# ip netns add net1 # ip netns add net2 # ip link add vxcan1 netns net1 type vxcan peer name vxcan2 netns net2
&lt;strong>&lt;em>Note&lt;/em>&lt;/strong>: VXCAN is not yet supported in Red Hat Enterprise Linux.&lt;/p>
&lt;h2 id="ipoib">IPOIB&lt;a class="td-heading-self-link" href="#ipoib" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>An IPOIB device supports the IP-over-InfiniBand protocol. This transports IP packets over InfiniBand (IB) so you can use your IB device as a fast NIC.
The IPoIB driver supports two modes of operation: datagram and connected. In datagram mode, the IB UD (Unreliable Datagram) transport is used. In connected mode, the IB RC (Reliable Connected) transport is used. The connected mode takes advantage of the connected nature of the IB transport and allows an MTU up to the maximal IP packet size of 64K.
For more details, please see the &lt;a href="https://www.kernel.org/doc/Documentation/infiniband/ipoib.txt">IPOIB kernel documentation&lt;/a>.
Use an IPOIB device when you have an IB device and want to communicate with a remote host via IP.
Here&amp;rsquo;s how to create an IPOIB device:
# ip link add ib0 name ipoib0 type ipoib pkey IB_PKEY mode connected&lt;/p>
&lt;h2 id="nlmon">NLMON&lt;a class="td-heading-self-link" href="#nlmon" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>NLMON is a Netlink monitor device.
Use an NLMON device when you want to monitor system Netlink messages.
Here&amp;rsquo;s how to create an NLMON device:
# ip link add nlmon0 type nlmon # ip link set nlmon0 up # tcpdump -i nlmon0 -w nlmsg.pcap
This creates an NLMON device named nlmon0 and sets it up. Use a packet sniffer (for example, tcpdump) to capture Netlink messages. Recent versions of Wireshark feature decoding of Netlink messages.&lt;/p>
&lt;h2 id="dummy">Dummy&lt;a class="td-heading-self-link" href="#dummy" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>dummy 是一个网络接口，是完全虚拟的，就像 loopback 设备。dummy 设备的目的是提供一种网络设备，用以路由数据包，而无需实际传输他们&lt;/p>
&lt;p>使用 dummy 设备使不活动的 SLIP(串行线路 Internet 协议) 地址看起来像本地程序的真实地址。 现在，dummy 设备主要用于测试和调试，同时，在 Kubernetes 中，Flannel 在 ipvs 模式下，也会创建一个名为 kube-ipvs0 的网络设备来路由数据包。&lt;/p>
&lt;p>dummy 设备的创建方式如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ip link add dummy1 &lt;span style="color:#204a87">type&lt;/span> dummy
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ip addr add 1.1.1.1/24 dev dummy1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ip link &lt;span style="color:#204a87">set&lt;/span> dummy1 up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="ifb">IFB&lt;a class="td-heading-self-link" href="#ifb" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The IFB (Intermediate Functional Block) driver supplies a device that allows the concentration of traffic from several sources and the shaping incoming traffic instead of dropping it.
Use an IFB interface when you want to queue and shape incoming traffic.
Here&amp;rsquo;s how to create an IFB interface:
# ip link add ifb0 type ifb # ip link set ifb0 up # tc qdisc add dev ifb0 root sfq # tc qdisc add dev eth0 handle ffff: ingress # tc filter add dev eth0 parent ffff: u32 match u32 0 0 action mirred egress redirect dev ifb0
This creates an IFB device named ifb0 and replaces the root qdisc scheduler with SFQ (Stochastic Fairness Queueing), which is a classless queueing scheduler. Then it adds an ingress qdisc scheduler on eth0 and redirects all ingress traffic to ifb0.
For more IFB qdisc use cases, please refer to this &lt;a href="https://wiki.linuxfoundation.org/networking/ifb">Linux Foundation wiki on IFB&lt;/a>.&lt;/p>
&lt;h2 id="additional-resources">Additional resources&lt;a class="td-heading-self-link" href="#additional-resources" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://developers.redhat.com/blog/tag/virtual-networking/">Virtual networking articles&lt;/a> on the Red Hat Developer blog&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/09/03/ovn-dynamic-ip-address-management/">Dynamic IP Address Management in Open Virtual Network (OVN)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2018/03/23/non-root-open-vswitch-rhel/">Non-root Open vSwitch in Red Hat Enterprise Linux&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/tag/open-vswitch/">Open vSwitch articles&lt;/a> on the Red hat Developer Blog&lt;/li>
&lt;/ul>
&lt;h2 id="netdevsim-interface">netdevsim interface&lt;a class="td-heading-self-link" href="#netdevsim-interface" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>netdevsim is a simulated networking device which is used for testing various networking APIs. At this time it is particularly focused on testing hardware
offloading, tc/XDP BPF and SR-IOV.
A netdevsim device can be created as follows
# ip link add dev sim0 type netdevsim # ip link set dev sim0 up
To enable tc offload:
# ethtool -K sim0 hw-tc-offload on
To load XDP BPF or tc BPF programs:
# ip link set dev sim0 xdpoffload obj prog.o
To add VFs for SR-IOV testing:
# echo 3 &amp;gt; /sys/class/net/sim0/device/sriov&lt;em>numvfs # ip link set sim0 vf 0 mac
To change the vf numbers, you need to disable them completely first:
# echo 0 &amp;gt; /sys/class/net/sim0/device/sriov_numvfs # echo 5 &amp;gt; /sys/class/net/sim0/device/sriov_numvfs
Note: netdevsim is not compiled in RHEL by default
_Last updated: September 11, 2019&lt;/em>&lt;/p>
&lt;h1 id="隧道网络设备">隧道网络设备&lt;a class="td-heading-self-link" href="#%e9%9a%a7%e9%81%93%e7%bd%91%e7%bb%9c%e8%ae%be%e5%a4%87" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#">https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Linux 支持多种隧道，但新用户可能会对它们的差异感到困惑，并不确定哪一种最适合给定的用例。在本文中，我将简要介绍 Linux 内核中常用的隧道接口。没有代码分析，只简单介绍了接口及其在 Linux 上的使用。任何有网络背景的人都可能对这些信息感兴趣。可以通过发出 iproute2 命令 ip link help 获得隧道接口列表以及特定隧道配置的帮助。&lt;/p>
&lt;p>这篇文章涵盖了以下常用接口：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#ipip">IPIP Tunnel&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#sit">SIT Tunnel&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#ip6tnl">ip6tnl Tunnel&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#vti">VTI and VTI6&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#gre">GRE and GRETAP&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#ip6gre">IP6GRE and IP6GRETAP&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#fou">FOU&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#gue">GUE&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#geneve">GENEVE&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/05/17/an-introduction-to-linux-virtual-interfaces-tunnels#erspan">ERSPAN and IP6ERSPAN&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="ipip-tunnel">IPIP Tunnel&lt;a class="td-heading-self-link" href="#ipip-tunnel" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>IPIP tunnel, just as the name suggests, is an IP over IP tunnel, defined in &lt;a href="https://tools.ietf.org/html/rfc2003">RFC 2003&lt;/a>. The IPIP tunnel header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493541929-3c498a49-7406-4a02-ae97-da31bd386c6b.png" alt="image.png">
It&amp;rsquo;s typically used to connect two internal IPv4 subnets through public IPv4 internet. It has the lowest overhead but can only transmit IPv4 unicast traffic. That means you &lt;strong>cannot&lt;/strong> send multicast via IPIP tunnel.
IPIP tunnel supports both IP over IP and MPLS over IP.
&lt;strong>Note&lt;/strong>: When the ipip module is loaded, or an IPIP device is created for the first time, the Linux kernel will create a tunl0 default device in each namespace, with attributes local=any and remote=any. When receiving IPIP protocol packets, the kernel will forward them to tunl0 as a fallback device if it can&amp;rsquo;t find another device whose local/remote attributes match their source or destination address more closely.
Here is how to create an IPIP tunnel:
On Server A: # ip link add name ipip0 type ipip local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR # ip link set ipip0 up # ip addr add INTERNAL_IPV4_ADDR/24 dev ipip0 Add a remote internal subnet route if the endpoints don&amp;rsquo;t belong to the same subnet # ip route add REMOTE_INTERNAL_SUBNET/24 dev ipip0 On Server B: # ip link add name ipip0 type ipip local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR # ip link set ipip0 up # ip addr add INTERNAL_IPV4_ADDR/24 dev ipip0 # ip route add REMOTE_INTERNAL_SUBNET/24 dev ipip0
Note: Please replace LOCAL_IPv4_ADDR, REMOTE_IPv4_ADDR, INTERNAL_IPV4_ADDR, REMOTE_INTERNAL_SUBNET to the addresses based on your testing environment. The same with following example configs.&lt;/p>
&lt;h2 id="sit-tunnel">SIT Tunnel&lt;a class="td-heading-self-link" href="#sit-tunnel" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>SIT stands for Simple Internet Transition. The main purpose is to interconnect isolated IPv6 networks, located in global IPv4 internet.
Initially, it only had an IPv6 over IPv4 tunneling mode. After years of development, however, it acquired support for several different modes, such as ipip (the same with IPIP tunnel), ip6ip, mplsip, and any. Mode any is used to accept both IP and IPv6 traffic, which may prove useful in some deployments. SIT tunnel also supports &lt;a href="https://www.ietf.org/rfc/rfc4214.txt">ISATA&lt;/a>, and here is a &lt;a href="http://www.litech.org/isatap">usage example&lt;/a>.
The SIT tunnel header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493541941-c151c630-2925-4a09-aa89-845588e3e5b3.png" alt="image.png">
When the sit module is loaded, the Linux kernel will create a default device, named sit0.
Here is how to create a SIT tunnel:
On Server A: # ip link add name sit1 type sit local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR mode any # ip link set sit1 up # ip addr add INTERNAL_IPV4_ADDR/24 dev sit1
Then, perform the same steps on the remote side.&lt;/p>
&lt;h2 id="ip6tnl-tunnel">ip6tnl Tunnel&lt;a class="td-heading-self-link" href="#ip6tnl-tunnel" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>ip6tnl is an IPv4/IPv6 over IPv6 tunnel interface, which looks like an IPv6 version of the SIT tunnel. The tunnel header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493541939-55d26347-12f2-4dab-b439-a20720e2714e.png" alt="image.png">
ip6tnl supports modes ip6ip6, ipip6, any. Mode ipip6 is IPv4 over IPv6, and mode ip6ip6 is IPv6 over IPv6, and mode any supports both IPv4/IPv6 over IPv6.
When the ip6tnl module is loaded, the Linux kernel will create a default device, named ip6tnl0.
Here is how to create an ip6tnl tunnel:
# ip link add name ipip6 type ip6tnl local LOCAL_IPv6_ADDR remote REMOTE_IPv6_ADDR mode any&lt;/p>
&lt;h2 id="vti-and-vti6">VTI and VTI6&lt;a class="td-heading-self-link" href="#vti-and-vti6" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Virtual Tunnel Interface (VTI) on Linux is similar to Cisco&amp;rsquo;s VTI and Juniper&amp;rsquo;s implementation of secure tunnel (st.xx).
This particular tunneling driver implements IP encapsulations, which can be used with xfrm to give the notion of a secure tunnel and then use kernel routing on top.
In general, VTI tunnels operate in almost the same way as ipip or sit tunnels, except that they add a fwmark and IPsec encapsulation/decapsulation.
VTI6 is the IPv6 equivalent of VTI.
Here is how to create a VTI tunnel:
# ip link add name vti1 type vti key VTI_KEY local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR # ip link set vti1 up # ip addr add LOCAL_VIRTUAL_ADDR/24 dev vti1 # ip xfrm state add src LOCAL_IPv4_ADDR dst REMOTE_IPv4_ADDR spi SPI PROTO ALGR mode tunnel # ip xfrm state add src REMOTE_IPv4_ADDR dst LOCAL_IPv4_ADDR spi SPI PROTO ALGR mode tunnel # ip xfrm policy add dir in tmpl src REMOTE_IPv4_ADDR dst LOCAL_IPv4_ADDR PROTO mode tunnel mark VTI_KEY # ip xfrm policy add dir out tmpl src LOCAL_IPv4_ADDR dst REMOTE_IPv4_ADDR PROTO mode tunnel mark VTI_KEY
You can also configure IPsec via &lt;a href="https://libreswan.org/wiki/Route-based_VPN_using_VTI">libreswan&lt;/a> or &lt;a href="https://wiki.strongswan.org/projects/strongswan/wiki/RouteBasedVPN">strongSwan&lt;/a>.&lt;/p>
&lt;h2 id="gre-and-gretap">GRE and GRETAP&lt;a class="td-heading-self-link" href="#gre-and-gretap" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Generic Routing Encapsulation, also known as GRE, is defined in &lt;a href="https://tools.ietf.org/html/rfc2784">RFC 2784&lt;/a>
GRE tunneling adds an additional GRE header between the inside and outside IP headers. In theory, GRE could encapsulate any Layer 3 protocol with a valid Ethernet type, unlike IPIP, which can only encapsulate IP. The GRE header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493541950-7306c06b-3438-4a0c-98f1-1dfac809d7a8.png" alt="image.png">
Note that you can transport multicast traffic and IPv6 through a GRE tunnel.
When the gre module is loaded, the Linux kernel will create a default device, named gre0.
Here is how to create a GRE tunnel:
# ip link add name gre1 type gre local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR [seq] key KEY
While GRE tunnels operate at OSI Layer 3, GRETAP works at OSI Layer 2, which means there is an Ethernet header in the inner header.
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493541978-5b18c4ce-a484-4882-90a4-1341aab450fd.png" alt="image.png">
Here is how to create a GRETAP tunnel:
# ip link add name gretap1 type gretap local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR&lt;/p>
&lt;h2 id="ip6gre-and-ip6gretap">IP6GRE and IP6GRETAP&lt;a class="td-heading-self-link" href="#ip6gre-and-ip6gretap" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>IP6GRE is the IPv6 equivalent of GRE, which allows us to encapsulate any Layer 3 protocol over IPv6. The tunnel header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493543192-8bbd04d7-88b1-407e-b183-27e70ac3142e.png" alt="image.png">
IP6GRETAP, just like GRETAP, has an Ethernet header in the inner header:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493543437-bc1c8e95-4dee-449b-a31d-61154a0bbd85.png" alt="image.png">
Here is how to create a GRE tunnel:
# ip link add name gre1 type ip6gre local LOCAL_IPv6_ADDR remote REMOTE_IPv6_ADDR # ip link add name gretap1 type ip6gretap local LOCAL_IPv6_ADDR remote REMOTE_IPv6_ADDR&lt;/p>
&lt;h2 id="fou">FOU&lt;a class="td-heading-self-link" href="#fou" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Tunneling can happen at multiple levels in the networking stack. IPIP, SIT, GRE tunnels are at the IP level, while FOU (foo over UDP) is UDP-level tunneling.
There are some advantages of using UDP tunneling as UDP works with existing HW infrastructure, like &lt;a href="https://en.wikipedia.org/wiki/Network_interface_controller#RSS">RSS&lt;/a> in NICs, &lt;a href="https://en.wikipedia.org/wiki/Equal-cost_multi-path_routing">ECMP&lt;/a> in switches, and checksum offload. The developer&amp;rsquo;s &lt;a href="https://lwn.net/Articles/614433/">patch set&lt;/a> shows significant performance increases for the SIT and IPIP protocols.
Currently, the FOU tunnel supports encapsulation protocol based on IPIP, SIT, GRE. An example FOU header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493543253-f5dddca7-c7be-42cd-8f26-7f17a6b45499.png" alt="image.png">
Here is how to create a FOU tunnel:
# ip fou add port 5555 ipproto 4 # ip link add name tun1 type ipip remote 192.168.1.1 local 192.168.1.2 ttl 225 encap fou encap-sport auto encap-dport 5555
The first command configured a FOU receive port for IPIP bound to 5555; for GRE, you need to set ipproto 47. The second command set up a new IPIP virtual interface (tun1) configured for FOU encapsulation, with dest port 5555.
&lt;strong>NOTE&lt;/strong>: FOU is not supported in Red Hat Enterprise Linux.&lt;/p>
&lt;h2 id="gue">GUE&lt;a class="td-heading-self-link" href="#gue" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://tools.ietf.org/html/draft-ietf-intarea-gue">Generic UDP Encapsulation&lt;/a> (GUE) is another kind of UDP tunneling. The difference between FOU and GUE is that GUE has its own encapsulation header, which contains the protocol info and other data.
Currently, GUE tunnel supports inner IPIP, SIT, GRE encapsulation. An example GUE header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493543283-20ce12c4-edf1-4a2b-8888-42d3bdb4d08e.png" alt="image.png">
Here is how to create a GUE tunnel:
# ip fou add port 5555 gue # ip link add name tun1 type ipip remote 192.168.1.1 local 192.168.1.2 ttl 225 encap gue encap-sport auto encap-dport 5555
This will set up a GUE receive port for IPIP bound to 5555, and an IPIP tunnel configured for GUE encapsulation.
&lt;strong>NOTE&lt;/strong>: GUE is not supported in Red Hat Enterprise Linux.&lt;/p>
&lt;h2 id="geneve">GENEVE&lt;a class="td-heading-self-link" href="#geneve" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Generic Network Virtualization Encapsulation (GENEVE) supports all of the capabilities of VXLAN, NVGRE, and STT and was designed to overcome their perceived limitations. Many believe GENEVE could eventually replace these earlier formats entirely. The tunnel header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493543437-55251107-feaf-4448-9a65-9b726a1fa1bb.png" alt="image.png">
which looks very similar to &lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/#vxlan">VXLAN&lt;/a>. The main difference is that the GENEVE header is flexible. It&amp;rsquo;s very easy to add new features by extending the header with a new Type-Length-Value (TLV) field. For more details, you can see the latest &lt;a href="https://tools.ietf.org/html/draft-ietf-nvo3-geneve-08">geneve ietf draft&lt;/a> or refer to this &lt;a href="https://www.redhat.com/en/blog/what-geneve">What is GENEVE?&lt;/a> article.
&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/networking_with_open_virtual_network/open_virtual_network_ovn">Open Virtual Network (OVN)&lt;/a> uses GENEVE as default encapsulation. Here is how to create a GENEVE tunnel:
# ip link add name geneve0 type geneve id VNI remote REMOTE_IPv4_ADDR&lt;/p>
&lt;h2 id="erspan-and-ip6erspan">ERSPAN and IP6ERSPAN&lt;a class="td-heading-self-link" href="#erspan-and-ip6erspan" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Encapsulated Remote Switched Port Analyzer (ERSPAN) uses GRE encapsulation to extend the basic port mirroring capability from Layer 2 to Layer 3, which allows the mirrored traffic to be sent through a routable IP network. The ERSPAN header looks like:
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/figk4l/1630493544476-8decf814-c9a0-4c61-9005-e7626ca9ae4a.png" alt="image.png">
The ERSPAN tunnel allows a Linux host to act as an ERSPAN traffic source and send the ERSPAN mirrored traffic to either a remote host or to an ERSPAN destination, which receives and parses the ERSPAN packets generated from Cisco or other ERSPAN-capable switches. This setup could be used to analyze, diagnose, and detect malicious traffic.
Linux currently supports most features of two ERSPAN versions: v1 (type II) and v2 (type III).
Here is how to create an ERSPAN tunnel:
# ip link add dev erspan1 type erspan local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR seq key KEY erspan_ver 1 erspan IDX or # ip link add dev erspan1 type erspan local LOCAL_IPv4_ADDR remote REMOTE_IPv4_ADDR seq key KEY erspan_ver 2 erspan_dir DIRECTION erspan_hwid HWID Add tc filter to monitor traffic # tc qdisc add dev MONITOR_DEV handle ffff: ingress # tc filter add dev MONITOR_DEV parent ffff: matchall skip_hw action mirred egress mirror dev erspan1&lt;/p>
&lt;h2 id="summary">Summary&lt;a class="td-heading-self-link" href="#summary" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Here is a summary of all the tunnels we introduced.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Tunnel/Link Type&lt;/th>
&lt;th>Outer Header&lt;/th>
&lt;th>Encapsulate Header&lt;/th>
&lt;th>Inner Header&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ipip&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;td>None&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>sit&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;td>None&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ip6tnl&lt;/td>
&lt;td>IPv6&lt;/td>
&lt;td>None&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>vti&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;td>IPsec&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>vti6&lt;/td>
&lt;td>IPv6&lt;/td>
&lt;td>IPsec&lt;/td>
&lt;td>IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gre&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;td>GRE&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gretap&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;td>GRE&lt;/td>
&lt;td>Ether + IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ip6gre&lt;/td>
&lt;td>IPv6&lt;/td>
&lt;td>GRE&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ip6gretap&lt;/td>
&lt;td>IPv6&lt;/td>
&lt;td>GRE&lt;/td>
&lt;td>Ether + IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>fou&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;td>UDP&lt;/td>
&lt;td>IPv4/IPv6/GRE&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gue&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;td>UDP + GUE&lt;/td>
&lt;td>IPv4/IPv6/GRE&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>geneve&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;td>UDP + Geneve&lt;/td>
&lt;td>Ether + IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>erspan&lt;/td>
&lt;td>IPv4&lt;/td>
&lt;td>GRE + ERSPAN&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ip6erspan&lt;/td>
&lt;td>IPv6&lt;/td>
&lt;td>GRE + ERSPAN&lt;/td>
&lt;td>IPv4/IPv6&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Note&lt;/strong>: All configurations in this tutorial are volatile and won’t survive to a server reboot. If you want to make the configuration persistent across reboots, please consider using a networking configuration daemon, such as &lt;a href="https://developer.gnome.org/NetworkManager/stable/">NetworkManager&lt;/a>, or distribution-specific mechanisms.
_Also read: _&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/">Introduction to Linux interfaces for virtual networking&lt;/a>
&lt;em>Last updated: October 18, 2019&lt;/em>&lt;/p></description></item></channel></rss>