<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Message Queue(消息队列) on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><description>Recent content in Message Queue(消息队列) on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index.xml" rel="self" type="application/rss+xml"/><item><title>Kafka</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/</guid><description>概述 参考：
官网 Kafka 的 Consumer 在消费数据时，并不是把数据拿走，而是从队列里拿走一个副本。
可以配置队列保存数据的 最大时间、占用容量、etc. 。
每次执行 kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my_topic --from-beginning --property print.offset=true --max-messages 2 这类命令，都会创建一个临时的 Consumer，从头开始消费数据，输出的结果就是已消费的数据。
Kafka 原理详解 原文: https://mp.weixin.qq.com/s/Y0jYbDhs5ARbDbkrnA7Rjg
Kafka 是什么？ Kafka 是 Apache 旗下的一款分布式流媒体平台，Kafka 是一种高吞吐量、持久性、分布式的发布订阅的消息队列系统。它最初由 LinkedIn(领英)公司发布，使用 Scala 语言编写，与 2010 年 12 月份开源，成为 Apache 的顶级子项目。它主要用于处理消费者规模网站中的所有动作流数据。动作指(网页浏览、搜索和其它用户行动所产生的数据)。
消息系统分类 我们知道常见的消息系统有 Kafka、RabbitMQ、ActiveMQ 等等，但是这些消息系统中所使用的消息模式如下两种：
Peer-to-Peer (Queue) 简称 PTP 队列模式，也可以理解为点到点。例如单发邮件，我发送一封邮件给小徐，我发送过之后邮件会保存在服务器的云端，当小徐打开邮件客户端并且成功连接云端服务器后，可以自动接收邮件或者手动接收邮件到本地，当服务器云端的邮件被小徐消费过之后，云端就不再存储(这根据邮件服务器的配置方式而定)。
名词解释：
Producer=生产者
Queue=队列
Consumer=消费者
Peer-to-Peer 模式工作原理：
消息生产者 Producer1 生产消息到 Queue，然后 Consumer1 从 Queue 中取出并且消费消息。 消息被消费后，Queue 将不再存储消息，其它所有 Consumer 不可能消费到已经被其它 Consumer 消费过的消息。 Queue 支持存在多个 Producer，但是对一条消息而言，只会有一个 Consumer 可以消费，其它 Consumer 则不能再次消费。 但 Consumer 不存在时，消息则由 Queue 一直保存，直到有 Consumer 把它消费。 Publish/Subscribe（Topic） 简称发布/订阅模式。例如我微博有 30 万粉丝，我今天更新了一条微博，那么这 30 万粉丝都可以接收到我的微博更新，大家都可以消费我的消息。</description></item><item><title>Message Queue(消息队列)</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid><description>概述 参考：
场景一：日志采集系统，拿 Loki 举例，采集器(promtail)采集数据后，存储到后端日志存储器(Loki)上，当需要采集多个节点，并且当日志大量产生时， Loki 的处理很有可能会出现瓶颈而无法处理写入请求，这时候，我们就想要在 采集器 和 存储中间添加一个缓冲，来减慢后端存储的压力
而这就是 消息队列 的作用之一，采集器作为 MQ 的生产者，将日志数据传入队列，日志存储器作为 MQ 的消费者，从队列中逐步拿取日志数据并存储。有了这么一个缓冲，Loki 的压力将会得到很大缓和。
这时候可能还会有这种想法：我直接限制 采集器 的处理逻辑不好么，为什么还要中间再加一层东西，增加故障点。这是为了解耦，采集器的处理逻辑就是采集日志并上传，不要过多关注此行为之外的东西，这样一个产品才能快速迭代，更好的处理逻辑。
这种行为简称：消减波峰，保护后端(消费端)
场景二：现代的互联网应用大量地使用了消息队列（Messaging）。消息队列不仅被用于系统内部组件之间的通信，同时也被用于系统跟其它服务之间的交互。消息队列的使用可以增加系统的可扩展性、灵活性和用户体验。非基于消息队列的系统，其运行速度取决于系统中最慢的组件的速度（注：短板效应）。而基于消息队列可以将系统中各组件解除耦合，这样系统就不再受最慢组件的束缚，各组件可以异步运行从而得以更快的速度完成各自的工作。
总结：消息队列能够将业务逻辑解耦，调用方只需要下达命令而不用等待整个逻辑执行完毕。除此之外消息队列也可以抑制性能波峰的产生，在瞬时业务增长产生时保持性能曲线的平滑。
常见消息队列 RocketMQ
RabbitMQ
Kafka
ZeroMQ</description></item><item><title>NSQ 消息队列</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/NSQ-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/NSQ-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid><description>概述 参考：
GitHub 项目，nsqio/nsq 官网</description></item></channel></rss>