<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>性能优化 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><description>Recent content in 性能优化 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><item><title>性能优化</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>概述 参考：
《性能之巅：洞悉系统、企业与云计算》
《BPF之巅 洞悉Linux系统和应用性能》
性能优化的一点感触 原文链接：https://mp.weixin.qq.com/s/OXvQCPK1ZyM7yyfFzyFYBA
最近参与了几个项目的性能优化，总体来说各个项目都有所提升，能够满足用户使用需求，但是这个过程耗费了大量的人力、物力资源成本，主要原因有以下几点:
系统本身没有任何参数指标，这一点其实是大多数系统存在的问题，打个比方我作为乙方给甲方做了一个软件，交付完成后供甲方使用，这个系统的 TPS 是多少？硬件配置/用户矩阵是什么？系统可靠性 4 个 9 还是 2 个 9？你可能会说，我们的客户要求根本没有这么严格，能用就行，实则不然，如果说一年没问题，一年后客户的用户数量增长了一倍，忽然发现系统卡顿，几乎不能使用，客户找你算账，这该怎么办？谁的原因造成的&amp;hellip;.. 你说我们给自己公司做的产品，不要求这些东西，满足当前用户即可，那我现在问你，你的系统用户承载量是什么？当你真的出现用户数量激增，你该如何应对？ 框架标准化，如果一个企业中多个项目使用的框架五花八门，真正出现性能问题的时候，只能大家齐上阵，见招拆招，忙的不亦乐乎，其实收效甚微。 翻译需求，很多功能逻辑说不通，但又没法改，为什么？客户要求如此、产品经理设计如此，产品经理也已经不在了，原型设计文档找不到了，当然这种项目都是比较老的项目，很多公司都会存在此类问题。 灰度发布系统，深夜一群人呆在一起发布一个系统，一起处理 bug 真的是团队团结的表现吗?回家陪陪老婆孩子，好好休息，第二天的工作效率不是更高吗？ 如果现在让我做一个系统，我应该如何设计？趁着周六有时间就这四个问题简单聊聊，希望能够对大家的工作有所启发。
系统参数 你打开的汽车使用说明书，它会告诉你它在什么温度下可以正常工作、最高时速是多少、承客量多大&amp;hellip;&amp;hellip;如果出现问题，仪表盘会给出什么样提示，你应该如何规避这些故障。软件系统也一样，你的安装部署手册里要告诉别人你的系统需要多大内存、多少硬盘、什么规格的 CPU 来支撑多少用户量。设计文档的非功能性指标应该包含系统每秒处理事务数量（TPS）或查询数量是多少、安全性指标等级甚至支持用户数量；你的管理端界面或者监控系统应该告诉运维人员 CPU 占用量、内存占用量、硬盘使用情况、带宽使用；阈值告警参数，触发阈值产生告警，研发人员如何查看日志排除故障。 说的简单，这些指标从哪里得到呢？没有特别好的办法，只能通过压力测试、稳定性测试、安全性测试甚至平时的故障模拟中得到。 确实这些度量指标非常昂贵，甚至要超过你系统本身的成本，即便如此，你要去做，因为你不去量化一个系统，你就无法管理一个系统，可以想象一下你每天都是在闭着眼睛开车，你永远不知道您离灾难有多近。所以你要说服你的老板，抵挡住节省金钱的诱惑，认真对待系统指标数据。 当然完全做出这些东西到底有多复杂？我作为过来人认为并不复杂，而且能减轻不少后期工作量，想想一个系统不会所有的接口都对性能有要求，所以你只要评估出存在性能瓶颈的接口加以性能测试即可；另外性能测试脚本开发完成后都是复用的状态，所以不会产生太大工作量，而且又保证了每次上线之前都可以自动化验证部分接口，这不比人肉点点点香的多吗？ 另外像一些系统层面的参数指标，比如 Http 调用成功/失败情况、CPU、内存占用情况、告警等，可以搭建一套监控工具，比如 Prometheus 等。完成此类指标的获取。 如果说我的系统总共就几个人用、或者这种付出和收益完全成反比，那当我没说。
框架标准化 框架，通俗来说也就是我们产品/项目架构，就架构本身而言，一定先有设计目标，架构要去干什么样的事情，去完成一个购物网站还是一个管理平台，存在很大区别；根据设计目标，应该定义出设计原则，这也就是平时经常见到的控制反转、里氏替换、最小依赖、单一职责等原则，加上清晰的边界和实现价值（架构做什么，不做什么）；最后通过使用 Gof 总结出来 23 种设计模式加上算法就形成了一套框架。在这个框架的基础上就可以开发我们的应用。你可能会反驳我们项目五花八门，经常变动，一般架构很难满足，甚至架构需要经常改动，大概率是框架抽象定义的不够好，你看看你平时用到的 tomcat 框架、spring 框架，你感知到它的存在了吗？反而像早期 IBM 做的 weblogic、jboss 什么都做的重量级框架，已被抛弃，所以解耦和抽象再怎么强调都不为过。 定义好框架只是第一步，下面就是使用了，就目前国内情况而言，开源项目越来越火爆，所以基本上从网上找找，七拼八凑就行成了一套自己的框架，这本身而言也没有错误，极大降低企业框架定义的成本，但是一个框架通常只能解决某一类的问题，所以前期就需要架构人员进行反复编写代码进行测试和使用，得到这个框架自身的数据，而不是看见别人用的很好，别人多少数据量都可以轻易支撑起来，别人的使用场景很可能跟你不一样，要不然为啥市面充斥着五花八门的框架，大多数原因都不能从根本上解决自己的痛点问题。 接着架构人员要参与到编码中，发现问题及时更正和修改，引导开发人员如何划分模块，关键时刻做出示例，进而形成自己的开发规范，而不仅仅是站在一个指导者的角色，口头告诉程序员该如何使用，满足不了性能指标或者业务一团糟的时候开始考虑拆分，然后拆成几个微服务也是乱上加乱，根本不能从本质上解决问题。 总结来说，做架构首先要考虑的是自己的需求、目的及边界、原则、实现价值，最后才考虑技术实现和工具组件，而不是首先撸出一套框架生搬硬套，最后说程序员不会使用，代码写的太垃圾。
翻译需求 通常来说，一般是提出需求，架构人员进行架构设计，产品经理画出原型设计，开发人员开始设计、开发、提交测试交付。最后一个阶段看似已经定型，按照需求完成任务即可。但是人都会犯错，作为开发/测试人员不能对照原型、设计文档翻译需求，出现问题后，自豪的说，就是这样设计的，我也没办法，你找产品去。但是你有没有考虑过，即使产品人员改了改需求，最后你不还是照做，受伤的还是自己。所以我们在做任何一个功能的时候都要搞清楚问题的本质，事情的初衷。 你可能会反驳说，我的产品比较强势，他做的东西面向的是用户，开发人员是无法理解的，照着做就行了。但我觉着这些并不是理由，如果一个产品说用户要求的，你可以站在一个用户的角度去理解，如果是从数据角度，让他把数据拿出来，如果讲不明白，你完全可以拒绝，否则你做出来的东西肯定是四不像。所谓铁打的营盘，流水的兵，换了几波人之后完全无法理解这种逻辑，产品如何迭代。你要说你的产品功能过于复杂，大多数是产品设计就存在一定问题，你看看你常用的应用，那个不是简单易用。 为什么要对开发人员强调需求呢？因为你的需求做的不严谨，存在漏洞，都会给后期的性能、再次开发埋下祸根，而且这种问题，越往后解决成本越高。
灰度发布 相信大家面试的时候经常会听到面试官问这个问题, 如何保证一个系统高可用？如何做到不停机发布系统？答案也很简单，负载均衡，当然负载均衡也有很多种，有基于域名重定向、DNS、IP、数据链路层的负载均衡，你可以根据你服务自身情况，选择一种适合自己的。当然你会反驳我说，我的系统就一个副本，不要求高可用，那我会说，你敢白天上线吗？如果不敢，请乖乖做灰度发布（金丝雀、A/B、蓝绿等等）。 这并不是凭空增加大家的工作量，不知道大家认不认这样一个事实，软件发布通常遵循墨菲定律，往往不好的，一般情况下不会出现的问题，甚至没有想到的，都会在线上出现。要么人家都说运维人员都相信玄学，其实倒不是因为玄学，是因为存在未知。线上的用户、历史数据量往往最多的，也是最全面的，所以线上更容易复现一些问题。通过灰度发布部署多套，开发/测试人员完全可以在工作时间、站在用户的角度测试完成后上线发布。否则直接回退，即实现了测试，也没有影响用户使用。 灰度发布说简单也简单，最简单的你在你的 nginx 写几句 lua 脚本，便可以把包含特定标识的用户路由到特定服务。
总结 看完本文后，感觉会有点诧异，说的不是性能优化吗？不应该讲讲连接池配置多大、缓存如何使用、系统优化、硬件配置、甚至代码如何编写的一些技巧吗？怎么扯了一堆没用的。从某种程度上来说，软件的性能优化成本往往跟前期的软件设计成本反比，前期在设计上花费的时间越多，往往后期优化成本就越低。没有任何组织能够一开始就做一个高性能的软件系统，大多数都是随着用户和数据的增多演化而来。前期的性能指标、系统架构、甚至功能需求编写都能够为后期软件性能优化带来帮助。</description></item><item><title>Flame Graphs(火焰图)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Flame-Graphs%E7%81%AB%E7%84%B0%E5%9B%BE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Flame-Graphs%E7%81%AB%E7%84%B0%E5%9B%BE/</guid><description>概述 参考：
GitHub 项目，brendangregg/FlameGraph 官方文档 论文 https://www.ruanyifeng.com/blog/2017/09/flame-graph.html
https://zhuanlan.zhihu.com/p/73385693
可以生成火焰图的工具：
perf 性能分析工具 前言 在没有读《性能之巅》这本书之前，就听说过火焰图。当时学习同事用 go 写的项目代码，发现里边有个文件夹叫火焰图，觉得名字很好玩，就百度了一下，惊叹还有这种操作。不过当时并没有听过 Brendan Gregg 的大名，因为懒也没有深入学习。这次找到了 Brendan Gregg 的 blog，也了解了一点动态追踪技术的知识，决心要好好学习一下。
于是就找到了一切开始的地方： Brendan Gregg 写的论文《The Flame Graph 》
作为一个英语菜鸡，从来都没有读过英文论文。正好借这次机会尝试一下，看能不能点个新的技能点。结果尝试才发现，真的好难～～刚开始，读一小段就开始犯困。于是坚持每天强迫自己从头开始重读一遍。花了差不多一周时间，总算能集中注意力的读完。
然后我就想，老是吐槽各种汉化的国外优秀的技术书籍生涩难懂，何不亲自试一试呢？于是就有了今天的这篇学习笔记。
火焰图 让软件执行情况可视化，是性能分析、调试的利器 Brendan Gregg, Netflix
日常工作中，我们需要理解软件对系统资源的使用情况。比如对于 cpu，我们想知道当前软件究竟使用了多少 cpu？软件更新以后又变化了多少？剖析器(profilers)可以用来分析这样的问题，帮助软件开发者优化代码，指导软件使用者调优运行环境。但是 profile 通常都很长，太长的输出分析和理解起来都很不方便。火焰图作为一种新的 profile 可视化方式，可以让我们更直观，更方便的理解、分析问题。
在像“Netflix 云微服务架构”这种软件升级迭代迅速的环境中，快速理解 profiles 尤为重要。同时，对 profile 的快速的理解也有助于我们更好的研究其他人编写的软件。
火焰图可以用多种 profilers（包括资源和系统事件）的输出生成，本文以 cpu 为例，介绍了火焰图的用法以及其可以解决的各种实际问题。
profile 的理解 profile 有 剖面、剖面图 的含义，对于医学角度来说，如果不解剖看剖面图，也就无法看到一个生物内部的运行情况。同理，在性能分析领域，想要理解一个程序，也需要解剖它，看看它的剖面图。所以，profile 就可以理解为一个应用程序的 剖面图。只有看到剖面图，才能深入程序内部一探究竟
CPU Profiling CPU 分析的一种常用技术是，使用像 Linux perf_events 和 DTrace 之类系统追踪工具的对 stack traces 进行采样。stack trace 显示了代码的调用关系，比如下面的 stack trace ,每个方法作为一行并按照父子关系从下到上排序。</description></item><item><title>SLI/SLO</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/SLI_SLO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/SLI_SLO/</guid><description>概述 参考：
公众号，通过 Prometheus 来做 SLI/SLO 监控展示 什么是 SLI/SLO SLI，全名 Service Level Indicator，是服务等级指标的简称，它是衡定系统稳定性的指标。
SLO，全名 Sevice Level Objective，是服务等级目标的简称，也就是我们设定的稳定性目标，比如&amp;quot;4 个 9&amp;quot;，&amp;ldquo;5 个 9&amp;quot;等。
SRE 通常通过这两个指标来衡量系统的稳定性，其主要思路就是通过 SLI 来判断 SLO，也就是通过一系列的指标来衡量我们的目标是否达到了&amp;quot;几个 9&amp;rdquo;。
如何选择 SLI 在系统中，常见的指标有很多种，比如：
系统层面：CPU 使用率、内存使用率、磁盘使用率等 应用服务器层面：端口存活状态、JVM 的状态等 应用运行层面：状态码、时延、QPS 等 中间件层面：QPS、TPS、时延等 业务层面：成功率、增长速度等 这么多指标，应该如何选择呢？只要遵从两个原则就可以：
选择能够标识一个主体是否稳定的指标，如果不是这个主体本身的指标，或者不能标识主体稳定性的，就要排除在外。 优先选择与用户体验强相关或用户可以明显感知的指标。 通常情况下，可以直接使用谷歌的 VALET 指标方法。
V：Volume，容量，服务承诺的最大容量 A：Availability，可用性，服务是否正常 L：Latency，延迟，服务的响应时间 E：Error，错误率，请求错误率是多少 T：Ticket，人工介入，是否需要人工介入 这就是谷歌使用 VALET 方法给的样例。
上面仅仅是简单的介绍了一下 SLI/SLO，更多的知识可以学习《SRE：Google 运维解密》和赵成老师的极客时间课程《SRE 实践手册》。下面来简单介绍如何使用 Prometheus 来进行 SLI/SLO 监控。
service-level-operator Service level operator 是为了 Kubernetes 中的应用 SLI/SLO 指标来衡量应用的服务指标，并可以通过 Grafana 来进行展示。</description></item></channel></rss>