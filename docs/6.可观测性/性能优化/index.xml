<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – 性能优化</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><description>Recent content in 性能优化 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Flame Graphs(火焰图)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Flame-Graphs%E7%81%AB%E7%84%B0%E5%9B%BE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Flame-Graphs%E7%81%AB%E7%84%B0%E5%9B%BE/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/brendangregg/FlameGraph">GitHub 项目，brendangregg/FlameGraph&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.brendangregg.com/flamegraphs.html">官方文档&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://queue.acm.org/detail.cfm?id=2927301">论文&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://www.ruanyifeng.com/blog/2017/09/flame-graph.html">https://www.ruanyifeng.com/blog/2017/09/flame-graph.html&lt;/a>
&lt;a href="https://zhuanlan.zhihu.com/p/73385693">https://zhuanlan.zhihu.com/p/73385693&lt;/a>&lt;/p>
&lt;p>可以生成火焰图的工具：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux%20%E7%AE%A1%E7%90%86/Linux%20%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/perf%20%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/perf%20%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7.md">perf 性能分析工具&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="前言">前言&lt;a class="td-heading-self-link" href="#%e5%89%8d%e8%a8%80" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>在没有读《性能之巅》这本书之前，就听说过火焰图。当时学习同事用 go 写的项目代码，发现里边有个文件夹叫火焰图，觉得名字很好玩，就百度了一下，惊叹还有这种操作。不过当时并没有听过 Brendan Gregg 的大名，因为懒也没有深入学习。这次找到了 Brendan Gregg 的 blog，也了解了一点动态追踪技术的知识，决心要好好学习一下。
于是就找到了一切开始的地方： Brendan Gregg 写的论文《&lt;a href="https://link.zhihu.com/?target=https%3A//queue.acm.org/detail.cfm%3Fid%3D2927301">The Flame Graph&lt;/a> 》
作为一个英语菜鸡，从来都没有读过英文论文。正好借这次机会尝试一下，看能不能点个新的技能点。结果尝试才发现，真的好难～～刚开始，读一小段就开始犯困。于是坚持每天强迫自己从头开始重读一遍。花了差不多一周时间，总算能集中注意力的读完。
然后我就想，老是吐槽各种汉化的国外优秀的技术书籍生涩难懂，何不亲自试一试呢？于是就有了今天的这篇学习笔记。&lt;/p>
&lt;h1 id="火焰图">火焰图&lt;a class="td-heading-self-link" href="#%e7%81%ab%e7%84%b0%e5%9b%be" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="让软件执行情况可视化是性能分析调试的利器">让软件执行情况可视化，是性能分析、调试的利器&lt;a class="td-heading-self-link" href="#%e8%ae%a9%e8%bd%af%e4%bb%b6%e6%89%a7%e8%a1%8c%e6%83%85%e5%86%b5%e5%8f%af%e8%a7%86%e5%8c%96%e6%98%af%e6%80%a7%e8%83%bd%e5%88%86%e6%9e%90%e8%b0%83%e8%af%95%e7%9a%84%e5%88%a9%e5%99%a8" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Brendan Gregg, Netflix
日常工作中，我们需要理解软件对系统资源的使用情况。比如对于 cpu，我们想知道当前软件究竟使用了多少 cpu？软件更新以后又变化了多少？剖析器(profilers)可以用来分析这样的问题，帮助软件开发者优化代码，指导软件使用者调优运行环境。但是 profile 通常都很长，太长的输出分析和理解起来都很不方便。火焰图作为一种新的 profile 可视化方式，可以让我们更直观，更方便的理解、分析问题。
在像“Netflix 云微服务架构”这种软件升级迭代迅速的环境中，快速理解 profiles 尤为重要。同时，对 profile 的快速的理解也有助于我们更好的研究其他人编写的软件。
火焰图可以用多种 profilers（包括资源和系统事件）的输出生成，本文以 cpu 为例，介绍了火焰图的用法以及其可以解决的各种实际问题。&lt;/p>
&lt;h3 id="profile-的理解">profile 的理解&lt;a class="td-heading-self-link" href="#profile-%e7%9a%84%e7%90%86%e8%a7%a3" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>profile 有 剖面、剖面图 的含义，对于医学角度来说，如果不解剖看剖面图，也就无法看到一个生物内部的运行情况。同理，在性能分析领域，想要理解一个程序，也需要解剖它，看看它的剖面图。所以，&lt;strong>profile 就可以理解为一个应用程序的 剖面图&lt;/strong>。只有看到剖面图，才能深入程序内部一探究竟~~~&lt;/p>
&lt;h2 id="cpu-profiling">CPU Profiling&lt;a class="td-heading-self-link" href="#cpu-profiling" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>CPU 分析的一种常用技术是，使用像 Linux perf_events 和 DTrace 之类系统追踪工具的对 stack traces 进行采样。stack trace 显示了代码的调用关系，比如下面的 stack trace ,每个方法作为一行并按照父子关系从下到上排序。&lt;/p>
&lt;pre>&lt;code>SpinPause
StealTask::do_it
GCTaskThread::run
java_start
start_thread
&lt;/code>&lt;/pre>
&lt;p>综合考虑采样成本、输出大小、应用环境，CPU profile 有可能是这样收集：对所有的 cpu，对 stack traces 以每秒 99 次的速度，连续采样 30 秒（使用 99 而不是 100，是为了防止采样周期与某些系统周期事件重合，影响采样结果）。对于一个 16 核的机器来说，输出结果可能会有 47520 个堆栈采样。可能会输出成千上万行文本。（ps:原文是 not 100, to avoid lock-step sampling 理解不了，所以按照书中的描述写的）
有些 profile 可以压缩输出，比如 DTrace，可以把相同的 stack traces 汇总到一起，只输出次数。这个优化还是蛮有用的，比如长时间的 for 循环，或者系统 idle 状态的 stack traces，都会被简化成一个。
Linux perf_events 还可以进一步压缩输出，通过合并相同的 substack，使用树形结构汇总输出。对于树的每个分枝，都可以统计 count 或百分比。如图一所示：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684402-a78901d6-3770-4ff9-90d9-3089acd9510c.jpeg" alt="">&lt;/p>
&lt;p>实际上，perf_events 和 DTrace 的输出，在很多情况下，足够分析问题使用了。但是也有时候，面对超长的输出，就像面对一堵写满字的高墙，分析其中某个堆栈就好比盲人摸象、管中窥豹。&lt;/p>
&lt;h3 id="the-problem">The Problem&lt;a class="td-heading-self-link" href="#the-problem" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>为了分析“the Joyent public cloud”的性能问题，我们发明了火焰图。问题简单描述就是:某台服务器上部署了一个 mysql 服务，该服务的 cpu 使用率比预期的情况高了 40%。
我们使用 DTrace，以 997 Hz 的频率连续采样 stack traces 60 秒，尽管 DTrace 对输出进行了压缩，输出还是有 591622 行，包括 27053 个 stack traces，图二展示了输出结果，屏幕最下方显示的是调用最频繁的方法，说不定是问题的关键。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684447-cc99cf85-c6e5-415f-995c-56ed19002211.jpeg" alt="">&lt;/p>
&lt;p>最频繁的方法是&lt;code>calc_sum_of_all_status()&lt;/code>,这个方法在执行 mysql 命令&lt;code>show status&lt;/code>时被调用。也许有个客户端在疯狂执行这个命令做监控？
为了证明这个结论，用该方法采样的次数 5530，除以总的采样次数 348427。算出来这个方法只占用了 1.6%,远远不到 40%。看来得继续分析 profile。
如果继续按照调用频度，一个一个分析 stack traces，完全是一项体力劳动。看下图三就知道这是一项多么庞大的工作量。缩放以后，整个 DTrace 输出就像一个毫无特征的灰色图片。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684409-cdd3aff2-75f7-47b6-9ed4-08b6df33d4ed.jpeg" alt="">
这简直是不可能完成的任务！那么，有没有更好的方法呢？
为了充分利用 stack traces 层次的特性，我发明了一种可视化原型，如图四所示，展示了跟图三相同的信息。图片之所以选择暖色调，是因为这种原型解释了为什么 cpu 很“hot”，也正是因为暖色调和火焰一样的形状。这种原型被命名为“火焰图”。（可交互的 svg 格式的图 4 可以在&lt;a href="https://link.zhihu.com/?target=http%3A//queue.acm.org/downloads/2016/Gregg4.svg">http://queue.acm.org/downloads/2016/Gregg4.svg&lt;/a> 体验）
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684411-236cd7fb-6362-4a8a-a78f-9a0d7256f2f0.jpeg" alt="">
使用火焰图可以很快的找到 profile 的主体部分，图片显示之前找到的 MySQL status 命令，只占 profile 的 3.28%，真正的大头是含有&lt;code>join&lt;/code>的 mysql 语句。顺着这个线索，我们找到了根本问题，解决以后，cpu 使用率下降了 40%。&lt;/p>
&lt;h3 id="flame-graphs-explained">Flame Graphs Explained&lt;a class="td-heading-self-link" href="#flame-graphs-explained" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>火焰图用相邻的 diagram 代表一堆 stack traces 。diagram 的形状像是一个倒着的冰锥 &lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684456-a7bde9ca-6bbf-459f-8fa6-6ccf8bf48044.svg" alt=""> 。这个冰锥一样的图形通常用来描述 cpu profile。
火焰图有以下特征：
• 一列 box 代表一个 stack trace，每个 box 代表一个 stack frame。
• y 轴显示了栈的深度，按照调用关系从下到上排列。最顶上的 box 代表采样时，on-CPU 的方法。每个 box 下边是该方法的调用者，以此类推。
• x 轴代表了整个采样的范围，注意 x 轴并不代表时间，所有 box 按照方法名称的字母顺序排列，这样的好处是，相同名称的 box，可以合并为一个。
• box 的宽度代表了该方法在采样中出现的频率。该频率与宽度成比例。
• 如果 box 很长，会显示完整的方法名称，如果很短，只会显示省略号或者 nothing。
• box 的颜色是随机选择的暖色调，这样有助于肉眼区分细长的塔状 boxes。当然也有其他配色方案，后面再说。
• profile 有可能是单线程、多线程、多应用甚至是多 host 的，如果需要，可以分解成子图。
• 还有很多其他的采样方式，box 的宽度除了频率以外，还可以表示多种其他的含义。比如 off-cpu 火焰图中，x 轴的宽度代表方法 block 的时间。
使用火焰图，整个 profile 一目了然，可以方便的定位到感兴趣的位置。火焰图成了软件执行情况的导航图。
除了这种可交互的展示方式，火焰图也可以方便的保存为静态图片的格式，方便打印出来。&lt;/p>
&lt;h3 id="interactivity">Interactivity&lt;a class="td-heading-self-link" href="#interactivity" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>火焰图可以支持交互功能，可以显示更多细节、改进导航和执行计算。
原生的火焰图使用嵌入式 javascript 生成一张可交互的 svg 图片，提供了三种交互特性：鼠标 hover 显示详情、点击缩放和搜索。
&lt;strong>hover 显示详情&lt;/strong>
当鼠标 hove 到 box 上，tooltip 内和图片左下方会显示方法的 full name，该方法的采样数量，以及百分比。格式如下：&lt;/p>
&lt;pre>&lt;code>Function: mysqld'JOIN::exec (272,959 samples, 78.34 percent).
&lt;/code>&lt;/pre>
&lt;p>hover 这项特性有助于用户查看很窄的 box，显示百分比能够帮助用户量化代码路径的资源使用率，指导用户找到代码中急需优化的部分。
&lt;strong>点击缩放&lt;/strong>
当用户点击一个 box 时，火焰图水平缩放，以显示局部的细节信息。该 box 下方的父 box 颜色变淡，表示只有部分被展示。点击 reset zoom 可以回到全局视图。
&lt;strong>搜索&lt;/strong>
点击 search 或者按 ctrl+f 来使用搜索功能。搜索功能支持正则表达式，所有命中的 box 会被高亮并被显示为紫色。同时，图片右下角会显示命中方法的总百分比。如图五所示。（可交互的图五可以在这里体验： &lt;a href="https://link.zhihu.com/?target=http%3A//queue.acm.org/downloads/2016/Gregg5.svg">http://queue.acm.org/downloads/2016/Gregg5.svg&lt;/a>.）
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684408-74db187a-b473-40ed-9232-ca926f24b102.jpeg" alt="">
搜索不仅可以方便定位方法，还可以高亮逻辑上相关的一组方法。比如输入&amp;quot;^ext4_&amp;ldquo;显示所有跟 linux ext4 文件系统相关的方法。
有时候，多个代码路径都以相同的热点函数（比如自旋锁）结束，如果这些方法分布在图片 20 多个位置上，汇总他们的百分比就很麻烦。搜索功能可以解决这个问题。&lt;/p>
&lt;h3 id="instructions">Instructions&lt;a class="td-heading-self-link" href="#instructions" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>火焰图有很多实现，原生的火焰图使用 Perl 编写，并且开放源码。包括采样在内，生成一张火焰图总共分三步：&lt;/p>
&lt;ol>
&lt;li>用户采样 stack traces (比如使用 Linux perf_events、DTrace 或者 Xperf)。&lt;/li>
&lt;li>将采样输出压缩为指定格式。我们已经编写了很多 perl 脚本处理各种 profiler 的输出。在项目中以&amp;quot;stackcollapse&amp;quot;前缀命名。&lt;/li>
&lt;li>使用 flamegraph.pl 生成火焰图. 该脚本使用 javascript 解析前边步骤的输出生成最终输出。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>指定压缩格式&lt;/strong>指的是：把一个 stack traces 展示为一行，栈帧之间使用分号间隔，并在末尾的空格之后显示采样数量。应用名称，进程 id 之类的信息，可以用“.”分隔以后， 补充在 stack traces 之前。增加这些信息以后，生成的火焰图中，会按照这些前缀进行分组。
比如说，假如 profile 包含下面三个 stack traces:&lt;/p>
&lt;pre>&lt;code>func_c func_b func_a start_thread
func_d func_a start_thread
func_d func_a start_thread
&lt;/code>&lt;/pre>
&lt;p>压缩为指定格式以后，是这个样子的:&lt;/p>
&lt;pre>&lt;code>start_thread;func_a;func_b;func_c 1
start_thread;func_a;func_d 2
&lt;/code>&lt;/pre>
&lt;p>如果把应用名称（比如：java）也加在里面，则是：&lt;/p>
&lt;pre>&lt;code>java;start_thread;func_a;func_b;func_c 1
java;start_thread;func_a;func_d 2
&lt;/code>&lt;/pre>
&lt;p>设计这种中间格式的好处是，如果出现了新的 profiler，只需要编写转换器就可以使用火焰图。目前已经有 DTrace、perf_events、FreeBSD pmcstat, Xperf, SystemTap, Xcode Instruments, Intel VTune, Lightweight Java Profiler, Java jstack, and gdb 这么多可用的转换器。
flamegraph.pl 支持一些用户选项，比如说更改火焰图的 title。
下面是从采样（使用 perf ）到生成图片的一个具体的例子:&lt;/p>
&lt;pre>&lt;code># git clone https://github.com/brendangregg/FlameGraph
# cd FlameGraph
# perf record -F 99 -a -g -- sleep 60
# perf script | ./stackcollapse-perf.pl | ./flamegraph.pl &amp;gt; out.svg
&lt;/code>&lt;/pre>
&lt;p>因为中间格式每个记录一行，在生成火焰图之前可以使用 grep/sed/awk 进行修改。使用其他 profiler 的教程参见&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/brendangregg/FlameGraph">官方文档&lt;/a>。&lt;/p>
&lt;h3 id="flame-graph-interpretation">Flame Graph Interpretation&lt;a class="td-heading-self-link" href="#flame-graph-interpretation" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>如何分析生成的火焰图:
• 火焰图顶部显示了采样过程中 on CPU 的方法。对 CPU profiles，这些方法直接占用 cpu 资源。对于其他的 profile，这些方法导致了相关的内核事件。
• 在火焰图顶部寻找“高原”状的方法，位于顶部的某个很宽的方法，表示其在采样中大量出现。对于 CPU profiles，这意味着这个方法经常在 CPU 上运行。
• 自顶向下看显示了调用关系，上边的方法被其下方的方法调用，以此类推。快速的从上往下浏览可以理解某个方法为什么被调用。
• 自底向上看显示了代码逻辑，提供了程序的全局视图。底部的方法会调用其顶部的多个方法，以此类推。自底向上看可以看到代码的分支形成的多个小型的“塔尖”。
• box 的宽度可以用来比较，更宽的 box 意味着在采样结果中更多的比例。
• 对于 cpu profiles 来说，如果 a 方法比 b 方法宽，有可能是因为 a 方法本身执行需要使用比 b 方法更多的 cpu。也有可能是 a 方法被调用的次数比 b 方法更频繁。采样的最终结果并不能体现一个方法被调用多少次，所以这两种情况都有可能。
• 如果一个方法顶部出现了两个“大塔尖”，导致火焰图中出现一个“大分叉”，这样的方法很值得研究。两个“塔尖”可能是被调用的两个子方法，也可能是条件语句的两个不同分支。&lt;/p>
&lt;h3 id="interpretation-example">Interpretation Example&lt;a class="td-heading-self-link" href="#interpretation-example" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>为了更直观的让大家理解火焰图的含义，下面以图六作为例子。这是使用 cpu profile 生成的一张火焰图。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684422-6c4e4abe-767b-4f3c-b725-b0380038f19a.jpg" alt="">
图片顶部显示说明&lt;code>g()&lt;/code>使用 cpu 最频繁；虽然&lt;code>d()&lt;/code>很宽，但是该方法直接使用 cpu 最少。&lt;code>b()&lt;/code>和&lt;code>c()&lt;/code>并不直接使用 cpu 资源，而他们的子方法使用。
&lt;code>g()&lt;/code>底部的方法显示了调用关系：&lt;code>g()&lt;/code>被&lt;code>f()&lt;/code>调用,&lt;code>f()&lt;/code>被 &lt;code>d()&lt;/code>调用,以此类推。
对比&lt;code>b()&lt;/code> 和&lt;code>h()&lt;/code>的宽度可以发现，&lt;code>b()&lt;/code>对 cpu 的使用率是&lt;code>h()&lt;/code>的 4 倍。真正在 cpu 上执行的是他们的子方法。
该图的主分支是&lt;code>a()&lt;/code> 调用了 &lt;code>b()&lt;/code> 和 &lt;code>h()&lt;/code>,原因有可能是&lt;code>a()&lt;/code>中存在条件分支（比如一个 if 语句，如果为 true 执行&lt;code>b()&lt;/code>,反之执行&lt;code>h()&lt;/code>）,也有可能&lt;code>a()&lt;/code>分成了两个步骤&lt;code>b()&lt;/code>和&lt;code>h()&lt;/code>。&lt;/p>
&lt;h3 id="other-code-path-visualizations">Other Code-Path Visualizations&lt;a class="td-heading-self-link" href="#other-code-path-visualizations" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>正如图一所示，&lt;strong>Linux perf_events&lt;/strong> 使用树形结构展示 cpu 使用率，这是另一种层级可视化方式。与火焰图相比，该方法并不能提供直观的全局视图。
&lt;strong>KCacheGrind&lt;/strong> 使用有向无环图实现可视化，使用宽度自适应的 box 表示方法，使用箭头表示调用关系，box 和箭头上都标注了百分比。与 Linux perf_events 一样，图片缩小以后，也很难提供全局信息。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684440-0ff268f5-3021-473d-aeaf-6fa1d4b5c051.jpeg" alt="">
&lt;strong>sunburst&lt;/strong>布局跟火焰图的冰锥布局很像。不同的是 sunburst 使用了极坐标。sunburst 生成的图形很漂亮，但是却并不利于理解。与角度大小相比，人们更容易区分宽度。所以在直观性上火焰图更胜一筹 &lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684460-0fa7cc81-0b41-49df-9df3-c52c3dc2c7a9.svg" alt=""> 。
&lt;strong>Flame charts&lt;/strong>灵感来源于火焰图，是跟火焰图相似的可视化方式。区别是，x 轴并不是按照字母表的顺序排列，而是按照时间百分比排序。这样做的优势是：很容易发现时间相关的问题。但同时，缺点也很明显，这种排序减少了方法的合并，当分析多个线程时，劣势更加明显。Flame charts 跟火焰图一起使用应该会更有用。&lt;/p>
&lt;h3 id="challenges">Challenges&lt;a class="td-heading-self-link" href="#challenges" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>火焰图面临的挑战，更多是来自于 profilers，而不是火焰图本身。profilers 会面对两类典型的问题：
• &lt;strong>Stack traces 不完整&lt;/strong>。
有些 profiler 只提供固定深度（比如 10）的采样，这种不完整的输出不利于分析，如果增大深度，这些 profiler 会直接失败。更糟糕的问题是有些编译器会使用“&lt;strong>重用帧指针寄存器&lt;/strong>（frame pointer register）”这样的编译优化，破坏了标准 Stack traces 采样流程。解决方式是关闭这种编译器优化（比如 gcc 使用参数 &lt;code>-fno-omit-frame-pointer&lt;/code>）或者使用另一种采样技术。
• &lt;strong>方法名称丢失&lt;/strong>。
有些 profilers，堆栈信息是完整的，但是方法名称却丢失了，显示为十六进制地址。使用了&lt;strong>JIT&lt;/strong> (just-in-time) 技术编译的代码经常有这个问题。因为 JIT 并不会为 profiler 创建符号表。对于不同的 profiler 和 runtime，这个问题有不同的解决方式，比如 Linux perf_events 允许应程序提供一个额外的符号表文件，用于产生采样结果。
我们在 Netflix 的工作过程中，曾经尝试为 Java 生成火焰图，结果两个问题都遇到了 &lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684464-4d4fe494-900b-49a2-8435-567c5510f0f0.svg" alt=""> 。第一个问题通过一个新的 jvm 参数：&lt;code>—XX:+PreserveFramePointer&lt;/code>解决了。该参数禁用了编译器优化。第二个问题由 perf-map-agent 解决，这个 Java agent 可以为 profiler 生成符号表。
火焰图面临的另一个挑战是生成 SVG 文件的大小。一个超大的 profile 有可能会有成千上万的 code paths，最终生成的 svg 可能有几十 mb,浏览器加载要花费比较长的时间。解决方式是忽略掉在途中细到肉眼难以观察的方法，忽略这些方法不会影响全局视图，同时能缩小输出。&lt;/p>
&lt;h3 id="other-color-schemes">Other Color Schemes&lt;a class="td-heading-self-link" href="#other-color-schemes" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>除了使用随机的暖色调外，火焰图支持其他配色方案，比如使用颜色区分代码或者数据维度。
Perl 版本的火焰图支持很多配色选项，其中一个选项是&lt;strong>java&lt;/strong>。该选项通过不同颜色区分模块，规则如下：绿色代表 Java，黄色为 C++，红色用于所有其他用户代码，橙色用于内核模块。见图七（可交互的 svg 格式的图 7 可以在&lt;a href="https://link.zhihu.com/?target=http%3A//queue.acm.org/downloads/2016/Gregg7.svg">http://queue.acm.org/downloads/2016/Gregg7.svg&lt;/a> 体验）。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684510-3f8c57a8-1f07-4361-936b-1539013e1dfb.jpeg" alt="">
另一个可用的选项是&lt;strong>hash&lt;/strong>，该选项根据函数名的 hash 选择颜色，这个选项在比较多张火焰图的时候非常有用，因为在不同的图片上，相同的方法会用相同的颜色表示。
颜色选项对于“差分火焰图”也很重要，“差分火焰图”将在下一节中介绍。&lt;/p>
&lt;h3 id="differential-flame-graphs">Differential Flame Graphs&lt;a class="td-heading-self-link" href="#differential-flame-graphs" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>差分火焰图显示了两个 profile 的区别。比如现在有两个 profile A 和 B，Perl 版本的火焰图支持这样的操作：以 A 为基准，使用 B 与 A 的差值生成一张火焰图。在差分火焰图上，红色代表差值为正数，蓝色代表差值为负数。这种差分图的问题是，如果 A 中的某个方法，在 B 中完全没有被调用，差分图就会把这种方法丢弃。丢失的数据会误导用户。
一种改进的方法是&lt;code>flamegraphdiff&lt;/code>，使用三张图解决这个问题。第一张是 A,第二张是 B，第三张是前边提到的差分图。当鼠标 hover 到任意一个方法时，三张图上该方法都会高亮显示。同时 flamegraphdiff 也支持红/蓝的配色方案说明百分比的增减。&lt;/p>
&lt;h3 id="other-targets">Other Targets&lt;a class="td-heading-self-link" href="#other-targets" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>前边提到，火焰图可以可视化多种 profiler 的输出。profiler 有以下几种：CPU PMC (performance monitoring counter) 溢出事件, 静态追踪（static tracing） 事件, 动态追踪（dynamic tracing） 事件。下面是一些其他 profiler 的例子.
&lt;strong>Stall Cycles&lt;/strong>
tall-cycle 火焰图显示被处理器或硬件资源（通常是内存 I/O）block 的代码路径。stack trace 使用 PMC profiler, 比如 Linux perf_events 采集，分析这样的火焰图，开发人员可以使用其他策略优化代码，优化的目的是减少内存 I/O，而不是减少指令。
&lt;strong>CPI&lt;/strong>
CPI(cycles per instruction)指令每周期数, 或者其倒数 IPC 可以描述 cpu 的使用情况。cpi 火焰图用宽度表示采样 cpu 周期数，同时用颜色区分每个函数的 cpi：红色表示高 cpi，蓝色表示低 cpi。cpi 火焰图需要两个 profile：CPU 采样 profile 和 指令数量 profile，使用差分火焰图技术生成。
&lt;strong>Memory&lt;/strong>
火焰图可以通过可视化许多不同的内存事件来揭示内存增长。
通过跟踪 malloc() 方法可以生成 malloc 火焰图，用于可视化申请内存的代码路径。这个方案可能很难应用与实践，因为 malloc 函数调用很频繁，使得在某些场景中跟踪它们的成本很高。
通过跟踪 brk()和 mmap()方法可以展示导致虚拟内存中的扩展的代码路径。当然如果异步的申请内存就另当别论了。这些方法调用频率很低，很适合追踪。
跟踪内存缺页异常可以展示导致物理内存中的扩展的代码路径。导致内存缺页的代码路径通常会频繁的申请内存。内存缺页异也是低频事件。
&lt;strong>I/O&lt;/strong>
与 io 相关的问题，比如文件系统，存储设备和网络，通常可以使用 system tracers 方便的追踪。使用这类 profiles 生成的火焰图显示了使用 I/O 的代码路径。
在实践中，io 火焰图可以定位导致 io 的原因。比如一个磁盘 io 可能由以下事件引起：应用程序发起系统调用，文件系统预读，异步的脏数据 flush，或者内核异步的磁盘清理。通过火焰图上的代码路径可以区分以上导致磁盘 io 的事件类型。
&lt;strong>Off-CPU&lt;/strong>
当然，也有许多问题使用上边提到的火焰图是看不见的。分析这些问题需要了解线程被阻塞（而不是 on cpu）的时间。线程阻塞的原因有很多，比如等待 I/O、锁、计时器、打开 CPU 以及等待分页或交换。追踪线程被重新调度时的 stack traces 可以区分这些原因，线程 block 的时间长度可以通过跟踪线程从离开 CPU 到返回 CPU 的时间来测量。系统 profilers 通常使用内核中的静态跟踪点来跟踪这些事件。
通过上边 profile 可以生成 Off-CPU 火焰图用来分析这类问题 &lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/hxnw7s/1619535684469-02f3f063-04fb-4a64-8b07-c845e66b25f8.svg" alt=""> 。
&lt;strong>Wakeups&lt;/strong>
在 Off-CPU 火焰图的应用中发现这样一个问题：当线程阻塞的原因是条件变量时，火焰图很难解答“为什么条件变量被其他线程持有这么长时间”这样的问题。
通过跟踪线程唤醒事件，可以生成 Wakeups 火焰图。该图显示了线程阻塞的原因。Wakeups 火焰图可以与 Off-CPU 火焰图一起研究，以获得关于阻塞线程的更多信息。
&lt;strong>Chain Graphs&lt;/strong>
持有条件变量的线程可能已在另一个条件变量（由另一个线程持有）上被阻塞。实际上，一个线程可能被第二个、第三个甚至第四个线程阻塞。对于这种复杂场景，只分析一个 wakeup 火焰图可能还不够。
chain 火焰图是分析这种复杂场景的一种尝试，chain 火焰图从 off-CPU 火焰图为基础，将 Wakeups 火焰图放到每个 stack traces 顶部。通过自顶向下的分析可以理解阻塞线程的整个条件变量链路。宽度对应线程 block 的时间。
chain 火焰图可以通过组合 Off-CPU 火焰图 U 和 Wakeups 火焰图来实现。这需要大量的采样，目前来看，在实际应用中不太现实。&lt;/p>
&lt;h3 id="future-work">Future Work&lt;a class="td-heading-self-link" href="#future-work" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>与火焰图相关的许多工作，都涉及到不同的 profiler 与不同的 runtimes（例如，对于 NoDE.JS、Ruby、Perl、Lua、Erlang、Python、Java、Gangangand，以及 dTrof、PrimeEvices、PMCSTAT、Xperf、仪器）。等等）。将来可能会增加更多种类。
另一个正在开发的差分火焰图，称为白/黑差分，使用前面描述的单火焰图方案加上右侧的一个额外区域，用来显示丢失的代码路径。差分火焰图（任何类型）在未来也会得到更多的应用；在 Netflix，我们正在努力让微服务每晚生成这些图：用来帮助进行性能问题分析。
其他几个火焰图实现正在开发中，探索不同的特性。比如：bla bla bla&amp;hellip;bla bla bla&amp;hellip;&lt;/p>
&lt;h3 id="conclusion">Conclusion&lt;a class="td-heading-self-link" href="#conclusion" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>火焰图是堆栈跟踪的可视化的高效工具，支持 CPU 以及许多其他 profile。它创建了软件执行情况的可视地图，并允许用户导航到感兴趣的区域。与其他可视化技术相比，火焰图更直观的传递信息，在处理超大 profile 是优势明显。火焰图作为理解 profile 的基本工具，已经成功分析解决了无数的性能问题。&lt;/p>
&lt;h3 id="acknowledgments">Acknowledgments&lt;a class="td-heading-self-link" href="#acknowledgments" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>bla bla bla&amp;hellip;bla bla bla&amp;hellip;&lt;/p>
&lt;h3 id="references只列举了感兴趣的">References(只列举了感兴趣的)&lt;a class="td-heading-self-link" href="#references%e5%8f%aa%e5%88%97%e4%b8%be%e4%ba%86%e6%84%9f%e5%85%b4%e8%b6%a3%e7%9a%84" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&amp;hellip;bla bla bla&amp;hellip;bla bla bla&amp;hellip;
6. &lt;a href="https://link.zhihu.com/?target=http%3A//techblog.netflix.com/2015/07/java-in-flames.html">Gregg, B., Spier, M. 2015. Java in flames. The Netflix Tech Blog;&lt;/a>
7. &lt;a href="https://link.zhihu.com/?target=http%3A//queue.acm.org/detail.cfm%3Fid%3D1805128">Heer, J., Bostock, M., Ogievetsky, V. 2010. A tour through the visualization zoo. acmqueue 8(5);&lt;/a>
&amp;hellip;bla bla bla&amp;hellip;bla bla bla&amp;hellip; 10.&lt;a href="https://link.zhihu.com/?target=http%3A//www.creativebloq.com/design/science-behind-data-visualisation-8135496">Odds, G. 2013. The science behind data visualisation. Creative Bloq;&lt;/a>
&amp;hellip;bla bla bla&amp;hellip;bla bla bla&amp;hellip; 15.&lt;a href="https://link.zhihu.com/?target=http%3A//agentzh.org/misc/slides/off-cpu-flame-graphs.pdf">Zhang, Y. 2013. Introduction to off-CPU time flame graphs;&lt;/a>&lt;/p>
&lt;h2 id="结论">结论&lt;a class="td-heading-self-link" href="#%e7%bb%93%e8%ae%ba" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>现在终于明白为什么很多汉化的技术书籍，读起来比较拗口了。翻译这么短的一篇介绍性文章，都感觉心力憔悴。。。
从最开始的小心翼翼，逐句翻译生怕表达错了含义，结果觉得翻译结果&lt;strong>啰哩啰嗦&lt;/strong>。到后来试图用自己的理解描述，又害怕因为理解错误，词不达意。到最后逐渐佛系，降低心里期望。现在终于明白了译者的辛苦。
在这里正好提一下这个 github 地址：&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/LCTT/TranslateProject">TranslateProject&lt;/a>，之前网上查到的好多帖子都是 LCTT 汉化的，一直都没有注意，这次查资料才发现。后续我也试一试按照他们的规范把这篇文章提个 push 申请啥的。
读完这篇论文，才知道网上很多对火焰图的理解都比较片面。特别是后边 Other Targets 部分，很多内容很有意思，网上查找“火焰图”关键词搜到的文章都没有提及。通过这次经历，也终于理解了之前一位前辈说&lt;strong>要多看 paper&lt;/strong>，不要老是在网上看几篇帖子就以为自己理解了。果然还是一手的信息靠谱。
整片文章我最感兴趣的，就是&lt;strong>Challenge&lt;/strong>里边提到的，作者在给 java 生成火焰图的时候，遇到的两个问题。当时读的时候，一直不理解帧指针寄存器（frame pointer register）是个啥东西。还好这段有 References &lt;a href="https://link.zhihu.com/?target=http%3A//techblog.netflix.com/2015/07/java-in-flames.html.">java-in-flames&lt;/a>。根据指导我详细学习了一下如何使用本文提到的技术，生成 java 的火焰图。后续会整理一个“《性能之巅》学习笔记之火焰图 其之二”介绍一下。总之也是挺有趣的。_当然，bcc 是什么鬼？我不知道啊，听都没听过
之前一直很奇怪，为什么论文必须要有 References，现在有点理解了。
这个技能点到底有没有点上，其实心里还是没什么底，希望能够坚持下去，虽然阅读英文的资料耗费心力，但是收获真的很大。就像长跑者思维：因为今天下雨了，所以才要去跑步。因为很困难，所以干就完了！&lt;/p></description></item><item><title>Docs: SLI/SLO</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/SLI_SLO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/SLI_SLO/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/GNx0a0IKwvtDQ4QzEro2cA">公众号,通过 Prometheus 来做 SLI/SLO 监控展示&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h2 id="什么是-slislo">什么是 SLI/SLO&lt;a class="td-heading-self-link" href="#%e4%bb%80%e4%b9%88%e6%98%af-slislo" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>SLI，全名 Service Level Indicator，是服务等级指标的简称，它是衡定系统稳定性的指标。&lt;/p>
&lt;p>SLO，全名 Sevice Level Objective，是服务等级目标的简称，也就是我们设定的稳定性目标，比如&amp;quot;4 个 9&amp;quot;，&amp;ldquo;5 个 9&amp;quot;等。&lt;/p>
&lt;p>SRE 通常通过这两个指标来衡量系统的稳定性，其主要思路就是通过 SLI 来判断 SLO，也就是通过一系列的指标来衡量我们的目标是否达到了&amp;quot;几个 9&amp;rdquo;。&lt;/p>
&lt;h2 id="如何选择-sli">如何选择 SLI&lt;a class="td-heading-self-link" href="#%e5%a6%82%e4%bd%95%e9%80%89%e6%8b%a9-sli" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在系统中，常见的指标有很多种，比如：&lt;/p>
&lt;ul>
&lt;li>系统层面：CPU 使用率、内存使用率、磁盘使用率等&lt;/li>
&lt;li>应用服务器层面：端口存活状态、JVM 的状态等&lt;/li>
&lt;li>应用运行层面：状态码、时延、QPS 等&lt;/li>
&lt;li>中间件层面：QPS、TPS、时延等&lt;/li>
&lt;li>业务层面：成功率、增长速度等&lt;/li>
&lt;/ul>
&lt;p>这么多指标，应该如何选择呢？只要遵从两个原则就可以：&lt;/p>
&lt;ul>
&lt;li>选择能够标识一个主体是否稳定的指标，如果不是这个主体本身的指标，或者不能标识主体稳定性的，就要排除在外。&lt;/li>
&lt;li>优先选择与用户体验强相关或用户可以明显感知的指标。&lt;/li>
&lt;/ul>
&lt;p>通常情况下，可以直接使用谷歌的 VALET 指标方法。&lt;/p>
&lt;ul>
&lt;li>V：Volume，容量，服务承诺的最大容量&lt;/li>
&lt;li>A：Availability，可用性，服务是否正常&lt;/li>
&lt;li>L：Latency，延迟，服务的响应时间&lt;/li>
&lt;li>E：Error，错误率，请求错误率是多少&lt;/li>
&lt;li>T：Ticket，人工介入，是否需要人工介入&lt;/li>
&lt;/ul>
&lt;p>这就是谷歌使用 VALET 方法给的样例。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/imm2o7/1663932362954-63a8386d-a582-49ab-b09a-499746bbb043.png" alt="">&lt;/p>
&lt;p>上面仅仅是简单的介绍了一下 SLI/SLO，更多的知识可以学习《SRE：Google 运维解密》和赵成老师的极客时间课程《SRE 实践手册》。下面来简单介绍如何使用 Prometheus 来进行 SLI/SLO 监控。&lt;/p>
&lt;h2 id="service-level-operator">service-level-operator&lt;a class="td-heading-self-link" href="#service-level-operator" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Service level operator 是为了 Kubernetes 中的应用 SLI/SLO 指标来衡量应用的服务指标，并可以通过 Grafana 来进行展示。&lt;/p>
&lt;p>Operator 主要是通过 SLO 来查看和创建新的指标。例如：&lt;/p>
&lt;p>&lt;code>apiVersion: monitoring.spotahome.com/v1alpha1 kind: ServiceLevel metadata:   name: awesome-service spec:   serviceLevelObjectives:     - name: &amp;quot;9999_http_request_lt_500&amp;quot;       description: 99.99% of requests must be served with &amp;lt;500 status code.       disable: false       availabilityObjectivePercent: 99.99       serviceLevelIndicator:         prometheus:           address: http://myprometheus:9090           totalQuery: sum(increase(http_request_total{host=&amp;quot;awesome_service_io&amp;quot;}[2m]))           errorQuery: sum(increase(http_request_total{host=&amp;quot;awesome_service_io&amp;quot;, code=~&amp;quot;5..&amp;quot;}[2m]))       output:         prometheus:           labels:             team: a-team             iteration: &amp;quot;3&amp;quot;&lt;/code>&lt;/p>
&lt;ul>
&lt;li>availabilityObjectivePercent：SLO&lt;/li>
&lt;li>totalQuery：总请求数&lt;/li>
&lt;li>errorQuery：错误请求数&lt;/li>
&lt;/ul>
&lt;p>Operator 通过 totalQuert 和 errorQuery 就可以计算出 SLO 的指标了。&lt;/p>
&lt;h2 id="部署-service-level-operator">部署 service-level-operator&lt;a class="td-heading-self-link" href="#%e9%83%a8%e7%bd%b2-service-level-operator" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;p>“&lt;/p>
&lt;p>前提：在 Kubernetes 集群中部署好 Prometheus，我这里是采用 Prometheus-Operator 方式进行部署的。&lt;/p>
&lt;p>”&lt;/p>
&lt;/blockquote>
&lt;p>（1）首先创建 RBAC&lt;/p>
&lt;p>`apiVersion: v1
kind: ServiceAccount
metadata:
  name: service-level-operator
  namespace: monitoring
  labels:
    app: service-level-operator
    component: app&lt;/p>
&lt;hr>
&lt;p>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: service-level-operator
  labels:
    app: service-level-operator
    component: app
rules:
  # Register and check CRDs.
  - apiGroups:
      - apiextensions.k8s.io
    resources:
      - customresourcedefinitions
    verbs:
      - &amp;ldquo;*&amp;rdquo;&lt;/p>
&lt;p># Operator logic.
  - apiGroups:
      - monitoring.spotahome.com
    resources:
      - servicelevels
      - servicelevels/status
    verbs:
      - &amp;ldquo;*&amp;rdquo;&lt;/p>
&lt;hr>
&lt;p>kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: service-level-operator
subjects:
  - kind: ServiceAccount
    name: service-level-operator
    namespace: monitoring 
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: service-level-operator&lt;/p>
&lt;p>`&lt;/p>
&lt;p>（2）然后创建 Deployment&lt;/p>
&lt;p>&lt;code>apiVersion: apps/v1  kind: Deployment metadata:   name: service-level-operator   namespace: monitoring   labels:     app: service-level-operator     component: app spec:   replicas: 1   selector:     matchLabels:       app: service-level-operator       component: app   strategy:     rollingUpdate:       maxUnavailable: 0   template:     metadata:       labels:         app: service-level-operator         component: app     spec:       serviceAccountName: service-level-operator       containers:         - name: app           imagePullPolicy: Always           image: quay.io/spotahome/service-level-operator:latest           ports:             - containerPort: 8080               name: http               protocol: TCP           readinessProbe:             httpGet:               path: /healthz/ready               port: http           livenessProbe:             httpGet:               path: /healthz/live               port: http           resources:             limits:               cpu: 220m               memory: 254Mi             requests:               cpu: 120m               memory: 128Mi&lt;/code>&lt;/p>
&lt;p>（3）创建 service&lt;/p>
&lt;p>&lt;code>apiVersion: v1 kind: Service metadata:   name: service-level-operator   namespace: monitoring   labels:     app: service-level-operator     component: app spec:   ports:     - port: 80       protocol: TCP       name: http       targetPort: http   selector:     app: service-level-operator     component: app&lt;/code>&lt;/p>
&lt;p>（4）创建 prometheus serviceMonitor&lt;/p>
&lt;p>&lt;code>apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata:   name: service-level-operator   namespace: monitoring   labels:     app: service-level-operator     component: app     prometheus: myprometheus spec:   selector:     matchLabels:       app: service-level-operator       component: app   namespaceSelector:     matchNames:       - monitoring    endpoints:     - port: http       interval: 10s&lt;/code>&lt;/p>
&lt;p>到这里，Service Level Operator 部署完成了，可以在 prometheus 上查看到对应的 Target，如下：&lt;/p>
&lt;p>然后就需要创建对应的服务指标了，如下所示创建一个示例。&lt;/p>
&lt;p>&lt;code>apiVersion: monitoring.spotahome.com/v1alpha1 kind: ServiceLevel metadata:   name: prometheus-grafana-service   namespace: monitoring spec:   serviceLevelObjectives:     - name: &amp;quot;9999_http_request_lt_500&amp;quot;       description: 99.99% of requests must be served with &amp;lt;500 status code.       disable: false       availabilityObjectivePercent: 99.99       serviceLevelIndicator:         prometheus:           address: http://prometheus-k8s.monitoring.svc:9090           totalQuery: sum(increase(http_request_total{service=&amp;quot;grafana&amp;quot;}[2m]))           errorQuery: sum(increase(http_request_total{service=&amp;quot;grafana&amp;quot;, code=~&amp;quot;5..&amp;quot;}[2m]))       output:         prometheus:           labels:             team: prometheus-grafana              iteration: &amp;quot;3&amp;quot;&lt;/code>&lt;/p>
&lt;p>上面定义了 grafana 应用&amp;quot;4 个 9&amp;quot;的 SLO。&lt;/p>
&lt;p>然后可以在 Prometheus 上看到具体的指标，如下。&lt;/p>
&lt;p>接下来在 Grafana 上导入 ID 为&lt;code>8793&lt;/code>的 Dashboard，即可生成如下图表。上面是 SLI，下面是错误总预算和已消耗的错误。&lt;/p>
&lt;p>下面可以定义告警规则，当 SLO 下降时可以第一时间收到，比如：&lt;/p>
&lt;p>&lt;code>groups:   - name: slo.rules     rules:       - alert: SLOErrorRateTooFast1h         expr: |           (             increase(service_level_sli_result_error_ratio_total[1h])             /             increase(service_level_sli_result_count_total[1h])           ) &amp;gt; (1 - service_level_slo_objective_ratio) * 14.6         labels:           severity: critical           team: a-team         annotations:           summary: The monthly SLO error budget consumed for 1h is greater than 2%           description: The error rate for 1h in the {{$labels.service_level}}/{{$labels.slo}} SLO error budget is being consumed too fast, is greater than 2% monthly budget.       - alert: SLOErrorRateTooFast6h         expr: |           (             increase(service_level_sli_result_error_ratio_total[6h])             /             increase(service_level_sli_result_count_total[6h])           ) &amp;gt; (1 - service_level_slo_objective_ratio) * 6         labels:           severity: critical           team: a-team         annotations:           summary: The monthly SLO error budget consumed for 6h is greater than 5%           description: The error rate for 6h in the {{$labels.service_level}}/{{$labels.slo}} SLO error budget is being consumed too fast, is greater than 5% monthly budget.&lt;/code>&lt;/p>
&lt;p>第一条规则表示在 1h 内消耗的错误率大于 30 天内的 2%，应该告警。第二条规则是在 6h 内的错误率大于 30 天的 5%，应该告警。&lt;/p>
&lt;p>下面是谷歌的的基准。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>SLO 错误率&lt;/th>
&lt;th>时间范围&lt;/th>
&lt;th>30 天消耗百分比&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>2%&lt;/td>
&lt;td>1h&lt;/td>
&lt;td>730 * 2 / 100 = 14.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5%&lt;/td>
&lt;td>6h&lt;/td>
&lt;td>730 / 6 * 5 / 100 = 6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>10%&lt;/td>
&lt;td>3d&lt;/td>
&lt;td>30 / 3 * 10 / 100 = 1&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="最后">最后&lt;a class="td-heading-self-link" href="#%e6%9c%80%e5%90%8e" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>说到系统稳定性，这里不得不提到系统可用性，SRE 提高系统的稳定性，最终还是为了提升系统的可用时间，减少故障时间。那如何来衡量系统的可用性呢？&lt;/p>
&lt;p>目前业界有两种衡量系统可用性的方式，一个是时间维度，一个是请求维度。时间维度就是从故障出发对系统的稳定性进行评估。请求维度是从成功请求占比的角度出发，对系统稳定性进行评估。&lt;/p>
&lt;ul>
&lt;li>时间维度：可用性 = 服务时间 / （服务时间 + 故障时间）&lt;/li>
&lt;li>请求维度：可用性 = 成功请求数 / 总请求数&lt;/li>
&lt;/ul>
&lt;p>在 SRE 实践中，通常会选择请求维度来衡量系统的稳定性，就如上面的例子。不过，如果仅仅通过一个维度来判断系统的稳定性也有点太武断，还应该结合更多的指标，比如延迟，错误率等，而且对核心应用，核心链路的 SLI 应该更细致。&lt;/p>
&lt;h2 id="参考">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>[1] 《SRE 实践手册》- 赵成
[2] 《SRE：Google 运维解密》
[3]  &lt;a href="https://github.com/spotahome/service-level-operator">https://github.com/spotahome/service-level-operator&lt;/a>&lt;/p></description></item><item><title>Docs: 性能优化</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>
&lt;p>&lt;strong>《性能之巅：洞悉系统、企业与云计算》&lt;/strong>
&lt;strong>《BPF之巅 洞悉Linux系统和应用性能》&lt;/strong>&lt;/p></description></item><item><title>Docs: 性能优化的一点感触</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E7%82%B9%E6%84%9F%E8%A7%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E7%82%B9%E6%84%9F%E8%A7%A6/</guid><description>
&lt;p>原文链接：&lt;a href="https://mp.weixin.qq.com/s/OXvQCPK1ZyM7yyfFzyFYBA">https://mp.weixin.qq.com/s/OXvQCPK1ZyM7yyfFzyFYBA&lt;/a>
最近参与了几个项目的性能优化，总体来说各个项目都有所提升，能够满足用户使用需求，但是这个过程耗费了大量的人力、物力资源成本，主要原因有以下几点:&lt;/p>
&lt;ul>
&lt;li>系统本身没有任何参数指标，这一点其实是大多数系统存在的问题，打个比方我作为乙方给甲方做了一个软件，交付完成后供甲方使用，这个系统的 TPS 是多少？硬件配置/用户矩阵是什么？系统可靠性 4 个 9 还是 2 个 9？你可能会说，我们的客户要求根本没有这么严格，能用就行，实则不然，如果说一年没问题，一年后客户的用户数量增长了一倍，忽然发现系统卡顿，几乎不能使用，客户找你算账，这该怎么办？谁的原因造成的&amp;hellip;.. 你说我们给自己公司做的产品，不要求这些东西，满足当前用户即可，那我现在问你，你的系统用户承载量是什么？当你真的出现用户数量激增，你该如何应对？&lt;/li>
&lt;li>框架标准化，如果一个企业中多个项目使用的框架五花八门，真正出现性能问题的时候，只能大家齐上阵，见招拆招，忙的不亦乐乎，其实收效甚微。&lt;/li>
&lt;li>翻译需求，很多功能逻辑说不通，但又没法改，为什么？客户要求如此、产品经理设计如此，产品经理也已经不在了，原型设计文档找不到了，当然这种项目都是比较老的项目，很多公司都会存在此类问题。&lt;/li>
&lt;li>灰度发布系统，深夜一群人呆在一起发布一个系统，一起处理 bug 真的是团队团结的表现吗?回家陪陪老婆孩子，好好休息，第二天的工作效率不是更高吗？&lt;/li>
&lt;/ul>
&lt;p>如果现在让我做一个系统，我应该如何设计？趁着周六有时间就这四个问题简单聊聊，希望能够对大家的工作有所启发。&lt;/p>
&lt;h2 id="系统参数">系统参数&lt;a class="td-heading-self-link" href="#%e7%b3%bb%e7%bb%9f%e5%8f%82%e6%95%b0" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>你打开的汽车使用说明书，它会告诉你它在什么温度下可以正常工作、最高时速是多少、承客量多大&amp;hellip;&amp;hellip;如果出现问题，仪表盘会给出什么样提示，你应该如何规避这些故障。软件系统也一样，你的安装部署手册里要告诉别人你的系统需要多大内存、多少硬盘、什么规格的 CPU 来支撑多少用户量。设计文档的非功能性指标应该包含系统每秒处理事务数量（TPS）或查询数量是多少、安全性指标等级甚至支持用户数量；你的管理端界面或者监控系统应该告诉运维人员 CPU 占用量、内存占用量、硬盘使用情况、带宽使用；阈值告警参数，触发阈值产生告警，研发人员如何查看日志排除故障。
说的简单，这些指标从哪里得到呢？没有特别好的办法，只能通过压力测试、稳定性测试、安全性测试甚至平时的故障模拟中得到。
确实这些度量指标非常昂贵，甚至要超过你系统本身的成本，即便如此，你要去做，因为你不去量化一个系统，你就无法管理一个系统，可以想象一下你每天都是在闭着眼睛开车，你永远不知道您离灾难有多近。所以你要说服你的老板，抵挡住节省金钱的诱惑，认真对待系统指标数据。
当然完全做出这些东西到底有多复杂？我作为过来人认为并不复杂，而且能减轻不少后期工作量，想想一个系统不会所有的接口都对性能有要求，所以你只要评估出存在性能瓶颈的接口加以性能测试即可；另外性能测试脚本开发完成后都是复用的状态，所以不会产生太大工作量，而且又保证了每次上线之前都可以自动化验证部分接口，这不比&lt;code>人肉点点点&lt;/code>香的多吗？
另外像一些系统层面的参数指标，比如 Http 调用成功/失败情况、CPU、内存占用情况、告警等，可以搭建一套监控工具，比如 Prometheus 等。完成此类指标的获取。
如果说我的系统总共就几个人用、或者这种付出和收益完全成反比，那当我没说。&lt;/p>
&lt;h2 id="框架标准化">框架标准化&lt;a class="td-heading-self-link" href="#%e6%a1%86%e6%9e%b6%e6%a0%87%e5%87%86%e5%8c%96" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>框架，通俗来说也就是我们产品/项目架构，就架构本身而言，一定先有设计目标，架构要去干什么样的事情，去完成一个购物网站还是一个管理平台，存在很大区别；根据设计目标，应该定义出设计原则，这也就是平时经常见到的控制反转、里氏替换、最小依赖、单一职责等原则，加上清晰的边界和实现价值（架构做什么，不做什么）；最后通过使用 Gof 总结出来 23 种设计模式加上算法就形成了一套框架。在这个框架的基础上就可以开发我们的应用。你可能会反驳我们项目五花八门，经常变动，一般架构很难满足，甚至架构需要经常改动，大概率是框架抽象定义的不够好，你看看你平时用到的 tomcat 框架、spring 框架，你感知到它的存在了吗？反而像早期 IBM 做的 weblogic、jboss 什么都做的重量级框架，已被抛弃，所以解耦和抽象再怎么强调都不为过。
定义好框架只是第一步，下面就是使用了，就目前国内情况而言，开源项目越来越火爆，所以基本上从网上找找，七拼八凑就行成了一套自己的框架，这本身而言也没有错误，极大降低企业框架定义的成本，但是一个框架通常只能解决某一类的问题，所以前期就需要架构人员进行反复编写代码进行测试和使用，得到这个框架自身的数据，而不是看见别人用的很好，别人多少数据量都可以轻易支撑起来，别人的使用场景很可能跟你不一样，要不然为啥市面充斥着五花八门的框架，大多数原因都不能从根本上解决自己的痛点问题。
接着架构人员要参与到编码中，发现问题及时更正和修改，引导开发人员如何划分模块，关键时刻做出示例，进而形成自己的开发规范，而不仅仅是站在一个指导者的角色，口头告诉程序员该如何使用，满足不了性能指标或者业务一团糟的时候开始考虑拆分，然后拆成几个微服务也是乱上加乱，根本不能从本质上解决问题。
总结来说，做架构首先要考虑的是自己的需求、目的及边界、原则、实现价值，最后才考虑技术实现和工具组件，而不是首先撸出一套框架生搬硬套，最后说程序员不会使用，代码写的太垃圾。&lt;/p>
&lt;h2 id="翻译需求">翻译需求&lt;a class="td-heading-self-link" href="#%e7%bf%bb%e8%af%91%e9%9c%80%e6%b1%82" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>通常来说，一般是提出需求，架构人员进行架构设计，产品经理画出原型设计，开发人员开始设计、开发、提交测试交付。最后一个阶段看似已经定型，按照需求完成任务即可。但是人都会犯错，作为开发/测试人员不能对照原型、设计文档翻译需求，出现问题后，自豪的说，&lt;code>就是这样设计的，我也没办法，你找产品去&lt;/code>。但是你有没有考虑过，即使产品人员改了改需求，最后你不还是照做，受伤的还是自己。所以我们在做任何一个功能的时候都要搞清楚问题的本质，事情的初衷。
你可能会反驳说，&lt;code>我的产品比较强势，他做的东西面向的是用户，开发人员是无法理解的，照着做就行了&lt;/code>。但我觉着这些并不是理由，如果一个产品说用户要求的，你可以站在一个用户的角度去理解，如果是从数据角度，让他把数据拿出来，如果讲不明白，你完全可以拒绝，否则你做出来的东西肯定是&lt;code>四不像&lt;/code>。所谓铁打的营盘，流水的兵，换了几波人之后完全无法理解这种逻辑，产品如何迭代。你要说你的产品功能过于复杂，大多数是产品设计就存在一定问题，你看看你常用的应用，那个不是简单易用。
为什么要对开发人员强调需求呢？因为你的需求做的不严谨，存在漏洞，都会给后期的性能、再次开发埋下祸根，而且这种问题，越往后解决成本越高。&lt;/p>
&lt;h2 id="灰度发布">灰度发布&lt;a class="td-heading-self-link" href="#%e7%81%b0%e5%ba%a6%e5%8f%91%e5%b8%83" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>相信大家面试的时候经常会听到面试官问这个问题, &lt;code>如何保证一个系统高可用？如何做到不停机发布系统？&lt;/code>答案也很简单，负载均衡，当然负载均衡也有很多种，有基于域名重定向、DNS、IP、数据链路层的负载均衡，你可以根据你服务自身情况，选择一种适合自己的。当然你会反驳我说，我的系统就一个副本，不要求高可用，那我会说，你敢白天上线吗？如果不敢，请乖乖做灰度发布（金丝雀、A/B、蓝绿等等）。
这并不是凭空增加大家的工作量，不知道大家认不认这样一个事实，软件发布通常遵循墨菲定律，往往不好的，一般情况下不会出现的问题，甚至没有想到的，都会在线上出现。要么人家都说运维人员都相信玄学，其实倒不是因为玄学，是因为存在未知。线上的用户、历史数据量往往最多的，也是最全面的，所以线上更容易复现一些问题。通过灰度发布部署多套，开发/测试人员完全可以在工作时间、站在用户的角度测试完成后上线发布。否则直接回退，即实现了测试，也没有影响用户使用。
灰度发布说简单也简单，最简单的你在你的 nginx 写几句 lua 脚本，便可以把包含特定标识的用户路由到特定服务。&lt;/p>
&lt;h2 id="总结">总结&lt;a class="td-heading-self-link" href="#%e6%80%bb%e7%bb%93" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>看完本文后，感觉会有点诧异，说的不是性能优化吗？不应该讲讲连接池配置多大、缓存如何使用、系统优化、硬件配置、甚至代码如何编写的一些技巧吗？怎么扯了一堆没用的。从某种程度上来说，软件的性能优化成本往往跟前期的软件设计成本反比，前期在设计上花费的时间越多，往往后期优化成本就越低。没有任何组织能够一开始就做一个高性能的软件系统，大多数都是随着用户和数据的增多演化而来。前期的性能指标、系统架构、甚至功能需求编写都能够为后期软件性能优化带来帮助。&lt;/p></description></item></channel></rss>