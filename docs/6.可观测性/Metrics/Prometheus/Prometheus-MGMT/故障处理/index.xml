<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>故障处理 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><description>Recent content in 故障处理 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/index.xml" rel="self" type="application/rss+xml"/><item><title>Prometheus 大量读操作</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Prometheus-%E5%A4%A7%E9%87%8F%E8%AF%BB%E6%93%8D%E4%BD%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Prometheus-%E5%A4%A7%E9%87%8F%E8%AF%BB%E6%93%8D%E4%BD%9C/</guid><description>故障现象
Prometheus 的读请求无故瞬间激增。
故障排查 重启 Prometheus 后解决，后续需要跟进看是否还会继续发生
当使用 Grafana 查询 30 天的指标时，Prometheus 的读请求就会激增：
怀疑可能是 Grafana 与 Prometheus 之间的连接没有中断，持续查询导致，但是暂无证据
1 月 20 日早晨进行 30 天查询后再次出现该问题，添加 netfilter 规则，阻断 grafana 与 prometheus 问题依旧；使用 docker 重启 prometheus 容器问题依旧；删除 grafana 问题依旧。
故障处理
实际上是由于每次评估规则时，有很多条规则的表达式是 30 天的范围表达式导致的。</description></item><item><title>故障处理</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>概述 公众号-CNCF，记一次远程写性能问题引发的Prometheus版本升级事件
compaction failed compaction failed 是一个 Prometheus 在压缩数据时产生的错误，导致该问题的因素多种多样，最常见的就是使用 NFS 作为 Prometehus 时序数据库的后端存储。
官方文档中曾明确表明不支持 NFS 文件系统
该问题的表现形式通常为文件丢失，比如，某个 Block 中的 meta.json 文件丢失
msg=&amp;#34;compaction failed&amp;#34; err=&amp;#34;plan compaction: open /prometheus/01FHHPS3NR7M2E8MAV37S61ME6/meta.json: no such file or directory&amp;#34; msg=&amp;#34;Failed to read meta.json for a block during reloadBlocks. Skipping&amp;#34; dir=/prometheus/01FHHPS3NR7M2E8MAV37S61ME6 err=&amp;#34;open /prometheus/01FHHPS3NR7M2E8MAV37S61ME6/meta.json: no such file or directory&amp;#34; 经过日志筛选，该问题起源于一次 Deleting obsolete block 操作之后的 compact blocks，也就是删除过期块后压缩块。 失败操作源于：
msg=&amp;#34;compaction failed&amp;#34; err=&amp;#34;delete compacted block after failed db reloadBlocks:01FHHPS3NR7M2E8MAV37S61ME6: unlinkat /prometheus/01FHHPS3NR7M2E8MAV37S61ME6/chunks: directory not empty&amp;#34; 这些报错日志信息，可以在 .</description></item></channel></rss>