<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Storage(存储) on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/</link><description>Recent content in Storage(存储) on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>Storage(存储)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Storage%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Storage%E5%AD%98%E5%82%A8/</guid><description>概述 参考：
官方文档，存储 官方文档，运维 - 存储 https://grafana.com/blog/2023/12/20/the-concise-guide-to-grafana-loki-everything-you-need-to-know-about-labels/ 与其他日志记录系统不同，Loki 是基于仅索引日志的元数据的想法而构建的。从 [Loki 的数据模型](/docs/6.可观测性/日志系统/Loki/Storage(存储)/Data%20Model(数据模型).md Model(数据模型).md)可知，日志是根据标签进行定位的。 日志数据本身会被压缩成 Chunks，并存储在本地的文件系统中；并且 Loki 还提供了一个 Index 数据，用来根据索引定位日志数据。小索引和高度压缩的 Chunks 简化了操作，并显着降低了 Loki 的成本。
所以 Loki 需要存储两种不同类型的数据，当 Loki 收到 Log Stream 时，会存储两类数据：
Chunk(块) # 日志流本身的信息。每一个 Chunk 都是将一段时间的日志流压缩后形成的一个文件。 一个 Chunks 就是一个对象，如果是使用本地文件系统存储 Chunks，则可以抽象得将一个 Chunks 文件当做一个对象。在一个 Chunks 文件中一般包含里一段时间的日志流数据。 Index(索引) # 日志流索引的信息。每一个 Index 都是 键/值 格式的数据库文件，文件中的内容用来关联 日志流的标签 与 Chunks。 Index 中的 Key 就是日志流的标签，Value 就是 Chunks 文件所在的绝对路径。 [!Tip] History Loki 在 2.0 版本之前，这两类数据是分开存放的，只有 Chunk 数据可以存在对象存储中。
直到 2.0 发布，Loki 开发了基于 BoltDB 的 BoltDB-Shipper 数据库用来存储 Index，并且已经可以将 Index 数据也存到对象存储中。也就是 Single stroe(单存储) 架构，此时 Chunk 和 Index 都可以同时存在本地文件系统或者同时存在对象存储中。</description></item><item><title>Data Model(数据模型)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Data-Model%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Data-Model%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考：
官方文档没有专门讲 Log Stream 的章节，Stream 的概念都是在其他章节提到的 官方文档，入门 - 标签 官方文档，运维 - 存储 Log Stream(日志流) 概念 Loki 通过一种称为 Log Stream(日志流) 的概念组织所有日志数据。Log Stream(日志流) 之于 Loki 类似于 Time series(时间序列) 之于 Prometheus
Loki 使用 Stream(流) 这个词来描述保存的日志数据，并根据 Label(标签) 来定位日志流，Label 是日志流的元数据。Label 的概念和用法与 Prometheus 中的 Label 一致。如果 Loki 与 Prometheus 同时使用，那么他们之间得标签是一致的，通过 Label，很容易得就可以将应用程序指标和日志数据关联起来。
Stream 与 Label 是强关联的，在 Loki 中，Label 是唯一可以定义 Log Stream 的东西。每个标签键和值的组合定义了一条 log stream。如果一个标签值发生了变化，则这会生成一个新的 Log stream。在 Prometheus 中，类似 Log Stream 概念的是 time series(stream 对应 series)。但是不同的是，在 Prometheus 中还有一个维度，是 metrics name(指标名称)。但是在 Loki 中则谁 Path，一个 采集日志的 Path 实际上是会采集很多很多日志的。也正是由于此，所以 Loki 将这种概念称为 Stream，而不是 Series。</description></item><item><title>弃用</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/%E5%BC%83%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/%E5%BC%83%E7%94%A8/</guid><description>概述 参考：
BoltDB-Shipper 运行细节 Ingester 组件用于将 Index 与 Chunks 数据写入存储；Querier 组件用于从存储中读取 Index 和 Chunks 以处理 LogQL 查询请求。
写入数据 在深入了解细节之前，需要知道 Ingester 如何管理存储中的 Index 数据。
读取数据 Queriers lazily loads BoltDB files from shared object store to configured cache_location. When a querier receives a read request, the query range from the request is resolved to period numbers and all the files for those period numbers are downloaded to cache_location, if not already. Once we have downloaded files for a period we keep looking for updates in shared object store and download them every 5 Minutes by default.</description></item></channel></rss>