<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 计算机视觉</title><link>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><description>Recent content in 计算机视觉 on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 计算机视觉</title><link>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Computer_vision">Wiki，Computer_vision&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Computer vision(计算机视觉)&lt;/strong> 任务包括获取、处理、分析和理解数字图像的方法，以及从现实世界中提取高维数据以产生数字或符号信息的方法，例如以决定的形式。 在这种情况下，理解意味着将视觉图像（视网膜的输入）转化为对思维过程有意义并可以引发适当行动的世界描述。这种图像理解可以看作是使用借助几何、物理学、统计学和学习理论构建的模型从图像数据中分离出符号信息。&lt;/p>
&lt;h1 id="视觉模型">视觉模型&lt;/h1>
&lt;p>现在有类似语言模型的视觉模型吗？&lt;/p>
&lt;p>Segment Anything Model 这个怎么样？&lt;/p>
&lt;h1 id="halcon-与-opencv">Halcon 与 OpenCV&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>OpenCV&lt;/th>
&lt;th>Halcon&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>开发语言&lt;/td>
&lt;td>C++、C#（emgu）、Python、Ruby、MATLAB等语言&lt;/td>
&lt;td>C，C++，C#，Visual basic和Delphi等语言&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>应用场合&lt;/td>
&lt;td>侧重计算机视觉领域，侧重研究领域&lt;/td>
&lt;td>侧重机器视觉领域，侧重应用领域&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>费用&lt;/td>
&lt;td>免费&lt;/td>
&lt;td>收费&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>开放性及版本更新速度&lt;/td>
&lt;td>开源（可看底层源码），版本和功能更新慢&lt;/td>
&lt;td>商业软件（底层代码封装），版本和功能更新快&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>对使用者的门槛&lt;/td>
&lt;td>偏科研，有难度，有深度，完全从底层开发，对使用者门槛高，开发效率低，开发慢&lt;/td>
&lt;td>偏工程应用，使用封装好的功能函数，对使用者门槛低，开发效率高，开发快&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>资料及技术支持&lt;/td>
&lt;td>资料少。遇到问题，难以获得技术支持&lt;/td>
&lt;td>资料多。遇到问题，可以及时、有效的获得技术支持&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="学习资料">学习资料&lt;/h1>
&lt;p>&lt;a href="https://www.bilibili.com/video/BV1is4y1D7oU">B 站，唐宇迪，【唐宇迪AI分享】CV和NLP两大板块一定要先选CV！！！&lt;/a>&lt;/p></description></item><item><title>Docs: OpenCV</title><link>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/opencv/opencv">GitHub 项目，opencv/opencv&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://opencv.org/">官网&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/">官方文档&lt;/a>，从左侧 Nightly 中选择想要查看的版本&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/115321759">https://zhuanlan.zhihu.com/p/115321759&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.jiqizhixin.com/articles/2019-03-22-10">手把手教你使用OpenCV库（附实例、Python代码解析）&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Open Source Computer Vision Library(开源计算机视觉库，简称 OpenCV)&lt;/strong> 是一个包含数百种计算机视觉算法的开源库。&lt;/p>
&lt;h2 id="各语言的库">各语言的库&lt;/h2>
&lt;p>官方提供了 Python、C++ 的 OpenCV 库&lt;/p>
&lt;p>go &lt;a href="https://github.com/hybridgroup/gocv">https://github.com/hybridgroup/gocv&lt;/a>&lt;/p>
&lt;h1 id="modules模块">Modules(模块)&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/index.html">4.x 官网文档，主页&lt;/a>&lt;/li>
&lt;li>&lt;a href="">4.x 官方文档，介绍&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/modules.html">4.x 官方文档，模块&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/annotated.html">4.x 官方文档，Class 列表&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/19988205">https://zhuanlan.zhihu.com/p/19988205&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>OpenCV 具有模块化的结构，整个 OpenCV 的功能由一个个模块提供，每个模块具有自己的类、函数、方法，并且可以多个模块共享使用。这种模块化的结构可以让 OpenCV 像一门编程语言一样，具有自己的标准库和第三方库，标准库中的标准模块可以实现自身的核心功能，第三方库的模块可以基于核心功能扩展其他功能。就像 &lt;a href="https://pkg.go.dev/">https://pkg.go.dev/&lt;/a> 中的各种包，可以看到类型、方法、函数等等的描述。&lt;/p>
&lt;p>所有 OpenCV 的类和函数都放在 cv Namespace 中(Namespace 是 C++ 编程语言的基本概念)，如果我们要使用 C++ 代码调用 OpenCV 的模块，需要使用 &lt;code>cv::&lt;/code> 或在头部添加 &lt;code>using namespace cv;&lt;/code> 指令。&lt;/p>
&lt;p>模块分为两类：&lt;/p>
&lt;ul>
&lt;li>Main Modules(主模块)&lt;/li>
&lt;li>Extra Modules(额外模块)&lt;/li>
&lt;/ul>
&lt;h2 id="main-modules主模块">Main Modules(主模块)&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>core&lt;/strong> # 核心功能模块，全称 &lt;a href="https://docs.opencv.org/4.x/d0/de1/group__core.html">Core functionality&lt;/a> 。定义了基本的数据结构，包括最重要的 Mat 类、XML 读写、opengl三维渲染等。&lt;/li>
&lt;li>&lt;strong>imgproc&lt;/strong> # &lt;a href="https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%A8%A1%E5%9D%97.md">图像处理模块&lt;/a>，全称 Image processing。包括图像滤波、集合图像变换、直方图计算、形状描述、物体检测、等等。图像处理是计算机视觉的重要工具。&lt;/li>
&lt;li>&lt;strong>imgcodecs&lt;/strong> # 图像文件读写模块，全称 &lt;a href="https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html">Image file reading and writing&lt;/a>。&lt;/li>
&lt;li>&lt;strong>videoio&lt;/strong> # 视频文件读写模块，全称 &lt;a href="https://docs.opencv.org/4.x/dd/de7/group__videoio.html">Video I/O&lt;/a>。也包括摄像头、Kinect 等的输入。&lt;/li>
&lt;li>&lt;strong>highgui&lt;/strong> # 高级图形界面及与 QT 框架的整合。
&lt;ul>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/d7/dfc/group__highgui.html">High-level GUI&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>video&lt;/strong> # 视频分析模块。包括背景提取、光流跟踪、卡尔曼滤波等，做视频监控的读者会经常使用这个模块。
&lt;ul>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/d7/de9/group__video.html">Video Analysis&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>calib3d. &lt;a href="https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html">Camera Calibration and 3D Reconstruction&lt;/a>&lt;/li>
&lt;li>features2d. &lt;a href="https://docs.opencv.org/4.x/da/d9b/group__features2d.html">2D Features Framework&lt;/a>&lt;/li>
&lt;li>objdetect. &lt;a href="https://docs.opencv.org/4.x/d5/d54/group__objdetect.html">Object Detection&lt;/a>&lt;/li>
&lt;li>dnn. &lt;a href="https://docs.opencv.org/4.x/d6/d0f/group__dnn.html">Deep Neural Network module&lt;/a>&lt;/li>
&lt;li>ml. &lt;a href="https://docs.opencv.org/4.x/dd/ded/group__ml.html">Machine Learning&lt;/a>&lt;/li>
&lt;li>flann. &lt;a href="https://docs.opencv.org/4.x/dc/de5/group__flann.html">Clustering and Search in Multi-Dimensional Spaces&lt;/a>&lt;/li>
&lt;li>photo. &lt;a href="https://docs.opencv.org/4.x/d1/d0d/group__photo.html">Computational Photography&lt;/a>&lt;/li>
&lt;li>stitching. &lt;a href="https://docs.opencv.org/4.x/d1/d46/group__stitching.html">Images stitching&lt;/a>&lt;/li>
&lt;li>gapi. &lt;a href="https://docs.opencv.org/4.x/d0/d1e/gapi.html">Graph API&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="extra-modules额外模块">Extra Modules(额外模块)&lt;/h2>
&lt;ul>
&lt;li>alphamat. &lt;a href="https://docs.opencv.org/4.x/d4/d40/group__alphamat.html">Alpha Matting&lt;/a>&lt;/li>
&lt;li>aruco. &lt;a href="https://docs.opencv.org/4.x/d9/d6a/group__aruco.html">Aruco markers, module functionality was moved to objdetect module&lt;/a>&lt;/li>
&lt;li>barcode. &lt;a href="https://docs.opencv.org/4.x/d2/dea/group__barcode.html">Barcode detecting and decoding methods&lt;/a>&lt;/li>
&lt;li>bgsegm. &lt;a href="https://docs.opencv.org/4.x/d2/d55/group__bgsegm.html">Improved Background-Foreground Segmentation Methods&lt;/a>&lt;/li>
&lt;li>bioinspired. &lt;a href="https://docs.opencv.org/4.x/dd/deb/group__bioinspired.html">Biologically inspired vision models and derivated tools&lt;/a>&lt;/li>
&lt;li>ccalib. &lt;a href="https://docs.opencv.org/4.x/d3/ddc/group__ccalib.html">Custom Calibration Pattern for 3D reconstruction&lt;/a>&lt;/li>
&lt;li>cudaarithm. &lt;a href="https://docs.opencv.org/4.x/d5/d8e/group__cudaarithm.html">Operations on Matrices&lt;/a>&lt;/li>
&lt;li>cudabgsegm. &lt;a href="https://docs.opencv.org/4.x/d6/d17/group__cudabgsegm.html">Background Segmentation&lt;/a>&lt;/li>
&lt;li>cudacodec. &lt;a href="https://docs.opencv.org/4.x/d0/d61/group__cudacodec.html">Video Encoding/Decoding&lt;/a>&lt;/li>
&lt;li>cudafeatures2d. &lt;a href="https://docs.opencv.org/4.x/d6/d1d/group__cudafeatures2d.html">Feature Detection and Description&lt;/a>&lt;/li>
&lt;li>cudafilters. &lt;a href="https://docs.opencv.org/4.x/dc/d66/group__cudafilters.html">Image Filtering&lt;/a>&lt;/li>
&lt;li>cudaimgproc. &lt;a href="https://docs.opencv.org/4.x/d0/d05/group__cudaimgproc.html">Image Processing&lt;/a>&lt;/li>
&lt;li>cudalegacy. &lt;a href="https://docs.opencv.org/4.x/d5/dc3/group__cudalegacy.html">Legacy support&lt;/a>&lt;/li>
&lt;li>cudaobjdetect. &lt;a href="https://docs.opencv.org/4.x/d9/d3f/group__cudaobjdetect.html">Object Detection&lt;/a>&lt;/li>
&lt;li>cudaoptflow. &lt;a href="https://docs.opencv.org/4.x/d7/d3f/group__cudaoptflow.html">Optical Flow&lt;/a>&lt;/li>
&lt;li>cudastereo. &lt;a href="https://docs.opencv.org/4.x/dd/d47/group__cudastereo.html">Stereo Correspondence&lt;/a>&lt;/li>
&lt;li>cudawarping. &lt;a href="https://docs.opencv.org/4.x/db/d29/group__cudawarping.html">Image Warping&lt;/a>&lt;/li>
&lt;li>cudev. &lt;a href="https://docs.opencv.org/4.x/df/dfc/group__cudev.html">Device layer&lt;/a>&lt;/li>
&lt;li>cvv. &lt;a href="https://docs.opencv.org/4.x/df/dff/group__cvv.html">GUI for Interactive Visual Debugging of Computer Vision Programs&lt;/a>&lt;/li>
&lt;li>datasets. &lt;a href="https://docs.opencv.org/4.x/d8/d00/group__datasets.html">Framework for working with different datasets&lt;/a>&lt;/li>
&lt;li>dnn_objdetect. &lt;a href="https://docs.opencv.org/4.x/d5/df6/group__dnn__objdetect.html">DNN used for object detection&lt;/a>&lt;/li>
&lt;li>dnn_superres. &lt;a href="https://docs.opencv.org/4.x/d9/de0/group__dnn__superres.html">DNN used for super resolution&lt;/a>&lt;/li>
&lt;li>dpm. &lt;a href="https://docs.opencv.org/4.x/d9/d12/group__dpm.html">Deformable Part-based Models&lt;/a>&lt;/li>
&lt;li>face. &lt;a href="https://docs.opencv.org/4.x/db/d7c/group__face.html">Face Analysis&lt;/a>&lt;/li>
&lt;li>freetype. &lt;a href="https://docs.opencv.org/4.x/d4/dfc/group__freetype.html">Drawing UTF-8 strings with freetype/harfbuzz&lt;/a>&lt;/li>
&lt;li>fuzzy. &lt;a href="https://docs.opencv.org/4.x/df/d5b/group__fuzzy.html">Image processing based on fuzzy mathematics&lt;/a>&lt;/li>
&lt;li>hdf. &lt;a href="https://docs.opencv.org/4.x/db/d77/group__hdf.html">Hierarchical Data Format I/O routines&lt;/a>&lt;/li>
&lt;li>hfs. &lt;a href="https://docs.opencv.org/4.x/dc/d29/group__hfs.html">Hierarchical Feature Selection for Efficient Image Segmentation&lt;/a>&lt;/li>
&lt;li>img_hash. &lt;a href="https://docs.opencv.org/4.x/d4/d93/group__img__hash.html">The module brings implementations of different image hashing algorithms.&lt;/a>&lt;/li>
&lt;li>intensity_transform. &lt;a href="https://docs.opencv.org/4.x/dc/dfe/group__intensity__transform.html">The module brings implementations of intensity transformation algorithms to adjust image contrast.&lt;/a>&lt;/li>
&lt;li>julia. &lt;a href="https://docs.opencv.org/4.x/d7/d44/group__julia.html">Julia bindings for OpenCV&lt;/a>&lt;/li>
&lt;li>line_descriptor. &lt;a href="https://docs.opencv.org/4.x/dc/ddd/group__line__descriptor.html">Binary descriptors for lines extracted from an image&lt;/a>&lt;/li>
&lt;li>mcc. &lt;a href="https://docs.opencv.org/4.x/dd/d19/group__mcc.html">Macbeth Chart module&lt;/a>&lt;/li>
&lt;li>optflow. &lt;a href="https://docs.opencv.org/4.x/d2/d84/group__optflow.html">Optical Flow Algorithms&lt;/a>&lt;/li>
&lt;li>ovis. &lt;a href="https://docs.opencv.org/4.x/d2/d17/group__ovis.html">OGRE 3D Visualiser&lt;/a>&lt;/li>
&lt;li>phase_unwrapping. &lt;a href="https://docs.opencv.org/4.x/df/d3a/group__phase__unwrapping.html">Phase Unwrapping API&lt;/a>&lt;/li>
&lt;li>plot. &lt;a href="https://docs.opencv.org/4.x/db/dfe/group__plot.html">Plot function for Mat data&lt;/a>&lt;/li>
&lt;li>quality. &lt;a href="https://docs.opencv.org/4.x/dc/d20/group__quality.html">Image Quality Analysis (IQA) API&lt;/a>&lt;/li>
&lt;li>rapid. &lt;a href="https://docs.opencv.org/4.x/d4/dc4/group__rapid.html">silhouette based 3D object tracking&lt;/a>&lt;/li>
&lt;li>reg. &lt;a href="https://docs.opencv.org/4.x/db/d61/group__reg.html">Image Registration&lt;/a>&lt;/li>
&lt;li>rgbd. &lt;a href="https://docs.opencv.org/4.x/d2/d3a/group__rgbd.html">RGB-Depth Processing&lt;/a>&lt;/li>
&lt;li>saliency. &lt;a href="https://docs.opencv.org/4.x/d8/d65/group__saliency.html">Saliency API&lt;/a>&lt;/li>
&lt;li>sfm. &lt;a href="https://docs.opencv.org/4.x/d8/d8c/group__sfm.html">Structure From Motion&lt;/a>&lt;/li>
&lt;li>shape. &lt;a href="https://docs.opencv.org/4.x/d1/d85/group__shape.html">Shape Distance and Matching&lt;/a>&lt;/li>
&lt;li>stereo. &lt;a href="https://docs.opencv.org/4.x/dd/d86/group__stereo.html">Stereo Correspondance Algorithms&lt;/a>&lt;/li>
&lt;li>structured_light. &lt;a href="https://docs.opencv.org/4.x/d1/d90/group__structured__light.html">Structured Light API&lt;/a>&lt;/li>
&lt;li>superres. &lt;a href="https://docs.opencv.org/4.x/d7/d0a/group__superres.html">Super Resolution&lt;/a>&lt;/li>
&lt;li>surface_matching. &lt;a href="https://docs.opencv.org/4.x/d9/d25/group__surface__matching.html">Surface Matching&lt;/a>&lt;/li>
&lt;li>text. &lt;a href="https://docs.opencv.org/4.x/d4/d61/group__text.html">Scene Text Detection and Recognition&lt;/a>&lt;/li>
&lt;li>tracking. &lt;a href="https://docs.opencv.org/4.x/d9/df8/group__tracking.html">Tracking API&lt;/a>&lt;/li>
&lt;li>videostab. &lt;a href="https://docs.opencv.org/4.x/d5/d50/group__videostab.html">Video Stabilization&lt;/a>&lt;/li>
&lt;li>viz. &lt;a href="https://docs.opencv.org/4.x/d1/d19/group__viz.html">3D Visualizer&lt;/a>&lt;/li>
&lt;li>wechat_qrcode. &lt;a href="https://docs.opencv.org/4.x/dd/d63/group__wechat__qrcode.html">WeChat QR code detector for detecting and parsing QR code.&lt;/a>&lt;/li>
&lt;li>xfeatures2d. &lt;a href="https://docs.opencv.org/4.x/d1/db4/group__xfeatures2d.html">Extra 2D Features Framework&lt;/a>&lt;/li>
&lt;li>ximgproc. &lt;a href="https://docs.opencv.org/4.x/df/d2d/group__ximgproc.html">Extended Image Processing&lt;/a>&lt;/li>
&lt;li>xobjdetect. &lt;a href="https://docs.opencv.org/4.x/d4/d54/group__xobjdetect.html">Extended object detection&lt;/a>&lt;/li>
&lt;li>xphoto. &lt;a href="https://docs.opencv.org/4.x/de/daa/group__xphoto.html">Additional photo processing algorithms&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="核心功能模块">核心功能模块&lt;/h1>
&lt;blockquote>
&lt;p>参考&lt;/p>
&lt;/blockquote>
&lt;h2 id="mat-类">Mat 类&lt;/h2>
&lt;p>Mat 类记录在 “核心功能模块 - 基本结构” 中。&lt;/p>
&lt;p>当我们使用 OpenCV 打开一张图片时，就是实例化了一个 Mat 类，这个类的本质是一个 &lt;strong>N-dimensional dense array class(N维密集数组类)&lt;/strong>。说白了就是将图像转为由纯数字表示的形式。任何对图像的处理，其实就是数学计算。&lt;/p>
&lt;p>Mat 类可存储实数或复值向量和矩阵、灰度或彩色图像、体素体积、向量场、点云、张量、直方图（不过，非常高维的直方图可能更好地存储在 SparseMat 中）。&lt;/p>
&lt;p>&lt;strong>对于图像处理来说，实例化一个 Mat 对象，是一切的基础。&lt;/strong>&lt;/p>
&lt;h1 id="图像文件读写模块">图像文件读写模块&lt;/h1>
&lt;h2 id="imread-函数">imread() 函数&lt;/h2>
&lt;p>从文件中读取图像，返回一个 Mat 实例&lt;/p>
&lt;h2 id="imwrite-函数">imwrite() 函数&lt;/h2>
&lt;p>保存图像到指定的文件中。&lt;/p>
&lt;h1 id="video-io-模块">Video I/O 模块&lt;/h1>
&lt;p>使用 OpenCV 读写视频或图像序列。&lt;/p>
&lt;h2 id="videocapture-类">VideoCapture 类&lt;/h2>
&lt;p>用于从视频文件、图像序列或摄像头中捕获视频的类。当我们打开一个视频或一个捕获设备时，就是实例化一个 VideoCapture。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>get() # 获取指定的 VideoCapture 属性&lt;/p>
&lt;/li>
&lt;li>
&lt;p>set() # 设置指定的 VideoCapture 属性&lt;/p>
&lt;/li>
&lt;li>
&lt;p>read() # 抓取、解码并返回下一个视频帧。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>release() # 关闭视频文件或捕获设备(比如摄像头)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="videowriter-类">VideoWriter 类&lt;/h2>
&lt;p>视频写入器的类&lt;/p></description></item><item><title>Docs: OCR</title><link>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Optical_character_recognition">Wiki，Optical_character_recognition&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/models.md">https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/models.md&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Optical character recognition(光学字符识别，简称 OCR)&lt;/strong> 是将图像以电子或机械方式转换为机器编码文本，无论是来自扫描文档、文档照片、场景照片、叠加在图像上的字母文字等。目前是文字识别的统称，已不限于文档或书本文字识别，更包括识别自然场景下的文字，又可以称为 &lt;strong>Scene Text Recognition(场景文字识别，简称 STR)&lt;/strong>。&lt;/p>
&lt;p>OCR 文字识别一般包括两个部分，&lt;strong>文本检测&lt;/strong>和&lt;strong>文本识别&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>文本检测首先利用检测算法检测到图像中的文本块&lt;/li>
&lt;li>然后文本识别利用识别算法去识别文本块中的具体文字&lt;/li>
&lt;/ul>
&lt;h2 id="detection-model检测模型">Detection Model(检测模型)&lt;/h2>
&lt;p>文本检测就是要定位图像中的文字区域，然后通常以边界框的形式将单词或文本行标记出来。传统的文字检测算法多是通过手工提取特征的方式，特点是速度快，简单场景效果好，但是面对自然场景，效果会大打折扣。当前多是采用深度学习方法来做。&lt;/p>
&lt;p>基于深度学习的文本检测算法可以大致分为以下几类：&lt;/p>
&lt;ol>
&lt;li>基于目标检测的方法；一般是预测得到文本框后，通过NMS筛选得到最终文本框，多是四点文本框，对弯曲文本场景效果不理想。典型算法为EAST、Text Box等方法。&lt;/li>
&lt;li>基于分割的方法；将文本行当成分割目标，然后通过分割结果构建外接文本框，可以处理弯曲文本，对于文本交叉场景问题效果不理想。典型算法为DB、PSENet等方法。&lt;/li>
&lt;li>混合目标检测和分割的方法；&lt;/li>
&lt;/ol>
&lt;h2 id="recognition-model识别模型">Recognition Model(识别模型)&lt;/h2>
&lt;p>OCR 识别算法的输入数据一般是文本行，背景信息不多，文字占据主要部分，识别算法目前可以分为两类算法：&lt;/p>
&lt;ol>
&lt;li>基于 CTC 的方法；即识别算法的文字预测模块是基于 CTC 的，常用的算法组合为 CNN+RNN+CTC。目前也有一些算法尝试在网络中加入 transformer 模块等等。&lt;/li>
&lt;li>基于 Attention 的方法；即识别算法的文字预测模块是基于 Attention 的，常用算法组合是 CNN+RNN+Attention&lt;/li>
&lt;/ol>
&lt;h2 id="预处理">预处理&lt;/h2>
&lt;p>为了可以让程序快速检测到字符块后精准识别字符，有的时候还需要对图片进行预处理&lt;/p>
&lt;ul>
&lt;li>比如图片是斜的，我们可以把图片正过来&lt;/li>
&lt;li>若是图片有干扰，可以去掉干扰&lt;/li>
&lt;li>等等&amp;hellip;&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>用稍微简单一些的话说，检测模型用来检查一个图片中，哪些地方可以被识别模型识别；然后交给识别模型。若将图片直接交给识别模型，那么是无法获得任何结果的&lt;/p>
&lt;p>用 PaddleOCR 的识别识别逻辑举例，至少需要用到两种模型：文本检测模型 和 文本识别模型。提供给 PaddleOCR 一张图后，首先先检测图片中包含的文字信息并定位为文本框，然后识别文本框中的文本。&lt;/p>
&lt;blockquote>
&lt;p>Tips: 若想要识别倒转的文字，还可以通过 方向分类器 模型进行预处理。有的 OCR 程序还有很多其他的&lt;strong>预处理&lt;/strong>操作，比如去斑、二值化、线条去除、布局分析 等等。&lt;/p>
&lt;/blockquote>
&lt;p>如下图：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ocr/202310311306270.png" alt="image.png|800">&lt;/p>
&lt;p>用红框框起来的就是检测到的文本框，每个文本框都由 &lt;code>[[196.0, 10.0], [237.0, 10.0], [237.0, 28.0], [196.0, 28.0]]&lt;/code> （这里用 驯兽师 三个字的文本块为例）这样的多维数组进行定位&lt;/p>
&lt;ul>
&lt;li>外层数组共 4 个元素，分别表示文本框的 4 个顶点；0 号元素为 &lt;strong>左上角&lt;/strong>，1 号元素为 &lt;strong>右上角&lt;/strong>，2 号元素为 &lt;strong>右下角&lt;/strong>，3 号元素为 &lt;strong>左下角&lt;/strong>。&lt;/li>
&lt;li>内层数组共 2 个元素，分别表示顶点的横/纵坐标；0 号元素为像素点的&lt;strong>横轴&lt;/strong>坐标，1 号元素为像素点的&lt;strong>纵轴&lt;/strong>坐标。&lt;/li>
&lt;/ul>
&lt;p>然后对每个文本框进行文字识别，以识别出其中的文字。&lt;/p>
&lt;h1 id="paddleocr">PaddleOCR&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/PaddlePaddle/PaddleOCR">GitHub 项目，PaddlePaddle/PaddleOCR&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1iY4y1s7fx">https://www.bilibili.com/video/BV1iY4y1s7fx&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>PaddleOCR 是百度开源的 OCR 工具。旨在打造一套丰富、领先、且实用的OCR工具库，助力开发者训练出更好的模型，并应用落地。&lt;/p>
&lt;h2 id="模型说明">模型说明&lt;/h2>
&lt;p>PaddleOCR 中集成了很多OCR算法，文本检测算法有 DB、EAST、SAST 等等，文本识别算法有CRNN、RARE、StarNet、Rosetta、SRN等算法。&lt;/p>
&lt;p>其中PaddleOCR针对中英文自然场景通用OCR，推出了PP-OCR系列模型，PP-OCR模型由DB+CRNN算法组成，利用海量中文数据训练加上模型调优方法，在中文场景上具备较高的文本检测识别能力。并且 PaddleOCR 推出了高精度超轻量 PP-OCRv2 模型，检测模型仅3M，识别模型仅8.5M，利用 &lt;a href="https://github.com/PaddlePaddle/PaddleSlim">PaddleSlim&lt;/a> 的模型量化方法，可以在保持精度不降低的情况下，将检测模型压缩到 0.8M，识别压缩到 3M，更加适用于移动端部署场景。&lt;/p>
&lt;h2 id="关联文件与配置">关联文件与配置&lt;/h2>
&lt;p>&lt;strong>~/.paddleocr/whl/&lt;/strong> # 模型保存路径。注意：第一次运行调用 PaddleOCR 包运行代码时，会自动下载最新的模型。详见 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/paddleocr.py#L58">paddleocr.py 文件的 MODEL_URLS 变量&lt;/a>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>./cls/&lt;/strong> # Direction Classification(方向分类器) 模型保存路径&lt;/li>
&lt;li>&lt;strong>./det/&lt;/strong> # Detection(检测) 模型保存路径&lt;/li>
&lt;li>&lt;strong>./rec/&lt;/strong> # Recognition(识别) 模型保存路径&lt;/li>
&lt;/ul>
&lt;h2 id="模型下载">模型下载&lt;/h2>
&lt;p>在 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_ch/models_list.md">PP-OCR系列模型列表&lt;/a> 处可以找到三个基本模型以及一个超轻量模型的简介、配置文件、下载地址。&lt;/p>
&lt;ul>
&lt;li>基本模型
&lt;ul>
&lt;li>文本检测模型&lt;/li>
&lt;li>文本识别模型&lt;/li>
&lt;li>文本方向分类模型&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>轻量模型&lt;/li>
&lt;/ul>
&lt;p>模型都分为多个种类&lt;/p>
&lt;ul>
&lt;li>推理模型 # 用于预测引擎推理。通常默认下载这种模型。&lt;/li>
&lt;li>训练模型 与 预训练模型 # 训练过程中保存的模型的参数、优化器状态和训练中间信息，多用于模型指标评估和恢复训练
&lt;ul>
&lt;li>训练模型 # 是基于预训练模型在真实数据与竖排合成文本数据上finetune得到的模型，在真实应用场景中有着更好的表现&lt;/li>
&lt;li>预训练模型 # 则是直接基于全量真实数据与合成数据训练得到，更适合用于在自己的数据集上finetune。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>nb模型 # 经过飞桨Paddle-Lite工具优化后的模型，适用于移动端/IoT端等端侧部署场景（需使用飞桨Paddle Lite部署）。&lt;/li>
&lt;/ul>
&lt;p>选择自己感兴趣的模型，下载即可。下载后，将对应的模型，解压到 &lt;code>ch_PP-OCRv4_server_rec&lt;/code> 目录下对应模型的目录中。比如在 &lt;code>2.1 中文识别模型&lt;/code> 章节中，找到 &lt;code>ch_PP-OCRv4_server_rec&lt;/code> 推理模型，下载并解压到 &lt;code>ch_PP-OCRv4_server_rec/rec/&lt;/code> 目录下即可。其他两个模型同理。这样就可以更换我们感兴趣的模型。&lt;/p>
&lt;h2 id="python-库">Python 库&lt;/h2>
&lt;p>详见：Python 第三方库 &lt;a href="https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python%20%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/paddleocr.md">paddleocr&lt;/a> 包&lt;/p>
&lt;h1 id="实用-ocr工具">实用 OCR工具&lt;/h1>
&lt;h2 id="umi-ocr">Umi-OCR&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/hiroi-sora/Umi-OCR">GitHub 项目，hiroi-sora/Umi-OCR&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/lkoBOAYCdIY8F2Y6FCR-7w">公众号-差评，完全免费，不用联网，这套 OCR 工具比微信的还好用！&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>OCR 图片转文字识别软件，完全离线。截屏/批量导入图片，支持多国语言、合并段落、竖排文字。可排除水印区域，提取干净的文本。基于 PaddleOCR 。&lt;/p></description></item><item><title>Docs: 图像处理模块</title><link>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%A8%A1%E5%9D%97/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/d7/dbd/group__imgproc.html">官方文档，模块-图像处理&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>图像处理模块下还有很多分类&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d4/d86/group__imgproc__filter.html">Image Filtering(图像过滤)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/da/d54/group__imgproc__transform.html">Geometric Image Transformations(几何图像变换)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d7/d1b/group__imgproc__misc.html">Miscellaneous Image Transformations(各种图像转换)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d6/d6e/group__imgproc__draw.html">Drawing Functions(绘图功能)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d8/d01/group__imgproc__color__conversions.html">Color Space Conversions(色彩空间转换)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d3/d50/group__imgproc__colormap.html">ColorMaps in OpenCV(OpenCV 中的颜色图)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/df/d5b/group__imgproc__subdiv2d.html">Planar Subdivision(平面细分)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d6/dc7/group__imgproc__hist.html">Histograms(直方图)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d3/dc0/group__imgproc__shape.html">Structural Analysis and Shape Descriptors(结构分析和形状描述符)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d7/df3/group__imgproc__motion.html">Motion Analysis and Object Tracking(运动分析和对象跟踪)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/dd/d1a/group__imgproc__feature.html">Feature Detection(特征检测)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/df/dfb/group__imgproc__object.html">Object Detection(物体检测)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d3/d47/group__imgproc__segmentation.html">Image Segmentation(图像分割)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/df/d4e/group__imgproc__c.html">C API&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.8.0/d3/df3/group__imgproc__hal.html">Hardware Acceleration Layer(硬件加速层)&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="object-detection物体检测">Object Detection(物体检测)&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/df/dfb/group__imgproc__object.html">官方文档，模块-图像处理-物体检测&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.opencv.org/4.x/de/da9/tutorial_template_matching.html">官方文档，教程-图像处理-模板匹配&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>通过&lt;a href="https://docs.opencv.org/4.x/de/da9/tutorial_template_matching.html">模板匹配&lt;/a>技术查找与模板图像（补丁）匹配（相似）的&lt;strong>图像区域&lt;/strong>的技术。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source image(源图像) (I)&lt;/strong> # 我们期望在其中找到与模板图像匹配的图像。一般就是大图、或者说背景图。&lt;/li>
&lt;li>&lt;strong>Template image(模板图像)（T）&lt;/strong> # 将与源图像进行比较的补丁图像。一般是较小的图片。&lt;/li>
&lt;/ul>
&lt;p>我们的目标是在源图像中检测到与模板图像的最佳匹配区域。比如这样：&lt;/p>
&lt;blockquote>
&lt;p>左边的大图是 I，中间的小图是 T。（x2 是什么意思不知道）。右边的是找到的图像区域。i.e. 在 I 中找到 T，用红框标出来&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/opencv/202311251931362.png" alt="image.png">&lt;/p>
&lt;p>为了识别匹配区域，通过 &lt;strong>sliding(滑动)&lt;/strong> 模板图像，以便与源图像进行比较。所谓的滑动，意思是将 T 一次移动一个像素（从左到右，从上到下）。我们将这个滑动的模板图像称为 &lt;strong>patch&lt;/strong>，patch 每移动一次，在当前位置，会根据 &lt;strong>Match mode(匹配模式)&lt;/strong> 计算一个 &lt;strong>metric(度量)&lt;/strong> 值以表示该位置的匹配程度是 “好”或“坏”（可以理解为模板图像在源图像的某个特定区域的相似程度）。除了计算出来的 metric，还有 &lt;strong>patch 左上角顶点&lt;/strong>的 &lt;strong>横/纵坐标&lt;/strong>。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/opencv/202311251931030.png" alt="image.png">&lt;/p>
&lt;p>对于 I 上 T 的每个位置，都会保存一份 metric 到 &lt;strong>result matrix(结果矩阵) R&lt;/strong> 中。&lt;/p>
&lt;p>下图是使用 &lt;strong>TM_CCORR_NORMED 匹配方法&lt;/strong>滑动 T 的结果 R。通过 &lt;code>minMaxLoc()&lt;/code> 函数可以定位到红色圆圈标记的矩形左上角的横纵坐标，该位置就是对于 T 来说在 I 上的&lt;strong>最佳匹配位置&lt;/strong>。黑色矩形就是匹配到的图像区域（之所以能画出来这个匹配到的矩形区域，是因为基于左上角这个点，使用模板图像的宽和高，即可画出来这个矩形）。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/opencv/202311251933896.png" alt="image.png">&lt;/p>
&lt;p>在实践中&lt;/p>
&lt;ul>
&lt;li>首先使用 &lt;code>matchTemplate()&lt;/code> 函数进行匹配并获取匹配到的图像区域，函数接受 3 个参数：源图像、模板图像、匹配方法。&lt;/li>
&lt;li>然后使用 &lt;code>minMaxLoc()&lt;/code> 函数从匹配到的图像区域中定位 R 矩阵中的最高值或最低值，和匹配到该值的图像区域，这个结果只是针对匹配到的图像区域的左上角的信息，
&lt;ul>
&lt;li>min_val 和 max_val 是根据算法得到的最好匹配结果或者最差匹配结果（不用的匹配方法，对于结果值的解读不同）&lt;/li>
&lt;li>min_loc 和 max_loc 是对应图像区域的左上角的横/纵坐标。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 返回一个结果矩阵 R&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>matchedResult &lt;span style="color:#f92672">=&lt;/span> cv2&lt;span style="color:#f92672">.&lt;/span>matchTemplate(source_img, temp_img, cv2&lt;span style="color:#f92672">.&lt;/span>TM_CCOEFF_NORMED)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 返回 patch 的最大值和最小值，以及这两个值所在位置的横纵坐标&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>min_val, max_val, min_loc, max_loc &lt;span style="color:#f92672">=&lt;/span> cv2&lt;span style="color:#f92672">.&lt;/span>minMaxLoc(late)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中匹配方式指的是一种数学公式（高数），也可以称为 匹配算法、匹配模式。共有 6 中匹配方法，不同的计算方式产生的结果的意义不一样。有些返回值越大表示匹配度越高，而有些返回值越小表示匹配程度越好：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>TM_SQDIFF&lt;/strong> # 平方差匹配法：该方法采用平方差来进行匹配；0 表示最好的匹配结果；数值越小，匹配效果越好。&lt;/li>
&lt;li>&lt;strong>TM_SQDIFF_NORMED&lt;/strong> # 标准平方差匹配法&lt;/li>
&lt;li>&lt;strong>TM_CCORR&lt;/strong> # 相关匹配法：该方法采用乘法操作；0 表示最坏的匹配结果；数值越大，匹配效果越好&lt;/li>
&lt;li>&lt;strong>TM_CCORR_NORMED&lt;/strong> # 标准相关匹配法&lt;/li>
&lt;li>&lt;strong>TM_CCOEFF&lt;/strong> # 相关系数匹配法：1 表示完美的匹配；-1 表示最差的匹配，0 表示没有任何相关性(随机序列)。数值越大，匹配效果越好&lt;/li>
&lt;li>&lt;strong>TM_CCOEFF_NORMED&lt;/strong> # 标准相关系数匹配法&lt;/li>
&lt;/ul></description></item></channel></rss>