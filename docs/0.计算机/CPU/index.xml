<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – CPU</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/</link><description>Recent content in CPU on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: CPU</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/CPU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/CPU/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;p>&lt;strong>Central Processing Unit(中央处理器，简称 CPU)&lt;/strong>。
如同华硕主板示意图上半部的中央部分，那就是 CPU 插槽。由于 CPU 负责大量运算，因此 CPU 通常是具有相当高发热量的元件。所以如果你曾经拆开过主板，应该就会看到 CPU 上头通常会安插一颗风扇来主动散热的。&lt;/p>
&lt;p>x86 个人电脑的 CPU 主要供应商为 Intel 与 AMD，目前（2015）主流的 CPU 都是双核以上的架构了！原本的单核心 CPU 仅有一个运算单元，所谓的多核心则是在一颗 CPU 封装当中嵌入了两个以上的运算核心， 简单的说，就是一个实体的 CPU 外壳中，含有两个以上的 CPU 单元就是了。&lt;/p>
&lt;p>不同的 CPU 型号大多具有不同的脚位（CPU 上面的插脚），能够搭配的主板芯片组也不同， 所以当你想要将你的主机升级时，不能只考虑 CPU，你还得要留意你的主板上面所支持的 CPU 型号喔！不然买了最新的 CPU 也不能够安插在你的旧主板上头的！目前主流的 CPU 有 Intel 的 i3/i5/i7 系列产品中，甚至先后期出厂的类似型号的脚位也不同， 例如 i7-2600 使用 LGA1155 脚位而 i7-4790 则使用 FCLGA1150 脚位，挑选时必须要很小心喔！&lt;/p>
&lt;p>我们前面谈到 CPU 内部含有微指令集，不同的微指令集会导致 CPU 工作效率的优劣。除了这点之外， CPU 性能的比较还有什么呢？那就是 CPU 的频率了！什么是频率呢？简单的说， 频率就是 CPU 每秒钟可以进行的工作次数。所以频率越高表示这颗 CPU 单位时间内可以作更多的事情。举例来说，Intel 的 i7-4790 CPU 频率为 3.6GHz， 表示这颗 CPU 在一秒内可以进行 3.6x109 次工作，每次工作都可以进行少数的指令运行之意。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/lgtxxk/1616168680795-7c145400-1473-4cdc-b525-3a106f810f80.gif" alt="">&lt;/p>
&lt;p>&lt;strong>Tips&lt;/strong>注意，不同的 CPU 之间不能单纯的以频率来判断运算性能喔！这是因为每颗 CPU 的微指令集不相同，架构也不见得一样，可使用的第二层高速缓存及其计算机制可能也不同，加上每次频率能够进行的工作指令数也不同！所以，频率目前仅能用来比较同款 CPU 的速度！&lt;/p>
&lt;p>CPU 的工作频率：外频与倍频&lt;/p>
&lt;p>早期的 CPU 架构主要通过北桥来链接系统最重要的 CPU、内存与显卡设备。因为所有的设备都得通过北桥来链接，因此每个设备的工作频率应该要相同。于是就有所谓的前端总线（FSB） 这个东西的产生。但因为 CPU 的运算速度比其他的设备都要来的快，又为了要满足 FSB 的频率，因此厂商就在 CPU 内部再进行加速， 于是就有所谓的外频与倍频了。&lt;/p>
&lt;p>总结来说，在早期的 CPU 设计中，所谓的外频指的是 CPU 与外部元件进行数据传输时的速度，倍频则是 CPU 内部用来加速工作性能的一个倍数， 两者相乘才是 CPU 的频率速度。例如 Intel Core 2 E8400 的内频为 3.0GHz，而外频是 333MHz，因此倍频就是 9 倍啰！（3.0G=333Mx9, 其中 1G=1000M）&lt;/p>
&lt;h2 id="超频">超频&lt;/h2>
&lt;p>&lt;strong>Tips&lt;/strong>很多计算机硬件玩家很喜欢玩“超频”，所谓的超频指的是：将 CPU 的倍频或者是外频通过主板的设置功能更改成较高频率的一种方式。但因为 CPU 的倍频通常在出厂时已经被锁定而无法修改，因此较常被超频的为外频。举例来说，像上述 3.0GHz 的 CPU 如果想要超频，可以将他的外频 333MHz 调整成为 400MHz，但如此一来整个主板的各个元件的运行频率可能都会被增加成原本的 1.333 倍(4/ 3)，虽然 CPU 可能可以到达 3.6GHz，但却因为频率并非正常速度，故可能会造成死机等问题。&lt;/p>
&lt;p>但如此一来所有的数据都被北桥卡死了，北桥又不可能比 CPU 更快，因此这家伙常常是系统性能的瓶颈。为了解决这个问题，新的 CPU 设计中， 已经将内存控制器整合到 CPU 内部，而链接 CPU 与内存、显卡的控制器的设计，在 Intel 部份使用 QPI （Quick Path Interconnect） 与 DMI 技术，而 AMD 部份则使用 Hyper Transport 了，这些技术都可以让 CPU 直接与内存、显卡等设备分别进行沟通，而不需要通过外部的链接芯片了。&lt;/p>
&lt;p>因为现在没有所谓的北桥了（整合到 CPU 内），因此，CPU 的频率设计就无须考虑得要同步的外频，只需要考虑整体的频率即可。所以，如果你经常有查阅自己 CPU 频率的习惯，当使用 cpu-z [9]这个软件时，应该会很惊讶的发现到，怎么外频变成 100MHz 而倍频可以到达 30 以上！相当有趣呢！&lt;/p>
&lt;p>&lt;strong>Tips&lt;/strong> 现在 Intel 的 CPU 会主动帮你超频喔！例如 i7-4790 这颗 CPU 的规格[10]中，基本频率为 3.6GHz，但是最高可自动超频到 4GHz 喔！通过的是 Intel 的 turbo 技术。同时，如果你没有大量的运算需求，该 CPU 频率会降到 1.xGHz 而已，借此达到节能省电的目的！所以，各位好朋友，不需要自己手动超频了！Intel 已经自动帮你进行超频了&amp;hellip;所以，如果你用 cpu-z 观察 CPU 频率，发现该频率会一直自动变动，很正常！你的系统没坏掉！&lt;/p>
&lt;p>32 位与 64 位的 CPU 与总线“宽度”&lt;/p>
&lt;p>从前面的简易说明中，我们知道 CPU 的各项数据通通得要来自于内存。因此，如果内存能提供给 CPU 的数据量越大的话，当然整体系统的性能应该也会比较快！那如何知道内存能提供的数据量呢？此时还是得要借由 CPU 内的内存控制芯片与内存间的传输速度“前端总线速度（Front Side Bus, FSB） 来说明。&lt;/p>
&lt;p>与 CPU 的频率类似的，内存也是有其工作的频率，这个频率限制还是来自于 CPU 内的内存控制器所决定的。以图 0.2.1 为例， CPU 内置的内存控制芯片对内存的工作频率最高可达到 1600MHz。这只是工作频率（每秒几次）。一般来说，每次频率能够传输的数据量，大多为 64 位，这个 64 位就是所谓的“宽度”了！因此，在图 0.2.1 这个系统中，CPU 可以从内存中取得的最快带宽就是 1600MHz &lt;em>64bit = 1600MHz&lt;/em> 8 Bytes = 12.8GByte/s。&lt;/p>
&lt;p>与总线宽度相似的，CPU 每次能够处理的数据量称为字组大小（word size）， 字组大小依据 CPU 的设计而有 32 位与 64 位。我们现在所称的电脑是 32 或 64 位主要是依据这个 CPU 解析的字组大小而来的！早期的 32 位 CPU 中，因为 CPU 每次能够解析的数据量有限， 因此由内存传来的数据量就有所限制了。这也导致 32 位的 CPU 最多只能支持最大到 4GBytes 的内存。&lt;/p>
&lt;p>&lt;strong>Tips&lt;/strong> 得利于北桥整合到 CPU 内部的设计，CPU 得以“个别”跟各个元件进行沟通！因此，每种元件与 CPU 的沟通具有很多不同的方式！例如内存使用系统总线带宽来与 CPU 沟通。而显卡则通过 PCI-E 的序列信道设计来与 CPU 沟通喔！详细说明我们在本章稍后的主板部份再来谈谈。&lt;/p>
&lt;p>CPU 等级&lt;/p>
&lt;p>由于 x86 架构的 CPU 在 Intel 的 Pentium 系列（1993 年）后就有不统一的脚位与设计，为了将不同种类的 CPU 规范等级， 所以就有 i386,i586,i686 等名词出现了。基本上，在 Intel Pentium MMX 与 AMD K6 年代的 CPU 称为 i586 等级， 而 Intel Celeron 与 AMD Athlon（K7）年代之后的 32 位 CPU 就称为 i686 等级。至于目前的 64 位 CPU 则统称为 x86_64 等级。&lt;/p>
&lt;p>目前很多的程序都有对 CPU 做最优化的设计，万一哪天你发现一些程序是注明给 x86_64 的 CPU 使用时， 就不要将他安装在 686 以下等级的电脑中，否则可是会无法执行该软件的！不过，在 x86_64 的硬件下倒是可以安装 386 的软件喔！也就是说，这些东西具有向下相容的能力啦！&lt;/p>
&lt;h2 id="超线程hyper-threading-ht">超线程（Hyper-Threading, HT）&lt;/h2>
&lt;p>我们知道现在的 CPU 至少都是两个核心以上的多核心 CPU 了，但是 Intel 还有个很怪的东西，叫做 CPU 的超线程（Hyper-Threading） 功能！那个是啥鬼东西？我们知道现在的 CPU 运算速度都太快了，因此运算核心经常处于闲置状态下。而我们也知道现在的系统大多都是多任务的系统， 同时间有很多的程序会让 CPU 来执行。因此，若 CPU 可以假象的同时执行两个程序，不就可以让系统性能增加了吗？反正 CPU 的运算能力还是没有用完啊！&lt;/p>
&lt;p>那是怎么达成的啊这个 HT 功能？强者鸟哥的同事蔡董大大用个简单的说明来解释。在每一个 CPU 内部将重要的寄存器（register） 分成两群， 而让程序分别使用这两群寄存器。也就是说，可以有两个程序“同时竞争 CPU 的运算单元”，而非通过操作系统的多任务切换！这一过程就会让 CPU 好像“同时有两个核心”的模样！因此，虽然大部分 i7 等级的 CPU 其实只有四个实体核心，但通过 HT 的机制， 则操作系统可以抓到八个核心！并且让每个核心逻辑上分离，就可以同时运行八个程序了。&lt;/p>
&lt;p>虽然很多研究与测试中，大多发现 HT 虽然可以提升性能，不过，有些情况下却可能导致性能降低喔！因为，实际上明明就仅有一个运算单元嘛！不过在鸟哥使用数值模式的情况下，因为鸟哥操作的数值模式主要为平行运算功能，且运算通常无法达到 100% 的 CPU 使用率，通常仅有大约 60%运算量而已。因此在鸟哥的实作过程中，这个 HT 确实提升相当多的性能！至少应该可以节省鸟哥大约 30%~50%的等待时间喔！不过网络上大家的研究中， 大多说这个是 case by case，而且使用的软件影响很大！所以，在鸟哥的例子是启用 HT 帮助很大！您的案例就得要自行研究啰！&lt;/p></description></item><item><title>Docs: CPU 精简指令集</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/CPU-%E7%B2%BE%E7%AE%80%E6%8C%87%E4%BB%A4%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/CPU-%E7%B2%BE%E7%AE%80%E6%8C%87%E4%BB%A4%E9%9B%86/</guid><description>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/VMDpW67zhJka0DKL8TQHrA">不懂精简指令集还敢说自己是程序员？&lt;/a>&lt;/p>
&lt;p>在上一篇文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&amp;amp;mid=2247486061&amp;amp;idx=1&amp;amp;sn=bc175595029d08f4766b7fe2468db5d8&amp;amp;chksm=fcb98d33cbce0425e02a9ddbba62d7da62201b2086af533a96f248aa9697ee4d66a404110341&amp;amp;scene=21#wechat_redirect">CPU 进化论：复杂指令集&lt;/a>》中我们从历史的角度讲述了复杂指令集出现的必然，随着时间的推移，采用复杂指令集架构的 CPU 出现各种各样的问题，面对这些问题一部分人开始重新思考指令集到底该如何设计。&lt;/p>
&lt;p>在这一时期，两个趋势的出现促成一种新的指令集设计思想。&lt;/p>
&lt;p>&lt;strong>内存与编译器&lt;/strong>&lt;/p>
&lt;p>时间来到了 1980s 年代，此时容量 “高达”64K 的内存开始出现，内存容量上终于不再捉襟见肘，价格也开始急速下降，在 1977 年，1MB 内存的价格高达**$5000**，要知道这可是 1977 年的 5000 刀，但到了 1994 年，1MB 内存价格就急速下降到大概只有 $6，这是第一个趋势。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcyvicvtS0zS0TmLEyibzO3IPzDBIcp5EPKmFQBgickYJ9YjKIcmOZgyeMwA/640?wx_fmt=png#id=kl2bC&amp;amp;originHeight=460&amp;amp;originWidth=715&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>此外在这一时期随着编译技术的进步，编译器越来越成熟，&lt;strong>渐渐的程序员们开始依靠编译器来生成汇编指令而不再自己手工编写&lt;/strong>。&lt;/p>
&lt;p>这两个趋势的出现让人们有了更多思考。&lt;/p>
&lt;h5 id="heading">&lt;/h5>
&lt;p>&lt;strong>化繁为简&lt;/strong>&lt;/p>
&lt;p>19 世纪末 20 世纪初意大利经济学家 Pareto 发现，在任何一组东西中，最重要的只占其中一小部分，约 20%，其余 80% 尽管是多数，却是次要的，这就是著名的二八定律，机器指令的执行频率也有类似的规律。&lt;/p>
&lt;p>大概 80% 的时间 CPU 都在执行那 20% 的机器指令，同时 CISC 中一部分比较复杂的指令并不怎么被经常用到，而且那些&lt;strong>设计编译器的程序员也更倾向于组合一些简单的指令来完成特定任务。&lt;/strong>&lt;/p>
&lt;p>与此同时我们在上文提到过的一位计算机科学家，被派去改善微代码设计，但后来这老哥发现有问题的是微代码本身，因此开始转过头来去思考微代码这种设计的问题在哪里。&lt;/p>
&lt;p>他的早期工作提出一个关键点，复杂指令集中那些被认为可以提高性能的指令其实在内部被微代码拖后腿了，如果移除掉微代码，程序反而可以运行的更快，并且可以节省构造 CPU 消耗的晶体管数量。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcyJfsicib1IzSjnYicl0YqHiaeWFPzqicwd4PLZAQWVXh1UV40bTEAA1bY9Gg/640?wx_fmt=png#id=lApuZ&amp;amp;originHeight=657&amp;amp;originWidth=1030&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>由于微代码的设计思想是将复杂机器指令&lt;strong>在 CPU 内部&lt;/strong>转为相对简单的机器指令，这一过程对编译器不可见，也就是说你没有办法通过编译器去影响 CPU 内部的微代码运行行为，因此如果微代码出现 bug 那么编译器是无能为力的，你没有办法通过编译器生成其它机器指令来修复问题而只能去修改微代码本身。&lt;/p>
&lt;p>此外他还发现，有时一些复杂的机器指令执行起来要比等价的多个简单指令要。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcyMXxicNgpjphy7Ynbe4XbbhwEeCdzIPia3zSXFIyIiatvhx4ZZF9DxphvQ/640?wx_fmt=png#id=m5lPU&amp;amp;originHeight=306&amp;amp;originWidth=1080&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>这一切都在提示：&lt;strong>为什么不直接用一些简单到指令来替换掉那些复杂的指令呢&lt;/strong>？&lt;/p>
&lt;h5 id="heading-1">&lt;/h5>
&lt;p>&lt;strong>精简指令集哲学&lt;/strong>&lt;/p>
&lt;p>基于对复杂指令集的思考，精简指令集哲学诞生了，精简指令集主要体现在以下三个方面：&lt;/p>
&lt;p>&lt;strong>1，指令本身的复杂度&lt;/strong>&lt;/p>
&lt;p>精简指令集的思想其实很简单，干嘛要去死磕复杂的指令，去掉复杂指令代之以一些简单的指令。&lt;/p>
&lt;p>有了简单指令 CPU 内部的微代码也不需要了，没有了微代码这层中间抽象，编译器生成的机器指令对 CPU 的控制力大大增强，有什么问题让写编译器的那帮家伙修复就好了，显然调试编译器这种软件要比调试 CPU 这种硬件要简单很多。&lt;/p>
&lt;p>注意，&lt;strong>精简指令集思想不是说指令集中指令的数量变少，而是说一条指令背后代表的动作更简单了&lt;/strong>。&lt;/p>
&lt;p>举个简单的例子，复杂指令集中的一条指令背后代表的含义是 “吃饭” 的全部过程，而精简指令集中的一条指令仅仅表示 “咀嚼一下” 的其中一个小步骤。&lt;/p>
&lt;p>博主在《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&amp;amp;mid=2247485439&amp;amp;idx=1&amp;amp;sn=5045e795fe3a881ec719ffd0ea41302a&amp;amp;chksm=fcb980a1cbce09b7cb79cac0964d082bda3f8b94701012ab5fbd911d630bd5fef6017feb6dd9&amp;amp;scene=21#wechat_redirect">你管这破玩意叫编程语言&lt;/a>》一文中举得例子其实更形象一些，复杂指令集下一条指令可以表示 “给我端杯水”，而在精简指令集下你需要这样表示：&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcySDa83ZSlHPLnmsafM68EYYLxfE3Fblhxx23ps9avicNcO3bXibVm23yQ/640?wx_fmt=png#id=hfbSU&amp;amp;originHeight=711&amp;amp;originWidth=1078&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>&lt;strong>2，编译器&lt;/strong>&lt;/p>
&lt;p>精简指令集的另一个特点就是编译器对 CPU 的控制力更强。&lt;/p>
&lt;p>在复杂指令集下，CPU 会对编译器隐藏机器指令的执行细节，就像微代码一样，编译器对此无能为力。&lt;/p>
&lt;p>而在精简指令集下 CPU 内部的操作细节暴露给编译器，编译器可以对其进行控制，也因此，精简指令集 RISC 还有一个有趣的称呼：“&lt;strong>R&lt;/strong>elegate &lt;strong>I&lt;/strong>nteresting &lt;strong>S&lt;/strong>tuff to &lt;strong>C&lt;/strong>ompiler”，把一些有趣的玩意儿让编译器来完成。&lt;/p>
&lt;p>&lt;strong>3，load/store architecture&lt;/strong>&lt;/p>
&lt;p>在复杂指令集下，一条机器指令可能涉及到从&lt;strong>内存&lt;/strong>中取出数据、执行一些操作比如加和、然后再把执行结果写回到内存中，注意这是在一条机器指令下完成的。&lt;/p>
&lt;p>但在精简指令集下，这绝对是大写的禁忌，&lt;strong>精简指令集下的指令只能操作寄存器中的数据&lt;/strong>，不可以直接操作内存中的数据，也就是说这些指令比如加法指令不会去访问内存。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcyaTUmS8YAejM93sc6xgDjZq75M5vYuzejCmrU2MYcr04M3FBr9DegrA/640?wx_fmt=png#id=eRUmP&amp;amp;originHeight=407&amp;amp;originWidth=1080&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>毕竟数据还是存放在内存中的，那么谁来读写内存呢？&lt;/p>
&lt;p>&lt;strong>原来在精简指令集下有专用的 load 和 store 两条机器指令来负责内存的读写&lt;/strong>，其它指令只能操作 CPU 内部的寄存器，这是和复杂指令集一个很鲜明的区别。&lt;/p>
&lt;p>你可能会好奇，用两条专用的指令来读写内存有什么好处吗？别着急，在本文后半部分我们还会回到 load/store 指令。&lt;/p>
&lt;p>以上就是三点就是精简指令集的设计哲学。&lt;/p>
&lt;p>接下来我们用一个例子来看下 RISC 和 CISC 的区别。&lt;/p>
&lt;h5 id="heading-2">&lt;/h5>
&lt;p>&lt;strong>两数相乘&lt;/strong>&lt;/p>
&lt;p>如图所示就是最经典的计算模型，最右边是内存，存放机器指令和数据，最左侧是 CPU，CPU 内部是寄存器和计算单元 ALU，进一步了解 CPU 请参考《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&amp;amp;mid=2247485529&amp;amp;idx=1&amp;amp;sn=4a1154e4acfb4335a44a81260485c7ca&amp;amp;chksm=fcb98f07cbce061138c68333f6c9c73e02321400c66c9835aee956a00bf4e8c54fefee678fd7&amp;amp;scene=21#wechat_redirect">你管这破玩意叫 CPU？&lt;/a>》&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcyZUH7DF0reMeGnpyd85zkgY6iaLhIpsibB6Est16RF0KNLwdGGmg0ERjQ/640?wx_fmt=png#id=iVDq5&amp;amp;originHeight=338&amp;amp;originWidth=429&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>内存中的地址 A 和地址 B 分别存放了两个数，假设我们想计算这两个数字之和，然后再把计算结果写回内存地址 A。&lt;/p>
&lt;p>我们分别来看下在 CISC 和在 RISC 下的会怎样实现。&lt;/p>
&lt;p>&lt;strong>1，CISC&lt;/strong>&lt;/p>
&lt;p>复杂指令集的一个主要目的就是让尽可能少的机器指令来完成尽可能多的任务，在这种思想下 CPU 需要在从内存中拿到一条机器指令后 “&lt;strong>自己去完成一系列的操作&lt;/strong>”，这部分操作对外不可见。&lt;/p>
&lt;p>在这种方法下，CISC 中可能会存在一条叫做 MULT 的机器指令，MULT 是乘法&lt;strong>mult&lt;/strong>iplication 的简写。&lt;/p>
&lt;p>当 CPU 执行 MULT 这条机器指令时需要：&lt;/p>
&lt;ol>
&lt;li>从内存中加载地址 A 上的数，存放在寄存器中&lt;/li>
&lt;li>从内存中夹杂地址 B 上的数，存放在寄存器中&lt;/li>
&lt;li>ALU 根据寄存器中的值进行乘积&lt;/li>
&lt;li>将乘积写回内存&lt;/li>
&lt;/ol>
&lt;p>以上这几部统统都可以用这样一条指令来完成：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-nginx" data-lang="nginx">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">MULT&lt;/span> &lt;span style="color:#e6db74">A&lt;/span> &lt;span style="color:#e6db74">B&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>MULT 就是所谓的复杂指令了，从这里我们也可以看出，&lt;strong>复杂指令并不是说 “MULT A B” 这一行指令本身有多复杂，而是其背后所代表的任务复杂。&lt;/strong>&lt;/p>
&lt;p>这条机器指令直接从内存中加载数据，程序员 (写汇编语言或者写编译器的程序员) 根本就不要自己显示的从内存中加载数据，实际上这条机器指令已经非常类似高级语言了，我们假设内存地址 A 中的值为变量 a，地址 B 中的值为变量 b，那么这条机器指令基本等价于高级语言中这样一句：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">a&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">a * b;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这就是我们在上一篇《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&amp;amp;mid=2247486061&amp;amp;idx=1&amp;amp;sn=bc175595029d08f4766b7fe2468db5d8&amp;amp;chksm=fcb98d33cbce0425e02a9ddbba62d7da62201b2086af533a96f248aa9697ee4d66a404110341&amp;amp;scene=21#wechat_redirect">CPU 进化论：复杂指令集&lt;/a>》中提到的所谓抹平差异，semantic gap，抹平高级语言和机器指令之间的差异，让程序员或者编译器使用最少的代码就能完成任务，因为这会节省程序本身占用的内存空间，要知道在在 1977 年，1MB 内存的价格大概需要 $5000，&lt;strong>省下来的就是钱&lt;/strong>。&lt;/p>
&lt;p>因为一条机器指令背后的操作很多，而程序员仅仅就写了一行 “MULT A B”，这行指令背后的复杂操作就必须由 CPU 直接通过硬件来实现，这加重了 CPU 硬件本身的复杂度，需要的晶体管数量也更多。&lt;/p>
&lt;p>接下来我们看 RISC 方法。&lt;/p>
&lt;p>&lt;strong>2，RISC&lt;/strong>&lt;/p>
&lt;p>相比之下 RISC 更倾向于使用一系列简单的指令来完成一项任务，我们来看下一条 MULT 指令需要完成的操作：&lt;/p>
&lt;ol>
&lt;li>从内存中加载地址 A 上的数，存放在寄存器中&lt;/li>
&lt;li>从内存中夹杂地址 B 上的数，存放在寄存器中&lt;/li>
&lt;li>ALU 根据寄存器中的值进行乘积&lt;/li>
&lt;li>将乘积写回内存&lt;/li>
&lt;/ol>
&lt;p>这几步需要 a) 从内存中读数据；b) 乘积；c) 向内存中写数据，因此在 RISC 下会有对应的 LOAD、PROD、STORE 指令来分别完成这几个操作。&lt;/p>
&lt;p>Load 指令会将数据从内存搬到寄存器；PROD 指令会计算两个寄存器中数字的乘积；Store 指令把寄存器中的数据写回内存，因此如果一个程序员想完成上述任务就需要写这些汇编指令：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-properties" data-lang="properties">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">LOAD&lt;/span> &lt;span style="color:#e6db74">RA, A&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">LOAD&lt;/span> &lt;span style="color:#e6db74">RB, B&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">PROD&lt;/span> &lt;span style="color:#e6db74">RA, RB&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">STORE&lt;/span> &lt;span style="color:#e6db74">A, RA&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在你应该看到了，同样一项任务，在 CISC 下只需要一条机器指令，而在 RISC 下需要四条机器指令，显然 RISC 下的程序本身所占据的空间要比 CISC 大，而且这对直接用汇编语言来写程序的程序员来说是很不友好的，因为更繁琐嘛！再来看看这样图感受一下：&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcySDa83ZSlHPLnmsafM68EYYLxfE3Fblhxx23ps9avicNcO3bXibVm23yQ/640?wx_fmt=png#id=B2xzX&amp;amp;originHeight=711&amp;amp;originWidth=1078&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>但 RISC 设计的初衷也&lt;strong>不是让程序员直接使用汇编语言来写程序&lt;/strong>，而是把这项任务交给编译器，让编译器来生成机器指令。&lt;/p>
&lt;h5 id="heading-3">&lt;/h5>
&lt;p>&lt;strong>标准从来都是一个好东西&lt;/strong>&lt;/p>
&lt;p>让我们再来仔细的看一下 RISC 下生成的几条指令：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-properties" data-lang="properties">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">LOAD&lt;/span> &lt;span style="color:#e6db74">RA, A&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">LOAD&lt;/span> &lt;span style="color:#e6db74">RB, B&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">PROD&lt;/span> &lt;span style="color:#e6db74">RA, RB&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">STORE&lt;/span> &lt;span style="color:#e6db74">A, RA&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这些指令都非常简单，CPU 内部不需要复杂的硬件逻辑来进行解码，因此更节省晶体管，这些节省下来的晶体管可用于其它功能上。&lt;/p>
&lt;p>最关键的是，注意，由于每一条指令都很简单，执行的时间都差不多，因此这使得一种能高效处理机器指令的方法成为可能，这项技术是什么呢？&lt;/p>
&lt;p>我们在《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&amp;amp;mid=2247485484&amp;amp;idx=1&amp;amp;sn=d5d00e08b7e91caaf35c03f3ef19d47b&amp;amp;chksm=fcb98f72cbce0664139f9b0ab9e23f5c88164bac95c7dd146cf29484e96ebc2c7ea13e9b01ed&amp;amp;scene=21#wechat_redirect">CPU 遇上特斯拉，程序员的心思你别猜&lt;/a>》这篇文章中提到过，这就是有名的&lt;strong>流水线技术&lt;/strong>。&lt;/p>
&lt;h5 id="heading-4">&lt;/h5>
&lt;p>&lt;strong>指令流水线&lt;/strong>&lt;/p>
&lt;p>流水线技术是初期精简指令集的杀手锏。&lt;/p>
&lt;p>在这里我们还是以生产汽车 (新能源) 为例来介绍一下。&lt;/p>
&lt;p>假设组装一辆汽车需要经过四个步骤：组装车架、安装引擎、安装电池、检验。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcySVK3y9s6QojhMRsCSuCnFZcYgDyQIL32cWseMlj40cr0R77eTc2DZA/640?wx_fmt=png#id=FKiie&amp;amp;originHeight=833&amp;amp;originWidth=895&amp;amp;originalType=binary&amp;amp;ratio=1&amp;amp;status=done&amp;amp;style=none" alt="">&lt;/p>
&lt;p>假设这每个步骤需要 10 分钟，如果没有流水线技术，那么生产一辆汽车的时间是 40 分钟，只有第一辆汽车完整的经过这四个步骤后下一辆车才能进入生产车间。&lt;/p>
&lt;p>这就是最初复杂指令集 CPU 的工作场景。&lt;/p>
&lt;p>显然这是相当低效的，因为当前一辆车在进行最后一个步骤时，前三个步骤：组装车架、安装引擎、安装电池，这三个步骤的工人是空闲。&lt;/p>
&lt;p>CPU 的道理也是一样的，低效的原因在于没有充分利用资源，在这种方法下有人会偷懒。&lt;/p>
&lt;p>但引入流水线技术就不一样了，当第一辆车还在安装引擎时后一辆车就可以进入流水线来组装车架了，采用流水线技术，四个步骤可以同时进行，&lt;strong>最大可能的充分利用资源&lt;/strong>。&lt;/p>
&lt;p>原来 40 分钟才能生产一辆车，现在有了流水线技术可以 10 分钟就生产出一辆车。&lt;/p>
&lt;p>注意，这里的假设是每个步骤都需要 10 分钟，&lt;strong>如果流水线每个阶段的耗时不同，将显著影响流水线的处理能力&lt;/strong>。&lt;/p>
&lt;p>假如其中一个步骤，安装电池，需要 20 分钟，那么安装电池的前一个和后一个步骤就会有 10 分钟的空闲，这显然不能充分利用资源。&lt;/p>
&lt;p>精简指令集的设计者们当然也明白这个道理，因此&lt;strong>他们尝试让每条指令执行的时间都差不多一样&lt;/strong>，尽可能让流水线更高效的处理机器指令，而这也是为什么在精简指令集中存在 Load 和 Store 两条访问内存指令的原因。&lt;/p>
&lt;p>由于复杂指令集指令与指令之间差异较大，执行时间参差不齐，没办法很好的以流水线的方式高效处理机器指令 (后续我们会看到复杂指令集会改善这一点)。&lt;/p>
&lt;p>第一代 RISC 处理器即为全流水线设计，典型的就是五级流水线，大概 1 到 2 个时钟周期就能执行一条指令，而这一时期的 CISC 大概 5 到 10 个时钟周期才能执行一条指令，尽管 RISC 架构下编译出的程序需要更多指令，但 RISC 精简的设计使得 RISC 架构下的 CPU 更紧凑，消耗更少的晶体管 (无需微代码)，因此带来更高的主频，这使得 RISC 架构下的 CPU 完成相同的任务速度优于 CISC。&lt;/p>
&lt;p>有流水线技术的加持，采用精简指令集设计的 CPU 在性能上开始横扫其复杂指令集对手。&lt;/p>
&lt;h5 id="heading-5">&lt;/h5>
&lt;p>&lt;strong>名扬天下&lt;/strong>&lt;/p>
&lt;p>到了 1980 年代中期，采用精简指令集的商业 CPU 开始出现，到 1980 年代后期，采用精简指令集设计的 CPU 就在性能上轻松碾压所有传统设计。&lt;/p>
&lt;p>到了 1987 年采用 RISC 设计的 MIPS R2000 处理器在性能上是采用 CISC 架构 (x86) 的 Intel i386DX 两到三倍。&lt;/p>
&lt;p>所有其它 CPU 生成厂商都开始跟进 RISC，积极采纳精简指令集设计思想，甚至操作系统 MINIX（就是那个 Linus 上大学时使用的操作系统）的作者 Andrew Tanenbaum 在 90 年代初预言：“5 年后 x86 将无人问津”，x86 正是基于 CISC。&lt;/p>
&lt;p>&lt;strong>CISC 迎来至暗时刻&lt;/strong>。&lt;/p>
&lt;p>接下来 CISC 该如何绝地反击，要知道 Inter 以及 AMD (x86 处理器两大知名生产商) 的硬件工程师们绝非等闲之辈。&lt;/p>
&lt;p>预知后事如何，请听下回分解。&lt;/p>
&lt;h5 id="heading-6">&lt;/h5>
&lt;p>&lt;strong>总结&lt;/strong>&lt;/p>
&lt;p>CISC 中微代码设计的复杂性让人们重新思考 CPU 到底该如何设计，基于对执行指令的重新审视 RISC 设计哲学应运而生。&lt;/p>
&lt;p>RISC 中每条指令更加简单，执行时间比较标准，因此可以很高效的利用流水线技术，这一切都让采用 RISC 架构的 CPU 获得了很好性能。&lt;/p>
&lt;p>面对 RISC，CISC 阵营也开始全面反思应如何应对挑战。后续文章将继续这一话题。&lt;/p></description></item></channel></rss>