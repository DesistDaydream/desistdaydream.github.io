<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – 爬虫</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/</link><description>Recent content in 爬虫 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Crawler</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Crawler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Crawler/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Web_crawler">Wiki，Web crawler&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Web crawler(网络爬虫)&lt;/strong>，大家习惯性简称 &lt;strong>Crawler(爬虫)&lt;/strong>。Web crawler 是一种可以系统浏览互联网的机器人，通常都是被搜索引擎用来抓取网络资源做成搜索索引。&lt;/p>
&lt;p>Crawler 与 &lt;a href="https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Reverse%20engineering/Reverse%20engineering.md">Reverse engineering&lt;/a>、&lt;a href="https://desistdaydream.github.io/docs/Web/Browser/Browser.md">Browser&lt;/a> 都紧密相连。&lt;/p>
&lt;h1 id="学习资料">学习资料&lt;a class="td-heading-self-link" href="#%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://spiderbox.cn/">Spider Box&lt;/a> # 爬虫逆向资源整合的网站&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1ub4y157g1">https://www.bilibili.com/video/BV1ub4y157g1&lt;/a> 介绍视频&lt;/li>
&lt;/ul>
&lt;p>B 站视频&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1ew411K7nB">B 站，【B站最全Python爬虫教程】整整748集，从0基础小白到爬虫大神只要这套就够了！（JS逆向/APP逆向/爬虫实战零基础到精通）&lt;/a> 更好一些&lt;/li>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV178411i7yR/">B 站，【全268集】清华大佬终于把Python爬虫讲明白了，从JS逆向、APP逆向、逆向算法、爬虫实战，这还学不会我退出IT圈！！&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>项目示例&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/onepureman/spider_draft">https://github.com/onepureman/spider_draft&lt;/a> 各种网站的登陆破解，仅供交流学习&lt;/li>
&lt;li>&lt;a href="https://github.com/Zero-S1/awesome-python-login-model">https://github.com/Zero-S1/awesome-python-login-model&lt;/a> python模拟登陆一些大型网站，还有一些简单的爬虫&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/lixi5338619/lxSpider">https://github.com/lixi5338619/lxSpider&lt;/a> 爬虫案例合集&lt;/p></description></item><item><title>Docs: 最佳实践</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="裁判文书网">裁判文书网&lt;a class="td-heading-self-link" href="#%e8%a3%81%e5%88%a4%e6%96%87%e4%b9%a6%e7%bd%91" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>检索到想要的文书后如何批量下载？&lt;/p>
&lt;p>参考: &lt;a href="https://www.bilibili.com/video/BV1zg411a7cN">https://www.bilibili.com/video/BV1zg411a7cN&lt;/a> （2023年12月2日10:08:12 已失效）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">button&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">document&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">getElementsByClassName&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;a_xzBox&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">let&lt;/span> &lt;span style="color:#000">i&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#000">i&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;lt;=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">5&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span> &lt;span style="color:#000">i&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">++&lt;/span>&lt;span style="color:#000;font-weight:bold">){&lt;/span>&lt;span style="color:#000">setTimeout&lt;/span>&lt;span style="color:#000;font-weight:bold">(()&lt;/span> &lt;span style="color:#000;font-weight:bold">=&amp;gt;&lt;/span>&lt;span style="color:#000">button&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">i&lt;/span>&lt;span style="color:#000;font-weight:bold">].&lt;/span>&lt;span style="color:#000">click&lt;/span>&lt;span style="color:#000;font-weight:bold">(),&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1000&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">i&lt;/span>&lt;span style="color:#000;font-weight:bold">)}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: 爬虫</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Python-Web-%E7%88%AC%E8%99%AB%E6%AD%A6%E5%99%A8%E5%BA%93%E7%9B%98%E7%82%B9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Python-Web-%E7%88%AC%E8%99%AB%E6%AD%A6%E5%99%A8%E5%BA%93%E7%9B%98%E7%82%B9/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/461875098">2022 Python Web 爬虫武器库盘点&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>本文大约五千字，耗费了作者近三天时间，希望能带给你提供有用信息。&lt;/p>
&lt;/blockquote>
&lt;p>以前大家写爬虫一般都用 Requests、Scrapy、Selenium。但近几年出现了一些更好用的工具或库。本文就来介绍一下个人强烈推荐爬虫库和工具。&lt;/p>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/601474166">curl_cffi: 支持原生模拟浏览器TLS/JA3 指纹的Python 库&lt;/a>&lt;/p>
&lt;h2 id="http-请求">HTTP 请求&lt;a class="td-heading-self-link" href="#http-%e8%af%b7%e6%b1%82" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="requests">Requests&lt;a class="td-heading-self-link" href="#requests" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Requests 是从 Python 2 就开始流行的 HTTP 请求库，至今已有十一年历史。当初 Python 内置的 http 库过于底层，用起来非常麻烦，Requests 的出现像救世主一样，slogan 就是“http for humans”，标版自己简单好用人性化。Requests 也确实对得起自己的 solgan，至少提供了以下便捷功能：&lt;/p>
&lt;ol>
&lt;li>对常用的 HTTP 请求方法进行封装，可以非常方便的设置 url 参数，表单参数。&lt;/li>
&lt;li>可以自动探测响应内容，自动对响应进行解码和解压缩。&lt;/li>
&lt;li>自动维护长连接和连接池。&lt;/li>
&lt;li>多文件上传。&lt;/li>
&lt;li>自动处理分块响应。&lt;/li>
&lt;li>会话和 cookie 持久化。&lt;/li>
&lt;li>支持 HTTP/HTTPS 代理。&lt;/li>
&lt;/ol>
&lt;p>特别是会话维持、 cookie 持久化、设置代理，是写爬虫必须的。有段时间，知乎上 Python 话题非常火，Python 话题下最火的子话题就是 “Python 爬虫”，而 “Python 爬虫”最火的子话题就是 Requests。&lt;/p>
&lt;p>但随着 Python 3.6、3.7、3.8、3.9、3.10 的发布，Python 社区对协程、Type Hint 的支持越来越成熟，同时有部分网站开始使用 HTTP/2 协议，Requests 对这些都不支持。从 2011 年开始，Requests 就显得不那么现代了。&lt;/p>
&lt;p>另外，Requests 满足不了特定场景的需求，只能依靠第三方包 requests_toolbelt 的帮助。本人曾经写爬虫时，需要将爬取到的图片上传到另一个对象存储服务，图片爬虫下来后是二进制的内容，而 Requests 不支持直接将二进制内容当成文件上传，只能将图片内容先保存到磁盘文件再用 &lt;code>open&lt;/code> 读取，将 &lt;code>open&lt;/code> 返回的句柄对象传递给 Requests。最后不得不使用另一个包 requests_toolbelt 。&lt;/p>
&lt;blockquote>
&lt;p>说一个新手不知道冷知识，Requests 最初的 logo 是一只海龟。&lt;/p>
&lt;/blockquote>
&lt;h3 id="优点">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ol>
&lt;li>在 Python 2 时代提供了简单好用、人性化的接口。&lt;/li>
&lt;li>封装了常见的 HTTP 任务。&lt;/li>
&lt;li>用户基数大，能踩的坑都填上了，文档丰富。&lt;/li>
&lt;/ol>
&lt;h3 id="缺点">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ol>
&lt;li>不支持协程，没有异步接口。&lt;/li>
&lt;li>不支持 Type Hint。（Type Hint 接口可以增加可读性，减少查看文档的次数）。&lt;/li>
&lt;li>只支持 HTTP/1.1，不支持 HTTP/2。&lt;/li>
&lt;li>不支持一些特定场景，需要 requests_toolbelt 作为辅助。&lt;/li>
&lt;/ol>
&lt;p>简单来说，Requests 的缺点是生的太早，没跟着社区一起进步。&lt;/p>
&lt;h3 id="参考">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//docs.python-requests.org/en/latest/">Requests: HTTP for Humans™ (python-requests.org)&lt;/a>&lt;/p>
&lt;h3 id="httpx">HTTPX&lt;a class="td-heading-self-link" href="#httpx" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>HTTPX 的 slogan 是 “Python 的下一代 HTTP 客户端”，从出生开始就只支持 Python 3.6 及更高版本。使用了 Type Hint，同时支持同步和异步接口，同时支持 HTTP/1.1 和 HTTP/2，还提供了命令行工具，可以在命令行中直接发送 HTTP 请求。HTTPX 站在 Requests 的肩膀上，Requests 支持的功能它都支持，Requests 不支持的功能它也支持，比 Requests 更现代，没有历史包袱。&lt;/p>
&lt;p>但 HTTPX 至今还没发布 1.0.0 版本，截至 2022-1-23 日，最新版本为 0.21.3。但本人在 pypi 上观察到 HTTPX 在 2021 年 9 月 14 发布了一个预发布版本 1.0.0b0，期待在 2022 年正式发布 1.0.0。本人从 2019 年开始从 Requests 转向 HTTPX，以后会一直使用 HTTPX。&lt;/p>
&lt;h3 id="优点-1">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-1" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>支持异步（协程）接口。&lt;/li>
&lt;li>支持 HTTP/2。&lt;/li>
&lt;li>支持 Type Hint。&lt;/li>
&lt;li>功能更丰富。&lt;/li>
&lt;/ul>
&lt;p>简单来说，HTTPX 的优点在于更加现代化。&lt;/p>
&lt;h3 id="缺点-1">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-1" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>还未发布 1.0.0 版本，不够成熟，需要时间踩坑。&lt;/li>
&lt;li>只支持 Python 3.6+。（这算不算缺点呢？）&lt;/li>
&lt;/ul>
&lt;h3 id="参考-1">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-1" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/encode/httpx/">encode/httpx: A next generation HTTP client for Python. (github.com)&lt;/a>&lt;/p>
&lt;h2 id="数据解析">数据解析&lt;a class="td-heading-self-link" href="#%e6%95%b0%e6%8d%ae%e8%a7%a3%e6%9e%90" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="beautiful-soup">Beautiful Soup&lt;a class="td-heading-self-link" href="#beautiful-soup" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Beautiful Soup 也是从 Python2 时代就开始流行的解析库，用于从 HTML 或 XML 文档中提取数据。Beautiful Soup 会将文档解析成树形文档结构，树中每个节点都是一个 Python 对象，并将节点分为 4 种类型：&lt;code>Tag&lt;/code> 、 &lt;code>NavigableString&lt;/code> 、&lt;code>BeautifulSoup&lt;/code> 、 &lt;code>Comment&lt;/code> ，并提供了遍历、搜索、修改文档树的接口。支持 CSS 搜索，可以美化 HTML 文档，快速提取文本。Beautiful Soup 还可以指定解析文档时使用的解析器，有的解析器效率高，有的解析器兼容性好，可以根据需要选择。&lt;/p>
&lt;p>但是 Beautiful Soup 毕竟出生于 Python 2 时代，没有 Type Hint，再加上接口比较多，每次写代码都要参考官方文档。&lt;/p>
&lt;h3 id="优点-2">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-2" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>提供了遍历、搜索、修改文档树的结构。&lt;/li>
&lt;li>可以快速提取所有 HTML 标签中的文本。&lt;/li>
&lt;li>可以美化 HTML 文档。&lt;/li>
&lt;li>可以根据需要选择不同的解析器。&lt;/li>
&lt;/ul>
&lt;p>虽然后面出现的 Parsel 解析库很好用，但需要一次性提取所有标签文本或编辑 DOM 树结构时还是 Beautiful Soup 好用。&lt;/p>
&lt;h3 id="缺点-2">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-2" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>接口复杂。&lt;/li>
&lt;li>没有 Type Hint。&lt;/li>
&lt;/ul>
&lt;p>这两个缺点导致写代码时非常依赖官方文档。本人只有在需要提取所有页面文本或编辑 DOM 树时才会用 Beautiful Soup。&lt;/p>
&lt;h3 id="参考-2">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-2" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//beautiful-soup-4.readthedocs.io/en/latest/">Beautiful Soup Documentation — Beautiful Soup 4.4.0 documentation (beautiful-soup-4.readthedocs.io)&lt;/a>&lt;/p>
&lt;h3 id="parsel">Parsel&lt;a class="td-heading-self-link" href="#parsel" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Parsel 是新一代的 HTML/XML 文档解析库，也是知名爬虫框架 Scrapy 内置的解析器，属于 Scrapy 项目。Parsel 支持 XPath 和 CSS 两种风格的解析器，并集成了正则表达式。&lt;/p>
&lt;h3 id="优点-3">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-3" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>初步使用了 Type Hint。&lt;/li>
&lt;li>接口简单，习惯后不依赖文档。&lt;/li>
&lt;li>提供了 XPath 和 CSS 两个风格的选择器。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-3">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-3" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>只能查找和删除文档树中的 HTML 标签，不能插入新标签。编辑能力弱于 Beautiful Soup。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-3">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-3" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/scrapy/parsel">scrapy/parsel: Parsel lets you extract data from XML/HTML documents using XPath or CSS selectors (github.com)&lt;/a>&lt;/p>
&lt;h3 id="jsonpath">JSONPath&lt;a class="td-heading-self-link" href="#jsonpath" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>JSONPath 是查询和解析复杂 JSON 文档的一门语言，JSONPath 的 slogan 是“XPath to JSON”，可以像用 XPath 解析 XML 文档一样用 JSONPath 解析 JSON 文档。JSONPath 由 Stefan Goessner 于 2007 年在&lt;a href="https://link.zhihu.com/?target=https%3A//goessner.net/articles/JsonPath/">一篇博客&lt;/a>中提出，Stefan Goessner 认为 JSON 是 C 系列编程语言中数据的自然表示，所以 JSONPath 表达式的语法也是 C 系列语言风格。例如，访问嵌套的结构可以用 &lt;code>.&lt;/code> 也可以用 &lt;code>[]&lt;/code>。&lt;/p>
&lt;p>JSONPath 的不完整语法如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>JSONPath&lt;/th>
&lt;th>描述&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>$&lt;/td>
&lt;td>根元素或对象&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@&lt;/td>
&lt;td>当前对象或元素&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>. 或 []&lt;/td>
&lt;td>访问子元素或对象&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>..&lt;/td>
&lt;td>递归下降&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>*&lt;/td>
&lt;td>通配符，匹配所有元素或对象&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[]&lt;/td>
&lt;td>下标运算符&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[,]&lt;/td>
&lt;td>用名称或数组下标索引将元素提取为一组&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[start&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/b088ad0b-52ae-4bbb-84fb-4198566eb0c6/1f51a.svg" alt="">step]&lt;/td>
&lt;td>切片操作&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>?()&lt;/td>
&lt;td>应用过滤表达式&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>()&lt;/td>
&lt;td>表达式&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>有一些网站可以提供 JSONPath 表达式的在线验证。例如，下面从一个表示热搜的复杂 JSON 文档中提取出热搜词列表。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/b088ad0b-52ae-4bbb-84fb-4198566eb0c6/v2-052f5331263a0505554b2705887fbe2d_b.jpg" alt="">&lt;/p>
&lt;p>JSONPath 在线验证&lt;/p>
&lt;p>JSONPath 有多种实现，在主流的编程语言中都有对应的库。但由于 JSONPath 没有严格规范的语法，各个实现都有自己的理解，导致同一个 JSONPath 表达式在不同的编程语言中有不同结果。&lt;/p>
&lt;h3 id="优点-4">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-4" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>可以方便的解析复杂 JSON 文档。&lt;/li>
&lt;li>语法类 C，相对好记。&lt;/li>
&lt;li>主流的编程语言都有库支持。&lt;/li>
&lt;li>代码简洁，占用内存低，高效。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-4">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-4" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>没有完整严格的语法规范，导致不同的实现各有差异。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-4">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-4" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//goessner.net/articles/JsonPath/">JSONPath - XPath for JSON (goessner.net)&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//www.jsonpath.cn/">JSONPath 在线验证&lt;/a>&lt;/p>
&lt;h3 id="jmespath">JMESPath&lt;a class="td-heading-self-link" href="#jmespath" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>JMESPath 是最近几年最流行的 JSON 文档查询、提取、转换的语言。克服了 JSONPath 的缺点，并提供更加强大功能，例如投影和管道。&lt;/p>
&lt;p>JMESPath 的基本表达式包括：标识符、子表达式（用于访问嵌套结构）、下标访问表达式。高级表达式包括：切片、投影、管道、多选、函数。特意没有提供递归下降的功能。&lt;/p>
&lt;h3 id="优点-5">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-5" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>JSONPath 的优点它都有，此外还具有 JSONPath 没有的优点：&lt;/p>
&lt;ul>
&lt;li>功能更强大。&lt;/li>
&lt;li>完整而规范的语法，用 ABNF 描述。&lt;/li>
&lt;li>有一套完整的数据驱动的测试用例，确保不同的 JMESPath 实现库都提供相同的语法支持。&lt;/li>
&lt;li>针对不同语言都有通过官方认证的实现库。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-5">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-5" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>语法相对复杂。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-5">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-5" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//jmespath.org/">JMESPath — JMESPath&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//datatracker.ietf.org/doc/html/rfc4234">RFC 4234 - Augmented BNF for Syntax Specifications: ABNF (ietf.org)&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//www.npmtrends.com/jmespath-vs-json-query-vs-jsonata-vs-jsonpath-vs-jsonpath-plus">jmespath vs json-query vs jsonata vs jsonpath vs jsonpath-plus | npm trends&lt;/a>&lt;/p>
&lt;h2 id="框架">框架&lt;a class="td-heading-self-link" href="#%e6%a1%86%e6%9e%b6" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Scrapy 是爬虫领域至今未被取代的框架，所以本节只介绍了 Scrapy。&lt;/p>
&lt;h3 id="scrapy">Scrapy&lt;a class="td-heading-self-link" href="#scrapy" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Scrapy 是一款流行了 11 年的 web 爬虫框架，也许是唯一广泛流行的 Python 爬虫框架。Scrapy 框架集成了 HTTP 请求、数据解析、数据持久化、请求调度、并发爬取。&lt;/p>
&lt;p>Scrapy 架构包括七个组件，包括：引擎、spider、spider 中间件、调度器、item 管道、下载器、下载器中间件。最基本的爬虫只需要用户继承 &lt;code>scrapy.Spider&lt;/code>，并实现解析方法 &lt;code>parse&lt;/code>。&lt;/p>
&lt;p>Scrapy 的一般用法是，自定义 spider 类实现请求和解析逻辑，通过 item 管道处理爬取到的数据，通过配置定制爬虫行为，添加 spider 中间件和下载器中间件扩展 Scrapy 的功能。&lt;/p>
&lt;p>Scrapy 还提供了 Scrapy-Redis 用于支持分布式爬取。&lt;/p>
&lt;p>但 Scrapy 发布时 Python 还没发布标准库 asyncio，也没有 type hint，HTTP/2 协议规范还未发布，所以 Scrapy 并不支持它们。现在只是对 HTTP/2 和 asyncio 有了实验性支持。&lt;/p>
&lt;h3 id="优点-6">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-6" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>对爬虫任务提供了相对完整的解决方案。&lt;/li>
&lt;li>提供了一定的扩展性。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-6">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-6" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>不支持动态渲染的 Web 页面。&lt;/li>
&lt;li>不支持 Type Hint。&lt;/li>
&lt;li>基于 Twisted 实现的异步模型不兼容 Python 标准库 asyncio。&lt;/li>
&lt;li>对 HTTP/2 的支持不够成熟。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-6">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-6" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//scrapy.org/">Scrapy | A Fast and Powerful Scraping and Web Crawling Framework&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//docs.scrapy.org/en/latest/">Scrapy 2.5 documentation — Scrapy 2.5.1 documentation&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/scrapy/scrapy">scrapy/scrapy: Scrapy, a fast high-level web crawling &amp;amp; scraping framework for Python. (github.com)&lt;/a>&lt;/p>
&lt;h2 id="模拟自动化工具">模拟/自动化工具&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e6%8b%9f%e8%87%aa%e5%8a%a8%e5%8c%96%e5%b7%a5%e5%85%b7" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>用自动化测试工具模拟真人爬取网页可以绕过大多数反爬策略，而且不用担心页面动态渲染的问题。&lt;/p>
&lt;p>下面介绍的自动化测试工具，原本都是为 Web 自动化测试而生，并不是为爬虫而设计的。本人是从爬虫角度了解它们，所以对它们的介绍肯定不全面，也可能某些地方不准确。&lt;/p>
&lt;h3 id="selenium">Selenium&lt;a class="td-heading-self-link" href="#selenium" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Selenium 是用于支持 web 浏览器自动化的综合项目，包括一系列工具和库的集合。其中最核心的是 WebDriver。我们用 Selenium 模拟爬取就是通过特定于浏览器&lt;strong>驱动&lt;/strong>控制浏览器，模拟真人使用浏览器的过程。驱动特定了浏览器，一般由浏览器厂商自己提供，例如 Chrome 浏览器的驱动为 ChromeDriver，Firefox 浏览器的驱动为 GeckoDriver。&lt;/p>
&lt;p>爬虫代码通过 WebDrvier 发送指令给驱动，驱动翻译指令后发给浏览器，浏览器的响应会返回给驱动，驱动再返回给 WebDrvier。&lt;/p>
&lt;p>Selenium 的目标是提供自动化测试套件，并没为爬取数据做优化，有时候爬取数据需要 hook 请求和返回，而 Selenium 并没有提供这样的功能。本人曾经在做某个项目时非常想要 hook 请求和返回，就去 Selenium 的 Github 仓库搜索相关 issue，发现很早就有人在 issue 里建议加上 hook 请求/响应的功能，但是官方回复说没有这种场景，所以不会提供，提 issue 的人也支支吾吾说不清应用场景，我猜他就是做爬虫的，不好啥意思说出来。&lt;/p>
&lt;p>Selenium 3.x 完全没有网络拦截功能，只能通过浏览器插件的形式阻止某个网络请求。&lt;/p>
&lt;p>2021 年 10 月 13，经过近三年的迭代，Selenium 终于发布了 4.0.0 版本。Selenium 4.0 引入了一个新特性，支持 Chrome DevTools 协议。利用 Chrome DevTools 协议可以根据 URL 规则阻止请求、mock 请求、记录请求、记录响应，但不支持修改请求或修改响应内容。&lt;/p>
&lt;p>另外，Selenium 的固有缺陷导致在驱动浏览器时很容易产生浏览器僵尸进程。当然，僵尸进程有解决办法。&lt;/p>
&lt;h3 id="优点-7">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-7" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>社区庞大，文档丰富，积累了大量实践经验。&lt;/li>
&lt;li>至少支持四种主流浏览器，包括：Google Chrome、Microsoft Edge、Mozilla Firefox、&lt;/li>
&lt;li>针对主流的编程语言都有对应的库。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-7">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-7" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>对网络请求/响应的 hook 支持不完善。&lt;/li>
&lt;li>不支持异步。&lt;/li>
&lt;li>容易产生浏览器僵尸进程。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-7">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-7" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//www.selenium.dev/">Selenium&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/SeleniumHQ/Selenium">https://github.com/SeleniumHQ/Selenium&lt;/a>&lt;/p>
&lt;h3 id="puppeteer">Puppeteer&lt;a class="td-heading-self-link" href="#puppeteer" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Puppeteer 是 Google Chrome 官方团队于 2017 年发布的一个 Node 库，通过 DevTools 协议控制浏览器。能控制的浏览器包括 Google Chrome、Microsoft Edge，不包括 Mozilla Firefox。默认为无头模式，也可以为有头模式。&lt;/p>
&lt;blockquote>
&lt;p>Puppeteer 的出现直接导致了另外一款无头浏览器 PhantomJS 于 2018 年宣布停止维护。参见 &lt;a href="https://link.zhihu.com/?target=https%3A//phantomjs.org/">PhantomJS - Scriptable Headless Browser&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Puppeteer 是 Node 库，接口自然都是异步的，async/await 随处可见。&lt;/p>
&lt;p>Puppeteer 除了可以模拟用户操作外，还可以拦截请求（修改请求、中止请求、定义返回）。&lt;/p>
&lt;p>Puppeteer 有个 Python 迁移版，叫 Pyppeteer，用 Python 的协程语法一比一实现了 Puppeteer 的接口，但由于是个人主导作品，更新、维护以及代码质量都比不上 Puppeteer，不建议使用。&lt;/p>
&lt;h3 id="优点-8">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-8" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>由 Gooolge Chrome 官方出品，不用担心更新和维护问题。&lt;/li>
&lt;li>可以拦截请求。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-8">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-8" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>官方没有提供相应的 Python 库。第三方提供的 Python 迁移版本质量不高。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-8">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-8" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/puppeteer/puppeteer">puppeteer/puppeteer: Headless Chrome Node.js API (github.com)&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//pptr.dev/">Puppeteer v13.1.1 (pptr.dev)&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/pyppeteer/pyppeteer">pyppeteer/pyppeteer: Headless chrome/chromium automation library (unofficial port of puppeteer) (github.com)&lt;/a>&lt;/p>
&lt;h3 id="playwright">Playwright&lt;a class="td-heading-self-link" href="#playwright" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Playwright 是微软官方于 2020 年发布的 Web 自动化测试工具。&lt;/p>
&lt;p>微软出手，果然不一般，直接支持了五大浏览器：Google Chrome、Microsoft Edge、Mozilla Firefox、Opera、Safari。支持跨平台，包括：Windows、Linux、macOS。并且还有官方维护的多种编程语言库，包括：TypeScript、JavaScript、Python、.NET、Java。&lt;/p>
&lt;p>Playwright 提供的网络拦截功能很适合写爬虫，包括修改请求、中止请求、mock 请求、修改响应。有了这个网络拦截功能，就不需要 mitmproxy 了。&lt;/p>
&lt;h3 id="优点-9">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-9" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>微软官方出品，不用担心更新和维护问题。&lt;/li>
&lt;li>兼容多种主流浏览器。&lt;/li>
&lt;li>官方支持多种编程语言对应的库。&lt;/li>
&lt;li>可以 hook 请求和响应。&lt;/li>
&lt;li>更加现代。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-9">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-9" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>暂无&lt;/li>
&lt;/ul>
&lt;p>参考&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/microsoft/playwright">microsoft/playwright: Playwright is a framework for Web Testing and Automation. It allows testing Chromium, Firefox and WebKit with a single API. (github.com)&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//playwright.dev/">Fast and reliable end-to-end testing for modern web apps | Playwright&lt;/a>&lt;/p>
&lt;h2 id="js-引擎-for-python">JS 引擎 for Python&lt;a class="td-heading-self-link" href="#js-%e5%bc%95%e6%93%8e-for-python" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>写爬虫经常会遇到一些场景，某个请求需要一些参数，而这些参数是经过执行一段复杂的 JavaScript 代码生成的。在用 Python 代码模拟发出该请求时，你可以选择用 Python 重写对于的 js 逻辑，这样会很麻烦，因为你要保证你的 Python 代码逻辑和对应的 JS 代码一模一样，通常还有考虑两种编程语言的异同。如果这段 JS 代码被混淆过，读懂它的逻辑就需要很大的工作量，更便捷的方法是直接将这段 JS 代码拷贝下来，放到一个 JavaScript 环境中执行，再拿到其结果。这就需要一个能在 Python 中使用的 JS 引擎库。&lt;/p>
&lt;p>另外在用 Python 脚本分析 JavaScript 代码时，也会需要一个 JavaScript 引擎 for Python。&lt;/p>
&lt;p>在 PyV8、PyExecJS 等库都停止维护的情况下，目前唯一比较好的选择是 PyMiniRacer。&lt;/p>
&lt;h3 id="pyminiracer">PyMiniRacer&lt;a class="td-heading-self-link" href="#pyminiracer" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>PyMiniRacer 是适用于 Python 的最小的现代嵌入式 V8。虽然维护团队很小，但却是目前的唯一选择。PyMiniRacer 支持最新的 ECMAScript 标准，支持 Assembly，并提供可重用的上下文。&lt;/p>
&lt;h3 id="优点-10">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-10" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>支持最新的 ECMAScript。&lt;/li>
&lt;li>内存消耗小。&lt;/li>
&lt;li>不需要额外安装 JavaScript 环境。&lt;/li>
&lt;li>提供可重用上下文。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-10">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-10" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>维护团队较小，至今未发布 1.0.0 版本。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-9">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-9" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//pypi.org/project/py-mini-racer/">py-mini-racer · PyPI&lt;/a>&lt;/p>
&lt;h2 id="虚拟显示器">虚拟显示器&lt;a class="td-heading-self-link" href="#%e8%99%9a%e6%8b%9f%e6%98%be%e7%a4%ba%e5%99%a8" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>服务器一般不会配置显式设备，服务器上的 Linux 系统一般也不会安装桌面环境。但如果我们要将一个使用有头浏览器的爬虫部署到服务器上，甚至是 Docker 容器里，该怎么办呢？这时候就可以用虚拟显示器了。目前只有 Xvfb 一个选择。&lt;/p>
&lt;h3 id="xvfb">Xvfb&lt;a class="td-heading-self-link" href="#xvfb" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Xvfb 是一个 X server，可以在没有显式硬件和物理输入设备的机器上运行，用虚拟内存模拟帧缓冲。&lt;/p>
&lt;p>Xvfb 可以设置模拟屏幕的分辨率、像素深度。&lt;/p>
&lt;p>我们可以使用 xvfb 启动需要界面的爬虫，或者使用 python 的 xvfbwrapper 在启动需要界面的浏览器之前启动一个虚拟显示器。&lt;/p>
&lt;h3 id="参考-10">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-10" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//linux.die.net/man/1/xvfb">xvfb(1): virtual framebuffer X server for X - Linux man page (die.net)&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//github.com/cgoldberg/xvfbwrapper">cgoldberg/xvfbwrapper: Manage headless displays with Xvfb (X virtual framebuffer) (github.com)&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//www.x.org/releases/X11R7.7/doc/man/man7/X.7.xhtml">X&lt;/a>&lt;/p>
&lt;h2 id="抓包工具">抓包工具&lt;a class="td-heading-self-link" href="#%e6%8a%93%e5%8c%85%e5%b7%a5%e5%85%b7" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="fiddler-classic">Fiddler Classic&lt;a class="td-heading-self-link" href="#fiddler-classic" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Fiddler Classic 是 Windows 平台上一款非常好用的抓包工具。网络上提到的 Fiddler 通常就是指的 Fiddler Classic。&lt;/p>
&lt;p>Fiddler Classic 用创建代理的方式抓取浏览器或其他程序的 HTTP/HTTPS 流量。Fiddler Classic 是商业公司推出的网络调试工具之一，该司目前停止了对免费产品 Fiddler Classic 的更新，主力推荐它们的商业收费产品，所以 Fiddler Classic 最后版本为 2020 年 11 月 3 日构建的 v5.0.20204.45441 for .NET 4.6.1。不够 Fiddler Classic 也够用了。如果有跨平台的需求，可以购买该司的 Fiddler Every。&lt;/p>
&lt;p>功能特性：&lt;/p>
&lt;ul>
&lt;li>可以多种角度查看 HTTP/HTTPS 流量。&lt;/li>
&lt;li>可以非常方便的构建 HTTP(S) 请求。&lt;/li>
&lt;li>可以对请求和返回进行断点，并修改继续发送。&lt;/li>
&lt;li>可以修改请求、重放请求。&lt;/li>
&lt;li>可以 mock 请求。&lt;/li>
&lt;li>可以将抓包结果持久化保存。&lt;/li>
&lt;/ul>
&lt;p>Fiddler 的抓包原理本质上属于一种“中间人攻击”，有的 app 会对请求进行中间人攻击检测，导致 Fiddler 不能顺利抓到流量。&lt;/p>
&lt;h3 id="优点-11">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-11" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>免费。&lt;/li>
&lt;li>可视化操作非常方便。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-11">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-11" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>只适用 Windows 平台。&lt;/li>
&lt;/ul>
&lt;h3 id="参考-11">参考&lt;a class="td-heading-self-link" href="#%e5%8f%82%e8%80%83-11" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://link.zhihu.com/?target=https%3A//www.telerik.com/fiddler/fiddler-classic">Fiddler Classic | Original Web Capturing Tool for Windows (telerik.com)&lt;/a>&lt;/p>
&lt;h3 id="浏览器">浏览器&lt;a class="td-heading-self-link" href="#%e6%b5%8f%e8%a7%88%e5%99%a8" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>浏览器自带的调试工具可以监控网络流量，而且不需要创建代理。但在浏览器的调试页面分析流量不怎么方便，对于复杂的网络交互过程可以将浏览器抓包到的结果保存为 HAR 文件，再用其他工具（例如 Fiddler Classic）分析。&lt;/p>
&lt;h3 id="优点-12">优点&lt;a class="td-heading-self-link" href="#%e4%bc%98%e7%82%b9-12" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>不用创建代理。&lt;/li>
&lt;li>不用担心 HTTPS 流量的解密问题。&lt;/li>
&lt;li>跨平台，免费。&lt;/li>
&lt;/ul>
&lt;h3 id="缺点-12">缺点&lt;a class="td-heading-self-link" href="#%e7%bc%ba%e7%82%b9-12" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>分析网络交互过程没有专门的工具方便。&lt;/li>
&lt;/ul>
&lt;h2 id="个人推荐的最佳组合">个人推荐的最佳组合&lt;a class="td-heading-self-link" href="#%e4%b8%aa%e4%ba%ba%e6%8e%a8%e8%8d%90%e7%9a%84%e6%9c%80%e4%bd%b3%e7%bb%84%e5%90%88" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>请求库： HTTPX。&lt;/li>
&lt;li>框架：Scrapy&lt;/li>
&lt;li>模拟爬取： Playwright&lt;/li>
&lt;li>JS 引擎 for Python：PyMiniRacer。&lt;/li>
&lt;li>抓包工具：Fiddler 和浏览器。&lt;/li>
&lt;/ul></description></item></channel></rss>