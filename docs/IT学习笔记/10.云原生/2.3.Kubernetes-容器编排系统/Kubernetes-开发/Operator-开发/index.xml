<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – Operator 开发</title><link>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/</link><description>Recent content in Operator 开发 on 断念梦</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Kubebuilder</title><link>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/Kubebuilder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/Kubebuilder/</guid><description>
&lt;h1 id="heading">&lt;/h1>
&lt;p>Kubebuilder 代码示例详见 &lt;a href="https://github.com/DesistDaydream/kubernetesAPI/tree/master/operator">GitHub 上我的 kubernetesAPI 仓库&lt;/a>&lt;/p>
&lt;h1 id="kubebuilder-命令行工具">kubebuilder 命令行工具&lt;/h1>
&lt;p>用于构建 Kubernetes 扩展和工具的开发工具包。 提供用于创建新项目，API 和控制器的库和工具。 包括用于将工件打包到安装程序容器中的工具。&lt;/p>
&lt;p>典型的项目生命周期：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>初始化项目：&lt;/p>
&lt;ul>
&lt;li>kubebuilder init &amp;ndash;domain example.com &amp;ndash;license apache2 &amp;ndash;owner &amp;ldquo;The Kubernetes authors&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>创建一个或多个新资源 API 并将代码添加到其中：&lt;/p>
&lt;ul>
&lt;li>kubebuilder create api &amp;ndash;group &lt;!-- raw HTML omitted --> &amp;ndash;version &lt;!-- raw HTML omitted --> &amp;ndash;kind &lt;!-- raw HTML omitted -->&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Create resource will prompt the user for if it should scaffold the Resource and / or Controller. To only scaffold a Controller for an existing Resource, select &amp;ldquo;n&amp;rdquo; for Resource. To only define the schema for a Resource without writing a Controller, select &amp;ldquo;n&amp;rdquo; for Controller.&lt;/p>
&lt;p>After the scaffold is written, api will run make on the project.&lt;/p>
&lt;p>&lt;strong>kubebuilder [COMMAND]&lt;/strong>&lt;/p>
&lt;p>Available Commands:&lt;/p>
&lt;h2 id="create-scaffold-a-kubernetes-api-or-webhook">create Scaffold a Kubernetes API or webhook&lt;/h2>
&lt;h2 id="edit-this-command-will-edit-the-project-configuration">edit This command will edit the project configuration&lt;/h2>
&lt;h2 id="init-initialize-a-new-project">init Initialize a new project&lt;/h2>
&lt;p>Initialize a new project including vendor / directory and Go package directories.&lt;/p>
&lt;p>Writes the following files:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>a boilerplate license file&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a PROJECT file with the project configuration&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a Makefile to build the project&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a go.mod with project dependencies&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a Kustomization.yaml for customizating manifests&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a Patch file for customizing image for manager manifests&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a Patch file for enabling prometheus metrics&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a cmd/manager/main.go to run&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>项目将在写入项目文件后提示用户运行 &amp;ldquo;dep sure&amp;rdquo;。&lt;/p>
&lt;p>&lt;strong>kubebuilder init [FLAGS]&lt;/strong>&lt;/p>
&lt;p>FLAGS&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&amp;ndash;domain STRING # domain for groups (default &amp;ldquo;my.domain&amp;rdquo;)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;ndash;fetch-deps # 确保下载依赖项。(default true)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;ndash;license STRING # license to use to boilerplate, may be one of &amp;lsquo;apache2&amp;rsquo;, &amp;rsquo;none&amp;rsquo; (default &amp;ldquo;apache2&amp;rdquo;)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;ndash;owner STRING # 在每个代码文件的开头添加 Cpoyright&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;ndash;project-version STRING # project version (default &amp;ldquo;2&amp;rdquo;)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;ndash;repo STRING # 用于 go 模块的名称(例如 github.com/user/repo)，默认为当前工作目录的 go 包名。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;ndash;skip-go-version-check # 如果指定，请跳过检查 Go 版本&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Examples:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>使用 &amp;ldquo;The Kubernetes authors&amp;rdquo; 作为所有者的 apache2 许可证来搭建项目&lt;/p>
&lt;ul>
&lt;li>kubebuilder init &amp;ndash;domain example.org &amp;ndash;license apache2 &amp;ndash;owner &amp;ldquo;The Kubernetes authors&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: Operator 开发</title><link>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/</guid><description/></item><item><title>Docs: 初识 Operator</title><link>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E5%88%9D%E8%AF%86-Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E5%88%9D%E8%AF%86-Operator/</guid><description>
&lt;p>Kubebuilder 代码示例详见 &lt;a href="https://github.com/DesistDaydream/kubernetesAPI/tree/master/operator">GitHub 上我的 kubernetesAPI 仓库&lt;/a>&lt;/p>
&lt;p>本文我们将首先了解到 Operator 是什么，之后逐步了解到 Operator 的生态建设，Operator 的关键组件及其基本的工作原理。&lt;/p>
&lt;h2 id="介绍">介绍&lt;/h2>
&lt;p>基于 Kubernetes 平台，我们可以轻松的搭建一些简单的无状态应用，比如对于一些常见的 web apps 或是移动端后台程序，开发者甚至不用十分了解 Kubernetes 就可以利用 Deployment，Service 这些基本单元模型构建出自己的应用拓扑并暴露相应的服务。由于无状态应用的特性支持其在任意时刻进行部署、迁移、升级等操作，Kubernetes 现有的 ReplicaSets、Deployment、Services 等资源对象已经足够支撑起无状态应用对于自动扩缩容、实例间负载均衡等基本需求。&lt;/p>
&lt;p>在管理简单的有状态应用时，我们可以利用社区原生的 StatefulSet 和 PV 模型来构建基础的应用拓扑，帮助实现相应的持久化存储，按顺序部署、顺序扩容、顺序滚动更新等特性。&lt;/p>
&lt;p>而随着 Kubernetes 的蓬勃发展，在数据分析，机器学习等领域相继出现了一些场景更为复杂的分布式应用系统，也给社区和相关应用的开发运维人员提出了新的挑战：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>不同场景下的分布式系统中通常维护了一套自身的模型定义规范，如何在 Kubernetes 平台中表达或兼容出应用原先的模型定义？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当应用系统发生扩缩容或升级时，如何保证当前已有实例服务的可用性？如何保证它们之间的可连通性？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如何去重新配置或定义复杂的分布式应用？是否需要大量的专业模板定义和复杂的命令操作？是否可以向无状态应用那样用一条 kubectl 命令就完成应用的更新？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如何备份和管理系统状态和应用数据？如何协调系统集群各成员间在不同生命周期的应用状态？&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>而所有的这些正是 Operator 希望解决的问题，本文我们将首先了解到 Operator 是什么，之后逐步了解到 Operator 的生态建设，Operator 的关键组件及其基本的工作原理，下面让我们来一探究竟吧。&lt;/p>
&lt;h2 id="初识-operator">&lt;strong>初识 Operator&lt;/strong>&lt;/h2>
&lt;p>首先让我们一起来看下什么是 Operator 以及它的诞生和发展历程。&lt;/p>
&lt;h3 id="1-什么是-operator">&lt;strong>1. 什么是 Operator&lt;/strong>&lt;/h3>
&lt;p>CoreOS 在 2016 年底提出了 Operator 的概念，当时的一段官方定义如下：&lt;/p>
&lt;p>“An Operator represents human operational knowledge in software, to reliably manage an application.”&lt;/p>
&lt;p>对于普通的应用开发者或是大多数的应用 SRE 人员，在他们的日常开发运维工作中，都需要基于自身的应用背景和领域知识构建出相应的自动化任务满足业务应用的管理、监控、运维等需求。在这个过程中，Kubernetes 自身的基础模型元素已经无法支撑不同业务领域下复杂的自动化场景。&lt;/p>
&lt;p>与此同时，在云原生的大背景下，生态系统是衡量一个平台成功与否的重要标准，而广大的应用开发者作为 Kubernetes 的最直接用户和服务推广者，他们的业务需求更是 Kubernetes 的生命线。于是，谷歌率先提出了 &lt;code>Third Party Resource&lt;/code> 的概念，允许开发者根据业务需求以插件化形式扩展出相应的 K8s API 对象模型，同时提出了自定义 controller 的概念用于编写面向领域知识的业务控制逻辑，基于 Third Party Resource，Kubernetes 社区在 1.7 版本中提出了&lt;code>custom resources and controllers&lt;/code> 的概念，这正是 Operator 的核心概念。&lt;/p>
&lt;p>基于 custom resources 和相应的自定义资源控制器，我们可以自定义扩展 Kubernetes 原生的模型元素，这样的自定义模型可以如同原生模型一样被 Kubernetes API 管理，支持 kubectl 命令行；同时 Operator 开发者可以像使用原生 API 进行应用管理一样，通过声明式的方式定义一组业务应用的期望终态，并且根据业务应用的自身特点进行相应控制器逻辑编写，以此完成对应用运行时刻生命周期的管理并持续维护与期望终态的一致性。这样的设计范式使得应用部署者只需要专注于配置自身应用的期望运行状态，而无需再投入大量的精力在手工部署或是业务在运行时刻的繁琐运维操作中。&lt;/p>
&lt;p>简单来看，&lt;strong>Operator 定义了一组在 Kubernetes 集群中打包和部署复杂业务应用的方法&lt;/strong>，它可以方便地在不同集群中部署并在不同的客户间传播共享；同时 Operator 还提供了一套应用在运行时刻的监控管理方法，&lt;strong>应用领域专家通过将业务关联的运维逻辑编写融入到 operator 自身控制器中&lt;/strong>，而一个运行中的 Operator 就像一个 7*24 不间断工作的优秀运维团队，它可以时刻监控应用自身状态和该应用在 Kubernetes 集群中的关注事件，并在毫秒级别基于期望终态做出对监听事件的处理，比如对应用的自动化容灾响应或是滚动升级等高级运维操作。&lt;/p>
&lt;p>进一步讲，Operator 的设计和实现并不是千篇一律的，开发者可以根据自身业务需求，不断演进应用的自定义模型，同时面向具体的自动化场景在控制器中扩展相应的业务逻辑。很多 Operator 的出现都是起源于一些相对简单的部署和配置需求，并在后续演进中不断完善补充对复杂运维需求的自动化处理。&lt;/p>
&lt;h3 id="2-operator-的发展">&lt;strong>2. Operator 的发展&lt;/strong>&lt;/h3>
&lt;p>时至今日，Kubernetes 已经确立了自己在云原生领域平台层开源软件中的绝对地位，我们可以说 Kubernetes 就是当今容器编排的事实标准；而在 Kubernetes 项目强大的影响力下，越来越多的企业级分布式应用选择拥抱云原生并开始了自己的容器化道路，而 Operator 的出现无疑极大的加速了这些传统的复杂分布式应用的上云过程。无论在生态还是生产领域，Operator 都是容器应用部署上云过程中广受欢迎的实现规范，本小节就让我们来一起回顾下 Operator 的诞生和发展历史。&lt;/p>
&lt;p>2014 到 2015 年，Docker 无疑是容器领域的绝对霸主，容器技术自身敏捷、弹性和可移植性等优势使其迅速成为了当时炙手可热的焦点。在这个过程中，虽然市场上涌现了大量应用镜像和技术分享，我们却很难在企业生产级别的分布式系统中寻找到容器应用的成功案例。容器技术的本质是提供了主机虚拟层之上的隔离，这样的隔离虽然带来了敏捷和弹性的优势，但同时也给容器和外部世界的交互带来了多一层的障碍；尤其是面向复杂分布式系统中，在处理自身以及不同容器间状态的依赖和维护问题上，往往需要大量的额外工作和依赖组件。这也成为了容器技术在云原生应用生产化道路上的一个瓶颈。&lt;/p>
&lt;p>与此同时，谷歌于 2014 年基于其内部的分布式底层框架 Borg 推出了 Kubernetes 并完成了第一次代码提交。&lt;/p>
&lt;p>2015 年，Kubernetes v1.0 版本正式发布，同时云原生计算基金会 Cloud Native Computing Foundation，简称 CNCF）正式成立，基于云原生这个大背景，CNCF 致力于维护和集成优秀开源技术以支撑编排容器化微服务架构应用。&lt;/p>
&lt;p>2016 年是 Kubernetes 进入主干道，开始蓬勃发展的一年。这一年的社区，开发者们从最初的种种疑虑转为对 Kubernetes 的大力追捧，无论从 commit 数量到个人贡献者数量都有了显著增长；同时越来越多的企业选择 Kubernetes 作为生产系统容器集群的编排引擎，而以 Kubernetes 为核心构建企业内部的容器生态已经开始逐渐成为云原生大背景下业界的共识。也正是在这一年，CoreOS 正式推出了 Operator，旨在通过扩展 Kubernetes 原生 API 的方式为 Kubernetes 应用提供创建、配置以及运行时刻生命周期管理能力，与此同时用户可以利用 Operator 方便的对应用模型进行更新、备份、扩缩容及监控等多种复杂运维操作。&lt;/p>
&lt;p>在 Kubernetes 实现容器编排的核心思想中，会使用控制器（Controller）模式对 etcd 里的 API 模型对象变化保持不断的监听（Watch），并在控制器中对指定事件进行响应处理，针对不同的 API 模型可以在对应的控制器中添加相应的业务逻辑，通过这种方式完成应用编排中各阶段的事件处理。而 Operator 正是基于控制器模式，允许应用开发者通过扩展 Kubernetes API 对象的方式，将复杂的分布式应用集群抽象为一个自定义的 API 对象，通过对自定义 API 模型的请求可以实现基本的运维操作，而在 Controller 中开发者可以专注实现应用在运行时刻管理中遇到的相关复杂逻辑。&lt;/p>
&lt;p>在当时，率先提出这种扩展原生 API 对象进行应用集群定义框架的并不是 CoreOS，而是当时还在谷歌的 Kubernetes 创始人 Brendan Burns；正是 Brendan 早在 1.0 版本发布前就意识到了 Kubernetes API 可扩展性对 Kubernetes 生态系统及其平台自身的重要性，并构建了相应的 API 扩展框架，谷歌将其命名为 &lt;code>Third Party Resource&lt;/code>，简称“TPR”。CoreOS 是最早的一批基于 Kubernetes 平台提供企业级容器服务解决方案的厂商之一，他们很敏锐地捕捉到了 TPR 和控制器模式对企业级应用开发者的重要价值；并很快基于 TPR 实现了历史上第一个 Operator：&lt;code>etcd-operator&lt;/code>。它可以让用户通过短短的几条命令就快速的部署一个 etcd 集群，并且基于 kubectl 命令行一个普通的开发者就可以实现 etcd 集群滚动更新、灾备、备份恢复等复杂的运维操作，极大的降低了 etcd 集群的使用门槛，在很短的时间就成为当时 K8s 社区关注的焦点项目。&lt;/p>
&lt;p>与此同时，Operator 以其插件化、自由化的模式特性，迅速吸引了大批的应用开发者，一时间很多市场上主流的分布式应用均出现了对应的 Operator 开源项目；而很多云厂商也迅速跟进，纷纷提出基于 Operator 进行应用上云的解决方案。Operator 在 Kubernetes 应用开发者中的热度大有星火燎原之势。&lt;/p>
&lt;p>虽然 Operator 的出现受到了大量应用开发者的热捧，但是它的发展之路并不是一帆风顺的。对于谷歌团队而言，Controller 和控制器模式一直以来是作为其 API 体系内部实现的核心，从未暴露给终端应用开发者，Kubernetes 社区关注的焦点也更多的是集中在 PaaS 平台层面的核心能力。而 Operator 的出现打破了社区传统意义上的格局，对于谷歌团队而言，Controller 作为 Kubernetes 原生 API 的核心机制，应该交由系统内部的 Controller Manager 组件进行管理，并且遵从统一的设计开发模式，而不是像 Operator 那样交由应用开发者自由地进行 Controller 代码的编写。&lt;/p>
&lt;p>另外 Operator 作为 Kubernetes 生态系统中与终端用户建立连接的桥梁，作为 Kubernetes 项目的设计和捐赠者，谷歌当然也不希望错失其中的主导权。同时 Brendan Burns 突然宣布加盟微软的消息，也进一步加剧了谷歌团队与 Operator 项目之间的矛盾。&lt;/p>
&lt;p>于是，2017 年开始谷歌和 RedHat 开始在社区推广 Aggregated apiserver，应用开发者需要按照标准的社区规范编写一个自定义的 apiserver，同时定义自身应用的 API 模型；通过原生 apiserver 的配置修改，扩展 apiserver 会随着原生组件一同部署，并且限制自定义 API 在系统管理组件下进行统一管理。之后，谷歌和 RedHat 开始在社区大力推广使用聚合层扩展 Kubernetes API，同时建议废弃 TPR 相关功能。&lt;/p>
&lt;p>然而，巨大的压力并没有让 Operator 昙花一现，就此消失。相反，社区大量的 Operator 开发和使用者仍旧拥护着 Operator 清晰自由的设计理念，继续维护演进着自己的应用项目；同时很多云服务提供商也并没有放弃 Operator，Operator 简洁的部署方式和易复制，自由开放的代码实现方式使其维护住了大量忠实粉丝。在用户的选择面前，强如谷歌，红帽这样的巨头也不得不做出退让。最终，TPR 并没有被彻底废弃，而是由 &lt;code>Custom Resource Definition&lt;/code>（简称 CRD）这个如今已经广为人知的资源模型范式代替。&lt;/p>
&lt;p>CoreOS 官方博客也第一时间发出了回应文章指导用户尽快从 TPR 迁移到 CRD：&lt;a href="https://coreos.com/blog/custom-resource-kubernetes-v17">https://coreos.com/blog/custom-resource-kubernetes-v17&lt;/a> 。&lt;/p>
&lt;p>2018 年初，RedHat 完成了对 CoreOS 的收购，并在几个月后发布了 Operator Framework，通过提供 SDK 等管理工具的方式进一步降低了应用开发与 Kubernetes 底层 API 知识体系之间的依赖。至此，Operator 进一步巩固了其在 Kubernetes 应用开发领域的重要地位。&lt;/p>
&lt;h3 id="3-operator-的社区与生态">&lt;strong>3. Operator 的社区与生态&lt;/strong>&lt;/h3>
&lt;p>Operator 开放式的设计模式使开发者可以根据自身业务自由的定义服务模型和相应的控制逻辑，可以说一经推出就在社区引起了巨大的反响。&lt;/p>
&lt;p>一时间，基于不同种类的业务应用涌现了一大批优秀的开源 Operator 项目，我们可以找到其中很多的典型案例，例如对于运维要求较高的数据库集群，我们可以找到像 etcd、Mysql、PostgreSQL、Redis、Cassandra 等很多主流数据库应用对应的 Operator 项目，这些 Operator 的推出有效的简化了数据库应用在 Kubernetes 集群上的部署和运维工作；在监控方向，CoreOS 开发的 prometheus-operator 早日成为社区里的明星项目，Jaeger、FluentD、Grafana 等主流监控应用也或由官方或由开发者迅速推出相应的 Operator 并持续演进；在安全领域，Aqua、Twistlock、Sisdig 等各大容器安全厂商也不甘落后，通过 Operator 的形式简化了相对门槛较高的容器安全应用配置，另外社区中像 cert-manager、vault-operator 这些热门项目也在很多生产环境上得到了广泛应用。&lt;/p>
&lt;p>可以说 &lt;strong>Operator 在很短的时间就成为了分布式应用在 Kubernetes 集群中部署的事实标准&lt;/strong>，同时 Operator 应用如此广泛的覆盖面也使它超过了分布式应用这个原始的范畴，成为了整个 Kubernetes 云原生应用下一个重要存在。&lt;/p>
&lt;p>随着 Operator 的持续发展，已有的社区共享模式已经渐渐不能满足广大开发者和 K8s 集群管理员的需求，如何快速寻找到业务需要的可用 Operator？如何给生态中大量的 Operator 定义一个统一的质量标准？这些都成为了刚刚完成收购的 RedHat 大佬们眼中亟需解决的问题。&lt;/p>
&lt;p>于是我们看到 RedHat 在年初联合 AWS、谷歌、微软等大厂推出了 OperatorHub.io，希望其作为 Kubernetes 社区的延伸，向广大 operator 用户提供一个集中式的公共仓库，用户可以在仓库网站上轻松的搜索到自己业务应用对应的 Operator 并在向导页的指导下完成实例安装；同时，开发者还可以基于 Operator Framework 开发自己的 Operator 并上传分享至仓库中。&lt;/p>
&lt;p>下图为一个 Operator 项目从开发到开源到被使用的全生命周期流程：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/wmo1ab/1616115017879-73ed4f47-23c8-409a-9deb-8f2a2475e386.png" alt="">&lt;/p>
&lt;p>Operator 开源生命周期流程图&lt;/p>
&lt;p>主要流程包括：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>开发者首先使用 Operator SDK 创建一个 Operator 项目；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>利用 SDK 我们可以生成 Operator 对应的脚手架代码，然后扩展相应业务模型和 API，最后实现业务逻辑完成一个 Operator 的代码编写；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>参考社区测试指南进行业务逻辑的本地测试以及打包和发布格式的本地校验；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在完成测试后可以根据规定格式向社区提交 PR，会有专人进行 review；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>待社区审核通过完成 merge 后，终端用户就可以在 OperatorHub.io 页面上找到业务对应的 Operator；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用户可以在 OperatorHub.io 上找到业务 Operator 对应的说明文档和安装指南，通过简单的命令行操作即可在目标集群上完成 Operator 实例的安装；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Operator 实例会根据配置创建所需的业务应用，OLM 和 Operator Metering 等组件可以帮助用户完成业务应用对应的运维和监控采集等管理操作。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>本文主要介绍了 Operator 的基本概念，让您了解 Operator 的应用场景和发展历程。Operator 已经成为 Kubernetes 生态的一个重要设计模式，Kubernetes 从 PaaS 层面提供整套集群、应用编排的框架，而用户通过 Operator 的方式扩展自己的应用，并实现与 Kubernetes 的融合。文章同时也介绍了使用 Operator 的生命周期流程，您可以结合自己的业务场景实现自己的 Operator 组件。&lt;/p></description></item><item><title>Docs: 深入理解Kubernetes Operator</title><link>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kubernetes-Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kubernetes-Operator/</guid><description>
&lt;h1 id="heading">&lt;/h1>
&lt;p>James Laverack InfoQ &lt;em>11 月 18 日&lt;/em>&lt;/p>
&lt;p>作者 | James Laverack 译者 | 王者&lt;strong>本文要点：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Kubernetes API 为所有云资源提供了单个集成点，以此来促进云原生技术的采用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>有一些框架和库可以用来简化 Operator 的编写。支持多种语言，其中 Go 生态系统是最为成熟的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>你可以为非自有的软件创建 Operator。DevOps 团队可能会通过这种方式来管理数据库或其他外部产品。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>难点不在于 Operator 本身，而是要学会理解它的行为。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>多年来，Operator 一直是 Kubernetes 生态系统的重要组成部分。通过将管理界面移动到 Kubneretes API 中，带来了“单层玻璃”的体验。对于希望简化 kuberentes 原生应用程序的开发人员或者希望降低现有系统复杂性的 DevOps 工程师来说，Operator 可能是一个非常有吸引力的选择。但如何从头开始创建一个 Operator 呢？&lt;/p>
&lt;p>深入理解 OperatorOperator 是什么？&lt;/p>
&lt;p>如今，Operator 无处不在。数据库、云原生项目、任何需要在 Kubernetes 上部署或维护的复杂项目都用到了 Operator。CoreOS 在 2016 年首次引入了 Operator，将运维关注点转移到软件系统中。Operator 自动执行操作，例如，Operator 可以部署数据库实例、升级数据库版本或执行备份。然后，这些系统可以被测试，响应速度比人类工程师更快。&lt;/p>
&lt;p>Operator 还通过使用自定义资源定义对 Kubenretes API 进行了扩展，将工具配置转移到了 API 中。这意味着 Kubenretes 本身就变成了“单层玻璃”。DevOps 工程师可以利用围绕 Kubernetes API 资源而构建的工具生态系统来管理和监控他们部署的应用程序：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>使用 Kubernetes 内置的基于角色的访问控制 (RBAC) 来修改授权和身份验证。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用“git ops”对生产变更进行可复制的部署和代码审查。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用基于开放策略代理 (OPA) 的安全工具在自定义资源上应用策略。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用 Helm、Kustomize、ksonnet 和 Terraform 等工具简化部署描述。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这种方法还可以确保生产、测试和开发环境之间的一致性。如果每个集群都是 Kubernetes 集群，则可以使用 Operator 在每个集群中部署相同的配置。&lt;/p>
&lt;p>为什么要使用 Operator？&lt;/p>
&lt;p>使用 Operator 有很多理由。通常情况下，要么是开发团队为他们的产品创建 Operator，要么是 DevOps 团队希望对第三方软件管理进行自动化。无论哪种方式，都应该从确定 Operator 应该负责哪些东西开始。&lt;/p>
&lt;p>最基本的 Operator 用于部署，使用 kubectl apply 就可以创建一个用于响应 API 资源的数据库，但这比内置的 Kubernetes 资源 (如 StatefulSets 或 Deployments) 好不了多少。复杂的 Operator 将提供更大的价值。如果你想要对数据库进行伸缩该怎么办？&lt;/p>
&lt;p>如果是 StatefulSet，你可以执行 kubectl scale statefulset my-db &amp;ndash;replicas 3，这样就可以得到 3 个实例。但如果这些实例需要不同的配置呢？是否需要指定一个实例为主实例，其他实例为副本？如果在添加新副本之前需要执行设置步骤，那该怎么办？在这种情况下，可以使用 Operator。&lt;/p>
&lt;p>更高级的 Operator 可以处理其他一些特性，如响应负载的自动伸缩、备份和恢复、与 Prometheus 等度量系统的集成，甚至可以进行故障检测和自动调优。任何具有传统“运行手册”文档的操作都可以被自动化、测试和依赖，并自动做出响应。&lt;/p>
&lt;p>被管理的系统甚至不需要部署在 Kubernetes 上也能从 Operator 中获益。例如，主要的云服务提供商（如 Amazon Web Services、微软 Azure 和谷歌云）提供 Kubenretes Operator 来管理其他云资源，如对象存储。用户可以通过配置 Kubernetes 应用程序的方式来配置云资源。运维团队可能对其他资源也采取同样的方法，使用 Operator 来管理任何东西——从第三方软件服务到硬件。&lt;/p>
&lt;p>Operator 示例&lt;/p>
&lt;p>在本文中，我们将重点关注 etcd-cluster-operator。这是我和一些同事共同开发的 Operator，用于管理 Kubernetes 内部的 etcd。本文不是专门介绍 Operator 或 etcd 本身，所以我不会太过详细介绍 etcd 的细节，只要能够让你了解 etcd 的用途即可。&lt;/p>
&lt;p>简单地说，etcd 是一个分布式键值数据存储。它有能力管理自己的稳定性，只要：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>每个 etcd 实例都有一个用于计算、网络和存储的独立故障域。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个 etcd 实例都有一个唯一的网络名称。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个 etcd 实例都可以连接到其他实例。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个 etcd 实例都知道其他实例的存在。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>此外：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>etcd 集群的增长或缩小需要使用 etcd 管理 API 进行特定的操作，在添加或删除实例之前声明集群要发生的变化。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>可以使用 etcd 管理 API 上的“快照”端点进行备份。通过 gRPC 调用它，你将得到一个备份文件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用 etcdctl 工具操作备份文件和 etcd 主机上的数据目录来实现恢复。这在真实的机器上很容易，但在 Kubernetes 上需要做一些协调。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>正如你所看到的，这比 Kubernetes StatefulSet 能做更多的事情，所以我们使用 Operator。我们不会深入讨论 etcd-cluster-operator 的机制，但在本文的其余部分，我们都将引用这个 Operator 示例。&lt;/p>
&lt;p>Operator 剖析&lt;/p>
&lt;p>Operator 由两部分组成：&lt;/p>
&lt;p>一个或多个 Kubernetes 自定义资源定义 (CRD)，它们描述了一种新的资源，包括应该具有哪些字段。CRD 可能会有多个，例如 etcd-cluster-operator 同时使用 EtcdCluster 和 EtcdPeer 来封装不同的概念。&lt;/p>
&lt;p>一个运行中的软件，读取自定义资源并作出响应。&lt;/p>
&lt;p>通常，Operator 被包含并部署在 Kubernetes 集群中，通常使用一个简单的 Deployment 资源。理论上，只要 Operator 能够与集群的 Kubernetes API 通信，它就可以在任何地方运行。但是，在集群中运行 Operator 通常更容易。通常情况下会使用自定义 Namespace 将 Operator 与其他资源分隔开来。&lt;/p>
&lt;p>如果我们使用这种方法来运行 Operator，还需要做一些事情：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>一个容器镜像，其中包含 Operator 可执行文件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一个 Namespace。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Operator 的 ServiceAccount，授予读取自定义资源的权限，并配置它要管理的资源 (例如 Pod)。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用于 Operator 容器的 Deployment。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ClusterRoleBinding 和 ClusterRole 资源，绑定到 ServiceAccount。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Webhook 配置。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>稍后我们将详细讨论权限模型和 Webhook。&lt;/p>
&lt;p>软件和工具&lt;/p>
&lt;p>第一个问题是编程语言和生态系统。从理论上讲，几乎任何能够进行 HTTP 调用的语言都可以使用 Operator。假设 Operator 部署在与资源相同的集群中，那么只需要在集群容器中运行它即可。通常是 linux/x86_64，这也是 etcd-cluster-operator 的目标平台，但 Operator 也可以被编译成 arm64 或其他架构，甚至是 Windows 容器。&lt;/p>
&lt;p>Go 语言拥有最成熟的工具。用于构建 Kubernetes 控制器的框架 controller-runtime 可以作为一个独立的工具。此外，Kubebuilder 和 Operator SDK 等项目都构建在控制器运行时之上，目的是提供一种流线化的开发体验。&lt;/p>
&lt;p>除了 Go 语言，其他语言 (如 Java、Rust、Python 和其他语言) 通常会提供用于连接 Kubernetes API 或者专门用于构建 Operator 的工具。这些工具的成熟度和支持水平各有差别。&lt;/p>
&lt;p>另一种选择是通过 HTTP 直接与 Kubernetes API 交互。这种方式所需的工作量最大，好处是团队可以使用他们最熟悉的编程语言。&lt;/p>
&lt;p>最终，这种选择取决于负责构建和维护 Operator 的团队。如果团队已经习惯使用 Go，那么 Go 生态系统丰富的工具显然是最佳的选择。如果团队还没有使用 Go，那么就需要做出权衡，要么在学习和培训更成熟的生态系统工具方面付出代价，要么选择不成熟但团队熟悉其底层语言的生态系统。&lt;/p>
&lt;p>对于 etcd-cluster-operator 来说，开发团队已经非常精通 Go，因此 Go 对我们来说是一个很明智的选择。我们还选择使用 Kubebuilder 而不是 Operator SDK，但这只是因为我们对它比较熟悉。我们的目标平台是 linux/x86_64，但如果需要的话，也可以以其他平台为目标。&lt;/p>
&lt;p>自定义资源和目标状态&lt;/p>
&lt;p>我们为我们的 etcd Operator 创建了一个叫作 EtcdCluster 的自定义资源定义。安装好 CRD 后，用户就可以创建 EtcdCluster 资源。EtcdCluster 资源描述了 etcd 集群的需求，并给出了它的配置。&lt;/p>
&lt;p>PlainTextapiVersion:etcd.improbable.io/v1alpha1kind:EtcdClustermetadata: name: my-first-etcd-clusterspec: replicas: 3 version: 3.2.28&lt;/p>
&lt;p>apiVersion 指定这是哪个版本的 API，在本例中是 v1alpha1。kind 声明这是一个 EtcdCluster。与其他类型的资源一样，我们有一个 metadata，它必须包含一个 name，也可能包含一个 namespace、labels、annotations 和其他标准项。这样我们就可以像对待 Kubernetes 中的其他资源一样对待 EtcdCluster。例如，我们可以使用一个标签来标识哪个团队负责哪一个集群，然后通过 kubectl get etcdcluster -l team=foo 搜索这些集群，就像使用其他标准资源一样。&lt;/p>
&lt;p>spec 字段包含了有关这个 etcd 集群的运维信息。还有很多其他字段，但这里我们只介绍最基本的字段。version 字段描述要部署的 etcd 版本，replicas 字段描述有多少个实例。&lt;/p>
&lt;p>还有一个 status 字段 (在示例中不可见)，运维人员用这个字段来描述集群的当前状态。spec 和 status 是 Kubernetes API 提供的标准字段，可以很好地与其他资源和工具集成。&lt;/p>
&lt;p>因为我们使用了 Kubebuilder，所以可以借助工具生成这些自定义资源定义。我们写了一个 Go 结构体，定义了 spec 和 status 字段：&lt;/p>
&lt;pre>&lt;code>type EtcdClusterSpec struct {
Version string `json:&amp;quot;version&amp;quot;`
Replicas *int32 `json:&amp;quot;replicas&amp;quot;`
Storage *EtcdPeerStorage `json:&amp;quot;storage,omitempty&amp;quot;`
PodTemplate *EtcdPodTemplateSpec `json:&amp;quot;podTemplate,omitempty&amp;quot;`
}
&lt;/code>&lt;/pre>
&lt;p>1
2
3
4
5
6
Go&lt;/p>
&lt;p>基于这个 Go 结构体（和一个类似的 status 结构体），Kubebuilder 会生成我们的自定义资源定义，我们只需要编写代码处理调解逻辑即可。&lt;/p>
&lt;p>其他语言提供的支持可能有所不同。如果你使用的是专为 Operator 设计的框架，那么可能会生成这个，例如 Rust 库 kube-derive 的生成方式就跟这个差不多。如果有团队直接使用 Kubernetes API，那么他们就必须分别编写 CRD 和用于解析数据的代码。&lt;/p>
&lt;p>调解循环&lt;/p>
&lt;p>现在我们已经有了描述 etcd 集群的方式，可以构建 Operator 来管理集群资源。Operator 可以以任何方式运行，而几乎所有 Operator 都可以使用控制器模式。&lt;/p>
&lt;p>控制器是一种简单的程序循环，通常被称为“Reconcile(调解) 循环”，它可以执行以下逻辑：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>观察期望的状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>观察所管理资源的当前状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>采取行动，使托管的资源处在期望的状态。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>对于 Kubernetes 中的 Operator，目标状态就是资源（示例中是 EtcdCluster 的 spec 字段指定的值）。我们的托管资源可以是集群内部或外部的任何资源。在我们的示例中，我们将创建其他 Kubneretes 资源，如 ReplicaSets、PersistentVolumeClaims 和 Services。&lt;/p>
&lt;p>对于 etcd，我们直接连接到 etcd 进程，使用管理 API 来获取它的状态。这种“非 kubernetes”的访问方式需要小心一点，因为它可能会受到网络中断的影响，所以对于这种情况，并不一定是因为服务被关闭了。我们不能将无法连接到 etcd 作为 etcd 没有在运行的信号 (如果我们这么认为了，那么重启 etcd 实例只会加重网络中断的发生)。&lt;/p>
&lt;p>通常，在与非 Kubernetes API 服务通信时，最重要的是要考虑可用性或一致性。对于 etcd 来说，如果我们获得响应，那它们一定是一致的，但其他系统可能不是这样。关键要避免由于信息过时而导致错误操作，从而使中断变得更糟。&lt;/p>
&lt;p>控制器的特性&lt;/p>
&lt;p>对于控制器来说，最简单的就是定时运行调解循环，比如每 30 秒一次。这样做是可以的，但有很多缺点。例如，它必须能够检测上一次循环是否还在运行，这样就不会同时运行两个循环。此外，这意味着每 30 秒会对 Kubernetes 进行一次完整的扫描来获得相关的资源，然后，对于 EtcdCluster 的每个实例，需要运行调解函数来获得相关 Pod 和其他资源。这种方式给 Kubernetes API 造成大量的负载。&lt;/p>
&lt;p>这也导致出现了一种非常“程序性”的方法，因为在下一次协调之前可能需要很长时间才能尽可能快地执行每个循环。例如，一次性创建多个资源。这可能会导致一种非常复杂的状态，运维人员需要进行很多检查才能知道要做什么，而且很有可能会出错。&lt;/p>
&lt;p>为了解决这个问题，控制器提供了一些特性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Kubernetes API 监听。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>API 缓存。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>批量更新。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>所有这些都可以有效地减少要执行的任务，因为运行单个循环的成本和需要等待的时间都减少了，协调逻辑的复杂性也就降低了。&lt;/p>
&lt;p>API 监听&lt;/p>
&lt;p>Kubernetes API 支持“监听”，而不是定时扫描。API 使用者可以对感兴趣的资源或资源类别进行注册，并在匹配的资源发生变更时收到通知。因为请求负载减少了，所以 Operator 大部分时间处于空闲状态，而且几乎可以立即对变更做出响应。Operator 框架通常会为你处理监听所需的注册和管理操作。&lt;/p>
&lt;p>这种设计的另一个结果是你还需要监听你所创建的资源。例如，如果我们创建了 Pods，那么也必须监听我们创建的 Pod。如果它们被删除或修改，导致与我们想要的状态不一致，我们就可以收到通知，并纠正它们。&lt;/p>
&lt;p>我们现在可以进一步简化调解程序。例如，为了响应 EtcdCluster，Operator 希望创建一个 Service 和一些 EtcdPeer 资源。它不是一次性创建好它们，而是先创建 Service，然后退出。但因为我们关注了自己的 Services，我们会收到通知，并立即重新进行调解。这样我们就可以创建对等资源了。否则，我们将创建大量的资源，然后为每个资源重新调解一次，这可能会触发更多的重新调解。&lt;/p>
&lt;p>这种设计有助于保持调解器循环的简单，因为只需要执行一个操作就退出，开发人员不需要处理复杂的状态。&lt;/p>
&lt;p>这样做的一个主要后果是可能会错过更新。网络中断、Pod 重启和其他问题在某些情况下可能导致错过事件。为了解决这个问题，关键在于 Operator 的运行方式应该“基于条件”而不是“基于边缘”。&lt;/p>
&lt;p>这些术语来自信号控制软件，是指基于信号电压做出响应。在软件领域，当我们说“基于边缘”时，意思是“对事件做出反应”，当我们说“基于条件”时，意思是“对观察到的状态做出反应”。&lt;/p>
&lt;p>例如，如果一个资源被删除，我们可以观察到删除事件并选择重新创建。但是，如果我们错过了删除事件，就可能永远不会尝试重新创建。或者，更糟糕的是，我们认为它还在，导致后续出现问题。相反，“基于条件”的方法将触发器简单地视为应该重新进行调解。它将再次观察外部状态，丢弃触发它的变更。&lt;/p>
&lt;p>API 缓存&lt;/p>
&lt;p>控制器的另一个主要特性是缓存请求。如果我们请求 Pods，并且会在 2 秒后再次触发，那么我们可能会为第二个请求保留缓存结果。这减少了 API 服务器的负载，但也给开发人员带来了一些需要注意的问题。&lt;/p>
&lt;p>由于资源请求可能过期，我们必须处理这个问题。资源创建没有被缓存，因此可能出现这种情况：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>调解 EtcdCluster 资源&lt;/p>
&lt;/li>
&lt;li>
&lt;p>搜索 Service，没有找到。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>创建 Service 并退出。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对创建的 Service 做出响应。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>搜索 Service，缓存过期，找不到。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>创建 Service。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>我们错误地创建了一个相同的 Service。Kubernetes API 将会处理这个问题，并给出一个错误，说明 Service 已经存在。因此，我们必须处理这个问题。一般来说，最好的做法是在以后的某个时间进行重新调解。在 Kubebuilder 中，只是简单地在 reconcile 函数中返回一个错误就会导致这种情况发生，但不同的框架可能会有所不同。当稍后重新运行时，缓存最终会保持一致，并可能发生下一阶段的调解。&lt;/p>
&lt;p>这样做的一个副作用是所有资源都必须有确定的名称。否则，如果我们创建了一个重复的资源，可能会使用不同的名称，导致真正的资源重复。&lt;/p>
&lt;p>批量更新&lt;/p>
&lt;p>在某些情况下，我们可能会同时进行很多个调解。例如，如果我们正在监听大量的 Pod 资源，其中有很资源同时处于停止状态 (例如，由于节点故障、管理员操作错误，等等)，那么我们希望得到多次通知。然而，在第一次调解触发并观察到集群状态时，所有的 Pod 都已经消失了，那么后续的调解就是没有必要的。&lt;/p>
&lt;p>如果数量很小，这就不是一个问题。但在较大的集群中，当一次处理数百或数千个更新时，这样做有可能会导致调解循环慢得像爬行一样，因为它一次性重复 100 次相同的操作，甚至会导致队列超载，并最终导致 Operator 崩溃。&lt;/p>
&lt;p>因为我们的调解函数是“基于条件”的，所以我们可以对其加以优化来解决这个问题。当我们将特定资源的更新操作放入队列时，如果队列中已经有该资源的更新操作，那么就将其删除。在从队列读取数据之前先等待一下，我们就可以有效地进行“批量”操作。因此，如果 200 个 Pod 同时停止，我们可能只需要进行一次调解，具体取决于 Operator 及其队列的配置情况。&lt;/p>
&lt;p>权 限&lt;/p>
&lt;p>访问 Kubernetes API 必须提供凭证。在集群中，这是由 ServiceAccount 负责处理的。我们可以使用 ClusterRole 和 ClusterRoleBinding 资源将权限与 ServiceAccount 关联起来。对于 Operator 来说，这很关键。Operator 必须拥有权限来 get、list 和 watch 它在整个集群中管理的资源。此外，对于它创建的任何资源，都需要权限。例如，Pods、StatefulSets、Services 等。&lt;/p>
&lt;p>Kubebuilder 和 Operator SDK 等框架可以为你提供这些权限。例如，Kubebuilder 采用了注解为每个控制器分配权限。如果多个控制器合并为一个二进制文件 (就像我们对 etcd-cluster-operator 所做的那样)，那么权限也将合并在一起。&lt;/p>
&lt;pre>&lt;code>//+kubebuilder:rbac:groups=etcd.improbable.io,resources=etcdpeers,verbs=get;list;watch
//+kubebuilder:rbac:groups=etcd.improbable.io,resources=etcdpeers/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=apps,resources=replicasets,verbs=list;get;create;watch
//+kubebuilder:rbac:groups=core,resources=persistentvolumeclaims,verbs=list;get;create;watch;delete
&lt;/code>&lt;/pre>
&lt;p>1
2
3
4
Plain Text&lt;/p>
&lt;p>这是 EtcdPeer 资源的调解器权限。可以看到，我们 get、list 和 watch 自己的资源，并且可以 update 和 patch 状态子资源。我们可以只更新状态，将信息显示给其他用户。最后，我们对所管理的资源具有广泛的权限，可以根据需要创建和删除它们。&lt;/p>
&lt;p>验证和默认值&lt;/p>
&lt;p>虽然自定义资源本身提供了一定级别的验证和默认值，但更复杂的检查操作需要由 Operator 来执行。最简单的方法是在 Operator 读取资源时执行这些操作，无论是 watch 返回的，还是手动读取后。但是，这意味着默认值将永远不会被应用到 Kubernetes 中，这种行为会让管理员感到困惑。&lt;/p>
&lt;p>更好的方法是使用验证和可变的 Webhook 配置。这些资源告诉 Kubernetes，当一个资源被创建、更新或者在持久化之前被删除时，必须使用 Webhook。&lt;/p>
&lt;p>例如，可变 Webhook 可以用来设置默认值。在 Kubebuilder 中，我们提供了一些额外的配置来创建 MutatingWebhookConfiguration，Kubebuilder 负责提供 API 端点。我们只需要在 spec 结构体中设置 Default 值。然后，当资源被创建时，Webhook 在持久化资源之前被调用，就会应用默认值。&lt;/p>
&lt;p>不过，我们仍然要在读取资源时应用默认值。Operator 不能假设已经知道平台是否启用了 Webhook。即使启用了，也可能配置错误，或者因为网络中断导致 Webhook 被跳过，或者资源可能在配置 Webhook 之前就已经被应用过了。所有这些问题都意味着，虽然 Webhook 提供了更好的用户体验，但 Operator 代码不能完全依赖它们，必须再次应用默认值。&lt;/p>
&lt;p>测 试&lt;/p>
&lt;p>任何一个单独的逻辑单元都可以使用编程语言的常规工具进行单元测试，但是，在进行集成测试时会出现一些特定的问题。我们可能会把 API 服务器当成可以被 mock 的数据库。但在真实的系统中，API 服务器会执行大量的验证和默认操作。这意味着测试和现实之间的行为可能是不一样的。&lt;/p>
&lt;p>一般来说，主要有两种方式：&lt;/p>
&lt;p>第一种方法，下载测试工具并执行 kube-apiserver etcd 可执行文件，创建一个真正的 API 服务器。当然，虽然你可以创建一个 ReplicaSet，但缺少了可以创建 Pods 的 Kubernetes 组件，所以我们看不到有东西真正在运行。&lt;/p>
&lt;p>第二种方法更加全面一些，它使用一个真正的 Kubernetes 集群，可以运行 Pods，并能准确做出响应。通过使用 kind，这种集成测试变得更加容易。kind 是“Kubernetes in Docker”的缩写，它可以在任何可以运行 Docker 容器的地方运行一个完整的 Kubernetes 集群。它提供了一个 API 服务器，可以运行 Pods，并运行 Kubernetes 所有主要的组件。因此，使用了 kind 的测试可以在笔记本电脑上或 CI 中运行，并提供近乎完美的 Kubernetes 体验。&lt;/p>
&lt;p>总 结&lt;/p>
&lt;p>在这篇文章中，我们谈到了很多想法：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>将 Operator 作为 Pods 部署在集群中。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>可以支持任何一种编程语言，所以请选择最适合团队的那一种。不过，Go 语言拥有最成熟的生态系统。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>小心使用非 kubernetes 资源，特别是在网络中断或上游 API 发生故障时，它们可能会导致更严重的中断。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在每个调解周期中执行一个操作，然后退出，并允许 Operator 重新将其放入队列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用“基于条件”的方法，忽略触发调解的事件的内容。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为新资源使用确定性的命名。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为你的服务帐户提供最小权限。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在 Webhook 和代码中应用默认值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用 kind 进行集成测试。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>有了这些工具，你就可以构建 Operator 来简化部署，并减轻运维团队的负担，无论是你所拥有的应用程序，还是你自己开发的应用程序。&lt;/p>
&lt;p>关于作者&lt;/p>
&lt;p>James Laverack 是英国 Kubernetes 专业服务公司 Jetstack 的一名解决方案工程师。凭借超过 7 年的行业经验，他的大部分时间都在帮助企业实现云原生化。他也是一个 Kubernetes 贡献者，并且从 1.18 版本开始就加入了 Kubernetes 发布团队。&lt;/p>
&lt;p>原文链接&lt;/p>
&lt;p>Kubernetes Operators in Depth&lt;/p>
&lt;p>&lt;a href="https://www.infoq.com/articles/kubernetes-operators-in-depth/">https://www.infoq.com/articles/kubernetes-operators-in-depth/&lt;/a>&lt;/p></description></item></channel></rss>