<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 性能优化与故障处理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><description>Recent content in 性能优化与故障处理 on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Containerd 问题汇总</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Containerd-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Containerd-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</guid><description>
&lt;h1 id="与老版本不兼容问题">与老版本不兼容问题&lt;/h1>
&lt;p>使用 nerdctl 通过 containerd 运行容器时报错：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>FATA&lt;span style="color:#f92672">[&lt;/span>0000&lt;span style="color:#f92672">]&lt;/span> failed to create shim: OCI runtime create failed: unable to retrieve OCI runtime error &lt;span style="color:#f92672">(&lt;/span>open /run/containerd/io.containerd.runtime.v2.task/default/210729ebc4386d8e89132a3dea24fa0d67643587af119247837a0f1009d82fa7/log.json: no such file or directory&lt;span style="color:#f92672">)&lt;/span>: runc did not terminate successfully: exit status 127: unknown
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>本质是 runc 问题&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># runc -v&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>runc: symbol lookup error: runc: undefined symbol: seccomp_api_get
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># ldd /usr/bin/runc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> linux-vdso.so.1 &lt;span style="color:#f92672">(&lt;/span>0x00007fffbfbee000&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> libpthread.so.0 &lt;span style="color:#f92672">=&lt;/span>&amp;gt; /lib/x86_64-linux-gnu/libpthread.so.0 &lt;span style="color:#f92672">(&lt;/span>0x00007fd802a37000&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> libseccomp.so.2 &lt;span style="color:#f92672">=&lt;/span>&amp;gt; /lib/x86_64-linux-gnu/libseccomp.so.2 &lt;span style="color:#f92672">(&lt;/span>0x00007fd802a15000&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> libc.so.6 &lt;span style="color:#f92672">=&lt;/span>&amp;gt; /lib/x86_64-linux-gnu/libc.so.6 &lt;span style="color:#f92672">(&lt;/span>0x00007fd802823000&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /lib64/ld-linux-x86-64.so.2 &lt;span style="color:#f92672">(&lt;/span>0x00007fd8036f9000&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;a href="https://github.com/containerd/containerd/issues/6209">https://github.com/containerd/containerd/issues/6209&lt;/a>&lt;/p>
&lt;p>主要是 libseccomp 这个包的版本问题，&lt;code>seccomp_api_get&lt;/code>是从 libseccomp 的 2.4.0 版本开始支持的，但是 RedHad 只能更新到 2.3.X。&lt;/p>
&lt;p>Ubuntu 可以通过 &lt;code>apt install libseccomp-dev&lt;/code> 安装解决，但是 CentOS 还不知道怎么解决&lt;/p>
&lt;p>runc 1.0.3 - 1.1.1 之间的几个版本报这个错，1.0.2 和 1.1.1 没问题，但是 containerd 1.5.9 默认带的就是 runc 1.0.3&lt;/p>
&lt;h1 id="各种命令与配置文件">各种命令与配置文件&lt;/h1>
&lt;p>ctr、nerdctl 等命令好像不会操作应用了 /etc/containerd/config.toml 配置文件的 Containerd，但是 crictl 会&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># ctr image pull reg.superstor.com/lchdzh/k8s-debug:v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>INFO&lt;span style="color:#f92672">[&lt;/span>0000&lt;span style="color:#f92672">]&lt;/span> trying next host error&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;failed to do request: Head \&amp;#34;https://reg.superstor.com/v2/lchdzh/k8s-debug/manifests/v1\&amp;#34;: x509: certificate is not valid for any names, but wanted to match reg.superstor.com&amp;#34;&lt;/span> host&lt;span style="color:#f92672">=&lt;/span>reg.superstor.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ctr: failed to resolve reference &lt;span style="color:#e6db74">&amp;#34;reg.superstor.com/lchdzh/k8s-debug:v1&amp;#34;&lt;/span>: failed to &lt;span style="color:#66d9ef">do&lt;/span> request: Head &lt;span style="color:#e6db74">&amp;#34;https://reg.superstor.com/v2/lchdzh/k8s-debug/manifests/v1&amp;#34;&lt;/span>: x509: certificate is not valid &lt;span style="color:#66d9ef">for&lt;/span> any names, but wanted to match reg.superstor.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># nerdctl pull reg.superstor.com/lchdzh/k8s-debug:v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>INFO&lt;span style="color:#f92672">[&lt;/span>0000&lt;span style="color:#f92672">]&lt;/span> trying next host error&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;failed to do request: Head \&amp;#34;https://reg.superstor.com/v2/lchdzh/k8s-debug/manifests/v1\&amp;#34;: x509: certificate is not valid for any names, but wanted to match reg.superstor.com&amp;#34;&lt;/span> host&lt;span style="color:#f92672">=&lt;/span>reg.superstor.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>FATA&lt;span style="color:#f92672">[&lt;/span>0000&lt;span style="color:#f92672">]&lt;/span> failed to resolve reference &lt;span style="color:#e6db74">&amp;#34;reg.superstor.com/lchdzh/k8s-debug:v1&amp;#34;&lt;/span>: failed to &lt;span style="color:#66d9ef">do&lt;/span> request: Head &lt;span style="color:#e6db74">&amp;#34;https://reg.superstor.com/v2/lchdzh/k8s-debug/manifests/v1&amp;#34;&lt;/span>: x509: certificate is not valid &lt;span style="color:#66d9ef">for&lt;/span> any names, but wanted to match reg.superstor.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># crictl pull reg.superstor.com/lchdzh/k8s-debug:v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Image is up to date &lt;span style="color:#66d9ef">for&lt;/span> sha256:c690d4fd64d6622c3721a1db686c2e4cfb559dd1d9f9ff825584a8f56ec02c7f
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>已经配置了私有镜像注册中心，但是 ctr 和 nerdctl 却没有效果。&lt;/p></description></item><item><title>Docs: docker 的 MountFlags=slave 与 live-restore 冲突问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/docker-%E7%9A%84-MountFlagsslave-%E4%B8%8E-live-restore-%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/docker-%E7%9A%84-MountFlagsslave-%E4%B8%8E-live-restore-%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/</guid><description>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s?__biz=MzU1MzY4NzQ1OA==&amp;amp;mid=2247488900&amp;amp;idx=1&amp;amp;sn=b9420dbae3d086311c282dde271b3471&amp;amp;chksm=fbee5549cc99dc5fcf4d83faeb77fd7f6c837f2ece304c6af625ae11ae843128aaed38b3c35d&amp;amp;scene=126&amp;amp;sessionid=1605832632&amp;amp;key=9dfe4cb30db17ae991f8e68174f62da318e75e7221e5fd48f6ef1e5c08a87e71f358fbaad41321ed6a549850dd297d227207d31209f9126b712acf4870650fd30050c23485171f2d1bf1980917bcae4f148a2cb5935ddc9c80a7c6215e6b6ce78ed056e8862f75298fc7d031b8c42f57eed7b759d6088d899168e9effbb1fb5a&amp;amp;ascene=1&amp;amp;uin=MTI5NTMzMzA0MQ%3D%3D&amp;amp;devicetype=Windows+10+x64&amp;amp;version=6300002f&amp;amp;lang=zh_CN&amp;amp;exportkey=AZNJ0xojlJzRbaM5mYfSnYM%3D&amp;amp;pass_ticket=mBtdtIuLwUXswbOD%2Bp8S%2Bqa1DJpz9Uz6Q9%2FxUG1bfKg%2FPKpyXOhyIuXDpZTrch%2BM&amp;amp;wx_header=0">Pod 一直停留在 Terminating 状态，我等得花儿都谢了~&lt;/a>&lt;/p>
&lt;p>近期，弹性云线上集群发生了几起特殊的容器漂移失败事件，其特殊之处在于容器处于 Pod Terminating 状态，而宿主则处于 Ready 状态。&lt;/p>
&lt;p>宿主状态为 Ready 说明其能够正常处理 Pod 事件，但是 Pod 却卡在了退出阶段，说明此问题并非由 kubelet 引起，那么 docker 就是 1 号犯罪嫌疑人了。&lt;/p>
&lt;p>下文将详细介绍问题的排查与分析全过程。&lt;/p>
&lt;h2 id="2-抽丝剥茧">2. 抽丝剥茧&lt;/h2>
&lt;h3 id="21-排除-kubelet-嫌疑">2.1 排除 kubelet 嫌疑&lt;/h3>
&lt;p>Pod 状态如下：&lt;/p>
&lt;p>&lt;code>[stupig@master ~]$ kubectl get pod -owide pod-976a0-5              0/1     Terminating        0          112m&lt;/code>&lt;/p>
&lt;p>尽管 kubelet 的犯罪嫌疑已经很小，但是我们还是需要排查 kubelet 日志进一步确认。截取 kubelet 关键日志片段如下：&lt;/p>
&lt;p>&lt;code>I1014 10:56:46.492682   34976 kubelet_pods.go:1017] Pod &amp;quot;pod-976a0-5_default(f1e03a3d-0dc7-11eb-b4b1-246e967c4efc)&amp;quot; is terminated, but some containers have not been cleaned up: {ID:{Type:docker ID:41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef} Name:stupig State:exited CreatedAt:2020-10-14 10:49:57.859913657 +0800 CST StartedAt:2020-10-14 10:49:57.928654495 +0800 CST FinishedAt:2020-10-14 10:50:28.661263065 +0800 CST ExitCode:0 Hash:2101852810 HashWithoutResources:2673273670 RestartCount:0 Reason:Completed Message: Resources:map[CpuQuota:200000 Memory:2147483648 MemorySwap:2147483648]} E1014 10:56:46.709255   34976 remote_runtime.go:250] RemoveContainer &amp;quot;41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef&amp;quot; from runtime service failed: rpc error: code = Unknown desc = failed to remove container &amp;quot;41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef&amp;quot;: Error response from daemon: container 41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef: driver &amp;quot;overlay2&amp;quot; failed to remove root filesystem: unlinkat /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged: device or resource busy E1014 10:56:46.709292   34976 kuberuntime_gc.go:126] Failed to remove container &amp;quot;41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef&amp;quot;: rpc error: code = Unknown desc = failed to remove container &amp;quot;41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef&amp;quot;: Error response from daemon: container 41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef: driver &amp;quot;overlay2&amp;quot; failed to remove root filesystem: unlinkat /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged: device or resource busy&lt;/code>&lt;/p>
&lt;p>日志显示 kubelet 处于 Pod Terminating 状态的原因很清楚：清理容器失败。&lt;/p>
&lt;p>kubelet 清理容器的命令是 &lt;code>docker rm -f&lt;/code> ，其失败的原因在于删除容器目录 &lt;code>xxx/merged&lt;/code> 时报错，错误提示为 &lt;code>device or resource busy&lt;/code> 。&lt;/p>
&lt;p>除此之外，kubelet 无法再提供其他关键信息。&lt;/p>
&lt;p>登陆宿主，我们验证对应容器的状态：&lt;/p>
&lt;p>&lt;code>[stupig@hostname ~]$ sudo docker ps -a | grep pod-976a0-5 41020461ed4d            Removal In Progress                            k8s_stupig_pod-976a0-5_default_f1e03a3d-0dc7-11eb-b4b1-246e967c4efc_0 f0a75e10b252            Exited (0) 2 minutes ago                       k8s_POD_pod-976a0-5_default_f1e03a3d-0dc7-11eb-b4b1-246e967c4efc_0 [stupig@hostname ~]$ sudo docker rm -f 41020461ed4d Error response from daemon: container 41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef: driver &amp;quot;overlay2&amp;quot; failed to remove root filesystem: unlinkat /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged: device or resource busy&lt;/code>&lt;/p>
&lt;p>问题已然清楚，现在我们有两种排查思路：&lt;/p>
&lt;ul>
&lt;li>参考 Google 上解决 &lt;code>device or resource busy&lt;/code> 问题的思路&lt;/li>
&lt;li>结合现象分析代码&lt;/li>
&lt;/ul>
&lt;h3 id="22-google-大法">2.2 Google 大法&lt;/h3>
&lt;p>有问题找 Google！所以，我们首先咨询了 Google，检索结果显示很多人都碰到了类似的问题。&lt;/p>
&lt;p>而网络上主流的解决方案：配置 docker 服务 MountFlags 为 slave，避免 docker 挂载点信息泄漏到其他 mnt 命名空间，详细原因请参阅：docker device busy 问题解决方案[1]。&lt;/p>
&lt;p>这么简单？？？显然不能，检查发现 docker 服务当前已配置 MountFlags 为 slave。网络银弹再次失去功效。&lt;/p>
&lt;p>so，我们还是老老实实结合现场分析代码吧。&lt;/p>
&lt;h3 id="23-docker-处理流程">2.3 docker 处理流程&lt;/h3>
&lt;p>在具体分析 docker 代码之前，先简单介绍下 docker 的处理流程，避免作为一只无头苍蝇处处碰壁。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/4d90f6bb-b649-46d3-870f-b087ab75cbf9/640" alt="">&lt;/p>
&lt;p>清楚了 docker 的处理流程之后，我们再来分析现场。&lt;/p>
&lt;h3 id="24-提审-docker">2.4 提审 docker&lt;/h3>
&lt;p>问题发生在 docker 清理阶段，docker 清理容器读写层出错，报错信息为 &lt;code>device or resource busy&lt;/code>，说明 docker 读写层并没有被正确卸载，或者是没有完全卸载。下面的命令可以验证这个结论：&lt;/p>
&lt;p>&lt;code>[stupig@hostname ~]$ grep -rwn '/home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged' /proc/*/mountinfo /proc/22283/mountinfo:50:386 542 0:92 / /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged rw,relatime - overlay overlay rw,lowerdir=XXX,upperdir=XXX,workdir=XXX /proc/22407/mountinfo:50:386 542 0:92 / /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged rw,relatime - overlay overlay rw,lowerdir=XXX,upperdir=XXX,workdir=XXX /proc/28454/mountinfo:50:386 542 0:92 / /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged rw,relatime - overlay overlay rw,lowerdir=XXX,upperdir=XXX,workdir=XXX /proc/28530/mountinfo:50:386 542 0:92 / /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged rw,relatime - overlay overlay rw,lowerdir=XXX,upperdir=XXX,workdir=XXX&lt;/code>&lt;/p>
&lt;p>不出所料，容器读写层仍然被以上四个进程所挂载，进而导致 docker 在清理读写层目录时报错。&lt;/p>
&lt;p>随之而来的问题是，为什么 docker 没有正确卸载容器读写层？我们先展示下 &lt;code>docker stop&lt;/code> 中卸载容器读写层挂载的相关部分代码：&lt;/p>
&lt;p>`func (daemon _Daemon) Cleanup(container_container.Container) {
   if err := daemon.conditionalUnmountOnCleanup(container); err != nil {
      if mountid, err := daemon.imageService.GetLayerMountID(container.ID, container.OS); err == nil {
         daemon.cleanupMountsByID(mountid)
      }
   }
}
func (daemon _Daemon) conditionalUnmountOnCleanup(container_container.Container) error {
   return daemon.Unmount(container)
}
func (daemon _Daemon) Unmount(container_container.Container) error {
   if container.RWLayer == nil {
      return errors.New(&amp;ldquo;RWLayer of container&amp;rdquo; + container.ID + &amp;ldquo;is unexpectedly nil&amp;rdquo;)
   }
   if err := container.RWLayer.Unmount(); err != nil {
      logrus.Errorf(&amp;ldquo;Error unmounting container %s: %s&amp;rdquo;, container.ID, err)
      return err
   }&lt;/p>
&lt;p>return nil
}
func (rl _referencedRWLayer) Unmount() error {
   return rl.layerStore.driver.Put(rl.mountedLayer.mountID)
}
func (d_Driver) Put(id string) error {
   d.locker.Lock(id)
   defer d.locker.Unlock(id)
   dir := d.dir(id)
   mountpoint := path.Join(dir, &amp;ldquo;merged&amp;rdquo;)
   logger := logrus.WithField(&amp;ldquo;storage-driver&amp;rdquo;, &amp;ldquo;overlay2&amp;rdquo;)
   if err := unix.Unmount(mountpoint, unix.MNT_DETACH); err != nil {
      logger.Debugf(&amp;ldquo;Failed to unmount %s overlay: %s - %v&amp;rdquo;, id, mountpoint, err)
   }
   if err := unix.Rmdir(mountpoint); err != nil &amp;amp;&amp;amp; !os.IsNotExist(err) {
      logger.Debugf(&amp;ldquo;Failed to remove %s overlay: %v&amp;rdquo;, id, err)
   }
   return nil
}&lt;/p>
&lt;p>`&lt;/p>
&lt;p>代码处理流程清晰明了，最终 docker 会发起 &lt;code>SYS_UMOUNT2&lt;/code> 系统调用卸载容器读写层。&lt;/p>
&lt;p>但是，docker 在清理容器读写层时却提示错误，并且容器读写层挂载信息也出现在其他进程中。难不成 docker 没有执行卸载操作？结合 docker 日志分析：&lt;/p>
&lt;p>&lt;code>Oct 14 10:50:28 hostname dockerd: time=&amp;quot;2020-10-14T10:50:28.769199725+08:00&amp;quot; level=debug msg=&amp;quot;Failed to unmount e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5 overlay: /home/docker_rt/overlay2/e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5/merged - invalid argument&amp;quot; storage-driver=overlay2 Oct 14 10:50:28 hostname dockerd: time=&amp;quot;2020-10-14T10:50:28.769213547+08:00&amp;quot; level=debug msg=&amp;quot;Failed to remove e5dab77be213d9f9cfc0b0b3281dbef9c2878fee3b8e406bc8ab97adc30ae4d5 overlay: device or resource busy&amp;quot; storage-driver=overlay2&lt;/code>&lt;/p>
&lt;p>日志显示 docker 在执行卸载容器读写层命令时出错，提示 &lt;code>invalid argument&lt;/code>。结合 umount2[2] 文档可知，容器读写层并非是 dockerd（docker 后台进程）的挂载点？？？&lt;/p>
&lt;p>现在，回过头来分析拥有容器读写层挂载信息的进程，我们发现一个惊人的信息：&lt;/p>
&lt;p>&lt;code>[stupig@hostname ~]$ ps -ef|grep -E &amp;quot;22283|22407|28454|28530&amp;quot; root      22283      1  0 10:48 ?        00:00:00 docker-containerd-shim -namespace moby root      22407      1  0 10:48 ?        00:00:00 docker-containerd-shim -namespace moby root      28454      1  0 10:49 ?        00:00:00 docker-containerd-shim -namespace moby root      28530      1  0 10:49 ?        00:00:00 docker-containerd-shim -namespace moby&lt;/code>&lt;/p>
&lt;p>容器读写层挂载信息没有出现在 dockerd 进程命名空间中，却出现在其他容器的托管服务 shim 进程的命名空间内，推断 dockerd 进程发生了重启，对比进程启动时间与命名空间详情可以进行验证：&lt;/p>
&lt;pre tabindex="0">&lt;code>
~]$ ps -eo pid,cmd,lstart|grep dockerd
 34836 /usr/bin/dockerd --storage- Wed Oct 14 10:50:15 2020
[stupig[@hostname ](https://notes-learning.oss-cn-beijing.aliyuncs.com/4d90f6bb-b649-46d3-870f-b087ab75cbf9/latex)(pidof dockerd)/ns
lrwxrwxrwx 1 root root 0 Oct 14 10:50 ipc -&amp;gt; ipc:\[4026531839]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 mnt -&amp;gt; mnt:\[4026533327]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 net -&amp;gt; net:\[4026531968]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 pid -&amp;gt; pid:\[4026531836]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 user -&amp;gt; user:\[4026531837]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 uts -&amp;gt; uts:\[4026531838]
[stupig[@hostname ](/hostname) ~]$ ps -eo pid,cmd,lstart|grep -w containerd|grep -v shim
 34849 docker-containerd --config  Wed Oct 14 10:50:15 2020
[stupig[@hostname ](https://notes-learning.oss-cn-beijing.aliyuncs.com/4d90f6bb-b649-46d3-870f-b087ab75cbf9/latex)(pidof docker-containerd)/ns
lrwxrwxrwx 1 root root 0 Oct 14 10:50 ipc -&amp;gt; ipc:\[4026531839]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 mnt -&amp;gt; mnt:\[4026533327]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 net -&amp;gt; net:\[4026531968]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 pid -&amp;gt; pid:\[4026531836]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 user -&amp;gt; user:\[4026531837]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 uts -&amp;gt; uts:\[4026531838]
[stupig[@hostname ](/hostname) ~]$ ps -eo pid,cmd,lstart|grep -w containerd-shim
 22283 docker-containerd-shim -nam Wed Oct 14 10:48:50 2020
 22407 docker-containerd-shim -nam Wed Oct 14 10:48:55 2020
 28454 docker-containerd-shim -nam Wed Oct 14 10:49:53 2020
 28530 docker-containerd-shim -nam Wed Oct 14 10:49:53 2020
[stupig[@hostname ](/hostname) ~]$ sudo ls -la /proc/28454/ns
lrwxrwxrwx 1 root root 0 Oct 14 10:50 ipc -&amp;gt; ipc:\[4026531839]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 mnt -&amp;gt; mnt:\[4026533200]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 net -&amp;gt; net:\[4026531968]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 pid -&amp;gt; pid:\[4026531836]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 user -&amp;gt; user:\[4026531837]
lrwxrwxrwx 1 root root 0 Oct 14 10:50 uts -&amp;gt; uts:\[4026531838]
[stupig[@hostname ](https://notes-learning.oss-cn-beijing.aliyuncs.com/4d90f6bb-b649-46d3-870f-b087ab75cbf9/latex)$/ns
lrwxrwxrwx 1 panpeilong panpeilong 0 Oct 14 21:49 ipc -&amp;gt; ipc:\[4026531839]
lrwxrwxrwx 1 panpeilong panpeilong 0 Oct 14 21:49 mnt -&amp;gt; mnt:\[4026531840]
lrwxrwxrwx 1 panpeilong panpeilong 0 Oct 14 21:49 net -&amp;gt; net:\[4026531968]
lrwxrwxrwx 1 panpeilong panpeilong 0 Oct 14 21:49 pid -&amp;gt; pid:\[4026531836]
lrwxrwxrwx 1 panpeilong panpeilong 0 Oct 14 21:49 user -&amp;gt; user:\[4026531837]
lrwxrwxrwx 1 panpeilong panpeilong 0 Oct 14 21:49 uts -&amp;gt; uts:\[4026531838]
&lt;/code>&lt;/pre>&lt;p>结果验证了我们推断的正确性。现在再补充下 docker 组件的进程树模型，用以解释这个现象，模型如下：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/4d90f6bb-b649-46d3-870f-b087ab75cbf9/640" alt="">&lt;/p>
&lt;p>dockerd 进程启动时，会自动拉起 containerd 进程；当用户创建并启动容器时，containerd 会启动 containerd-shim 进程用于托管容器进程，最终由 containerd-shim 调用 runc 启动容器进程。runc 负责初始化进程命名空间，并 exec 容器启动命令。&lt;/p>
&lt;p>上述模型中 shim 进程存在的意义是：允许 dockerd/containerd 升级或重启，同时不影响已运行容器。docker 提供了 &lt;code>live-restore&lt;/code> 的能力，而我们的集群也的确启用了该配置。&lt;/p>
&lt;p>此外，由于我们在 systemd 的 docker 配置选项中配置了 &lt;code>MountFlags=slave&lt;/code>，参考 systemd 配置说明[3]，systemd 在启动 dockerd 进程时，会创建一个新的 mnt 命名空间。&lt;/p>
&lt;p>至此，问题已基本定位清楚：&lt;/p>
&lt;ul>
&lt;li>systemd 在启动 dockerd 服务时，将 dockerd 安置在一个新的 mnt 命名空间中&lt;/li>
&lt;li>用户创建并启动容器时，dockerd 会在本 mnt 命名空间内挂载容器读写层目录，并启动 shim 进程托管容器进程&lt;/li>
&lt;li>由于某种原因，dockerd 服务发生重启，systemd 会将其安置在另一个新的 mnt 命名空间内&lt;/li>
&lt;li>用户删除容器时，容器退出时，dockerd 在清理容器读写层挂载时报错，因为挂载并非在当前 dockerd 的 mnt 命名空间内&lt;/li>
&lt;/ul>
&lt;p>后来，我们在 docker issue 中也发现了官方给出的说明[4]，&lt;code>MountFlags=slave&lt;/code> 与 &lt;code>live-restore&lt;/code> 确实不能同时使用。&lt;/p>
&lt;h3 id="25-一波又起">2.5 一波又起&lt;/h3>
&lt;p>还没当我们沉浸在解决问题的喜悦之中，另一个疑问接踵而来。我们线上集群好多宿主同时配置了 &lt;code>MountFlags=slave&lt;/code> 和 &lt;code>live-restore=true&lt;/code>，为什么问题直到最近才报出来呢？&lt;/p>
&lt;p>当我们分析了几起 &lt;code>Pod Terminating&lt;/code> 的涉事宿主后，发现它们的一个通性是 docker 版本为 &lt;code>18.06.3-ce&lt;/code>，而我们当前主流的版本仍然是 &lt;code>1.13.1&lt;/code>。&lt;/p>
&lt;p>难道是新版本中才引入的问题？我们首先在测试环境中对 &lt;code>1.13.1&lt;/code> 版本的 docker 进行了验证，Pod 确实没有被阻塞在 Terminating 状态，这是不是说明低版本 docker 不存在挂载点泄漏的问题呢？&lt;/p>
&lt;p>事实并非如此。当我们再次进行验证时，在删除 Pod 前记录了测试容器的读写层，之后发送删除 Pod 指令，Pod 顺利退出，但此时，我们登录 Pod 之前所在宿主，发现 docker 日志中同样也存在如下日志：&lt;/p>
&lt;p>&lt;code>Oct 14 22:12:43 hostname2 dockerd: time=&amp;quot;2020-10-14T22:12:43.730726978+08:00&amp;quot; level=debug msg=&amp;quot;Failed to unmount fb41efa2cfcbfbb8d90bd1d8d77d299e17518829faf52af40f7a1552ec8aa165 overlay: /home/docker_rt/overlay2/fb41efa2cfcbfbb8d90bd1d8d77d299e17518829faf52af40f7a1552ec8aa165/merged - invalid argument&amp;quot;&lt;/code>&lt;/p>
&lt;p>同样存在卸载问题的情况下，高低版本的 docker 却呈现出了不同的结果，这显然是 docker 的处理逻辑发生了变更，这里我们对比源码能够很快得出结论：&lt;/p>
&lt;p>``// 1.13.1  版本处理逻辑
func (daemon _Daemon) cleanupContainer(container_container.Container, forceRemove, removeVolume bool) (err error) {
   // If force removal is required, delete container from various
   // indexes even if removal failed.
   defer func() {
      if err == nil || forceRemove {
         daemon.nameIndex.Delete(container.ID)
         daemon.linkIndex.delete(container)
         selinuxFreeLxcContexts(container.ProcessLabel)
         daemon.idIndex.Delete(container.ID)
         daemon.containers.Delete(container.ID)
         if e := daemon.removeMountPoints(container, removeVolume); e != nil {
            logrus.Error(e)
         }
         daemon.LogContainerEvent(container, &amp;ldquo;destroy&amp;rdquo;)
      }
   }()&lt;/p>
&lt;p>if err = os.RemoveAll(container.Root); err != nil {
      return fmt.Errorf(&amp;ldquo;Unable to remove filesystem for %v: %v&amp;rdquo;, container.ID, err)
   }&lt;/p>
&lt;p>// When container creation fails and &lt;code>RWLayer&lt;/code> has not been created yet, we
   // do not call &lt;code>ReleaseRWLayer&lt;/code>
   if container.RWLayer != nil {
      metadata, err := daemon.layerStore.ReleaseRWLayer(container.RWLayer)
      layer.LogReleaseMetadata(metadata)
      if err != nil &amp;amp;&amp;amp; err != layer.ErrMountDoesNotExist {
         return fmt.Errorf(&amp;ldquo;Driver %s failed to remove root filesystem %s: %s&amp;rdquo;, daemon.GraphDriverName(), container.ID, err)
      }
   }&lt;/p>
&lt;p>return nil
}&lt;/p>
&lt;p>// 18.06.3-ce  版本处理逻辑
func (daemon _Daemon) cleanupContainer(container_container.Container, forceRemove, removeVolume bool) (err error) {
   // When container creation fails and &lt;code>RWLayer&lt;/code> has not been created yet, we
   // do not call &lt;code>ReleaseRWLayer&lt;/code>
   if container.RWLayer != nil {
      err := daemon.imageService.ReleaseLayer(container.RWLayer, container.OS)
      if err != nil {
         err = errors.Wrapf(err, &amp;ldquo;container %s&amp;rdquo;, container.ID)
         container.SetRemovalError(err)
         return err
      }
      container.RWLayer = nil
   }&lt;/p>
&lt;p>if err := system.EnsureRemoveAll(container.Root); err != nil {
      e := errors.Wrapf(err, &amp;ldquo;unable to remove filesystem for %s&amp;rdquo;, container.ID)
      container.SetRemovalError(e)
      return e
   }&lt;/p>
&lt;p>linkNames := daemon.linkIndex.delete(container)
   selinuxFreeLxcContexts(container.ProcessLabel)
   daemon.idIndex.Delete(container.ID)
   daemon.containers.Delete(container.ID)
   daemon.containersReplica.Delete(container)
   if e := daemon.removeMountPoints(container, removeVolume); e != nil {
      logrus.Error(e)
   }
   for _, name := range linkNames {
      daemon.releaseName(name)
   }
   container.SetRemoved()
   stateCtr.del(container.ID)
   return nil
}&lt;/p>
&lt;p>``&lt;/p>
&lt;p>改动一目了然，官方在清理容器变更[5]中给出了详细的说明。也即在低版本 docker 中，问题并非不存在，仅仅是被隐藏了，并在高版本中被暴露出来。&lt;/p>
&lt;h2 id="3-问题影响">3. 问题影响&lt;/h2>
&lt;p>既然所有版本的 docker 都存在这个问题，那么其影响是什么呢？&lt;/p>
&lt;p>在高版本 docker 中，其影响是显式的，会引起容器清理失败，进而造成 Pod 删除失败。&lt;/p>
&lt;p>而在低版本 docker 中，其影响是隐式的，造成挂载点泄漏，进而可能会造成的影响如下：&lt;/p>
&lt;ul>
&lt;li>inode 被打满：由于挂载点泄漏，容器读写层不会被清理，长时间累计可能会造成 inode 耗尽问题，但是是小概率事件&lt;/li>
&lt;li>容器 ID 复用：由于挂载点未被卸载，当 docker 复用了原来已经退出的容器 ID 时，在挂载容器 init 层与读写层时会失败。由于 docker 生成容器 ID 是随机的，因此也是小概率事件&lt;/li>
&lt;/ul>
&lt;h2 id="4-解决方案">4. 解决方案&lt;/h2>
&lt;p>问题已然明确，如何解决问题成了当务之急。思路有二：&lt;/p>
&lt;ol>
&lt;li>治标：对标 &lt;code>1.13.1&lt;/code> 版本的处理逻辑，修改 &lt;code>18.06.3-ce&lt;/code> 处理代码&lt;/li>
&lt;li>治本：既然官方也提及 &lt;code>MountFlags=slave&lt;/code> 与 &lt;code>live-restore&lt;/code> 不能同时使用，那么我们修改两个配置选项之一即可&lt;/li>
&lt;/ol>
&lt;p>考虑到 &lt;strong>重启 docker 不重启容器&lt;/strong> 这样一个强需求的存在，似乎我们唯一的解决方案就是关闭 &lt;code>MountFlags=slave&lt;/code> 配置。关闭该配置后，与之而来的疑问如下：&lt;/p>
&lt;ul>
&lt;li>能够解决本问题？&lt;/li>
&lt;li>网传其他 systemd 托管服务启用 PrivateTmp 是否会造成挂载点泄漏？&lt;/li>
&lt;/ul>
&lt;p>欲知后事如何，且听下回分解！&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1]&lt;/p>
&lt;p>docker device busy 问题解决方案: &lt;a href="https://blog.terminus.io/docker-device-is-busy/">&lt;em>https://blog.terminus.io/docker-device-is-busy/&lt;/em>&lt;/a>&lt;/p>
&lt;p>[2]&lt;/p>
&lt;p>umount2: &lt;a href="https://man7.org/linux/man-pages/man2/umount.2.html">&lt;em>https://man7.org/linux/man-pages/man2/umount.2.html&lt;/em>&lt;/a>&lt;/p>
&lt;p>[3]&lt;/p>
&lt;p>systemd 配置说明: &lt;a href="https://freedesktop.org/software/systemd/man/systemd.exec.html#MountFlags=">&lt;em>https://freedesktop.org/software/systemd/man/systemd.exec.html#MountFlags=&lt;/em>&lt;/a>&lt;/p>
&lt;p>[4]&lt;/p>
&lt;p>官方给出的说明: &lt;a href="https://github.com/moby/moby/issues/35873#issuecomment-386467562">&lt;em>https://github.com/moby/moby/issues/35873#issuecomment-386467562&lt;/em>&lt;/a>&lt;/p>
&lt;p>[5]&lt;/p>
&lt;p>清理容器变更: &lt;a href="https://github.com/moby/moby/pull/31012">&lt;em>https://github.com/moby/moby/pull/31012&lt;/em>&lt;/a>&lt;/p></description></item><item><title>Docs: Docker 获取 parent 逻辑</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%8E%B7%E5%8F%96-parent-%E9%80%BB%E8%BE%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%8E%B7%E5%8F%96-parent-%E9%80%BB%E8%BE%91/</guid><description>
&lt;p>每次 kubelet 获取镜像列表时，docker 都会获取一遍镜像的 parent
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/fnmwl8/1648798871972-b0aab87e-1e9d-47c9-8053-1e976e8a8f70.png" alt="image.png">&lt;/p>
&lt;p>具体逻辑在这里 &lt;a href="https://github.com/moby/moby/blob/20.10/image/store.go#L202">image/store.go&lt;/a>
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/fnmwl8/1648798901545-0898c7d4-448a-47a1-a53a-077aa24b5539.png" alt="image.png">&lt;/p></description></item><item><title>Docs: Docker 资源泄露系列</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%B5%84%E6%BA%90%E6%B3%84%E9%9C%B2%E7%B3%BB%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%B5%84%E6%BA%90%E6%B3%84%E9%9C%B2%E7%B3%BB%E5%88%97/</guid><description>
&lt;h1 id="heading">&lt;/h1>
&lt;p>原文连接：&lt;/p>
&lt;p>&lt;a href="https://www.likakuli.com/posts/docker-leak3/">博客&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s?__biz=MzU1MzY4NzQ1OA==&amp;amp;mid=2247490402&amp;amp;idx=2&amp;amp;sn=e9f70c854a8e77f43170f064de58843f&amp;amp;chksm=fbee5bafcc99d2b9b0ed7573a5fc78d843391176dc538134397bfe9a9f11f99c8ffe2ac6bb4d&amp;amp;scene=126&amp;amp;sessionid=1609114834&amp;amp;key=2e9eeff5d417729e9825ed88477d990aa52aecaacf854ad15dc661ecff4aeec7ae712c2a8f1cdafc4bdef9d9012c80325d1f3f1541ad922552e15b2a206fe2db7e2a10e95cdc2c4ff6128602a57c0344fe91a2bfa7ca25a24d60b15c89fbb7b5fe3fd463c5abb21e9d025b8b7d10990d534f98a4d2bd67b820a7edbdf26e8c38&amp;amp;ascene=1&amp;amp;uin=MTI5NTMzMzA0MQ%3D%3D&amp;amp;devicetype=Windows+10+x64&amp;amp;version=6300002f&amp;amp;lang=zh_CN&amp;amp;exportkey=AQGO8HBy1qkeFnsEjpWPAx4%3D&amp;amp;pass_ticket=O3LiXYt6FFEMTWkOMp0ckREAEhXAOX%2FRacopdscy8mB%2FoCYiaILEI3YjYaJX3OTg&amp;amp;wx_header=0">微信公众号&lt;/a>&lt;/p></description></item><item><title>Docs: 内核4.18版本以下导致slab内存过高问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%86%85%E6%A0%B84.18%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8B%E5%AF%BC%E8%87%B4slab%E5%86%85%E5%AD%98%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%86%85%E6%A0%B84.18%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8B%E5%AF%BC%E8%87%B4slab%E5%86%85%E5%AD%98%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98/</guid><description>
&lt;p>参考：&lt;a href="https://www.cnblogs.com/zerchin/p/kubernetes.html">原文链接&lt;/a>&lt;/p>
&lt;h2 id="问题背景">问题背景&lt;/h2>
&lt;p>客户的 k8s 集群环境，发现所有的 worker 节点的 kubelet 进程的 CPU 使用率长时间占用过高，通过 pidstat 可以看到 CPU 使用率高达 100%。针对此问题对 kubelet 进程的异常进行问题排查。&lt;/p>
&lt;p>&lt;a href="https://notes-learning.oss-cn-beijing.aliyuncs.com/25de45d3-746c-4662-939d-bc6d7e63667a/DcfCjI.png">
&lt;/a>&lt;/p>
&lt;h2 id="集群环境">集群环境&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>软件&lt;/th>
&lt;th>版本&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>kubernetes&lt;/td>
&lt;td>v1.18.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>docker&lt;/td>
&lt;td>18.09.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>rancher&lt;/td>
&lt;td>v2.4.8-ent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CentOS&lt;/td>
&lt;td>7.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>kernel&lt;/td>
&lt;td>4.4.227-1.el7.elrepo.x86_64&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="排查过程">排查过程&lt;/h2>
&lt;h3 id="使用-strace-工具对-kubelet-进程进行跟踪">使用 strace 工具对 kubelet 进程进行跟踪&lt;/h3>
&lt;ol>
&lt;li>由于 kubelet 进程 CPU 使用率异常，可以使用 strace 工具对 kubelet 进程动态跟踪进程的调用情况，首先使用&lt;code>strace -cp &amp;lt;PID&amp;gt;&lt;/code>命令统计 kubelet 进程在某段时间内的每个系统调用的时间、调用和错误情况.&lt;/li>
&lt;/ol>
&lt;p>&lt;a href="https://notes-learning.oss-cn-beijing.aliyuncs.com/25de45d3-746c-4662-939d-bc6d7e63667a/Dcf9gA.png">
&lt;/a>&lt;/p>
&lt;p>从上图可以看到，执行系统调用过程中，futex 抛出了五千多个 errors，这肯定是不正常的，而且这个函数占用的时间也达到了 99%，所以需要更深层次的查看 kubelet 进程相关的调用。&lt;/p>
&lt;ol start="2">
&lt;li>由于&lt;code>strace -cp&lt;/code>命令只能查看进程的整体调用情况，所以我们可以通过&lt;code>strace -tt -p &amp;lt;PID&amp;gt;&lt;/code>命令打印每个系统调用的时间戳，如下：&lt;/li>
&lt;/ol>
&lt;p>&lt;a href="https://notes-learning.oss-cn-beijing.aliyuncs.com/25de45d3-746c-4662-939d-bc6d7e63667a/DcfS9H.png">
&lt;/a>&lt;/p>
&lt;p>从 strace 输出的结果来看，在执行 futex 相关的系统调用时，有大量的 Connect timed out，并返回了&lt;code>-1&lt;/code> 和&lt;code>ETIMEDOUT&lt;/code>的 error，所以才会在&lt;code>strace -cp&lt;/code>中看到了那么多的 error。&lt;/p>
&lt;p>futex 是一种用户态和内核态混合的同步机制，当 futex 变量告诉进程有竞争发生时，会执行系统调用去完成相应的处理，例如 wait 或者 wake up，从官方的文档了解到，futex 有这么几个参数：&lt;/p>
&lt;pre>&lt;code>futex(uint32_t *uaddr, int futex_op, uint32_t val,
const struct timespec *timeout,
uint32_t *uaddr2, uint32_t val3);
&lt;/code>&lt;/pre>
&lt;p>官方文档给出&lt;code>ETIMEDOUT&lt;/code>的解释：&lt;/p>
&lt;pre>&lt;code>ETIMEDOUT
The operation in futex_op employed the timeout specified in
timeout, and the timeout expired before the operation
completed.
&lt;/code>&lt;/pre>
&lt;p>意思就是在指定的 timeout 时间中，未能完成相应的操作，其中&lt;code>futex_op&lt;/code>对应上述输出结果的&lt;code>FUTEX_WAIT_PRIVATE&lt;/code>和&lt;code>FUTEX_WAIT_PRIVATE&lt;/code>，可以看到基本都是发生在&lt;code>FUTEX_WAIT_PRIVATE&lt;/code>时发生的超时。&lt;/p>
&lt;p>从目前的系统调用层面可以判断，futex 无法顺利进入睡眠状态，但是 futex 做了哪些操作还是不清楚，还无法判断 kubeletCPU 飙高的原因，所以我们需要进一步从 kubelet 的函数调用中去看到底是执行了卡在了哪个地方。&lt;/p>
&lt;blockquote>
&lt;p>FUTEX_PRIVATE_FLAG：这个参数告诉内核 futex 是进程专用的，不与其他进程共享，这里的 FUTEX_WAIT_PRIVATE 和 FUTEX_WAKE_PRIVATE 就是其中的两种 FLAG；&lt;/p>
&lt;p>futex 相关说明 1：&lt;a href="https://man7.org/linux/man-pages/man7/futex.7.html">https://man7.org/linux/man-pages/man7/futex.7.html&lt;/a>&lt;/p>
&lt;p>fuex 相关说明 2： &lt;a href="https://man7.org/linux/man-pages/man2/futex.2.html">https://man7.org/linux/man-pages/man2/futex.2.html&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h3 id="使用-go-pprof-工具对-kubelet-函数调用进行分析">使用 go pprof 工具对 kubelet 函数调用进行分析&lt;/h3>
&lt;p>早期的 k8s 版本，可以直接通过&lt;code>debug/pprof&lt;/code> 接口获取 debug 数据，后面考虑到相关安全性的问题，取消了这个接口，参考&lt;a href="https://github.com/kubernetes/kubernetes/issues/81023">CVE-2019-11248&lt;/a>，我们可以通过 kubectl 开启 proxy 进行相关数据指标的获取&lt;/p>
&lt;ol>
&lt;li>
&lt;p>首先使用&lt;code>kubectl proxy&lt;/code>命令启动 API server 代理&lt;/p>
&lt;p>kubectl proxy &amp;ndash;address=&amp;lsquo;0.0.0.0&amp;rsquo; &amp;ndash;accept-hosts=&amp;rsquo;^*$&amp;rsquo;&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>这里需要注意，如果使用的是 Rancher UI 上 copy 的 kubeconfig 文件，则需要使用指定了 master IP 的 context，如果是 RKE 或者其他工具安装则可以忽略&lt;/p>
&lt;ol start="2">
&lt;li>
&lt;p>构建 golang 环境。go pprof 需要在 golang 环境下使用，本地如果没有安装 golang，则可以通过 docker 快速构建 golang 环境&lt;/p>
&lt;p>docker run -itd &amp;ndash;name golang-env &amp;ndash;net host golang bash&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用 go pprof 工具导出采集的指标，这里替换 127.0.0.1 为 apiserver 节点的 IP，默认端口是 8001，如果 docker run 的环境跑在 apiserver 所在的节点上，可以使用 127.0.0.1。另外，还要替换 NODENAME 为对应的节点名称。&lt;/p>
&lt;p>docker exec -it golang-env bash
go tool pprof -seconds=60 -raw -output=kubelet.pprof http://127.0.0.1:8001/api/v1/nodes/${NODENAME}/proxy/debug/pprof/profile&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>这里等待 60s 后，会将这 60s 内相关的函数调用输出到当前目录的 kubelet.pprof 文件中。&lt;/p>
&lt;ol start="4">
&lt;li>
&lt;p>输出好的 pprof 文件不方便查看，需要转换成火焰图，推荐使用 FlameGraph 工具生成 svg 图&lt;/p>
&lt;p>git clone &lt;a href="https://github.com/brendangregg/FlameGraph.git">https://github.com/brendangregg/FlameGraph.git&lt;/a>
cd FlameGraph/
./stackcollapse-go.pl kubelet.pprof &amp;gt; kubelet.out
./flamegraph.pl kubelet.out &amp;gt; kubelet.svg&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>转换成火焰图后，就可以在浏览器很直观的看到函数相关调用和具体调用时间比了。&lt;/p>
&lt;ol start="5">
&lt;li>分析火焰图&lt;/li>
&lt;/ol>
&lt;p>&lt;a href="https://notes-learning.oss-cn-beijing.aliyuncs.com/25de45d3-746c-4662-939d-bc6d7e63667a/Dcfp3d.png">
&lt;/a>&lt;/p>
&lt;p>从 kubelet 的火焰图可以看到，调用时间最长的函数是&lt;code>k8s.io/kubernetes/vendor/github.com/google/cadvisor/manager.(*containerData).housekeeping&lt;/code>，其中 cAdvisor 是 kubelet 内置的指标采集工具，主要是负责对节点机器上的资源及容器进行实时监控和性能数据采集，包括 CPU 使用情况、内存使用情况、网络吞吐量及文件系统使用情况。&lt;/p>
&lt;p>深入函数调用可以发现&lt;code>k8s.io/kubernetes/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs.(*Manager).GetStats&lt;/code>这个函数占用&lt;code>k8s.io/kubernetes/vendor/github.com/google/cadvisor/manager.(*containerData).housekeeping&lt;/code>这个函数的时间是最长的，说明在获取容器 CGroup 相关状态时占用了较多的时间。&lt;/p>
&lt;ol start="6">
&lt;li>既然这个函数占用时间长，那么我们就分析一下这个函数具体干了什么事儿&lt;/li>
&lt;/ol>
&lt;p>查看源代码：&lt;a href="https://github.com/kubernetes/kubernetes/blob/ded8a1e2853aef374fc93300fe1b225f38f19d9d/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go#L162">https://github.com/kubernetes/kubernetes/blob/ded8a1e2853aef374fc93300fe1b225f38f19d9d/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go#L162&lt;/a>&lt;/p>
&lt;pre>&lt;code>func (s *MemoryGroup) GetStats(path string, stats *cgroups.Stats) error {
statsFile, err := os.Open(filepath.Join(path, &amp;quot;memory.stat&amp;quot;))
if err != nil {
if os.IsNotExist(err) {
return nil
}
return err
}
defer statsFile.Close()
sc := bufio.NewScanner(statsFile)
for sc.Scan() {
t, v, err := fscommon.GetCgroupParamKeyValue(sc.Text())
if err != nil {
return fmt.Errorf(&amp;quot;failed to parse memory.stat (%q) - %v&amp;quot;, sc.Text(), err)
}
stats.MemoryStats.Stats[t] = v
}
stats.MemoryStats.Cache = stats.MemoryStats.Stats[&amp;quot;cache&amp;quot;]
memoryUsage, err := getMemoryData(path, &amp;quot;&amp;quot;)
if err != nil {
return err
}
stats.MemoryStats.Usage = memoryUsage
swapUsage, err := getMemoryData(path, &amp;quot;memsw&amp;quot;)
if err != nil {
return err
}
stats.MemoryStats.SwapUsage = swapUsage
kernelUsage, err := getMemoryData(path, &amp;quot;kmem&amp;quot;)
if err != nil {
return err
}
stats.MemoryStats.KernelUsage = kernelUsage
kernelTCPUsage, err := getMemoryData(path, &amp;quot;kmem.tcp&amp;quot;)
if err != nil {
return err
}
stats.MemoryStats.KernelTCPUsage = kernelTCPUsage
useHierarchy := strings.Join([]string{&amp;quot;memory&amp;quot;, &amp;quot;use_hierarchy&amp;quot;}, &amp;quot;.&amp;quot;)
value, err := fscommon.GetCgroupParamUint(path, useHierarchy)
if err != nil {
return err
}
if value == 1 {
stats.MemoryStats.UseHierarchy = true
}
pagesByNUMA, err := getPageUsageByNUMA(path)
if err != nil {
return err
}
stats.MemoryStats.PageUsageByNUMA = pagesByNUMA
return nil
}
&lt;/code>&lt;/pre>
&lt;p>从代码中可以看到，进程会去读取&lt;code>memory.stat&lt;/code>这个文件，这个文件存放了 cgroup 内存使用情况。也就是说，在读取这个文件花费了大量的时间。这时候，如果我们手动去查看这个文件，会是什么效果？&lt;/p>
&lt;pre tabindex="0">&lt;code>
real 0m9.065s
user 0m0.000s
sys 0m9.064s
&lt;/code>&lt;/pre>&lt;p>从这里可以看出端倪了，读取这个文件花费了 9s，显然是不正常的，难怪 kubeletCPU 使用飙高，原来是堵在这里了。&lt;/p>
&lt;p>基于上述结果，我们在 cAdvisor 的 GitHub 上查找到一个&lt;a href="https://github.com/google/cadvisor/issues/1774">issue&lt;/a>，从该 issue 中可以得知，该问题跟 slab memory 缓存有一定的关系。从该 issue 中得知，受影响的机器的内存会逐渐被使用，通过/proc/meminfo 看到使用的内存是 slab memory，该内存是内核缓存的内存页，并且其中绝大部分都是 dentry 缓存。从这里我们可以判断出，当 CGroup 中的进程生命周期结束后，由于缓存的原因，还存留在 slab memory 中，导致其类似僵尸 CGroup 一样无法被释放。&lt;/p>
&lt;p>也就是每当创建一个 memory CGroup，在内核内存空间中，就会为其创建分配一份内存空间，该内存包含当前 CGroup 相关的 cache（dentry、inode），也就是目录和文件索引的缓存，该缓存本质上是为了提高读取的效率。但是当 CGroup 中的所有进程都退出时，存在内核内存空间的缓存并没有清理掉。&lt;/p>
&lt;p>内核通过伙伴算法进行内存分配，每当有进程申请内存空间时，会为其分配至少一个内存页面，也就是最少会分配 4k 内存，每次释放内存，也是按照最少一个页面来进行释放。当请求分配的内存大小为几十个字节或几百个字节时，4k 对其来说是一个巨大的内存空间，在 Linux 中，为了解决这个问题，引入了 slab 内存分配管理机制，用来处理这种小量的内存请求，这就会导致，当 CGroup 中的所有进程都退出时，不会轻易回收这部分的内存，而这部分内存中的缓存数据，还会被读取到 stats 中，从而导致影响读取的性能。&lt;/p>
&lt;h2 id="解决方法">解决方法&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>清理节点缓存，这是一个临时的解决方法，暂时清空节点内存缓存，能够缓解 kubelet CPU 使用率，但是后面缓存上来了，CPU 使用率又会升上来。&lt;/p>
&lt;p>echo 2 &amp;gt; /proc/sys/vm/drop_caches&lt;/p>
&lt;/li>
&lt;li>
&lt;p>升级内核版本
2.1. 其实这个主要还是内核的问题，在 GitHub 上这个&lt;a href="https://github.com/torvalds/linux/commit/205b20cc5a99cdf197c32f4dbee2b09c699477f0">commit&lt;/a>中有提到，在 5.2+以上的内核版本中，优化了 CGroup stats 相关的查询性能，如果想要更好的解决该问题，建议可以参考自己操作系统和环境，合理的升级内核版本。
2.2. 另外 Redhat 在&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1795049">kernel-4.18.0-176&lt;/a>版本中也优化了相关 CGroup 的性能问题，而 CentOS 8/RHEL 8 默认使用的内核版本就是 4.18，如果目前您使用的操作系统是 RHEL7/CentOS7，则可以尝试逐渐替换新的操作系统，使用这个 4.18.0-176 版本以上的内核，毕竟新版本内核总归是对容器相关的体验会好很多。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>kernel 相关 commit：&lt;a href="https://github.com/torvalds/linux/commit/205b20cc5a99cdf197c32f4dbee2b09c699477f0">https://github.com/torvalds/linux/commit/205b20cc5a99cdf197c32f4dbee2b09c699477f0&lt;/a>&lt;/p>
&lt;p>redhat kernel bug fix：&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1795049">https://bugzilla.redhat.com/show_bug.cgi?id=1795049&lt;/a>&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: 性能优化与故障处理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.2.%E5%AE%9E%E7%8E%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E5%B7%A5%E5%85%B7/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>
&lt;h1 id="容器无法启动时如何排查">容器无法启动时，如何排查&lt;/h1>
&lt;p>场景：有些时候我们用一个官方的容器直接启动，会报错，或者说效果不是我们想要的，我们大概知道如何排查，比如改改容器里面的配置文件，重新启动什么的，那么问题来了，容器起不来我怎么进去？&lt;/p>
&lt;p>如下实例，启动一个 consul 容器报错&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker run -d --name=consul --net=host gliderlabs/consul-server -bootstrap&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker ps -a --no-trunc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>88f8ca844420937fc57c7f46b3b99222a7fdd47591e8a14da34c4110fe3f5c29 gliderlabs/consul-server &lt;span style="color:#e6db74">&amp;#34;/bin/consul agent -server -config-dir=/config -bootstrap&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span> minutes ago Exited &lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span> minutes ago consul
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker logs consul&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">==&lt;/span>&amp;gt; WARNING: Bootstrap mode enabled! Do not enable unless necessary
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">==&lt;/span>&amp;gt; Starting Consul agent...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">==&lt;/span>&amp;gt; Error starting agent: Failed to get advertise address: Multiple private IPs found. Please configure one.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># hostname -I&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>10.222.32.122 172.17.0.1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们可以通过下面的方法，让容器先夯住，让后进入容器调试&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker rm -fv consul&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker run --rm --entrypoint &amp;#34;ls&amp;#34; --name=consul --net=host gliderlabs/consul-server /config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>agent.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>server.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker run -d --entrypoint tail --name=consul --net=host gliderlabs/consul-server -F /tmp/tmp.txt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@10-222-32-122 ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker exec -it consul sh&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="docker-比较不错的-image-推荐">docker 比较不错的 image 推荐&lt;/h1>
&lt;p>&lt;a href="https://hub.docker.com/r/polinux/stress/">https://hub.docker.com/r/polinux/stress/&lt;/a> # 一个非常好用的压测容器，可以对容器指定其所使用的内存和 cpu 等资源的大小。当创建完资源配合等资源限制的对象后，可以通过该容器来测试资源限制是否生效。&lt;/p>
&lt;p>使用示例如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -ti &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --rm &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> polinux/stress stress &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --cpu &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --io &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --vm &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --vm-bytes 128M &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --timeout 1s &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --verbose
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;a href="https://hub.docker.com/r/containous/whoami">https://hub.docker.com/r/containous/whoami&lt;/a> # 一个 go 语言编写的 web 服务器，当请求该容器时，可以输出操作系统信息和 HTTP 请求等，信息如下所示：包括当前容器的 ip 地址，容器的主机名等等&lt;/p>
&lt;h1 id="如何运行一个容器并启动-bash">如何运行一个容器并启动 bash&lt;/h1>
&lt;p>由于容器中的进行执行完成后就会自动退出，所以每次 docker run 之后，有一部分容器无法持久运行，比如 centos 镜像，这时候可以使用下面的方式让容器镜像持续输出任意内容而不会因进程完成而自动退出了&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker create -it -d --name test centos:latest &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> docker start test
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="通过-host-的-veth-设备查找对端-container-的-ip">通过 host 的 veth 设备查找对端 container 的 ip&lt;/h1>
&lt;p>for i in &lt;code>docker ps -q&lt;/code>; do pid=$(docker inspect &amp;ndash;format &amp;lsquo;{{.State.Pid}}&amp;rsquo; $i); nsenter -t $pid &amp;ndash;net ip addr | grep -A 2 if40; done&lt;/p>
&lt;p>注意命令中 grep 筛选的 if40 中的 40 是宿主机上查到的 veth 设备的序号，通过 ip link show 即可获得设备需要，&lt;strong>在屏幕最左侧&lt;/strong>。而 if40 则是容器网络设备所关联对端网络设备名称。下面示例可以看到，155 对应 if155，if154 对应 154&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 宿主机网络设备信息&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># ip a&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>....
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>155: veth74d05e8@if154: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu &lt;span style="color:#ae81ff">1500&lt;/span> qdisc noqueue master docker0 state UP group default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> link/ether 0a:9e:19:c3:98:b7 brd ff:ff:ff:ff:ff:ff link-netnsid &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inet6 fe80::89e:19ff:fec3:98b7/64 scope link
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> valid_lft forever preferred_lft forever
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 容器内网络设备信息&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao network-scripts&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># nsenter -n -t 3039&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao network-scripts&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># ip a&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>....
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>154: eth0@if155: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu &lt;span style="color:#ae81ff">1500&lt;/span> qdisc noqueue state UP group default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> valid_lft forever preferred_lft forever
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="通过各种系统信息查找目标容器">通过各种系统信息查找目标容器&lt;/h1>
&lt;p>在管理 Kubernetes 集群的过程中，我们经常会遇到这样一种情况：在某台节点上发现某个进程资源占用量很高，却又不知道是哪个容器里的进程。有没有办法可以根据 PID 快速找到 Pod 名称呢？&lt;/p>
&lt;p>要获取容器的 ID，通过在 PID 对应的 cgroup 信息中即可查到(比如进程号 32000 的 cgroup 信息在 /proc/32000/cgroup 文件中。该文件内容每行的最后一个段落就是 容器的 ID。)&lt;/p>
&lt;h2 id="通过-pid-查找容器">通过 PID 查找容器&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>pid&lt;span style="color:#f92672">=&lt;/span>$1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>cat /proc/&lt;span style="color:#e6db74">${&lt;/span>pid&lt;span style="color:#e6db74">}&lt;/span>/cgroup | head -1 | awk -F &lt;span style="color:#e6db74">&amp;#39;/&amp;#39;&lt;/span> &lt;span style="color:#e6db74">&amp;#39;{print $5}&amp;#39;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>echo &lt;span style="color:#e6db74">${&lt;/span>CID:7:15&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo docker inspect $CID | jq &lt;span style="color:#e6db74">&amp;#39;.[0].Config.Labels.&amp;#34;io.kubernetes.pod.name&amp;#34;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>而想要反查，那么通过 docker top CONTAINER 命令即可直接获取改容器的 PID&lt;/p>
&lt;h2 id="通过-mount-信息查找目标容器">通过 mount 信息查找目标容器&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ou0feg/1635215387580-a2da5aed-f711-4313-8977-86137662f7fd.png" alt="image.png">
通过 mount 信息中的 layer 信息中的 cacheID，去 layer 的元数据目录中筛选包含该 cacheID 的文件&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao mounts&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># pwd&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/var/lib/docker/image/overlay2/layerdb/mounts
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao mounts&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># grep -r d976eddf7575a3464486d92539229146f3df66080a3265195791ebb0d24b24dd ./&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./mounts/28f5bed704dc80bed6dbaa8af514d2191d8d4ab0339bb3a663e66609ccd34c10/mount-id:d976eddf7575a3464486d92539229146f3df66080a3265195791ebb0d24b24dd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./mounts/28f5bed704dc80bed6dbaa8af514d2191d8d4ab0339bb3a663e66609ccd34c10/init-id:d976eddf7575a3464486d92539229146f3df66080a3265195791ebb0d24b24dd-init
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到该 layer 所属的 ContainerID 为 28f5bed704dc80bed6dbaa8af514d2191d8d4ab0339bb3a663e66609ccd34c10&lt;/p>
&lt;p>这时候通过 docker ps 命令，筛选 ID 前几位，就可以找到该容器了&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@lichenhao layerdb&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># docker ps --all | grep 28f5bed704&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>28f5bed704dc ubuntu:latest &lt;span style="color:#e6db74">&amp;#34;/bin/bash&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> hours ago Up &lt;span style="color:#ae81ff">4&lt;/span> minutes docker_runtime_test
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="通过-netns-信息查找容器">通过 netns 信息查找容器&lt;/h2>
&lt;p>failed to get sandbox ip: check network namespace closed: remove netns: unlinkat /var/run/netns/XXXXXX: device or resource busy。参考：&lt;a href="https://github.com/containerd/containerd/issues/3667">https://github.com/containerd/containerd/issues/3667&lt;/a>&lt;/p>
&lt;p>有时候 pod 在删除时，会卡在 terminating 状态，并在日志中显示无法删除某个 /var/run/netns/ 目录下的 netns，根据这个 netns 的名称，可以找到容器&lt;/p>
&lt;p>grep -l XXX /proc/*/mountinfo # 该命令会显示正在使用 XXX 这个 netns 的进程。然后根据进程号找到容器，重启它即可。&lt;/p>
&lt;h1 id="docker-容器时间与宿主机同步">Docker 容器时间与宿主机同步&lt;/h1>
&lt;p>在我们平时使用 docker，运行我们的应用的时候，访问应用页面的时间与现在相差 8 个小时。无法结合时间点去判断当时服务的异常。同样，当我们在 docker 上运行某些服务时，需要时间与宿主机同步，否则会发生异常&lt;/p>
&lt;p>为了保证容器和宿主机之间的时间同步，可以使用以下几种办法：&lt;/p>
&lt;h2 id="1docker-run">1.Docker run&lt;/h2>
&lt;p>使用 docker run 运行容器时，添加参数 &lt;code>-v /etc/localtime:/etc/localtime:ro&lt;/code>&lt;/p>
&lt;h2 id="2dockerfile">2.DockerFile&lt;/h2>
&lt;p>在 Docker File 中添加如下参数：将时区配置添加到环境变量，并使用软连接，并将时区配置文件覆盖&lt;/p>
&lt;blockquote>
&lt;p>注意：需要保证所使用的基础镜像具有 tzdata 包，否则不会加载 /etc/localtime 文件以更新时区&lt;/p>
&lt;/blockquote>
&lt;pre>&lt;code>RUN apk add --no-caceh tzdata
ENV TimeZone=Asia/Shanghai
RUN ln -snf /usr/share/zoneinfo/$TimeZone /etc/localtime &amp;amp;&amp;amp; echo $TimeZone &amp;gt;/etc/timezone
&lt;/code>&lt;/pre>
&lt;p>实例 DockerFile 如下：&lt;/p>
&lt;blockquote>
&lt;p>设置变量与创建软链接这两个方法任选其一即可&lt;/p>
&lt;/blockquote>
&lt;pre>&lt;code>FROM alpine # Centos 基础镜像
RUN apk add --no-caceh tzdata
ENV TimeZone=Asia/Shanghai # 添加时区环境变量，亚洲，上海
RUN ln -snf /usr/share/zoneinfo/$TimeZone /etc/localtime &amp;amp;&amp;amp; echo $TimeZone &amp;gt;/etc/timezone # 使用软连接，并且将时区配置覆盖/etc/timezone
&lt;/code>&lt;/pre>
&lt;p>构建镜像&lt;/p>
&lt;pre>&lt;code>docker build -t alpine:time .
&lt;/code>&lt;/pre>
&lt;p>正在运行的容器，时间如何同步？&lt;/p>
&lt;p>这种方式同样适用于，构造镜像完成后，时间不同步的状况&lt;/p>
&lt;blockquote>
&lt;p>但是，同样需要保证容器中具有 tzdata 包&lt;/p>
&lt;/blockquote>
&lt;p>在宿主机执行命令如下：&lt;/p>
&lt;pre>&lt;code> docker cp /usr/share/zoneinfo/Asia/Shanghai &amp;lt;容器名&amp;gt;:/etc/localtime
&lt;/code>&lt;/pre></description></item></channel></rss>