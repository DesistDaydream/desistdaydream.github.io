<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>性能优化与故障处理 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><description>Recent content in 性能优化与故障处理 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/index.xml" rel="self" type="application/rss+xml"/><item><title>性能优化与故障处理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>概述 参考：
容器无法启动时，如何排查 场景：有些时候我们用一个官方的容器直接启动，会报错，或者说效果不是我们想要的，我们大概知道如何排查，比如改改容器里面的配置文件，重新启动什么的，那么问题来了，容器起不来我怎么进去？
如下实例，启动一个 consul 容器报错
[root@10-222-32-122 ~]# docker run -d --name=consul --net=host gliderlabs/consul-server -bootstrap [root@10-222-32-122 ~]# docker ps -a --no-trunc CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 88f8ca844420937fc57c7f46b3b99222a7fdd47591e8a14da34c4110fe3f5c29 gliderlabs/consul-server &amp;#34;/bin/consul agent -server -config-dir=/config -bootstrap&amp;#34; 3 minutes ago Exited (1) 3 minutes ago consul [root@10-222-32-122 ~]# docker logs consul ==&amp;gt; WARNING: Bootstrap mode enabled! Do not enable unless necessary ==&amp;gt; Starting Consul agent... ==&amp;gt; Error starting agent: Failed to get advertise address: Multiple private IPs found.</description></item><item><title>Containerd 问题汇总</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Containerd-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Containerd-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</guid><description>与老版本不兼容问题 使用 nerdctl 通过 containerd 运行容器时报错：
FATA[0000] failed to create shim: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/default/210729ebc4386d8e89132a3dea24fa0d67643587af119247837a0f1009d82fa7/log.json: no such file or directory): runc did not terminate successfully: exit status 127: unknown 本质是 runc 问题
~]# runc -v runc: symbol lookup error: runc: undefined symbol: seccomp_api_get ~]# ldd /usr/bin/runc linux-vdso.so.1 (0x00007fffbfbee000) libpthread.so.0 =&amp;gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fd802a37000) libseccomp.so.2 =&amp;gt; /lib/x86_64-linux-gnu/libseccomp.so.2 (0x00007fd802a15000) libc.so.6 =&amp;gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fd802823000) /lib64/ld-linux-x86-64.so.2 (0x00007fd8036f9000) https://github.</description></item><item><title>docker 的 MountFlags=slave 与 live-restore 冲突问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/docker-%E7%9A%84-MountFlagsslave-%E4%B8%8E-live-restore-%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/docker-%E7%9A%84-MountFlagsslave-%E4%B8%8E-live-restore-%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/</guid><description>Pod 一直停留在 Terminating 状态，我等得花儿都谢了~
1.背景 近期，弹性云线上集群发生了几起特殊的容器漂移失败事件，其特殊之处在于容器处于 Pod Terminating 状态，而宿主则处于 Ready 状态。
宿主状态为 Ready 说明其能够正常处理 Pod 事件，但是 Pod 却卡在了退出阶段，说明此问题并非由 kubelet 引起，那么 docker 就是 1 号犯罪嫌疑人了。
下文将详细介绍问题的排查与分析全过程。
2.抽丝剥茧 Pod 状态如下：
[stupig@master ~]$ kubectl get pod -owide pod-976a0-5 0/1 Terminating 0 112m 尽管 kubelet 的犯罪嫌疑已经很小，但是我们还是需要排查 kubelet 日志进一步确认。截取 kubelet 关键日志片段如下：
I1014 10:56:46.492682 34976 kubelet_pods.go:1017] Pod &amp;#34;pod-976a0-5_default(f1e03a3d-0dc7-11eb-b4b1-246e967c4efc)&amp;#34; is terminated, but some containers have not been cleaned up: {ID:{Type:docker ID:41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef} Name:stupig State:exited CreatedAt:2020-10-14 10:49:57.859913657 +0800 CST StartedAt:2020-10-14 10:49:57.</description></item><item><title>Docker 获取 parent 逻辑</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%8E%B7%E5%8F%96-parent-%E9%80%BB%E8%BE%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%8E%B7%E5%8F%96-parent-%E9%80%BB%E8%BE%91/</guid><description>每次 kubelet 获取镜像列表时，docker 都会获取一遍镜像的 parent 具体逻辑在这里 image/store.go</description></item><item><title>Docker 资源泄露系列</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%B5%84%E6%BA%90%E6%B3%84%E9%9C%B2%E7%B3%BB%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%B5%84%E6%BA%90%E6%B3%84%E9%9C%B2%E7%B3%BB%E5%88%97/</guid><description>原文连接：
博客
微信公众号</description></item><item><title>内核4.18版本以下导致slab内存过高问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%86%85%E6%A0%B84.18%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8B%E5%AF%BC%E8%87%B4slab%E5%86%85%E5%AD%98%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%86%85%E6%A0%B84.18%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8B%E5%AF%BC%E8%87%B4slab%E5%86%85%E5%AD%98%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98/</guid><description>参考：原文链接
问题背景 客户的 k8s 集群环境，发现所有的 worker 节点的 kubelet 进程的 CPU 使用率长时间占用过高，通过 pidstat 可以看到 CPU 使用率高达 100%。针对此问题对 kubelet 进程的异常进行问题排查。
集群环境 软件 版本 kubernetes v1.18.8 docker 18.09.9 rancher v2.4.8-ent CentOS 7.6 kernel 4.4.227-1.el7.elrepo.x86_64 排查过程 使用 strace 工具对 kubelet 进程进行跟踪 由于 kubelet 进程 CPU 使用率异常，可以使用 strace 工具对 kubelet 进程动态跟踪进程的调用情况，首先使用strace -cp &amp;lt;PID&amp;gt;命令统计 kubelet 进程在某段时间内的每个系统调用的时间、调用和错误情况. 从上图可以看到，执行系统调用过程中，futex 抛出了五千多个 errors，这肯定是不正常的，而且这个函数占用的时间也达到了 99%，所以需要更深层次的查看 kubelet 进程相关的调用。
由于strace -cp命令只能查看进程的整体调用情况，所以我们可以通过strace -tt -p &amp;lt;PID&amp;gt;命令打印每个系统调用的时间戳，如下： 从 strace 输出的结果来看，在执行 futex 相关的系统调用时，有大量的 Connect timed out，并返回了-1 和ETIMEDOUT的 error，所以才会在strace -cp中看到了那么多的 error。</description></item></channel></rss>