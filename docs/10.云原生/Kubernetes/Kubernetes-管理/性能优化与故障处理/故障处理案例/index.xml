<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>故障处理案例 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</link><description>Recent content in 故障处理案例 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>BUG</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/BUG/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/BUG/</guid><description>概述 参考：
已修复 orphaned pod &amp;ldquo;XX&amp;rdquo; found, but volume paths are still present on disk 问题跟踪：issue #60987
kubelet 执行逻辑：https://github.com/kubernetes/kubernetes/blob/release-1.19/pkg/kubelet/kubelet_volumes.go#L173
解决方式：
更新至 1.19.8 版本及以上，ChangeLog 中提到，在 #95301 Merged 中已解决 未更新的话，通过 ali 提供的脚本，进行一些修改，该脚本会手动 umount 和 rm 目录 aggregator_unavailable_apiservice 问题描述：聚合 API 删除之后，依然存在于 kube-apiserver 的 metrics 中，这会导致频繁告警
跟踪连接：https://github.com/kubernetes/kubernetes/issues/92671
解决方式：https://github.com/kubernetes/kubernetes/pull/96421
将在 1.20 版本解决
Scope libcontainer-21733-systemd-test-default-dependencies.scope has no PIDs. Refusing 问题跟踪：https://github.com/kubernetes/kubernetes/issues/71887
解决方式：（1.16 及以后的版本中，无该问题。主要是 18+版本 docker 无该问题）
忽略该告警：https://www-01.ibm.com/support &amp;hellip; .wss?uid=ibm10883724
Error while processing event (&amp;quot;/sys/fs/cgroup/devices/libcontainer_2434_systemd_test_default.slice&amp;quot;: 0x40000100 == IN_CREATE|IN_ISDIR): open /sys/fs/cgroup/devices/libcontainer_2434_systemd_test_default.</description></item><item><title>kubernetes 环境开启 bridge-nf-call-iptables</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubernetes-%E7%8E%AF%E5%A2%83%E5%BC%80%E5%90%AF-bridge-nf-call-iptables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubernetes-%E7%8E%AF%E5%A2%83%E5%BC%80%E5%90%AF-bridge-nf-call-iptables/</guid><description>概述 参考：
原文,公众号,为什么 kubernetes 环境要求开启 bridge-nf-call-iptables ? 背景 Kubernetes 环境中，很多时候都要求节点内核参数开启 bridge-nf-call-iptables:
sysctl -w net.bridge.bridge-nf-call-iptables=1 参考官方文档 Network Plugin Requirements
如果不开启或中途因某些操作导致参数被关闭了，就可能造成一些奇奇怪怪的网络问题，排查起来非常麻烦。
为什么要开启呢？本文就来跟你详细掰扯下。
基于网桥的容器网络 Kubernetes 集群网络有很多种实现，有很大一部分都用到了 Linux 网桥:
每个 Pod 的网卡都是 veth 设备，veth pair 的另一端连上宿主机上的网桥。 由于网桥是虚拟的二层设备，同节点的 Pod 之间通信直接走二层转发，跨节点通信才会经过宿主机 eth0。 Service 同节点通信问题 不管是 iptables 还是 ipvs 转发模式，Kubernetes 中访问 Service 都会进行 DNAT，将原本访问 ClusterIP:Port 的数据包 DNAT 成 Service 的某个 Endpoint (PodIP:Port)，然后内核将连接信息插入 conntrack 表以记录连接，目的端回包的时候内核从 conntrack 表匹配连接并反向 NAT，这样原路返回形成一个完整的连接链路:
但是 Linux 网桥是一个虚拟的二层转发设备，而 iptables conntrack 是在三层上，所以如果直接访问同一网桥内的地址，就会直接走二层转发，不经过 conntrack:
Pod 访问 Service，目的 IP 是 Cluster IP，不是网桥内的地址，走三层转发，会被 DNAT 成 PodIP:Port。 如果 DNAT 后是转发到了同节点上的 Pod，目的 Pod 回包时发现目的 IP 在同一网桥上，就直接走二层转发了，没有调用 conntrack，导致回包时没有原路返回 (见下图)。 由于没有原路返回，客户端与服务端的通信就不在一个 &amp;ldquo;频道&amp;rdquo; 上，不认为处在同一个连接，也就无法正常通信。</description></item><item><title>故障处理案例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description>概述 参考：
OpenAI 新部署的遥测服务在大规模集群中产生了大量 API 调用导致控制平面过载，让 CoreDNS 服务不可用导致集群内部交互出现问题 https://status.openai.com/incidents/ctrsv3lwd797
公众号 -k8s技术圈，OpenAI 严重生产故障复盘，这次真的是 Kubernetes 的锅～ 案例列表 公众号 - 云原生实验室，JVM 内存与 K8s 容器内存不一致引发的 OOMKilled 总结
公众号 - 云原生运维，从崩溃到防御：一个 emptyDir 引发的「蝴蝶效应」
nfs 相关 K8S 中与 NFS 相关的故障通常为 Node 没有安装 nfs 客户端。还有不太常见的版本问题（在 storageclass 中添加 mountOptions 字段指定 nfs 版本即可）。
张馆长，k8s 使用 nfs 下 pod 无法创建的解决思路
kube-proxy 无法绑定 NodePort 端口 故障现象 参考：
其他有相同现象的人： 馆长 ieevee kube-proxy 日志报错：
root@desistdaydream:~# kubectl logs -n kube-system kube-proxy-4thfl | more E0507 06:05:09.</description></item><item><title>Kubernetes 网络疑难杂症排查分享</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/Kubernetes-%E7%BD%91%E7%BB%9C%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E6%8E%92%E6%9F%A5%E5%88%86%E4%BA%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/Kubernetes-%E7%BD%91%E7%BB%9C%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E6%8E%92%E6%9F%A5%E5%88%86%E4%BA%AB/</guid><description>原文链接：https://zhuanlan.zhihu.com/p/77808615
大家好，我是 roc，来自腾讯云容器服务(TKE)团队，经常帮助用户解决各种 K8S 的疑难杂症，积累了比较丰富的经验，本文分享几个比较复杂的网络方面的问题排查和解决思路，深入分析并展开相关知识，信息量巨大，相关经验不足的同学可能需要细细品味才能消化，我建议收藏本文反复研读，当完全看懂后我相信你的功底会更加扎实，解决问题的能力会大大提升。 本文发现的问题是在使用 TKE 时遇到的，不同厂商的网络环境可能不一样，文中会对不同的问题的网络环境进行说明
跨 VPC 访问 NodePort 经常超时 现象: 从 VPC a 访问 VPC b 的 TKE 集群的某个节点的 NodePort，有时候正常，有时候会卡住直到超时。 原因怎么查？
当然是先抓包看看啦，抓 server 端 NodePort 的包，发现异常时 server 能收到 SYN，但没响应 ACK: 反复执行 netstat -s | grep LISTEN 发现 SYN 被丢弃数量不断增加: 分析：
两个 VPC 之间使用对等连接打通的，CVM 之间通信应该就跟在一个内网一样可以互通。 为什么同一 VPC 下访问没问题，跨 VPC 有问题? 两者访问的区别是什么? 再仔细看下 client 所在环境，发现 client 是 VPC a 的 TKE 集群节点，捋一下:
client 在 VPC a 的 TKE 集群的节点 server 在 VPC b 的 TKE 集群的节点 因为 TKE 集群中有个叫 ip-masq-agent 的 daemonset，它会给 node 写 iptables 规则，默认 SNAT 目的 IP 是 VPC 之外的报文，所以 client 访问 server 会做 SNAT，也就是这里跨 VPC 相比同 VPC 访问 NodePort 多了一次 SNAT，如果是因为多了一次 SNAT 导致的这个问题，直觉告诉我这个应该跟内核参数有关，因为是 server 收到包没回包，所以应该是 server 所在 node 的内核参数问题，对比这个 node 和 普通 TKE node 的默认内核参数，发现这个 node net.</description></item><item><title>常见问题排查与解决方案</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid><description>原文链接：https://mp.weixin.qq.com/s/URU5jz8oFi-jQhWR4snGWQ https://kubesphere.com.cn/forum/d/5152-kubernetes
XXX:10250 connect: no route to host 网络问题，API Server 与 Kubelet 通信失败，将会导致很多很多问题
CRD spec.versions: Invalid value 原因: CRD yaml 文件中 apiVersion 与 versions 中的版本不对应 参考: https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/
删除 namespaces 时 Terminating，无法强制删除且无法在该 ns 下创建对象 原因: ns 处于 terminating 时 hang 住了，使用 &amp;ndash;grace-period=0 &amp;ndash;force 强制删除也无效 解决: # 导出 K8s 访问密钥 echo $(kubectl config view &amp;ndash;raw -oyaml | grep client-cert |cut -d &amp;rsquo; &amp;rsquo; -f 6) |base64 -d &amp;gt; /tmp/client.pem echo $(kubectl config view &amp;ndash;raw -oyaml | grep client-key-data |cut -d &amp;rsquo; &amp;rsquo; -f 6 ) |base64 -d &amp;gt; /tmp/client-key.</description></item><item><title>当master丢失一个节点后，如何恢复</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%BD%93master%E4%B8%A2%E5%A4%B1%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E5%90%8E%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%BD%93master%E4%B8%A2%E5%A4%B1%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E5%90%8E%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/</guid><description>故障现象 在日常维护中，如果三台 master 节点的其中一个节点故障，并不可恢复，我们如何重新建建立一个 master 节点并重新加入进去呢？
假设曾经有三个节点
master-1.tj-test master-2.tj-test master-3.tj-test 其中一个节点丢失后，想要新建一个节点并重新加入集群，但是失败了
故障排查 当 master-3 挂掉并不可恢复时，首先需要通过 kubectl delete node master-3.tj-test 命令来删除该节点。然后使用一台新的设备初始化环境，并通过 kubeadm join 命令来加入集群，但是这时候，加入集群是失败的。
因为虽然使用命令删除了 master-3 节点，但是 etcd 集群的 master-3 这个 member 还存在
~]# etcdv3 member list 13b7460f0eebe6ea, started, master-1.tj-test, https://172.38.40.212:2380, https://172.38.40.212:2379 fdddf32d7b4d4498, started, master-3.tj-test, https://172.38.40.214:2380, https://172.38.40.214:2379 fed9f57af62ba6a0, started, master-2.tj-test, https://172.38.40.213:2380, https://172.38.40.213:2379 故障处理 这时候需要通过 etcdctl 命令 etcdv3 member remove fdddf32d7b4d4498 将该 member 移除，再重新让 master-3 加入集群，就可以了。</description></item><item><title>记一次 K8S 内部服务调用域名解析超时排坑经历</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E8%AE%B0%E4%B8%80%E6%AC%A1-K8S-%E5%86%85%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E8%B6%85%E6%97%B6%E6%8E%92%E5%9D%91%E7%BB%8F%E5%8E%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E8%AE%B0%E4%B8%80%E6%AC%A1-K8S-%E5%86%85%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E8%B6%85%E6%97%B6%E6%8E%92%E5%9D%91%E7%BB%8F%E5%8E%86/</guid><description>原文连接：https://juejin.im/post/6844904178582552590
记一次 K8S 内部服务调用域名解析超时排坑经历
前言 近期线上 k8s 时不时就会出现一些内部服务间的调用超时问题，通过日志可以得知超时的原因都是出现在域名解析上，并且都是 k8s 内部的域名解析超时，于是直接先将内部域名替换成 k8s service 的 IP，观察一段时间发现没有超时的情况发生了，但是由于使用 service IP 不是长久之计，所以还要去找解决办法。
复现 一开始运维同事在调用方 pod 中使用ab工具对目标服务进行了多次压测，并没有发现有超时的请求，我介入之后分析ab这类 http 压测工具应该都会有 dns 缓存，而我们主要是要测试 dns 服务的性能，于是直接动手撸了一个压测工具只做域名解析，代码如下：
package main import ( &amp;#34;context&amp;#34; &amp;#34;flag&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;net&amp;#34; &amp;#34;sync/atomic&amp;#34; &amp;#34;time&amp;#34; ) var host string var connections int var duration int64 var limit int64 var timeoutCount int64 func main() { // os.Args = append(os.Args, &amp;#34;-host&amp;#34;, &amp;#34;www.baidu.com&amp;#34;, &amp;#34;-c&amp;#34;, &amp;#34;200&amp;#34;, &amp;#34;-d&amp;#34;, &amp;#34;30&amp;#34;, &amp;#34;-l&amp;#34;, &amp;#34;5000&amp;#34;) flag.StringVar(&amp;amp;host, &amp;#34;host&amp;#34;, &amp;#34;&amp;#34;, &amp;#34;Resolve host&amp;#34;) flag.</description></item></channel></rss>