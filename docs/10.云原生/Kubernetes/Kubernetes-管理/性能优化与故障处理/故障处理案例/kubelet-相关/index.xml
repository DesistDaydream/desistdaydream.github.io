<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kubelet 相关 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/</link><description>Recent content in kubelet 相关 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/index.xml" rel="self" type="application/rss+xml"/><item><title>Failed to get system container stats、failed to get cgroup stats</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/Failed-to-get-system-container-statsfailed-to-get-cgroup-stats/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/Failed-to-get-system-container-statsfailed-to-get-cgroup-stats/</guid><description>Failed to get system container stats for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: failed to get cgroup stats for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: failed to get cgroup stats for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: failed to get container info for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: unknown container &amp;ldquo;/system.slice/docker.service&amp;rdquo;
参考：Stackoverflow
这个问题大概就是因为 kubelet 在 docker 之前就启动了。</description></item><item><title>容器重启原理-Kubelet hash计算</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/%E5%AE%B9%E5%99%A8%E9%87%8D%E5%90%AF%E5%8E%9F%E7%90%86-Kubelet-hash%E8%AE%A1%E7%AE%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/%E5%AE%B9%E5%99%A8%E9%87%8D%E5%90%AF%E5%8E%9F%E7%90%86-Kubelet-hash%E8%AE%A1%E7%AE%97/</guid><description>原文链接：https://mp.weixin.qq.com/s/8Txf6naaWaetTr2-sGyptg
在日常的开发工作中相信使用 Kubernetes 的同学们一定会偶尔收到容器重启的事件告警。由于应用层面的问题导致的容器重启相对容易排查，比如看容器的内存监控我们能确定是不是内存超过配置的 limit; 又或者看是不是应用有 panic 没有 recovery。 一个正常的工作日我们突然连续收到多条容器重启告警，查看报警还是来自不同的应用。按照一般的排查思路先去查看监控，内存没有异常，使用值一直在 limit 之下；然后去看日志也没有找到任何 panic 或者其他错误。仔细一看这几个告警的应用都是来自同一个集群，这个时候猜测大概率和集群有关系，但是这个集群我们还有其他很多应用并没有发生容器重启，所以猜测应该不是集群本身的问题，那是不是和机器有关系呢？然后我把重启过的实例所在的 node ip 都筛选出来发现重启的应用都是集中在某几台机器。在这些节点上我去查看了一下 kubelet进程，发现 kubelet 在容器告警的时间段都重启了进程。在这种情况下基本就找到了容器重启的直接原因&amp;ndash;kubelet 重启了。但是我们并没有更新实例，kubelet 重启怎么会把我们的容器重启呢？下面我们就介绍一下根本原因&amp;ndash;kubelet计算容器的 hash 值。 我们知道在 Kubernetes 中的节点上运行着 kubelet 进程，这个进程负责当前节点上所有 Pod 的生命周期。在这里我们从源码层面看看 kubelet 怎么实现容器的重启。
SyncPod 我们首先看 [https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/kuberuntime_manager.go](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/kuberuntime_manager.go) 中的 SyncPod 方法, 这个方法就是保证运行中的 Pod 与我们期望的配置时刻保持一致。通过以下步骤完成
根据从 API Server 获得的 Pod Spec 以及当前 Pod 的 Status 计算所需要执行的 Actions 在需要情况下 Kill 掉当前 Pod 的 sandbox 根据需要（如重启）kill 掉 Pod 内的 containers 根据需要创建 Pod 的 sandbox 启动下一个 init container 启动 Pod 内的 containers func (m *kubeGenericRuntimeManager) SyncPod(pod *v1.</description></item></channel></rss>