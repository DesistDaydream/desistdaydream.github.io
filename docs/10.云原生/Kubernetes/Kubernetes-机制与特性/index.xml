<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes 机制与特性 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/</link><description>Recent content in Kubernetes 机制与特性 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/index.xml" rel="self" type="application/rss+xml"/><item><title>Pod 是如何出现的</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Pod-%E6%98%AF%E5%A6%82%E4%BD%95%E5%87%BA%E7%8E%B0%E7%9A%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Pod-%E6%98%AF%E5%A6%82%E4%BD%95%E5%87%BA%E7%8E%B0%E7%9A%84/</guid><description>概述 参考：
公众号 - 程序员白日梦，一文讲明白-K8S各核心架构组件 https://www.cnblogs.com/ZhuChangwu/p/16441181.html Pod 出现流程中的 Watch 机制的应用 通过 kubectl 命名发起请求。 apiserver 通过对应的 kubeconfig 进行认证，认证通过后将 yaml 中的 pod 信息存到 etcd。 Controller-Manager 通过 apiserver 的 Watch 接口发现了pod信息的更新，执行该资源所依赖的拓扑结构整合，整合后将对应的信息交给 apiserver，apiserver 写到 etcd。 Scheduler 同样通过 apiserver 的 watch 接口更新到 pod 可以被调度，通过算法给 pod 分配节点，并将 pod 和对应节点绑定的信息交给 apiserver，apiserver 写到 etcd。 kubelet 从 apiserver 获取需要创建的 pod 信息，调用 CNI 接口给 pod 创建 pod 网络，调用 CRI 接口去启动容器，调用 CSI 进行存储卷的挂载。 网络，容器，存储创建完成后 pod 创建完成，等业务进程启动后，pod 运行成功。 输入 kubectl run 时会发生什么? 参考:</description></item><item><title>Watch and Informer</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Watch-and-Informer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Watch-and-Informer/</guid><description>概述 参考：
官方文档，参考 - API 概述 - Kubernetes API 概念, 高效监测变化 K8s list-watch 机制和 Informer 模块 Reflector
在 Kubernetes 中，有5个主要的组件，分别是 master 节点上的 kube-api-server、kube-controller-manager 和 kube-scheduler，node 节点上的 kubelet 和kube-proxy 。这其中 kube-apiserver 是对外和对内提供资源的声明式 API 的组件，其它4个组件都需要和它交互。为了保证消息的实时性，有两种方式：
客户端组件 (kubelet, scheduler, controller-manager 等) 轮询 apiserver apiserver 通知客户端 为了降低 kube-apiserver 的压力，有一个非常关键的机制就是 list-watch。list-watch 本质上也是 client 端监听 k8s 资源变化并作出相应处理的生产者消费者框架
list-watach 机制需要满足以下需求：
实时性 (即数据变化时，相关组件越快感知越好) 保证消息的顺序性 (即消息要按发生先后顺序送达目的组件。很难想象在Pod创建消息前收到该Pod删除消息时组件应该怎么处理) 保证消息不丢失或者有可靠的重新获取机制 (比如 kubelet 和 kube-apiserver 间网络闪断，需要保证网络恢复后kubelet可以收到网络闪断期间产生的消息) list-watch 机制 list-watch 由两部分组成，分别是 list 和 watch。list 非常好理解，就是调用资源的 list API 罗列资源 ，基于 HTTP 短链接实现，watch 则是调用资源的 watch API 监听资源变更事件，基于 HTTP 长链接实现</description></item><item><title>Leader Election(领导人选举)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Leader-Election%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Leader-Election%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE/</guid><description>概述 参考：
官方博客, Kubernetes 的简单领导人选举 zhengyinyong 用法： 公众号-云原生实验室，巧用 Kubernetes 中的 Leader 选举机制来实现自己的 HA 应用 为什么需要 Pod 之间的 Leader Election 一般来说，由 Deployment 创建的 1 个或多个 Pod 都是对等关系，彼此之间提供一样的服务。但是在某些场合，多个 Pod 之间需要有一个 Leader 的角色，即：
Pod 之间有且只有一个 Leader； Leader 在一定周期不可用时，其他 Pod 会再选出一个 Leader； 由处于 Leader 身份的 Pod 来完成某些特殊的业务逻辑（通常是写操作）； 比如，当多个 Pod 之间只需要一个写者时，如果不采用 Leader Election，那么就必须在 Pod 启动之初人为地配置一个 Leader。如果配置的 Leader 在后续的服务中失效且没有对应机制来生成新的 Leader，那么对应 Pod 服务就可能处于不可用状态，违背高可用原则。
典型地，Kubernetes 的核心组件 kube-controller-manager 和 scheduler 就需要一个需要 Leader 的场景。当 kube-controller-manager 的启动参数设置 --leader-elect=true 时，对应节点的 kube-controller-manager 在启动时会执行选主操作。当选出一个 Leader 之后，由 Leader 来启动所有的控制器。如果 Leader Pod 不可用，将会自动选出新的 Leader Pod，从而保障控制器仍处于运行状态。</description></item></channel></rss>