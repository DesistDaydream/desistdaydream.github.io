<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 9.Kubernetes 存储</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/</link><description>Recent content in 9.Kubernetes 存储 on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 9.Kubernetes 存储</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/9.Kubernetes-%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/9.Kubernetes-%E5%AD%98%E5%82%A8/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/storage/">官方文档,概念-存储&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/hNR5XkMeZbDVInUOX_5MAg">公众号-CNCF，卷扩展现在是个稳定特性&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/EBghRVRQvnPSTf4YdCkp2w">公众号-CNCF，存储容量跟踪在 Kubernetes1.24 中正式 GA&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>在 Container 中的文件在磁盘上是临时存储的(这与 Docker 一样，容器删除后，容器内的文件也随着删除)，这给 Container 中运行的需要持久化存储的应用程序带来了很多问题。&lt;/p>
&lt;ul>
&lt;li>第一，当 Container 崩溃时，kubelet 会重启它，但是文件都将丢失并且 Container 以最干净的状态启动&lt;/li>
&lt;li>第二，当在 Pod 中运行多个 Container 的时候，这些 Container 需要共享文件以实现功能。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Volume(卷)&lt;/strong> 就是为了解决上面两种情况出现的。&lt;/p>
&lt;p>从本质上讲，Volume(卷) 只是一个包含一些数据目录，Pod 中 Container 可以访问这个目录。至于该目录是如何形成的是由所使用的 Volume 类型决定的。这个 Volume 的类型可以是：host 的内存，host 的文件，host 的目录，nfs、glusterfs、甚至是云厂商所提供的各种类型的存储&lt;/p>
&lt;p>&lt;strong>可以说，Kubernetes 存储功能的基础，就是 Volume(卷)。&lt;/strong>&lt;/p>
&lt;p>Volume 功能详解见 &lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes%20%E5%AD%98%E5%82%A8/Volume/Volume.md">Volume&lt;/a> 章节&lt;/p>
&lt;h2 id="与-docker-中的-volume-的概念比较">与 Docker 中的 Volume 的概念比较&lt;/h2>
&lt;p>Kubernetse 为什么不直接复用 Docker 中的 Volume，而是要自己实现呢?~&lt;/p>
&lt;p>Kubernetes Volume 和 Docker Volume 概念相似，但是又有不同的地方，Kubernetes Volume 与 Pod 的生命周期相同，但与容器的生命周期不相关。当容器终止或重启时，Volume 中的数据也不会丢失。当 Pod 被删除时，Volume 才会被清理。并且数据是否丢失取决于 Volume 的具体类型，比如 emptyDir 类型的 Volume 数据会丢失，而持久化类型的数据则不会丢失。另外 Kubernetes 提供了将近 20 种 Volume 类型。&lt;/p>
&lt;h1 id="volume-的实现-volume-plugins卷插件">Volume 的实现-Volume Plugins(卷插件)&lt;/h1>
&lt;p>&lt;strong>Volume Plugins(卷插件)&lt;/strong> 是实现 Kubernetes 存储功能的方式。说白了，&lt;strong>Volume Plugins 就是用来实现 Volume 功能的&lt;/strong>。一共可以分为两类：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>In-Tree(树内)&lt;/strong> # 代码逻辑在 K8S 官方仓库中；表示源码是放在 Kubernetes 内部的(常见的 NFS、cephfs 等)，和 Kubernetes 一起发布、管理与迭代，缺点是迭代速度慢、灵活性差；&lt;/li>
&lt;li>&lt;strong>Out-of-Tree(树外)&lt;/strong> # 代码逻辑在 K8s 官方仓库之外，实现与 K8s 代码的解耦；表示代码独立于 Kubernetes，它是由存储提供商实现的，目前主要有 &lt;strong>Flexvolume&lt;/strong> 或 &lt;strong>CSI&lt;/strong> 两种实现机制，可以根据存储类型实现不同的存储插件&lt;/li>
&lt;/ul>
&lt;h2 id="in-tree树内">In-Tree(树内)&lt;/h2>
&lt;p>&lt;strong>In-Tree 类型的卷插件的代码 与 Kubernetes 代码 在一起&lt;/strong>。比如 emptyDir、hostPath、ConfigMap、PVC 等等类型的 Volume，凡是在&lt;a href="https://kubernetes.io/docs/concepts/storage/volumes/">官方文档的卷类型&lt;/a>中的都属于 In-Tree 类型的卷插件。所以 卷插件类型 也可以说是 卷类型。&lt;/p>
&lt;h2 id="out-of-tree树外">Out-of-Tree(树外)&lt;/h2>
&lt;p>&lt;strong>OUt-of-Tree 类型的卷插件代码 与 Kubernetes 代码 不在一起&lt;/strong>。这种类型的插件，可以让存储供应商创建自定义的存储插件而无需将他们添加到 Kubernetes 代码仓库。&lt;/p>
&lt;p>这类卷插件的实现方式分两位 &lt;strong>CSI&lt;/strong> 和 &lt;strong>FlexVolume&lt;/strong> 两类。都允许独立于 Kubernetes 代码库开发卷插件，并作为 Pod 部署在 Kubernetes 集群中。&lt;/p>
&lt;h3 id="csi--container-storage-interface容器存储接口">CSI # Container Storage Interface(容器存储接口)&lt;/h3>
&lt;p>CSI 为容器编排系统定义标准规范，以将任意存储系统暴露给它们的容器。&lt;/p>
&lt;p>详见 &lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes%20%E5%AD%98%E5%82%A8/CSI/CSI.md">CSI&lt;/a>&lt;/p>
&lt;h3 id="flexvolume">FlexVolume&lt;/h3>
&lt;p>FlexVolume 是一个自 1.2 版本（在 CSI 之前）以来在 Kubernetes 中一直存在的树外插件接口。 它使用基于 exec 的模型来与驱动程序对接。 用户必须在每个节点（在某些情况下是主控节点）上的预定义卷插件路径中安装 FlexVolume 驱动程序可执行文件。
Pod 通过 &lt;code>flexvolume&lt;/code> 树内插件与 Flexvolume 驱动程序交互。 更多详情请参考 &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md">FlexVolume&lt;/a> 示例。&lt;/p>
&lt;h2 id="in-tree-向-csi-迁移">In-Tree 向 CSI 迁移&lt;/h2>
&lt;p>从 Kubernetes &lt;a href="https://kubernetes.io/zh-cn/blog/2021/12/10/storage-in-tree-to-csi-migration-status-update/">2021 年 12 月 10 日的博客&lt;/a>中报告了迁移工作的进展。从这里可以看到，Kubernetes 官方希望我们无论使用那哪种 In-Tree 模型的卷插件，都尽早迁移至使用 CSI 驱动的模型。&lt;/p>
&lt;p>容器存储接口旨在帮助 Kubernetes 取代其现有的树内存储驱动机制 ── 特别是供应商的特定插件。自 v1.13 起，Kubernetes 对&lt;a href="https://github.com/container-storage-interface/spec/blob/master/spec.md#README">容器存储接口&lt;/a>的支持工作已达到&lt;a href="https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/">正式发布阶段&lt;/a>。引入对 CSI 驱动的支持，将使得 Kubernetes 和存储后端技术之间的集成工作更易建立和维护。使用 CSI 驱动可以实现更好的可维护性（驱动作者可以决定自己的发布周期和支持生命周期）、减少出现漏洞的机会（得益于更少的树内代码，出现错误的风险会降低。另外，集群操作员可以只选择集群需要的存储驱动）。&lt;/p>
&lt;p>随着更多的 CSI 驱动诞生并进入生产就绪阶段，Kubernetes 存储特别兴趣组希望所有 Kubernetes 用户都能从 CSI 模型中受益 ── 然而，我们不应破坏与现有存储 API 类型的 API 兼容性。对此，我们给出的解决方案是 CSI 迁移：该功能实现将树内存储 API 翻译成等效的 CSI API，并把操作委托给一个替换的 CSI 驱动来完成。&lt;/p>
&lt;p>CSI 迁移工作使存储后端现有的树内存储插件（如 kubernetes.io/gce-pd 或 kubernetes.io/aws-ebs）能够被相应的 &lt;a href="https://kubernetes-csi.github.io/docs/introduction.html">CSI 驱动&lt;/a> 所取代。如果 CSI 迁移功能正确发挥作用，Kubernetes 终端用户应该不会注意到有什么变化。现有的 StorageClass、PersistentVolume 和 PersistentVolumeClaim 对象应继续工作。当 Kubernetes 集群管理员更新集群以启用 CSI 迁移功能时，利用到 PVCs&lt;a href="https://kubernetes.io/zh-cn/blog/2021/12/10/storage-in-tree-to-csi-migration-status-update/#fn:1">1&lt;/a>（由树内存储插件支持）的现有工作负载将继续像以前一样运作 ── 不过在幕后，Kubernetes 将所有存储管理操作（以前面向树内存储驱动的）交给 CSI 驱动控制。&lt;/p>
&lt;p>举个例子。假设你是 kubernetes.io/gce-pd 用户，在启用 CSI 迁移功能后，你仍然可以使用 kubernetes.io/gce-pd 来配置新卷、挂载现有的 GCE-PD 卷或删除现有卷。所有现有的 API/接口 仍将正常工作 ── 只不过，底层功能调用都将通向 &lt;a href="https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver">GCE PD CSI 驱动&lt;/a>，而不是 Kubernetes 的树内存储功能。&lt;/p>
&lt;p>不过，这里面没提到那些 Kubernetes 内置资源类型的卷，比如 ConfigMap、Secret、等等。人们主要需要迁移的是那些类似 glusterfs、cephfs 之类第三方的 In-Tree 类型的卷插件。&lt;/p>
&lt;p>迁移进展文章&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/6nhv2zQIAOAfUJ661YmDsQ">https://mp.weixin.qq.com/s/6nhv2zQIAOAfUJ661YmDsQ&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="kubernetes-存储模型">Kubernetes 存储模型&lt;/h1>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/aplkpr/1616117503767-42e19ed6-fbd6-4b5b-bc38-db7e7a699432.jpeg" alt="">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Volume Controller&lt;/strong> # K8S 的卷控制器。&lt;a href="https://github.com/kubernetes/kubernetes/tree/master/pkg/controller/volume">代码位置&lt;/a>
&lt;ul>
&lt;li>&lt;strong>PV Controller&lt;/strong> # 负责 PV/PVC 的绑定、生命周期管理，并根据需求进行数据卷的 &lt;strong>Provision/Delete&lt;/strong> 操作。&lt;a href="https://github.com/kubernetes/kubernetes/tree/master/pkg/controller/volume/persistentvolume">代码位置&lt;/a>&lt;/li>
&lt;li>&lt;strong>AD Controller&lt;/strong> # 负责存储设备的 &lt;strong>Attach/Detach&lt;/strong> 操作，将设备挂载到目标节点。&lt;a href="https://github.com/kubernetes/kubernetes/tree/master/pkg/controller/volume/attachdetach">代码位置&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Kubelet&lt;/strong> # Kubelet 是在每个 Node 节点上运行的主要 “节点代理”，功能是 Pod 生命周期管理、容器健康检查、容器监控等；
&lt;ul>
&lt;li>&lt;strong>Volume Manager&lt;/strong> # 属于 kubelet 中的组件，管理卷的 &lt;strong>Mount/Unmount&lt;/strong> 操作、卷设备的格式化的操作.
&lt;ul>
&lt;li>注意：Volume Manager 也可以负责数据卷的 &lt;strong>Attach/Detach&lt;/strong> 操作，需要配置 kubelet 开启特性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Volume Plugins&lt;/strong> # 它主要是对上面所有挂载功能的实现。PV Controller、AD Controller、Volume Manager 主要是进行操作的调用，而具体操作则是由 Volume Plugins 实现的。根据源码的位置可将 Volume Plugins 分为 In-Tree 和 Out-of-Tree 两类
&lt;ul>
&lt;li>In-Tree # 与 Kubernetes 代码强耦合的卷插件&lt;/li>
&lt;li>Out-of-Tree # 与 Kubernetes 代码无关的卷插件。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Scheduler&lt;/strong> # 实现对 Pod 的调度能力，会根据一些存储相关的的定义去做存储相关的调度&lt;/li>
&lt;li>其他
&lt;ul>
&lt;li>&lt;strong>External Provioner：&lt;/strong> External Provioner 是一种 sidecar 容器，作用是调用 Volume Plugins 中的 CreateVolume 和 DeleteVolume 函数来执行 &lt;strong>Provision/Delet&lt;/strong>e 操作。因为 K8s 的 PV 控制器无法直接调用 Volume Plugins 的相关函数，故由 External Provioner 通过 gRPC 来调用&lt;/li>
&lt;li>&lt;strong>External Attacher：&lt;/strong> External Attacher 是一种 sidecar 容器，作用是调用 Volume Plugins 中的 ControllerPublishVolume 和 ControllerUnpublishVolume 函数来执行 &lt;strong>Attach/Detach&lt;/strong> 操作。因为 K8s 的 AD 控制器无法直接调用 Volume Plugins 的相关函数，故由 External Attacher 通过 gRPC 来调用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: 持久化存储流程</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/jpopq16BOA_vrnLmejwEdQ">公众号，一文读懂 K8s 持久化存储流程&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="k8s-持久化存储基础">K8S 持久化存储基础&lt;/h1>
&lt;p>在进行 K8s 存储流程讲解之前，先回顾一下 K8s 中持久化存储的基础概念。&lt;/p>
&lt;h2 id="1-名词解释">1. 名词解释&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>in-tree：&lt;/strong> 代码逻辑在 K8s 官方仓库中；&lt;/li>
&lt;li>&lt;strong>out-of-tree：&lt;/strong> 代码逻辑在 K8s 官方仓库之外，实现与 K8s 代码的解耦；&lt;/li>
&lt;li>&lt;strong>PV：&lt;/strong> PersistentVolume，集群级别的资源，由 集群管理员 or External Provisioner 创建。PV 的生命周期独立于使用 PV 的 Pod，PV 的 .Spec 中保存了存储设备的详细信息；&lt;/li>
&lt;li>&lt;strong>PVC：&lt;/strong> PersistentVolumeClaim，命名空间（namespace）级别的资源，由 用户 or StatefulSet 控制器（根据VolumeClaimTemplate） 创建。PVC 类似于 Pod，Pod 消耗 Node 资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存），而 PVC 可以请求特定存储卷的大小及访问模式（Access Mode）；&lt;/li>
&lt;li>&lt;strong>StorageClass：&lt;/strong> StorageClass 是集群级别的资源，由集群管理员创建。SC 为管理员提供了一种动态提供存储卷的“类”模板，SC 中的 .Spec 中详细定义了存储卷 PV 的不同服务质量级别、备份策略等等；&lt;/li>
&lt;li>&lt;strong>CSI：&lt;/strong> Container Storage Interface，目的是定义行业标准的“容器存储接口”，使存储供应商（SP）基于 CSI 标准开发的插件可以在不同容器编排（CO）系统中工作，CO 系统包括 Kubernetes、Mesos、Swarm 等。&lt;/li>
&lt;/ul>
&lt;h2 id="2-组件介绍">2. 组件介绍&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>PV Controller：&lt;/strong> 负责 PV/PVC 绑定及周期管理，根据需求进行数据卷的 &lt;strong>Provision/Delete&lt;/strong> 操作；&lt;/li>
&lt;li>&lt;strong>AD Controller：&lt;/strong> 负责数据卷的 &lt;strong>Attach/Detach&lt;/strong> 操作，将设备挂接到目标节点；&lt;/li>
&lt;li>&lt;strong>Kubelet：&lt;/strong> Kubelet 是在每个 Node 节点上运行的主要 “节点代理”，功能是 Pod 生命周期管理、容器健康检查、容器监控等；&lt;/li>
&lt;li>&lt;strong>Volume Manager：&lt;/strong> Kubelet 中的组件，负责管理数据卷的 &lt;strong>Mount/Umount&lt;/strong> 操作（也负责数据卷的 &lt;strong>Attach/Detach&lt;/strong> 操作，需配置 kubelet 相关参数开启该特性）、卷设备的格式化等等；&lt;/li>
&lt;li>&lt;strong>Volume Plugins：&lt;/strong> 存储插件，由存储供应商开发，目的在于扩展各种存储类型的卷管理能力，实现第三方存储的各种操作能力。Volume Plugins 有 in-tree 和 out-of-tree 两种；&lt;/li>
&lt;li>&lt;strong>External Provioner：&lt;/strong> External Provioner 是一种 sidecar 容器，作用是调用 Volume Plugins 中的 CreateVolume 和 DeleteVolume 函数来执行 &lt;strong>Provision/Delet&lt;/strong>e 操作。因为 K8s 的 PV 控制器无法直接调用 Volume Plugins 的相关函数，故由 External Provioner 通过 gRPC 来调用；&lt;/li>
&lt;li>&lt;strong>External Attacher：&lt;/strong> External Attacher 是一种 sidecar 容器，作用是调用 Volume Plugins 中的 ControllerPublishVolume 和 ControllerUnpublishVolume 函数来执行 &lt;strong>Attach/Detach&lt;/strong> 操作。因为 K8s 的 AD 控制器无法直接调用 Volume Plugins 的相关函数，故由 External Attacher 通过 gRPC 来调用。&lt;/li>
&lt;/ul>
&lt;h2 id="3-持久卷使用">3. 持久卷使用&lt;/h2>
&lt;p>Kubernetes 为了使应用程序及其开发人员能够正常请求存储资源，&lt;strong>避免处理存储设施细节&lt;/strong>，引入了 PV 和 PVC。创建 PV 有两种方式：&lt;/p>
&lt;ul>
&lt;li>一种是集群管理员通过手动方式&lt;strong>静态创建&lt;/strong>应用所需要的 PV；&lt;/li>
&lt;li>另一种是用户手动创建 PVC 并由 Provisioner 组件&lt;strong>动态创建&lt;/strong>对应的 PV。&lt;/li>
&lt;/ul>
&lt;p>下面我们以 NFS 共享存储为例来看二者区别。&lt;/p>
&lt;h3 id="静态创建存储卷">&lt;strong>静态创建存储卷&lt;/strong>&lt;/h3>
&lt;p>静态创建存储卷流程如下图所示：&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/yvBJb5IiafvmXbo2aumGmMtcbkUU4icJLRUn7DQa7Ifpa3l0tR0TtneyiahC3jlkBdHJicQegHMCmI53Rib12cukHWQ/640?wx_fmt=png" alt="">&lt;/p>
&lt;p>&lt;strong>第一步：&lt;/strong> 集群管理员创建 NFS PV，NFS 属于 K8s 原生支持的 in-tree 存储类型。yaml 文件如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  nfs:
    server: 192.168.4.1
    path: /nfs_storage
&lt;/code>&lt;/pre>&lt;p>&lt;strong>第二步：&lt;/strong> 用户创建 PVC，yaml 文件如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
&lt;/code>&lt;/pre>&lt;p>通过 kubectl get pv 命令可看到 PV 和 PVC 已绑定：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@huizhi ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># kubectl get pvcNAME      STATUS   VOLUME               CAPACITY   ACCESS MODES   STORAGECLASS   AGEnfs-pvc   Bound    nfs-pv-no-affinity   10Gi       RWO                           4s&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>第三步：&lt;/strong> 用户创建应用，并使用第二步创建的 PVC。&lt;/p>
&lt;pre tabindex="0">&lt;code>apiVersion: v1
kind: Pod
metadata:
  name: test-nfs
spec:
  containers:
  - image: nginx:alpine
    imagePullPolicy: IfNotPresent
    name: nginx
    volumeMounts:
    - mountPath: /data
      name: nfs-volume
  volumes:
  - name: nfs-volume
    persistentVolumeClaim:
      claimName: nfs-pvc
&lt;/code>&lt;/pre>&lt;p>此时 NFS 的远端存储就挂载了到 Pod 中 nginx 容器的 /data 目录下。&lt;/p>
&lt;h3 id="动态创建存储卷">&lt;strong>动态创建存储卷&lt;/strong>&lt;/h3>
&lt;blockquote>
&lt;p>动态创建存储卷，要求集群中部署有 nfs-client-provisioner 以及对应的 storageclass。&lt;/p>
&lt;/blockquote>
&lt;p>动态创建存储卷相比静态创建存储卷，少了集群管理员的干预，流程如下图所示：&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/yvBJb5IiafvmXbo2aumGmMtcbkUU4icJLREojmFJg08eIA1ya9XicW6grKWID5wDTy0jibY5bnyYT4Oicj6X8ZgSfxg/640?wx_fmt=png" alt="">&lt;/p>
&lt;p>集群管理员只需要保证环境中有 NFS 相关的 storageclass 即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">kind: StorageClass &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">apiVersion: storage.k8s.io/v1 &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  &lt;span style="color:#ae81ff">name: nfs-sc &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">provisioner: example.com/nfs &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">mountOptions&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  - &lt;span style="color:#ae81ff">vers=4.1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>第一步：&lt;/strong> 用户创建 PVC，此处 PVC 的 storageClassName 指定为上面 NFS 的 storageclass 名称：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">kind: PersistentVolumeClaim &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">apiVersion: v1 &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  &lt;span style="color:#ae81ff">name: nfs &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  &lt;span style="color:#f92672">annotations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    &lt;span style="color:#ae81ff">volume.beta.kubernetes.io/storage-class: &amp;#34;example-nfs&amp;#34; &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  &lt;span style="color:#f92672">accessModes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    - &lt;span style="color:#ae81ff">ReadWriteMany &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    &lt;span style="color:#f92672">requests&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>      &lt;span style="color:#ae81ff">storage: 10Mi &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>  &lt;span style="color:#ae81ff">storageClassName: nfs-sc&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>第二步：&lt;/strong> 集群中的 nfs-client-provisioner 会动态创建相应 PV。此时可看到环境中 PV 已创建，并与 PVC 已绑定。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@huizhi ~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># kubectl get pv &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME                                       CAPACITY   ACCESSMODES   RECLAIMPOLICY   STATUS      CLAIM         REASON    AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pvc-dce84888-7a9d-11e6-b1ee-5254001e0c1b   10Mi        RWX           Delete          Bound       default/nfs             4s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>第三步：&lt;/strong> 用户创建应用，并使用第二步创建的 PVC，同静态创建存储卷的第三步。&lt;/p>
&lt;h1 id="k8s-持久化存储流程">K8s 持久化存储流程&lt;/h1>
&lt;h2 id="1-流程概览">1. 流程概览&lt;/h2>
&lt;blockquote>
&lt;p>此处借鉴 @郡宝 在云原生存储课程中的流程图。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/yvBJb5IiafvmXbo2aumGmMtcbkUU4icJLRDevub1zpBWHBhFWEfUDdEqX8NgeAVHZxYu9bibiaky63DUEtBzZdDtIg/640?wx_fmt=png" alt="">&lt;/p>
&lt;p>流程如下：&lt;/p>
&lt;ol>
&lt;li>用户创建了一个包含 PVC 的 Pod，该 PVC 要求使用动态存储卷；&lt;/li>
&lt;li>&lt;strong>Scheduler&lt;/strong> 根据 Pod 配置、节点状态、PV 配置等信息，把 Pod 调度到一个合适的 Worker 节点上；&lt;/li>
&lt;li>&lt;strong>PV 控制器&lt;/strong> watch 到该 Pod 使用的 PVC 处于 Pending 状态，于是调用 &lt;strong>Volume Plugin&lt;/strong>（in-tree）创建存储卷，并创建 PV 对象（out-of-tree 由 External Provisioner 来处理）；&lt;/li>
&lt;li>&lt;strong>AD 控制器&lt;/strong>发现 Pod 和 PVC 处于待挂接状态，于是调用 &lt;strong>Volume Plugin&lt;/strong> 挂接存储设备到目标 Worker 节点上&lt;/li>
&lt;li>在 Worker 节点上，&lt;strong>Kubelet 中的 Volume Manager&lt;/strong> 等待存储设备挂接完成，并通过 &lt;strong>Volume Plugin&lt;/strong> 将设备挂载到全局目录：/var/lib/kubelet/pods/[pod uid]/volumes/kubernetes.io~iscsi/[PV name]（以 iscsi 为例）；&lt;/li>
&lt;li>&lt;strong>Kubelet&lt;/strong> 通过 Docker 启动 &lt;strong>Pod 的 Containers&lt;/strong>，用 &lt;strong>bind mount&lt;/strong> 方式将已挂载到本地全局目录的卷映射到&lt;strong>容器&lt;/strong>中。&lt;/li>
&lt;/ol>
&lt;p>更详细的流程如下：&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/yvBJb5IiafvmXbo2aumGmMtcbkUU4icJLR9xNtPZVjn0mic2tiamiaYfu9015XKpxNLlv1Stia0nvgPa8PuSa4QIcTMw/640?wx_fmt=png" alt="">&lt;/p>
&lt;h2 id="2-流程详解">2. 流程详解&lt;/h2>
&lt;blockquote>
&lt;p>不同 K8s 版本，持久化存储流程略有区别。本文基于 Kubernetes 1.14.8 版本。&lt;/p>
&lt;/blockquote>
&lt;p>从上述流程图中可看到，存储卷从创建到提供应用使用共分为三个阶段：&lt;strong>Provision/Delete、Attach/Detach、Mount/Unmount&lt;/strong>。&lt;/p>
&lt;h3 id="provisioning-volumes">&lt;strong>provisioning volumes&lt;/strong>&lt;/h3>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/yvBJb5IiafvmXbo2aumGmMtcbkUU4icJLRXn9ZAfLS2DlnC5UZU2xduqg8MM873rR0p2xefctmkSSSOiaQ5xoVXzA/640?wx_fmt=png" alt="">&lt;/p>
&lt;p>&lt;strong>PV 控制器中有两个 Worker：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>ClaimWorker：&lt;/strong> 处理 PVC 的 add / update / delete 相关事件以及 PVC 的状态迁移；&lt;/li>
&lt;li>&lt;strong>VolumeWorker：&lt;/strong> 负责 PV 的状态迁移。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>PV 状态迁移（UpdatePVStatus）：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PV 初始状态为 Available，当 PV 与 PVC 绑定后，状态变为 Bound；&lt;/li>
&lt;li>与 PV 绑定的 PVC 删除后，状态变为 Released；&lt;/li>
&lt;li>当 PV 回收策略为 Recycled 或手动删除 PV 的 .Spec.ClaimRef 后，PV 状态变为 Available；&lt;/li>
&lt;li>当 PV 回收策略未知或 Recycle 失败或存储卷删除失败，PV 状态变为 Failed；&lt;/li>
&lt;li>手动删除 PV 的 .Spec.ClaimRef，PV 状态变为 Available。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>PVC 状态迁移（UpdatePVCStatus）：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>当集群中不存在满足 PVC 条件的 PV 时，PVC 状态为 Pending。在 PV 与 PVC 绑定后，PVC 状态由 Pending 变为 Bound；&lt;/li>
&lt;li>与 PVC 绑定的 PV 在环境中被删除，PVC 状态变为 Lost；&lt;/li>
&lt;li>再次与一个&lt;strong>同名 PV&lt;/strong> 绑定后，PVC 状态变为 Bound。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Provisioning 流程如下所示（此处模拟用户创建一个新 PVC）。&lt;/strong>&lt;/p>
&lt;p>&lt;strong>静态存储卷流程（FindBestMatch）&lt;/strong>：PV 控制器首先在环境中筛选一个状态为 Available 的 PV 与新 PVC匹配。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>DelayBinding：&lt;/strong> PV 控制器判断该 PVC 是否需要延迟绑定：1. 查看 PVC 的 annotation 中是否包含volume.kubernetes.io / selected-node，若存在则表示该 PVC 已经被调度器指定好了节点（属于 &lt;strong>ProvisionVolume&lt;/strong>），故不需要延迟绑定；2. 若 PVC 的 annotation 中不存在 volume.kubernetes.io / selected-node，同时没有 StorageClass，默认表示不需要延迟绑定；若有 StorageClass，查看其 VolumeBindingMode 字段，若为 WaitForFirstConsumer 则需要延迟绑定，若为 Immediate 则不需要延迟绑定；&lt;/li>
&lt;li>&lt;strong>FindBestMatchPVForClaim：&lt;/strong> PV 控制器尝试找一个满足 PVC 要求的环境中现有的 PV。PV 控制器会将所有的 PV 进行一次筛选，并会从满足条件的 PV 中选择一个最佳匹配的PV。筛选规则：1. VolumeMode 是否匹配；2. PV 是否已绑定到 PVC 上；3. PV 的 .Status.Phase 是否为 Available；4. LabelSelector 检查，PV 与 PVC 的 label 要保持一致；5. PV 与 PVC 的 StorageClass 是否一致；6. 每次迭代更新最小满足 PVC requested size 的 PV，并作为最终结果返回；&lt;/li>
&lt;li>&lt;strong>Bind：&lt;/strong> PV 控制器对选中的 PV、PVC 进行绑定。1. 更新 PV 的 .Spec.ClaimRef 信息为当前 PVC；2. 更新 PV 的 .Status.Phase 为 Bound；3. 新增 PV 的 annotation：pv.kubernetes.io/bound-by-controller: &amp;ldquo;yes&amp;rdquo;；4. 更新 PVC 的 .Spec.VolumeName 为 PV 名称；5. 更新 PVC 的 .Status.Phase 为 Bound；6. 新增 PVC 的 annotation：pv.kubernetes.io/bound-by-controller: &amp;ldquo;yes&amp;rdquo; 和 pv.kubernetes.io/bind-completed: &amp;ldquo;yes&amp;rdquo;；&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>动态存储卷流程（ProvisionVolume）&lt;/strong>：若环境中没有合适的 PV，则进入动态 Provisioning 场景。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Before Provisioning：&lt;/strong> 1. PV 控制器首先判断 PVC 使用的 StorageClass 是 in-tree 还是 out-of-tree：通过查看 StorageClass 的 Provisioner 字段是否包含 &amp;ldquo;kubernetes.io/&amp;rdquo; 前缀来判断；2. PV 控制器更新 PVC 的 annotation：claim.Annotations[&amp;ldquo;volume.beta.kubernetes.io/storage-provisioner&amp;rdquo;] = storageClass.Provisioner；&lt;/li>
&lt;li>&lt;strong>in-tree Provisioning（internal provisioning）：&lt;/strong> 1. in-tree 的 Provioner 会实现 ProvisionableVolumePlugin 接口的 NewProvisioner 方法，用来返回一个新的 Provisioner；2. PV 控制器调用 Provisioner 的 Provision 函数，该函数会返回一个 PV 对象；3. PV 控制器创建上一步返回的 PV 对象，将其与 PVC 绑定，Spec.ClaimRef 设置为 PVC，.Status.Phase 设置为 Bound，.Spec.StorageClassName 设置为与 PVC 相同的 StorageClassName；同时新增 annotation：&amp;ldquo;pv.kubernetes.io/bound-by-controller&amp;rdquo;=&amp;ldquo;yes&amp;rdquo; 和 &amp;ldquo;pv.kubernetes.io/provisioned-by&amp;rdquo;=plugin.GetPluginName()；&lt;/li>
&lt;li>&lt;strong>out-of-tree Provisioning（external provisioning）：&lt;/strong> 1. External Provisioner 检查 PVC 中的 claim.Spec.VolumeName 是否为空，不为空则直接跳过该 PVC；2. External Provisioner 检查 PVC 中的 claim.Annotations[&amp;ldquo;volume.beta.kubernetes.io/storage-provisioner&amp;rdquo;] 是否等于自己的 Provisioner Name（External Provisioner 在启动时会传入&amp;ndash;provisioner 参数来确定自己的 Provisioner Name）；3. 若 PVC 的 VolumeMode=Block，检查 External Provisioner 是否支持块设备；4. External Provisioner 调用 Provision 函数：通过 gRPC 调用 &lt;strong>CSI 存储插件的 CreateVolume 接口&lt;/strong>；5. External Provisioner 创建一个 PV 来代表该 volume，同时将该 PV 与之前的 PVC 做绑定。&lt;/li>
&lt;/ul>
&lt;h3 id="deleting-volumes">&lt;strong>deleting volumes&lt;/strong>&lt;/h3>
&lt;p>&lt;strong>Deleting 流程为 Provisioning 的反操作：&lt;/strong> 用户删除 PVC，删除 PV 控制器改变 PV.Status.Phase 为 Released。&lt;/p>
&lt;p>当 PV.Status.Phase == Released 时，PV 控制器首先检查 Spec.PersistentVolumeReclaimPolicy 的值。为 Retain 时直接跳过，为 Delete 时：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>in-tree Deleting：&lt;/strong> 1. in-tree 的 Provioner 会实现 DeletableVolumePlugin 接口的 NewDeleter 方法，用来返回一个新的 Deleter；2. 控制器调用 Deleter 的 Delete 函数，删除对应 volume；3. 在 volume 删除后，PV 控制器会删除 PV 对象；&lt;/li>
&lt;li>&lt;strong>out-of-tree Deleting：1.&lt;/strong> External Provisioner 调用 Delete 函数，&lt;strong>通过 gRPC 调用 CSI 插件的 DeleteVolume 接口&lt;/strong>；2. 在 volume 删除后，External Provisioner 会删除 PV 对象&lt;/li>
&lt;/ul>
&lt;h3 id="attaching-volumes">&lt;strong>Attaching Volumes&lt;/strong>&lt;/h3>
&lt;blockquote>
&lt;p>Kubelet 组件和 AD 控制器都可以做 attach/detach 操作，若 Kubelet 的启动参数中指定了&amp;ndash;enable-controller-attach-detach，则由 Kubelet 来做；否则默认由 AD 控制起来做。下面以 AD 控制器为例来讲解 attach/detach 操作。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/yvBJb5IiafvmXbo2aumGmMtcbkUU4icJLRxAickDo9iaD4Q6UL7CwpIcCSax7aYIwveN9qicrZelVkUOvXLCauxv6nQ/640?wx_fmt=png" alt="">&lt;/p>
&lt;p>&lt;strong>AD 控制器中有两个核心变量：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>DesiredStateOfWorld（DSW）：集群中预期的数据卷挂接状态，包含了 nodes-&amp;gt;volumes-&amp;gt;pods 的信息；&lt;/li>
&lt;li>ActualStateOfWorld（ASW）：集群中实际的数据卷挂接状态，包含了 volumes-&amp;gt;nodes 的信息。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Attaching 流程如下所示：&lt;/strong>&lt;/p>
&lt;p>AD 控制器根据集群中的资源信息，初始化 DSW 和 ASW。&lt;/p>
&lt;p>AD 控制器内部有三个组件周期性更新 DSW 和 ASW：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Reconciler&lt;/strong>。通过一个 GoRoutine 周期性运行，确保 volume 挂接/摘除完毕。此期间不断更新 ASW：&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>in-tree attaching：&lt;/strong> 1. in-tree 的 Attacher 会实现 AttachableVolumePlugin 接口的 NewAttacher 方法，用来返回一个新的 Attacher；2. AD 控制器调用 Attacher 的 Attach 函数进行设备挂接；3. 更新 ASW。&lt;/p>
&lt;p>&lt;strong>out-of-tree attaching：&lt;/strong> 1. 调用 in-tree 的 CSIAttacher 创建一个 VolumeAttachement（VA）对象，该对象包含了 Attacher 信息、节点名称、待挂接 PV 信息；2. External Attacher 会 watch 集群中的 VolumeAttachement 资源，发现有需要挂接的数据卷时，调用 Attach 函数，通过 gRPC 调用 CSI 插件的 ControllerPublishVolume 接口。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>DesiredStateOfWorldPopulator&lt;/strong>。通过一个 GoRoutine 周期性运行，主要功能是更新 DSW：&lt;/li>
&lt;/ul>
&lt;p>findAndRemoveDeletedPods - 遍历所有 DSW 中的 Pods，若其已从集群中删除则从 DSW 中移除；&lt;/p>
&lt;p>findAndAddActivePods - 遍历所有 PodLister 中的 Pods，若 DSW 中不存在该 Pod 则添加至 DSW。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>PVC Worker&lt;/strong>。watch PVC 的 add/update 事件，处理 PVC 相关的 Pod，并实时更新 DSW。&lt;/li>
&lt;/ul>
&lt;h3 id="detaching-volumes">&lt;strong>Detaching Volumes&lt;/strong>&lt;/h3>
&lt;p>&lt;strong>Detaching 流程如下：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>当 Pod 被删除，AD 控制器会 watch 到该事件。首先 AD 控制器检查 Pod 所在的 Node 资源是否包含&amp;quot;volumes.kubernetes.io/keep-terminated-pod-volumes&amp;quot;标签，若包含则不做操作；不包含则从 DSW 中去掉该 volume；&lt;/li>
&lt;li>AD 控制器通过 &lt;strong>Reconciler&lt;/strong> 使 ActualStateOfWorld 状态向 DesiredStateOfWorld 状态靠近，当发现 ASW 中有 DSW 中不存在的 volume 时，会做 Detach 操作：&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>in-tree detaching：&lt;/strong> 1. AD 控制器会实现 AttachableVolumePlugin 接口的 NewDetacher 方法，用来返回一个新的 Detacher；2. 控制器调用 Detacher 的 Detach 函数，detach 对应 volume；3. AD 控制器更新 ASW。&lt;/p>
&lt;p>&lt;strong>out-of-tree detaching：&lt;/strong> 1. AD 控制器调用 in-tree 的 CSIAttacher 删除相关 VolumeAttachement 对象；2. External Attacher 会 watch 集群中的 VolumeAttachement（VA）资源，发现有需要摘除的数据卷时，调用 Detach 函数，通过 gRPC 调用 &lt;strong>CSI 插件的 ControllerUnpublishVolume 接口&lt;/strong>；3. AD 控制器更新 ASW。&lt;/p>
&lt;h3 id="mountingunmounting-volumes">&lt;strong>Mounting/Unmounting Volumes&lt;/strong>&lt;/h3>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/yvBJb5IiafvmXbo2aumGmMtcbkUU4icJLRt8qlbMGLK41icklvb0JaDyyia62TRrb6KGKk6zibpZyDTibth5syiauQCng/640?wx_fmt=png" alt="">&lt;/p>
&lt;p>&lt;strong>Volume Manager&lt;/strong> 中同样也有两个核心变量：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>DesiredStateOfWorld（DSW）：&lt;/strong> 集群中预期的数据卷挂载状态，包含了 volumes-&amp;gt;pods 的信息；&lt;/li>
&lt;li>&lt;strong>ActualStateOfWorld（ASW）：&lt;/strong> 集群中实际的数据卷挂载状态，包含了 volumes-&amp;gt;pods 的信息。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Mounting/UnMounting 流程如下：&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>全局目录（global mount path）存在的目的：块设备在 Linux 上只能挂载一次，而在 K8s 场景中，一个 PV 可能被挂载到同一个 Node 上的多个 Pod 实例中。若块设备格式化后先挂载至 Node 上的一个临时全局目录，然后再使用 Linux 中的 bind mount 技术把这个全局目录挂载进 Pod 中对应的目录上，就可以满足要求。上述流程图中，全局目录即 /var/lib/kubelet/pods/[pod uid]/volumes/kubernetes.io~iscsi/[PV name]。&lt;/p>
&lt;/blockquote>
&lt;p>VolumeManager 根据集群中的资源信息，初始化 &lt;strong>DSW 和 ASW&lt;/strong>。&lt;/p>
&lt;p>VolumeManager 内部有两个组件周期性更新 &lt;strong>DSW 和 ASW&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>DesiredStateOfWorldPopulator&lt;/strong>：通过一个 GoRoutine 周期性运行，主要功能是&lt;strong>更新 DSW&lt;/strong>；&lt;/li>
&lt;li>&lt;strong>Reconciler：&lt;/strong> 通过一个 GoRoutine 周期性运行，&lt;strong>确保 volume 挂载/卸载完毕&lt;/strong>。此期间不断更新 ASW：&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>unmountVolumes：&lt;/strong> 确保 Pod 删除后 volumes 被 unmount。遍历一遍所有 ASW 中的 Pod，若其不在 DSW 中（表示 Pod 被删除），此处以 VolumeMode=FileSystem 举例，则执行如下操作：&lt;/p>
&lt;ol>
&lt;li>Remove all bind-mounts：调用 Unmounter 的 TearDown 接口（若为 out-of-tree 则调用 &lt;strong>CSI 插件的 NodeUnpublishVolume 接口&lt;/strong>）；&lt;/li>
&lt;li>Unmount volume：调用 DeviceUnmounter 的 UnmountDevice 函数（若为 out-of-tree 则调用 &lt;strong>CSI 插件的 NodeUnstageVolume 接口&lt;/strong>）；&lt;/li>
&lt;li>更新 ASW。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>mountAttachVolumes：&lt;/strong> 确保 Pod 要使用的 volumes 挂载成功。遍历一遍所有 DSW 中的 Pod，若其不在 ASW 中（表示目录待挂载映射到 Pod 上），此处以 VolumeMode=FileSystem 举例，执行如下操作：&lt;/p>
&lt;ol>
&lt;li>等待 volume 挂接到节点上（由 External Attacher or Kubelet 本身挂接）；&lt;/li>
&lt;li>挂载 volume 到全局目录：调用 DeviceMounter 的 MountDevice 函数（若为 out-of-tree 则调用 &lt;strong>CSI 插件的 NodeStageVolume 接口&lt;/strong>）；&lt;/li>
&lt;li>更新 ASW：该 volume 已挂载到全局目录；&lt;/li>
&lt;li>bind-mount volume 到 Pod 上：调用 Mounter 的 SetUp 接口（若为 out-of-tree 则调用 &lt;strong>CSI 插件的 NodePublishVolume 接口&lt;/strong>）；&lt;/li>
&lt;li>更新 ASW。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>unmountDetachDevices：&lt;/strong> 确保需要 unmount 的 volumes 被 unmount。遍历一遍所有 ASW 中的 UnmountedVolumes，若其不在 DSW 中（表示 volume 已无需使用），执行如下操作：&lt;/p>
&lt;ol>
&lt;li>Unmount volume：调用 DeviceUnmounter 的 UnmountDevice 函数（若为 out-of-tree 则调用 &lt;strong>CSI 插件的NodeUnstageVolume接口&lt;/strong>）；&lt;/li>
&lt;li>更新 ASW。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>总结&lt;/strong>&lt;/p>
&lt;p>本文先对 K8s 持久化存储基础概念及使用方法进行了介绍，并对 K8s 内部存储流程进行了深度解析。在 K8s 上，使用任何一种存储都离不开上面的流程（有些场景不会用到 attach/detach），环境上的存储问题也一定是其中某个环节出现了故障。&lt;/p>
&lt;p>容器存储的坑比较多，专有云环境下尤其如此。不过挑战越多，机遇也越多！目前国内专有云市场在存储领域也是群雄逐鹿，我们敏捷 PaaS 容器团队欢迎大侠的加入，一起共创未来！&lt;/p>
&lt;h1 id="参考链接">&lt;strong>参考链接&lt;/strong>&lt;/h1>
&lt;ul>
&lt;li>Kubernetes 社区源码&lt;/li>
&lt;li>&lt;a href="http://mp.weixin.qq.com/s?__biz=MzUzNzYxNjAzMg==&amp;amp;mid=2247489053&amp;amp;idx=1&amp;amp;sn=88b3eb1eb0c726f6ab9a309ff3c0fe9c&amp;amp;chksm=fae51dd2cd9294c4b4c555ebfa5a12f0ac2a1a768a150b57048402e288689ccd5ad704984a00&amp;amp;scene=21#wechat_redirect">Kubernetes 存储架构及插件使用&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://mp.weixin.qq.com/s?__biz=MzUzNzYxNjAzMg==&amp;amp;mid=2247487353&amp;amp;idx=1&amp;amp;sn=80263666e7e2e17da37374990262d283&amp;amp;chksm=fae504b6cd928da0b44045ed3d1596597a84128cd6a7d6cfbcfac33382a252f295fce2e39d78&amp;amp;scene=21#wechat_redirect">应用存储和持久化数据卷 - 核心知识&lt;/a>&lt;/li>
&lt;li>volume-provisioning&lt;/li>
&lt;li>CSI Volume Plugins in Kubernetes Design Doc&lt;/li>
&lt;/ul></description></item><item><title>Docs: CSI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/CSI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/CSI/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/container-storage-interface/spec">GitHub 项目,规范&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>CSI 是与 &lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes%20%E7%BD%91%E7%BB%9C/CNI/CNI.md">CNI&lt;/a> 类似的东西，都是一种规范。&lt;/p>
&lt;p>Container Storage Interface，容器存储接口（CSI）为容器编排系统（如 Kubernetes）定义了一个标准接口，以将任意存储系统暴露给其容器工作负载。&lt;/p>
&lt;h2 id="csi-specification-规范介绍">CSI Specification 规范介绍&lt;/h2>
&lt;p>官方文档：&lt;a href="https://github.com/container-storage-interface/spec/blob/master/spec.md">https://github.com/container-storage-interface/spec/blob/master/spec.md&lt;/a>&lt;/p>
&lt;h1 id="背景">背景&lt;/h1>
&lt;p>CSI 出现之前，很多存储类型的 PV，比如 iSCSI、NFS、CephFS 等等(&lt;a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes">详见 k8s 官方支持列表&lt;/a>)。这些类型的存储的代码，放在 Kubernetes 代码仓库中，这种称为 &lt;strong>in-tree&lt;/strong> 类型的存储(也就是在代码树中)。这里代理的问题是 Kubernetes 代码与 第三方存储厂商的代码&lt;strong>强耦合&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>更改 in-tree 类型的存储代码，用户必须更新 K8s 组件，成本较高&lt;/li>
&lt;li>in-tree 存储代码中的 bug 会引发 K8s 组件不稳定&lt;/li>
&lt;li>K8s 社区需要负责维护及测试 in-tree 类型的存储功能&lt;/li>
&lt;li>in-tree 存储插件享有与 K8s 核心组件同等的特权，存在安全隐患&lt;/li>
&lt;li>三方存储开发者必须遵循 K8s 社区的规则开发 in-tree 类型存储代码&lt;/li>
&lt;/ul>
&lt;p>**CSI(容器存储接口)**标准的出现解决了上述问题，将三方存储代码与 K8S 代码解耦，使得三方存储厂商研发人员只需实现 CSI 接口（无需关注容器平台是 K8s 还是 Swarm 等）。&lt;/p></description></item><item><title>Docs: Persistent Volume(持久卷)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/</guid><description/></item><item><title>Docs: Storage Classes(存储类)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/</guid><description/></item><item><title>Docs: Volume</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/Volume/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/9.Kubernetes-%E5%AD%98%E5%82%A8/Volume/</guid><description/></item></channel></rss>