<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – Rancher</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/</link><description>Recent content in Rancher on 断念梦</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 1.1.Rancher 介绍</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/1.1.Rancher-%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/1.1.Rancher-%E4%BB%8B%E7%BB%8D/</guid><description>
&lt;h1 id="rancher-介绍">Rancher 介绍&lt;/h1>
&lt;p>官方文档：&lt;a href="https://rancher.com/">https://rancher.com/&lt;/a>&lt;/p>
&lt;p>Rancher 是为使用容器的公司打造的容器管理平台。Rancher 简化了使用 Kubernetes 的流程，开发者可以随处运行 Kubernetes（Run Kubernetes Everywhere），满足 IT 需求规范，赋能 DevOps 团队。&lt;/p>
&lt;p>Rancher 在现阶段可以看作是一个解决方案，是一套产品的统称，这套产品包括如下几个：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>K3S # 用于运行高可用 Rancher 的底层平台。是一个轻量的 kubernetes，一个 k3s 二进制文件即可包含所有 kubernetes 的主要组件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Rancher Server # Rancher 管理程序，常部署于 k3s 之上，用来管理其下游 k8s 集群。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RKE # Rancher 创建的 kubernetes 集群。是一个可以通过名为 rke 的二进制文件以及一个 yaml 文件，即可启动 kubernetes 集群的引擎。RKE 与 kubernetes 的关系，类似于 docker 与 containerd 的关系。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="rancher-server-介绍">Rancher Server 介绍&lt;/h2>
&lt;p>Rancher Server 由认证代理(Authentication Proxy)、Rancher API Server、集群控制器(Cluster Controller)、数据存储(比如 etcd、mysql 等)和集群代理(Cluster Agent) 组成。除了 Cluster Agent 以外，其他组件都部署在 Rancher Server 中。(这些组件都集中在一起，一般可以通过 docker 直接启动一个 Rancher Server。)&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kxmsmg/1616114814016-9de5267d-0813-4790-826c-7c4448e40861.png" alt="">&lt;/p>
&lt;p>Rancher Server 可以管理多种 k8s 集群&lt;/p>
&lt;ol>
&lt;li>
&lt;p>通过 Rancher Server 来创建一个 RKE 集群&lt;/p>
&lt;/li>
&lt;li>
&lt;p>托管的 kubernetes 集群。e.g.Amazon EKS、Azure AKS、Google GKE 等等&lt;/p>
&lt;/li>
&lt;li>
&lt;p>导入已有的 kubernetes 集群。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="rancher-与下游集群交互的方式">Rancher 与下游集群交互的方式&lt;/h2>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kxmsmg/1616114813966-db373999-6c8f-4541-a09f-5f20eaa656ce.png" alt="">&lt;/p>
&lt;p>通过 Rancher 管理的 kubernetes 集群(不管是导入的还是通过 Rancher 创建的)，都会在集群中部署两种 agent，来与 Rancher 进行交互。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>cattle-cluster-agent # 上图中的 Cluster Agent。用于本集群与 Rancher Server 的 Cluster Controller(集群控制器)的通信&lt;/p>
&lt;/li>
&lt;li>
&lt;p>连接 Rancher 与本集群的 API Server&lt;/p>
&lt;/li>
&lt;li>
&lt;p>管理集群内的工作负载，比如 Rancher Server 下发一个部署 pod 的任务，集群代理就会与本集群 API 交互来处理任务&lt;/p>
&lt;/li>
&lt;li>
&lt;p>根据每个集群的设置，配置 Role 和 RoleBindings&lt;/p>
&lt;/li>
&lt;li>
&lt;p>实现集群和 Rancher Server 之间的消息传输，包括事件，指标，健康状况和节点信息等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cattle-node-agent # 上图中的 Node Agent。用于处理本节点的任务，比如升级 kubernetes 版本以及创建或者还原 etcd 快照等等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Note：如果 Cluster Agent 不可用，下游集群中的其中一个 Node Agent 会创建一个通信管道，由节点 Agent 连接到集群控制器，实现下游集群和 Rancher 之间的通信。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一般使用 DaemonSet 的方式部署到集群中，以保证每个节点都有一个代理可以执行 Rancher Server 下发的任务。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h1 id="rancher-配置">Rancher 配置&lt;/h1>
&lt;p>Rancher 套件中的各组件配置详见各自组件配置详解&lt;/p>
&lt;h2 id="k3s-配置">K3S 配置&lt;/h2>
&lt;h2 id="rancher-server-配置">Rancher Server 配置&lt;/h2>
&lt;h2 id="rancher-创建的集群配置">Rancher 创建的集群配置&lt;/h2>
&lt;p>Rancher 创建的集群是为 RKE 集群，配置详见：RKE 配置详解&lt;/p></description></item><item><title>Docs: 1.2.Rancher 部署与清理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/1.2.Rancher-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/1.2.Rancher-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</guid><description>
&lt;h1 id="rancher-部署">Rancher 部署&lt;/h1>
&lt;p>常见问题：&lt;a href="https://www.bookstack.cn/read/rancher-2.4.4-zh/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98.md">https://www.bookstack.cn/read/rancher-2.4.4-zh/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98.md&lt;/a>&lt;/p>
&lt;h2 id="快速部署体验">快速部署体验&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker run -d --name&lt;span style="color:#f92672">=&lt;/span>rancher-server --restart&lt;span style="color:#f92672">=&lt;/span>unless-stopped &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 60080:80 -p 60443:443 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -v /opt/rancher:/var/lib/rancher &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --privileged &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> rancher/rancher:v2.5.3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果想让 rancher 可以验证外部 https 的自建 CA 证书，需要在启动前将证书导入 rancher-server 中，效果如下：&lt;/p>
&lt;p>参考链接： &lt;a href="https://rancher.com/docs/rancher/v2.x/en/installation/resources/chart-options/#additional-trusted-cas">https://rancher.com/docs/rancher/v2.x/en/installation/resources/chart-options/#additional-trusted-cas&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://rancher.com/docs/rancher/v2.x/en/installation/other-installation-methods/single-node-docker/advanced/#custom-ca-certificate">https://rancher.com/docs/rancher/v2.x/en/installation/other-installation-methods/single-node-docker/advanced/#custom-ca-certificate&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker run -d --name&lt;span style="color:#f92672">=&lt;/span>rancher-server --restart&lt;span style="color:#f92672">=&lt;/span>unless-stopped &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 60080:80 -p 60443:443 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -v /opt/rancher:/var/lib/rancher &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -v /host/certs:/container/certs &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -e SSL_CERT_DIR&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/container/certs&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --privileged &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> rancher/rancher:latest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在宿主机的 /host/certs 目录中存放要导入的证书，比如可以把 harbor 的证书与私钥放入该目录中，这样 rancher 就可以添加 https 的 harbor 仓库了&lt;/p>
&lt;p>还可以传递 CATTLE_SYSTEM_DEFAULT_REGISTRY 环境变量，让 rancher 内部使用私有镜像地址。比如&lt;/p>
&lt;pre>&lt;code>docker run -d --name=rancher-server --restart=unless-stopped \
-p 60080:80 -p 60443:443 \
-v /opt/rancher:/var/lib/rancher \
--privileged \
-e CATTLE_SYSTEM_DEFAULT_REGISTRY=&amp;quot;registry.wx-net.ehualu.com&amp;quot; \
rancher/rancher:latest
&lt;/code>&lt;/pre>
&lt;h2 id="高可用部署">高可用部署&lt;/h2>
&lt;p>Rancher 的高可用本质上就是将 Rancher 作为 kubernetes 上的一个服务对外提供(这个 k8s 集群通常只用来运行 Rancher)。Rancher 的数据储存在 k8s 集群的后端存储中(i.e.ETCD)。由于原生 k8s 部署负责，资源需求大，不易维护等问题，Rancher 官方推出了一个简化版的 k8s，即 &lt;a href="https://github.com/rancher/k3s">k3s&lt;/a>。k3s 是一个简化版的 k8s，可以实现基本的 k8s 功能，但是部署更简单，资源需求更少，更易维护。&lt;a href="https://github.com/rancher/k3s">k3s&lt;/a> 介绍详见 k3s 介绍&lt;/p>
&lt;h3 id="可选启动-k3s-集群">(可选)启动 k3s 集群&lt;/h3>
&lt;p>启动 mysql 用于 k3s 存储数据&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -d --name k3s-mysql --restart&lt;span style="color:#f92672">=&lt;/span>always &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-v /opt/k3s-cluster/mysql/conf:/etc/mysql/conf.d &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-v /opt/k3s-cluster/mysql/data:/var/lib/mysql &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-e MYSQL_ROOT_PASSWORD&lt;span style="color:#f92672">=&lt;/span>root &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-p 3306:3306 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>mysql:5.7.29 --default-time-zone&lt;span style="color:#f92672">=&lt;/span>+8:00 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--character-set-server&lt;span style="color:#f92672">=&lt;/span>utf8mb4 --collation-server&lt;span style="color:#f92672">=&lt;/span>utf8mb4_general_ci &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--explicit_defaults_for_timestamp&lt;span style="color:#f92672">=&lt;/span>true --lower_case_table_names&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --max_allowed_packet&lt;span style="color:#f92672">=&lt;/span>128M
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>启动 k3s&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl -sfL https://docs.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR&lt;span style="color:#f92672">=&lt;/span>cn sh -s - server &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--docker --datastore-endpoint&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;mysql://root:root@tcp(172.38.40.212:3306)/k3s&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 配置 kubectl 的 kubeconfig 文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir ~/.kube
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp /etc/rancher/k3s/k3s.yaml /root/.kube/config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>echo &lt;span style="color:#e6db74">&amp;#34;source &amp;lt;(kubectl completion bash)&amp;#34;&lt;/span> &amp;gt;&amp;gt; ~/.bashrc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="部署-rancher">部署 Rancher&lt;/h3>
&lt;p>创建证书参考：&lt;a href="https://thoughts.teambition.com/workspaces/5f90e312c800160016ea22fb/docs/5fa4f848eaa1190001257bba">&lt;strong>自建 CA 脚本&lt;/strong>&lt;/a>，该脚本参考：&lt;a href="https://docs.rancher.cn/docs/rancher2/installation/options/self-signed-ssl/_index">https://docs.rancher.cn/docs/rancher2/installation/options/self-signed-ssl/_index&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 创建用于运行 Rancher 的名称空间&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kubectl create namespace cattle-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 创建CA证书&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl genrsa -out ca.key &lt;span style="color:#ae81ff">4096&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl req -x509 -new -nodes -sha512 -days &lt;span style="color:#ae81ff">36500&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -subj &lt;span style="color:#e6db74">&amp;#34;/C=CN/ST=Tianjin/L=Tianjin/O=eHualu/OU=Operations/CN=k3s-rancher.desistdaydream.ltd&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -key ca.key &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -out ca.crt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl genrsa -out k3s-rancher.desistdaydream.ltd.key &lt;span style="color:#ae81ff">4096&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl req -sha512 -new &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -subj &lt;span style="color:#e6db74">&amp;#34;/C=CN/ST=Tianjin/L=Tianjin/O=eHualu/OU=Operations/CN=k3s-rancher.desistdaydream.ltd&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -key k3s-rancher.desistdaydream.ltdn.key &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -out k3s-rancher.desistdaydream.ltd.csr
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cat &amp;gt; v3.ext &lt;span style="color:#e6db74">&amp;lt;&amp;lt;EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">authorityKeyIdentifier=keyid,issuer
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">basicConstraints=CA:FALSE
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">extendedKeyUsage = serverAuth
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">subjectAltName = @alt_names
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">[alt_names]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">DNS.1=k3s-rancher.desistdaydream.ltd
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl x509 -req -sha512 -days &lt;span style="color:#ae81ff">36500&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -extfile v3.ext &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -CA ca.crt -CAkey ca.key -CAcreateserial &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -in k3s-rancher.desistdaydream.ltd.csr &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -out k3s-rancher.desistdaydream.ltd.crt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 将证书添加到 secret 资源，以便让 Rancher 读取&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp k3s-rancher.desistdaydream.ltd.crt tls.crt &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> cp k3s-rancher.desistdaydream.ltd.key tls.key
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kubectl -n cattle-system create secret tls tls-rancher-ingress &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --cert&lt;span style="color:#f92672">=&lt;/span>tls.crt &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --key&lt;span style="color:#f92672">=&lt;/span>tls.key
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp ca.crt cacerts.pem
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kubectl -n cattle-system create secret generic tls-ca &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --from-file&lt;span style="color:#f92672">=&lt;/span>cacerts.pem&lt;span style="color:#f92672">=&lt;/span>./cacerts.pem
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 添加 rancher 的 helm 仓库&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>helm repo add rancher-stable http://rancher-mirror.oss-cn-beijing.aliyuncs.com/server-charts/stable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>helm repo update
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 部署指定版本的 Rancher&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>helm install rancher rancher-stable/rancher &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --namespace cattle-system &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --set hostname&lt;span style="color:#f92672">=&lt;/span>k3s-rancher.desistdaydream.ltd &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --set ingress.tls.source&lt;span style="color:#f92672">=&lt;/span>secret &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --set privateCA&lt;span style="color:#f92672">=&lt;/span>true
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="高可用离线部署">高可用离线部署&lt;/h2>
&lt;p>与在线部署类似，但是需要一个私有镜像仓库，所需相关的部署镜像需要先推送到私有镜像仓库中。&lt;/p>
&lt;p>需要提前准备的文件列表：&lt;/p>
&lt;p>在 &lt;a href="https://github.com/rancher/rancher/releases">https://github.com/rancher/rancher/releases&lt;/a> 页面，下载推送镜像所需的文件，这里以 2.4.5 为例。一共需要三个文件。&lt;/p>
&lt;p>rancher-images.txt rancher 镜像列表。&lt;/p>
&lt;p>rancher-save-images.sh 根据镜像列表文件打包所有镜像。&lt;/p>
&lt;p>rancher-load-images.sh 将打包好的镜像推送到私有仓库。&lt;/p>
&lt;ol>
&lt;li>rancher-images.tar.gz # rancher 的镜像
&lt;ol>
&lt;li>curl -LO &lt;a href="https://github.com/rancher/rancher/releases/download/v2.4.5/rancher-images.txt">https://github.com/rancher/rancher/releases/download/v2.4.5/rancher-images.txt&lt;/a>&lt;/li>
&lt;li>curl -LO &lt;a href="https://github.com/rancher/rancher/releases/download/v2.4.5/rancher-save-images.sh">https://github.com/rancher/rancher/releases/download/v2.4.5/rancher-save-images.sh&lt;/a>&lt;/li>
&lt;li>sort -u rancher-images.txt -o rancher-images.txt&lt;/li>
&lt;li>./rancher-save-images.sh &amp;ndash;image-list ./rancher-images.txt&lt;/li>
&lt;li>保存完成后，会生成名为 rancher-images.tar.gz 的镜像打包文件。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>rancher-load-images.sh # 推送 rancher 镜像的脚本
&lt;ol>
&lt;li>curl -LO &lt;a href="https://github.com/rancher/rancher/releases/download/v2.4.5/rancher-load-images.sh">https://github.com/rancher/rancher/releases/download/v2.4.5/rancher-load-images.sh&lt;/a>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>mysql.tar # mysql 镜像。&lt;/li>
&lt;li>k3s # k3s 二进制文件&lt;/li>
&lt;li>k3s-airgap-images-amd64.tar # k3s 运行所需的镜像
&lt;ol>
&lt;li>从 &lt;a href="https://github.com/rancher/k3s/releases">此处&lt;/a> 下载 k3s 二进制文件以及镜像的压缩包。二进制文件名称为 &lt;a href="https://github.com/rancher/k3s/releases/download/v1.18.6%2Bk3s1/k3s">k3s&lt;/a>。镜像压缩包的文件名为 &lt;a href="https://github.com/rancher/k3s/releases/download/v1.18.6%2Bk3s1/k3s-airgap-images-amd64.tar">k3s-airgap-images-amd64.tar&lt;/a>。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>install.sh # 部署 k3s 的脚本
&lt;ol>
&lt;li>从 &lt;a href="https://get.k3s.io">此处&lt;/a> 获取离线安装所需的脚本。国内用户从 &lt;a href="http://mirror.cnrancher.com/">这个页面&lt;/a>的 k3s 目录下获取脚本，脚本名为 k3s-install.sh。&lt;/li>
&lt;li>curl -LO &lt;a href="https://raw.githubusercontent.com/rancher/k3s/master/install.sh">https://raw.githubusercontent.com/rancher/k3s/master/install.sh&lt;/a>&lt;/li>
&lt;li>curl -LO &lt;a href="https://docs.rancher.cn/k3s/k3s-install.sh">https://docs.rancher.cn/k3s/k3s-install.sh&lt;/a>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>rancher-2.4.5.tgz # 用于部署 rancher 的 helm chart。
&lt;ol>
&lt;li>helm repo add rancher-stable &lt;a href="https://releases.rancher.com/server-charts/stable">https://releases.rancher.com/server-charts/stable&lt;/a>&lt;/li>
&lt;li>helm pull rancher-stable/rancher&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>helm # helm 二进制文件
&lt;ol>
&lt;li>从 git 上下载 tar 包，解压获取二进制文件。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>kubectl # kubectl 二进制文件，用于在 Rancher 创建的集群节点上操作集群。&lt;/li>
&lt;/ol>
&lt;h3 id="部署私有镜像仓库">部署私有镜像仓库&lt;/h3>
&lt;p>略。&lt;/p>
&lt;p>推送用于部署 Rancher 所需的镜像，到私有镜像仓库。&lt;/p>
&lt;pre>&lt;code># 拷贝 rancher-images.tar.gz 文件到当前目录
# 假如私有镜像仓库的访问路径为 http://172.38.40.180
./rancher-load-images.sh --image-list ./rancher-images.txt --registry 172.38.40.180
&lt;/code>&lt;/pre>
&lt;h3 id="启动-mysql">启动 mysql&lt;/h3>
&lt;p>注意修改 ${CustomRegistry} 变量为指定的私有镜像仓库的仓库名&lt;/p>
&lt;pre>&lt;code>docker run -d --name k3s-mysql --restart=always \
-v /opt/k3s-cluster/mysql/conf:/etc/mysql/conf.d \
-v /opt/k3s-cluster/mysql/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=root \
-p 3306:3306 \
${CustomRegistry}mysql:5.7.29 --default-time-zone=+8:00 \
--character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci \
--explicit_defaults_for_timestamp=true --lower_case_table_names=1 --max_allowed_packet=128M
docker run -d --name k3s-mysql --restart=always \
-v /opt/k3s-cluster/mysql/conf:/etc/mysql/conf.d \
-v /opt/k3s-cluster/mysql/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=root \
-p 3306:3306 ${CustomRegistry}/mysql:5.7.29 --default-time-zone=+8:00
&lt;/code>&lt;/pre>
&lt;h3 id="部署-k3s">部署 k3s&lt;/h3>
&lt;p>准备部署环境
需要 k3s、k3s-airgap-images-amd64.tar、install.sh 文件，拷贝到同一个目录中。并在需要部署 k3s 节点的设备上执行如下命令。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 将下载好的k3s镜像包放到指定目录中，k3s 启动时直接使用该目录的镜像压缩包，加载并启动容器。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir -p /var/lib/rancher/k3s/agent/images/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp ./k3s-airgap-images-amd64.tar /var/lib/rancher/k3s/agent/images/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 将二进制文件放在每个节点的 /usr/local/bin 目录中。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chmod &lt;span style="color:#ae81ff">755&lt;/span> ./k3s &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> cp ./k3s /usr/local/bin/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 拷贝 helm 二进制文件到 /usr/local/bin 目录下&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chmod &lt;span style="color:#ae81ff">755&lt;/span> ./helm &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> cp ./helm /usr/local/bin
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 离线安装脚本放在任意路径下。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mv ./k3s-install.sh ./install.sh &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> chmod &lt;span style="color:#ae81ff">755&lt;/span> install.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 准备 k3s containerd 操作私有镜像仓库的配置文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir -p /etc/rancher/k3s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cat &amp;gt; /etc/rancher/k3s/registries.yaml &lt;span style="color:#e6db74">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">mirrors:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> registry-test.ehualu.com:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> endpoint:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> - &amp;#34;http://172.38.40.180&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">configs:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> &amp;#34;registry-test.ehualu.com&amp;#34;:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> auth:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> username: admin
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> password: Harbor12345
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 配置解析以访问私有仓库&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cat &amp;gt;&amp;gt; /etc/hosts &lt;span style="color:#e6db74">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">172.38.40.180 registry-test.ehualu.com
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>开始部署 k3s&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 在 install.sh 所在目录执行部署命令&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>INSTALL_K3S_SKIP_DOWNLOAD&lt;span style="color:#f92672">=&lt;/span>true INSTALL_K3S_EXEC&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;server --docker --datastore-endpoint=mysql://root:root@tcp(172.38.40.212:3306)/k3s&amp;#39;&lt;/span> ./install.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note：&lt;/p>
&lt;ol>
&lt;li>若 k3s.service 无法启动，报错 msg=&amp;ldquo;starting kubernetes: preparing server: creating storage endpoint: building kine: dial tcp: unknown network tcp&amp;rdquo;，则修改 /etc/systemd/system/k3s.service 文件。
&lt;ol>
&lt;li>将其中 &amp;lsquo;&amp;ndash;datastore-endpoint=mysql://root:root@tcp(172.38.40.214:3306)/k3s&amp;rsquo; \ 这行改为 &amp;lsquo;&amp;ndash;datastore-endpoint=mysql://root:root@tcp(172.38.40.214:3306)/k3s&amp;rsquo;  \&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;p>配置 kubectl config 文件&lt;/p>
&lt;p>虽然高版本 k3s 在 /usr/local/bin/ 目录下生成了 kubectl 的软连接，但是 kubeconfig 文件依然需要拷贝到 .kube 目录中，因为 helm 也会使用。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 获取 kubectl 二进制文件并放入 /usr/local/bin/ 目录中&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 从别的机器 copy 一个对应 k3s 版本的 kubeclt 二进制文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 拷贝 kubeconfig 文件到 kubectl 配置目录，并配置命令补全功能&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir ~/.kube
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp /etc/rancher/k3s/k3s.yaml /root/.kube/config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>echo &lt;span style="color:#e6db74">&amp;#34;source &amp;lt;(kubectl completion bash)&amp;#34;&lt;/span> &amp;gt;&amp;gt; ~/.bashrc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="部署-rancher-1">部署 Rancher&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 创建所需 namespaces&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kubectl create namespace cattle-system
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>创建 Rancher 所需证书&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 创建证书&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl genrsa -out ca.key &lt;span style="color:#ae81ff">4096&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl req -x509 -new -nodes -sha512 -days &lt;span style="color:#ae81ff">36500&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -subj &lt;span style="color:#e6db74">&amp;#34;/C=CN/ST=Tianjin/L=Tianjin/O=eHualu/OU=Operations/CN=rancher.ehualu.com&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -key ca.key &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -out ca.crt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl genrsa -out ehualu.com.key &lt;span style="color:#ae81ff">4096&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl req -sha512 -new &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -subj &lt;span style="color:#e6db74">&amp;#34;/C=CN/ST=Tianjin/L=Tianjin/O=eHualu/OU=Operations/CN=rancher.ehualu.com&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -key ehualu.com.key &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -out ehualu.com.csr
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cat &amp;gt; v3.ext &lt;span style="color:#e6db74">&amp;lt;&amp;lt;-EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">authorityKeyIdentifier=keyid,issuer
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">basicConstraints=CA:FALSE
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">extendedKeyUsage = serverAuth
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">subjectAltName = @alt_names
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">[alt_names]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">DNS.1=rancher.ehualu.com
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openssl x509 -req -sha512 -days &lt;span style="color:#ae81ff">36500&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -extfile v3.ext &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -CA ca.crt -CAkey ca.key -CAcreateserial &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -in ehualu.com.csr &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -out ehualu.com.crt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 将证书添加到 secret 资源，以便让 Rancher 读取&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp ehualu.com.crt tls.crt &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> cp ehualu.com.key tls.key
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kubectl -n cattle-system create secret tls tls-rancher-ingress &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --cert&lt;span style="color:#f92672">=&lt;/span>tls.crt &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --key&lt;span style="color:#f92672">=&lt;/span>tls.key
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cp ca.crt cacerts.pem
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kubectl -n cattle-system create secret generic tls-ca &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --from-file&lt;span style="color:#f92672">=&lt;/span>cacerts.pem&lt;span style="color:#f92672">=&lt;/span>./cacerts.pem
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>部署&lt;/p>
&lt;pre>&lt;code># 通过 helm 生成部署 rancher 的 yaml。
helm template rancher ./rancher-2.4.5.tgz --output-dir . \
--namespace cattle-system \
--set hostname=rancher.ehualu.com \
--set rancherImage=registry.ehualu.com/rancher/rancher \
--set ingress.tls.source=secret \
--set privateCA=true \
--set systemDefaultRegistry=registry.ehualu.com \
--set useBundledSystemChart=true \
--set rancherImageTag=v2.4.5
# 部署 Rancher
kubectl -n cattle-system apply -R -f ./rancher
&lt;/code>&lt;/pre>
&lt;h1 id="rancher-升级">Rancher 升级&lt;/h1>
&lt;p>Rancher 本身的升级，就是 k8s 集群中服务的升级，使用 helm 更新即可，新版 pod 创建后销毁旧版 pod。&lt;/p>
&lt;p>Rancher 管理的 k8s 集群升级参考 &lt;a href="https://docs.rancher.cn/docs/rancher2/cluster-admin/upgrading-kubernetes/_index/">官方文档&lt;/a>，在 web 页面点两下就好很简单 。&lt;/p>
&lt;h1 id="rancher-清理">Rancher 清理&lt;/h1>
&lt;h2 id="清理-rancher">清理 Rancher&lt;/h2>
&lt;p>官方文档：&lt;a href="https://rancher.com/docs/rancher/v2.x/en/faq/removing-rancher/#what-if-i-don-t-want-rancher-anymore">https://rancher.com/docs/rancher/v2.x/en/faq/removing-rancher/#what-if-i-don-t-want-rancher-anymore&lt;/a>&lt;/p>
&lt;p>通过 &lt;a href="https://rancher.com/docs/rancher/v2.x/en/system-tools/#remove">rancher 系统工具的 remove 子命令&lt;/a>来清理 k8s 集群上 rancher&lt;/p>
&lt;h2 id="清理通过-rancher-创建的-k8s-集群">清理通过 Rancher 创建的 k8s 集群&lt;/h2>
&lt;p>官方文档：&lt;a href="https://docs.rancher.cn/docs/rancher2/cluster-admin/cleaning-cluster-nodes/_index/">https://docs.rancher.cn/docs/rancher2/cluster-admin/cleaning-cluster-nodes/_index/&lt;/a>&lt;/p>
&lt;p>在 Rancher web UI 上删除集群后，手动执行一些 &lt;a href="https://rancher2.docs.rancher.cn/docs/cluster-admin/cleaning-cluster-nodes/_index#%E6%89%8B%E5%8A%A8%E4%BB%8E%E9%9B%86%E7%BE%A4%E4%B8%AD%E5%88%A0%E9%99%A4-rancher-%E7%BB%84%E4%BB%B6">命令&lt;/a> 以删除在节点上生成的数据，并重启相关节点。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#！/bin/bash&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 清理所有 Docker 容器、镜像和卷：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker rm -f &lt;span style="color:#66d9ef">$(&lt;/span>docker ps -qa&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker rmi -f &lt;span style="color:#66d9ef">$(&lt;/span>docker images -q&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker volume rm &lt;span style="color:#66d9ef">$(&lt;/span>docker volume ls -q&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 卸载挂载&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> mount in &lt;span style="color:#66d9ef">$(&lt;/span>mount | grep tmpfs | grep &lt;span style="color:#e6db74">&amp;#39;/var/lib/kubelet&amp;#39;&lt;/span> | awk &lt;span style="color:#e6db74">&amp;#39;{ print $3 }&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span> /var/lib/kubelet /var/lib/rancher; &lt;span style="color:#66d9ef">do&lt;/span> umount $mount; &lt;span style="color:#66d9ef">done&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 清理目录及数据&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rm -rf /etc/ceph &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /etc/cni &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /etc/kubernetes &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /opt/cni &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /opt/rke &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /run/secrets/kubernetes.io &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /run/calico &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /run/flannel &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/lib/calico &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/lib/etcd &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/lib/cni &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/lib/kubelet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/lib/rancher/rke/log &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/log/containers &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/log/kube-audit &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/log/pods &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> /var/run/calico
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 清理 iptables 与 网络设备，需要重启设备，也可以自己手动清理&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># reboot&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: 1.3.Rancher 配置</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/1.3.Rancher-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/1.3.Rancher-%E9%85%8D%E7%BD%AE/</guid><description>
&lt;p>Rancher Server URL 的修改&lt;/p>
&lt;p>当 Rancher Server URL 变更后(比如从 40443 变到 60443)，则还需要连带修改以下几部分&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Rancher Web 页面最上面的标签，进入&lt;code>系统设置&lt;/code>，修改&lt;code>server-url&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>k8s 集群中，修改 cattle-system 名称空间中，名为&lt;code>cattle-credentials-XXX&lt;/code>的 secret 资源中的 .data.url 字段的值，这个值是用 base64 编码的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>echo -n &amp;ldquo;https://X.X.X.X:60443&amp;rdquo; | bas64 ，通过该命令获取编码后的 url，然后填入 .data.url 字段中&lt;/p>
&lt;/li>
&lt;li>
&lt;p>k8s 集群中，修改 cattle-cluster-agent-XX 和 cattle-node-agent-XX 这些 pod 的 env 参数，将其中的 CATTLE_SERVER 的值改为想要的 URL。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cattle-node-agent 在 2.5.0 版本之后没有了，就不用改了。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>导入集群的 yaml 文件位置&lt;/p>
&lt;p>打开 &lt;code>https://RancherIP/v3/cluster/集群ID/clusterregistrationtokens&lt;/code> 页面&lt;/p>
&lt;p>在 data 字段下，可以看到获取 yaml 文件的 URL，可能会有多组，一般以时间最新的那组为准。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ggn0dn/1616114779749-bd6fd7cc-32cb-41b8-9122-2047f125c4a7.png" alt="">&lt;/p></description></item><item><title>Docs: 3.1.RKE</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.1.RKE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.1.RKE/</guid><description>
&lt;h1 id="rke-介绍">RKE 介绍&lt;/h1>
&lt;p>官方文档：&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://rancher.com/docs/rke/latest/en/">https://rancher.com/docs/rke/latest/en/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://rancher2.docs.rancher.cn/docs/rke/_index/">https://rancher2.docs.rancher.cn/docs/rke/_index/&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Rancher Kubernetes Engine(RKE)&lt;/strong>，是经过 CNCF 认证的 Kubernetes 发行版，完全在 Docker 容器内运行。它适用于裸机和虚拟机。RKE 解决了安装复杂性的问题，这是 Kubernetes 社区中的常见问题。借助 RKE，Kubernetes 的安装和操作既简单又自动化，并且完全独立于所运行的操作系统和平台。只要服务器可以运行受支持的 Docker 版本，就可以使用 RKE 部署和运行 Kubernetes。&lt;/p>
&lt;p>使用 rke 工具，仅需通过一个 yaml 的配置文件以及 docker 环境，即可启动一个功能完全的 kubernetes 集群。其中所有系统组件(包括 kubelet)都是以容器的方式运行的。通过 Rancher 创建的 kubernetes 集群，就是 RKE 集群。&lt;/p>
&lt;h2 id="rke-集群与原生-k8s-集群的区别">RKE 集群与原生 K8S 集群的区别&lt;/h2>
&lt;p>RKE 与 sealos 实现高可用的方式类似。不同点是 RKE 集群的 node 节点是通过 ngxin 来连接 API Server。&lt;/p>
&lt;h1 id="rke-集群部署">RKE 集群部署&lt;/h1>
&lt;p>参考：RKE 部署与清理&lt;/p>
&lt;ul>
&lt;li>下载 rke 二进制文件。(在 github 上下载 rke 命令行工具)&lt;/li>
&lt;li>创建集群配置文件。
&lt;ul>
&lt;li>RKE 默认使用名为 cluster.yml 的集群配置文件来确定集群中应该包含哪些节点以及如何部署 Kubernetes。&lt;/li>
&lt;li>下面是一个单节点 cluster.yml 文件示例，&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat &amp;gt; cluster.yml &amp;lt;&amp;lt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 指定要部署集群的节点信息&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nodes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 指定该节点的IP&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- address: 1.2.3.4
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 指定部署集群时，所使用的用户&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> user: ubuntu
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 指定该集群的角色，controlplane运行k8s主要组件，etcd运行etcd，worker运行用户创建的非k8s主要组件的pod。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> role:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - controlplane &lt;span style="color:#75715e"># 对应 k8s master 节点&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - etcd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - worker &lt;span style="color:#75715e"># 对应 k8s node 节点&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>EOF
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>在 cluster.yml 执行 &lt;code>rke up&lt;/code> 命令&lt;/li>
&lt;/ul>
&lt;h2 id="rke-清理">RKE 清理&lt;/h2>
&lt;p>参考：&lt;a href="https://rancher.com/docs/rke/latest/en/managing-clusters/">https://rancher.com/docs/rke/latest/en/managing-clusters/&lt;/a>。&lt;/p>
&lt;p>中文：&lt;a href="https://rancher2.docs.rancher.cn/docs/rke/managing-clusters/_index">https://rancher2.docs.rancher.cn/docs/rke/managing-clusters/_index&lt;/a>&lt;/p>
&lt;p>在 cluster.yaml 文件所在目录&lt;/p>
&lt;h1 id="rke-配置">RKE 配置&lt;/h1>
&lt;p>RKE 默认通过一个名为 cluster.yml 的文件配置集群参数。可以通过 &amp;ndash;config 选项来指定其他的 yaml 格式的文件&lt;/p>
&lt;p>cluster.yml #&lt;/p></description></item><item><title>Docs: 3.3.RKE 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.3.RKE-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.3.RKE-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description/></item><item><title>Docs: 3.4.RKE yaml 示例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.4.RKE-yaml-%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.4.RKE-yaml-%E7%A4%BA%E4%BE%8B/</guid><description>
&lt;h1 id="heading">&lt;/h1>
&lt;pre>&lt;code># Cluster Config
#
answers: {}
docker_root_dir: /var/lib/docker
enable_cluster_alerting: false
enable_cluster_monitoring: false
enable_network_policy: false
local_cluster_auth_endpoint:
enabled: true
name: kubernetes-test
#
# Rancher Config
#
rancher_kubernetes_engine_config:
addon_job_timeout: 30
authentication:
strategy: x509|webhook
authorization: {}
bastion_host:
ssh_agent_auth: false
cloud_provider: {}
dns:
linear_autoscaler_params:
cores_per_replica: 128
max: 0
min: 1
nodes_per_replica: 4
prevent_single_point_failure: true
node_selector: null
nodelocal:
ip_address: ''
node_selector: null
update_strategy:
rolling_update: {}
reversecidrs: null
stubdomains: null
update_strategy:
rolling_update: {}
upstreamnameservers: null
ignore_docker_version: true
#
# # 当前仅支持nginx的ingress
# # 设置`provider: none`禁用ingress控制器
# # 通过node_selector可以指定在某些节点上运行ingress控制器，例如:
# provider: nginx
# node_selector:
# app: ingress
#
ingress:
provider: nginx
kubernetes_version: v1.18.6-rancher1-1
monitoring:
provider: metrics-server
replicas: 1
#
# # 如果您在AWS上使用calico
#
# network:
# plugin: calico
# calico_network_provider:
# cloud_provider: aws
#
# # 指定flannel网络接口
#
# network:
# plugin: flannel
# flannel_network_provider:
# iface: eth1
#
# # 指定canal网络插件的flannel网络接口
#
# network:
# plugin: canal
# canal_network_provider:
# iface: eth1
#
network:
mtu: 0
options:
flannel_backend_type: vxlan
plugin: flannel
restore:
restore: false
#
# # 自定义服务参数，仅适用于Linux环境
# services:
# kube-api:
# service_cluster_ip_range: 10.43.0.0/16
# extra_args:
# watch-cache: true
# kube-controller:
# cluster_cidr: 10.42.0.0/16
# service_cluster_ip_range: 10.43.0.0/16
# extra_args:
# # 修改每个节点子网大小(cidr掩码长度)，默认为24，可用IP为254个；23，可用IP为510个；22，可用IP为1022个；
# node-cidr-mask-size: 24
# # 控制器定时与节点通信以检查通信是否正常，周期默认5s
# node-monitor-period: '5s'
# # 当节点通信失败后，再等一段时间kubernetes判定节点为notready状态。这个时间段必须是kubelet的nodeStatusUpdateFrequency(默认10s)的N倍，其中N表示允许kubelet同步节点状态的重试次数，默认40s。
# node-monitor-grace-period: '20s'
# # 再持续通信失败一段时间后，kubernetes判定节点为unhealthy状态，默认1m0s。
# node-startup-grace-period: '30s'
# # 再持续失联一段时间，kubernetes开始迁移失联节点的Pod，默认5m0s。
# pod-eviction-timeout: '1m'
# kubelet:
# cluster_domain: cluster.local
# cluster_dns_server: 10.43.0.10
# # 扩展变量
# extra_args:
# # 与apiserver会话时的并发数，默认是10
# kube-api-burst: '30'
# # 与apiserver会话时的 QPS,默认是5
# kube-api-qps: '15'
# # 修改节点最大Pod数量
# max-pods: '250'
# # secrets和configmaps同步到Pod需要的时间，默认一分钟
# sync-frequency: '3s'
# # kubelet默认一次拉取一个镜像，设置为false可以同时拉取多个镜像，前提是存储驱动要为overlay2，对应的Docker也需要增加下载并发数
# serialize-image-pulls: false
# # 拉取镜像的最大并发数，registry-burst不能超过registry-qps ，仅当registry-qps大于0(零)时生效，(默认10)。如果registry-qps为0则不限制(默认5)。
# registry-burst: '10'
# registry-qps: '0'
# # 以下配置用于配置节点资源预留和限制
# cgroups-per-qos: 'true'
# cgroup-driver: cgroupfs
# # 以下两个参数指明为相关服务预留多少资源，仅用于调度，不做实际限制
# system-reserved: 'memory=300Mi'
# kube-reserved: 'memory=2Gi'
# enforce-node-allocatable: 'pods'
# # 硬驱逐阈值，当节点上的可用资源少于这个值时，就会触发强制驱逐。强制驱逐会强制kill掉POD，不会等POD自动退出。
# eviction-hard: 'memory.available&amp;lt;300Mi,nodefs.available&amp;lt;10%,imagefs.available&amp;lt;15%,nodefs.inodesFree&amp;lt;5%'
# # 软驱逐阈值
# ## 以下四个参数配套使用，当节点上的可用资源少于这个值时但大于硬驱逐阈值时候，会等待eviction-soft-grace-period设置的时长；
# ## 等待中每10s检查一次，当最后一次检查还触发了软驱逐阈值就会开始驱逐，驱逐不会直接Kill POD，先发送停止信号给POD，然后等待eviction-max-pod-grace-period设置的时长；
# ## 在eviction-max-pod-grace-period时长之后，如果POD还未退出则发送强制kill POD
# eviction-soft: 'memory.available&amp;lt;500Mi,nodefs.available&amp;lt;50%,imagefs.available&amp;lt;50%,nodefs.inodesFree&amp;lt;10%'
# eviction-soft-grace-period: 'memory.available=1m30s'
# eviction-max-pod-grace-period: '30'
# ## 当处于驱逐状态的节点不可调度，当节点恢复正常状态后
# eviction-pressure-transition-period: '5m0s'
# extra_binds:
# - &amp;quot;/usr/libexec/kubernetes/kubelet-plugins:/usr/libexec/kubernetes/kubelet-plugins&amp;quot;
# - &amp;quot;/etc/iscsi:/etc/iscsi&amp;quot;
# - &amp;quot;/sbin/iscsiadm:/sbin/iscsiadm&amp;quot;
# etcd:
# # 修改空间配额为$((4*1024*1024*1024))，默认2G,最大8G
# extra_args:
# quota-backend-bytes: '4294967296'
# auto-compaction-retention: 240 #(单位小时)
# kubeproxy:
# extra_args:
# # 默认使用iptables进行数据转发
# proxy-mode: &amp;quot;&amp;quot; # 如果要启用ipvs，则此处设置为`ipvs`
#
services:
etcd:
backup_config:
enabled: true
interval_hours: 12
retention: 6
safe_timestamp: false
creation: 12h
extra_args:
election-timeout: '5000'
heartbeat-interval: '500'
listen-metrics-urls: 'http://0.0.0.0:2381'
gid: 0
retention: 72h
snapshot: false
uid: 0
kube-api:
always_pull_images: false
pod_security_policy: false
service_node_port_range: 30000-60000
kube-controller: {}
kubelet:
extra_args:
cgroup-driver: systemd
fail_swap_on: false
generate_serving_certificate: false
kubeproxy:
extra_args:
proxy-mode: ipvs
scheduler: {}
ssh_agent_auth: false
upgrade_strategy:
drain: false
max_unavailable_controlplane: '1'
max_unavailable_worker: 10%%
node_drain_input:
delete_local_data: false
force: false
grace_period: -1
ignore_daemon_sets: true
timeout: 120
scheduled_cluster_scan:
enabled: false
scan_config:
cis_scan_config:
debug_master: false
debug_worker: false
override_benchmark_version: rke-cis-1.4
profile: permissive
schedule_config:
cron_schedule: 0 0 * * *
retention: 24
&lt;/code>&lt;/pre></description></item><item><title>Docs: 3.5.RKE 部署时输出的信息</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.5.RKE-%E9%83%A8%E7%BD%B2%E6%97%B6%E8%BE%93%E5%87%BA%E7%9A%84%E4%BF%A1%E6%81%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/3.5.RKE-%E9%83%A8%E7%BD%B2%E6%97%B6%E8%BE%93%E5%87%BA%E7%9A%84%E4%BF%A1%E6%81%AF/</guid><description>
&lt;h1 id="rke-部署时输出的信息">RKE 部署时输出的信息&lt;/h1>
&lt;pre>&lt;code>[root@chinese-test rke]# rke up
INFO[0000] Running RKE version: v1.1.4
INFO[0000] Initiating Kubernetes cluster
INFO[0000] [dialer] Setup tunnel for host [172.38.40.214]
INFO[0000] Checking if container [cluster-state-deployer] is running on host [172.38.40.214], try #1
INFO[0000] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0002] Starting container [cluster-state-deployer] on host [172.38.40.214], try #1
INFO[0003] [state] Successfully started [cluster-state-deployer] container on host [172.38.40.214]
INFO[0003] [certificates] Generating CA kubernetes certificates
INFO[0004] [certificates] Generating Kubernetes API server aggregation layer requestheader client CA certificates
INFO[0004] [certificates] GenerateServingCertificate is disabled, checking if there are unused kubelet certificates
INFO[0004] [certificates] Generating Kubernetes API server certificates
INFO[0005] [certificates] Generating Service account token key
INFO[0005] [certificates] Generating Kube Controller certificates
INFO[0005] [certificates] Generating Kube Scheduler certificates
INFO[0005] [certificates] Generating Kube Proxy certificates
INFO[0006] [certificates] Generating Node certificate
INFO[0006] [certificates] Generating admin certificates and kubeconfig
INFO[0006] [certificates] Generating Kubernetes API server proxy client certificates
INFO[0006] [certificates] Generating kube-etcd-172-38-40-214 certificate and key
INFO[0006] Successfully Deployed state file at [./cluster.rkestate]
INFO[0006] Building Kubernetes cluster
INFO[0006] [dialer] Setup tunnel for host [172.38.40.214]
INFO[0006] [network] Deploying port listener containers
INFO[0006] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0008] Starting container [rke-etcd-port-listener] on host [172.38.40.214], try #1
INFO[0008] [network] Successfully started [rke-etcd-port-listener] container on host [172.38.40.214]
INFO[0008] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0009] Starting container [rke-cp-port-listener] on host [172.38.40.214], try #1
INFO[0009] [network] Successfully started [rke-cp-port-listener] container on host [172.38.40.214]
INFO[0009] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0010] Starting container [rke-worker-port-listener] on host [172.38.40.214], try #1
INFO[0011] [network] Successfully started [rke-worker-port-listener] container on host [172.38.40.214]
INFO[0011] [network] Port listener containers deployed successfully
INFO[0011] [network] Running control plane -&amp;gt; etcd port checks
INFO[0011] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0011] Starting container [rke-port-checker] on host [172.38.40.214], try #1
INFO[0012] [network] Successfully started [rke-port-checker] container on host [172.38.40.214]
INFO[0012] Removing container [rke-port-checker] on host [172.38.40.214], try #1
INFO[0012] [network] Running control plane -&amp;gt; worker port checks
INFO[0012] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0012] Starting container [rke-port-checker] on host [172.38.40.214], try #1
INFO[0013] [network] Successfully started [rke-port-checker] container on host [172.38.40.214]
INFO[0013] Removing container [rke-port-checker] on host [172.38.40.214], try #1
INFO[0013] [network] Running workers -&amp;gt; control plane port checks
INFO[0013] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0013] Starting container [rke-port-checker] on host [172.38.40.214], try #1
INFO[0014] [network] Successfully started [rke-port-checker] container on host [172.38.40.214]
INFO[0014] Removing container [rke-port-checker] on host [172.38.40.214], try #1
INFO[0014] [network] Checking KubeAPI port Control Plane hosts
INFO[0014] [network] Removing port listener containers
INFO[0014] Removing container [rke-etcd-port-listener] on host [172.38.40.214], try #1
INFO[0015] [remove/rke-etcd-port-listener] Successfully removed container on host [172.38.40.214]
INFO[0015] Removing container [rke-cp-port-listener] on host [172.38.40.214], try #1
INFO[0015] [remove/rke-cp-port-listener] Successfully removed container on host [172.38.40.214]
INFO[0015] Removing container [rke-worker-port-listener] on host [172.38.40.214], try #1
INFO[0016] [remove/rke-worker-port-listener] Successfully removed container on host [172.38.40.214]
INFO[0016] [network] Port listener containers removed successfully
INFO[0016] [certificates] Deploying kubernetes certificates to Cluster nodes
INFO[0016] Checking if container [cert-deployer] is running on host [172.38.40.214], try #1
INFO[0016] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0016] Starting container [cert-deployer] on host [172.38.40.214], try #1
INFO[0017] Checking if container [cert-deployer] is running on host [172.38.40.214], try #1
INFO[0022] Checking if container [cert-deployer] is running on host [172.38.40.214], try #1
INFO[0022] Removing container [cert-deployer] on host [172.38.40.214], try #1
INFO[0022] [reconcile] Rebuilding and updating local kube config
INFO[0022] Successfully Deployed local admin kubeconfig at [./kube_config_cluster.yml]
INFO[0022] [certificates] Successfully deployed kubernetes certificates to Cluster nodes
INFO[0022] [file-deploy] Deploying file [/etc/kubernetes/audit-policy.yaml] to node [172.38.40.214]
INFO[0022] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0022] Starting container [file-deployer] on host [172.38.40.214], try #1
INFO[0023] Successfully started [file-deployer] container on host [172.38.40.214]
INFO[0023] Waiting for [file-deployer] container to exit on host [172.38.40.214]
INFO[0023] Waiting for [file-deployer] container to exit on host [172.38.40.214]
INFO[0023] Removing container [file-deployer] on host [172.38.40.214], try #1
INFO[0023] [remove/file-deployer] Successfully removed container on host [172.38.40.214]
INFO[0023] [/etc/kubernetes/audit-policy.yaml] Successfully deployed audit policy file to Cluster control nodes
INFO[0023] [reconcile] Reconciling cluster state
INFO[0023] [reconcile] This is newly generated cluster
INFO[0023] Pre-pulling kubernetes images
INFO[0023] Image [rancher/hyperkube:v1.18.6-rancher1] exists on host [172.38.40.214]
INFO[0023] Kubernetes images pulled successfully
INFO[0023] [etcd] Building up etcd plane..
INFO[0023] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0024] Starting container [etcd-fix-perm] on host [172.38.40.214], try #1
INFO[0024] Successfully started [etcd-fix-perm] container on host [172.38.40.214]
INFO[0024] Waiting for [etcd-fix-perm] container to exit on host [172.38.40.214]
INFO[0024] Waiting for [etcd-fix-perm] container to exit on host [172.38.40.214]
INFO[0024] Container [etcd-fix-perm] is still running on host [172.38.40.214]
INFO[0025] Waiting for [etcd-fix-perm] container to exit on host [172.38.40.214]
INFO[0025] Removing container [etcd-fix-perm] on host [172.38.40.214], try #1
INFO[0025] [remove/etcd-fix-perm] Successfully removed container on host [172.38.40.214]
INFO[0025] Image [rancher/coreos-etcd:v3.4.3-rancher1] exists on host [172.38.40.214]
INFO[0026] Starting container [etcd] on host [172.38.40.214], try #1
INFO[0026] [etcd] Successfully started [etcd] container on host [172.38.40.214]
INFO[0026] [etcd] Running rolling snapshot container [etcd-snapshot-once] on host [172.38.40.214]
INFO[0026] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0027] Starting container [etcd-rolling-snapshots] on host [172.38.40.214], try #1
INFO[0027] [etcd] Successfully started [etcd-rolling-snapshots] container on host [172.38.40.214]
INFO[0032] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0033] Starting container [rke-bundle-cert] on host [172.38.40.214], try #1
INFO[0034] [certificates] Successfully started [rke-bundle-cert] container on host [172.38.40.214]
INFO[0034] Waiting for [rke-bundle-cert] container to exit on host [172.38.40.214]
INFO[0034] Container [rke-bundle-cert] is still running on host [172.38.40.214]
INFO[0035] Waiting for [rke-bundle-cert] container to exit on host [172.38.40.214]
INFO[0035] [certificates] successfully saved certificate bundle [/opt/rke/etcd-snapshots//pki.bundle.tar.gz] on host [172.38.40.214]
INFO[0035] Removing container [rke-bundle-cert] on host [172.38.40.214], try #1
INFO[0035] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0035] Starting container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0036] [etcd] Successfully started [rke-log-linker] container on host [172.38.40.214]
INFO[0036] Removing container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0036] [remove/rke-log-linker] Successfully removed container on host [172.38.40.214]
INFO[0036] [etcd] Successfully started etcd plane.. Checking etcd cluster health
INFO[0036] [controlplane] Building up Controller Plane..
INFO[0036] Checking if container [service-sidekick] is running on host [172.38.40.214], try #1
INFO[0036] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0037] Image [rancher/hyperkube:v1.18.6-rancher1] exists on host [172.38.40.214]
INFO[0037] Starting container [kube-apiserver] on host [172.38.40.214], try #1
INFO[0038] [controlplane] Successfully started [kube-apiserver] container on host [172.38.40.214]
INFO[0038] [healthcheck] Start Healthcheck on service [kube-apiserver] on host [172.38.40.214]
INFO[0048] [healthcheck] service [kube-apiserver] on host [172.38.40.214] is healthy
INFO[0048] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0049] Starting container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0050] [controlplane] Successfully started [rke-log-linker] container on host [172.38.40.214]
INFO[0050] Removing container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0050] [remove/rke-log-linker] Successfully removed container on host [172.38.40.214]
INFO[0050] Image [rancher/hyperkube:v1.18.6-rancher1] exists on host [172.38.40.214]
INFO[0050] Starting container [kube-controller-manager] on host [172.38.40.214], try #1
INFO[0050] [controlplane] Successfully started [kube-controller-manager] container on host [172.38.40.214]
INFO[0050] [healthcheck] Start Healthcheck on service [kube-controller-manager] on host [172.38.40.214]
INFO[0056] [healthcheck] service [kube-controller-manager] on host [172.38.40.214] is healthy
INFO[0056] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0056] Starting container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0057] [controlplane] Successfully started [rke-log-linker] container on host [172.38.40.214]
INFO[0057] Removing container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0058] [remove/rke-log-linker] Successfully removed container on host [172.38.40.214]
INFO[0058] Image [rancher/hyperkube:v1.18.6-rancher1] exists on host [172.38.40.214]
INFO[0058] Starting container [kube-scheduler] on host [172.38.40.214], try #1
INFO[0059] [controlplane] Successfully started [kube-scheduler] container on host [172.38.40.214]
INFO[0059] [healthcheck] Start Healthcheck on service [kube-scheduler] on host [172.38.40.214]
INFO[0064] [healthcheck] service [kube-scheduler] on host [172.38.40.214] is healthy
INFO[0064] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0064] Starting container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0065] [controlplane] Successfully started [rke-log-linker] container on host [172.38.40.214]
INFO[0066] Removing container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0066] [remove/rke-log-linker] Successfully removed container on host [172.38.40.214]
INFO[0066] [controlplane] Successfully started Controller Plane..
INFO[0066] [authz] Creating rke-job-deployer ServiceAccount
INFO[0066] [authz] rke-job-deployer ServiceAccount created successfully
INFO[0066] [authz] Creating system:node ClusterRoleBinding
INFO[0066] [authz] system:node ClusterRoleBinding created successfully
INFO[0066] [authz] Creating kube-apiserver proxy ClusterRole and ClusterRoleBinding
INFO[0066] [authz] kube-apiserver proxy ClusterRole and ClusterRoleBinding created successfully
INFO[0066] Successfully Deployed state file at [./cluster.rkestate]
INFO[0066] [state] Saving full cluster state to Kubernetes
INFO[0066] [state] Successfully Saved full cluster state to Kubernetes ConfigMap: full-cluster-state
INFO[0066] [worker] Building up Worker Plane..
INFO[0066] Checking if container [service-sidekick] is running on host [172.38.40.214], try #1
INFO[0066] [sidekick] Sidekick container already created on host [172.38.40.214]
INFO[0066] Image [rancher/hyperkube:v1.18.6-rancher1] exists on host [172.38.40.214]
INFO[0066] Starting container [kubelet] on host [172.38.40.214], try #1
INFO[0067] [worker] Successfully started [kubelet] container on host [172.38.40.214]
INFO[0067] [healthcheck] Start Healthcheck on service [kubelet] on host [172.38.40.214]
INFO[0077] [healthcheck] service [kubelet] on host [172.38.40.214] is healthy
INFO[0077] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0078] Starting container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0079] [worker] Successfully started [rke-log-linker] container on host [172.38.40.214]
INFO[0080] Removing container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0080] [remove/rke-log-linker] Successfully removed container on host [172.38.40.214]
INFO[0080] Image [rancher/hyperkube:v1.18.6-rancher1] exists on host [172.38.40.214]
INFO[0080] Starting container [kube-proxy] on host [172.38.40.214], try #1
INFO[0081] [worker] Successfully started [kube-proxy] container on host [172.38.40.214]
INFO[0081] [healthcheck] Start Healthcheck on service [kube-proxy] on host [172.38.40.214]
INFO[0086] [healthcheck] service [kube-proxy] on host [172.38.40.214] is healthy
INFO[0086] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0087] Starting container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0088] [worker] Successfully started [rke-log-linker] container on host [172.38.40.214]
INFO[0088] Removing container [rke-log-linker] on host [172.38.40.214], try #1
INFO[0088] [remove/rke-log-linker] Successfully removed container on host [172.38.40.214]
INFO[0088] [worker] Successfully started Worker Plane..
INFO[0088] Image [rancher/rke-tools:v0.1.59] exists on host [172.38.40.214]
INFO[0089] Starting container [rke-log-cleaner] on host [172.38.40.214], try #1
INFO[0090] [cleanup] Successfully started [rke-log-cleaner] container on host [172.38.40.214]
INFO[0090] Removing container [rke-log-cleaner] on host [172.38.40.214], try #1
INFO[0091] [remove/rke-log-cleaner] Successfully removed container on host [172.38.40.214]
INFO[0091] [sync] Syncing nodes Labels and Taints
INFO[0091] [sync] Successfully synced nodes Labels and Taints
INFO[0091] [network] Setting up network plugin: flannel
INFO[0091] [addons] Saving ConfigMap for addon rke-network-plugin to Kubernetes
INFO[0091] [addons] Successfully saved ConfigMap for addon rke-network-plugin to Kubernetes
INFO[0091] [addons] Executing deploy job rke-network-plugin
INFO[0101] [addons] Setting up coredns
INFO[0101] [addons] Saving ConfigMap for addon rke-coredns-addon to Kubernetes
INFO[0101] [addons] Successfully saved ConfigMap for addon rke-coredns-addon to Kubernetes
INFO[0101] [addons] Executing deploy job rke-coredns-addon
INFO[0112] [addons] CoreDNS deployed successfully
INFO[0112] [dns] DNS provider coredns deployed successfully
INFO[0112] [addons] Setting up Metrics Server
INFO[0112] [addons] Saving ConfigMap for addon rke-metrics-addon to Kubernetes
INFO[0112] [addons] Successfully saved ConfigMap for addon rke-metrics-addon to Kubernetes
INFO[0112] [addons] Executing deploy job rke-metrics-addon
INFO[0122] [addons] Metrics Server deployed successfully
INFO[0122] [ingress] Setting up nginx ingress controller
INFO[0122] [addons] Saving ConfigMap for addon rke-ingress-controller to Kubernetes
INFO[0122] [addons] Successfully saved ConfigMap for addon rke-ingress-controller to Kubernetes
INFO[0122] [addons] Executing deploy job rke-ingress-controller
INFO[0137] [ingress] ingress controller nginx deployed successfully
INFO[0137] [addons] Setting up user addons
INFO[0137] [addons] no user addons defined
INFO[0137] Finished building Kubernetes cluster successfully
&lt;/code>&lt;/pre></description></item><item><title>Docs: Rancher</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher/</guid><description/></item><item><title>Docs: 问题实例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</guid><description>
&lt;h1 id="待解决问题">待解决问题&lt;/h1>
&lt;p>RKE 问题&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Centos 启动 RKE 集群还存在用户权限问题，无法使用 root 安装。详见：&lt;a href="https://rancher2.docs.rancher.cn/docs/rke/os/_index#rhel%25E3%2580%2581oel%25E3%2580%2581centos">https://rancher2.docs.rancher.cn/docs/rke/os/_index#rhel%E3%80%81oel%E3%80%81centos&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>kube-proxy、kube-scheduler、kube-controller-manager、kube-apiserver、etcd 这些集群组件，无守护，不是通过 kubelet 的静态 pod 拉起。如果容器被停掉，则无法自动恢复。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ube-scheduler、kube-controller-manager 的 https 端口无法使用，证书有问题。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>K3S 问题&lt;/p>
&lt;ol>
&lt;li>
&lt;p>k3s 中的 kubelet 无法使用 systemd 后端，k3s 官方人员吐槽 k8s 官方使用 systemd 后端。详见：&lt;a href="https://github.com/rancher/k3s/issues/797">https://github.com/rancher/k3s/issues/797&lt;/a>&lt;/p>
&lt;ol>
&lt;li>吐槽详见：&lt;a href="https://github.com/rancher/k3s/issues/797#issuecomment-529139150">https://github.com/rancher/k3s/issues/797#issuecomment-529139150&lt;/a>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;p>Rancher 问题&lt;/p>
&lt;ol>
&lt;li>
&lt;p>rancher 崩溃或数据丢失，会导致的问题&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过 rancher 创建的集群无法添加节点，无法升级，所有关于 kubeadm 可以使用的东西都无法使用。就算通过 kubelet 手动添加也不行。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>rancher 部署在原生 k8s 集群上入侵行太强，会创建几十个 CRD。当删除的时候，还无法正常删除，只能删除其垃圾回收机制中的 finalizers 字段才可以。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>rancher 会为集群中每个 namespace 添加注释以及 finalizers，包括 kube-system，issuer 详见 &lt;a href="https://github.com/rancher/rancher/issues/14715">#14715&lt;/a>。如果想要自己删除 ns，则会被卡住，因为 ns 在等待 &lt;code>controller.cattle.io/namespace-auth&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>导入集群清理 rancher 不干净，留下非常非常多的 rolebing、clusterrole、clusterbinding，很多都是操作 ns 所需的。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h1 id="agent-无法连接-rancher-server">Agent 无法连接 Rancher server&lt;/h1>
&lt;p>&lt;a href="https://rancher2.docs.rancher.cn/docs/faq/install/_index#agent-%25E6%2597%25A0%25E6%25B3%2595%25E8%25BF%259E%25E6%258E%25A5-rancher-server">https://rancher2.docs.rancher.cn/docs/faq/install/_index#agent-%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5-rancher-server&lt;/a>&lt;/p>
&lt;p>ERROR: &lt;a href="https://x.x.x.x/ping">https://x.x.x.x/ping&lt;/a> is not accessible (Failed to connect to x.x.x.x port 443: Connection timed out)&lt;/p>
&lt;ol>
&lt;li>ERROR: &lt;a href="https://x.x.x.x/ping">https://x.x.x.x/ping&lt;/a> is not accessible (Failed to connect to x.x.x.x port 443: Connection timed out)&lt;/li>
&lt;/ol>
&lt;p>在 cattle-cluster-agent 或 cattle-node-agent 中出现以上错误，代表 agent 无法连接到 rancher server，请按照以下步骤排查网络连接：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>从 agent 宿主机访问 rancher server 的 443 端口，例如：telnet x.x.x.x 443&lt;/p>
&lt;/li>
&lt;li>
&lt;p>从容器内访问 rancher server 的 443 端口，例如：telnet x.x.x.x 443&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>ERROR: &lt;a href="https://rancher.my.org/ping">https://rancher.my.org/ping&lt;/a> is not accessible (Could not resolve host: rancher.my.org)&lt;/p>
&lt;ol>
&lt;li>ERROR: &lt;a href="https://rancher.my.org/ping">https://rancher.my.org/ping&lt;/a> is not accessible (Could not resolve host: rancher.my.org)&lt;/li>
&lt;/ol>
&lt;p>在 cattle-cluster-agent 或 cattle-node-agent 中出现以上错误，代表 agent 无法通过域名解析到 rancher server，请按照以下步骤进行排查网络连接：&lt;/p>
&lt;ul>
&lt;li>从容器内访问通过域名访问 rancher server，例如：ping rancher.my.org&lt;/li>
&lt;/ul>
&lt;p>这个问题在内网并且无 DNS 服务器的环境下非常常见，即使在/etc/hosts 文件中配置了映射关系也无法解决，这是因为 cattle-node-agent 从宿主机的/etc/resolv.conf 中继承 nameserver 用作 dns 服务器。&lt;/p>
&lt;p>所以要解决这个问题，有两个办法：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>可以在环境中搭建一个 dns 服务器，配置正确的域名和 IP 的对应关系，然后将每个节点的 nameserver 指向这个 dns 服务器。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用 HostAliases，向 pod 内添加 hosts 条目：&lt;/p>
&lt;p>kubectl -n cattle-system patch deployments cattle-cluster-agent &amp;ndash;patch &amp;lsquo;{
&amp;ldquo;spec&amp;rdquo;: {
&amp;ldquo;template&amp;rdquo;: {
&amp;ldquo;spec&amp;rdquo;: {
&amp;ldquo;hostAliases&amp;rdquo;: [
{
&amp;ldquo;hostnames&amp;rdquo;:
[
&amp;ldquo;{{ rancher_server_hostname }}&amp;rdquo;
],
&amp;ldquo;ip&amp;rdquo;: &amp;ldquo;{{ rancher_server_ip }}&amp;rdquo;
}
]
}
}
}
}&amp;rsquo;&lt;/p>
&lt;p>kubectl -n cattle-system patch daemonsets cattle-node-agent &amp;ndash;patch &amp;lsquo;{
&amp;ldquo;spec&amp;rdquo;: {
&amp;ldquo;template&amp;rdquo;: {
&amp;ldquo;spec&amp;rdquo;: {
&amp;ldquo;hostAliases&amp;rdquo;: [
{
&amp;ldquo;hostnames&amp;rdquo;:
[
&amp;ldquo;{{ rancher_server_hostname }}&amp;rdquo;
],
&amp;ldquo;ip&amp;rdquo;: &amp;ldquo;{{ rancher_server_ip }}&amp;rdquo;
}
]
}
}
}
}&amp;rsquo;&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h1 id="githubcomranchernormancontrollergeneric_controllergo237-failed-to-list-v1limitrange-get-https109601443apiv1limitrangesresourceversion4897timeout30s-context-deadline-exceeded">github.com/rancher/norman/controller/generic_controller.go:237: Failed to list *v1.LimitRange: Get &lt;a href="https://10.96.0.1:443/api/v1/limitranges?resourceVersion=4897&amp;amp;timeout=30s:">https://10.96.0.1:443/api/v1/limitranges?resourceVersion=4897&amp;amp;timeout=30s:&lt;/a> context deadline exceeded&lt;/h1>
&lt;p>&lt;a href="https://github.com/rancher/rancher/issues/27736">https://github.com/rancher/rancher/issues/27736&lt;/a>&lt;/p></description></item></channel></rss>