<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 4.Controller(控制器)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/</link><description>Recent content in 4.Controller(控制器) on 断念梦</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 4.Controller(控制器)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/architecture/controller/">官方文档,概念-集群架构-控制器&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Controller 是 Kubernetes 的大脑&lt;/p>
&lt;p>在机器人和自动化技术中，控制环是一个控制系统状态不终止的循环。&lt;/p>
&lt;p>比如：房间里的温度自动调节器，当我设置了温度，告诉温度调节器我的期望状态。房间的实际温度是当前状态。温度自动调节器就会让当前状态一直去接近期望状态。&lt;/p>
&lt;p>kubernetes 的 Controller 就是这样一种东西，通过 apiserver 监控集群的期望状态，并致力于将当前状态转变为期望状态。而 controller 是一个更高层次的抽象概念，指代多种具有 controller 功能的资源，比如 deployment、statefulset 等等。&lt;/p>
&lt;p>可以用一段 Go 语言风格的伪代码，来描述这个控制循环：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">实际状态&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">获取集群中对象&lt;/span> &lt;span style="color:#a6e22e">X&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">的实际状态（&lt;/span>&lt;span style="color:#a6e22e">Actual&lt;/span> &lt;span style="color:#a6e22e">State&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">）&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">期望状态&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">获取集群中对象&lt;/span> &lt;span style="color:#a6e22e">X&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">的期望状态（&lt;/span>&lt;span style="color:#a6e22e">Desired&lt;/span> &lt;span style="color:#a6e22e">State&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">）&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">实际状态&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">期望状态&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">什么都不做&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">执行编排动作，将实际状态调整为期望状态&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在具体实现中，实际状态一般来自于 kubernetes 集群本身，e.g.kubelet 收集所在节点上容器状态和节点状态。而期望状态，一般来自于用户提交的 YAMl 文件。&lt;/p>
&lt;p>以 Deployment 这种控制器为例，简单描述一下它对控制器模型的实现：&lt;/p>
&lt;ul>
&lt;li>控制器从 Etcd 中获取到所有携带了“app: nginx”标签的 Pod，然后统计它们的数量，这就是实际状态；&lt;/li>
&lt;li>用户提交的 yaml 文件中 Replicas 字段的值就是期望状态(提交的 yaml 也会保存到 etcd 中)；&lt;/li>
&lt;li>控制器将两个状态做比较，然后根据比较结果，确定是创建 Pod，还是删除已有的 Pod 。&lt;/li>
&lt;/ul>
&lt;p>这个对比的操作通常被叫作 &lt;strong>Reconcile(调和)&lt;/strong>。这个调谐的过程，则被称作 &lt;strong>Reconcile Loop(调和循环)&lt;/strong> 或者 &lt;strong>Sync Loop(同步循环)&lt;/strong>。这些词其实都代表一个东西：&lt;strong>控制循环&lt;/strong>。&lt;/p>
&lt;blockquote>
&lt;p>Reconcile 这词儿用的还挺有意思，Reconcile 是调和、使协调一致的概念，就是让具有矛盾的两方和解~这就好比控制器和被控制者，当被控制者不符合控制者预期状态时，这就相当于两者有矛盾了~~Reconcile 就会让矛盾消失
Reconcile 是一个动词，表示一个过程，在 k8s 中还有一个对应的名词 Reconciliation，用以表示“确保系统的实际状态与期望状态一致”&lt;/p>
&lt;/blockquote>
&lt;p>也可以这么说：控制器，使用一种 API 对象管理另一种 API 对象的工具。控制器这个对象本身负责定义被管理对象的期望状态(e.g.deployment 里的 replicas: 2 这个字段)；而被控制对象的定义，则来自于一个“模板”(e.g.deployment 里的 template 字段)。&lt;/p>
&lt;p>可以看到，deployment 资源中 template 字段里的内容跟一个标准的 pod 对象的定义丝毫不差。而所有被这个 deployment 管理的 pod 对象，都是根据 template 字段的内容创建出来的。&lt;/p>
&lt;p>像 Deployment 定义的 template 字段，在 Kubernetes 项目中有一个专有的名字，叫作 PodTemplate（Pod 模板）。更有意思的是，我们还会看到其他类型的对象模板，比如 Volume 的模板。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/udaias/1617283643337-37faf2ac-fcaa-4f18-a119-c1099af0c765.png" alt="image.png">&lt;/p>
&lt;p>如上图所示，类似 Deployment 这样的一个控制器，实际上都是由上半部分的控制器定义（包括期望状态），加上下半部分的被控制对象的模板组成的。&lt;/p>
&lt;p>这就是为什么，在所有 API 对象的 Metadata 里，都有一个字段叫作 ownerReference，用于保存当前这个 API 对象的拥有者（Owner）的信息。&lt;/p>
&lt;p>各种 Controller 是 kubernetes 的大脑，通过 apiserver 监控整个集群的状态，作为集群内部的管理控制中心，负责集群内的 Node、Pod 副本、服务端点（Endpoint）、命名空间（Namespace）、服务账号（ServiceAccount）、资源定额（ResourceQuota）等资源的管理。比如，当某个 Node 意外宕机时，Controller 会及时发现并执行自动化修复流程，comtroller 会确保集群始终处于预期的工作状态。&lt;/p>
&lt;p>Note：严格来说 Pod 并不是由 controller 直接管理的，而是通过 deployment 之类的 controller 来管理 Pod 或者由 kubelet 来管理 pod。kubelet 自身也具备控制循环的功能。&lt;/p>
&lt;h2 id="用白话来说">用白话来说&lt;/h2>
&lt;p>kubernetes 有各种各样的资源，每个资源都有其自己的各种定义(比如一个 pod 资源里有 image、name、volumemount 等等)，那么这些定义所能实现的功能，又是谁来决定的呢？答案就是 controller&lt;/p>
&lt;p>资源的定义只是提供了 JSON 格式的数据，至于如何执行这些数据，则是 controller 这个程序的作用。&lt;/p>
&lt;p>例如 deployment 中定义了一个 replicas，该 replicas 有一个值，那么系统是怎么知道 replicas:VALUE 这一串字符串是干什么用的呢，这就是 controller 的作用，controller 会告诉 k8s 集群，这一段字符串的含义是该 deployment 下的 pod 应该具有多少个副本。除了描述该字段的含义以外，还会控制 deployment 下的 pod 向着期望的值来转变，当 pod 的副本数量多余或者少于设定的值时，controller 都会删除或者创建相应的 pod 来满足指定的值。&lt;/p>
&lt;p>而各种 controller 内各个字段的含义，则是靠 kube-controller-manager 这个程序来管理并定义其中各个字段的含义。&lt;/p>
&lt;p>总结：
这就是 kubernetes 的核心思想，编排也是依靠 controller 来实现的。&lt;/p>
&lt;h1 id="控制器的实现">控制器的实现&lt;/h1>
&lt;p>&lt;a href="https://www.yuque.com/go/doc/33166804">&lt;strong>kube-controller-manager&lt;/strong>&lt;/a> 是实现 Kubernetes 控制器功能的程序。&lt;/p>
&lt;p>可以在 &lt;a href="https://github.com/kubernetes/kubernetes/tree/master/pkg/controller">Controller 代码&lt;/a>中，找到所有可用的控制器。所以，从逻辑上来说，每个控制器都应该是一个单独的进程，但是为了降低复杂性，这些控制器都被编译到同一个执行文件中，并在同一个进程中运行。所以，这些控制器的集合体，就称为 **Controller Manager(控制器管理器)，**所以实现控制器功能的组件的名称就叫 &lt;strong>kube-controller-manager&lt;/strong>。&lt;/p>
&lt;h1 id="各种控制器介绍">各种控制器介绍&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>官方文档：&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/">https://kubernetes.io/docs/concepts/workloads/controllers/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Controller 包括以下这些：不同的 controller 管理不同的资源。&lt;/p>
&lt;ul>
&lt;li>Replication Controller # 副本控制器，主要用于保障 pod 的副本数量(副本就是复制)
&lt;ul>
&lt;li>Deployment 可以管理 Pod 的多个副本，并确保 Pod 按照期望的状态运行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Node Controller # 节点控制器，用于控制节点相关信息，比如该节点的 cidr 信息等。&lt;/li>
&lt;li>CronJob Controller&lt;/li>
&lt;li>Daemon Controller&lt;/li>
&lt;li>Deployment Controller # 部署控制器，管理 Deployment 资源&lt;/li>
&lt;li>Endpoint Controller # 端点控制器&lt;/li>
&lt;li>Garbage Collector&lt;/li>
&lt;li>Namespace Controller # 管理 Namespace 资源。&lt;/li>
&lt;li>Job Controller&lt;/li>
&lt;li>Pod AutoScaler # i.e.HPA，用于 pod 自动伸缩&lt;/li>
&lt;li>RelicaSet&lt;/li>
&lt;li>Service Controller&lt;/li>
&lt;li>ServiceAccount Controller # 服务账户控制器&lt;/li>
&lt;li>StatefulSet Controller&lt;/li>
&lt;li>Volume Controller # 卷控制器&lt;/li>
&lt;li>Resource quota Controller&lt;/li>
&lt;/ul>
&lt;h2 id="deployment--管理-pod-的多个副本并确保-pod-按照期望的状态运行">Deployment # 管理 Pod 的多个副本，并确保 Pod 按照期望的状态运行&lt;/h2>
&lt;blockquote>
&lt;p>官方文档：&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>比 ReplicaSet 还多了几个功能支持滚动更新和回滚，支持声明式配置的功能&lt;/p>
&lt;ol>
&lt;li>ReplicaSet 实现了 Pod 的多副本管理，一般情况 ReplicaSet 管理无状态的 Pod。使用 Deployment 时会自动创建 ReplicaSet，也就是说 Deployment 是通过 ReplicaSet 来管理 Pod 的多个副本，我们通常不需要直接使用 ReplicaSet。 ReplicaSet 一般由下面三个组件组成，当启动 Pod 时，按照如下顺序进行创建 Pod
&lt;ol>
&lt;li>用户期望的副本数，即希望创建多少个与该 Pod 一样的副本，进行统一管理，创建在不同 Node 上以实现负载均衡以及高可用，这些 Pod 的功能与服务一模一样&lt;/li>
&lt;li>标签选择器，以便选定由自己管理和控制的 Pod，如果标签选择器选择的 pod 数量少于用户期望的副本数，则使用 Pod 资源模板&lt;/li>
&lt;li>Pod 资源模板，新建 Pod 资源&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Deployment 的滚动更新可以进行定制化配置，比如仅更新一个 pod 到新版，观察其稳定情况几天后决定是否更新现网其余 pod，使用的方式详见 kubectl set image 命令的内容&lt;/li>
&lt;/ol>
&lt;h2 id="statefulset--statefulset-表示对-pod-设定一致性身份consistent-identities">StatefulSet # StatefulSet 表示对 Pod 设定一致性身份(consistent identities)&lt;/h2>
&lt;blockquote>
&lt;p>官方文档：&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Identities 的定义：&lt;/p>
&lt;ol>
&lt;li>Network:单一稳定的主机名和 DNS&lt;/li>
&lt;li>Storage: 具有同样的一些 VolumeClaims. StatefulSet 保证给定的网络标识将始终映射到相同的存储标识。&lt;/li>
&lt;/ol>
&lt;p>StatefulSet 能够保证 Pod 的每个副本在整个生命周期中名称是不变的，一般情况 StatefulSet 管理有状态的 Pod。而其他 Controller 不提供这个功能，当某个 Pod 发生故障需要删除并重新启动时，Pod 的名称会发生变化。同时 StatefulSet 会保证副本按照固定的顺序启动、更新或者删除。&lt;/p>
&lt;ol>
&lt;li>当需要保持 Pod 不变，比如数据库类型的服务，则使用该类型&lt;/li>
&lt;li>当一个有状态的应用失败需要重启的时候，比如主从结构的数据库，其中需要进行的操作时非常复杂的，这时候需要通过一个脚本来定义 statefulset 的功能，如果以后的研发人员可以基于 kubernetes 来开发有状态的应用(比如数据库等)，让新的应用在开发的时候就想着要放在云上运行，这种云原生的应用，则可以让 statefulset 更好的支持他&lt;/li>
&lt;/ol>
&lt;h2 id="daemonset--用于每个-node-最多只运行一个-pod-副本的场景正如其名称所揭示的daemonset-通常用于运行-daemon">DaemonSet # 用于每个 Node 最多只运行一个 Pod 副本的场景。正如其名称所揭示的，DaemonSet 通常用于运行 daemon&lt;/h2>
&lt;blockquote>
&lt;p>官方文档：&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>当一个服务可以想象成守护进程的时候，使用该类型&lt;/p>
&lt;h2 id="cronjob-与-job--用于运行结束就删除的应用而其他-controller-中的-pod-通常是长期持续运行">CronJob 与 Job # 用于运行结束就删除的应用。而其他 Controller 中的 Pod 通常是长期持续运行&lt;/h2>
&lt;blockquote>
&lt;p>官方文档：&lt;/p>
&lt;ul>
&lt;li>job 文档：&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/">https://kubernetes.io/docs/concepts/workloads/controllers/job/&lt;/a>&lt;/li>
&lt;li>cronjob 文档：&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Job 对象用来创建一个或多个 pod，并确保指定数量的 pod 成功终止。pod 成功完成后，job 将跟踪完成的情况。当达到指定的成功完成次数时，Job 就完成了。删除 job 将清除其创建的 pod 。&lt;/p>
&lt;p>job 对象可以 通过 cronjob 对象来创建。cronjob 可以按照重复计划创建 job。cronjob 与 linux 中 crontab 的用法一样。可以根据指定的时间间隔定时运行任务。&lt;/p>
&lt;p>其实，cronjob 与 job 的关系，有点像 deployment 之类的控制器与 pod 之间的关系。在编写 yaml 时，deployment 需要指定 pod 的 template，而 cronjob 则需要指定 jobTemplate。&lt;/p>
&lt;p>CronJob 的行为可以通过其 yaml 中的 spec 字段中的相关字段来指定
官方文档：&lt;a href="https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#writing-a-cron-job-spec">https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#writing-a-cron-job-spec&lt;/a>&lt;/p>
&lt;ul>
&lt;li>concurrencyPolicy &amp;lt;string&amp;gt; # 指定如何处理作业的并发执行。有效值为：-“允许”（默认）：允许 CronJobs 同时运行； -“禁止”：禁止并行运行，如果前一个运行尚未完成，则跳过下一个运行； -“替换”：取消当前正在运行的作业，并将其替换为新作业&lt;/li>
&lt;li>failedJobsHistoryLimit &amp;lt;INTEGER&amp;gt; # 执行失败的 job(Completed 状态的 pod) 的保留数为 INTEGER。默认为 1&lt;/li>
&lt;li>jobTemplate &amp;lt;Object&amp;gt; # -required- 指定在执行 CronJob 时将创建的作业。类似于 deployment 下的。&lt;/li>
&lt;li>schedule &amp;lt;string&amp;gt; # -required- Cron 格式的日程表，请参阅&lt;a href="https://en.wikipedia.org/wiki/Cron">https://en.wikipedia.org/wiki/Cron&lt;/a>。&lt;/li>
&lt;li>startingDeadlineSeconds &amp;lt;integer&amp;gt; # 如果由于任何原因错过了计划的时间，则以秒为单位的可选截止日期，用于启动作业。错过的工作执行将被视为失败的工作。&lt;/li>
&lt;li>successfulJobsHistoryLimit &amp;lt;INTEGER&amp;gt; # 执行成功的 job(Completed 状态的 pod) 的保留数为 INTEGER。默认为 3&lt;/li>
&lt;li>suspend &amp;lt;boolean&amp;gt; # 此标志告诉控制器暂停随后的执行，不适用于已经开始的执行。默认为 false。&lt;/li>
&lt;/ul>
&lt;h2 id="garbage-collection垃圾收集器">Garbage Collection(垃圾收集器)&lt;/h2>
&lt;blockquote>
&lt;p>官方文档：&lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/">https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Kubernetes 垃圾收集器的作用是删除某些对象。曾经有一个所有者，但不再有一个所有者。&lt;/p>
&lt;p>详见：&lt;a href="https://www.yuque.com/go/doc/33166462">Garbage Collection 垃圾收集器&lt;/a>&lt;/p>
&lt;h2 id="hpa--horizontal-pod-autoscaler">HPA # Horizontal Pod Autoscaler&lt;/h2>
&lt;blockquote>
&lt;p>官方文档：&lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/&lt;/a>&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: Garbage Collection(垃圾收集)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/</guid><description/></item><item><title>Docs: kube-controller-manager 实现控制器的程序</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/kube-controller-manager-%E5%AE%9E%E7%8E%B0%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E7%A8%8B%E5%BA%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/4.Controller%E6%8E%A7%E5%88%B6%E5%99%A8/kube-controller-manager-%E5%AE%9E%E7%8E%B0%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E7%A8%8B%E5%BA%8F/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;p>kube-controller-manager 是实现 &lt;a href="https://www.yuque.com/desistdaydream/learning/xwr8r7#0yYOq">Kubernetes 控制器功能&lt;/a>的程序。一般在集群启动之前，由 kubelet 使用静态 Pod 以容器方式运行；或者使用 systemd 以 daemon 方式运行。&lt;/p>
&lt;p>kube-controller-manager 启动后监听两个端口。&lt;/p>
&lt;ol>
&lt;li>10257 端口是需要身份验证和授权的 https 服务端口。&lt;/li>
&lt;li>10252 为不安全的 http 服务端口。&lt;/li>
&lt;/ol>
&lt;h2 id="kube-controller-manager-高可用">kube-controller-manager 高可用&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;a href="https://www.yuque.com/go/doc/34288737">Leader Election 机制&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>我们都知道 k8s 核心组件，其中 apiserver 只用于接收 api 请求，不会主动进行各种动作，所以他们在每个节点都运行并且都可以接收请求，不会造成异常；kube-proxy 也是一样，只用于做端口转发，不会主动进行动作执行。
但是 scheduler, controller-manager 不同，他们参与了 Pod 的调度及具体的各种资源的管控，如果同时有多个 controller-manager 来对 Pod 资源进行调度，结果太美不敢看，那么 k8s 是如何做到正确运转的呢？
k8s 所有功能都是通过 &lt;code>services&lt;/code> 对外暴露接口，而 &lt;code>services&lt;/code> 对应的是具体的 &lt;code>endpoints&lt;/code> ，那么来看下 scheduler 和 controller-manager 的 &lt;code>endpoints&lt;/code> 是什么：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@node70 21:04:46 ~&lt;span style="color:#f92672">]&lt;/span>$kubectl -n kube-system describe endpoints kube-scheduler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: kube-scheduler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: kube-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: control-plane.alpha.kubernetes.io/leader:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;holderIdentity&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;node70_ed12bf09-7aa3-47d6-9546-97752bb589b5&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;leaseDurationSeconds&amp;#34;&lt;/span>:15,&lt;span style="color:#e6db74">&amp;#34;acquireTime&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-09-11T05:31:58Z&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;renewTime&amp;#34;&lt;/span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Subsets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Events: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>root@node70 21:05:25 ~&lt;span style="color:#f92672">]&lt;/span>$kubectl -n kube-system describe endpoints kube-controller-manager
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: kube-controller-manager
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: kube-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: control-plane.alpha.kubernetes.io/leader:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;holderIdentity&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;node71_c8deeaea-2d66-4459-90ee-65c28563062f&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;leaseDurationSeconds&amp;#34;&lt;/span>:15,&lt;span style="color:#e6db74">&amp;#34;acquireTime&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-09-12T12:44:15Z&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;renewTime&amp;#34;&lt;/span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Subsets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Events:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Reason Age From Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ---- ---- -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Normal LeaderElection 22m kube-controller-manager node71_c8deeaea-2d66-4459-90ee-65c28563062f became leader
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到关键字 &lt;code>[control-plane.alpha.kubernetes.io/leader](http://control-plane.alpha.kubernetes.io/leader)&lt;/code> ，这两个组件是通过 leader 选举来从集群中多个节点选择一个执行具体动作&lt;/p>
&lt;p>其实，kube-controller-manager 默认使用 leases 资源来实现领导者选举功能：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>root@lichenhao:~# kubectl get leases.coordination.k8s.io -n kube-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME HOLDER AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kube-controller-manager master-2.bj-net_62b724de-66a3-4aff-9a7c-e7c3d66555d1 176d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kube-scheduler master-2.bj-net_50df0a21-f59a-48de-98a5-93ab4a0ddf3b 176d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root@lichenhao:~# kubectl get leases.coordination.k8s.io -n kube-system kube-controller-manager -oyaml | neat
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: coordination.k8s.io/v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Lease
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: kube-controller-manager
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: kube-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> acquireTime: &lt;span style="color:#e6db74">&amp;#34;2021-03-28T13:22:03.000000Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> holderIdentity: master-2.bj-net_62b724de-66a3-4aff-9a7c-e7c3d66555d1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> leaseDurationSeconds: &lt;span style="color:#ae81ff">15&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> leaseTransitions: &lt;span style="color:#ae81ff">9&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> renewTime: &lt;span style="color:#e6db74">&amp;#34;2021-04-07T08:36:21.251656Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里的关键字段是 holderIdentity，可以看到，现在 master-2 上的 kube-controller-manager 是领导者&lt;/p>
&lt;p>如果我们去看 &lt;code>/etc/kubernetes/manifests/&lt;/code> 下的配置文件，会看到这行配置：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">creationTimestamp&lt;/span>: &lt;span style="color:#66d9ef">null&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">component&lt;/span>: &lt;span style="color:#ae81ff">kube-controller-manager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tier&lt;/span>: &lt;span style="color:#ae81ff">control-plane&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">kube-controller-manager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">kube-system&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">command&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">kube-controller-manager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">leader-elect=true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>通过在 YAML 中添加 &lt;code>--leader-elect=true&lt;/code> 来决定是否进行选主逻辑。而这个参数也是在执行 &lt;code>kubeadm&lt;/code> 部署集群时就自动配置好了，无需手动配置。&lt;/p>
&lt;h2 id="kube-controller-manager-监控指标">kube-controller-manager 监控指标&lt;/h2>
&lt;p>详见：[kubernetes 监控](/docs/10.云原生/2.3.Kubernetes%20 容器编排系统/Kubernetes%20 管理/Kubernetes%20 监控/Kubernetes%20 系统组件指标.md 管理/Kubernetes 监控/Kubernetes 系统组件指标.md)&lt;/p>
&lt;h1 id="kube-controller-manager-配置">kube-controller-manager 配置&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/">官方文档,参考-组件工具-kube-controller-manager&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>kube-controller-manager 主要通过命令行标志来控制运行时行为&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&amp;ndash;bind-address=&lt;!-- raw HTML omitted -->&lt;/strong> # 指定监听在 &amp;ndash;secure-port 参数设定的端口的 IP。集群的其余部分以及 CLI 或者 web 客户端必须可以访问关联的接口。&lt;/li>
&lt;li>&lt;strong>&amp;ndash;cluster-cidr=&lt;!-- raw HTML omitted -->&lt;/strong> # 集群中 Pod 的 CIDR 范围。
&lt;ul>
&lt;li>用白话说：可以给 Pod 分配的 IP 范围。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>&amp;ndash;controllers=&lt;!-- raw HTML omitted -->&lt;/strong> # 要启动的控制器列表。&lt;code>默认值：*&lt;/code>。
&lt;ul>
&lt;li>&lt;code>*&lt;/code> 表示默认的控制器，比如 deployment 等。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>&amp;ndash;leader-elect=&lt;!-- raw HTML omitted -->&lt;/strong> # 在程序开始循环监控之前，是否要启用领导者选举功能。&lt;code>默认值：true&lt;/code>。
&lt;ul>
&lt;li>若集群中有多个 kube-controller-manager，则必须要启用领导者选举功能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>&amp;ndash;leader-elect-resource-lock=&lt;!-- raw HTML omitted -->&lt;/strong> # 在领导者选举期间用于获取锁的资源。&lt;code>默认值：leases&lt;/code>。
&lt;ul>
&lt;li>其他可以获取锁的资源有 endpoints 和 configmaps。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>&amp;ndash;node-cidr-mask-size=&lt;!-- raw HTML omitted -->&lt;/strong> # 集群中 Node 的 CIDR 的掩码。&lt;code>IPv4 的默认值：24&lt;/code>。&lt;code>IPv6的默认值：64&lt;/code>。
&lt;ul>
&lt;li>用白话说：与 &amp;ndash;cluster-cidr 标志互相配合，以确定 CNI 可以为每个节点分配的 IP 范围。该标志的值必须要大于 &amp;ndash;cluster-cidr 中掩码的值。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>&amp;ndash;node-monitor-grace-period=&lt;!-- raw HTML omitted -->&lt;/strong> # 将一个 Running 状态节点标记为不健康(NotReady、Unkonw 等)状态之前，允许节点处于不健康状态的时间上限。&lt;/li>
&lt;li>&lt;strong>&amp;ndash;node-monitor-period=&lt;!-- raw HTML omitted -->&lt;/strong> # 节点控制器同步节点状态的周期。&lt;code>默认值：5s&lt;/code>。
&lt;ul>
&lt;li>kube-controller-manager 每隔 &amp;ndash;node-monitor-period 时间就会去检查所有节点上 kubelet 的状态。如果持续 &amp;ndash;node-monitor-grace-period 时间之后，被检查的节点依然不健康，则会将该节点标记为不健康&lt;/li>
&lt;li>并且，当节点被标记为不健康时，所有节点的 Pod 都会从 Endpoint 中踢出。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>&amp;ndash;node-startup-grace-period=&lt;!-- raw HTML omitted -->&lt;/strong> # 节点启动期间可以处于无响应状态，但是超出 &amp;ndash;node-startup-grace-period 时间后依然无响应，则将节点标记为不健康(NotRead、Unknow 等)状态。&lt;/li>
&lt;li>&lt;strong>&amp;ndash;pod-eviction-timeout=&lt;!-- raw HTML omitted -->&lt;/strong> # 节点被标记为不健康状态(NotReady、Unkonw 等)后，等待 DURATION 时间后驱逐故障节点上所有 Pod。&lt;code>默认值：5m0s&lt;/code>
&lt;ul>
&lt;li>这个标志的用法，可以通过&lt;a href="https://kubernetes.io/docs/concepts/architecture/nodes/#condition">官方文档,概念-集群架构-节点 章节中节点状态&lt;/a>小节获得更详细的说明。&lt;/li>
&lt;li>其实，由于节点不可用，kubelet 无法接收到消息，说是删除 Pod，其实故障节点上 Pod 只会一直处于 Terminating 状态，因为故障节点的 kubelet 不可用，无法真正完成删除操作。&lt;/li>
&lt;li>但是在驱逐之前，如果节点状态不健康，则 service 管理的 endpoint 中，所有属于该节点的 Pod 都会被踢出，防止异常节点上的 Pod 处理请求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>&amp;ndash;secure-port=&lt;!-- raw HTML omitted -->&lt;/strong> # 指定通过身份验证和授权为 HTTPS 服务的端口。&lt;code>默认值：10257&lt;/code>。&lt;/li>
&lt;li>&lt;strong>&amp;ndash;use-service-account-credentials=&lt;!-- raw HTML omitted -->&lt;/strong> # 是否为每个控制器使用单独的 service account。&lt;code>默认值：无&lt;/code>。&lt;/li>
&lt;/ul>
&lt;h2 id="默认的-manifest-示例">默认的 manifest 示例&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">creationTimestamp&lt;/span>: &lt;span style="color:#66d9ef">null&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">component&lt;/span>: &lt;span style="color:#ae81ff">kube-controller-manager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tier&lt;/span>: &lt;span style="color:#ae81ff">control-plane&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">kube-controller-manager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">kube-system&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">command&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">kube-controller-manager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">allocate-node-cidrs=true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">authentication-kubeconfig=/etc/kubernetes/controller-manager.conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">authorization-kubeconfig=/etc/kubernetes/controller-manager.conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">bind-address=0.0.0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">client-ca-file=/etc/kubernetes/pki/ca.crt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">cluster-cidr=10.244.0.0/16&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">cluster-name=kubernetes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">cluster-signing-key-file=/etc/kubernetes/pki/ca.key&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">controllers=*,bootstrapsigner,tokencleaner&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">kubeconfig=/etc/kubernetes/controller-manager.conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">leader-elect=true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">node-cidr-mask-size=24&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">port=10252&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">root-ca-file=/etc/kubernetes/pki/ca.crt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">service-account-private-key-file=/etc/kubernetes/pki/sa.key&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">service-cluster-ip-range=10.96.0.0/12&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - --&lt;span style="color:#ae81ff">use-service-account-credentials=true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">registry.aliyuncs.com/k8sxio/kube-controller-manager:v1.19.2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">imagePullPolicy&lt;/span>: &lt;span style="color:#ae81ff">IfNotPresent&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">livenessProbe&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">failureThreshold&lt;/span>: &lt;span style="color:#ae81ff">8&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">httpGet&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/healthz&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">port&lt;/span>: &lt;span style="color:#ae81ff">10257&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">scheme&lt;/span>: &lt;span style="color:#ae81ff">HTTPS&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">initialDelaySeconds&lt;/span>: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">periodSeconds&lt;/span>: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">timeoutSeconds&lt;/span>: &lt;span style="color:#ae81ff">15&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">kube-controller-manager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">cpu&lt;/span>: &lt;span style="color:#ae81ff">200m&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">startupProbe&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">failureThreshold&lt;/span>: &lt;span style="color:#ae81ff">24&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">httpGet&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/healthz&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">port&lt;/span>: &lt;span style="color:#ae81ff">10257&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">scheme&lt;/span>: &lt;span style="color:#ae81ff">HTTPS&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">initialDelaySeconds&lt;/span>: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">periodSeconds&lt;/span>: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">timeoutSeconds&lt;/span>: &lt;span style="color:#ae81ff">15&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumeMounts&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/ssl/certs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">ca-certs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">readOnly&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/pki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">etc-pki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">readOnly&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/usr/libexec/kubernetes/kubelet-plugins/volume/exec&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">flexvolume-dir&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/localtime&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">host-time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">readOnly&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/kubernetes/pki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">k8s-certs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">readOnly&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/kubernetes/controller-manager.conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">kubeconfig&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">readOnly&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">hostNetwork&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">priorityClassName&lt;/span>: &lt;span style="color:#ae81ff">system-node-critical&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">hostPath&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/etc/ssl/certs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">DirectoryOrCreate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">ca-certs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">hostPath&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/etc/pki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">DirectoryOrCreate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">etc-pki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">hostPath&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/usr/libexec/kubernetes/kubelet-plugins/volume/exec&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">DirectoryOrCreate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">flexvolume-dir&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">hostPath&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/etc/localtime&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">host-time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">hostPath&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/etc/kubernetes/pki&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">DirectoryOrCreate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">k8s-certs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">hostPath&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">path&lt;/span>: &lt;span style="color:#ae81ff">/etc/kubernetes/controller-manager.conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">FileOrCreate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">kubeconfig&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>