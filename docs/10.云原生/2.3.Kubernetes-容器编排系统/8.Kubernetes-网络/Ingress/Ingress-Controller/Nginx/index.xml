<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – Nginx</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/</link><description>Recent content in Nginx on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Annotations 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Annotations-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Annotations-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/">官方文档，用户指南-Annotations&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>与 ConfigMap 实现配置 Nginx Ingress Controller 运行时行为类似，只不过，Annotations 的方式，是通过在 Ingress 对象的 &lt;code>.metadata.annotations&lt;/code> 字段下的内容实现的。&lt;/p>
&lt;p>同样，&lt;code>.metadata.annotations&lt;/code> 字段下的内容也是由无数的 &lt;strong>Key/Value Pairs(键/值对)&lt;/strong> 组成。很多 &lt;strong>Key&lt;/strong> 都会对应一个 Nginx 的 &lt;a href="docs/Web/Nginx/Nginx%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Nginx%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3.md#Directives(%E6%8C%87%E4%BB%A4)">&lt;strong>Directives(指令)&lt;/strong>&lt;/a>&lt;/p>
&lt;h1 id="key-详解">Key 详解&lt;/h1>
&lt;h2 id="authenticationhttpskubernetesgithubioingress-nginxuser-guidenginx-configurationannotationsauthentication--认证相关配置">&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#authentication">Authentication&lt;/a> # 认证相关配置&lt;/h2>
&lt;p>可以为 Nginx 所代理的后端配置一些简单的认证，比如 用户名/密码&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/auth-realm: &amp;lt;STRING&amp;gt;&lt;/strong> #&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/auth-secret: &amp;lt;STRING&amp;gt;&lt;/strong> #&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/auth-type: &amp;lt;STRING&amp;gt;&lt;/strong> #&lt;/p>
&lt;h2 id="custom-timeoutshttpskubernetesgithubioingress-nginxuser-guidenginx-configurationannotationscustom-timeouts--自定义超时时间">&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#custom-timeouts">Custom Timeouts&lt;/a> # 自定义超时时间&lt;/h2>
&lt;p>配置与 upstream 中定义的服务器的连接超时时间。&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/proxy-connect-timeout: &amp;lt;&amp;gt;&lt;/strong># 对应 Nginx 的 proxy_connect_timeout 指令&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/proxy-send-timeout: &amp;lt;&amp;gt;&lt;/strong>#&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/proxy-read-timeout: &amp;lt;&amp;gt;&lt;/strong> #&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/proxy-next-upstream: &amp;lt;&amp;gt;&lt;/strong> #&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/proxy-next-upstream-timeout: &amp;lt;&amp;gt;&lt;/strong> #&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/proxy-next-upstream-tries: &amp;lt;&amp;gt;&lt;/strong> #&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/proxy-request-buffering: &amp;lt;&amp;gt;&lt;/strong> #&lt;/p>
&lt;h2 id="canaryhttpskubernetesgithubioingress-nginxuser-guidenginx-configurationannotationscanary--金丝雀灰度发布相关配置">&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#canary">Canary&lt;/a> # 金丝雀/灰度发布相关配置&lt;/h2>
&lt;p>通过 canary 相关的注释，我们可以实现金丝雀/灰度发布。即.相同的 host，根据不同的规则，将请求转发给不同的后端。&lt;/p>
&lt;p>&lt;strong>nginx.ingress.kubernetes.io/canary: &amp;ldquo;&amp;lt;BOOLEAN&amp;gt;&amp;rdquo;&lt;/strong> # 是否启用 Canary 功能&lt;/p>
&lt;p>其他功能详见 《&lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes%20%E7%BD%91%E7%BB%9C/Ingress/Ingress%20Controller/Nginx/%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%94%A8%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83.md">实现应用灰度发布&lt;/a>》&lt;/p></description></item><item><title>Docs: ConfigMap 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/ConfigMap-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/ConfigMap-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/">官方文档,用户指南-ConfigMap&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/ingress-nginx/blob/master/internal/ingress/controller/config/config.go">GitHub 代码中的可用的配置，及其默认值&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>可以通过 ConfigMap 资源来控制 Nginx Ingress Controller 的运行时行为。Nginx Ingress Controller 将会读取指定 ConfigMap 对象中的 &lt;code>.data&lt;/code> 字段下的内容，并解析其中的内容，转换为传统 Nginx 的配置。&lt;/p>
&lt;p>&lt;code>.data&lt;/code> 字段下的内容由无数的 &lt;strong>Key/Value Pairs(键/值对)&lt;/strong> 组成。绝大部分 &lt;strong>Key&lt;/strong> 都会对应一个 Nginx 的 &lt;a href="docs/Web/Nginx/Nginx%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Nginx%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3.md#Directives(%E6%8C%87%E4%BB%A4)">&lt;strong>Directives(指令)&lt;/strong>&lt;/a>。Key 的 Value 就是指令的参数。假如现在有如下 ConfigMap 配置：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">data&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">map-hash-bucket-size&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;128&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ssl-protocols&lt;/span>: &lt;span style="color:#ae81ff">SSLv2&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这就会生成如下 Ngxin 的配置&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-nginx" data-lang="nginx">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">http&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">······&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">map_hash_bucket_size&lt;/span> &lt;span style="color:#ae81ff">128&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ssl_protocols&lt;/span> &lt;span style="color:#e6db74">SSLv2&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">······&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="可用的-key-详解">可用的 Key 详解&lt;/h1>
&lt;p>下面每个 Key 的详解中，若没写对应指令，则表示这个 Key 没有对应的老式 Nginx 指令。&lt;/p>
&lt;p>&lt;strong>enable-undersores-in-headers: &lt;!-- raw HTML omitted -->&lt;/strong> # 是否接收 key 中带有下划线的请求头。&lt;/p>
&lt;ul>
&lt;li>默认值：&lt;code>&amp;quot;true&amp;quot;&lt;/code>&lt;/li>
&lt;li>对应指令：&lt;a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#underscores_in_headers">underscores_in_headers&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>**log-format-escape-json: &lt;!-- raw HTML omitted --> **# 是否为 log_format 指令开启 escape(转义) 参数&lt;/p>
&lt;ul>
&lt;li>默认值：&lt;code>&amp;quot;false&amp;quot;&lt;/code>&lt;/li>
&lt;li>对应指令：&lt;a href="http://nginx.org/en/docs/http/ngx_http_log_module.html#log_format">log_format 指令&lt;/a>中的 escape 参数&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>log-format-upstream: &lt;!-- raw HTML omitted -->&lt;/strong> # 设定 Nginx 的日志格式&lt;/p>
&lt;ul>
&lt;li>默认值：&lt;code>'$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; $status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &amp;quot;$http_user_agent&amp;quot; $request_length $request_time [$proxy_upstream_name] [$proxy_alternative_upstream_name] $upstream_addr $upstream_response_length $upstream_response_time $upstream_status $req_id'&lt;/code>&lt;/li>
&lt;li>对应指令：&lt;a href="http://nginx.org/en/docs/http/ngx_http_log_module.html#log_format">log_format&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>**use-geoip2: &lt;!-- raw HTML omitted --> **# 是否启用 geoip2 模块。&lt;/p>
&lt;ul>
&lt;li>默认值：&lt;code>&amp;quot;false&amp;quot;&lt;/code>&lt;/li>
&lt;li>对应指令：无&lt;/li>
&lt;/ul>
&lt;p>该配置需要与 &lt;code>--maxmind-license-key&lt;/code> 命令好标志配合使用。这是由于 MaxMind 已经于 &lt;a href="https://blog.maxmind.com/2019/12/18/significant-changes-to-accessing-and-using-geolite2-databases/">2019 年 12 月对数据库进行了大改&lt;/a>，需要一个 License 才可以访问数据库。所以，&lt;code>--maxmind-license-key&lt;/code> 标志就是用来指定 License Key 的，可以创建完 MaxMind 账户后，在&lt;a href="https://www.maxmind.com/en/accounts/545756/license-key">此页面&lt;/a>创建一个 License Key。&lt;/p>
&lt;p>启用 geoip2 模块后，会自动添加相关 geoip2 指令到 http{} 配置环境，详见 &lt;a href="https://github.com/kubernetes/ingress-nginx/blob/master/rootfs/etc/nginx/template/nginx.tmpl#L195">nginx.tmpl 模板文件&lt;/a>。&lt;/p>
&lt;p>**use-forwarded-headers: &lt;!-- raw HTML omitted --> **# 是否使用 &lt;code>X-Forwarded-*&lt;/code> 请求头&lt;/p>
&lt;ul>
&lt;li>默认值：&lt;code>&amp;quot;false&amp;quot;&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>注意：&lt;/p>
&lt;ul>
&lt;li>当 Nginx Ingress Controller 处于其他 7 层代理 或 负载均衡器 后面时，应为 &lt;code>true&lt;/code>。&lt;/li>
&lt;li>当 Nginx Ingress Controller 直接暴露在互联网上是，应为&lt;/li>
&lt;/ul></description></item><item><title>Docs: Nginx</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Nginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Nginx/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;p>分为两个版本&lt;/p>
&lt;ul>
&lt;li>K8S 社区版 Nginx Ingress Controller # &lt;a href="https://github.com/kubernetes/ingress-nginx">https://github.com/kubernetes/ingress-nginx&lt;/a>&lt;/li>
&lt;li>Nginx 官网版 Nginx Ingress Controller # &lt;a href="https://github.com/nginxinc/kubernetes-ingress">https://github.com/nginxinc/kubernetes-ingress&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="部署">部署&lt;/h1>
&lt;p>版本支持矩阵: &lt;a href="https://github.com/kubernetes/ingress-nginx#supported-versions-table">https://github.com/kubernetes/ingress-nginx#supported-versions-table&lt;/a>&lt;/p>
&lt;h2 id="k8s-社区版部署方式">k8s 社区版部署方式&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters">官方文档，部署-安装指南-裸金属集群&lt;/a>(就是通过纯 Manifests 文件部署)&lt;/li>
&lt;li>&lt;a href="https://kubernetes.github.io/ingress-nginx/deploy/#using-helm">官方文档，部署-安装指南-&lt;/a>快速开始(直接就是 Helm 安装)&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>注意：&lt;/p>
&lt;ul>
&lt;li>从 v1.0.0 版本开始，仅支持 Kubernetes 版本 &amp;gt;= v1.19 ，因为从 v1.0.0 版本开始，删除了对 &lt;code>networking.k8s.io/v1beta&lt;/code> 资源的支持。
&lt;ul>
&lt;li>详见：&lt;a href="https://mp.weixin.qq.com/s/hVTWlfrqmjZRrb0KTsDrZA">公众号-CNCF，更新 NGINX-Ingress 以使用稳定的 Ingress API&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>从 v1.3.0 版本开始，仅支持 Kubernetes 版本 &amp;gt;= v1.20。
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/7vOTDqpi4tg-AEzP_YAWAQ">详见：公众号-MoeLove，K8S 生态周报| Kubernetes Ingress-NGINX 功能冻结前最后一个版本发布&lt;/a>&lt;/li>
&lt;li>为了能兼容 Kubernetes 的更高版本，所以我们将 controller 中用于选举的机制修改成了使用 Lease API 的方式，而不再是原先的 configmap 的方式。其实在 Kubernetes Ingress-NGINX v1.3.0 版本中，我增加了往 Lease API 平滑迁移的逻辑，在使用 v1.3.0 版本的时候，可以自动的完成 ConfigMap 往 Lease API 迁移的逻辑。 &lt;strong>所以，如果是想要从旧版本进行平滑升级，建议先升级到 v1.3.0，待完成自动的迁移后，再往更新的版本升级&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>其中&lt;a href="https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal">Bare-metal 段落&lt;/a>为通过 yaml 文件部署方式&lt;/p>
&lt;ul>
&lt;li>部署一个 Nginx 的 IngressController&lt;/li>
&lt;li>Nginx-IngressController 的配置详见：&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="使用-helm-部署">使用 helm 部署&lt;/h3>
&lt;ul>
&lt;li>helm repo add ingress-nginx &lt;a href="https://kubernetes.github.io/ingress-nginx">https://kubernetes.github.io/ingress-nginx&lt;/a>&lt;/li>
&lt;li>helm pull ingress-nginx/ingress-nginx&lt;/li>
&lt;li>tar -zxvf ingress-nginx-X.X.X.tgz&lt;/li>
&lt;li>cd ingress-nginx&lt;/li>
&lt;li>helm install nginx &amp;ndash;namespace ingress-controller &amp;ndash;create-namesapce .&lt;/li>
&lt;/ul>
&lt;p>部署完成后，即可创建 Ingress 对象，关联后端 Service&lt;/p>
&lt;ul>
&lt;li>配置好域名解析，直接使用域名访问即可，不用域名会出现问题。(如果 ingress 中没有配置 host 字段，则无需解析)
&lt;ul>
&lt;li>因为在 《&lt;a href="https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/7.HTTP/7.HTTP.md">HTTP&lt;/a>》 文章中，http 协议的 Request-URL 中包含了 client 访问时输入的网址，可以是 IP 或者域名，而 ingress 对象的配置中，host 配置的都是域名，如果是 ip 的话， ingress 是无法识别出带有 IP 的 URL 的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="nginx-官方版部署方式">Nginx 官方版部署方式&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/">https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/&lt;/a>
&lt;ul>
&lt;li>直接创建一个 daemonset 类型的 nginx-ingress(就是 ingress-controller)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>创建 Ingress 对象，关联后端 Service&lt;/li>
&lt;li>配置好域名解析，直接使用域名访问即可。(如果 ingress 中没有配置 host 字段，则无需解析)
&lt;ul>
&lt;li>Note：不用域名会出现问题。因为在 《&lt;a href="https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/7.HTTP/7.HTTP.md">HTTP&lt;/a>》 文章中，http 协议的 Request-URL 中包含了 client 访问时输入的网址，可以是 IP 或者域名，而 ingress 对象的配置中，host 配置的都是域名，如果是 ip 的话， ingress 是无法识别出带有 IP 的 URL 的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="关联文件与配置">关联文件与配置&lt;/h1>
&lt;p>可以通过如下几种方式来配置 Nginx Ingress Controller&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Command Line Flags&lt;/strong> # Controller 程序的命令行标志，可以定义程序自身的运行时行为。&lt;/li>
&lt;li>&lt;strong>ConfigMap&lt;/strong># 通过 &lt;code>--configmap&lt;/code> 命令行标志指定的名称空间下的 ConfigMap 资源，仅支持一个 ConfigMap 对象。
&lt;ul>
&lt;li>Nginx Ingress Controller 会读取该 ConfigMap 对象下的内容，并与 Custom template 一起生成 Nginx 的 nginx.conf 文件&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Annotations&lt;/strong># 通过为 Ingress 对象添加 Annotations 字段下的内容来定义 Nginx Ingress Controller 的运行时行为。&lt;/li>
&lt;li>&lt;strong>Custom template&lt;/strong> # Nginx Ingress Controller 会使用模板文件生成 nginx.conf 文件。模板文件可以在 &lt;a href="https://github.com/kubernetes/ingress-nginx/blob/master/rootfs/etc/nginx/template/nginx.tmpl">GitHub 代码&lt;/a>中找到&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>ConfigMap、Annotations、Custom template 都可以用来定义 nginx.conf 这个配置文件&lt;/strong>，不同的是：&lt;/p>
&lt;ul>
&lt;li>Annotations 主要用于定义每一个 Virtual Server 中的指令(比如 server{}、location{} 中的指令)&lt;/li>
&lt;li>而 ConfigMap 更多是定义 http{}、stream{} 这种配置环境中的指令。&lt;/li>
&lt;li>Custom template 则是生成 ngxin.conf 的模板文件，Annotations 与 ConfigMap 中定义的内容，都会通过值传递的方式，传递到模板文件中，然后生成 ngxin.conf 文件。&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/kubernetes/ingress-nginx/blob/main/rootfs/etc/nginx/template/nginx.tmpl">&lt;strong>/etc/nginx/template/nginx.tmpl&lt;/strong>&lt;/a> # Nginx 的 nginx.conf 文件的模板文件&lt;/p>
&lt;h1 id="grafana-面板">Grafana 面板&lt;/h1>
&lt;h2 id="12559">12559&lt;/h2>
&lt;p>&lt;a href="https://grafana.com/grafana/dashboards/12559">https://grafana.com/grafana/dashboards/12559&lt;/a>&lt;/p>
&lt;p>该面板曾经名称为：Loki v2 Web Analytics Dashboard，在 Grafana 官方面板首页最顶部推荐了很久；现在更名为：&lt;/p>
&lt;p>Grafana Loki Dashboard for NGINX Service Mesh&lt;/p></description></item><item><title>Docs: 命令行标志</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A0%87%E5%BF%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A0%87%E5%BF%97/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/cli-arguments/">官方文档,用户指南-命令行参数&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="命令行标志详解">命令行标志详解&lt;/h1>
&lt;p>&lt;strong>&amp;ndash;controller-class=&amp;lt;STRING&amp;gt;&lt;/strong> # Ingress Class Controller value this Ingress satisfies.&lt;code>默认值：k8s.io/ingress-nginx&lt;/code>&lt;/p>
&lt;ul>
&lt;li>想要控制器使用对应的 Ingress，该标志的值，需要与 ingressClass 资源中 &lt;code>spec.controller&lt;/code> 的值相同&lt;/li>
&lt;li>通常来说，在部署 Nginx ingress controller 时，都是同时部署一个 ingressClass 资源&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>&amp;ndash;publish-service=&amp;lt;STRING&amp;gt;&lt;/strong> # 与 controller-class 功能一起来定位控制器应该使用哪个 ingressClass 的 Ingress 资源
&lt;strong>&amp;ndash;maxmind-license-key=&amp;lt;STRING&amp;gt;&lt;/strong> # 从 MaxMind 下载 GeoLite2 数据库时所需的 License Key。&lt;/p></description></item><item><title>Docs: 实现应用灰度发布</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%94%A8%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%94%A8%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>原文链接：&lt;a href="https://mp.weixin.qq.com/s/xFdrfUYygsXmnJbEozosgQ">公众号-运维开发故事，如何通过 ingress-nginx 实现应用灰度发布？&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>在日常的工作中，我们会经常对应用进行发版升级，在互联网公司尤为频繁，主要是为了满足快速的业务发展。我们经常用到的发布方式有滚动更新、蓝绿发布、灰度发布。&lt;/p>
&lt;ul>
&lt;li>滚动更新：依次进行新旧替换，直到旧的全部被替换为止。&lt;/li>
&lt;li>蓝绿发布：两套独立的系统，对外提供服务的称为绿系统，待上线的服务称为蓝系统，当蓝系统里面的应用测试完成后，用户流量接入蓝系统，蓝系统将称为绿系统，以前的绿系统就可以销毁。&lt;/li>
&lt;li>灰度发布：在一套集群中存在稳定和灰度两个版本，灰度版本可以限制只针对部分人员可用，待灰度版本测试完成后，可以将灰度版本升级为稳定版本，旧的稳定版本就可以下线了，我们也称之为金丝雀发布。&lt;/li>
&lt;/ul>
&lt;p>这里主要给大家分享如果通过 ingress-nginx controller 实现灰度发布。&lt;/p>
&lt;p>本文大纲如下。&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/18f2621f-4692-48c5-a086-213c9333a04b/640" alt="">&lt;/p>
&lt;h2 id="如何通过-ingress-nginx-实现灰度发布">如何通过 ingress-nginx 实现灰度发布&lt;/h2>
&lt;p>ingress-nginx 是 Kubernetes 官方推荐的 ingress controller，它是基于 nginx 实现的，增加了一组用于实现额外功能的 Lua 插件。&lt;/p>
&lt;p>为了实现灰度发布，ingress-nginx 通过定义 annotation 来实现不同场景的灰度发布，其支持的规则如下：&lt;/p>
&lt;ul>
&lt;li>&lt;code>nginx.ingress.kubernetes.io/canary-by-header&lt;/code>：基于 Request Header 的流量切分，适用于灰度发布以及 A/B 测试。当 Request Header 设置为 &lt;code>always&lt;/code>时，请求将会被一直发送到 Canary 版本；当 Request Header 设置为 &lt;code>never&lt;/code>时，请求不会被发送到 Canary 入口；对于任何其他 Header 值，将忽略 Header，并通过优先级将请求与其他金丝雀规则进行优先级的比较。&lt;/li>
&lt;li>&lt;code>nginx.ingress.kubernetes.io/canary-by-header-value&lt;/code>：要匹配的 Request Header 的值，用于通知 Ingress 将请求路由到 Canary Ingress 中指定的服务。当 Request Header 设置为此值时，它将被路由到 Canary 入口。该规则允许用户自定义 Request Header 的值，必须与上一个 annotation (即：canary-by-header）一起使用。&lt;/li>
&lt;li>&lt;code>nginx.ingress.kubernetes.io/canary-weight&lt;/code>：基于服务权重的流量切分，适用于蓝绿部署，权重范围 0 - 100 按百分比将请求路由到 Canary Ingress 中指定的服务。权重为 0 意味着该金丝雀规则不会向 Canary 入口的服务发送任何请求。权重为 100 意味着所有请求都将被发送到 Canary 入口。&lt;/li>
&lt;li>&lt;code>nginx.ingress.kubernetes.io/canary-by-cookie&lt;/code>：基于 Cookie 的流量切分，适用于灰度发布与 A/B 测试。用于通知 Ingress 将请求路由到 Canary Ingress 中指定的服务的 cookie。当 cookie 值设置为 &lt;code>always&lt;/code>时，它将被路由到 Canary 入口；当 cookie 值设置为 &lt;code>never&lt;/code>时，请求不会被发送到 Canary 入口；对于任何其他值，将忽略 cookie 并将请求与其他金丝雀规则进行优先级的比较。&lt;/li>
&lt;/ul>
&lt;p>我们也是通过上面的 annotation 来实现灰度发布，其思路如下：&lt;/p>
&lt;ol>
&lt;li>在集群中部署两套系统，一套是 stable 版本，一套是 canary 版本，两个版本都有自己的 service&lt;/li>
&lt;li>定义两个 ingress 配置，一个正常提供服务，一个增加 canary 的 annotation&lt;/li>
&lt;li>待 canary 版本无误后，将其切换成 stable 版本，并且将旧的版本下线，流量全部接入新的 stable 版本&lt;/li>
&lt;/ol>
&lt;h2 id="发布场景介绍">发布场景介绍&lt;/h2>
&lt;p>上面介绍了 ingress-nginx 实现灰度发布的方法以及咱们自己的实现思路，这里来探讨一下灰度发布有哪些发布场景。&lt;/p>
&lt;h3 id="基于权重的发布场景">基于权重的发布场景&lt;/h3>
&lt;p>假如在生产上已经运行了 A 应用对外提供服务，此时开发修复了一些 Bug，需要发布 A2 版本将其上线，但是我们又不希望直接的将所有流量接入到新的 A2 版本，而是希望将 10%的流量进入到 A2 中，待 A2 稳定后，才会将所有流量接入进来，再下线原来的 A 版本。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/18f2621f-4692-48c5-a086-213c9333a04b/640" alt="">
要实现这种，只需要在 canary 的 ingress 中添加如下 annotation。&lt;/p>
&lt;pre>&lt;code>nginx.ingress.kubernetes.io/canary: &amp;quot;true&amp;quot;
nginx.ingress.kubernetes.io/canary-weight: &amp;quot;10&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>其中&lt;code>nginx.ingress.kubernetes.io/canary&lt;/code>表示开启 canary，&lt;code>nginx.ingress.kubernetes.io/canary-weight&lt;/code>表示我们设置的权重大小。&lt;/p>
&lt;h3 id="基于用户请求的发布场景">基于用户请求的发布场景&lt;/h3>
&lt;p>基于权重的发布场景比较粗糙，它是所有用户中的 20%，无法限制具体的用户。&lt;/p>
&lt;p>我们有时候会有这样的需求，比如我们有广东、北京、四川这三个地区的用户，并且已经有 A 版本的应用为这三个地区提供服务，由于更新了需求，我们需要发布 A2 应用，但是我们不想所有地区都访问 A2 应用，而是希望只有四川的用户可以访问，待四川地区反馈没问题后，才开放其他地区。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/18f2621f-4692-48c5-a086-213c9333a04b/640" alt="">
对于这种我们需要在 canary 的 ingress 中添加如下 annotation。&lt;/p>
&lt;pre>&lt;code>nginx.ingress.kubernetes.io/canary: &amp;quot;true&amp;quot;
nginx.ingress.kubernetes.io/canary-by-header: &amp;quot;region&amp;quot;
nginx.ingress.kubernetes.io/canary-by-header-value: &amp;quot;sichuan&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>主要就是上面两种发布场景，下面会针对这两种场景分别进行实验。&lt;/p>
&lt;h2 id="灰度发布具体实现">灰度发布具体实现&lt;/h2>
&lt;p>我这里准备了两个镜像，一个是稳定 stable 版本，一个是灰度 canary 版本。&lt;/p>
&lt;ul>
&lt;li>registry.cn-hangzhou.aliyuncs.com/rookieops/go-test:v1&lt;/li>
&lt;li>registry.cn-hangzhou.aliyuncs.com/rookieops/go-test:v2&lt;/li>
&lt;/ul>
&lt;p>由于两个场景只有在 ingress 处的配置不一致，其他都一样的，所以这里先将两个版本的应用都部署好。&lt;/p>
&lt;p>（1）stable 版本&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server-stable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matchLabels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">go-test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#ae81ff">stable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">replicas&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">go-test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#ae81ff">stable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">registry.cn-hangzhou.aliyuncs.com/rookieops/go-test:v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">imagePullPolicy&lt;/span>: &lt;span style="color:#ae81ff">IfNotPresent&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containerPort&lt;/span>: &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Service&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server-stable-svc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">go-test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#ae81ff">stable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">port&lt;/span>: &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>访问效果如下：&lt;/p>
&lt;pre>&lt;code># curl 10.97.112.137:8080
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>（2）canary 版本&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server-canary&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matchLabels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">go-test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#ae81ff">canary&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">replicas&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">go-test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#ae81ff">canary&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">registry.cn-hangzhou.aliyuncs.com/rookieops/go-test:v2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">imagePullPolicy&lt;/span>: &lt;span style="color:#ae81ff">IfNotPresent&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containerPort&lt;/span>: &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Service&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server-canary-svc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">go-test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#ae81ff">canary&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">port&lt;/span>: &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>访问效果如下：&lt;/p>
&lt;pre>&lt;code># curl 10.110.178.174:8080
{&amp;quot;data&amp;quot;:&amp;quot;hello SB&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v2&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>上面已经将应用部署好了，下面将针对权重和用户请求两个场景进行测试。&lt;/p>
&lt;h3 id="基于权重的发布场景-1">基于权重的发布场景&lt;/h3>
&lt;p>（1）配置 stable 版本的 ingress&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">networking.k8s.io/v1beta1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Ingress&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server-stable-ingress&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">annotations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kubernetes.io/ingress.class&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;nginx&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">rules&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">host&lt;/span>: &lt;span style="color:#ae81ff">joker.coolops.cn&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">http&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">paths&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">path&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">backend&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">serviceName&lt;/span>: &lt;span style="color:#ae81ff">app-server-stable-svc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">servicePort&lt;/span>: &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>（2）配置 canary 版本的 ingress&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">networking.k8s.io/v1beta1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Ingress&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">app-server-canary-ingress&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">annotations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kubernetes.io/ingress.class&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;nginx&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">nginx.ingress.kubernetes.io/canary&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">nginx.ingress.kubernetes.io/canary-weight&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;10&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">rules&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">host&lt;/span>: &lt;span style="color:#ae81ff">joker.coolops.cn&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">http&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">paths&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">path&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">backend&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">serviceName&lt;/span>: &lt;span style="color:#ae81ff">app-server-canary-svc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">servicePort&lt;/span>: &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后我们通过访问测试，效果如下：&lt;/p>
&lt;pre>&lt;code># curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello SB&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v2&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>基本保持在&lt;code>9:1&lt;/code>的比例。&lt;/p>
&lt;h3 id="基于用户请求的发布场景-1">基于用户请求的发布场景&lt;/h3>
&lt;p>（1）配置 stable 版本的 ingress&lt;/p>
&lt;pre>&lt;code>apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
name: app-server-stable-ingress
annotations:
kubernetes.io/ingress.class: &amp;quot;nginx&amp;quot;
spec:
rules:
- host: joker.coolops.cn
http:
paths:
- path:
backend:
serviceName: app-server-stable-svc
servicePort: 8080
&lt;/code>&lt;/pre>
&lt;p>（2）配置 canary 版本的 ingress&lt;/p>
&lt;pre>&lt;code>apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
name: app-server-canary-ingress
annotations:
kubernetes.io/ingress.class: &amp;quot;nginx&amp;quot;
nginx.ingress.kubernetes.io/canary: &amp;quot;true&amp;quot;
nginx.ingress.kubernetes.io/canary-by-header: &amp;quot;region&amp;quot;
nginx.ingress.kubernetes.io/canary-by-header-value: &amp;quot;sichuan&amp;quot;
spec:
rules:
- host: joker.coolops.cn
http:
paths:
- path:
backend:
serviceName: app-server-canary-svc
servicePort: 8080
&lt;/code>&lt;/pre>
&lt;p>当我们访问的时候不带 header，则只会访问 stable 版本应用，如下：&lt;/p>
&lt;pre>&lt;code># curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
# curl joker.coolops.cn
{&amp;quot;data&amp;quot;:&amp;quot;hello world&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>如果我们在访问的时候带上&lt;code>region: sichuan&lt;/code> 的 header，则只会访问到 canary 版本应用，如下：&lt;/p>
&lt;pre>&lt;code># curl joker.coolops.cn -H &amp;quot;region: sichuan&amp;quot;
{&amp;quot;data&amp;quot;:&amp;quot;hello SB&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v2&amp;quot;}
# curl joker.coolops.cn -H &amp;quot;region: sichuan&amp;quot;
{&amp;quot;data&amp;quot;:&amp;quot;hello SB&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v2&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>实现是不是很简单？&lt;/p>
&lt;p>我们现在来想另外一个问题，上面的所有操作都是手动的，我们应该如何进行自动化？应该怎样来设计流水线？&lt;/p>
&lt;p>下面来说说我个人的想法。&lt;/p>
&lt;h2 id="关于灰度发布流水线设计的想法">关于灰度发布流水线设计的想法&lt;/h2>
&lt;p>首先来捋捋过程：&lt;/p>
&lt;ol>
&lt;li>发布 canary 版本应用进行测试&lt;/li>
&lt;li>测试完成将 canary 版本替换成 stable 版本&lt;/li>
&lt;li>删除 canary 版本的 ingress 配置&lt;/li>
&lt;li>删除老的 stable 版本&lt;/li>
&lt;/ol>
&lt;p>整个过程很简单，但是对于已经部署好的&lt;code>deployment&lt;/code>是不允许直接修改&lt;code>labels&lt;/code>标签的。这时候是不是可以在 canary 版本测试 i 完成后直接更新 stable 版本的镜像？当然这种情况会存在滚动更新的一个过程。&lt;/p>
&lt;p>那我们流水线可以这样设计，如下：&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/18f2621f-4692-48c5-a086-213c9333a04b/640" alt="">&lt;/p>
&lt;p>这样设计存在一个问题，那就是无法确定等待的时间，如果等待的时间很长，不仅很耗资源，也可能自动超时退出。&lt;/p>
&lt;p>那我们是不是可以将其拆分为两条流水线？流程如下：&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/18f2621f-4692-48c5-a086-213c9333a04b/640" alt="">&lt;/p>
&lt;p>我比较倾向第二种，这种方式流水线跑完了就退出，不会占用额外的资源。&lt;/p>
&lt;p>在开发流水线之前，我们需要先定义好命名标准，这样在操作的时候更加方便。&lt;/p>
&lt;ol>
&lt;li>流水线名字格式如下：&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-stable&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-canary&lt;/li>
&lt;li>deployment 的名字格式如下：&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-stable&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-canary&lt;/li>
&lt;li>service 的名字格式如下：&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-stable-svc&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-canary-svc&lt;/li>
&lt;li>ingress 的名字格式如下：&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-stable-ingress&lt;/li>
&lt;li>&amp;lt;APP_NAME&amp;gt;-canary-ingress&lt;/li>
&lt;/ol>
&lt;p>标准定义好之后，在实现的时候就简单多了。&lt;/p>
&lt;p>代码位置：&lt;a href="https://gitee.com/coolops/gary-devops.git">https://gitee.com/coolops/gary-devops.git&lt;/a>&lt;/p>
&lt;p>我定义了两个 Jenkinsfile，一个叫 canary.Jenkinsfile，一个叫 stable.Jenkinsfile，他们分别用来部署 canary 和 stable 版本。&lt;/p>
&lt;p>然后我们会创建两条流水线，如下：&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/18f2621f-4692-48c5-a086-213c9333a04b/640" alt="">
其中&lt;code>joker-gary-devops-canary&lt;/code>是用来部署 canary 版本，另外一个是用来部署 stable 版本。&lt;/p>
&lt;p>现在在集群里运行着 stable 版本，如下：&lt;/p>
&lt;pre>&lt;code># curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>我们修改了需求，更改了代码，变动如下：&lt;/p>
&lt;pre>&lt;code>package main
import (
&amp;quot;net/http&amp;quot;
&amp;quot;github.com/gin-gonic/gin&amp;quot;
)
func main() {
g := gin.Default()
g.GET(&amp;quot;/&amp;quot;, func(c *gin.Context) {
c.JSON(http.StatusOK, gin.H{
&amp;quot;version&amp;quot;: &amp;quot;v1&amp;quot;,
&amp;quot;data&amp;quot;: &amp;quot;hello Joker!&amp;quot;,
})
})
_ = g.Run(&amp;quot;:8080&amp;quot;)
}
&lt;/code>&lt;/pre>
&lt;p>首先发布 canary 流水线，待流水线发布完成，可以在集群中看到 canary 版本的 pod 以及 ingress 等，如下：&lt;/p>
&lt;pre>&lt;code># kubectl get po| grep canary
gray-devops-canary-59c88846dc-j2vlc 1/1 Running 0 55s
# kubectl get svc| grep canary
gray-devops-canary-svc ClusterIP 10.233.18.235 &amp;lt;none&amp;gt; 8080/TCP 3h14m
# kubectl get ingress| grep canary
gray-devops-canary-ingress joker.coolops.cn 192.168.100.61 80 63s
&lt;/code>&lt;/pre>
&lt;p>查看一下 canary-ingress 的内容，看是否是我们需要的，如下：&lt;/p>
&lt;pre>&lt;code># kubectl get ingress gray-devops-canary-ingress -o yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
annotations:
kubernetes.io/ingress.class: nginx
nginx.ingress.kubernetes.io/canary: &amp;quot;true&amp;quot;
nginx.ingress.kubernetes.io/canary-weight: &amp;quot;10&amp;quot;
creationTimestamp: &amp;quot;2022-02-15T05:43:32Z&amp;quot;
generation: 1
name: gray-devops-canary-ingress
namespace: default
resourceVersion: &amp;quot;412247041&amp;quot;
selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/gray-devops-canary-ingress
uid: fe13b38d-1f6f-45fb-8d89-504b4b8288ea
spec:
rules:
- host: joker.coolops.cn
http:
paths:
- backend:
serviceName: gray-devops-canary-svc
servicePort: 8080
status:
loadBalancer:
ingress:
- ip: 192.168.100.61
&lt;/code>&lt;/pre>
&lt;p>可以发现跟我们预设的一样。&lt;/p>
&lt;p>访问测试也没问题，如下：&lt;/p>
&lt;pre>&lt;code># curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello Joker!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello Joker!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}[root@master ~]# curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello world!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>现在就可以发布 stable 版本了，运行 stable 版本的流水线。发布完成后，集群里就只有 stable 版本的应用了，如下：&lt;/p>
&lt;pre tabindex="0">&lt;code># kubectl get po | grep gray
gray-devops-stable-7f977bb6cf-8jzgt 1/1 Running 0 35s
# kubectl get ingress | grep gray
gray-devops-stable-ingress joker.coolops.cn 192.168.100.61 80 111m
&lt;/code>&lt;/pre>&lt;p>通过域名访问也是符合预期的。&lt;/p>
&lt;pre>&lt;code># curl -H &amp;quot;Host: joker.coolops.cn&amp;quot; http://192.168.100.61
{&amp;quot;data&amp;quot;:&amp;quot;hello Joker!&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;v1&amp;quot;}
&lt;/code>&lt;/pre>
&lt;p>到此基本实现了自己的想法。&lt;/p>
&lt;blockquote>
&lt;p>说明：Jenkinsfile 中涉及的用户名和密码都保存在 Jenkins 的凭据中，插件需要安装 kubernetes deploy 插件，到插件中心搜索就行。&lt;/p>
&lt;/blockquote>
&lt;h2 id="最后">最后&lt;/h2>
&lt;p>上面我们基本实现了灰度发布的过程，也只是仅仅将手动的变成了自动。但是你有没有发现什么问题？&lt;/p>
&lt;p>首先需要切换流水线进行发布，其次是发布控制方面也不是很友好，比如要增加 canary 版本的节点，就需要我们手动去做。&lt;/p>
&lt;p>其实我更推荐使用 argo-rollouts 结合 argocd 进行灰度发布，argo-rollouts 自定义了一套 CRD 用于控制发布流程，可以省去很多手动操作过程，argocd 是基于 gitops 实现的一套软件，便于我们进行 CD 控制，也提供了 UI 面板进行操作。不过要用这套就需要更改现有的发布方式以及应用模板，不复杂，但是存在一定的风险，需要进行一定程度的测试。&lt;/p>
&lt;p>我是 乔克，《运维开发故事》公众号团队中的一员，一线运维农民工，云原生实践者，这里不仅有硬核的技术干货，还有我们对技术的思考和感悟，欢迎关注我们的公众号，期待和你一起成长！&lt;/p></description></item><item><title>Docs: 优化</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E4%BC%98%E5%8C%96/</guid><description>
&lt;p>原文链接：&lt;a href="https://mp.weixin.qq.com/s/H7nfSEswggu92myHiRqWHg">https://mp.weixin.qq.com/s/H7nfSEswggu92myHiRqWHg&lt;/a>&lt;/p>
&lt;h2 id="k8s-的-nginx-ingress-调优">k8s 的 Nginx Ingress 调优&lt;/h2>
&lt;h2 id="概述">概述&lt;/h2>
&lt;p>Nginx Ingress Controller 基于 Nginx 实现了 Kubernetes Ingress API，Nginx 是公认的高性能网关，但如果不对其进行一些参数调优，就不能充分发挥出高性能的优势。Nginx Ingress 工作原理：&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/dyz9tv/1628558200515-4cee865b-a872-4265-9170-6c2d3d101fd6.png" alt="image.png">&lt;/p>
&lt;h2 id="内核参数调优">内核参数调优&lt;/h2>
&lt;p>我们先看看通过内核的哪些参数能够提高 Ingress 的性能。保证在高并发环境下，发挥 Ingress 的最大性能。&lt;/p>
&lt;h3 id="调大全连接队列的大小">调大全连接队列的大小&lt;/h3>
&lt;p>TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)。在高并发环境下，如果队列过小，可能导致队列溢出，使得连接部分连接无法建立。要调大 Nginx Ingress 的连接队列，只需要调整 somaxconn 内核参数的值即可，但我想跟你分享下这背后的相关原理。Nginx 监听 socket 时没有读取 somaxconn，而是有自己单独的参数配置。在 nginx.conf 中 listen 端口的位置，还有个叫 backlog 参数可以设置，它会决定 nginx listen 的端口的连接队列大小。
server {
    listen  80  backlog=1024;
    &amp;hellip;&lt;/p>
&lt;p>backlog 是 listen(int sockfd, int backlog) 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；还有 Go 程序标准库在 listen 时，默认直接读取 somaxconn 作为队列大小。就是说，即便你的 somaxconn 配的很高，nginx 所监听端口的连接队列最大却也只有 511，高并发场景下可能导致连接队列溢出。所以在这个在 Nginx Ingress 中， Nginx Ingress Controller 会自动读取 somaxconn 的值作为 backlog 参数写到生成的 nginx.conf 中: &lt;a href="https://github.com/kubernetes/ingress-nginx/blob/controller-v0.34.1/internal/ingress/controller/nginx.go#L592">https://github.com/kubernetes/ingress-nginx/blob/controller-v0.34.1/internal/ingress/controller/nginx.go#L592&lt;/a> 也就是说，Nginx Ingress 的连接队列大小只取决于 somaxconn 的大小，这个值在 Nginx Ingress 默认为 4096，建议给 Nginx Ingress 设为 65535:
sysctl -w net.core.somaxconn=65535&lt;/p>
&lt;h3 id="扩大源端口范围">扩大源端口范围&lt;/h3>
&lt;p>根据《linux 中 TCP 三次握手与四次挥手介绍及调优》的介绍，我们知道客户端会占用端口。在高并发场景会导致 Nginx Ingress 使用大量源端口与 upstream 建立连接。源端口范围是在内核参数 net.ipv4.ip_local_port_range 中调整的。在高并发环境下，端口范围过小容易导致源端口耗尽，使得部分连接异常。Nginx Ingress 创建的 Pod 源端口范围默认是 32768-60999，建议将其扩大，调整为 1024-65535:
sysctl -w net.ipv4.ip_local_port_range=&amp;ldquo;1024 65535&amp;rdquo;&lt;/p>
&lt;h3 id="time_wait">TIME_WAIT&lt;/h3>
&lt;p>根据《linux 中 TCP 三次握手与四次挥手介绍及调优》的介绍，我们知道客户端会占用端口。当在 netns 中 TIME_WAIT 状态的连接就比较多的时候，源端口就会被长时间占用。因为而 TIME_WAIT 连接默认要等 2MSL 时长才释放，当这种状态连接数量累积到超过一定量之后可能会导致无法新建连接。所以建议给 Nginx Ingress 开启 TIME_WAIT 复用，即允许将 TIME_WAIT 连接重新用于新的 TCP 连接:
sysctl -w net.ipv4.tcp_tw_reuse=1&lt;/p>
&lt;p>减小 FIN_WAIT2 状态的参数 net.ipv4.tcp_fin_timeout 的时间和减小 TIME_WAIT 状态的参数 net.netfilter.nf_conntrack_tcp_timeout_time_wait 的时间 ，让系统尽快释放它们所占用的资源。
sysctl -w net.ipv4.tcp_fin_timeout=15
sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=30&lt;/p>
&lt;h3 id="调大增大处于-time_wait-状态的连接数">调大增大处于 TIME_WAIT 状态的连接数&lt;/h3>
&lt;p>Nginx 一定要关注这个值，因为它对你的系统起到一个保护的作用，一旦端口全部被占用，服务就异常了。tcp_max_tw_buckets 能帮你降低这种情况的发生概率，争取补救时间。在只有 60000 多个端口可用的情况下，配置为：
sysctl -w net.ipv4.tcp_max_tw_buckets = 55000&lt;/p>
&lt;h3 id="调大最大文件句柄数">调大最大文件句柄数&lt;/h3>
&lt;p>Nginx 作为反向代理，对于每个请求，它会与 client 和 upstream server 分别建立一个连接，即占据两个文件句柄，所以理论上来说 Nginx 能同时处理的连接数最多是系统最大文件句柄数限制的一半。系统最大文件句柄数由 fs.file-max 这个内核参数来控制，默认值为 838860，建议调大:
sysctl -w fs.file-max=1048576&lt;/p>
&lt;h3 id="配置示例">配置示例&lt;/h3>
&lt;p>给 Nginx Ingress Controller 的 Pod 添加 initContainers 来设置内核参数:
initContainers:
      - name: setsysctl
        image: busybox
        securityContext:
          privileged: true
        command:
        - sh
        - -c
        - |
          sysctl -w net.core.somaxconn=65535
          sysctl -w net.ipv4.ip_local_port_range=&amp;ldquo;1024 65535&amp;rdquo;
          sysctl -w net.ipv4.tcp_max_tw_buckets = 55000
          sysctl -w net.ipv4.tcp_tw_reuse=1
          sysctl -w fs.file-max=1048576
          sysctl -w net.ipv4.tcp_fin_timeout=15
          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=30&lt;/p>
&lt;h2 id="应用层配置调优">应用层配置调优&lt;/h2>
&lt;p>除了内核参数需要调优，Nginx 本身的一些配置也需要进行调优，下面我们来详细看下。&lt;/p>
&lt;h3 id="调高-keepalive-连接最大请求数">调高 keepalive 连接最大请求数&lt;/h3>
&lt;p>keepalive_requests 指令用于设置一个 keep-alive 连接上可以服务的请求的最大数量，当最大请求数量达到时，连接被关闭。默认是 100。这个参数的真实含义，是指一个 keep alive 建立之后，nginx 就会为这个连接设置一个计数器，记录这个 keep alive 的长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则 nginx 会强行关闭这个长连接，逼迫客户端不得不重新建立新的长连接。&lt;/p>
&lt;p>简单解释一下：QPS=10000 时，客户端每秒发送 10000 个请求(通常建立有多个长连接)，每个连接只能最多跑 100 次请求，意味着平均每秒钟就会有 100 个长连接因此被 nginx 关闭。同样意味着为了保持 QPS，客户端不得不每秒重新新建 100 个连接。因此，就会发现有大量的 TIME_WAIT 的 socket 连接(即使此时 keep alive 已经在 client 和 nginx 之间生效)。因此对于 QPS 较高的场景，非常有必要加大这个参数，以避免出现大量连接被生成再抛弃的情况，减少 TIME_WAIT。
如果是内网 Ingress，单个 client 的 QPS 可能较大，比如达到 10000 QPS，Nginx 就可能频繁断开跟 client 建立的 keepalive 连接，然后就会产生大量 TIME_WAIT 状态连接。我们应该尽量避免产生大量 TIME_WAIT 连接，所以，建议这种高并发场景应该增大 Nginx 与 client 的 keepalive 连接的最大请求数量，在 Nginx Ingress 的配置对应 keep-alive-requests，可以设置为 10000，参考: &lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#keep-alive-requests">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#keep-alive-requests&lt;/a> 同样的，Nginx 与 upstream 的 keepalive 连接的请求数量的配置是 upstream-keepalive-requests，参考: &lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#upstream-keepalive-requests">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#upstream-keepalive-requests&lt;/a>
但是，一般情况应该不必配此参数，如果将其调高，可能导致负载不均，因为 Nginx 与 upstream 保持的 keepalive 连接过久，导致连接发生调度的次数就少了，连接就过于 &amp;ldquo;固化&amp;rdquo;，使得流量的负载不均衡。&lt;/p>
&lt;h3 id="调高-keepalive-最大空闲连接数">调高 keepalive 最大空闲连接数&lt;/h3>
&lt;p>Nginx 针对 upstream 有个叫 keepalive 的配置，它不是 keepalive 超时时间，也不是 keepalive 最大连接数，而是 keepalive 最大空闲连接数。当这个数量被突破时，最近使用最少的连接将被关闭。&lt;/p>
&lt;p>简单解释一下：有一个 HTTP 服务，作为 upstream 服务器接收请求，响应时间为 100 毫秒。如果要达到 10000 QPS 的性能，就需要在 nginx 和 upstream 服务器之间建立大约 1000 条 HTTP 连接。nginx 为此建立连接池，然后请求过来时为每个请求分配一个连接，请求结束时回收连接放入连接池中，连接的状态也就更改为 idle。我们再假设这个 upstream 服务器的 keepalive 参数设置比较小，比如常见的 10. A、假设请求和响应是均匀而平稳的，那么这 1000 条连接应该都是一放回连接池就立即被后续请求申请使用，线程池中的 idle 线程会非常的少，趋近于零，不会造成连接数量反复震荡。B、显示中请求和响应不可能平稳，我们以 10 毫秒为一个单位，来看连接的情况(注意场景是 1000 个线程+100 毫秒响应时间，每秒有 10000 个请求完成)，我们假设应答始终都是平稳的，只是请求不平稳，第一个 10 毫秒只有 50,第二个 10 毫秒有 150：&lt;/p>
&lt;ol>
&lt;li>下一个 10 毫秒，有 100 个连接结束请求回收连接到连接池，但是假设此时请求不均匀 10 毫秒内没有预计的 100 个请求进来，而是只有 50 个请求。注意此时连接池回收了 100 个连接又分配出去 50 个连接，因此连接池内有 50 个空闲连接。&lt;/li>
&lt;li>然后注意看 keepalive=10 的设置，这意味着连接池中最多容许保留有 10 个空闲连接。因此 nginx 不得不将这 50 个空闲连接中的 40 个关闭，只留下 10 个。&lt;/li>
&lt;li>再下一个 10 个毫秒，有 150 个请求进来，有 100 个请求结束任务释放连接。150 - 100 = 50,空缺了 50 个连接，减掉前面连接池保留的 10 个空闲连接，nginx 不得不新建 40 个新连接来满足要求。&lt;/li>
&lt;/ol>
&lt;p>C、同样，如果假设相应不均衡也会出现上面的连接数波动情况。
它的默认值为 32，在高并发下场景下会产生大量请求和连接，而现实世界中请求并不是完全均匀的，有些建立的连接可能会短暂空闲，而空闲连接数多了之后关闭空闲连接，就可能导致 Nginx 与 upstream 频繁断连和建连，引发 TIME_WAIT 飙升。在高并发场景下可以调到 1000，参考: &lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#upstream-keepalive-connections">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#upstream-keepalive-connections&lt;/a>&lt;/p>
&lt;h3 id="网关超时">网关超时&lt;/h3>
&lt;p>ingress nginx 与 upstream pod 建立 TCP 连接并进行通信，其中涉及 3 个超时配置，我们也相应进行调优。proxy-connect-timeout 选项 设置 nginx 与 upstream pod 连接建立的超时时间，ingress nginx 默认设置为 5s，由于在 nginx 和业务均在内网同机房通信，我们将此超时时间缩短一些，比如 3 秒。参考：&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-connect-timeout">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-connect-timeout&lt;/a>
proxy-read-timeout 选项设置 nginx 与 upstream pod 之间读操作的超时时间，ingress nginx 默认设置为 60s，当业务方服务异常导致响应耗时飙涨时，异常请求会长时间夯住 ingress 网关，我们在拉取所有服务正常请求的 P99.99 耗时之后，将网关与 upstream pod 之间读写超时均缩短到 3s，使得 nginx 可以及时掐断异常请求，避免长时间被夯住。参考：&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-read-timeout">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-read-timeout&lt;/a>
&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-send-timeout">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-send-timeout&lt;/a>&lt;/p>
&lt;h3 id="调高单个-worker-最大连接数">调高单个 worker 最大连接数&lt;/h3>
&lt;p>max-worker-connections 控制每个 worker 进程可以打开的最大连接数，默认配置是 16384。在高并发环境建议调高，比如设置到 65536，这样可以让 nginx 拥有处理更多连接的能力，参考: &lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections&lt;/a>&lt;/p>
&lt;h3 id="优化重试机制">优化重试机制&lt;/h3>
&lt;p>nginx 提供了默认的 upstream 请求重试机制，默认情况下，当 upstream 服务返回 error 或者超时，nginx 会自动重试异常请求，并且没有重试次数限制。由于接入层 nginx 和 ingress nginx 本质都是 nginx，两层 nginx 都启用了默认的重试机制，异常请求时会出现大量重试，最差情况下会导致集群网关雪崩。接入层 nginx 一起解决了这个问题：接入层 nginx 必须使用 proxy_next_upstream_tries 严格限制重试次数，ingress nginx 则使用 proxy-next-upstream=&amp;ldquo;off&amp;quot;直接关闭默认的重试机制。参考：&lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-next-upstream">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#proxy-next-upstream&lt;/a>&lt;/p>
&lt;h3 id="开启-brotli-压缩">开启 brotli 压缩&lt;/h3>
&lt;p>参考: &lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#enable-brotli">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#enable-brotli&lt;/a>
压缩是时间换空间的通用方法。用 cpu 时间来换取大量的网络带宽，增大吞吐量。Brotli 是 Google 开发的一种压缩方法，于 2015 年发布。我们常用的压缩算法是 gzip（Ingress-nginx 也是默认使用 gzip），据说 brotli 要比 gzip 高出 20％至 30％的压缩率。默认的压缩算法是 gzip，压缩级别为 1，如需要启用 brotli，需要配置以下三个参数：&lt;/p>
&lt;ul>
&lt;li>enable-brotli: true 或 false，是否启用 brotli 压缩算法&lt;/li>
&lt;li>brotli-level: 压缩级别，范围 1~11，默认为 4，级别越高，越消耗 CPU 性能。&lt;/li>
&lt;li>brotli-types: 由 brotli 即时压缩的 MIME 类型&lt;/li>
&lt;/ul>
&lt;h3 id="配置示例-1">配置示例&lt;/h3>
&lt;p>Nginx 全局配置通过 configmap 配置(Nginx Ingress Controller 会 watch 并自动 reload 配置):
apiVersion: v1
kind: ConfigMap
metadata:
name: nginx-ingress-controller
data:
keep-alive-requests: &amp;ldquo;10000&amp;rdquo;
upstream-keepalive-connections: &amp;ldquo;200&amp;rdquo;
max-worker-connections: &amp;ldquo;65536&amp;rdquo;
proxy-connect-timeout: &amp;ldquo;3&amp;rdquo;
proxy-read-timeout: &amp;ldquo;3&amp;rdquo;
proxy-send-timeout: &amp;ldquo;3&amp;rdquo;
proxy-next-upstream: &amp;ldquo;off&amp;rdquo;
enable-brotli: &amp;ldquo;true&amp;rdquo;
brotli-level: &amp;ldquo;6&amp;rdquo;
brotli-types: &amp;ldquo;text/xml image/svg+xml application/x-font-ttf image/vnd.microsoft.icon application/x-font-opentype application/json font/eot application/vnd.ms-fontobject application/javascript font/otf application/xml application/xhtml+xml text/javascript application/x-javascript text/plain application/x-font-truetype application/xml+rss image/x-icon font/opentype text/css image/x-win-bitmap&amp;rdquo;&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;ul>
&lt;li>优化 nginx-ingress-controller 并发性能：&lt;a href="https://cloud.tencent.com/developer/article/1537695">https://cloud.tencent.com/developer/article/1537695&lt;/a>&lt;/li>
&lt;li>Nginx Ingress 配置参考: &lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/&lt;/a>&lt;/li>
&lt;li>Tuning NGINX for Performance: &lt;a href="https://www.nginx.com/blog/tuning-nginx/">https://www.nginx.com/blog/tuning-nginx/&lt;/a>&lt;/li>
&lt;li>ngx_http_upstream_module 官方文档: &lt;a href="http://nginx.org/en/docs/http/ngx%5C_http%5C_upstream%5C_module.html">http://nginx.org/en/docs/http/ngx\_http\_upstream\_module.html&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>