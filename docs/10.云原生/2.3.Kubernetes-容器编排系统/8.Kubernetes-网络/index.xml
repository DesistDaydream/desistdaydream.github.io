<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 8.Kubernetes 网络</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/</link><description>Recent content in 8.Kubernetes 网络 on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 8.Kubernetes 网络</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/8.Kubernetes-%E7%BD%91%E7%BB%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/8.Kubernetes-%E7%BD%91%E7%BB%9C/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">官方文档,概念-集群管理-集群网络&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>kubernetes 的整体网络分为以下三类&lt;/p>
&lt;ul>
&lt;li>Node IP(各节点网络) #&lt;/li>
&lt;li>Cluster IP(Service 网络) # 虚拟的，在 Netfilter 结构上，就是主机上 iptables 规则中的地址&lt;/li>
&lt;li>Pod IP(Pod 网络) #&lt;/li>
&lt;/ul>
&lt;p>网络是 Kubernetes 的核心部分，Kubernetes 中有下面几个点需要互相通信&lt;/p>
&lt;ol>
&lt;li>同一个 Pod 内的多个容器间通信，通过各容器的 lo 通信&lt;/li>
&lt;li>Pod 之间的通信，Pod IP&amp;lt;&amp;ndash;&amp;gt;Pod IP
&lt;ol>
&lt;li>overlay 叠加网络转发二层报文，通过隧道方式转发三层报文&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Pod 与 Service 之间的通信，Pod IP&amp;lt;&amp;ndash;&amp;gt;Cluster IP。详见 &lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes%20%E7%BD%91%E7%BB%9C/Service(%E6%9C%8D%E5%8A%A1).md">Service(服务)&lt;/a>。&lt;/li>
&lt;li>Service 与集群外部客户端的通信。详见 &lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes%20%E7%BD%91%E7%BB%9C/Service(%E6%9C%8D%E5%8A%A1).md">Service(服务)&lt;/a>。&lt;/li>
&lt;/ol>
&lt;p>Kubernetes 的宗旨就是在应用之间共享机器。 通常来说，共享机器需要两个应用之间不能使用相同的端口，但是在多个应用开发者之间 去大规模地协调端口是件很困难的事情，尤其是还要让用户暴露在他们控制范围之外的集群级别的问题上。&lt;/p>
&lt;p>动态分配端口也会给系统带来很多复杂度 - 每个应用都需要设置一个端口的参数， 而 API 服务器还需要知道如何将动态端口数值插入到配置模块中，服务也需要知道如何找到对方等等。 与其去解决这些问题，Kubernetes 选择了其他不同的方法。&lt;/p>
&lt;h2 id="kubernetes-网络模型">Kubernetes 网络模型&lt;/h2>
&lt;p>每一个 Pod 都有它自己的 IP 地址，这就意味着你不需要显式地在每个 Pod 之间创建链接， 你几乎不需要处理容器端口到主机端口之间的映射。 这将创建一个干净的、向后兼容的模型，在这个模型里，从端口分配、命名、服务发现、 负载均衡、应用配置和迁移的角度来看，Pod 可以被视作虚拟机或者物理主机。&lt;/p>
&lt;p>Kubernetes 对所有网络设施的实施，都需要满足以下的基本要求（除非有设置一些特定的网络分段策略）：&lt;/p>
&lt;ul>
&lt;li>节点上的 Pod 可以不通过 NAT 和其他任何节点上的 Pod 通信&lt;/li>
&lt;li>节点上的代理（比如：系统守护进程、kubelet） 可以和节点上的所有 Pod 通信&lt;/li>
&lt;/ul>
&lt;p>备注：仅针对那些支持 Pods 在主机网络中运行的平台(比如：Linux) ：&lt;/p>
&lt;ul>
&lt;li>那些运行在节点的主机网络里的 Pod 可以不通过 NAT 和所有节点上的 Pod 通信&lt;/li>
&lt;/ul>
&lt;p>这个模型不仅不复杂，而且还和 Kubernetes 的实现廉价的从虚拟机向容器迁移的初衷相兼容， 如果你的工作开始是在虚拟机中运行的，你的虚拟机有一个 IP ， 这样就可以和其他的虚拟机进行通信，这是基本相同的模型。&lt;/p>
&lt;p>Kubernetes 的 IP 地址存在于 Pod 范围内 - 容器分享它们的网络命名空间 - 包括它们的 IP 地址。 这就意味着 Pod 内的容器都可以通过 localhost 到达各个端口。 这也意味着 Pod 内的容器都需要相互协调端口的使用，但是这和虚拟机中的进程似乎没有什么不同， 这也被称为“一个 Pod 一个 IP” 模型。&lt;/p>
&lt;p>如何实现这一点是正在使用的容器运行时的特定信息。&lt;/p>
&lt;p>也可以在 node 本身通过端口去请求你的 Pod （称之为主机端口）， 但这是一个很特殊的操作。转发方式如何实现也是容器运行时的细节。 Pod 自己并不知道这些主机端口是否存在。&lt;/p>
&lt;h1 id="network-plugin网络插件--实现-kubernetes-网络模型的方式">Network Plugin(网络插件) — 实现 Kubernetes 网络模型的方式&lt;/h1>
&lt;p>官方文档：&lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/&lt;/a>&lt;/p>
&lt;p>Kubernetes 中的网络插件有几种类型：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CNI 插件： 遵守 appc/CNI 规约，为互操作性设计。详见：CNI 介绍&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kubenet 插件：使用 bridge 和 host-local CNI 插件实现了基本的 cbr0&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: CNI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/CNI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/CNI/</guid><description/></item><item><title>Docs: Gateway API</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Gateway-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Gateway-API/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes-sigs/gateway-api/">GitHub 项目，kubernetes-sigs/gateway-api&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://lib.jimmysong.io/kubernetes-handbook/service-discovery/gateway/">云原生资料库-Kubernetes 基础教程，服务发现与路由-GatewayAPI&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/JeuQZv_CN1c9qip7JMyzmg">公众号-MoeLove，Gateway API： 在Kubernetes网络中掀起一场革命&lt;/a>&lt;/p></description></item><item><title>Docs: Ingress</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/</guid><description/></item><item><title>Docs: kube-proxy(实现 Service 功能的组件)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/</guid><description/></item><item><title>Docs: Kubernetes DNS</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/</guid><description/></item><item><title>Docs: NetworkPolicy 网络策略</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/NetworkPolicy-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/NetworkPolicy-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</guid><description>
&lt;p>如果想要正常使用 NetworkPolicy 对象，则集群的网路插件必须要支持该功能&lt;/p>
&lt;p>使用 NetworkPolicy 对象来定义网络策略(注意：该定义的网络策略只能适用于某个 namesapce 下的 Pod，可以在 metadata 中定义生效的 namespace)&lt;/p>
&lt;p>一个网络策略中包含两中类型的规则，规则用于控制数据流量(Traffic)，&lt;/p>
&lt;ol>
&lt;li>
&lt;p>ingress # 入口(入站)规则，列出所选择的 Pod，把入口规则应用其上&lt;/p>
&lt;ol>
&lt;li>port，定义允许还是拒绝哪些端口，ingress 规则中为，从外面来的可以从自己哪个端口进来&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>from # ingress 定义 from(目标过来的规则，即从哪来的可以入)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>ipBlock # 定义从哪来的 IP 段可以进来&lt;/p>
&lt;ul>
&lt;li>except # 定义完 ipBlock 后，定义 IP 段内的某些事不能进来&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>namespaceSelector # 定义来自哪些 namesapce 的可以进来&lt;/p>
&lt;/li>
&lt;li>
&lt;p>podSelector # 定义来自哪些 Pod 的可以进来&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>egress # 出口(出站)规则，列出所选择的 Pod，把出口规则应用其上&lt;/p>
&lt;ol>
&lt;li>port，定义允许还是拒绝哪些端口，egress 规则中，到哪的端口可以出去&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>to # egress 定义 to(到目标的规则，即到哪的可以出)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>ipBlock # 定义到哪的 IP 段可以出去&lt;/p>
&lt;ul>
&lt;li>except # 定义完 ipBlock 后，定义 IP 段内的某些事不能出去&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>namespaceSelector # 定义到哪些 namesapce 的可以出去&lt;/p>
&lt;/li>
&lt;li>
&lt;p>podSelector # 定义到哪些 Pod 的可以出去&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>规则说明&lt;/p>
&lt;ol>
&lt;li>
&lt;p>若不定义该规则，则默认全部允许&lt;/p>
&lt;/li>
&lt;li>
&lt;p>若定义了规则，那么规则默认拒绝，定义了哪些(ip、namespace、pod)那么定义的这些就允许&lt;/p>
&lt;/li>
&lt;li>
&lt;p>若定义的规则且内容为{}，说明全部允许&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对 Pod1 使用入站规则设定 Pod2 不能进，那么 Pod2 无法 ping 通 Pod1，但是 Pod1 可以 ping 通 pod2&lt;/p>
&lt;/li>
&lt;li>
&lt;p>注意：出入规则为单向限制，仅对请求报文限制，响应报文不做限制。比如，对我使用入站规则禁止你 ping 我，但是我依然可以 ping 你，但是到某 IP 还是可以的，除非禁用了到那些 IP 的 Pod，那么就不能出也不能进了。该策略跟那种限制了出和入其中一个就都不行的不一样&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;p>网络策略中还包括规则的生效范围、(即把规则应用于 Pod 上和定义两个规则是否生效）。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>podSelector # 通过标签选择器，选择出把该策略的规则应用于哪些 Pod 上(默认为{}空，则对所有 Pod 生效)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>policyTypes # 列出网络策略涉及的规则类型。列出哪个规则，哪个规则生效，生效后默认拒绝所有，需要再定义规则以便允许，如果不定义规则那么什么都访问不了；如果两个规则都没列出，那么后面定义了哪个规则，则哪个规则生效。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/zghpo8/1616117994284-0bc4626b-55c8-4f72-8e67-3e20bbe787c3.jpeg" alt="">&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/zghpo8/1616117994290-5d61a239-4ce3-4fcd-94d8-a0f102cdb416.jpeg" alt="">&lt;/p></description></item><item><title>Docs: Service(服务)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Service%E6%9C%8D%E5%8A%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes-%E7%BD%91%E7%BB%9C/Service%E6%9C%8D%E5%8A%A1/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/">官方文档，概念-服务，负载均衡，网络-服务&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Service 资源可以将一组运行在 Pods 上的应用程序暴露为网络服务，这是一种抽象的功能，说白了 Service 资源实现 服务发现，执行访问 POD 的任务、4 层代理 等功能&lt;/p>
&lt;p>为什么要使用 Service？&lt;/p>
&lt;p>Deployment 可以部署多个副本，每个 Pod 都有自己的 IP，外界如何访问这些副本呢？通过 Pod 的 IP 吗？要知道 Pod 很可能会被频繁地销毁和重启，它们的 IP 会发生变化，用 IP 来访问不太现实。答案是 Service。Service 作为访问 Pod 的接入层来使用。service 就像 lvs 的 director 一样，充当一个调度器的作用。&lt;/p>
&lt;p>Service 定义了外界访问一组特定 Pod 的方式。Service 有自己的 IP 和 PORT ，Service 为 Pod 提供了负载均衡。&lt;/p>
&lt;p>可以把 Service 想象成负载均衡功能的前端，该 Service 下的 Pod 是负载均衡功能的后端。通过其自动创建的 ipvs 或者 iptables 的规则，访问 Service 的 IP:PORT，然后转发数据到后端的 Pod&lt;/p>
&lt;h2 id="endpoints">Endpoints&lt;/h2>
&lt;p>注意：在 service 与 pod 中间，还有一个中间层，这个中间层就是 Endpoints 资源。&lt;/p>
&lt;p>Endpoints 是一个由 IP 和 PORT 组成的 endpoint 列表，Endpoints 的这些 IP 和 PORT 来自于由 Service 的标签选择器匹配到的 pod 资源(也可在 service 不适用标签选择器的时候，手动指定 endpoints 的 IP 与 PORT)。默认情况下，创建 Service 资源时，会自动创建同名的 Endpoints 资源。从抽象角度看，service 所关联的每一个 pod 其实都是 Endpoints 资源列表中的一个 endpoint&lt;/p>
&lt;h1 id="service-的实现">Service 的实现&lt;/h1>
&lt;p>Service 是 k8s 中的一种资源，但是如果想要实现 Service 资源定义的那些内容，则需要 &lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes%20%E7%BD%91%E7%BB%9C/kube-proxy/kube-proxy.md">kube-proxy&lt;/a> 这个程序，实际上，创建一个 service，就是让 kube-proxy 创建一系列 iptables 或者 ipvs 规则&lt;/p>
&lt;ul>
&lt;li>userspace：在 1.1.0 版本之前使用该模型，由于需要把报文转到内核空间再回到用户空间过于低效&lt;/li>
&lt;li>iptables：通过 Kube-proxy 监听 Pod 变化在宿主机上生成并维护。由于 kube-proxy 需要在总之循环里不断得刷新 iptables 规则来确保它们始终是正确的，这样当 Host 上有大量 Pod 时，会产生极多 Iptables 规则，大量占用 Host 的 CPU 资源，这时候 ipvs 模型就可以解决该问题&lt;/li>
&lt;li>ipvs：将负载均衡与代理功能从 iptables 手中接过来，一些辅助性并且数量不多的(比如包过滤、SNAT 等)操作依然由 iptables 完成。如果想要启用 ipvs 工作模型，那么需要在/etc/sysconfig/kubelet 该配置文件中加入 KUBE_PROXY_MODE=ipvs 这一行，且给 linux 装载 ipvs 模块和连接跟踪模块&lt;/li>
&lt;/ul>
&lt;p>有的 CNI 插件，比如 &lt;a href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes%20%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/8.Kubernetes%20%E7%BD%91%E7%BB%9C/CNI/Cilium/Cilium.md">Cilium&lt;/a>、等等，其项目内部也基于自身的应用场景，做出了可以替代 kube-proxy 的程序，以更适用于本身的逻辑。&lt;/p>
&lt;h1 id="publishing-service发布-service">Publishing Service(发布 Service)&lt;/h1>
&lt;p>发布 Service 是指将 Service 暴露出去以供其他客户端访问他，并将请求转给其所关联的后端 Pod。Service 有多种类型，不同的类型对应不同的发布 Service 方式，默认的类型为 &lt;code>ClusterIP&lt;/code>&lt;/p>
&lt;ul>
&lt;li>ClusterIP # 通过集群的内部 IP 暴露 Service。该 Service 只能被暴露在进群内部，集群外部无法访问。
&lt;ul>
&lt;li>Service 暴露的集群内部 IP 由 kube-controller-manager 程序的 &lt;code>--service-cluster-ip-range&lt;/code> 标志控制。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>NodePort # 在集群中每个节点 IP 的静态端口上暴露 Service 给集群外部，每个节点上将会创建到 Service 的 CluseterIP 的路由条目，以便我们从集群外部访问 NodePort 类型的 Service&lt;/li>
&lt;li>LoadBalancer # 使用云提供商的负载均衡器暴露 Service 给集群外部。&lt;/li>
&lt;li>ExternalName #&lt;/li>
&lt;/ul>
&lt;p>我们还可以使用 Kubernetes 的 Ingress 资源暴露 Service。&lt;/p>
&lt;h2 id="clusterip仅用于-kubernetes-集群内通信">ClusterIP：仅用于 kubernetes 集群内通信&lt;/h2>
&lt;p>每个 Service 创建完成后一般都会有一个 cluster-ip(headless 类型的 service 没有)，这个 IP 是 Kubernetes 集群的专用 IP，是一种虚拟 IP，可以把它当做 lvs 中的 vip。只不过这些 IP 并不能直接访问到，而是在 Service 创建完成后，在 iptables 或者 ipvs 规则中所使用的 IP。Kubernetes 创建完成后，cluster-ip 默认的使用范围是 10.96.0.0/12&lt;/p>
&lt;ul>
&lt;li>headless：无头服务，当不需要使用负载均衡和单一服务 IP 的时候，可以给 ClusterIP 设为 None。kube-proxy 不使用这些服务并且平台(platform)没有负载均衡和代理
&lt;ul>
&lt;li>headless 由于没有 cluster-ip，所以是通过域名的方式来让外部访问到该 service 的 endpoint 的，如果有 cluster-ip 的话，则 ServiceName.NameSpaceName.svc.cluster.local 的域名会解析到该 service 的 cluster-ip 上，如果是 headless 的话，域名解析的结果则是所有 endpoint 的 ip，客户端每次向此 headless 类型的 service 发起的请求，将直接接入到各个 endpoint 上，不再由 service 资源进行代理转发，而是由 DNS 服务器收到查询请求时以轮训的方式返回各个 endpoint 的 IP。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="nodeport用于从集群外部访问-service">NodePort：用于从集群外部访问 Service&lt;/h2>
&lt;p>通过 kube-proxy 添加 iptables 规则，把流量通过主机的 port 转发到 Service 的 port 上。&lt;/p>
&lt;p>NodePort 建立在 ClusterIP 类型之上，NodePort 会将宿主机的 port 与 service 的 port 所关联，这样就可以将 service 乃至其 endpoint 都可以让集群外部直接访问。如果定义 NodePort 时不指定，则会随机选择宿主机上的 30000 至 32767 之间的一个端口作为 NodePort 的 PORT。&lt;/p>
&lt;p>比如下图画红框的部分就表示冒号前是 service 的 port，冒号后是宿主机上的 port，当访问宿主机的 port 的时候，该访问请求会被 iptables 或者 ipvs 规则转发到 service 的 port 上，然后转交给其 endpoint&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/fd3b0g/1616118462642-7b49b026-38af-4641-84db-d58f9cbfbed8.jpeg" alt="">&lt;/p>
&lt;p>但是，请注意！NodePort 有个很致命的确定，&lt;a href="">kube-proxy 无法绑定 NodePort 案例&lt;/a>&lt;/p>
&lt;h2 id="loadbalancer一般当-kubernetes-部署在云上时使用">LoadBalancer：一般当 kubernetes 部署在云上时使用&lt;/h2>
&lt;p>LoadBalancer 建立在 NodePort 之上，可以将实现 Service 资源的默认负载均衡器(i.e.kube-proxy)替换为其他的负载均衡器。这时可以直接通过负载均衡器暴露的 IP + PORT 直接访问 Service 后端关联的 Pod。&lt;/p>
&lt;p>现阶段，想让 Service 对接外部负载均衡器，在指定 Service 的 &lt;code>spec.type&lt;/code> 字段的值为 LoadBalancer 以外，还需要配置 &lt;code>metadata.annotations&lt;/code> 字段，以便让外部负载均衡器的控制器获取 Service 信息以便对自己进行配置。&lt;/p>
&lt;p>当我们创建了一个 LoadBalancer 类型的 Service 后，该 Sevice 对象将会获得一个 External-IP，通常这个 IP 是由外部负载均衡器的控制器提供的：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kubectl get svc nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME TYPE CLUSTER-IP EXTERNAL-IP PORT&lt;span style="color:#f92672">(&lt;/span>S&lt;span style="color:#f92672">)&lt;/span> AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nginx LoadBalancer 10.100.126.91 192.168.0.101 80:31555/TCP 4s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时，通过 LB 控制器，可以让 LB 自动关联到 Service 后端的 Pod 上，通常来说 &lt;code>192.168.0.101&lt;/code> 是 LB 设备的 VIP，访问 &lt;code>192.168.0.101&lt;/code> 的 31555 端口会自动负载均衡到 nginx Service 后端的 Pod&lt;/p>
&lt;p>常见的负载均衡器：&lt;/p>
&lt;ul>
&lt;li>各大公有云厂商的 LB。比如华为的 ELB、等&lt;/li>
&lt;li>&lt;a href="https://github.com/metallb/metallb">MetalLB&lt;/a> #
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/BY6hrLjaWfPYJzYmpbl1fQ">公众号-运维开发故事，Kubernetes 开源 LoadBalancer-Metallb(BGP)&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/openelb/openelb">OpenELB&lt;/a> #&lt;/li>
&lt;/ul>
&lt;h2 id="externalname把集群外部的服务引入到集群内部">ExternalName：把集群外部的服务引入到集群内部&lt;/h2>
&lt;h2 id="external-ips外部-ip">External IPs(外部 IP)&lt;/h2>
&lt;p>为 Service 对象配置 &lt;code>spec.externalIPs&lt;/code> 字段后，会在节点上创建一个 ipvs 条目，Director 为 externalIPs 的值，RealServer 为 Service 关联的后端 Pod 的 IP。此时，只要为客户端配置一条路由规则，目的地址是 ExternalIP 的包都转发给 K8S 的节点，就可以从集群外部访问 Service 了。&lt;/p>
&lt;blockquote>
&lt;p>注意：externalIPs 不受 Kubernetes 管理&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/fd3b0g/1649947301381-c990dbc0-9232-4171-ac34-905219da5d8a.png" alt="image.png">
External IP 还会在使用 LoadBalancer 类型的 Service 时，自动被公有云厂商的 LB 填充，通常都是将 ingress-controller-nginx 的 Service 配置为 LoadBalancer 类型以对接公有云厂商的 LB。&lt;/p>
&lt;h2 id="手动指定-endpoints">手动指定 Endpoints&lt;/h2>
&lt;p>不指定 selector，手动创建一个与 Service 同名的 Endpoints，这样就能实现手动指定该 Service 所关联的 Endpoints&lt;/p></description></item></channel></rss>