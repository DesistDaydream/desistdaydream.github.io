<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – Kubelet 特性</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/</link><description>Recent content in Kubelet 特性 on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 10.1.bootstrap 认证配置步骤介绍</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/10.1.bootstrap-%E8%AE%A4%E8%AF%81%E9%85%8D%E7%BD%AE%E6%AD%A5%E9%AA%A4%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/10.1.bootstrap-%E8%AE%A4%E8%AF%81%E9%85%8D%E7%BD%AE%E6%AD%A5%E9%AA%A4%E4%BB%8B%E7%BB%8D/</guid><description>
&lt;p>kubelet 授权 kube-apiserver 的一些操作 exec run logs 等&lt;/p>
&lt;p>&lt;strong>RBAC 只需创建一次就可以&lt;/strong>&lt;/p>
&lt;pre>&lt;code>kubectl create clusterrolebinding kube-apiserver:kubelet-apis --clusterrole=system:kubelet-api-admin --user kubernetes
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>创建 bootstrap kubeconfig 文件&lt;/strong>&lt;/p>
&lt;p>注意: token 生效时间为 1day , 超过时间未创建自动失效，需要重新创建 token&lt;/p>
&lt;pre>&lt;code>kubeadm token create --description kubelet-bootstrap-token --groups system:bootstrappers:kubernetes-clientgroup --kubeconfig ~/.kube/config
&lt;/code>&lt;/pre>
&lt;p>查看生成的 token&lt;/p>
&lt;pre>&lt;code>kubeadm token list --kubeconfig ~/.kube/config
&lt;/code>&lt;/pre>
&lt;p>TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS&lt;/p>
&lt;p>** 2kcmsb.hyl5s4g0l1mkff9z** &lt;strong>23h&lt;/strong> 2018-11-16T11:08:00+08:00 authentication,signing kubelet-bootstrap-token system:bootstrappers:kubernetes-clientgroup&lt;/p>
&lt;p>配置集群参数，生成 kubernetes-clientgroup-bootstrap.kubeconfig&lt;/p>
&lt;pre>&lt;code>kubectl config set-cluster kubernetes \
--certificate-authority=/etc/kubernetes/ssl/ca.pem \
--embed-certs=true \
--server=https://192.168.1.7:6443 \ #master节点ip
--kubeconfig=kubernetes-clientgroup-bootstrap.kubeconfig
&lt;/code>&lt;/pre>
&lt;p>配置客户端认证&lt;/p>
&lt;pre>&lt;code>kubectl config set-credentials kubelet-bootstrap \
--token= 2kcmsb.hyl5s4g0l1mkff9z \ #上面生成的token
--kubeconfig=kubernetes-clientgroup-bootstrap.kubeconfig
&lt;/code>&lt;/pre>
&lt;p>配置关联&lt;/p>
&lt;pre>&lt;code>kubectl config set-context default \
--cluster=kubernetes \
--user=kubelet-bootstrap \
--kubeconfig=kubernetes-clientgroup-bootstrap.kubeconfig
&lt;/code>&lt;/pre>
&lt;p>配置默认关联&lt;/p>
&lt;pre>&lt;code>kubectl config use-context default --kubeconfig=kubernetes-clientgroup-bootstrap.kubeconfig
&lt;/code>&lt;/pre>
&lt;p>拷贝生成的 kubernetes-clientgroup-bootstrap.kubeconfig 文件到其它所有的 node 节点，并重命名&lt;/p>
&lt;pre>&lt;code>scp kubernetes-clientgroup-bootstrap.kubeconfig 192.168.1.8:/etc/kubernetes/bootstrap.kubeconfig
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>配置 bootstrap RBAC 权限&lt;/strong>&lt;/p>
&lt;pre>&lt;code>kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers
否则报如下错误
failed to run Kubelet: cannot create certificate signing request: certificatesigningrequests.certificates.k8s.io is forbidden: User &amp;quot;system:bootstrap:1jezb7&amp;quot; cannot create
certificatesigningrequests.certificates.k8s.io at the cluster scope
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>创建自动批准相关 CSR 请求的 ClusterRole&lt;/strong>&lt;/p>
&lt;pre>&lt;code>vi /etc/kubernetes/tls-instructs-csr.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver
rules:
- apiGroups: [&amp;quot;certificates.k8s.io&amp;quot;]
resources: [&amp;quot;certificatesigningrequests/selfnodeserver&amp;quot;]
verbs: [&amp;quot;create&amp;quot;]
&lt;/code>&lt;/pre>
&lt;p>导入 yaml 文件&lt;/p>
&lt;pre>&lt;code>kubectl apply -f /etc/kubernetes/tls-instructs-csr.yaml
&lt;/code>&lt;/pre>
&lt;p>clusterrole.rbac.authorization.k8s.io &amp;ldquo;system:certificates.k8s.io:certificatesigningrequests:selfnodeserver&amp;rdquo; created&lt;/p>
&lt;p>查看创建的 ClusterRole&lt;/p>
&lt;pre>&lt;code>kubectl describe ClusterRole/system:certificates.k8s.io:certificatesigningrequests:selfnodeserver
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>将 ClusterRole 绑定到适当的用户组&lt;/strong>&lt;/p>
&lt;pre>&lt;code># 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-approve-csr --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --group=system:bootstrappers
# 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes
# 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求
kubectl create clusterrolebinding node-server-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver --group=system:nodes
查看已有绑定 kubectl get clusterrolebindings
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>动态 kubelet 配置&lt;/strong>&lt;/p>
&lt;p>创建 kubelet 服务文件&lt;/p>
&lt;pre>&lt;code>mkdir -p /var/lib/kubelet
vim /etc/systemd/system/kubelet.service
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service
[Service]
WorkingDirectory=/var/lib/kubelet
ExecStart=/usr/local/bin/kubelet \
--hostname-override=k8s-wjoyxt \ #本地node节点的hostname
--pod-infra-container-image=jicki/pause-amd64:3.1 \ #pod的基础镜像，即gcr的gcr.io/google_containers/pause-amd64:3.1镜像
--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \
--kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
--config=/etc/kubernetes/kubelet.config.json \
--cert-dir=/etc/kubernetes/ssl \
--logtostderr=true \
--v=2
[Install]
WantedBy=multi-user.target创建 kubelet config 配置文件
vim /etc/kubernetes/kubelet.config.json
{
&amp;quot;kind&amp;quot;: &amp;quot;KubeletConfiguration&amp;quot;,
&amp;quot;apiVersion&amp;quot;: &amp;quot;kubelet.config.k8s.io/v1beta1&amp;quot;,
&amp;quot;authentication&amp;quot;: {
&amp;quot;x509&amp;quot;: {
&amp;quot;clientCAFile&amp;quot;: &amp;quot;/etc/kubernetes/ssl/ca.pem&amp;quot;
},
&amp;quot;webhook&amp;quot;: {
&amp;quot;enabled&amp;quot;: true,
&amp;quot;cacheTTL&amp;quot;: &amp;quot;2m0s&amp;quot;
},
&amp;quot;anonymous&amp;quot;: {
&amp;quot;enabled&amp;quot;: false
}
},
&amp;quot;authorization&amp;quot;: {
&amp;quot;mode&amp;quot;: &amp;quot;Webhook&amp;quot;,
&amp;quot;webhook&amp;quot;: {
&amp;quot;cacheAuthorizedTTL&amp;quot;: &amp;quot;5m0s&amp;quot;,
&amp;quot;cacheUnauthorizedTTL&amp;quot;: &amp;quot;30s&amp;quot;
}
},
&amp;quot;address&amp;quot;: &amp;quot;172.16.6.66&amp;quot;, #本地node节点的IP
&amp;quot;port&amp;quot;: 10250,
&amp;quot;readOnlyPort&amp;quot;: 0,
&amp;quot;cgroupDriver&amp;quot;: &amp;quot;cgroupfs&amp;quot;,
&amp;quot;hairpinMode&amp;quot;: &amp;quot;promiscuous-bridge&amp;quot;,
&amp;quot;serializeImagePulls&amp;quot;: false,
&amp;quot;RotateCertificates&amp;quot;: true,
&amp;quot;featureGates&amp;quot;: {
&amp;quot;RotateKubeletClientCertificate&amp;quot;: true,
&amp;quot;RotateKubeletServerCertificate&amp;quot;: true
},
&amp;quot;MaxPods&amp;quot;: &amp;quot;512&amp;quot;,
&amp;quot;failSwapOn&amp;quot;: false,
&amp;quot;containerLogMaxSize&amp;quot;: &amp;quot;10Mi&amp;quot;,
&amp;quot;containerLogMaxFiles&amp;quot;: 5,
&amp;quot;clusterDomain&amp;quot;: &amp;quot;cluster.local.&amp;quot;,
&amp;quot;clusterDNS&amp;quot;: [&amp;quot;10.254.0.2&amp;quot;]
}
&lt;/code>&lt;/pre>
&lt;p>以上配置中:&lt;/p>
&lt;p>cluster.local. 为 kubernetes 集群的 domain&lt;/p>
&lt;p>10.254.0.2 预分配的 dns 地址&lt;/p>
&lt;p>&amp;ldquo;clusterDNS&amp;rdquo;: [&amp;ldquo;10.254.0.2&amp;rdquo;] 可配置多个 dns 地址，逗号可开, 可配置宿主机 dns&lt;/p>
&lt;p>&lt;strong>启动 Kubelet 服务&lt;/strong>&lt;/p>
&lt;pre>&lt;code>systemctl daemon-reload
systemctl enable kubelet
systemctl start kubelet
systemctl status kubelet
&lt;/code>&lt;/pre>
&lt;p>验证 nodes&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/crt3fo/1616120007572-6678d863-7c6f-4000-8c7f-6e7c17ff42ca.png" alt="">&lt;/p>
&lt;p>注意:这里的 ROLES 是节点标签&lt;/p>
&lt;p>关于 kubectl get node 中的 ROLES 的标签&lt;/p>
&lt;p>单 Master 打标签 kubectl label node es-60 node-role.kubernetes.io/master=&amp;quot;&amp;quot;，当标签为 NoSchedule，表示不进行资源调度&lt;/p>
&lt;p>更新标签命令为 kubectl label nodes es-60 node-role.kubernetes.io/master=:NoSchedule &amp;ndash;overwrite&lt;/p>
&lt;p>单 Node 打标签 kubectl label node es-61 node-role.kubernetes.io/node=&amp;quot;&amp;quot;&lt;/p>
&lt;p>关于删除 label 可使用 - 号相连 如: kubectl label nodes es-61 node-role.kubernetes.io/node-&lt;/p>
&lt;p>查看自动生成的证书配置文件&lt;/p>
&lt;pre>&lt;code>ls -lt /etc/kubernetes/ssl/kubelet-*
&lt;/code>&lt;/pre></description></item><item><title>Docs: Garbage Collection(垃圾回收)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/Garbage-Collection%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/Garbage-Collection%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</guid><description>
&lt;h1 id="kubelet-garbage-collection-介绍">kubelet Garbage Collection 介绍&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>官方文档：&lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/kubelet-garbage-collection/">https://kubernetes.io/docs/concepts/cluster-administration/kubelet-garbage-collection/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>垃圾回收是 kubelet 的一个有用功能，它将清理未使用的镜像和容器。 Kubelet 将每分钟对容器执行一次垃圾回收，每五分钟对镜像执行一次垃圾回收。&lt;/p>
&lt;p>注意！！不建议使用外部垃圾收集工具，因为这些工具可能会删除原本期望存在的容器进而破坏 kubelet 的行为。&lt;/p>
&lt;p>比如：
使用 docker container prune -f 命令，清理了节点上不再使用的容器，这时候，在 /var/log/pods/ContainerNAME/* 目录下的日志软链接是不会清除的，因为这个软连接由 kubelet 管理，并且只有在日志关联的容器被 kubelet 清理时，才会清理该软链接。所以容器没了，软连接 kubelet 也就不管了~&lt;/p>
&lt;p>解决办法：
find -L /var/log/pods -type l -delete 直接直接该命令即可&lt;/p>
&lt;p>代码路径：./pkg/kubelet/kuberuntime/kuberuntime_gc&lt;/p>
&lt;h2 id="镜像回收">镜像回收&lt;/h2>
&lt;p>Kubernetes 借助于 cadvisor 通过 imageManager 来管理所有镜像的生命周期。&lt;/p>
&lt;p>镜像垃圾回收策略只考虑两个因素：HighThresholdPercent 和 LowThresholdPercent。 磁盘使用率超过上限阈值（HighThresholdPercent）将触发垃圾回收。 垃圾回收将删除最近最少使用的镜像，直到磁盘使用率满足下限阈值（LowThresholdPercent）。&lt;/p>
&lt;h2 id="容器回收">容器回收&lt;/h2>
&lt;p>容器垃圾回收策略考虑三个用户定义变量。 MinAge 是容器可以被执行垃圾回收的最小生命周期。 MaxPerPodContainer 是每个 pod 内允许存在的死亡容器的最大数量。 MaxContainers 是全部死亡容器的最大数量。 可以分别独立地通过将 MinAge 设置为 0，以及将 MaxPerPodContainer 和 MaxContainers 设置为小于 0 来禁用这些变量。&lt;/p>
&lt;p>kubelet 将处理无法辨识的、已删除的以及超出前面提到的参数所设置范围的容器。 最老的容器通常会先被移除。 MaxPerPodContainer 和 MaxContainer 在某些场景下可能会存在冲突， 例如在保证每个 pod 内死亡容器的最大数量（MaxPerPodContainer）的条件下可能会超过 允许存在的全部死亡容器的最大数量（MaxContainer）。 MaxPerPodContainer 在这种情况下会被进行调整： 最坏的情况是将 MaxPerPodContainer 降级为 1，并驱逐最老的容器。 此外，pod 内已经被删除的容器一旦年龄超过 MinAge 就会被清理。&lt;/p>
&lt;p>不被 kubelet 管理的容器不受容器垃圾回收的约束。&lt;/p>
&lt;h1 id="用户配置">用户配置&lt;/h1>
&lt;p>用户可以使用以下 kubelet 参数调整相关阈值来优化镜像垃圾回收：&lt;/p>
&lt;ul>
&lt;li>image-gc-high-threshold # 触发镜像垃圾回收的磁盘使用率百分比。默认值为 85%。&lt;/li>
&lt;li>image-gc-low-threshold # 镜像垃圾回收试图释放资源后达到的磁盘使用率百分比。默认值为 80%。&lt;/li>
&lt;/ul>
&lt;p>我们还允许用户通过以下 kubelet 参数自定义垃圾收集策略：&lt;/p>
&lt;ul>
&lt;li>minimum-container-ttl-duration # 完成的容器在被垃圾回收之前的最小年龄，默认是 0 分钟。 这意味着每个完成的容器都会被执行垃圾回收。&lt;/li>
&lt;li>maximum-dead-containers-per-container # 每个容器要保留的旧实例的最大数量。默认值为 1。&lt;/li>
&lt;li>maximum-dead-containers # 要全局保留的旧容器实例的最大数量。 默认值是 -1，意味着没有全局限制。&lt;/li>
&lt;/ul>
&lt;p>容器可能会在其效用过期之前被垃圾回收。这些容器可能包含日志和其他对故障诊断有用的数据。 强烈建议为 maximum-dead-containers-per-container 设置一个足够大的值，以便每个预期容器至少保留一个死亡容器。 由于同样的原因，maximum-dead-containers 也建议使用一个足够大的值。&lt;/p>
&lt;p>查阅这个 Issue 获取更多细节。&lt;/p>
&lt;p>弃用&lt;/p>
&lt;p>这篇文档中的一些 kubelet 垃圾收集（Garbage Collection）功能将在未来被 kubelet 驱逐回收（eviction）所替代。&lt;/p>
&lt;p>包括:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>现存参数&lt;/td>
&lt;td>新参数&lt;/td>
&lt;td>解释&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;image-gc-high-threshold&lt;/td>
&lt;td>&amp;ndash;eviction-hard 或 &amp;ndash;eviction-soft&lt;/td>
&lt;td>现存的驱逐回收信号可以触发镜像垃圾回收&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;image-gc-low-threshold&lt;/td>
&lt;td>&amp;ndash;eviction-minimum-reclaim&lt;/td>
&lt;td>驱逐回收实现相同行为&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;maximum-dead-containers&lt;/td>
&lt;td>&lt;/td>
&lt;td>一旦旧日志存储在容器上下文之外，就会被弃用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;maximum-dead-containers-per-container&lt;/td>
&lt;td>&lt;/td>
&lt;td>一旦旧日志存储在容器上下文之外，就会被弃用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;minimum-container-ttl-duration&lt;/td>
&lt;td>&lt;/td>
&lt;td>一旦旧日志存储在容器上下文之外，就会被弃用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;low-diskspace-threshold-mb&lt;/td>
&lt;td>&amp;ndash;eviction-hard or eviction-soft&lt;/td>
&lt;td>驱逐回收将磁盘阈值泛化到其他资源&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;outofdisk-transition-frequency&lt;/td>
&lt;td>&amp;ndash;eviction-pressure-transition-period&lt;/td>
&lt;td>驱逐回收将磁盘压力转换到其他资源&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Docs: Kubelet 特性</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/Kubelet-%E7%89%B9%E6%80%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/Kubelet-%E7%89%B9%E6%80%A7/</guid><description/></item><item><title>Docs: Node 资源预留与 Pod 驱逐</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/Node-%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99%E4%B8%8E-Pod-%E9%A9%B1%E9%80%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/Node-%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99%E4%B8%8E-Pod-%E9%A9%B1%E9%80%90/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>原文：&lt;a href="https://segmentfault.com/a/1190000021402192">SegmentFault(思否)，k8s 节点资源预留与 pod 驱逐&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="节点资源管理">节点资源管理&lt;/h1>
&lt;h2 id="为什么">为什么&lt;/h2>
&lt;p>K8S 的节点上的资源会被 pod 和系统进程所使用，如果默认什么都不配置，那么节点上的全部资源都是可以分配给 pod 使用的，系统进程本身没有保障，这样做很危险：&lt;/p>
&lt;ul>
&lt;li>集群雪崩：如果节点上调度了大量 pod，且 pod 没有合理的 limit 限制，节点资源将被耗尽，sshd、kubelet 等进程 OOM，节点变成 not ready 状态，pod 重新继续调度到其他节点，新节点也被打挂，引起集群雪崩。&lt;/li>
&lt;li>系统进程异常：就算 pod 设置了 limit，但如果机器遇到资源不足，系统进程如 docker 没有资源保障，会频繁 OOM，或者进程 hang 住无响应，虽然能运行，但容器会反复出问题&lt;/li>
&lt;/ul>
&lt;p>节点资源主要分为两类：&lt;/p>
&lt;ul>
&lt;li>可压缩资源：如 CPU，即使 cpu 超配，也可以划分时间片运行，只是运行变慢，进程不会挂。&lt;/li>
&lt;li>不可压缩资源：Memory/Storage，内存不同于 CPU，系统内存不足时，会触发 OOM 杀死进程，按照 oom score 来确定先 kill 谁，oom_score_adj 值越高，被 kill 的优先级越高。&lt;/li>
&lt;/ul>
&lt;p>oom 分数：
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/251afead-3706-4ed7-9dbe-ed79c2f36290/1460000021402196" alt="">
所以，OOM 的优先级如下：&lt;/p>
&lt;pre>&lt;code>BestEffort Pod &amp;gt; Burstable Pod &amp;gt; 其它进程 &amp;gt; Guaranteed Pod &amp;gt; kubelet/docker 等 &amp;gt; sshd 等进程
&lt;/code>&lt;/pre>
&lt;p>因此需要对节点的内存等资源进行配置，以保证节点核心进程运行正常。&lt;/p>
&lt;h2 id="怎么做">怎么做&lt;/h2>
&lt;p>节点资源的配置一般分为 2 种：&lt;/p>
&lt;ol>
&lt;li>资源预留：为系统进程和 k8s 进程预留资源&lt;/li>
&lt;li>pod 驱逐：节点资源到达一定使用量，开始驱逐 pod&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/251afead-3706-4ed7-9dbe-ed79c2f36290/1460000021402198" alt="">&lt;/p>
&lt;ul>
&lt;li>Node Capacity：Node 的所有硬件资源&lt;/li>
&lt;li>kube-reserved：给 kube 组件预留的资源：kubelet,kube-proxy 以及 docker 等&lt;/li>
&lt;li>system-reserved：给 system 进程预留的资源&lt;/li>
&lt;li>eviction-threshold：kubelet eviction 的阈值设定&lt;/li>
&lt;li>Allocatable：真正 scheduler 调度 Pod 时的参考值（保证 Node 上所有 Pods 的 request resource 不超过 Allocatable）&lt;/li>
&lt;/ul>
&lt;p>allocatable 的值即对应 describe node 时看到的 allocatable 容量，pod 调度的上限&lt;/p>
&lt;pre>&lt;code>计算公式：节点上可配置值 = 总量 - 预留值 - 驱逐阈值
Allocatable = Capacity - Reserved(kube+system) - Eviction Threshold
&lt;/code>&lt;/pre>
&lt;p>以上配置均在 kubelet 中添加，涉及的参数有：&lt;/p>
&lt;pre>&lt;code>--enforce-node-allocatable=pods,kube-reserved,system-reserved
--kube-reserved-cgroup=/system.slice/kubelet.service
--system-reserved-cgroup=/system.slice
--kube-reserved=cpu=200m,memory=250Mi
--system-reserved=cpu=200m,memory=250Mi
--eviction-hard=memory.available&amp;lt;5%,nodefs.available&amp;lt;10%,imagefs.available&amp;lt;10%
--eviction-soft=memory.available&amp;lt;10%,nodefs.available&amp;lt;15%,imagefs.available&amp;lt;15%
--eviction-soft-grace-period=memory.available=2m,nodefs.available=2m,imagefs.available=2m
--eviction-max-pod-grace-period=30
--eviction-minimum-reclaim=memory.available=0Mi,nodefs.available=500Mi,imagefs.available=500Mi
&lt;/code>&lt;/pre>
&lt;h2 id="配置含义">配置含义&lt;/h2>
&lt;p>配置的含义如下：&lt;/p>
&lt;p>（1）&amp;ndash;enforce-node-allocatable&lt;/p>
&lt;pre>&lt;code>含义：指定kubelet为哪些进程做硬限制，可选的值有：
* pods
* kube-reserved
* system-reserve
这个参数开启并指定pods后kubelet会为所有pod的总cgroup做资源限制(通过cgroup中的kubepods.limit\_in\_bytes)，限制为公式计算出的allocatable的大小。
假如想为系统进程和k8s进程也做cgroup级别的硬限制，还可以在限制列表中再加system-reserved和kube-reserved，同时还要分别加上--kube-reserved-cgroup和--system-reserved-cgroup以指定分别限制在哪个cgroup里。
配置：--enforce-node-allocatable\=pods,kube-reserved,system-reserved
&lt;/code>&lt;/pre>
&lt;p>（2）设置 k8s 组件的 cgroup&lt;/p>
&lt;pre>&lt;code>含义：这个参数用来指定k8s系统组件所使用的cgroup。
注意，这里指定的cgroup及其子系统需要预先创建好，kubelet并不会为你自动创建好。
配置：--kube-reserved-cgroup=/system.slice/kubelet.service
&lt;/code>&lt;/pre>
&lt;p>（3）设置系统守护进程的 cgroup&lt;/p>
&lt;pre>&lt;code>含义：这个参数用来指定系统守护进程所使用的cgroup。
注意，这里指定的cgroup及其子系统需要预先创建好，kubelet并不会为你自动创建好。
配置：--system\-reserved-cgroup=/system.slice
&lt;/code>&lt;/pre>
&lt;p>（4）配置 k8s 组件预留资源的大小，CPU、Mem&lt;/p>
&lt;pre>&lt;code>指定为k8s系统组件（kubelet、kube-proxy、dockerd等）预留的资源量，
如：--kube-reserved=cpu=1,memory=2Gi,ephemeral-storage=1Gi。
这里的kube-reserved只为非pod形式启动的kube组件预留资源，假如组件要是以static pod（kubeadm）形式启动的，那并不在这个kube-reserved管理并限制的cgroup中，而是在kubepod这个cgroup中。
（ephemeral storage需要kubelet开启feature\-gates，预留的是临时存储空间（log，EmptyDir），生产环境建议先不使用）
ephemeral-storage是kubernetes1.8开始引入的一个资源限制的对象，kubernetes 1.10版本中kubelet默认已经打开的了,到目前1.11还是beta阶段，主要是用于对本地临时存储使用空间大小的限制，如对pod的empty dir、/var/lib/kubelet、日志、容器可读写层的使用大小的限制。
&lt;/code>&lt;/pre>
&lt;p>（5）配置 系统守护进程预留资源的大小（预留的值需要根据机器上容器的密度做一个合理的值）&lt;/p>
&lt;pre>&lt;code>含义：为系统守护进程(sshd, udev等)预留的资源量，
如：--system\-reserved=cpu=500m,memory\=1Gi,ephemeral-storage=1Gi。
注意，除了考虑为系统进程预留的量之外，还应该为kernel和用户登录会话预留一些内存。
配置：--system\-reserved=cpu=200m,memory\=250Mi
&lt;/code>&lt;/pre>
&lt;p>（6）配置 驱逐 pod 的硬阈值&lt;/p>
&lt;pre>&lt;code>含义：设置进行pod驱逐的阈值，这个参数只支持内存和磁盘。
通过
kubelet 将会对pod进行驱逐。
配置：--eviction-hard=memory.available&amp;lt;5%,nodefs.available&amp;lt;10%,imagefs.available&amp;lt;10%
&lt;/code>&lt;/pre>
&lt;p>（7）配置 驱逐 pod 的软阈值&lt;/p>
&lt;pre>&lt;code>--eviction-soft=memory.available&amp;lt;10%,nodefs.available&amp;lt;15%,imagefs.available&amp;lt;15%
&lt;/code>&lt;/pre>
&lt;p>（8）定义达到软阈值之后，持续时间超过多久才进行驱逐&lt;/p>
&lt;pre>&lt;code>--eviction-soft-grace-period=memory.available=2m,nodefs.available=2m,imagefs.available=2m
&lt;/code>&lt;/pre>
&lt;p>（9）驱逐 pod 前最大等待时间 = min(pod.Spec.TerminationGracePeriodSeconds, eviction-max-pod-grace-period)，单位为秒&lt;/p>
&lt;pre>&lt;code>--eviction-max-pod-grace-period=30
&lt;/code>&lt;/pre>
&lt;p>（10）至少回收的资源量&lt;/p>
&lt;pre>&lt;code>--eviction-minimum-reclaim=memory.available=0Mi,nodefs.available=500Mi,imagefs.available=500Mi
&lt;/code>&lt;/pre>
&lt;p>以上配置均为百分比，举例：&lt;/p>
&lt;p>以 2 核 4GB 内存 40GB 磁盘空间的配置为例，Allocatable 是 1.6 CPU，3.3Gi 内存，25Gi 磁盘。当 pod 的总内存消耗大于 3.3Gi 或者磁盘消耗大于 25Gi 时，会根据相应策略驱逐 pod。&lt;/p>
&lt;h2 id="硬驱逐与软驱逐">硬驱逐与软驱逐&lt;/h2>
&lt;h3 id="硬驱逐">硬驱逐&lt;/h3>
&lt;p>kubelet 利用 metric 的值作为决策依据来触发驱逐行为，下面内容来自于 Kubelet summary API。&lt;/p>
&lt;p>一旦超出阈值，就会触发 kubelet 进行资源回收的动作（区别于软驱逐，有宽限期），指标如下：
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/251afead-3706-4ed7-9dbe-ed79c2f36290/1460000021402197" alt="">&lt;/p>
&lt;ul>
&lt;li>nodefs： 机器文件系统&lt;/li>
&lt;li>imagesfs: Kubelet 能够利用 cAdvisor 自动发现这些文件系统，镜像存储空间&lt;/li>
&lt;/ul>
&lt;p>例如如果一个 Node 有 10Gi 内存，我们希望在可用内存不足 1Gi 时进行驱逐，就可以选取下面的一种方式来定义驱逐阈值：&lt;/p>
&lt;ul>
&lt;li>memory.available&amp;lt;10%&lt;/li>
&lt;li>memory.available&amp;lt;1Gi&lt;/li>
&lt;/ul>
&lt;p>可以配置百分比或者实际值，但是操作符只能使用小于号，即 &amp;lt;&lt;/p>
&lt;h3 id="软驱逐">软驱逐&lt;/h3>
&lt;p>软阈值需要和一个宽限期参数协同工作。当系统资源消耗达到软阈值时，这一状况的持续时间超过了宽限期之前，Kubelet 不会触发任何动作。如果没有定义宽限期，Kubelet 会拒绝启动。&lt;/p>
&lt;p>另外还可以定义一个 Pod 结束的宽限期。如果定义了这一宽限期，那么 Kubelet 会使用 pod.Spec.TerminationGracePeriodSeconds 和最大宽限期这两个值之间较小的那个（进行宽限），如果没有指定的话，kubelet 会不留宽限立即杀死 Pod。&lt;/p>
&lt;p>软阈值的定义包括以下几个参数：&lt;/p>
&lt;ul>
&lt;li>eviction-soft：驱逐阈值，例如 memory.available&amp;lt;1.5Gi，如果满足这一条件的持续时间超过宽限期，就会触发对 Pod 的驱逐动作。&lt;/li>
&lt;li>eviction-soft-grace-period：驱逐宽限期，例如 memory.available=1m30s，用于定义达到软阈值之后，持续时间超过多久才进行驱逐。&lt;/li>
&lt;li>eviction-max-pod-grace-period：达到软阈值之后，到驱逐一个 Pod 之前的最大宽限时间（单位是秒）&lt;/li>
&lt;/ul>
&lt;h3 id="判断周期">判断周期&lt;/h3>
&lt;p>Housekeeping interval 参数定义一个时间间隔，Kubelet 每隔这一段就会对驱逐阈值进行评估。&lt;/p>
&lt;ul>
&lt;li>housekeeping-interval：容器检查的时间间隔。&lt;/li>
&lt;/ul>
&lt;h3 id="节点表现">节点表现&lt;/h3>
&lt;p>如果触发了硬阈值，或者符合软阈值的时间持续了与其对应的宽限期，Kubelet 就会认为当前节点压力太大，下面的节点状态定义描述了这种对应关系。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/251afead-3706-4ed7-9dbe-ed79c2f36290/1460000021402200" alt="">
Kubelet 会持续报告节点状态的更新过程，这一频率由参数 —node-status-update-frequency 指定，缺省情况下取值为 10s。&lt;/p>
&lt;p>如果一个节点的状况在软阈值的上下波动，但是又不会超过他的宽限期，将会导致该节点的状态持续的在是否之间徘徊，最终会影响降低调度的决策过程。&lt;/p>
&lt;p>要防止这种状况，下面的标志可以用来通知 Kubelet，在脱离 pressure 之前，必须等待。&lt;/p>
&lt;p>&lt;code>eviction-pressure-transition-period&lt;/code> 定义了在脱离 pressure 状态之前要等待的时间&lt;/p>
&lt;p>Kubelet 在把 pressure 状态设置为 False 之前，会确认在周期之内，该节点没有达到阈值&lt;/p>
&lt;hr>
&lt;p>如果达到了驱逐阈值，并且超出了宽限期，那么 Kubelet 会开始回收超出限量的资源，直到回到阈值以内。&lt;/p>
&lt;p>Kubelet 在驱逐用户 Pod 之前，会尝试回收节点级别的资源。如果服务器为容器定义了独立的 imagefs，他的回收过程会有所不同。&lt;/p>
&lt;p>&lt;strong>有 Imagefs&lt;/strong>
如果 nodefs 文件系统到达了驱逐阈值，kubelet 会按照下面的顺序来清理空间:&lt;/p>
&lt;ul>
&lt;li>删除死掉的 Pod / 容器&lt;/li>
&lt;/ul>
&lt;p>如果 imagefs 文件系统到达了驱逐阈值，kubelet 会按照下面的顺序来清理空间:&lt;/p>
&lt;ul>
&lt;li>删掉所有无用镜像&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>没有 Imagefs&lt;/strong>&lt;/p>
&lt;p>如果 nodefs 文件系统到达了驱逐阈值，kubelet 会按照下面的顺序来清理空间。&lt;/p>
&lt;ol>
&lt;li>删除死掉的 Pod / 容器&lt;/li>
&lt;li>删掉所有无用镜像&lt;/li>
&lt;/ol>
&lt;h2 id="pod-驱逐策略">pod 驱逐策略&lt;/h2>
&lt;p>Kubelet 会按照下面的标准对 Pod 的驱逐行为进行评判：&lt;/p>
&lt;ul>
&lt;li>根据服务质量：即 BestEffort、Burstable、Guaranteed&lt;/li>
&lt;li>根据 Pod 调度请求的被耗尽资源的消耗量&lt;/li>
&lt;/ul>
&lt;p>接下来，Pod 按照下面的顺序进行驱逐（QOS）：&lt;/p>
&lt;ol>
&lt;li>BestEffort：消耗最多紧缺资源的 Pod 最先驱逐。&lt;/li>
&lt;li>Burstable：请求（request）最多紧缺资源的 Pod 被驱逐，如果没有 Pod 超出他们的请求，会驱逐资源消耗量最大的 Pod。&lt;/li>
&lt;li>Guaranteed：请求（request）最多紧缺资源的 Pod 被驱逐，如果没有 Pod 超出他们的请求，会驱逐资源消耗量最大的 Pod。&lt;/li>
&lt;/ol>
&lt;p>参考 POD 的 QOS：&lt;a href="https://link.segmentfault.com/?url=https%3A%2F%2Fk8smeetup.github.io%2Fdocs%2Ftasks%2Fconfigure-pod-container%2Fquality-service-pod%2F">服务质量等级&lt;/a>&lt;/p>
&lt;p>Guaranteed Pod 不会因为其他 Pod 的资源被驱逐。如果系统进程（例如 kubelet、docker、journald 等）消耗了超出 system-reserved 或者 kube-reserved 的资源，而且这一节点上只运行了 Guaranteed Pod，那么为了保证节点的稳定性并降低异常请求对其他 Guaranteed Pod 的影响，必须选择一个 Guaranteed Pod 进行驱逐。&lt;/p>
&lt;p>本地磁盘是一个 BestEffort 资源。如有必要，kubelet 会在 DiskPressure 的情况下，kubelet 会按照 QoS 进行评估。如果 Kubelet 判定缺乏 inode 资源，就会通过驱逐最低 QoS 的 Pod 的方式来回收 inodes。如果 kubelet 判定缺乏磁盘空间，就会通过在相同 QoS 的 Pods 中，选择消耗最多磁盘空间的 Pod 进行驱逐。&lt;/p>
&lt;hr>
&lt;p>&lt;strong>有 Imagefs&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>如果 nodefs 触发了驱逐，Kubelet 会用 nodefs 的使用对 Pod 进行排序 – Pod 中所有容器的本地卷和日志。&lt;/li>
&lt;li>如果 imagefs 触发了驱逐，Kubelet 会根据 Pod 中所有容器的消耗的可写入层进行排序。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>没有 Imagefs&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>如果 nodefs 触发了驱逐，Kubelet 会对各个 Pod 的所有容器的总体磁盘消耗进行排序 —— 本地卷 + 日志 + 写入层。&lt;/li>
&lt;li>在某些场景下，驱逐 Pod 可能只回收了很少的资源。这就导致了 kubelet 反复触发驱逐阈值。另外回收资源例如磁盘资源，是需要消耗时间的。&lt;/li>
&lt;li>要缓和这种状况，Kubelet 能够对每种资源定义 minimum-reclaim。kubelet 一旦发现了资源压力，就会试着回收至少 minimum-reclaim 的资源，使得资源消耗量回到期望范围。&lt;/li>
&lt;/ul>
&lt;p>例如下面的配置：&lt;/p>
&lt;pre>&lt;code>--eviction-hard=memory.available&amp;lt;500Mi,nodefs.available&amp;lt;1Gi,imagefs.available&amp;lt;100Gi
--eviction-minimum-reclaim=&amp;quot;memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi&amp;quot;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果 memory.available 被触发，Kubelet 会启动回收，让 memory.available 至少有 500Mi。&lt;/li>
&lt;li>如果是 nodefs.available，Kubelet 就要想法子让 nodefs.available 回到至少 1.5Gi。&lt;/li>
&lt;li>而对于 imagefs.available， kubelet 就要回收到最少 102Gi。&lt;/li>
&lt;/ul>
&lt;p>缺省情况下，所有资源的 eviction-minimum-reclaim 为 0。&lt;/p>
&lt;p>&lt;em>在节点资源紧缺的情况下，调度器将不再继续向此节点部署新的 Pod&lt;/em>&lt;/p>
&lt;h2 id="节点-oom-时">节点 OOM 时&lt;/h2>
&lt;p>如果节点在 Kubelet 能够回收内存之前，遭遇到了系统的 OOM (内存不足)，节点就依赖 oom_killer 进行响应了。&lt;/p>
&lt;p>kubelet 根据 Pod 的 QoS 为每个容器设置了一个 oom_score_adj 值。
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/251afead-3706-4ed7-9dbe-ed79c2f36290/1460000021402201" alt="">
如果 kubelet 无法在系统 OOM 之前回收足够的内存，oom_killer 就会根据根据内存使用比率来计算 oom_score，得出结果和 oom_score_adj 相加，最后得分最高的 Pod 会被首先驱逐。&lt;/p>
&lt;p>跟 Pod 驱逐不同，如果一个 Pod 的容器被 OOM 杀掉，他是可能被 kubelet 根据 RestartPolicy 重启的。&lt;/p>
&lt;h2 id="daemonset-的处理">Daemonset 的处理&lt;/h2>
&lt;p>因为 DaemonSet 中的 Pod 会立即重建到同一个节点，所以 Kubelet 不应驱逐 DaemonSet 中的 Pod。&lt;/p>
&lt;p>但是目前 Kubelet 无法分辨一个 Pod 是否由 DaemonSet 创建。如果 Kubelet 能够识别这一点，那么就可以先从驱逐候选列表中过滤掉 DaemonSet 的 Pod。&lt;/p>
&lt;p>一般来说，强烈建议 DaemonSet 不要创建 BestEffort Pod，而是使用 Guaranteed Pod，来避免进入驱逐候选列表。&lt;/p>
&lt;h2 id="已知问题">已知问题&lt;/h2>
&lt;h3 id="kubelet-无法及时监测到内存压力">Kubelet 无法及时监测到内存压力&lt;/h3>
&lt;p>Kubelet 目前从 cAdvisor 定时获取内存使用状况统计。如果内存使用在这个时间段内发生了快速增长，Kubelet 就无法观察到 MemoryPressure，可能会触发 OOMKiller。我们正在尝试将这一过程集成到 memcg 通知 API 中，来降低这一延迟，而不是让内核首先发现这一情况。&lt;/p>
&lt;p>如果用户不是希望获得终极使用率，而是作为一个过量使用的衡量方式，对付这一个问题的较为可靠的方式就是设置驱逐阈值为 75% 容量。这样就提高了避开 OOM 的能力，提高了驱逐的标准，有助于集群状态的平衡。&lt;/p>
&lt;h3 id="kubelet-可能驱逐超出需要的更多-pod">Kubelet 可能驱逐超出需要的更多 Pod&lt;/h3>
&lt;p>这也是因为状态搜集的时间差导致的。未来会加入功能，让根容器的统计频率和其他容器分别开来（&lt;a href="https://link.segmentfault.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fcadvisor%2Fissues%2F1247">https://github.com/google/cad&amp;hellip;&lt;/a>）。&lt;/p>
&lt;h3 id="kubelet-如何在-inode-耗尽的时候评价-pod-的驱逐">Kubelet 如何在 inode 耗尽的时候评价 Pod 的驱逐&lt;/h3>
&lt;p>目前不可能知道一个容器消耗了多少 inode。如果 Kubelet 觉察到了 inode 耗尽，他会利用 QoS 对 Pod 进行驱逐评估。在 cadvisor 中有一个 issue，来跟踪容器的 inode 消耗，这样我们就能利用 inode 进行评估了。例如如果我们知道一个容器创建了大量的 0 字节文件，就会优先驱逐这一 Pod&lt;/p>
&lt;h2 id="最佳实践">最佳实践&lt;/h2>
&lt;h3 id="资源预留">资源预留&lt;/h3>
&lt;p>1、资源预留需要设置，pod 的 limit 也要设置。
2、cpu 是可压缩资源，内存、磁盘资源是不可压缩资源。内存一定要预留，CPU 可以根据实际情况来调整
3、预留多少合适：根据集群规模设置阶梯，如下 (GKE 建议)：&lt;/p>
&lt;p>Allocatable = Capacity - Reserved - Eviction Threshold&lt;/p>
&lt;p>对于内存资源：&lt;/p>
&lt;ul>
&lt;li>内存少于 1GB，则设置 255 MiB&lt;/li>
&lt;li>内存大于 4G，设置前 4GB 内存的 25％&lt;/li>
&lt;li>接下来 4GB 内存的 20％（最多 8GB）&lt;/li>
&lt;li>接下来 8GB 内存的 10％（最多 16GB）&lt;/li>
&lt;li>接下来 112GB 内存的 6％（最高 128GB）&lt;/li>
&lt;li>超过 128GB 的任何内存的 2％&lt;/li>
&lt;li>在 1.12.0 之前的版本中，内存小于 1GB 的节点不需要保留内存&lt;/li>
&lt;/ul>
&lt;p>对于 CPU 资源：&lt;/p>
&lt;ul>
&lt;li>第一个核的 6％&lt;/li>
&lt;li>下一个核的 1％（最多 2 个核）&lt;/li>
&lt;li>接下来 2 个核的 0.5％（最多 4 个核）&lt;/li>
&lt;li>4 个核以上的都是总数的 0.25％&lt;/li>
&lt;/ul>
&lt;p>对于磁盘资源（不是正式特性，仅供参考）：
&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/251afead-3706-4ed7-9dbe-ed79c2f36290/1460000021402199" alt="">
效果：查看节点的可分配资源：&lt;/p>
&lt;pre>&lt;code>kubectl describe node \[NODE\_NAME\] | grep Allocatable -B 4 -A 3
&lt;/code>&lt;/pre>
&lt;h3 id="驱逐配置">驱逐配置&lt;/h3>
&lt;pre>&lt;code>--eviction-hard=memory.available&amp;lt;5%,nodefs.available&amp;lt;10%,imagefs.available&amp;lt;10%
--eviction-soft\=memory.available&amp;lt;10%,nodefs.available&amp;lt;15%,imagefs.available&amp;lt;15%
--eviction-soft\-grace-period=memory.available=2m,nodefs.available=2m,imagefs.available=2m
--eviction-max\-pod-grace-period=30
--eviction-minimum-reclaim=memory.available=0Mi,nodefs.available=500Mi,imagefs.available=500Mi
&lt;/code>&lt;/pre>
&lt;p>原文链接：&lt;a href="https://link.segmentfault.com/?url=http%3A%2F%2Fwww.xuyasong.com%2F%3Fp%3D1725">http://www.xuyasong.com/?p=1725&lt;/a>&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://link.segmentfault.com/?url=https%3A%2F%2Fkubernetes.io%2Fdocs%2Fadmin%2Fout-of-resource%2F">https://kubernetes.io/docs/admin/out-of-resource/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://link.segmentfault.com/?url=https%3A%2F%2Fk8smeetup.github.io%2Fdocs%2Ftasks%2Fconfigure-pod-container%2Fquality-service-pod%2F">https://k8smeetup.github.io/docs/tasks/configure-pod-container/quality-service-pod/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://link.segmentfault.com/?url=https%3A%2F%2Fcloud.google.com%2Fkubernetes-engine%2Fdocs%2Fconcepts%2Fcluster-architecture%23node_allocatable">https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture#node_allocatable&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: PLEG</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/PLEG/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/2.Kubelet-%E8%8A%82%E7%82%B9%E4%BB%A3%E7%90%86/Kubelet-%E7%89%B9%E6%80%A7/PLEG/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/lPYd9tNQyjidJ-sLt2sDLg">公众号,运维开发故事-PLEG is not healthy？幕后黑手居然是它！&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/t7H2MQ2429LQB9XfrB23YA">公众号,云原生实验室-Kubelet 中的 “PLEG is not healthy” 到底是个什么鬼？&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes#">https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes#&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/lPYd9tNQyjidJ-sLt2sDLg">
&lt;/a>&lt;/p>
&lt;h2 id="问题描述">问题描述&lt;/h2>
&lt;p>环境 ：ubuntu18.04，自建集群 k8s 1.18 ，容器运行时 docker。&lt;/p>
&lt;p>现象：某个 Node 频繁 NotReady，kubectl describe 该 Node，出现如下报错日志：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>PLEG is not healthy: pleg was last seen active 3m46.752815514s ago; threshold is 3m0s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>频率在 5-10 分钟就会出现一次。&lt;/p>
&lt;h2 id="我们首先要明白-pleg-是什么">我们首先要明白 PLEG 是什么？&lt;/h2>
&lt;p>&lt;strong>Pod Lifecycle Event Generator(Pod 生命周期事件生成器，简称 PLEG)&lt;/strong> 是 Kubelet 中的一个模块，主要职责就是通过每个匹配的 Pod 级别事件来调整容器运行时的状态，并将调整的结果写入缓存，使 Pod 的缓存保持最新状态。先来聊聊 PLEG 的出现背景。在 Kubernetes 中，每个节点上都运行着一个守护进程 Kubelet 来管理节点上的容器，调整容器的实际状态以匹配 spec 中定义的状态。具体来说，Kubelet 需要对两个地方的更改做出及时的回应：&lt;/p>
&lt;ol>
&lt;li>Pod spec 中定义的状态&lt;/li>
&lt;li>容器运行时的状态&lt;/li>
&lt;/ol>
&lt;p>对于 Pod，Kubelet 会从多个数据来源 watch Pod spec 中的变化。对于容器，Kubelet 会定期（例如，10s）轮询容器运行时，以获取所有容器的最新状态。随着 Pod 和容器数量的增加，轮询会产生不可忽略的开销，并且会由于 Kubelet 的并行操作而加剧这种开销（为每个 Pod 分配一个 goruntine，用来获取容器的状态）。轮询带来的周期性大量并发请求会导致较高的 CPU 使用率峰值（即使 Pod 的定义和容器的状态没有发生改变），降低性能。最后容器运行时可能不堪重负，从而降低系统的可靠性，限制 Kubelet 的可扩展性。为了降低 Pod 的管理开销，提升 Kubelet 的性能和可扩展性，引入了 PLEG，改进了之前的工作方式：&lt;/p>
&lt;ul>
&lt;li>减少空闲期间的不必要工作（例如 Pod 的定义和容器的状态没有发生更改）。&lt;/li>
&lt;li>减少获取容器状态的并发请求数量。&lt;/li>
&lt;/ul>
&lt;p>所以我们看这一切都离不开 kubelet 与 pod 的容器运行时。&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/35160200-5f9f-4cfd-911c-afa960062a5c/640" alt="">
一方面，kubelet 扮演的是集群控制器的角色，它定期从 API Server 获取 Pod 等相关资源的信息，并依照这些信息，控制运行在节点上 Pod 的执行；&lt;/p>
&lt;p>另外一方面，kubelet 作为节点状况的监视器，它获取节点信息，并以集群客户端的角色，把这些状况同步到 API Server。在这个问题中，kubelet 扮演的是第二种角色。Kubelet 会使用上图中的 NodeStatus 机制，定期检查集群节点状况，并把节点状况同步到 API Server。而 NodeStatus 判断节点就绪状况的一个主要依据，就是 PLEG。&lt;/p>
&lt;p>PLEG 是 Pod Lifecycle Events Generator 的缩写，基本上它的执行逻辑，是定期检查节点上 Pod 运行情况，如果发现感兴趣的变化，PLEG 就会把这种变化包装成 Event 发送给 Kubelet 的主同步机制 syncLoop 去处理。但是，在 PLEG 的 Pod 检查机制不能定期执行的时候，NodeStatus 机制就会认为，这个节点的状况是不对的，从而把这种状况同步到 API Server。&lt;/p>
&lt;p>整体的工作流程如下图所示，虚线部分是 PLEG 的工作内容。&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/35160200-5f9f-4cfd-911c-afa960062a5c/640" alt="">&lt;/p>
&lt;h3 id="以-node-notready-这个场景为例来讲解-pleg">以 node notready 这个场景为例，来讲解 PLEG：&lt;/h3>
&lt;p>Kubelet 中的 NodeStatus 机制会定期检查集群节点状况，并把节点状况同步到 API Server。而 NodeStatus 判断节点就绪状况的一个主要依据，就是 PLEG。&lt;/p>
&lt;p>PLEG 定期检查节点上 Pod 运行情况，并且会把 pod 的变化包装成 Event 发送给 Kubelet 的主同步机制 syncLoop 去处理。但是，在 PLEG 的 Pod 检查机制不能定期执行的时候，NodeStatus 机制就会认为这个节点的状况是不对的，从而把这种状况同步到 API Server，我们就会看到 not ready 。&lt;/p>
&lt;p>PLEG 有两个关键的时间参数，一个是检查的执行间隔，另外一个是检查的超时时间。以默认情况为准，PLEG 检查会间隔一秒，换句话说，每一次检查过程执行之后，PLEG 会等待一秒钟，然后进行下一次检查；而每一次检查的超时时间是三分钟，如果一次 PLEG 检查操作不能在三分钟内完成，那么这个状况，会被 NodeStatus 机制当做集群节点 NotReady 的凭据，同步给 API Server。&lt;/p>
&lt;p>PLEG Start 就是启动一个协程，每个 relistPeriod(1s) 就调用一次 relist，根据最新的 PodStatus 生成 PodLiftCycleEvent。relist 是 PLEG 的核心，它从 container runtime 中查询属于 kubelet 管理 containers/sandboxes 的信息，并与自身维护的 pods cache 信息进行对比，生成对应的 PodLifecycleEvent，然后输出到 eventChannel 中，通过 eventChannel 发送到 kubelet syncLoop 进行消费，然后由 kubelet syncPod 来触发 pod 同步处理过程，最终达到用户的期望状态。&lt;/p>
&lt;h3 id="pleg-is-not-healthy-的原因">PLEG is not healthy 的原因&lt;/h3>
&lt;p>这个报错清楚地告诉我们，容器 runtime 是不正常的，且 PLEG 是不健康的。这里容器 runtime 指的就是 docker daemon 。Kubelet 通过操作 docker daemon 来控制容器的生命周期。而这里的 PLEG，指的是 pod lifecycle event generator。PLEG 是 kubelet 用来检查 runtime 的健康检查机制。这件事情本来可以由 kubelet 使用 polling 的方式来做。但是 polling 有其高成本的缺陷，所以 PLEG 应用而生。PLEG 尝试以一种 “中断” 的形式，来实现对容器 runtime 的健康检查，虽然实际上，它同时用了 polling 和”中断”这样折中的方案。&lt;/p>
&lt;p>从 Docker 1.11 版本开始，Docker 容器运行就不是简单通过 Docker Daemon 来启动了，而是通过集成 containerd、runc 等多个组件来完成的。虽然 Docker Daemon 守护进程模块在不停的重构，但是基本功能和定位没有太大的变化，一直都是 CS 架构，守护进程负责和 Docker Client 端交互，并管理 Docker 镜像和容器。现在的架构中组件 containerd 就会负责集群节点上容器的生命周期管理，并向上为 Docker Daemon 提供 gRPC 接口。&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/35160200-5f9f-4cfd-911c-afa960062a5c/640" alt="">&lt;/p>
&lt;p>PLEG 在每次迭代检查中会调用 runc 的 relist() 函数干的事情，是定期重新列出节点上的所有容器，并与上一次的容器列表进行对比，以此来判断容器状态的变换。相当于 docker ps 来获取所有容器，在通过 docker Inspect 来获取这些容器的详细信息。在有问题的节点上，通过 docker ps 命令会没有响应，这说明上边的报错是准确的。&lt;/p>
&lt;h3 id="经常出现的场景">经常出现的场景&lt;/h3>
&lt;p>出现 pleg not healthy，一般有以下几种可能：&lt;/p>
&lt;ul>
&lt;li>容器运行时无响应或响应超时，如 docker 进程响应超时（比较常见）&lt;/li>
&lt;li>该节点上容器数量过多，导致 relist 的过程无法在 3 分钟内完成&lt;/li>
&lt;li>relist 出现了死锁，该 bug 已在 Kubernetes 1.14 中修复。&lt;/li>
&lt;li>网络&lt;/li>
&lt;/ul>
&lt;h3 id="排查处理过程描述">排查处理过程描述&lt;/h3>
&lt;ol>
&lt;li>我们在问题节点上执行 top，发现有进程名为 scope 的进程 cpu 占用率一直是 100%。通过翻阅资料得知 systemd.scope：范围 (scope) 单元并不通过单元文件进行配置， 而是仅能以编程的方式通过 systemd D-Bus 接口创建。范围单元的名称都以 &amp;ldquo;.scope&amp;rdquo; 作为后缀。与服务 (service) 单元不同，范围单元用于管理 一组外部创建的进程， 它自身并不派生 (fork) 任何进程。范围 (scope) 单元的主要目的在于以分组的方式管理系统服务的工作进程。2. 在继续执行在有问题的节点上，通过 docker ps 命令会没有响应。说明容器 runtime 也是有问题的。那容器 runtime 与 systemd 有不有关系呢？3. 我们通过查阅到阿里的一篇文章，阿里巴巴 Kubernetes 集群问题排查思路和方法。找到了关系，有兴趣的可以根据文末提供的链接去细致了解。以下是在该文章中截取的部分内容。&lt;/li>
&lt;/ol>
&lt;h4 id="什么是-d-bus-呢">什么是 D-Bus 呢？&lt;/h4>
&lt;p>通过阿里巴巴 Kubernetes 集群问题排查思路和方法[1]中如下描述：在 Linux 上，dbus 是一种进程间进行消息通信的机制。&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/35160200-5f9f-4cfd-911c-afa960062a5c/640" alt="">&lt;/p>
&lt;h4 id="runc-请求-d-bus">RunC 请求 D-Bus&lt;/h4>
&lt;p>容器 runtime 的 runC 命令，是 libcontainer 的一个简单的封装。这个工具可以用来管理单个容器，比如容器创建和容器删除。在上节的最后，我们发现 runC 不能完成创建容器的任务。我们可以把对应的进程杀掉，然后在命令行用同样的命令启动容器，同时用 strace 追踪整个过程。&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/35160200-5f9f-4cfd-911c-afa960062a5c/640" alt="">
分析发现，runC 停在了向带有 org.free 字段的 dbus socket 写数据的地方。&lt;/p>
&lt;h4 id="解决问题">解决问题&lt;/h4>
&lt;p>最后可以断定是 systemd 的问题，我们用 systemctl daemon-reexec 来重启 systemd，问题消失了。所以更加确定是 systemd 的问题。&lt;/p>
&lt;p>具体原因大家可以参考：&lt;a href="https://www.infoq.cn/article/t_ZQeWjJLGWGT8BmmiU4%E8%BF%99%E7%AF%87%E6%96%87%E7%AB%A0%E3%80%82">https://www.infoq.cn/article/t_ZQeWjJLGWGT8BmmiU4 这篇文章。&lt;/a>&lt;/p>
&lt;p>根本上解决问题是：将 systemd 升级到 v242-rc2，升级后需要重启操作系统。（&lt;a href="https://github.com/lnykryn/systemd-rhel/pull/322%EF%BC%89">https://github.com/lnykryn/systemd-rhel/pull/322）&lt;/a>&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>PLEG is not healthy 的问题居然是因为 systemd 导致的。最后通过将 systemd 升级到 v242-rc2，升级后需要重启操作系统。（&lt;a href="https://github.com/lnykryn/systemd-rhel/pull/322%EF%BC%89">https://github.com/lnykryn/systemd-rhel/pull/322）&lt;/a> 参考资料&lt;/p>
&lt;ul>
&lt;li>Kubelet: Pod Lifecycle Event Generator (PLEG)&lt;/li>
&lt;li>Kubelet: Runtime Pod Cache&lt;/li>
&lt;li>relist() in kubernetes/pkg/kubelet/pleg/generic.go&lt;/li>
&lt;li>Past bug about CNI — PLEG is not healthy error, node marked NotReady&lt;/li>
&lt;li>&lt;a href="https://www.infoq.cn/article/t_ZQeWjJLGWGT8BmmiU4">https://www.infoq.cn/article/t_ZQeWjJLGWGT8BmmiU4&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.tencent.com/developer/article/1550038">https://cloud.tencent.com/developer/article/1550038&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>