<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – Kubernetes 管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/</link><description>Recent content in Kubernetes 管理 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Kubernetes 管理案例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description/></item><item><title>Docs: 性能优化与故障处理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description/></item><item><title>Docs: HPA(Horizontal Pod Autoscaler)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/HPAHorizontal-Pod-Autoscaler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/HPAHorizontal-Pod-Autoscaler/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>官方文档：&lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.qikqiak.com/post/k8s-hpa-usage/">https://www.qikqiak.com/post/k8s-hpa-usage/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Pod 水平自动扩缩（Horizontal Pod Autoscaler） 可以基于 CPU 利用率自动扩缩 ReplicationController、Deployment 和 ReplicaSet 中的 Pod 数量。 除了 CPU 利用率，也可以基于其他应程序提供的&lt;a href="https://git.k8s.io/community/contributors/design-proposals/instrumentation/custom-metrics-api.md">自定义度量指标&lt;/a> 来执行自动扩缩。 Pod 自动扩缩不适用于无法扩缩的对象，比如 DaemonSet。&lt;/p>
&lt;p>Pod 水平自动扩缩特性由 Kubernetes API 资源和控制器实现。资源决定了控制器的行为。 控制器会周期性的调整副本控制器或 Deployment 中的副本数量，以使得 Pod 的平均 CPU 利用率与用户所设定的目标值匹配。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kpk0nr/1616116805897-3bfc7a8f-d1bb-4268-a2a3-eebfb62a1e45.png" alt="">&lt;/p>
&lt;p>我们可以简单的通过 kubectl autoscale 命令来创建一个 HPA 资源对象， HPAController 默认 30s 轮询一次（可通过 kube-controller-manager 的 &amp;ndash;horizontal-pod-autoscaler-sync-period 参数进行设置），查询指定的资源中的 Pod 资源使用率，并且与创建时设定的值和指标做对比，从而实现自动伸缩的功能。&lt;/p>
&lt;h2 id="metrics-server">Metrics Server&lt;a class="td-heading-self-link" href="#metrics-server" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在 HPA 的第一个版本中，我们需要 &lt;code>Heapster&lt;/code> 提供 CPU 和内存指标，在 HPA v2 过后就需要安装 Metrcis Server 了，&lt;code>Metrics Server&lt;/code> 可以通过标准的 Kubernetes API 把监控数据暴露出来，有了 &lt;code>Metrics Server&lt;/code> 之后，我们就完全可以通过标准的 Kubernetes API 来访问我们想要获取的监控数据了：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>https://10.96.0.1/apis/metrics.k8s.io/v1beta1/namespaces/&amp;lt;namespace-name&amp;gt;/pods/&amp;lt;pod-name&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>比如当我们访问上面的 API 的时候，我们就可以获取到该 Pod 的资源数据，这些数据其实是来自于 kubelet 的 &lt;code>Summary API&lt;/code> 采集而来的。不过需要说明的是我们这里可以通过标准的 API 来获取资源监控数据，并不是因为 &lt;code>Metrics Server&lt;/code> 就是 APIServer 的一部分，而是通过 Kubernetes 提供的 &lt;code>Aggregator&lt;/code> 汇聚插件来实现的，是独立于 APIServer 之外运行的。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kpk0nr/1616116806050-9e81e7fd-4f38-4745-bcb0-7774067f17f7.png" alt="">&lt;/p>
&lt;p>HAP Metrics Server&lt;/p>
&lt;h3 id="聚合-api">聚合 API&lt;a class="td-heading-self-link" href="#%e8%81%9a%e5%90%88-api" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;code>Aggregator&lt;/code> 允许开发人员编写一个自己的服务，把这个服务注册到 Kubernetes 的 APIServer 里面去，这样我们就可以像原生的 APIServer 提供的 API 使用自己的 API 了，我们把自己的服务运行在 Kubernetes 集群里面，然后 Kubernetes 的 &lt;code>Aggregator&lt;/code> 通过 Service 名称就可以转发到我们自己写的 Service 里面去了。这样这个聚合层就带来了很多好处：&lt;/p>
&lt;ul>
&lt;li>增加了 API 的扩展性，开发人员可以编写自己的 API 服务来暴露他们想要的 API。&lt;/li>
&lt;li>丰富了 API，核心 kubernetes 团队阻止了很多新的 API 提案，通过允许开发人员将他们的 API 作为单独的服务公开，这样就无须社区繁杂的审查了。&lt;/li>
&lt;li>开发分阶段实验性 API，新的 API 可以在单独的聚合服务中开发，当它稳定之后，在合并会 APIServer 就很容易了。&lt;/li>
&lt;li>确保新 API 遵循 Kubernetes 约定，如果没有这里提出的机制，社区成员可能会被迫推出自己的东西，这样很可能造成社区成员和社区约定不一致。&lt;/li>
&lt;/ul>
&lt;h3 id="安装">安装&lt;a class="td-heading-self-link" href="#%e5%ae%89%e8%a3%85" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>所以现在我们要使用 HPA，就需要在集群中安装 &lt;code>Metrics Server&lt;/code> 服务，要安装 &lt;code>Metrics Server&lt;/code> 就需要开启 &lt;code>Aggregator&lt;/code>，因为 &lt;code>Metrics Server&lt;/code> 就是通过该代理进行扩展的，不过我们集群是通过 Kubeadm 搭建的，默认已经开启了，如果是二进制方式安装的集群，需要单独配置 kube-apsierver 添加如下所示的参数：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>--requestheader-client-ca-file&lt;span style="color:#f92672">=&lt;/span>&amp;lt;path to aggregator CA cert&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>--requestheader-allowed-names&lt;span style="color:#f92672">=&lt;/span>aggregator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>--requestheader-extra-headers-prefix&lt;span style="color:#f92672">=&lt;/span>X-Remote-Extra-
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>--requestheader-group-headers&lt;span style="color:#f92672">=&lt;/span>X-Remote-Group
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>--requestheader-username-headers&lt;span style="color:#f92672">=&lt;/span>X-Remote-User
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>--proxy-client-cert-file&lt;span style="color:#f92672">=&lt;/span>&amp;lt;path to aggregator proxy cert&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>--proxy-client-key-file&lt;span style="color:#f92672">=&lt;/span>&amp;lt;path to aggregator proxy key&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果 &lt;code>kube-proxy&lt;/code> 没有和 APIServer 运行在同一台主机上，那么需要确保启用了如下 kube-apsierver 的参数：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>--enable-aggregator-routing&lt;span style="color:#f92672">=&lt;/span>true
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于这些证书的生成方式，我们可以查看官方文档：&lt;a href="https://github.com/kubernetes-sigs/apiserver-builder-alpha/blob/master/docs/concepts/auth.md">https://github.com/kubernetes-sigs/apiserver-builder-alpha/blob/master/docs/concepts/auth.md&lt;/a>。&lt;/p>
&lt;p>&lt;code>Aggregator&lt;/code> 聚合层启动完成后，就可以来安装 &lt;code>Metrics Server&lt;/code> 了，我们可以获取该仓库的官方安装资源清单：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ git clone https://github.com/kubernetes-incubator/metrics-server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cd metrics-server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl apply -f deploy/1.8+/
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在部署之前，修改 &lt;code>metrcis-server/deploy/1.8+/metrics-server-deployment.yaml&lt;/code> 的镜像地址为：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">metrics-server&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">gcr.azk8s.cn/google_containers/metrics-server-amd64:v0.3.6&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>等部署完成后，可以查看 Pod 日志是否正常：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get pods -n kube-system -l k8s-app&lt;span style="color:#f92672">=&lt;/span>metrics-server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metrics-server-6886856d7c-g5k6q 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 2m39s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl logs -f metrics-server-6886856d7c-g5k6q -n kube-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>E1119 09:05:57.234312 &lt;span style="color:#ae81ff">1&lt;/span> manager.go:111&lt;span style="color:#f92672">]&lt;/span> unable to fully collect metrics: &lt;span style="color:#f92672">[&lt;/span>unable to fully scrape metrics from source kubelet_summary:ydzs-node1: unable to fetch metrics from Kubelet ydzs-node1 &lt;span style="color:#f92672">(&lt;/span>ydzs-node1&lt;span style="color:#f92672">)&lt;/span>: Get https://ydzs-node1:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: dial tcp: lookup ydzs-node1 on 10.96.0.10:53: no such host, unable to fully scrape metrics from source kubelet_summary:ydzs-node4: unable to fetch metrics from Kubelet ydzs-node4 &lt;span style="color:#f92672">(&lt;/span>ydzs-node4&lt;span style="color:#f92672">)&lt;/span>: Get https://ydzs-node4:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: dial tcp: lookup ydzs-node4 on 10.96.0.10:53: no such host, unable to fully scrape metrics from source kubelet_summary:ydzs-node3: unable to fetch metrics from Kubelet ydzs-node3 &lt;span style="color:#f92672">(&lt;/span>ydzs-node3&lt;span style="color:#f92672">)&lt;/span>: Get https://ydzs-node3:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: dial tcp: lookup ydzs-node3 on 10.96.0.10:53: no such host, unable to fully scrape metrics from source kubelet_summary:ydzs-master: unable to fetch metrics from Kubelet ydzs-master &lt;span style="color:#f92672">(&lt;/span>ydzs-master&lt;span style="color:#f92672">)&lt;/span>: Get https://ydzs-master:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: dial tcp: lookup ydzs-master on 10.96.0.10:53: no such host, unable to fully scrape metrics from source kubelet_summary:ydzs-node2: unable to fetch metrics from Kubelet ydzs-node2 &lt;span style="color:#f92672">(&lt;/span>ydzs-node2&lt;span style="color:#f92672">)&lt;/span>: Get https://ydzs-node2:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: dial tcp: lookup ydzs-node2 on 10.96.0.10:53: no such host&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们可以发现 Pod 中出现了一些错误信息：&lt;code>xxx: no such host&lt;/code>，我们看到这个错误信息一般就可以确定是 DNS 解析不了造成的，我们可以看到 Metrics Server 会通过 kubelet 的 10250 端口获取信息，使用的是 hostname，我们部署集群的时候在节点的 &lt;code>/etc/hosts&lt;/code> 里面添加了节点的 hostname 和 ip 的映射，但是是我们的 Metrics Server 的 Pod 内部并没有这个 hosts 信息，当然也就不识别 hostname 了，要解决这个问题，有两种方法：第一种方法就是在集群内部的 DNS 服务里面添加上 hostname 的解析，比如我们这里集群中使用的是 &lt;code>CoreDNS&lt;/code>，我们就可以去修改下 CoreDNS 的 Configmap 信息，添加上 hosts 信息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">$ kubectl edit configmap coredns -n kube-system&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">data&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">Corefile&lt;/span>: |&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> .:53 {
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> errors
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> health
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> hosts { # 添加集群节点hosts隐射信息
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> 10.151.30.11 ydzs-master
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> 10.151.30.57 ydzs-node3
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> 10.151.30.59 ydzs-node4
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> 10.151.30.22 ydzs-node1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> 10.151.30.23 ydzs-node2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> fallthrough
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> }
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> kubernetes cluster.local in-addr.arpa ip6.arpa {
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> pods insecure
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> upstream
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> fallthrough in-addr.arpa ip6.arpa
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> }
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> prometheus :9153
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> proxy . /etc/resolv.conf
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> cache 30
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> reload
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> }&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ConfigMap&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">creationTimestamp&lt;/span>: &lt;span style="color:#e6db74">2019-05-18T11:07:46Z&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">coredns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">kube-system&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样当在集群内部访问集群的 hostname 的时候就可以解析到对应的 ip 了，另外一种方法就是在 metrics-server 的启动参数中修改 &lt;code>kubelet-preferred-address-types&lt;/code> 参数，如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">args&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">cert-dir=/tmp&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">secure-port=4443&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">kubelet-preferred-address-types=InternalIP&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们这里使用第二种方式，然后重新安装：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get pods -n kube-system -l k8s-app&lt;span style="color:#f92672">=&lt;/span>metrics-server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metrics-server-6dcfdf89b5-tvdcp 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 33s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl logs -f metric-metrics-server-58fc94d9f-jlxcb -n kube-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>E1119 09:08:49.805959 &lt;span style="color:#ae81ff">1&lt;/span> manager.go:111&lt;span style="color:#f92672">]&lt;/span> unable to fully collect metrics: &lt;span style="color:#f92672">[&lt;/span>unable to fully scrape metrics from source kubelet_summary:ydzs-node3: unable to fetch metrics from Kubelet ydzs-node3 &lt;span style="color:#f92672">(&lt;/span>10.151.30.57&lt;span style="color:#f92672">)&lt;/span>: Get https://10.151.30.57:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: x509: cannot validate certificate &lt;span style="color:#66d9ef">for&lt;/span> 10.151.30.57 because it doesn&lt;span style="color:#e6db74">&amp;#39;t contain any IP SANs, unable to fully scrape metrics from source kubelet_summary:ydzs-node4: unable to fetch metrics from Kubelet ydzs-node4 (10.151.30.59): Get https://10.151.30.59:10250/stats/summary?only_cpu_and_memory=true: x509: cannot validate certificate for 10.151.30.59 because it doesn&amp;#39;&lt;/span>t contain any IP SANs, unable to fully scrape metrics from source kubelet_summary:ydzs-node2: unable to fetch metrics from Kubelet ydzs-node2 &lt;span style="color:#f92672">(&lt;/span>10.151.30.23&lt;span style="color:#f92672">)&lt;/span>: Get https://10.151.30.23:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: x509: cannot validate certificate &lt;span style="color:#66d9ef">for&lt;/span> 10.151.30.23 because it doesn&lt;span style="color:#e6db74">&amp;#39;t contain any IP SANs, unable to fully scrape metrics from source kubelet_summary:ydzs-master: unable to fetch metrics from Kubelet ydzs-master (10.151.30.11): Get https://10.151.30.11:10250/stats/summary?only_cpu_and_memory=true: x509: cannot validate certificate for 10.151.30.11 because it doesn&amp;#39;&lt;/span>t contain any IP SANs, unable to fully scrape metrics from source kubelet_summary:ydzs-node1: unable to fetch metrics from Kubelet ydzs-node1 &lt;span style="color:#f92672">(&lt;/span>10.151.30.22&lt;span style="color:#f92672">)&lt;/span>: Get https://10.151.30.22:10250/stats/summary?only_cpu_and_memory&lt;span style="color:#f92672">=&lt;/span>true: x509: cannot validate certificate &lt;span style="color:#66d9ef">for&lt;/span> 10.151.30.22 because it doesn&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>t contain any IP SANs&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>因为部署集群的时候，CA 证书并没有把各个节点的 IP 签上去，所以这里 &lt;code>Metrics Server&lt;/code> 通过 IP 去请求时，提示签的证书没有对应的 IP（错误：&lt;code>x509: cannot validate certificate for 10.151.30.22 because it doesn’t contain any IP SANs&lt;/code>），我们可以添加一个&lt;code>--kubelet-insecure-tls&lt;/code>参数跳过证书校验：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">args&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">cert-dir=/tmp&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">secure-port=4443&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">kubelet-insecure-tls&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- --&lt;span style="color:#ae81ff">kubelet-preferred-address-types=InternalIP&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后再重新安装即可成功！可以通过如下命令来验证：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl apply -f deploy/1.8+/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get pods -n kube-system -l k8s-app&lt;span style="color:#f92672">=&lt;/span>metrics-server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metrics-server-5d4dbb78bb-6klw6 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 14s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl logs -f metrics-server-5d4dbb78bb-6klw6 -n kube-system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>I1119 09:10:44.249092 &lt;span style="color:#ae81ff">1&lt;/span> serving.go:312&lt;span style="color:#f92672">]&lt;/span> Generated self-signed cert &lt;span style="color:#f92672">(&lt;/span>/tmp/apiserver.crt, /tmp/apiserver.key&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>I1119 09:10:45.264076 &lt;span style="color:#ae81ff">1&lt;/span> secure_serving.go:116&lt;span style="color:#f92672">]&lt;/span> Serving securely on &lt;span style="color:#f92672">[&lt;/span>::&lt;span style="color:#f92672">]&lt;/span>:4443
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get apiservice | grep metrics
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>v1beta1.metrics.k8s.io kube-system/metrics-server True 9m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get --raw &lt;span style="color:#e6db74">&amp;#34;/apis/metrics.k8s.io/v1beta1/nodes&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;NodeMetricsList&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;metrics.k8s.io/v1beta1&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;selfLink&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/apis/metrics.k8s.io/v1beta1/nodes&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;items&amp;#34;&lt;/span>:&lt;span style="color:#f92672">[{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;ydzs-node3&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;selfLink&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/apis/metrics.k8s.io/v1beta1/nodes/ydzs-node3&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;creationTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:53Z&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;timestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:38Z&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;window&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;30s&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;usage&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;cpu&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;240965441n&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;memory&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;3004360Ki&amp;#34;&lt;/span>&lt;span style="color:#f92672">}}&lt;/span>,&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;ydzs-node4&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;selfLink&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/apis/metrics.k8s.io/v1beta1/nodes/ydzs-node4&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;creationTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:53Z&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;timestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:37Z&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;window&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;30s&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;usage&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;cpu&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;167036681n&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;memory&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2574664Ki&amp;#34;&lt;/span>&lt;span style="color:#f92672">}}&lt;/span>,&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;ydzs-master&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;selfLink&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/apis/metrics.k8s.io/v1beta1/nodes/ydzs-master&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;creationTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:53Z&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;timestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:38Z&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;window&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;30s&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;usage&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;cpu&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;350907350n&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;memory&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2986716Ki&amp;#34;&lt;/span>&lt;span style="color:#f92672">}}&lt;/span>,&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;ydzs-node1&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;selfLink&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/apis/metrics.k8s.io/v1beta1/nodes/ydzs-node1&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;creationTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:53Z&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;timestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:39Z&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;window&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;30s&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;usage&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;cpu&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;1319638039n&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;memory&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2094376Ki&amp;#34;&lt;/span>&lt;span style="color:#f92672">}}&lt;/span>,&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;ydzs-node2&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;selfLink&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/apis/metrics.k8s.io/v1beta1/nodes/ydzs-node2&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;creationTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:53Z&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;timestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:11:36Z&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;window&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;30s&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;usage&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;cpu&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;320381888n&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;memory&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;3270368Ki&amp;#34;&lt;/span>&lt;span style="color:#f92672">}}]}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl top nodes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME CPU&lt;span style="color:#f92672">(&lt;/span>cores&lt;span style="color:#f92672">)&lt;/span> CPU% MEMORY&lt;span style="color:#f92672">(&lt;/span>bytes&lt;span style="color:#f92672">)&lt;/span> MEMORY%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ydzs-master 351m 17% 2916Mi 79%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ydzs-node1 1320m 33% 2045Mi 26%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ydzs-node2 321m 8% 3193Mi 41%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ydzs-node3 241m 6% 2933Mi 37%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ydzs-node4 168m 4% 2514Mi 32%
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在我们可以通过 &lt;code>kubectl top&lt;/code> 命令来获取到资源数据了，证明 &lt;code>Metrics Server&lt;/code> 已经安装成功了。&lt;/p>
&lt;h2 id="基于-cpu">基于 CPU&lt;a class="td-heading-self-link" href="#%e5%9f%ba%e4%ba%8e-cpu" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>现在我们用 Deployment 来创建一个 Nginx Pod，然后利用 &lt;code>HPA&lt;/code> 来进行自动扩缩容。资源清单如下所示：（hpa-demo.yaml）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matchLabels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">containerPort&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后直接创建 Deployment：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl apply -f hpa-demo.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/hpa-demo created
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get pods -l app&lt;span style="color:#f92672">=&lt;/span>nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-85ff79dd56-pz8th 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 21s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在我们来创建一个 &lt;code>HPA&lt;/code> 资源对象，可以使用&lt;code>kubectl autoscale&lt;/code>命令来创建：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl autoscale deployment hpa-demo --cpu-percent&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10&lt;/span> --min&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --max&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>horizontalpodautoscaler.autoscaling/hpa-demo autoscaled
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo Deployment/hpa-demo &amp;lt;unknown&amp;gt;/10% &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> 16s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>此命令创建了一个关联资源 hpa-demo 的 HPA，最小的 Pod 副本数为 1，最大为 10。HPA 会根据设定的 cpu 使用率（10%）动态的增加或者减少 Pod 数量。&lt;/p>
&lt;p>当然我们依然还是可以通过创建 YAML 文件的形式来创建 HPA 资源对象。如果我们不知道怎么编写的话，可以查看上面命令行创建的 HPA 的 YAML 文件：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">$ kubectl get hpa hpa-demo -o yaml&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">autoscaling/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">HorizontalPodAutoscaler&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">annotations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">autoscaling.alpha.kubernetes.io/conditions&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;[{&amp;#34;type&amp;#34;:&amp;#34;AbleToScale&amp;#34;,&amp;#34;status&amp;#34;:&amp;#34;True&amp;#34;,&amp;#34;lastTransitionTime&amp;#34;:&amp;#34;2019-11-19T09:15:12Z&amp;#34;,&amp;#34;reason&amp;#34;:&amp;#34;SucceededGetScale&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;the
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> HPA controller was able to get the target&amp;#39;&amp;#39;s current scale&amp;#34;},{&amp;#34;type&amp;#34;:&amp;#34;ScalingActive&amp;#34;,&amp;#34;status&amp;#34;:&amp;#34;False&amp;#34;,&amp;#34;lastTransitionTime&amp;#34;:&amp;#34;2019-11-19T09:15:12Z&amp;#34;,&amp;#34;reason&amp;#34;:&amp;#34;FailedGetResourceMetric&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;the
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> HPA was unable to compute the replica count: missing request for cpu&amp;#34;}]&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">creationTimestamp&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2019-11-19T09:14:56Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">default&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resourceVersion&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;3094084&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selfLink&lt;/span>: &lt;span style="color:#ae81ff">/apis/autoscaling/v1/namespaces/default/horizontalpodautoscalers/hpa-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uid&lt;/span>: &lt;span style="color:#ae81ff">b84d79f1-75b0-46e0-95b5-4cbe3509233b&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">maxReplicas&lt;/span>: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">minReplicas&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">scaleTargetRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">targetCPUUtilizationPercentage&lt;/span>: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">status&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">currentReplicas&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">desiredReplicas&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后我们可以根据上面的 YAML 文件就可以自己来创建一个基于 YAML 的 HPA 描述文件了。但是我们发现上面信息里面出现了一些 Fail 信息，我们来查看下这个 HPA 对象的信息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl describe hpa hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CreationTimestamp: Tue, &lt;span style="color:#ae81ff">19&lt;/span> Nov &lt;span style="color:#ae81ff">2019&lt;/span> 17:14:56 +0800
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Reference: Deployment/hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Metrics: &lt;span style="color:#f92672">(&lt;/span> current / target &lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resource cpu on pods &lt;span style="color:#f92672">(&lt;/span>as a percentage of request&lt;span style="color:#f92672">)&lt;/span>: &amp;lt;unknown&amp;gt; / 10%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Min replicas: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Max replicas: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Deployment pods: &lt;span style="color:#ae81ff">1&lt;/span> current / &lt;span style="color:#ae81ff">0&lt;/span> desired
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Status Reason Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ------ -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AbleToScale True SucceededGetScale the HPA controller was able to get the target&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>s current scale
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ScalingActive False FailedGetResourceMetric the HPA was unable to compute the replica count: missing request &lt;span style="color:#66d9ef">for&lt;/span> cpu
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Events:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Reason Age From Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ---- ---- -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Warning FailedGetResourceMetric 14s &lt;span style="color:#f92672">(&lt;/span>x4 over 60s&lt;span style="color:#f92672">)&lt;/span> horizontal-pod-autoscaler missing request &lt;span style="color:#66d9ef">for&lt;/span> cpu
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Warning FailedComputeMetricsReplicas 14s &lt;span style="color:#f92672">(&lt;/span>x4 over 60s&lt;span style="color:#f92672">)&lt;/span> horizontal-pod-autoscaler invalid metrics &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> invalid out of 1&lt;span style="color:#f92672">)&lt;/span>, first error is: failed to get cpu utilization: missing request &lt;span style="color:#66d9ef">for&lt;/span> cpu
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们可以看到上面的事件信息里面出现了 &lt;code>failed to get cpu utilization: missing request for cpu&lt;/code> 这样的错误信息。这是因为我们上面创建的 Pod 对象没有添加 request 资源声明，这样导致 HPA 读取不到 CPU 指标信息，所以如果要想让 HPA 生效，对应的 Pod 资源必须添加 requests 资源声明，更新我们的资源清单文件：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matchLabels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">containerPort&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">memory&lt;/span>: &lt;span style="color:#ae81ff">50Mi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">cpu&lt;/span>: &lt;span style="color:#ae81ff">50m&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后重新更新 Deployment，重新创建 HPA 对象：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl apply -f hpa.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/hpa-demo configured
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get pods -o wide -l app&lt;span style="color:#f92672">=&lt;/span>nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-twtdp 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 4m11s 10.244.4.97 ydzs-node4 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl delete hpa hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>horizontalpodautoscaler.autoscaling &lt;span style="color:#e6db74">&amp;#34;hpa-demo&amp;#34;&lt;/span> deleted
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl autoscale deployment hpa-demo --cpu-percent&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10&lt;/span> --min&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --max&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>horizontalpodautoscaler.autoscaling/hpa-demo autoscaled
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl describe hpa hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CreationTimestamp: Tue, &lt;span style="color:#ae81ff">19&lt;/span> Nov &lt;span style="color:#ae81ff">2019&lt;/span> 17:23:49 +0800
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Reference: Deployment/hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Metrics: &lt;span style="color:#f92672">(&lt;/span> current / target &lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resource cpu on pods &lt;span style="color:#f92672">(&lt;/span>as a percentage of request&lt;span style="color:#f92672">)&lt;/span>: 0% &lt;span style="color:#f92672">(&lt;/span>0&lt;span style="color:#f92672">)&lt;/span> / 10%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Min replicas: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Max replicas: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Deployment pods: &lt;span style="color:#ae81ff">1&lt;/span> current / &lt;span style="color:#ae81ff">1&lt;/span> desired
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Status Reason Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ------ -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AbleToScale True ScaleDownStabilized recent recommendations were higher than current one, applying the highest recent recommendation
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from cpu resource utilization &lt;span style="color:#f92672">(&lt;/span>percentage of request&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ScalingLimited False DesiredWithinRange the desired count is within the acceptable range
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Events: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo Deployment/hpa-demo 0%/10% &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> 52s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在可以看到 HPA 资源对象已经正常了，现在我们来增大负载进行测试，我们来创建一个 busybox 的 Pod，并且循环访问上面创建的 Pod：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl run -it --image busybox test-hpa --restart&lt;span style="color:#f92672">=&lt;/span>Never --rm /bin/sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>If you don&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>t see a command prompt, try pressing enter.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/ &lt;span style="color:#75715e"># while true; do wget -q -O- http://10.244.4.97; done&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>下图可以看到，HPA 已经开始工作：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo Deployment/hpa-demo 338%/10% &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> 5m15s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get pods -l app&lt;span style="color:#f92672">=&lt;/span>nginx --watch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-8hjnn 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 22s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-9ss9f 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 22s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-bllsd 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 22s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-lnh8k 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 37s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-r8zfh 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 22s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-twtdp 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 6m43s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-w792g 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 37s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-zlxkp 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 37s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-znp6q 0/1 ContainerCreating &lt;span style="color:#ae81ff">0&lt;/span> 6s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo-69968bb59f-ztnvx 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 6s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们可以看到已经自动拉起了很多新的 Pod，最后定格在了我们上面设置的 10 个 Pod，同时查看资源 hpa-demo 的副本数量，副本数量已经从原来的 1 变成了 10 个：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get deployment hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY UP-TO-DATE AVAILABLE AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo 10/10 &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span> 17m
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>查看 HPA 资源的对象了解工作过程：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl describe hpa hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CreationTimestamp: Tue, &lt;span style="color:#ae81ff">19&lt;/span> Nov &lt;span style="color:#ae81ff">2019&lt;/span> 17:23:49 +0800
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Reference: Deployment/hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Metrics: &lt;span style="color:#f92672">(&lt;/span> current / target &lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resource cpu on pods &lt;span style="color:#f92672">(&lt;/span>as a percentage of request&lt;span style="color:#f92672">)&lt;/span>: 0% &lt;span style="color:#f92672">(&lt;/span>0&lt;span style="color:#f92672">)&lt;/span> / 10%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Min replicas: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Max replicas: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Deployment pods: &lt;span style="color:#ae81ff">10&lt;/span> current / &lt;span style="color:#ae81ff">10&lt;/span> desired
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Status Reason Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ------ -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AbleToScale True ScaleDownStabilized recent recommendations were higher than current one, applying the highest recent recommendation
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from cpu resource utilization &lt;span style="color:#f92672">(&lt;/span>percentage of request&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ScalingLimited True TooManyReplicas the desired replica count is more than the maximum replica count
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Events:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Reason Age From Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ---- ---- -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Normal SuccessfulRescale 5m45s horizontal-pod-autoscaler New size: 4; reason: cpu resource utilization &lt;span style="color:#f92672">(&lt;/span>percentage of request&lt;span style="color:#f92672">)&lt;/span> above target
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Normal SuccessfulRescale 5m30s horizontal-pod-autoscaler New size: 8; reason: cpu resource utilization &lt;span style="color:#f92672">(&lt;/span>percentage of request&lt;span style="color:#f92672">)&lt;/span> above target
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Normal SuccessfulRescale 5m14s horizontal-pod-autoscaler New size: 10; reason: cpu resource utilization &lt;span style="color:#f92672">(&lt;/span>percentage of request&lt;span style="color:#f92672">)&lt;/span> above target
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>同样的这个时候我们来关掉 busybox 来减少负载，然后等待一段时间观察下 HPA 和 Deployment 对象：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo Deployment/hpa-demo 0%/10% &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> 14m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get deployment hpa-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY UP-TO-DATE AVAILABLE AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-demo 1/1 &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> 24m
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到副本数量已经由 10 变为 1，当前我们只是演示了 CPU 使用率这一个指标，在后面的课程中我们还会学习到根据自定义的监控指标来自动对 Pod 进行扩缩容。&lt;/p>
&lt;h2 id="基于内存">基于内存&lt;a class="td-heading-self-link" href="#%e5%9f%ba%e4%ba%8e%e5%86%85%e5%ad%98" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;code>HorizontalPodAutoscaler&lt;/code> 是 Kubernetes autoscaling API 组的资源，在当前稳定版本 &lt;code>autoscaling/v1&lt;/code> 中只支持基于 CPU 指标的缩放。在 Beta 版本 &lt;code>autoscaling/v2beta2&lt;/code>，引入了基于内存和自定义指标的缩放。所以我们这里需要使用 Beta 版本的 API。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kpk0nr/1616116805951-274bb778-81fd-4004-a69d-c928b5d90fa7.png" alt="">&lt;/p>
&lt;p>hpa api version&lt;/p>
&lt;p>现在我们用 Deployment 来创建一个 Nginx Pod，然后利用 HPA 来进行自动扩缩容。资源清单如下所示：（hpa-mem-demo.yaml）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-mem-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matchLabels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">increase-mem-script&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMap&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">increase-mem-config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">nginx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">containerPort&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumeMounts&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">increase-mem-script&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/script&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">memory&lt;/span>: &lt;span style="color:#ae81ff">50Mi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">cpu&lt;/span>: &lt;span style="color:#ae81ff">50m&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">securityContext&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">privileged&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里和前面普通的应用有一些区别，我们将一个名为 &lt;code>increase-mem-config&lt;/code> 的 ConfigMap 资源对象挂载到了容器中，该配置文件是用于后面增加容器内存占用的脚本，配置文件如下所示：（increase-mem-cm.yaml）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ConfigMap&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">increase-mem-config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">data&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">increase-mem.sh&lt;/span>: |&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> #!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> mkdir /tmp/memory
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> mount -t tmpfs -o size=40M tmpfs /tmp/memory
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> dd if=/dev/zero of=/tmp/memory/block
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> sleep 60
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> rm /tmp/memory/block
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> umount /tmp/memory
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> rmdir /tmp/memory&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>由于这里增加内存的脚本需要使用到 &lt;code>mount&lt;/code> 命令，这需要声明为特权模式，所以我们添加了 &lt;code>securityContext.privileged=true&lt;/code> 这个配置。现在我们直接创建上面的资源对象即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl apply -f increase-mem-cm.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl apply -f hpa-mem-demo.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get pods -l app&lt;span style="color:#f92672">=&lt;/span>nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-mem-demo-66944b79bf-tqrn9 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 35s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后需要创建一个基于内存的 HPA 资源对象：（hpa-mem.yaml）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">autoscaling/v2beta1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">HorizontalPodAutoscaler&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx-hpa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">scaleTargetRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-mem-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">minReplicas&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">maxReplicas&lt;/span>: &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metrics&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">Resource&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resource&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">memory&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">targetAverageUtilization&lt;/span>: &lt;span style="color:#ae81ff">60&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>要注意这里使用的 &lt;code>apiVersion&lt;/code> 是 &lt;code>autoscaling/v2beta1&lt;/code>，然后 &lt;code>metrics&lt;/code> 属性里面指定的是内存的配置，直接创建上面的资源对象即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl apply -f hpa-mem.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>horizontalpodautoscaler.autoscaling/nginx-hpa created
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nginx-hpa Deployment/hpa-mem-demo 2%/60% &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> 12s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>到这里证明 HPA 资源对象已经部署成功了，接下来我们对应用进行压测，将内存压上去，直接执行上面我们挂载到容器中的 &lt;code>increase-mem.sh&lt;/code> 脚本即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl exec -it hpa-mem-demo-66944b79bf-tqrn9 /bin/bash
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root@hpa-mem-demo-66944b79bf-tqrn9:/# ls /etc/script/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>increase-mem.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root@hpa-mem-demo-66944b79bf-tqrn9:/# source /etc/script/increase-mem.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dd: writing to &lt;span style="color:#e6db74">&amp;#39;/tmp/memory/block&amp;#39;&lt;/span>: No space left on device
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>81921+0 records in
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>81920+0 records out
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">41943040&lt;/span> bytes &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#ae81ff">42&lt;/span> MB, &lt;span style="color:#ae81ff">40&lt;/span> MiB&lt;span style="color:#f92672">)&lt;/span> copied, 0.584029 s, 71.8 MB/s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后打开另外一个终端观察 HPA 资源对象的变化情况：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nginx-hpa Deployment/hpa-mem-demo 83%/60% &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> 5m3s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl describe hpa nginx-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: nginx-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: kubectl.kubernetes.io/last-applied-configuration:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;autoscaling/v2beta1&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;HorizontalPodAutoscaler&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;annotations&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;nginx-hpa&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;namespace&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CreationTimestamp: Tue, &lt;span style="color:#ae81ff">07&lt;/span> Apr &lt;span style="color:#ae81ff">2020&lt;/span> 13:13:59 +0800
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Reference: Deployment/hpa-mem-demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Metrics: &lt;span style="color:#f92672">(&lt;/span> current / target &lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resource memory on pods &lt;span style="color:#f92672">(&lt;/span>as a percentage of request&lt;span style="color:#f92672">)&lt;/span>: 3% &lt;span style="color:#f92672">(&lt;/span>1740800&lt;span style="color:#f92672">)&lt;/span> / 60%
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Min replicas: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Max replicas: &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Deployment pods: &lt;span style="color:#ae81ff">2&lt;/span> current / &lt;span style="color:#ae81ff">2&lt;/span> desired
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Status Reason Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ------ -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AbleToScale True ScaleDownStabilized recent recommendations were higher than current one, applying the highest recent recommendation
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from memory resource utilization &lt;span style="color:#f92672">(&lt;/span>percentage of request&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ScalingLimited False DesiredWithinRange the desired count is within the acceptable range
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Events:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Type Reason Age From Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ---- ------ ---- ---- -------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Warning FailedGetResourceMetric 5m26s &lt;span style="color:#f92672">(&lt;/span>x3 over 5m58s&lt;span style="color:#f92672">)&lt;/span> horizontal-pod-autoscaler unable to get metrics &lt;span style="color:#66d9ef">for&lt;/span> resource memory: no metrics returned from resource metrics API
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Warning FailedComputeMetricsReplicas 5m26s &lt;span style="color:#f92672">(&lt;/span>x3 over 5m58s&lt;span style="color:#f92672">)&lt;/span> horizontal-pod-autoscaler invalid metrics &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> invalid out of 1&lt;span style="color:#f92672">)&lt;/span>, first error is: failed to get memory utilization: unable to get metrics &lt;span style="color:#66d9ef">for&lt;/span> resource memory: no metrics returned from resource metrics API
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Normal SuccessfulRescale 77s horizontal-pod-autoscaler New size: 2; reason: memory resource utilization &lt;span style="color:#f92672">(&lt;/span>percentage of request&lt;span style="color:#f92672">)&lt;/span> above target
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl top pod hpa-mem-demo-66944b79bf-tqrn9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME CPU&lt;span style="color:#f92672">(&lt;/span>cores&lt;span style="color:#f92672">)&lt;/span> MEMORY&lt;span style="color:#f92672">(&lt;/span>bytes&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-mem-demo-66944b79bf-tqrn9 0m 41Mi
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到内存使用已经超过了我们设定的 60% 这个阈值了，HPA 资源对象也已经触发了自动扩容，变成了两个副本了：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get pods -l app&lt;span style="color:#f92672">=&lt;/span>nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-mem-demo-66944b79bf-8m4d9 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 2m51s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-mem-demo-66944b79bf-tqrn9 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 8m11s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>当内存释放掉后，controller-manager 默认 5 分钟过后会进行缩放，到这里就完成了基于内存的 HPA 操作。&lt;/p>
&lt;h2 id="基于自定义指标">基于自定义指标&lt;a class="td-heading-self-link" href="#%e5%9f%ba%e4%ba%8e%e8%87%aa%e5%ae%9a%e4%b9%89%e6%8c%87%e6%a0%87" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>除了基于 CPU 和内存来进行自动扩缩容之外，我们还可以根据自定义的监控指标来进行。这个我们就需要使用 &lt;code>Prometheus Adapter&lt;/code>，Prometheus 用于监控应用的负载和集群本身的各种指标，&lt;code>Prometheus Adapter&lt;/code> 可以帮我们使用 Prometheus 收集的指标并使用它们来制定扩展策略，这些指标都是通过 APIServer 暴露的，而且 HPA 资源对象也可以很轻易的直接使用。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kpk0nr/1616116805981-8c3dbfc1-65c1-48db-8e3b-710da1c58765.png" alt="">&lt;/p>
&lt;p>custom metrics by prometheus&lt;/p>
&lt;p>首先，我们部署一个示例应用，在该应用程序上测试 Prometheus 指标自动缩放，资源清单文件如下所示：（hpa-prome-demo.yaml）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-prom-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matchLabels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx-server&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx-server&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">cnych/nginx-vts:v1.0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">limits&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">cpu&lt;/span>: &lt;span style="color:#ae81ff">50m&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">cpu&lt;/span>: &lt;span style="color:#ae81ff">50m&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">containerPort&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Service&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-prom-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">annotations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">prometheus.io/scrape&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">prometheus.io/port&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;80&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">prometheus.io/path&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/status/format/prometheus&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">port&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">targetPort&lt;/span>: &lt;span style="color:#ae81ff">80&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">selector&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">nginx-server&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">NodePort&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里我们部署的应用是在 80 端口的 &lt;code>/status/format/prometheus&lt;/code> 这个端点暴露 nginx-vts 指标的，前面我们已经在 Prometheus 中配置了 Endpoints 的自动发现，所以我们直接在 Service 对象的 &lt;code>annotations&lt;/code> 中进行配置，这样我们就可以在 Prometheus 中采集该指标数据了。为了测试方便，我们这里使用 NodePort 类型的 Service，现在直接创建上面的资源对象即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl apply -f hpa-prome-demo.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/hpa-prom-demo created
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>service/hpa-prom-demo created
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get pods -l app&lt;span style="color:#f92672">=&lt;/span>nginx-server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-prom-demo-755bb56f85-lvksr 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 4m52s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get svc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME TYPE CLUSTER-IP EXTERNAL-IP PORT&lt;span style="color:#f92672">(&lt;/span>S&lt;span style="color:#f92672">)&lt;/span> AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-prom-demo NodePort 10.101.210.158 &amp;lt;none&amp;gt; 80:32408/TCP 5m44s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>部署完成后我们可以使用如下命令测试应用是否正常，以及指标数据接口能够正常获取：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ curl http://k8s.qikqiak.com:32408
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;!DOCTYPE html&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;html&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;head&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;style&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> body &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> width: 35em;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> margin: &lt;span style="color:#ae81ff">0&lt;/span> auto;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> font-family: Tahoma, Verdana, Arial, sans-serif;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/style&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/head&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;body&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;p&amp;gt;If you see this page, the nginx web server is successfully installed and
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>working. Further configuration is required.&amp;lt;/p&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;p&amp;gt;For online documentation and support please refer to
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;a href&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;http://nginx.org/&amp;#34;&lt;/span>&amp;gt;nginx.org&amp;lt;/a&amp;gt;.&amp;lt;br/&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Commercial support is available at
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;a href&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;http://nginx.com/&amp;#34;&lt;/span>&amp;gt;nginx.com&amp;lt;/a&amp;gt;.&amp;lt;/p&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;p&amp;gt;&amp;lt;em&amp;gt;Thank you &lt;span style="color:#66d9ef">for&lt;/span> using nginx.&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/body&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/html&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ curl http://k8s.qikqiak.com:32408/status/format/prometheus
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># HELP nginx_vts_info Nginx info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># TYPE nginx_vts_info gauge&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nginx_vts_info&lt;span style="color:#f92672">{&lt;/span>hostname&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;hpa-prom-demo-755bb56f85-lvksr&amp;#34;&lt;/span>,version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;1.13.12&amp;#34;&lt;/span>&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># HELP nginx_vts_start_time_seconds Nginx start time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># TYPE nginx_vts_start_time_seconds gauge&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nginx_vts_start_time_seconds 1586240091.623
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># HELP nginx_vts_main_connections Nginx connections&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># TYPE nginx_vts_main_connections gauge&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>......
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>上面的指标数据中，我们比较关心的是 &lt;code>nginx_vts_server_requests_total&lt;/code> 这个指标，表示请求总数，是一个 &lt;code>Counter&lt;/code> 类型的指标，我们将使用该指标的值来确定是否需要对我们的应用进行自动扩缩容。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kpk0nr/1616116805999-cf50cbd9-8273-472c-bb6f-dac9055780b5.png" alt="">&lt;/p>
&lt;p>nginx_vts_server_requests_total&lt;/p>
&lt;p>接下来我们将 Prometheus-Adapter 安装到集群中，并添加一个规则来跟踪 Pod 的请求，我们可以将 Prometheus 中的任何一个指标都用于 HPA，但是前提是你得通过查询语句将它拿到（包括指标名称和其对应的值）。&lt;/p>
&lt;p>这里我们定义一个如下所示的规则：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">rules&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- &lt;span style="color:#f92672">seriesQuery&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;nginx_vts_server_requests_total&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">seriesFilters&lt;/span>: []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">overrides&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kubernetes_namespace&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resource&lt;/span>: &lt;span style="color:#ae81ff">namespace&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kubernetes_pod_name&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resource&lt;/span>: &lt;span style="color:#ae81ff">pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matches&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;^(.*)_total&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">as&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;${1}_per_second&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metricsQuery&lt;/span>: &lt;span style="color:#ae81ff">(sum(rate(&amp;lt;.Series&amp;gt;&amp;gt;{&amp;lt;&amp;lt;.LabelMatchers&amp;gt;&amp;gt;}[1m])) by (&amp;lt;.GroupBy&amp;gt;))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这是一个带参数的 Prometheus 查询，其中：&lt;/p>
&lt;ul>
&lt;li>&lt;code>seriesQuery&lt;/code>：查询 Prometheus 的语句，通过这个查询语句查询到的所有指标都可以用于 HPA&lt;/li>
&lt;li>&lt;code>seriesFilters&lt;/code>：查询到的指标可能会存在不需要的，可以通过它过滤掉。&lt;/li>
&lt;li>&lt;code>resources&lt;/code>：通过 &lt;code>seriesQuery&lt;/code> 查询到的只是指标，如果需要查询某个 Pod 的指标，肯定要将它的名称和所在的命名空间作为指标的标签进行查询，&lt;code>resources&lt;/code> 就是将指标的标签和 k8s 的资源类型关联起来，最常用的就是 pod 和 namespace。有两种添加标签的方式，一种是 &lt;code>overrides&lt;/code>，另一种是 &lt;code>template&lt;/code>。
&lt;ul>
&lt;li>&lt;code>overrides&lt;/code>：它会将指标中的标签和 k8s 资源关联起来。上面示例中就是将指标中的 pod 和 namespace 标签和 k8s 中的 pod 和 namespace 关联起来，因为 pod 和 namespace 都属于核心 api 组，所以不需要指定 api 组。当我们查询某个 pod 的指标时，它会自动将 pod 的名称和名称空间作为标签加入到查询条件中。比如 &lt;code>nginx: {group: &amp;quot;apps&amp;quot;, resource: &amp;quot;deployment&amp;quot;}&lt;/code> 这么写表示的就是将指标中 nginx 这个标签和 apps 这个 api 组中的 &lt;code>deployment&lt;/code> 资源关联起来；&lt;/li>
&lt;li>template：通过 go 模板的形式。比如&lt;code>template: &amp;quot;kube_&amp;lt;&amp;lt;.Group&amp;gt;&amp;gt;_&amp;lt;&amp;lt;.Resource&amp;gt;&amp;gt;&amp;quot;&lt;/code> 这么写表示，假如 &lt;code>&amp;lt;&amp;lt;.Group&amp;gt;&amp;gt;&lt;/code> 为 apps，&lt;code>&amp;lt;&amp;lt;.Resource&amp;gt;&amp;gt;&lt;/code> 为 deployment，那么它就是将指标中 &lt;code>kube_apps_deployment&lt;/code> 标签和 deployment 资源关联起来。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>name&lt;/code>：用来给指标重命名的，之所以要给指标重命名是因为有些指标是只增的，比如以 total 结尾的指标。这些指标拿来做 HPA 是没有意义的，我们一般计算它的速率，以速率作为值，那么此时的名称就不能以 total 结尾了，所以要进行重命名。
&lt;ul>
&lt;li>&lt;code>matches&lt;/code>：通过正则表达式来匹配指标名，可以进行分组&lt;/li>
&lt;li>&lt;code>as&lt;/code>：默认值为 &lt;code>$1&lt;/code>，也就是第一个分组。&lt;code>as&lt;/code> 为空就是使用默认值的意思。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>metricsQuery&lt;/code>：这就是 Prometheus 的查询语句了，前面的 &lt;code>seriesQuery&lt;/code> 查询是获得 HPA 指标。当我们要查某个指标的值时就要通过它指定的查询语句进行了。可以看到查询语句使用了速率和分组，这就是解决上面提到的只增指标的问题。
&lt;ul>
&lt;li>&lt;code>Series&lt;/code>：表示指标名称&lt;/li>
&lt;li>&lt;code>LabelMatchers&lt;/code>：附加的标签，目前只有 &lt;code>pod&lt;/code> 和 &lt;code>namespace&lt;/code> 两种，因此我们要在之前使用 &lt;code>resources&lt;/code> 进行关联&lt;/li>
&lt;li>&lt;code>GroupBy&lt;/code>：就是 pod 名称，同样需要使用 &lt;code>resources&lt;/code> 进行关联。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>接下来我们通过 Helm Chart 来部署 Prometheus Adapter，新建 &lt;code>hpa-prome-adapter-values.yaml&lt;/code> 文件覆盖默认的 Values 值，内容如下所示：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">rules&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">default&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">custom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">seriesQuery&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;nginx_vts_server_requests_total&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resources&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">overrides&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kubernetes_namespace&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resource&lt;/span>: &lt;span style="color:#ae81ff">namespace&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kubernetes_pod_name&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">resource&lt;/span>: &lt;span style="color:#ae81ff">pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">matches&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;^(.*)_total&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">as&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;${1}_per_second&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metricsQuery&lt;/span>: &lt;span style="color:#ae81ff">(sum(rate(&amp;lt;.Series&amp;gt;&amp;gt;{&amp;lt;&amp;lt;.LabelMatchers&amp;gt;&amp;gt;}[1m])) by (&amp;lt;.GroupBy&amp;gt;))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">prometheus&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">url&lt;/span>: &lt;span style="color:#ae81ff">http://thanos-querier.kube-mon.svc.cluster.local&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里我们添加了一条 rules 规则，然后指定了 Prometheus 的地址，我们这里是使用了 Thanos 部署的 Promethues 集群，所以用 Querier 的地址。使用下面的命令一键安装：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ helm install prometheus-adapter stable/prometheus-adapter -n kube-mon -f hpa-prome-adapter-values.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME: prometheus-adapter
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>LAST DEPLOYED: Tue Apr &lt;span style="color:#ae81ff">7&lt;/span> 15:26:36 &lt;span style="color:#ae81ff">2020&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAMESPACE: kube-mon
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>STATUS: deployed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>REVISION: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>TEST SUITE: None
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NOTES:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prometheus-adapter has been deployed.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>In a few minutes you should be able to list metrics using the following command&lt;span style="color:#f92672">(&lt;/span>s&lt;span style="color:#f92672">)&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>等一小会儿，安装完成后，可以使用下面的命令来检测是否生效了：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get pods -n kube-mon -l app&lt;span style="color:#f92672">=&lt;/span>prometheus-adapter
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>prometheus-adapter-58b559fc7d-l2j6t 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 3m21s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl get --raw&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/apis/custom.metrics.k8s.io/v1beta1&amp;#34;&lt;/span> | jq
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;APIResourceList&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;groupVersion&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;custom.metrics.k8s.io/v1beta1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;resources&amp;#34;&lt;/span>: &lt;span style="color:#f92672">[&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;namespaces/nginx_vts_server_requests_per_second&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;singularName&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;namespaced&amp;#34;&lt;/span>: false,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;MetricValueList&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;verbs&amp;#34;&lt;/span>: &lt;span style="color:#f92672">[&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;get&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;pods/nginx_vts_server_requests_per_second&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;singularName&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;namespaced&amp;#34;&lt;/span>: true,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;MetricValueList&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;verbs&amp;#34;&lt;/span>: &lt;span style="color:#f92672">[&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;get&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们可以看到 &lt;code>nginx_vts_server_requests_per_second&lt;/code> 指标可用。 现在，让我们检查该指标的当前值：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get --raw &lt;span style="color:#e6db74">&amp;#34;/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/nginx_vts_server_requests_per_second&amp;#34;&lt;/span> | jq .
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;MetricValueList&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;custom.metrics.k8s.io/v1beta1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>: &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;selfLink&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/%2A/nginx_vts_server_requests_per_second&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;items&amp;#34;&lt;/span>: &lt;span style="color:#f92672">[&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;describedObject&amp;#34;&lt;/span>: &lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Pod&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;namespace&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;hpa-prom-demo-755bb56f85-lvksr&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/v1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;metricName&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;nginx_vts_server_requests_per_second&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;timestamp&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2020-04-07T09:45:45Z&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;value&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;527m&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;selector&amp;#34;&lt;/span>: null
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>出现类似上面的信息就表明已经配置成功了，接下来我们部署一个针对上面的自定义指标的 HAP 资源对象，如下所示：(hpa-prome.yaml)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">autoscaling/v2beta1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">HorizontalPodAutoscaler&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">nginx-custom-hpa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">scaleTargetRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">apps/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Deployment&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">hpa-prom-demo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">minReplicas&lt;/span>: &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">maxReplicas&lt;/span>: &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metrics&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">Pods&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">pods&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metricName&lt;/span>: &lt;span style="color:#ae81ff">nginx_vts_server_requests_per_second&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">targetAverageValue&lt;/span>: &lt;span style="color:#ae81ff">10&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果请求数超过每秒 10 个，则将对应用进行扩容。直接创建上面的资源对象：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl apply -f hpa-prome.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>horizontalpodautoscaler.autoscaling/nginx-custom-hpa created
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl describe hpa nginx-custom-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: nginx-custom-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: kubectl.kubernetes.io/last-applied-configuration:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;autoscaling/v2beta1&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;HorizontalPodAutoscaler&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;annotations&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;nginx-custom-hpa&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;namespace&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;d...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">CreationTimestamp: Tue, 07 Apr 2020 17:54:55 +0800
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Reference: Deployment/hpa-prom-demo
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Metrics: ( current / target )
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>nginx_vts_server_requests_per_second&lt;span style="color:#e6db74">&amp;#34; on pods: &amp;lt;unknown&amp;gt; / 10
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Min replicas: 2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Max replicas: 5
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Deployment pods: 1 current / 2 desired
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Conditions:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Type Status Reason Message
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ---- ------ ------ -------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> AbleToScale True SucceededRescale the HPA controller was able to update the target scale to 2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Events:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Type Reason Age From Message
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ---- ------ ---- ---- -------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Normal SuccessfulRescale 7s horizontal-pod-autoscaler New size: 2; reason: Current number of replicas below Spec.MinReplicas
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到 HPA 对象已经生效了，会应用最小的副本数 2，所以会新增一个 Pod 副本：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get pods -l app&lt;span style="color:#f92672">=&lt;/span>nginx-server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-prom-demo-755bb56f85-s5dzf 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 67s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hpa-prom-demo-755bb56f85-wbpfr 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 3m30s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>接下来我们同样对应用进行压测：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ &lt;span style="color:#66d9ef">while&lt;/span> true; &lt;span style="color:#66d9ef">do&lt;/span> wget -q -O- http://k8s.qikqiak.com:32408; &lt;span style="color:#66d9ef">done&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>打开另外一个终端观察 HPA 对象的变化：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl get hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nginx-custom-hpa Deployment/hpa-prom-demo 14239m/10 &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> 4m27s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ kubectl describe hpa nginx-custom-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: nginx-custom-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: kubectl.kubernetes.io/last-applied-configuration:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;autoscaling/v2beta1&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;HorizontalPodAutoscaler&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;annotations&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;nginx-custom-hpa&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;namespace&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;d...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">CreationTimestamp: Tue, 07 Apr 2020 17:54:55 +0800
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Reference: Deployment/hpa-prom-demo
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Metrics: ( current / target )
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>nginx_vts_server_requests_per_second&lt;span style="color:#e6db74">&amp;#34; on pods: 14308m / 10
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Min replicas: 2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Max replicas: 5
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Deployment pods: 3 current / 3 desired
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Conditions:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Type Status Reason Message
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ---- ------ ------ -------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> AbleToScale True ReadyForNewScale recommended size matches current size
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from pods metric nginx_vts_server_requests_per_second
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ScalingLimited False DesiredWithinRange the desired count is within the acceptable range
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Events:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Type Reason Age From Message
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ---- ------ ---- ---- -------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Normal SuccessfulRescale 5m2s horizontal-pod-autoscaler New size: 2; reason: Current number of replicas below Spec.MinReplicas
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Normal SuccessfulRescale 61s horizontal-pod-autoscaler New size: 3; reason: pods metric nginx_vts_server_requests_per_second above target
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到指标 &lt;code>nginx_vts_server_requests_per_second&lt;/code> 的数据已经超过阈值了，触发扩容动作了，副本数变成了 3，但是后续很难继续扩容了，这是因为上面我们的 &lt;code>while&lt;/code> 命令并不够快，3 个副本完全可以满足每秒不超过 10 个请求的阈值。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/kpk0nr/1616116806033-505c410e-406f-4fda-bc27-030171a8a558.png" alt="">&lt;/p>
&lt;p>nginx_vts_server_requests_per_second&lt;/p>
&lt;p>如果需要更好的进行测试，我们可以使用一些压测工具，比如 ab、fortio 等工具。当我们中断测试后，默认 5 分钟过后就会自动缩容：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl describe hpa nginx-custom-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Name: nginx-custom-hpa
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Labels: &amp;lt;none&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Annotations: kubectl.kubernetes.io/last-applied-configuration:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;autoscaling/v2beta1&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;kind&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;HorizontalPodAutoscaler&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;metadata&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;annotations&amp;#34;&lt;/span>:&lt;span style="color:#f92672">{}&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;nginx-custom-hpa&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;namespace&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;d...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">CreationTimestamp: Tue, 07 Apr 2020 17:54:55 +0800
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Reference: Deployment/hpa-prom-demo
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Metrics: ( current / target )
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>nginx_vts_server_requests_per_second&lt;span style="color:#e6db74">&amp;#34; on pods: 533m / 10
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Min replicas: 2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Max replicas: 5
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Deployment pods: 2 current / 2 desired
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Conditions:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Type Status Reason Message
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ---- ------ ------ -------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> AbleToScale True ReadyForNewScale recommended size matches current size
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from pods metric nginx_vts_server_requests_per_second
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ScalingLimited True TooFewReplicas the desired replica count is less than the minimum replica count
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Events:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Type Reason Age From Message
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> ---- ------ ---- ---- -------
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Normal SuccessfulRescale 23m horizontal-pod-autoscaler New size: 2; reason: Current number of replicas below Spec.MinReplicas
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Normal SuccessfulRescale 19m horizontal-pod-autoscaler New size: 3; reason: pods metric nginx_vts_server_requests_per_second above target
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Normal SuccessfulRescale 4m2s horizontal-pod-autoscaler New size: 2; reason: All metrics below target
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>到这里我们就完成了使用自定义的指标对应用进行自动扩缩容的操作。如果 Prometheus 安装在我们的 Kubernetes 集群之外，则只需要确保可以从集群访问到查询的端点，并在 adapter 的部署清单中对其进行更新即可。在更复杂的场景中，可以获取多个指标结合使用来制定扩展策略。&lt;/p></description></item><item><title>Docs: kubeadm 命令行工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description/></item><item><title>Docs: kubectl 命令行工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description/></item><item><title>Docs: Kubernetes 管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="telepresence">Telepresence&lt;a class="td-heading-self-link" href="#telepresence" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/telepresenceio/telepresence">GitHub 项目，telepresenceio/telepresence&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/FhpgIqqbJeeGNjSqzMdP8Q">公众号-马哥 Linux 运维，K8S 运维开发调试神器 Telepresence 实践及踩坑记&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote></description></item><item><title>Docs: Kubernetes 监控</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/</guid><description/></item><item><title>Docs: Kubernetes 日志</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E6%97%A5%E5%BF%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E6%97%A5%E5%BF%97/</guid><description/></item><item><title>Docs: Quota(配额)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Quota%E9%85%8D%E9%A2%9D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/Quota%E9%85%8D%E9%A2%9D/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/policy/limit-range/">官方文档,概念-策略-LimitRange&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">官方文档,概念-策略-ResourceQuotas&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="namespace-中的资源配额">namespace 中的资源配额&lt;a class="td-heading-self-link" href="#namespace-%e4%b8%ad%e7%9a%84%e8%b5%84%e6%ba%90%e9%85%8d%e9%a2%9d" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>官方文档：&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/">https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/&lt;/a>&lt;/p>
&lt;p>当多个团队或者用户共用同一个集群的时候难免会有资源竞争的情况发生，这时候就需要对不同团队或用户的资源使用配额做出限制。比如，不同团队使用不同的 namespace，然后给该 namespace 进行资源限制即可&lt;/p>
&lt;p>目前有两种 k8s 对象分配管理相关的控制策略&lt;/p>
&lt;h2 id="limitrange限制范围">LimitRange(限制范围)&lt;a class="td-heading-self-link" href="#limitrange%e9%99%90%e5%88%b6%e8%8c%83%e5%9b%b4" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>设定 pod 等对象的默认资源消耗以及可以消耗的资源范围&lt;/p>
&lt;p>官方文档：&lt;/p>
&lt;ul>
&lt;li>概念：&lt;a href="https://kubernetes.io/docs/concepts/policy/limit-range/">https://kubernetes.io/docs/concepts/policy/limit-range/&lt;/a>&lt;/li>
&lt;li>用法：
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/">https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/">https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/">https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/">https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/&lt;/a>&lt;/li>
&lt;li>&amp;hellip;..等等&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="resourcequota资源配额">ResourceQuota(资源配额)&lt;a class="td-heading-self-link" href="#resourcequota%e8%b5%84%e6%ba%90%e9%85%8d%e9%a2%9d" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>基于 namespace，限制该 namesapce 下的总体资源的创建和消耗&lt;/p>
&lt;p>官方文档：&lt;/p>
&lt;ul>
&lt;li>概念：&lt;a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">https://kubernetes.io/docs/concepts/policy/resource-quotas/&lt;/a>&lt;/li>
&lt;li>用法：
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/">https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-pod-namespace/">https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-pod-namespace/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/quota-api-object/">https://kubernetes.io/docs/tasks/administer-cluster/quota-api-object/&lt;/a> # 为指定的 API 对象设置 resourceQuota&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>资源配额分为三种类型：&lt;/p>
&lt;ul>
&lt;li>计算资源配额&lt;/li>
&lt;li>存储资源配额&lt;/li>
&lt;li>对象数量配额&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结&lt;a class="td-heading-self-link" href="#%e6%80%bb%e7%bb%93" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>仅设置 ResourceQuota 时，如果不再 pod 上设置资源的需求和限制，则无法成功创建 pod，需要配合 LimitRange 设置 pod 的默认需求和限制，才可成功创建 pod&lt;/li>
&lt;li>两种控制策略的作用范围都是对于某一 namespace
&lt;ul>
&lt;li>ResourceQuota 用来限制 namespace 中所有的 Pod 占用的总的资源 request 和 limit&lt;/li>
&lt;li>LimitRange 是用来设置 namespace 中 Pod 的默认的资源 request 和 limit 值，还有，Pod 的可用资源的 request 和 limit 值的最大与最小值。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="简单的应用示例">简单的应用示例&lt;a class="td-heading-self-link" href="#%e7%ae%80%e5%8d%95%e7%9a%84%e5%ba%94%e7%94%a8%e7%a4%ba%e4%be%8b" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Note：polinux/stress 这是一个非常好用的压测容器，可以对容器指定其所使用的内存和 cpu 等资源的大小。当创建完资源配合等资源限制的对象后，可以通过该容器来测试资源限制是否生效。&lt;/p>
&lt;h2 id="配置计算资源配额">配置计算资源配额&lt;a class="td-heading-self-link" href="#%e9%85%8d%e7%bd%ae%e8%ae%a1%e7%ae%97%e8%b5%84%e6%ba%90%e9%85%8d%e9%a2%9d" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>为 test 名称空间分配了如下配合，最多能建立 2 个 pod，最多 request 的 cpu 数量为 2 个，内存为 10G，最多 limit 的 cpu 数量为 4 个，内存为 20G&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ResourceQuota&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">compute-resources&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">hard&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">pods&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests.cpu&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests.memory&lt;/span>: &lt;span style="color:#ae81ff">10Gi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">limits.cpu&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;4&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">limits.memory&lt;/span>: &lt;span style="color:#ae81ff">20Gi&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="配置-api-对象数量限制">配置 API 对象数量限制&lt;a class="td-heading-self-link" href="#%e9%85%8d%e7%bd%ae-api-%e5%af%b9%e8%b1%a1%e6%95%b0%e9%87%8f%e9%99%90%e5%88%b6" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ResourceQuota&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">object-counts&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">hard&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configmaps&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">persistentvolumeclaims&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;4&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">replicationcontrollers&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">secrets&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;10&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">services&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;10&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">services.loadbalancers&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="配置-cpu-和内存-limitrange">配置 CPU 和内存 LimitRange&lt;a class="td-heading-self-link" href="#%e9%85%8d%e7%bd%ae-cpu-%e5%92%8c%e5%86%85%e5%ad%98-limitrange" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>test 名称空间下的 pod 启动后，默认 request 的 cpu 为 0.5，内存为 256M，默认 limit 的 cpu 为 1，内存为 512M&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">LimitRange&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">limit-range&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">test&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">limits&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">default&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">memory&lt;/span>: &lt;span style="color:#ae81ff">512Mi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">cpu&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">defaultRequest&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">memory&lt;/span>: &lt;span style="color:#ae81ff">256Mi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">cpu&lt;/span>: &lt;span style="color:#ae81ff">0.5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">type&lt;/span>: &lt;span style="color:#ae81ff">Container&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note:&lt;/p>
&lt;ul>
&lt;li>default 即 limit 的值&lt;/li>
&lt;li>defaultRequest 即 request 的值&lt;/li>
&lt;/ul>
&lt;p>在 limits 字段下还有其他的可用字段如下：&lt;/p>
&lt;ul>
&lt;li>max 代表 limit 的最大值&lt;/li>
&lt;li>min 代表 request 的最小值&lt;/li>
&lt;li>maxLimitRequestRatio 代表 limit / request 的最大值。由于节点是根据 pod request 调度资源，可以做到节点超卖，maxLimitRequestRatio 代表 pod 最大超卖比例。&lt;/li>
&lt;/ul></description></item><item><title>Docs: 好用的镜像-有特殊功能</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/%E5%A5%BD%E7%94%A8%E7%9A%84%E9%95%9C%E5%83%8F-%E6%9C%89%E7%89%B9%E6%AE%8A%E5%8A%9F%E8%83%BD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/%E5%A5%BD%E7%94%A8%E7%9A%84%E9%95%9C%E5%83%8F-%E6%9C%89%E7%89%B9%E6%AE%8A%E5%8A%9F%E8%83%BD/</guid><description>
&lt;p>node-shell&lt;/p>
&lt;p>可以通过 exec 像 ssh 一样控制节点的镜像，好像是 &lt;a href="https://github.com/kvaps/kubectl-node-shell">https://github.com/kvaps/kubectl-node-shell&lt;/a> 这个？待确认&lt;/p>
&lt;p>polinux/stress&lt;/p>
&lt;p>一个非常好用的压测容器，可以对容器指定其所使用的内存和 cpu 等资源的大小。当创建完资源配合等资源限制的对象后，可以通过该容器来测试资源限制是否生效。&lt;/p>
&lt;p>containous/whoami&lt;/p>
&lt;p>一个 go 语言编写的 web 服务器，当请求该容器时，可以输出操作系统信息和 HTTP 请求等，信息如下所示：包括当前容器的 ip 地址，容器的主机名等等&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">Hostname&lt;/span>: &lt;span style="color:#ae81ff">whoami-bd6b677dc-7tq7h&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">IP&lt;/span>: &lt;span style="color:#ae81ff">127.0.0.1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">IP&lt;/span>: &lt;span style="color:#ae81ff">10.252.131.122&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">RemoteAddr&lt;/span>: &lt;span style="color:#ae81ff">127.0.0.1&lt;/span>:&lt;span style="color:#ae81ff">35358&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">GET /notls HTTP/1.1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">Host&lt;/span>: &lt;span style="color:#ae81ff">10.10.9.51&lt;/span>:&lt;span style="color:#ae81ff">30272&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">User-Agent&lt;/span>: &lt;span style="color:#ae81ff">curl/7.29.0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">Accept&lt;/span>: &lt;span style="color:#75715e">*/*&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">Accept-Encoding&lt;/span>: &lt;span style="color:#ae81ff">gzip&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">X-Forwarded-For&lt;/span>: &lt;span style="color:#ae81ff">10.10.9.51&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">X-Forwarded-Host&lt;/span>: &lt;span style="color:#ae81ff">10.10.9.51&lt;/span>:&lt;span style="color:#ae81ff">30272&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">X-Forwarded-Port&lt;/span>: &lt;span style="color:#ae81ff">30272&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">X-Forwarded-Proto&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">X-Forwarded-Server&lt;/span>: &lt;span style="color:#ae81ff">traefik-6fbbb464b5-mcq99&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">X-Real-Ip&lt;/span>: &lt;span style="color:#ae81ff">10.10.9.51&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="kiwigridk8s-sidecar">kiwigrid/k8s-sidecar&lt;a class="td-heading-self-link" href="#kiwigridk8s-sidecar" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>参考：&lt;a href="https://github.com/kiwigrid/k8s-sidecar">GitHub 项目&lt;/a>&lt;/p>
&lt;p>该容器会持续监听指定的 configmap 和 secret 资源，当 configmap 或 secret 对象被创建或更新时，会将该对象内的数据，转换成文件，并保存在容器内指定的路径中。&lt;/p>
&lt;p>这个&lt;strong>镜像常常作为 sidecar 容器使用&lt;/strong>，与主容器共享相同目录，这样，主程序就可以实时读取到新创建的 configmap 或 secret&lt;/p>
&lt;p>比如，该容器可以与 Grafana 一起使用，用来为 Grafana 实时提供 provisioning 功能的 dashboard。kiwigrid/k8s-sidecar 容器与 Grafana 容器 首先挂载相同的目录。此时，我们可以为每个 dashboard 都创建一个 configmap，然后带上 kiwigrid/k8s-sidecar 容器所需的标签。这样每当创建或修改一个仪表盘时， kiwigrid/k8s-sidecar 容器就会将 configmap 变为文件，并保存到与 Grafana 相同挂载的目录，此时，Grafana 的 provisioning 功能定时扫描该目录时，就会加载到相关的仪表盘&lt;/p></description></item><item><title>Docs: 重大变化</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/2.3.Kubernetes-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F/Kubernetes-%E7%AE%A1%E7%90%86/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/</guid><description/></item></channel></rss>