<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>🤖12.AI on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/12.AI/</link><description>Recent content in 🤖12.AI on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/index.xml" rel="self" type="application/rss+xml"/><item><title>12.AI</title><link>https://desistdaydream.github.io/docs/12.AI/12.AI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/12.AI/</guid><description>概述 参考：
Wiki, Artificial_intelligence Artificial intelligence(人工智能，简称 AI) 是机器所展示的智能，与人类和其他动物的智能相对应。AI 通常包含语音识别、计算机视觉、自然语言处理、以及其他输入的映射
随着机器的能力越来越强，被认为需要“智能”的任务通常从 AI 的定义中删除，这种现象被称为 AI 效应。例如，OCR 经常被排除在被认为是人工智能的事物之外，已成为一项常规技术。
TODO,名词解释：
拟合 回归 Embedding 凸优化 AI 好像不等于机器。。不像机器精确执行 01 指令。。AI 的本质好像是数学，并且是数学中的统计学，AI 的每一次判断都是一次概率统计然后输出概率大的内容。
TODO: 本质上是将 数学问题转为数值计算问题？因为机器不认识加减乘除这些符号，但是又要训练机器学会这些，那么机器就要学会 101 如何变成 111 这类？
人工智能发展阶段 https://zhuanlan.zhihu.com/p/24811027
运算智能、感知智能、认知智能
一是运算智能，即快速计算和记忆存储能力。人工智能所涉及的各项技术的发展是不均衡的。现阶段计算机比较具有优势的是运算能力和存储能力。1996 年 IBM 的深蓝计算机战胜了当时的国际象棋冠军卡斯帕罗夫，从此，人类在这样的强运算型的比赛方面就不能战胜机器了。
二是感知智能，即视觉、听觉、触觉等感知能力。人和动物都具备，能够通过各种智能感知能力与自然界进行交互。自动驾驶汽车，就是通过激光雷达等感知设备和人工智能算法，实现这样的感知智能的。机器在感知世界方面，比人类还有优势。人类都是被动感知的，但是机器可以主动感知，如：激光雷达、微波雷达和红外雷达。不管是 Big Dog 这样的感知机器人，还是自动驾驶汽车，因为充分利用了 DNN 和大数据的成果，机器在感知智能方面已越来越接近于人类。
早期的计算机视觉属于感知智能，只能认识图片，而无法知道图片中所表达的意思。 三是认知智能。通俗讲是“能理解会思考”。人类有语言，才有概念，才有推理，所以概念、意识、观念等都是人类认知智能的表现。典型的自然语言处理，就需要认知智能。
第一层是语言理解 第二层是分析、推理 第三层是人格和情感 技术脉络关系 个人总结：
如果人工智能的本质是数学计算，那么首先出现的是辅助计算的工具，比如 NumPy、Torch，然后利用这些计算能力，发展出让机器学习的工具，TensorFlow、PyTorch 等，最后通过机器学习，训练出来可用的各种基本模型，比如 Transformer。
NumPy、Torch 提供计算能力 TensorFlow、PyTorch 依赖计算能力实现的用于机器学习的框架 Transformer 使用学习框架生成模型，Transformer 一般是指一个过程、工具集，而不是单指一种模型，很多模型是通过 Transformer 工具使用或训练。 机器学习 机器学习源于对 AI 的探索。在人工智能作为一门学科的早期，一些研究人员对让机器从数据中学习很感兴趣。他们试图用各种符号方法以及当时称为“神经网络”的方法来解决这个问题。</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/12.AI/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Glossary/</guid><description>概述 参考：
B 站，一口气通关大模型的 100 个关键词 Synmbolism(符号主义)
Connectionism(联结主义)
Model(模型) # 函数
Weight(权重) # 函数里的参数
Large Model(大模型) # 参数量特别大的模型
Training(训练) # 调整模型参数的过程
Pre-training(预训练) # “事先训练”好一个基础模型的方式
Fine-tuning(微调) # 基于预训练的模型“继续训练”，让模型学会具体的任务的方式
Inference(推理) # 参数调整好后，根据函数的输入计算输出结果这个过程
Emergence(涌现) # 量变引起质变，而突然出现的以前没有的能力的现象
Generative Pre-trained Transformer(生成式预训练变换器，简称 GPT)
训练过程 权重 Closed-source Model 闭源模型 × × Open-weight Model 开放权重模型 × √ Open-source Model 开源模型 √ √ Generative AI(生成式 AI) #
Token # 不适合翻译成中文，一种抽象的概念，用来表示某种事物，所以类似代币的感觉
Context(上下文)
Prompt(提示词)
Randomness(随机性)
Temperature(温度) # 控制输出的随机性
Top-K # 控制选择范围中最高的</description></item><item><title>Hugging Face</title><link>https://desistdaydream.github.io/docs/12.AI/Hugging-Face/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Hugging-Face/</guid><description>概述 参考：
GitHub 组织，huggingface 官网 Wiki, Hugging_Face 知乎，Huggingface 超详细介绍 Hugging Face 即是一个工具包的集合，也是一个社区。
在 2017 年在 GitHub 上开源了非常著名的 Transformers 库。 在 2019 年推出了 Hugging Face Hub，一个用于共享和加载预训练模型和数据集的平台 后续也陆续开发了其他的工具包，例如 tokenizers、datasets、huggingface_hub、accelerate和peft，以及一个公共的推理API，为机器学习开发者提供了更多的便利和资源。 它提供了多种工具包，例如：
transformers：一个用于构建和使用预训练语言模型的 Python 库，支持 PyTorch 和 TensorFlow。 tokenizers：一个用于快速和高效地创建和使用词法分析器的 Python 库。 datasets：一个用于轻松共享和加载数据集和评估指标的 Python 库。 huggingface_hub：一个用于创建、删除、更新和检索仓库信息的 Python 库，也可以从仓库下载文件或将它们集成到你的库中。 accelerate：一个用于轻松地训练和使用 PyTorch 模型的 Python 库，支持多 GPU、TPU 和混合精度。 peft：一个用于实现参数高效微调（PEFT）方法的 Python 库，可以有效地将预训练语言模型（PLMs）适应于各种下游应用，而无需微调所有模型参数6。 使用 Hugging Face 可以帮助我们在 NLP 领域进行创新和探索。
Hugging face 起初是一家总部位于纽约的聊天机器人初创服务商，他们本来打算创业做聊天机器人，然后在github上开源了一个Transformers库，虽然聊天机器人业务没搞起来，但是他们的这个库在机器学习社区迅速大火起来。目前已经共享了超100,000个预训练模型，10,000个数据集，变成了机器学习界的github。
最佳实践 Hugging Face下载大模型的相关文件说明
如何理解仓库中的模型文件
在Hugging Face的模型存储库中，这些文件通常用于表示预训练模型及其相关配置、模型权重、词汇表和分词器等。下面是这些文件的一般作用：
.gitignore ：是一个纯文本文件，包含了项目中所有指定的文件和文件夹的列表，这些文件和文件夹是Git应该忽略和不追踪的 MODEL_LICENSE：模型商用许可文件 REDAME.</description></item><item><title>MCP</title><link>https://desistdaydream.github.io/docs/12.AI/MCP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/MCP/</guid><description>概述 参考：
GitHub 组织，modelcontextprotocol 官网 Model Context Protocol(模型上下文协议，简称 MCP) 是一种开放协议，能够实现 LLM 应用程序与外部数据源和工具之间的无缝集成。无论是在构建 AI 驱动的 IDE、增强聊天界面，还是创建自定义 AI 工作流，MCP 都提供了一种标准化的方式，将 LLM 连接到所需的上下文。
规范 参考：
规范 架构 https://modelcontextprotocol.io/specification/2025-03-26/architecture
MCP 的工程化实现本质也是一个类似 C/S 的架构，但是在其中多了 Model(模型) 的参与。一套完整的 MCP 系统通常包含如下几类组件：
Tips: 有些模型进行了 MCP 的训练，可以正常识别 MCP 的上下文内容，并且也可以返回 MCP 标准的上下文
Host(主持人) # 充当内容的容器和协调器。创建和管理多个 MCP Client 实例。协调 AI/LLM 集成和采样。管理跨客户端的上下文聚合。 类似 Web 中的 User Agent 概念。 MCP Client # 由 Host 创建并维护。与 MCP Server 建立 1:1 的连接关系。 MCP Server # 通过 MCP 原语公开 Resources, Tools, Prompts，提供后端程序的功能，用于与 MCP Client 通信。 类似各种可以提供 API 的 Web 应用程序。只不过使用了 MCP 协议包装了 API 或其他各种功能。 MCP Server 可以是多种形态，并不只局限于是监听了 TCP 的进程。甚至可以是一个本地文件系统上独立的 py 文件或二进制文件，只在使用时，由 MCP Client 直接使用以从标准输入和输出中进行交互。 Model # AI 模型。为问题提供 分析、总结 能力。 一套完整的 MCP 系统的运行过程通常如下所述：</description></item><item><title>Retrieval</title><link>https://desistdaydream.github.io/docs/12.AI/Retrieval/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Retrieval/</guid><description>概述 参考：
RAG 参考：
Wiki, # Retrieval-augmented generation B 站，AI知识库RAG技术原理，三大痛点与进阶方案【不用编程】 Retrieval-augmented generation(检索增强生成，简称 RAG) 是一种使 12.AI 模型能够检索信息的技术。它修改了与 LLM 的交互，使模型能够参考指定的一组文档来响应用户的查询，并使用这些信息来补充其预先存在训练数据中的信息。
用户把资料添加进知识库的时候，程序会先把它们拆分成很多个文本块，然后使用嵌入模型对这些文本块进行向量化（向量化指的是把切拆分后的文本），变成一个超长的数字序列。然后程序把向量以及对应的文本保存在向量数据库里面。
接下来用户开始提问，不过这个提问并非直接送达到大模型那里，而是把其本身也经过向量化处理，先变成一个1024维的向量。然后把用户的提问与向量数据库进行相似度匹配，这个匹配过程是基于向量的纯数学运算，最后知识库选出匹配度最高的几个原文片段，再加上用户的问题发给大模型，大模型进行最后的归纳总结
存在问题：
切片很粗暴 检索不精准 # 搜索知识库时，只能找到切片，无法将搜索内容与全文进行上下文管理，只有部分切片。最后会 AI 拿到的内容是不足的，导致结果不精准。 没有大局观 重排序模型，可以把向量数据库初步检索出来的数据，使用专用的重排序模型进行更深入的语义分析。然后再按照问题的相关性进行重新的排序，把相关性最大的一些数据排到前面并且交付给大模型。这是一种先粗后细的两步检索策略，可以进一步提高检索精度
使用超长上下文，避免切片太碎，但是。。。。资源消耗非常非常高。。。。</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
AI是如何作画和修复老电影的？10分钟还你一个4K的青春。【AI原理解析系列】
为什么需要 AI ？跟传统搜索有什么区别？
比如想要搜索如下问题：
玩 XXX 游戏的时候，在游戏中正常，但是切出游戏使用其他程序时 CPU 使用率直接到 100%，再切回游戏又正常了 如果是传统搜索引擎，需要我们自己有一定基础，然后提炼其中的关键字，再从搜索结果中，逐步筛选想要的结果，但是用 AI 的话，直接把问题抛给 AI，AI 来处理，并对搜索到的结果进行总结
提示语 参考：
GitHub 项目，f/awesome-chatgpt-prompts GitHub 项目，PlexPt/awesome-chatgpt-prompts-zh 公众号-云原生小白，你应该知道的ChatGPT提示语 ChatGPT 对话中提示语可以极大影响对话质量。定义明确的提示语可以帮助确保我们的对话保持在正确的方向上。并涵盖用户感兴趣的上下文信息，从而带来较好的用户体验。
那么，什么是好的 ChatGPT 提示语，以及我们如何制作有效的提示语？有几个关键原则需要记住。
明确性。清晰简洁的提示将有助于确保 ChatGPT 理解当前的对话主题。避免使用过于复杂或模棱两可的语言。 重点。一个明确的提示语应该有明确的目的和重点，避免使用过于宽泛或开放式的提示，这可能会导致对话不连贯或方向失控。 相关性。确保你的提示语与当前对话相关。避免引入不相关的话题或切入点分散ChatGPT 的焦点 遵循这些原则，我们就可以制作有效的 ChatGPT 提示语。并以此推动产生一个富有吸引力和质量上层的对话体验。
案例分析 为了更好的理解 ChatGPT 提示语，我们来看看一些非常成功的案例
英语翻译和改进者 下面我让你来充当翻译家，你的目标是把任何语言翻译成中文，请翻译时不要带翻译腔，而是要翻译得自然、流畅和地道，使用优美和高雅的表达方式。请翻译下面这句话：“how are you ?”
担任面试官 我想让你充当面试官。我将是候选人，你将向我提出该职位的面试问题。我希望你只以面试官的身份回答。不要一下子写出所有的问题。我希望你只对我进行面试。问我问题，并等待我的回答。不要写解释。像面试官那样一个一个地问我问题，并等待我的回答。我的第一句话是 &amp;ldquo;你好面试官&amp;rdquo;
在这个例子中，ChatGPT 被当做面试官，它需要先提出问题并等待用户回答。这个提示是非常具体的和有针对性的概述让 ChatGPT 进行人物角色扮演，和对对话场景的模拟。
旅游指南 我想让你充当一个旅游向导。我将给你写下我的位置，你将为我的位置附近的一个地方提供旅游建议。在某些情况下，我也会告诉你我要访问的地方的类型。你也会向我推荐与我的第一个地点相近的类似类型的地方。我的第一 个建议请求是&amp;quot;我在成都，我只想看大熊猫&amp;quot;
在这个例子中，ChatGPT 被用作旅游指南，根据具体地点和地方类型提供参观建议。该提示语也是具有有针对性的，清楚地概述了对当前对话的期望。
作为专业DBA 贡献者：墨娘
我要你扮演一个专业DBA。我将提供给你数据表结构以及我的需求，你的目标是告知我性能最优的可执行的SQL语句，并尽可能的向我解释这段SQL语句，如果有更好的优化建议也可以提出来。
我的数据表结构为:
CREATE TABLE user ( id int NOT NULL AUTO_INCREMENT, name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT &amp;rsquo;&amp;rsquo; COMMENT &amp;lsquo;名字&amp;rsquo;, PRIMARY KEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT=&amp;lsquo;用户表&amp;rsquo;;</description></item></channel></rss>