<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – 机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 机器学习 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning">Wiki, Machine_learning&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Data_mining">Wiki, Data mining&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Machine learning(机器学习，简称 ML)&lt;/strong> 是一个致力于理解和构建让机器“学习”的方法的领域 - 就是利用数据提高计算机在某些任务上性能的方法。&lt;/p>
&lt;p>就像人需要学习一样，机器也需要学习。机器学习是&lt;a href="https://desistdaydream.github.io/docs/12.AI/12.AI.md">人工智能&lt;/a>的一个广泛子领域。&lt;/p>
&lt;p>机器学习通常需要一个模型和训练模型的方法，通过训练好的模型，可以更准确得预测或分类新的未见过的数据。e.g. 自然语言处理中，当我们向模型提交输入的文字后，模型会根据参数，逐步预测将要输出的每一个文字，每个文字都是由模型根据训练好的参数，依据统计学的百分比概率推导出来的。&lt;/p>
&lt;p>我们人类好像也是通过这种方式沟通的，每个字都在脑子中依据已有知识，推理出来后，逐一说出来。&lt;/p>
&lt;p>TODO: 这都是啥？&lt;/p>
&lt;ul>
&lt;li>Convolutional Neural Network(卷积神经网络简称 CNN)&lt;/li>
&lt;li>Transformer(变压器)&lt;/li>
&lt;li>Generative Adversarial Network(对抗网络模型，简称 GAN)&lt;/li>
&lt;/ul>
&lt;p>TODO: &lt;strong>Data mining(数据挖掘)&lt;/strong>&lt;/p>
&lt;h1 id="学习方法">学习方法&lt;a class="td-heading-self-link" href="#%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Approaches">https://en.wikipedia.org/wiki/Machine_learning#Approaches&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Supervised_learning">Wiki, Supervised learning&lt;/a> 监督学习&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Wiki, Unsupervised learning&lt;/a> 无监督学习&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;ul>
&lt;li>Supervised learning(监督学习)&lt;/li>
&lt;li>Unsupervised learning(无监督学习)&lt;/li>
&lt;li>Reinforcement learning(强化学习)&lt;/li>
&lt;li>etc.&lt;/li>
&lt;/ul>
&lt;p>Claude 交流：&lt;/p>
&lt;p>问：AI 领域，监督学习和无监督学习的区别是是否使用训练集么？&lt;/p>
&lt;p>答：（多次问答后的个人总结）&lt;/p>
&lt;p>不完全正确。让我来解释监督学习和无监督学习的主要区别:&lt;/p>
&lt;p>监督学习和无监督学习的核心区别在于&lt;strong>训练数据是否有标签&lt;/strong>，而不是是否使用训练集。两种方法都需要使用训练数据。&lt;/p>
&lt;p>监督学习:&lt;/p>
&lt;ul>
&lt;li>训练数据包含输入特征和对应的标签/答案&lt;/li>
&lt;li>例如:图片分类中,每张图片都标注了&amp;quot;猫&amp;quot;或&amp;quot;狗&amp;quot;&lt;/li>
&lt;li>算法目标是学习输入到标签的映射关系&lt;/li>
&lt;li>常见应用：分类、回归预测&lt;/li>
&lt;li>最终目标是：给一张新图片,能准确判断是猫还是狗&lt;/li>
&lt;/ul>
&lt;p>无监督学习:&lt;/p>
&lt;ul>
&lt;li>训练数据只有输入特征，没有标签，训练数据是 1000 张动物图片，但没有任何标注&lt;/li>
&lt;li>模型会基于图片的相似度(如颜色分布、形状特征等)自动分组&lt;/li>
&lt;li>最终可能会将图片分成几类:
&lt;ul>
&lt;li>一类都是毛茸茸、有尖耳朵的(实际上是猫)&lt;/li>
&lt;li>一类都是体型较大、有长嘴的(实际上是狗)&lt;/li>
&lt;li>但模型并不知道这些类别的具体含义&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>算法目标是发现数据中的内在结构和模式&lt;/li>
&lt;li>常见应用：聚类分析、降维、异常检测&lt;/li>
&lt;li>最终目标是：给一张新图片，能够判断它与哪组已有图片最相似，将它自动归类到相应的组别中&lt;/li>
&lt;/ul>
&lt;p>简单来说:&lt;/p>
&lt;ul>
&lt;li>监督学习像是有老师指导的学习，告诉你答案是什么，需要自己&lt;strong>总结&lt;/strong>数据中的规律&lt;/li>
&lt;li>无监督学习像是自学，需要自己&lt;strong>发现&lt;/strong>数据中的规律&lt;/li>
&lt;/ul>
&lt;h1 id="模型">模型&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>机器学习 通常包含 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Model.md">Model&lt;/a>(模型) 的训练&lt;/p>
&lt;p>模型通常可以应用于 1 种或多种 Tasks(任务)。&lt;/p>
&lt;h1 id="任务">任务&lt;a class="td-heading-self-link" href="#%e4%bb%bb%e5%8a%a1" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>Tasks(任务)&lt;/strong> 通常是指一种具体的 AI 应用场景，比如 计算机视觉 的 目标检测、自然语言处理 的 情感分析、etc. 这些都属于 Task。有的地方将 Tasks 称为 Sub-domains(子领域)&lt;/p>
&lt;p>Claude 问题: 常见的 AI 任务有哪些？&lt;/p>
&lt;p>回答:&lt;/p>
&lt;p>以下是一些常见的AI任务:&lt;/p>
&lt;ul>
&lt;li>自然语言处理
&lt;ul>
&lt;li>文本分类&lt;/li>
&lt;li>情感分析&lt;/li>
&lt;li>机器翻译&lt;/li>
&lt;li>问答系统&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>计算机视觉
&lt;ul>
&lt;li>图像分类&lt;/li>
&lt;li>目标检测&lt;/li>
&lt;li>人脸识别&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>语音技术
&lt;ul>
&lt;li>语音识别&lt;/li>
&lt;li>语音合成&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>推荐系统&lt;/li>
&lt;li>预测分析&lt;/li>
&lt;li>自动驾驶&lt;/li>
&lt;li>游戏AI&lt;/li>
&lt;li>异常检测&lt;/li>
&lt;li>机器人控制&lt;/li>
&lt;/ul>
&lt;p>这些只是AI应用的一部分。AI技术正在不断发展,应用领域也在持续扩大。您对其中哪个领域特别感兴趣?我可以提供更多相关信息。&lt;/p></description></item><item><title>Docs: Model</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Model/</link><pubDate>Tue, 16 Jan 2024 22:39:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Model/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Models">Wiki, Machine_learning - Models&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">Wiki, Hyperparameter&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>执行机器学习涉及创建 &lt;strong>Model(模型)&lt;/strong>，这个模型狭义上指&lt;a href="https://en.wikipedia.org/wiki/Mathematical_model">数学模型&lt;/a>中的&lt;a href="https://en.wikipedia.org/wiki/Statistical_model">统计模型&lt;/a>，是一种数学表示，用于描述和解决特定类型的问题。这些模型可以是各种各样的，包括传统的统计学模型，如线性回归和逻辑回归，也可以是基于神经网络的深度学习模型，如卷积神经网络和循环神经网络。&lt;/p>
&lt;p>模型通常由 &lt;strong>数学公式&lt;/strong>、&lt;strong>超参数&lt;/strong>、&lt;strong>参数&lt;/strong> 组成，可以根据给定的输入数据进行训练和调整，以使它们能够在未见过的数据上进行准确预测或分类。因此，AI 领域中的模型本质上是一种数学模型，通过使用数学方法来处理和分析数据，以解决各种问题，如分类、预测、图像处理、自然语言处理等。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>数学公式&lt;/strong> # 模型的结构通常用数学公式表示，e.g. 线性变换、激活函数、etc. 。e.g. 线性层的计算: $y = Wx + b$ ，其中 W 是权重矩阵，x 是输入向量，b 是偏置。&lt;/li>
&lt;li>&lt;strong>Hyperparameter(超参数)&lt;/strong> # 训练和模型架构设置中手动配置的参数，影响模型的性能和训练过程。常见的超参数包括：学习率、批量大小、网络层数和每层的神经元数量、激活函数类型、训练轮数、etc. 。而其他参数（例如节点权重）的值是通过训练得出的。&lt;/li>
&lt;li>&lt;strong>Parameters(参数)&lt;/strong> # 模型训练过程中学习到的一系列数值，e.g. &lt;strong>权重&lt;/strong>、etc. 。它们决定了输入数据如何影响模型的输出。&lt;/li>
&lt;/ul>
&lt;p>模型需要训练，训练后得到的模型文件是一系列的权值（权重值），通常是大量(上亿)个浮点数，如果进行了&lt;strong>模型量化&lt;/strong>，也可以是整数。&lt;/p>
&lt;h2 id="创建模型">创建模型&lt;a class="td-heading-self-link" href="#%e5%88%9b%e5%bb%ba%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>想要创建一个可用的模型，通常至少需要如下几步：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定义模型结构&lt;/strong> # 选择模型类型等。比如 &lt;code>nn.Linear(10, 1)&lt;/code> 定义了一个简单的全连接层。&lt;/li>
&lt;li>TODO：&lt;strong>定义损失函数和优化器&lt;/strong> # 如交叉熵损失、均方误差，以及优化算法如 SGD、Adam。
&lt;ul>
&lt;li>激活函数 # 每个神经元应用的非线性函数，用于引入非线性，使模型能够学习复杂的模式。&lt;/li>
&lt;li>损失函数 # 用于衡量模型输出与实际目标之间的差异。在训练过程中，模型会尝试最小化损失函数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>标注数据&lt;/strong> # 标注数据以生成数据集用以训练模型&lt;/li>
&lt;li>&lt;strong>训练模型&lt;/strong> # 利用数据集训练模型。通过给模型输入数据集和目标，让模型经过计算后调整自身参数（权重）。&lt;/li>
&lt;li>&lt;strong>保存模型&lt;/strong> # 在训练完毕后保存模型，以便后续测试或部署。&lt;/li>
&lt;/ul>
&lt;p>暂时先用下面的代码尝试理解一下，随着后续深入学习逐步完善：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">torch&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">nn&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 一、定义模型结构&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># Linear() 可以暂时理解为使用 Linear 模型，可以假设模型是 y = xA^T + b；&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 10, 1 可以理解为 超参数。也可以简单理解为是在训练模型以检查返回值 fc 是否满足预期&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">fc&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">nn&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Linear&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">10&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 二、定义损失函数、优化器&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 略&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 三、训练模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 注意：fc.state_dict() 并不是真正意义上的训练模型。仅是获取模型的当前参数（e.g. 权重值、etc.）这些参数可能是刚初始化的（随机值），也可能是已经训练过的。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 通常，在训练完成后调用 state_dict() 来保存模型的参数。这样可以在之后加载这些参数，继续训练或进行推理。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">fc&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">state_dict&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 四、保存模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 将训练结果 fc 保存到模型文件 hello_world.pth 中&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">torch&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">save&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">model&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;./models/hello_world.pth&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 从 hello_world.pth 模型文件中读取参数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">weight&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">torch&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">load&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;./models/hello_world.pth&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">weights_only&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">True&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 模型文件中的内容本质上是一系列权重值的集合，效果如下：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># OrderedDict({&amp;#39;weight&amp;#39;: tensor([[0.0382, -0.1313, 0.2224, -0.2967, -0.2892, -0.2951, 0.0455, -0.0702,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># -0.2919, 0.2825]]), &amp;#39;bias&amp;#39;: tensor([-0.2147])})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">print&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">weight&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>[!Note] 个人理解
nn.Linear() 就像编程体系中的汇编，是所有高级模型的基础。只不过还有很多不同点，比如 汇编没有训练的概念、etc. 。&lt;/p>
&lt;p>似乎，从这种底层逻辑看，所有模型其实都是一样的，底层只有像 Linear() 之类的简单线性层，不同点在于高级模型会用到 非常多的层数、训练方式、训练数据。&lt;/p>
&lt;/blockquote>
&lt;h1 id="training">Training&lt;a class="td-heading-self-link" href="#training" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Training_models">Wiki, Machine_learning - Training_models&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets">Wiki, raining, validation, and test data sets&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Training#Artificial-intelligence_feedback">https://en.wikipedia.org/wiki/Training#Artificial-intelligence_feedback&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://easyaitech.medium.com/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82-ai-%E6%95%B0%E6%8D%AE%E9%9B%86-%E8%AE%AD%E7%BB%83%E9%9B%86-%E9%AA%8C%E8%AF%81%E9%9B%86-%E6%B5%8B%E8%AF%95%E9%9B%86-%E9%99%84-%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-9b3afd37fd58">https://easyaitech.medium.com/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82-ai-%E6%95%B0%E6%8D%AE%E9%9B%86-%E8%AE%AD%E7%BB%83%E9%9B%86-%E9%AA%8C%E8%AF%81%E9%9B%86-%E6%B5%8B%E8%AF%95%E9%9B%86-%E9%99%84-%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-9b3afd37fd58&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Training(训练)&lt;/strong> 模型最基本需要如下几样东西&lt;/p>
&lt;ul>
&lt;li>&lt;strong>原始模型&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Hyperparameter(超参数)&lt;/strong>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset.md">Dataset&lt;/a>(数据集)&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>加载原始模型，设置超参数，将数据集的数据转为模型可以识别的数值，一遍一遍训练，最后得出一组参数。&lt;/p>
&lt;p>在开始训练之前，通常需要准备三个数据集，分别用于 训练、验证、测试：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Training datasets(训练数据集)&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Validation datasets(验证数据集)&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Test datasets(测试数据集)&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>先使用训练数据集对模型进行最初的训练生成参数；然后使用验证数据集对训练后的模型进行评估打分，调整参数纠正训练中的偏差；最后使用测试数据集对模型评估打分。&lt;/p>
&lt;p>一个模型的权重在没有训练之前通常都有一个默认值（0 - 1 的正态分布）。训练模型一般是指将数据集提供给模型后，数据将会转为一组数值，模型根据这组数值调整权重，随着一次一次的训练，模型会不断更新这些权重，直到满足最终目标。&lt;/p>
&lt;p>通过模型配套的程序，将数据集交给原始模型并训练 N epoch(周期)，最终得到可以执行特定任务的模型（识别对象、沟通、etc.）&lt;/p>
&lt;blockquote>
&lt;p>[!Tip]
不同的模型（计算机视觉、自然语言处理、etc.）训练时，可能需要一些特定于该种类模型的东西。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>TODO:&lt;/p>
&lt;p>注意日常口语化的名词 &lt;strong>调参&lt;/strong>，调的是什么参？超参？权重？还是什么？&lt;/p>
&lt;p>写好模型后，向模型中传入参数用结果与历史真实结果对比，差值越小，模型越精准？若是差值大就修改参数，直到最后差值无限接近 0 ？&lt;/p>
&lt;/blockquote>
&lt;h2 id="训练场景">训练场景&lt;a class="td-heading-self-link" href="#%e8%ae%ad%e7%bb%83%e5%9c%ba%e6%99%af" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://www.baeldung.com/cs/neural-network-pre-training">https://www.baeldung.com/cs/neural-network-pre-training&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.reddit.com/r/learnmachinelearning/comments/19f04y3/what_is_the_difference_between_pretraining/">https://www.reddit.com/r/learnmachinelearning/comments/19f04y3/what_is_the_difference_between_pretraining/&lt;/a>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Pre-training(预训练)&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Fine-tuning(微调)&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Instruct-tuning(指令调整)&lt;/strong> TODO: 是个较新得概念&lt;/li>
&lt;/ul>
&lt;p>假设我们想要对一个包含猫和狗的数据集进行分类。我们开发了一个机器学习模型来完成这个分类任务。一旦训练完成，我们就将模型及其所有参数保存下来。现在假设我们有另一个任务要完成: 物体检测。我们不是从头开始训练新模型，而是在物体检测数据集上使用这个已有的模型。我们把这种方法称为预训练。&lt;/p>
&lt;p>微调是指给模型一些新的数据，比如使用标注得更精准得数据集让模型效果更好；或者使用一些新的数据集让模型认识少量新的目标。&lt;/p>
&lt;p>虽然将训练方式分成了三类，但是本质上，这三种说法其实都是训练模型&lt;/p>
&lt;h1 id="模型文件格式">模型文件格式&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e5%9e%8b%e6%96%87%e4%bb%b6%e6%a0%bc%e5%bc%8f" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>ONNX 是业界通用的格式，还有很多特定于项目的格式。&lt;/p>
&lt;p>绝大部分模型，都支持导出成 .onnx 格式。e.g. &lt;a href="docs/12.AI/AI%20Projects/Yolo.md">Yolo&lt;/a> 可以导出成 .onnx，也支持导出成用于 &lt;a href="docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch.md">PyTorch&lt;/a> 的 torchscript 格式，etc.&lt;/p>
&lt;h2 id="onnx">ONNX&lt;a class="td-heading-self-link" href="#onnx" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/onnx/onnx">GitHub 项目，onnx/onnx&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Open Neural Network Exchange (开放神经网络交换，简称：ONNX)&lt;/strong> 是一个开放的生态系统，使人工智能开发人员能够随着项目的发展选择正确的工具。 ONNX 为人工智能模型（深度学习和传统机器学习）提供开源格式。它定义了可扩展的计算图模型，以及内置运算符和标准数据类型的定义。目前我们重点关注推理（评分）所需的能力。&lt;/p>
&lt;p>人话：机器学习互操作性的开放标准，就是协议，也就是定义了模型应该用什么的方式 读/写，用什么格式存储。&lt;/p>
&lt;h1 id="模型可视化">模型可视化&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e5%9e%8b%e5%8f%af%e8%a7%86%e5%8c%96" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/lutzroeder/netron">GitHub 项目，lutzroeder/netron&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mltalks.medium.com/pytorch%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96%E7%94%BB%E5%9B%BE%E5%B7%A5%E5%85%B7%E5%90%88%E9%9B%86-%E6%96%87%E5%90%8E%E9%99%84%E4%B8%8A%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-a796ee726a87">https://mltalks.medium.com/pytorch%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96%E7%94%BB%E5%9B%BE%E5%B7%A5%E5%85%B7%E5%90%88%E9%9B%86-%E6%96%87%E5%90%8E%E9%99%84%E4%B8%8A%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-a796ee726a87&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Netron 是用于神经网络、深度学习和机器学习模型的可视化工具&lt;/p>
&lt;p>下面是 &lt;a href="https://netron.app/">https://netron.app/&lt;/a> 可视化模型的效果，可以显示模型的神经结构以及参数，每个小方框都可以惦记查看具体数据&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ai/model/202410311032939.png" alt="image.png">&lt;/p></description></item><item><title>Docs: Dataset</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>TODO: Wiki, 没有 Wiki？&lt;/li>
&lt;li>&lt;a href="https://docs.lanyingim.com/quest/40_20240615_1_73_1718389635.html">https://docs.lanyingim.com/quest/40_20240615_1_73_1718389635.html&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Datasete(数据集)&lt;/strong> 是用于 训练模型、测试模型 的一组特定数据的集合。Dataset 中通常包含两部分内容&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Unlabeled data(未标记数据)&lt;/strong> i.e. 原始数据&lt;/li>
&lt;li>&lt;strong>Labeled data(已标记数据)&lt;/strong> 也称为 Annotated data(已标注的数据)&lt;/li>
&lt;/ul>
&lt;p>通过数据标注，将 Unlabeled data 变为 Labeled data 后，将这些 Labeled data 打包成 Dataset 供模型训练。&lt;/p>
&lt;p>有时候，训练模型并需要已标记的数据，比如 无监督学习、etc. 。&lt;/p>
&lt;h1 id="data-annotation数据注释">Data annotation(数据注释)&lt;a class="td-heading-self-link" href="#data-annotation%e6%95%b0%e6%8d%ae%e6%b3%a8%e9%87%8a" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://opencv.org/blog/data-annotation/">OpenCV 博客，Data Annotation – A Beginner’s Guide&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Labeled_data">Wiki, Labeled data&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.amantyatech.com/data-annotation-and-labeling-everything-you-need-to-know">https://www.amantyatech.com/data-annotation-and-labeling-everything-you-need-to-know&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/what-is/data-labeling/">AWS，What is Data Labeling?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://toloka.ai/blog/annotation-vs-labeling/">https://toloka.ai/blog/annotation-vs-labeling/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Data annotation(数据注释)&lt;/strong> 是一组数据中的 信息 &lt;strong>Annotation(注释)/Label(标签)&lt;/strong>。这些 &lt;strong>信息注释/标签&lt;/strong> 在不同的场景下有不同的表示含义，e.g. 一张照片中哪部分是牛，哪部分是马；录音中说了哪些词；视频中正在执行什么类型的动作；新闻文章的主题是什么；推文想要表达的是一种什么情绪；X 光片中的一个点是否是肿瘤；etc. 。&lt;/p>
&lt;blockquote>
&lt;p>[!Note]
上面例子中标记照片中的牛、马通常用于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object%20detection.md">Object detection&lt;/a>(对象检测) 任务、识别音频中的问题通常用于 语音识别 任务、识别动作通常用于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose%20estimation.md">Pose estimation&lt;/a>(姿态评估) 任务、etc.&lt;/p>
&lt;/blockquote>
&lt;p>人们通过 &lt;strong>Data annotating/Data Labeling(数据标注)&lt;/strong> 行为，处理一组未标记的数据，为每一条数据添加数据注释。这些被添加了注释的数据称为 &lt;strong>Labeled data/Annotated data(已标记的数据)&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>[!Attention]
Data annotation 是非常常见的词，在口语化或各种文章中，通常有多种含义。既可以表示动作，也可以当作形容词描述一个实体，也可以作名词表示一个实体。e.g. 我执行了 Data annotation(数据标注) 行为，添加了 Data annotation(数据注释)，让这些数据变成了 Data annotation(具有注释的数据)。( ╯□╰ )&lt;/p>
&lt;p>个人感觉 Annotation 是 Label 的超集，Label 应该是 Annotation 的一种。&lt;/p>
&lt;/blockquote>
&lt;p>由于训练模型使用数据集进行训练，这些已标记数据的质量直接影响&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.md">机器学习&lt;/a>的效果。&lt;/p>
&lt;p>Data annotation 通常可以简单得做如下分类：&lt;/p>
&lt;ul>
&lt;li>Text annotation(文字注释)&lt;/li>
&lt;li>Image annotation(图像标注)&lt;/li>
&lt;li>Video annotation(视频注释)&lt;/li>
&lt;li>Audio Annotation(音频注释)&lt;/li>
&lt;li>Key-point Annotation(关键点标注)&lt;/li>
&lt;li>etc.&lt;/li>
&lt;li>TODO&lt;/li>
&lt;/ul>
&lt;p>基于不同的 AI 任务场景及实际需求，Data annotation 的样式也多种多样：&lt;/p>
&lt;ul>
&lt;li>CV 任务
&lt;ul>
&lt;li>&lt;strong>Bounding box(边界框)&lt;/strong> # CV 的对象检测任务所需数据的标注方式&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>NLP 任务
&lt;ul>
&lt;li>&lt;strong>Text Annotation(文字注释)&lt;/strong> #&lt;/li>
&lt;li>&lt;strong>Semantic Annotation(语义注释)&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>etc.&lt;/li>
&lt;li>TODO&lt;/li>
&lt;/ul>
&lt;h2 id="数据标注工具">数据标注工具&lt;a class="td-heading-self-link" href="#%e6%95%b0%e6%8d%ae%e6%a0%87%e6%b3%a8%e5%b7%a5%e5%85%b7" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Roboflow&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/roboflow">https://github.com/roboflow&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://roboflow.com/">https://roboflow.com/&lt;/a>&lt;/li>
&lt;li>在线&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=7YRJIAIhMpw">https://www.youtube.com/watch?v=7YRJIAIhMpw&lt;/a> 讲了一下基础&lt;/li>
&lt;/ul>
&lt;p>labelme&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/wkentaro/labelme">https://github.com/wkentaro/labelme&lt;/a>&lt;/li>
&lt;li>本地&lt;/li>
&lt;/ul>
&lt;h1 id="cv-数据集">CV 数据集&lt;a class="td-heading-self-link" href="#cv-%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89.md">计算机视觉&lt;/a> 相关 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Dataset.md">Dataset&lt;/a> 中最常见、最基础的是用于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object%20detection.md">Object detection&lt;/a>(对象检测) 训练任务的数据集，需要进行人工标注，以确定让模型识别图片中的哪些对象。&lt;/p>
&lt;p>2006年，斯坦福大学以人为中心的人工智能研究所联席主任李飞飞发起研究，通过大幅扩大训练数据来改进图像识别的人工智能模型和算法。研究人员从万维网上下载了数百万张图像，一组本科生开始为每张图像应用对象标签。 2007 年，李将亚马逊 Mechanical Turk（数字计件工作在线市场）上的数据标记工作外包。由 49,000 多名工作人员标记的 320 万张图像构成了 ImageNet 的基础，ImageNet 是最大的物体识别轮廓手工标记数据库之一。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;h1 id="nlp-数据集">NLP 数据集&lt;a class="td-heading-self-link" href="#nlp-%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Labeled_data">Wiki, Labeled data&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Docs: PyTorch</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/pytorch/pytorch">GitHub 项目，pytorch/pytorch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/">官网&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>PyTorch 是一个使用 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch.md">Torch&lt;/a> 构建的 Python 包，提供两个高级特性：&lt;/p>
&lt;ul>
&lt;li>带有强大 GPU 加速的张量计算（类似于 NumPy）&lt;/li>
&lt;li>基于计算图的自动微分系统构建的深度神经网络&lt;/li>
&lt;/ul>
&lt;h2 id="安装-pytorch">安装 PyTorch&lt;a class="td-heading-self-link" href="#%e5%ae%89%e8%a3%85-pytorch" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://pytorch.org/get-started/locally/">官方文档，开始&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>安装 PyTorch 分为使用 GPU 和 CPU 两种，比如：&lt;/p>
&lt;ul>
&lt;li>CPU
&lt;ul>
&lt;li>&lt;code>pip3 install torch torchvision torchaudio&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>GPU
&lt;ul>
&lt;li>&lt;code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>GPU 版的 PyTorch 依赖 CUDA&lt;/p>
&lt;blockquote>
&lt;p>Note: 如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：&lt;code>Torch not compiled with CUDA enabled&lt;/code>。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>[!Tip]
若安装速度太慢，可以在 pip install 命令中看到 Downloading 的 URL，手动下载，比如 &lt;code>https://download.pytorch.org/whl/cu121/torch-2.4.1+cu121-cp311-cp311-win_amd64.whl&lt;/code>，然后先执行 &lt;code>pip intall torch-2.4.1+cu121-cp311-cp311-win_amd64.whl&lt;/code> 进行本地安装，再执行上面的命令安装其他包&lt;/p>
&lt;/blockquote>
&lt;p>安装完成后可以通过如下代码在 Python 解释器中验证 CUDA 是否可用，若可用，将输出 True&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">print&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">torch&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">cuda&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">is_available&lt;/span>&lt;span style="color:#000;font-weight:bold">())&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="学习">学习&lt;a class="td-heading-self-link" href="#%e5%ad%a6%e4%b9%a0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://www.bilibili.com/video/BV1GC4y15736">B 站，10分钟入门神经网络 PyTorch 手写数字识别&lt;/a>&lt;/p>
&lt;h1 id="torchscript">TorchScript&lt;a class="td-heading-self-link" href="#torchscript" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://pytorch.org/docs/stable/jit.html">https://pytorch.org/docs/stable/jit.html&lt;/a>&lt;/p>
&lt;p>TorchScript 是一种从 PyTorch 代码创建可序列化和可优化模型的方法。任何 TorchScript 程序都可以从 Python 进程保存并加载到不存在 Python 依赖项的进程中。&lt;/p>
&lt;p>TorchScript 是 PyTorch 模型（nn.Module 的子类）的中间表示形式，可以在 C++ 等高性能环境中运行。&lt;/p>
&lt;p>人话：就是一种读写模型的协议，通常以 .pt、.pth、.torchscript 作为文件后缀&lt;/p></description></item><item><title>Docs: Transformers</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/huggingface/transformers">GitHub 项目，huggingface/transformers&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Wiki, Transformer_(machine_learning_model)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://my.oschina.net/oneflow/blog/5525728">Hugging Face 创始人亲述：一个 GitHub 史上增长最快的 AI 项目&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://huggingface.co/docs/transformers/index">官方文档&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Transformer&lt;/strong> 是 &lt;a href="https://desistdaydream.github.io/docs/12.AI/Hugging%20Face.md">Hugging Face&lt;/a> 开源的是一种&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.md">深度学习&lt;/a>模型，它采用自注意力机制，对输入数据的每一部分的重要性进行差异加权。它主要用于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.md">自然语言处理(NLP)&lt;/a> 和 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89.md">计算机视觉(CV)&lt;/a> 领域。&lt;/p>
&lt;p>Transformers 提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。它的宗旨是让最先进的 NLP 技术人人易用。&lt;/p>
&lt;p>Transformers 提供了便于快速下载和使用的 API，让你可以把预训练模型用在给定文本、在你的数据集上微调然后通过 &lt;a href="https://huggingface.co/models">model hub&lt;/a> 与社区共享。同时，每个定义的 Python 模块均完全独立，方便修改和快速研究实验。&lt;/p>
&lt;p>Transformers 支持三个最热门的深度学习库： &lt;a href="https://jax.readthedocs.io/en/latest/">Jax&lt;/a>, &lt;a href="https://pytorch.org/">PyTorch&lt;/a> 以及 &lt;a href="https://www.tensorflow.org/">TensorFlow&lt;/a> — 并与之无缝整合。你可以直接使用一个框架训练你的模型然后用另一个加载和推理。&lt;/p>
&lt;h1 id="安装-transformers">安装 Transformers&lt;a class="td-heading-self-link" href="#%e5%ae%89%e8%a3%85-transformers" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>安装 Transformers 本质就是安装 Transformers 的模型，并且还需要一些可以调用模型的代码(通常都是 Python 包)。&lt;/p>
&lt;p>Transformers 模型可以对接多种热门的深度学习库：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch.md">PyTorch&lt;/a>
&lt;ul>
&lt;li>注意：安装 PyTorch 时，安装 GPU 版的。如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：&lt;code>Torch not compiled with CUDA enabled&lt;/code>。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>TensorFlow&lt;/li>
&lt;/ul>
&lt;p>只安装 Transformers&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install transformers
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装完 Transformers 包后，可以根据需要安装 PyTorch、TensorFlow 等深度学习的的包。&lt;/p>
&lt;h1 id="关联文件与配置">关联文件与配置&lt;a class="td-heading-self-link" href="#%e5%85%b3%e8%81%94%e6%96%87%e4%bb%b6%e4%b8%8e%e9%85%8d%e7%bd%ae" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>~/.cache/huggingface/&lt;/strong> # HuggingFace 缓存路径，保存模型、调用模型的代码 等。可以通过 &lt;code>${HF_HOME}&lt;/code> 更改路径位置；也可以通过 &lt;code>${XDG_CACHE_HOME}&lt;/code> 更改路径位置，但是需要注意，&lt;code>${XDG_CACHE_HOME}&lt;/code> 针对的 &lt;code>~/.cache/&lt;/code> 这部分。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>./hub/&lt;/strong> # 预训练模型在本地缓存的保存路径。可以通过 &lt;code>${HUGGINGFACE_HUB_CACHE}&lt;/code> 环境变量变更路径位置。&lt;/li>
&lt;li>&lt;strong>./modules/&lt;/strong> #&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>为了防止下载很多模型撑爆 C 盘，个人习惯设置 &lt;code>${HF_HOME}&lt;/code> 变量为 &lt;code>D:\Projects\.huggingface&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;h1 id="快速体验">快速体验&lt;a class="td-heading-self-link" href="#%e5%bf%ab%e9%80%9f%e4%bd%93%e9%aa%8c" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>只需要几行代码，就可以在给定任务中下载和使用任何预训练模型，这里官方使用了一个情绪分析模型，用以分析指定文本的情绪是正向的还是负向的：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">transformers&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">pipeline&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 下载并缓存 pipline 使用的预训练模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#000">classifier&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">pipeline&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;sentiment-analysis&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 评估给定的文本&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#000">classifier&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;We are very happy to introduce pipeline to the transformers repository.&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">[{&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;label&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#39;POSITIVE&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#4e9a06">&amp;#39;score&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0.9996980428695679&lt;/span>&lt;span style="color:#000;font-weight:bold">}]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>transformers 库会自动从 Hugging Face 中下载名为 sentiment-analysis 到默认的缓存路径中。&lt;/p>
&lt;h2 id="高级体验">高级体验&lt;a class="td-heading-self-link" href="#%e9%ab%98%e7%ba%a7%e4%bd%93%e9%aa%8c" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>有时我们使用的模型可能会产生某些问题，此时我们可以手动下载模型，比如我们用清华开源的 chatglm-6b 模型举例，只需要先在本地目录下载模型 &lt;code>git clone https://huggingface.co/THUDM/chatglm-6b-int&lt;/code>，然后运行如下代码即可使用 CPU 体验。其中注意要安装 chatglm-6b 项目中的 Python 依赖。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">transformers&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">AutoTokenizer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">AutoModel&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">tokenizer&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">AutoTokenizer&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">from_pretrained&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">trust_remote_code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">True&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">AutoModel&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">from_pretrained&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>&lt;span style="color:#000">trust_remote_code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">True&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">float&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">model&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">eval&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">response&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">history&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">model&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">chat&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">tokenizer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;你好&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">history&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#000;font-weight:bold">[])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">print&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">response&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>代码运行后，获得回复：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># python demo.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="其他学习">其他学习&lt;a class="td-heading-self-link" href="#%e5%85%b6%e4%bb%96%e5%ad%a6%e4%b9%a0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/NgUNuWhvp2SqG-XWYv2PGQ">公众号-阿里云开发者，Transformer 一起动手编码学原理&lt;/a>&lt;/p></description></item><item><title>Docs: 深度学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Deep_learning">Wiki, Deep_learning&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Deep learning(深度学习)&lt;/strong> 是&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.md">机器学习&lt;/a>方法家族的一部分，它基于具有表示学习的人工神经网络。学习可以是监督的、半监督的或无监督的。&lt;/p>
&lt;p>深度神经网络、深度信念网络、深度强化学习、递归神经网络、卷积神经网络和 Transformer 等深度学习架构已应用于计算机视觉、语音识别、自然语言处理、机器翻译、生物信息学、药物设计等领域、医学图像分析、气候科学、材料检验和棋盘游戏程序，它们在这些方面产生的结果可与人类专家的表现相媲美，在某些情况下甚至超过人类专家的表现&lt;/p>
&lt;h1 id="深度学习框架">深度学习框架&lt;a class="td-heading-self-link" href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>TensorFlow # 基于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/NumPy.md">NumPy&lt;/a> 构建，谷歌开发&lt;/p>
&lt;p>PyTorch # 基于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch.md">Torch&lt;/a> 构建，Facebook 开发&lt;/p>
&lt;p>Paddle，百度飞桨&lt;/p>
&lt;h1 id="deepspeed">DeepSpeed&lt;a class="td-heading-self-link" href="#deepspeed" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/DeepSpeed">GitHub 项目，microsoft/DeepSpeed&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>DeepSpeed Chat 一键式RLHF训练，让你的类 ChatGPT 千亿大模型提速省钱15倍&lt;/p></description></item></channel></rss>