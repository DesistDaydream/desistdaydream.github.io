<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – 机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 机器学习 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning">Wiki，Machine_learning&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Machine learning(机器学习，简称 ML)&lt;/strong> 是一个致力于理解和构建让机器“学习”的方法的领域 - 就是利用数据提高计算机在某些任务上性能的方法。&lt;/p>
&lt;p>就像人需要学习一样，机器也需要学习。机器学习是&lt;a href="https://desistdaydream.github.io/docs/12.AI/12.AI.md">人工智能&lt;/a>的一个广泛子领域。&lt;/p>
&lt;p>机器学习通常需要一个模型和训练模型的方法，通过训练好的模型，可以更准确得预测或分类新的未见过的数据。比如自然语言处理中，当我们像模型提交输入的文字后，模型会根据参数，逐步预测将要输出的每一个文字，每个文字都是由模型根据训练好的参数，依据统计学的百分比概率推导出来的。&lt;/p>
&lt;p>我们人类好像也是通过这种方式沟通的，每个字都在脑子中依据已有知识，推理出来后，逐一说出来。&lt;/p>
&lt;h1 id="学习方法">学习方法&lt;a class="td-heading-self-link" href="#%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Approaches">https://en.wikipedia.org/wiki/Machine_learning#Approaches&lt;/a>&lt;/p>
&lt;ul>
&lt;li>Supervised learning(监督学习)&lt;/li>
&lt;li>Unsupervised learning(无监督学习)&lt;/li>
&lt;li>Reinforcement learning(强化学习)&lt;/li>
&lt;/ul>
&lt;p>TODO: 学习方法？&lt;/p>
&lt;ul>
&lt;li>Convolutional Neural Network(卷积神经网络简称 CNN)&lt;/li>
&lt;li>Transformer(变压器)&lt;/li>
&lt;li>Generative Adversarial Network(对抗网络模型，简称 GAN)&lt;/li>
&lt;/ul>
&lt;p>Emergence(涌现)&lt;/p>
&lt;h1 id="模型">模型&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>机器学习离不开&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B.md">模型&lt;/a>&lt;/p></description></item><item><title>Docs: PyTorch</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/pytorch/pytorch">GitHub 项目，pytorch/pytorch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/">官网&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>PyTorch 是一个使用 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch.md">Torch&lt;/a> 构建的 Python 包，提供两个高级特性：&lt;/p>
&lt;ul>
&lt;li>带有强大 GPU 加速的张量计算（类似于 NumPy）&lt;/li>
&lt;li>基于计算图的自动微分系统构建的深度神经网络&lt;/li>
&lt;/ul>
&lt;h2 id="安装-pytorch">安装 PyTorch&lt;a class="td-heading-self-link" href="#%e5%ae%89%e8%a3%85-pytorch" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://pytorch.org/get-started/locally/">官方文档，开始&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>安装 PyTorch 分为使用 GPU 和 CPU 两种，比如：&lt;/p>
&lt;ul>
&lt;li>CPU
&lt;ul>
&lt;li>&lt;code>pip3 install torch torchvision torchaudio&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>GPU
&lt;ul>
&lt;li>&lt;code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>GPU 版的 PyTorch 依赖 CUDA&lt;/p>
&lt;blockquote>
&lt;p>如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：&lt;code>Torch not compiled with CUDA enabled&lt;/code>。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。&lt;/p>
&lt;/blockquote>
&lt;p>可以通过如下代码在 Python 解释器中验证 CUDA 是否可用，若可用，将输出 True&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">print&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">torch&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">cuda&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">is_available&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="学习">学习&lt;a class="td-heading-self-link" href="#%e5%ad%a6%e4%b9%a0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://www.bilibili.com/video/BV1GC4y15736">B 站，10分钟入门神经网络 PyTorch 手写数字识别&lt;/a>&lt;/p></description></item><item><title>Docs: Transformers</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/huggingface/transformers">GitHub 项目，huggingface/transformers&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Wiki，Transformer_(machine_learning_model)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://my.oschina.net/oneflow/blog/5525728">Hugging Face 创始人亲述：一个 GitHub 史上增长最快的 AI 项目&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://huggingface.co/docs/transformers/index">官方文档&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Transformer&lt;/strong> 是 &lt;a href="https://desistdaydream.github.io/docs/12.AI/Hugging%20Face.md">Hugging Face&lt;/a> 开源的是一种&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.md">深度学习&lt;/a>模型，它采用自注意力机制，对输入数据的每一部分的重要性进行差异加权。它主要用于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.md">自然语言处理(NLP)&lt;/a> 和 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89.md">计算机视觉(CV)&lt;/a> 领域。&lt;/p>
&lt;p>Transformers 提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。它的宗旨是让最先进的 NLP 技术人人易用。&lt;/p>
&lt;p>Transformers 提供了便于快速下载和使用的 API，让你可以把预训练模型用在给定文本、在你的数据集上微调然后通过 &lt;a href="https://huggingface.co/models">model hub&lt;/a> 与社区共享。同时，每个定义的 Python 模块均完全独立，方便修改和快速研究实验。&lt;/p>
&lt;p>Transformers 支持三个最热门的深度学习库： &lt;a href="https://jax.readthedocs.io/en/latest/">Jax&lt;/a>, &lt;a href="https://pytorch.org/">PyTorch&lt;/a> 以及 &lt;a href="https://www.tensorflow.org/">TensorFlow&lt;/a> — 并与之无缝整合。你可以直接使用一个框架训练你的模型然后用另一个加载和推理。&lt;/p>
&lt;h1 id="安装-transformers">安装 Transformers&lt;a class="td-heading-self-link" href="#%e5%ae%89%e8%a3%85-transformers" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>安装 Transformers 本质就是安装 Transformers 的模型，并且还需要一些可以调用模型的代码(通常都是 Python 包)。&lt;/p>
&lt;p>Transformers 模型可以对接多种热门的深度学习库：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch.md">PyTorch&lt;/a>
&lt;ul>
&lt;li>注意：安装 PyTorch 时，安装 GPU 版的。如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：&lt;code>Torch not compiled with CUDA enabled&lt;/code>。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>TensorFlow&lt;/li>
&lt;/ul>
&lt;p>只安装 Transformers&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install transformers
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装完 Transformers 包后，可以根据需要安装 PyTorch、TensorFlow 等深度学习的的包。&lt;/p>
&lt;h1 id="关联文件与配置">关联文件与配置&lt;a class="td-heading-self-link" href="#%e5%85%b3%e8%81%94%e6%96%87%e4%bb%b6%e4%b8%8e%e9%85%8d%e7%bd%ae" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>~/.cache/huggingface/&lt;/strong> # HuggingFace 缓存路径，保存模型、调用模型的代码 等。可以通过 &lt;code>${HF_HOME}&lt;/code> 更改路径位置；也可以通过 &lt;code>${XDG_CACHE_HOME}&lt;/code> 更改路径位置，但是需要注意，&lt;code>${XDG_CACHE_HOME}&lt;/code> 针对的 &lt;code>~/.cache/&lt;/code> 这部分。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>./hub/&lt;/strong> # 预训练模型在本地缓存的保存路径。可以通过 &lt;code>${HUGGINGFACE_HUB_CACHE}&lt;/code> 环境变量变更路径位置。&lt;/li>
&lt;li>&lt;strong>./modules/&lt;/strong> #&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>为了防止下载很多模型撑爆 C 盘，个人习惯设置 &lt;code>${HF_HOME}&lt;/code> 变量为 &lt;code>D:\Projects\.huggingface&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;h1 id="快速体验">快速体验&lt;a class="td-heading-self-link" href="#%e5%bf%ab%e9%80%9f%e4%bd%93%e9%aa%8c" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>只需要几行代码，就可以在给定任务中下载和使用任何预训练模型，这里官方使用了一个情绪分析模型，用以分析指定文本的情绪是正向的还是负向的：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">transformers&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">pipeline&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 下载并缓存 pipline 使用的预训练模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#000">classifier&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">pipeline&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;sentiment-analysis&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 评估给定的文本&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#000">classifier&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;We are very happy to introduce pipeline to the transformers repository.&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000;font-weight:bold">[{&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;label&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#39;POSITIVE&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#4e9a06">&amp;#39;score&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0.9996980428695679&lt;/span>&lt;span style="color:#000;font-weight:bold">}]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>transformers 库会自动从 Hugging Face 中下载名为 sentiment-analysis 到默认的缓存路径中。&lt;/p>
&lt;h2 id="高级体验">高级体验&lt;a class="td-heading-self-link" href="#%e9%ab%98%e7%ba%a7%e4%bd%93%e9%aa%8c" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>有时我们使用的模型可能会产生某些问题，此时我们可以手动下载模型，比如我们用清华开源的 chatglm-6b 模型举例，只需要先在本地目录下载模型 &lt;code>git clone https://huggingface.co/THUDM/chatglm-6b-int&lt;/code>，然后运行如下代码即可使用 CPU 体验。其中注意要安装 chatglm-6b 项目中的 Python 依赖。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">transformers&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">AutoTokenizer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">AutoModel&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">tokenizer&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">AutoTokenizer&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">from_pretrained&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">trust_remote_code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">True&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">AutoModel&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">from_pretrained&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>&lt;span style="color:#000">trust_remote_code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">True&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">float&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">model&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">eval&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">response&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">history&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">model&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">chat&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">tokenizer&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;你好&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">history&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#000;font-weight:bold">[])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">print&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">response&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>代码运行后，获得回复：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># python demo.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="其他学习">其他学习&lt;a class="td-heading-self-link" href="#%e5%85%b6%e4%bb%96%e5%ad%a6%e4%b9%a0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/NgUNuWhvp2SqG-XWYv2PGQ">公众号-阿里云开发者，Transformer 一起动手编码学原理&lt;/a>&lt;/p></description></item><item><title>Docs: 模型</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Models">Wiki, Machine_learning - Models&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">Wiki, Hyperparameter&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>执行机器学习涉及创建 &lt;strong>Model(模型)&lt;/strong>，这个模型狭义上指&lt;a href="https://en.wikipedia.org/wiki/Mathematical_model">数学模型&lt;/a>中的&lt;a href="https://en.wikipedia.org/wiki/Statistical_model">统计模型&lt;/a>，是一种数学表示，用于描述和解决特定类型的问题。这些模型可以是各种各样的，包括传统的统计学模型，如线性回归和逻辑回归，也可以是基于神经网络的深度学习模型，如卷积神经网络和循环神经网络。&lt;/p>
&lt;p>模型通常由 &lt;strong>数学公式&lt;/strong>、&lt;strong>超参数&lt;/strong>、&lt;strong>参数&lt;/strong> 组成，可以根据给定的输入数据进行训练和调整，以使它们能够在未见过的数据上进行准确预测或分类。因此，AI 领域中的模型本质上是一种数学模型，通过使用数学方法来处理和分析数据，以解决各种问题，如分类、预测、图像处理、自然语言处理等。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>数学公式&lt;/strong> # 模型的结构通常用数学公式表示，e.g. 线性变换、激活函数、etc. 。e.g. 线性层的计算: $y = Wx + b$ ，其中 W 是权重矩阵，x 是输入向量，b 是偏置。&lt;/li>
&lt;li>&lt;strong>Hyperparameter(超参数)&lt;/strong> # 训练和模型架构设置中手动配置的参数，影响模型的性能和训练过程。常见的超参数包括：学习率、批量大小、网络层数和每层的神经元数量、激活函数类型、训练轮数、etc. 。而其他参数（例如节点权重）的值是通过训练得出的。&lt;/li>
&lt;li>&lt;strong>Parameters(参数)&lt;/strong> # 模型训练过程中学习到的一系列数值，e.g. &lt;strong>权重&lt;/strong>、etc. 。它们决定了输入数据如何影响模型的输出。&lt;/li>
&lt;/ul>
&lt;p>模型需要训练，训练后得到的模型文件是一系列的权值（权重值），通常是大量(上亿)个浮点数，如果进行了&lt;strong>模型量化&lt;/strong>，也可以是整数。&lt;/p>
&lt;h1 id="创建模型">创建模型&lt;a class="td-heading-self-link" href="#%e5%88%9b%e5%bb%ba%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>定义模型结构&lt;/strong> # 选择模型类型等。比如 &lt;code>nn.Linear(10, 1)&lt;/code> 定义了一个简单的全连接层。&lt;/li>
&lt;li>TODO：&lt;strong>定义损失函数和优化器&lt;/strong> # 如交叉熵损失、均方误差，以及优化算法如 SGD、Adam。
&lt;ul>
&lt;li>激活函数 # 每个神经元应用的非线性函数，用于引入非线性，使模型能够学习复杂的模式。&lt;/li>
&lt;li>损失函数 # 用于衡量模型输出与实际目标之间的差异。在训练过程中，模型会尝试最小化损失函数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>训练模型&lt;/strong> # 通过给模型输入数据和目标，计算损失并反向传播调整参数。&lt;/li>
&lt;li>&lt;strong>保存模型&lt;/strong> # 在训练完毕后保存模型，以便后续测试或部署。你可以通过 &lt;code>torch.save()&lt;/code> 保存模型，&lt;code>torch.load()&lt;/code> 加载模型。&lt;/li>
&lt;/ul>
&lt;p>暂时先用下面的代码尝试理解一下，随着后续深入学习逐步完善：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">torch&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">nn&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 一、定义模型结构&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># Linear() 可以暂时理解为使用 Linear 模型，可以假设模型是 y = xA^T + b；&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 10, 1 可以理解为 超参数。也可以简单理解为是在训练模型以检查返回值 fc 是否满足预期&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">fc&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">nn&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Linear&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">10&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 二、定义损失函数、优化器&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 略&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 三、训练模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 注意：fc.state_dict() 并不是真正意义上的训练模型。仅是获取模型的当前参数（e.g. 权重值、etc.）这些参数可能是刚初始化的（随机值），也可能是已经训练过的。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 通常，在训练完成后调用 state_dict() 来保存模型的参数。这样可以在之后加载这些参数，继续训练或进行推理。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">fc&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">state_dict&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 四、保存模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 将训练结果 fc 保存到模型文件 hello_world.pth 中&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">torch&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">save&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">model&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;./models/hello_world.pth&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 从 hello_world.pth 模型文件中读取参数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">weight&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">torch&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">load&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;./models/hello_world.pth&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">weights_only&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">True&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 模型文件中的内容本质上是一系列权重值的集合，效果如下：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># OrderedDict({&amp;#39;weight&amp;#39;: tensor([[0.0382, -0.1313, 0.2224, -0.2967, -0.2892, -0.2951, 0.0455, -0.0702,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># -0.2919, 0.2825]]), &amp;#39;bias&amp;#39;: tensor([-0.2147])})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">print&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">weight&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>nn.Linear() 就像编程体系中的汇编，是所有高级模型的基础。只不过还有很多不同点，比如 汇编没有训练的概念、etc. 。&lt;/p>
&lt;p>似乎，从这种底层逻辑看，所有模型其实都是一样的，底层只有像 Linear() 之类的简单线性层，不同点在于高级模型会用到 非常多的层数、训练方式、训练数据。&lt;/p>
&lt;h1 id="训练模型">训练模型&lt;a class="td-heading-self-link" href="#%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Training_models">Wiki，Machine_learning - Training_models&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>写好模型后，向模型中传入参数用结果与历史真实结果对比，差值越小，模型越精准？若是差值大就修改参数，直到最后差值无限接近 0 ？&lt;/p>
&lt;p>一个模型的权重在没有训练之前通常都有一个默认值（0 - 1 的正态分布）。训练模型一般是指将数据提供给模型后，数据将会转为一组数值，模型根据这组数值调整权重，随着一次一次的训练，模型会不断更新这些权重，直到满足最终目标&lt;/p>
&lt;p>注意日常口语化的名词 &lt;strong>调参&lt;/strong>，调的是什么参？超参？权重？还是什么？&lt;/p>
&lt;p>训练模型最基本需要如下几样东西&lt;/p>
&lt;ul>
&lt;li>&lt;strong>原始模型&lt;/strong>&lt;/li>
&lt;li>&lt;strong>待训练数据集&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>通过模型配套的程序，将数据集交给原始模型并训练 N epoch(周期)，最终得到可以执行特定任务的模型（识别对象、沟通、etc.）&lt;/p>
&lt;blockquote>
&lt;p>[!Tip]
不同的模型（计算机视觉、自然语言处理、etc.）训练时，可能需要一些特定于该种类模型的东西。&lt;/p>
&lt;/blockquote>
&lt;h2 id="训练数据">训练数据&lt;a class="td-heading-self-link" href="#%e8%ae%ad%e7%bb%83%e6%95%b0%e6%8d%ae" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>用图像识别举例，训练数据需要进行人工标注，以确定需要让模型识别图片中的哪些内容。标注是指：在一张图片中圈出 N 个感兴趣的点（就像 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV.md">OpenCV&lt;/a> 的 Region Of Interest(感兴趣的区域，简称 ROI)），然后会生成图片对应的 Label，每个 ROI 都有一个数字表示的类别、以及 ROI 左上角与右上角的 x轴 与 y轴 坐标，共 5 个数字&lt;/p>
&lt;p>然后标注工具会基于这些图片及其 Label 生成一个文件，将这些文件交给模型，并编写模型配套的训练代码，即可开始训练。&lt;/p></description></item><item><title>Docs: 深度学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Deep_learning">Wiki，Deep_learning&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Deep learning(深度学习)&lt;/strong> 是&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.md">机器学习&lt;/a>方法家族的一部分，它基于具有表示学习的人工神经网络。学习可以是监督的、半监督的或无监督的。&lt;/p>
&lt;p>深度神经网络、深度信念网络、深度强化学习、递归神经网络、卷积神经网络和 Transformer 等深度学习架构已应用于计算机视觉、语音识别、自然语言处理、机器翻译、生物信息学、药物设计等领域、医学图像分析、气候科学、材料检验和棋盘游戏程序，它们在这些方面产生的结果可与人类专家的表现相媲美，在某些情况下甚至超过人类专家的表现&lt;/p>
&lt;h1 id="深度学习框架">深度学习框架&lt;a class="td-heading-self-link" href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>TensorFlow # 基于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/NumPy.md">NumPy&lt;/a> 构建，谷歌开发&lt;/p>
&lt;p>PyTorch # 基于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch.md">Torch&lt;/a> 构建，Facebook 开发&lt;/p>
&lt;p>Paddle，百度飞桨&lt;/p>
&lt;h1 id="deepspeed">DeepSpeed&lt;a class="td-heading-self-link" href="#deepspeed" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/DeepSpeed">GitHub 项目，microsoft/DeepSpeed&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>DeepSpeed Chat 一键式RLHF训练，让你的类 ChatGPT 千亿大模型提速省钱15倍&lt;/p></description></item></channel></rss>