<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦 – 机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 机器学习 on 断念梦</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning">Wiki，Machine_learning&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Machine learning(机器学习，简称 ML)&lt;/strong> 是一个致力于理解和构建让机器“学习”的方法的领域 - 就是利用数据提高计算机在某些任务上性能的方法。&lt;/p>
&lt;p>就像人需要学习一样，机器也需要学习。机器学习是&lt;a href="https://desistdaydream.github.io/docs/12.AI/12.AI.md">人工智能&lt;/a>的一个广泛子领域。&lt;/p>
&lt;p>机器学习通常需要一个模型和训练模型的方法，通过训练好的模型，可以更准确得预测或分类新的未见过的数据。比如自然语言处理中，当我们像模型提交输入的文字后，模型会根据参数，逐步预测将要输出的每一个文字，每个文字都是由模型根据训练好的参数，依据统计学的百分比概率推导出来的。&lt;/p>
&lt;p>我们人类好像也是通过这种方式沟通的，每个字都在脑子中依据已有知识，推理出来后，逐一说出来。&lt;/p>
&lt;h1 id="学习方法">学习方法&lt;/h1>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Approaches">https://en.wikipedia.org/wiki/Machine_learning#Approaches&lt;/a>&lt;/p>
&lt;ul>
&lt;li>Supervised learning(监督学习)&lt;/li>
&lt;li>Unsupervised learning(无监督学习)&lt;/li>
&lt;li>Reinforcement learning(强化学习)&lt;/li>
&lt;/ul>
&lt;p>TODO: 学习方法？&lt;/p>
&lt;ul>
&lt;li>Convolutional Neural Network(卷积神经网络简称 CNN)&lt;/li>
&lt;li>Transformer(变压器)&lt;/li>
&lt;li>Generative Adversarial Network(对抗网络模型，简称 GAN)&lt;/li>
&lt;/ul>
&lt;p>Emergence(涌现)&lt;/p>
&lt;h1 id="模型">模型&lt;/h1>
&lt;p>机器学习离不开&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B.md">模型&lt;/a>&lt;/p>
&lt;h1 id="分类">分类&lt;/h1>
&lt;blockquote>
&lt;p>#人工智能 #机器学习&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: PyTorch</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/pytorch/pytorch">GitHub 项目，pytorch/pytorch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/">官网&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>PyTorch 是一个使用 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch.md">Torch&lt;/a> 构建的 Python 包，提供两个高级特性：&lt;/p>
&lt;ul>
&lt;li>带有强大 GPU 加速的张量计算（类似于 NumPy）&lt;/li>
&lt;li>基于计算图的自动微分系统构建的深度神经网络&lt;/li>
&lt;/ul>
&lt;h2 id="安装-pytorch">安装 PyTorch&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://pytorch.org/get-started/locally/">官方文档，开始&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>安装 PyTorch 分为使用 GPU 和 CPU 两种，比如：&lt;/p>
&lt;ul>
&lt;li>CPU
&lt;ul>
&lt;li>&lt;code>pip3 install torch torchvision torchaudio&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>GPU
&lt;ul>
&lt;li>&lt;code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>GPU 版的 PyTorch 依赖 CUDA&lt;/p>
&lt;blockquote>
&lt;p>如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：&lt;code>Torch not compiled with CUDA enabled&lt;/code>。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。&lt;/p>
&lt;/blockquote>
&lt;h1 id="学习">学习&lt;/h1>
&lt;p>&lt;a href="https://www.bilibili.com/video/BV1GC4y15736">B 站，10分钟入门神经网络 PyTorch 手写数字识别&lt;/a>&lt;/p>
&lt;h1 id="分类">分类&lt;/h1>
&lt;blockquote>
&lt;p>#人工智能 #机器学习 #Python&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: Transformers</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/huggingface/transformers">GitHub 项目，huggingface/transformers&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Wiki，Transformer_(machine_learning_model)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://my.oschina.net/oneflow/blog/5525728">Hugging Face 创始人亲述：一个 GitHub 史上增长最快的 AI 项目&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://huggingface.co/docs/transformers/index">官方文档&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Transformer&lt;/strong> 是 &lt;a href="https://desistdaydream.github.io/docs/12.AI/Hugging%20Face.md">Hugging Face&lt;/a> 开源的是一种&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.md">深度学习&lt;/a>模型，它采用自注意力机制，对输入数据的每一部分的重要性进行差异加权。它主要用于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.md">自然语言处理(NLP)&lt;/a> 和 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89.md">计算机视觉(CV)&lt;/a> 领域。&lt;/p>
&lt;p>🤗 Transformers 提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。它的宗旨是让最先进的 NLP 技术人人易用。&lt;/p>
&lt;p>🤗 Transformers 提供了便于快速下载和使用的 API，让你可以把预训练模型用在给定文本、在你的数据集上微调然后通过 &lt;a href="https://huggingface.co/models">model hub&lt;/a> 与社区共享。同时，每个定义的 Python 模块均完全独立，方便修改和快速研究实验。&lt;/p>
&lt;p>🤗 Transformers 支持三个最热门的深度学习库： &lt;a href="https://jax.readthedocs.io/en/latest/">Jax&lt;/a>, &lt;a href="https://pytorch.org/">PyTorch&lt;/a> 以及 &lt;a href="https://www.tensorflow.org/">TensorFlow&lt;/a> — 并与之无缝整合。你可以直接使用一个框架训练你的模型然后用另一个加载和推理。&lt;/p>
&lt;h1 id="安装-transformers">安装 Transformers&lt;/h1>
&lt;p>安装 Transformers 本质就是安装 Transformers 的模型，并且还需要一些可以调用模型的代码(通常都是 Python 包)。&lt;/p>
&lt;p>Transformers 模型可以对接多种热门的深度学习库：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch.md">PyTorch&lt;/a>
&lt;ul>
&lt;li>注意：安装 PyTorch 时，安装 GPU 版的。如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：&lt;code>Torch not compiled with CUDA enabled&lt;/code>。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>TensorFlow&lt;/li>
&lt;/ul>
&lt;p>只安装 Transformers&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install transformers
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装完 Transformers 包后，可以根据需要安装 PyTorch、TensorFlow 等深度学习的的包。&lt;/p>
&lt;h1 id="关联文件与配置">关联文件与配置&lt;/h1>
&lt;p>&lt;strong>~/.cache/huggingface/&lt;/strong> # HuggingFace 缓存路径，保存模型、调用模型的代码 等。可以通过 &lt;code>${HF_HOME}&lt;/code> 更改路径位置；也可以通过 &lt;code>${XDG_CACHE_HOME}&lt;/code> 更改路径位置，但是需要注意，&lt;code>${XDG_CACHE_HOME}&lt;/code> 针对的 &lt;code>~/.cache/&lt;/code> 这部分。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>./hub/&lt;/strong> # 预训练模型在本地缓存的保存路径。可以通过 &lt;code>${HUGGINGFACE_HUB_CACHE}&lt;/code> 环境变量变更路径位置。&lt;/li>
&lt;li>&lt;strong>./modules/&lt;/strong> #&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>为了防止下载很多模型撑爆 C 盘，个人习惯设置 &lt;code>${HF_HOME}&lt;/code> 变量为 &lt;code>D:\Projects\.huggingface&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;h1 id="快速体验">快速体验&lt;/h1>
&lt;p>只需要几行代码，就可以在给定任务中下载和使用任何预训练模型，这里官方使用了一个情绪分析模型，用以分析指定文本的情绪是正向的还是负向的：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> pipeline
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 下载并缓存 pipline 使用的预训练模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> classifier &lt;span style="color:#f92672">=&lt;/span> pipeline(&lt;span style="color:#e6db74">&amp;#39;sentiment-analysis&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 评估给定的文本&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> classifier(&lt;span style="color:#e6db74">&amp;#39;We are very happy to introduce pipeline to the transformers repository.&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[{&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;POSITIVE&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;score&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">0.9996980428695679&lt;/span>}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>transformers 库会自动从 Hugging Face 中下载名为 sentiment-analysis 到默认的缓存路径中。&lt;/p>
&lt;h2 id="高级体验">高级体验&lt;/h2>
&lt;p>有时我们使用的模型可能会产生某些问题，此时我们可以手动下载模型，比如我们用清华开源的 chatglm-6b 模型举例，只需要先在本地目录下载模型 &lt;code>git clone https://huggingface.co/THUDM/chatglm-6b-int&lt;/code>，然后运行如下代码即可使用 CPU 体验。其中注意要安装 chatglm-6b 项目中的 Python 依赖。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> AutoTokenizer, AutoModel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenizer &lt;span style="color:#f92672">=&lt;/span> AutoTokenizer&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4&amp;#34;&lt;/span>, trust_remote_code&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> AutoModel&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;D:\Projects\DesistDaydream\python-transformers\chatglm-6b-int4&amp;#34;&lt;/span>,trust_remote_code&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>float()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> model&lt;span style="color:#f92672">.&lt;/span>eval()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response, history &lt;span style="color:#f92672">=&lt;/span> model&lt;span style="color:#f92672">.&lt;/span>chat(tokenizer, &lt;span style="color:#e6db74">&amp;#34;你好&amp;#34;&lt;/span>, history&lt;span style="color:#f92672">=&lt;/span>[])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(response)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>代码运行后，获得回复：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#75715e"># python demo.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="其他学习">其他学习&lt;/h1>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/NgUNuWhvp2SqG-XWYv2PGQ">公众号-阿里云开发者，Transformer 一起动手编码学原理&lt;/a>&lt;/p>
&lt;h1 id="分类">分类&lt;/h1>
&lt;blockquote>
&lt;p>#人工智能 #机器学习&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: 模型</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Models">Wiki，Machine_learning-Models&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>执行机器学习涉及创建&lt;strong>Model(模型)&lt;/strong>，这个模型狭义上指&lt;a href="https://en.wikipedia.org/wiki/Mathematical_model">数学模型&lt;/a>中的&lt;a href="https://en.wikipedia.org/wiki/Statistical_model">统计模型&lt;/a>，是一种数学表示，用于描述和解决特定类型的问题。这些模型可以是各种各样的，包括传统的统计学模型，如线性回归和逻辑回归，也可以是基于神经网络的深度学习模型，如卷积神经网络和循环神经网络。&lt;/p>
&lt;p>这些模型通常由&lt;strong>数学公式&lt;/strong>和&lt;strong>参数&lt;/strong>组成，可以根据给定的输入数据进行训练和调整，以使它们能够在未见过的数据上进行准确预测或分类。因此，AI领域中的模型本质上是一种数学模型，通过使用数学方法来处理和分析数据，以解决各种问题，如分类、预测、图像处理、自然语言处理等。&lt;/p>
&lt;p>模型通常需要训练，训练后得到的模型文件是一系列的权值，通常是大量(上亿)个浮点数，如果进行了&lt;strong>模型量化&lt;/strong>，也可以是整数。&lt;/p>
&lt;h1 id="训练模型">训练模型&lt;/h1>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Machine_learning#Training_models">https://en.wikipedia.org/wiki/Machine_learning#Training_models&lt;/a>&lt;/p>
&lt;p>在 AI 领域，什么是训练？模型是一段代码么？可以通过训练自动更新代码？模型是数学公式么？可以通过训练自动更新公式吗？&lt;/p>
&lt;p>以下来自 ChatGPT 3.5 的回答：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>在AI领域中，训练指的是使用数据集来调整模型的参数，使其能够更准确地预测未知数据。训练的目的是为了使模型能够从数据中学习到规律和特征，从而在未知数据上表现出良好的预测能力。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>模型通常是一段代码，它定义了一个计算图（computational graph），用于将输入数据转换为预测结果。通过训练，可以调整模型代码中的参数值，以使其能够更好地拟合数据，并提高其预测能力。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>在训练过程中，模型并不是通过自动更新代码来实现优化的。相反，模型的代码是固定的，而是通过调整模型的参数值来提高其性能。这些参数值通常是模型中数学公式的系数，因此可以认为模型是数学公式的实现。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>因此，模型中的数学公式可以通过训练来自动更新其系数，以使其能够更好地拟合数据并提高其预测能力。然而，模型代码本身并不会自动更新。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>为了调整模型的参数，通常需要使用反向传播算法等技术来计算模型误差，并更新模型参数。在这个过程中，模型的表现会不断地得到改善，直到其达到满意的准确度或性能为止。一旦训练完成，模型就可以用于实际应用。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>TODO: 什么是预训练模型？为什么可以直接用？&lt;/p>
&lt;p>以下来自 ChatGPT 3.5 的回答：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>预训练模型是指在大规模数据上训练好的模型，通常是使用无监督学习方法进行训练的，比如自编码器、变分自编码器、生成对抗网络等。这些模型在训练时能够学习到一些通用的特征表示，比如图像中的边缘、纹理、形状等，文本中的语义、情感、关系等。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>预训练模型之所以可以直接用于特定任务，是因为这些通用特征表示可以被迁移至其他相关任务。例如，一个在大规模文本数据上预训练好的语言模型，可以用于下游任务，如文本分类、命名实体识别等。在这些任务中，语言模型可以提供有用的特征表示，帮助模型更好地理解和处理文本。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>此外，预训练模型通常需要大量的计算资源和数据集来进行训练，因此直接使用这些模型可以避免用户自己进行大规模训练的时间和成本。同时，预训练模型还可以提供良好的初始化参数，帮助加速特定任务的训练过程。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>总之，预训练模型可以通过迁移学习的方式，将通用特征表示迁移到特定任务中，从而提高模型的性能和效率。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="分类">分类&lt;/h1>
&lt;blockquote>
&lt;p>#人工智能 #机器学习&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: 深度学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid><description>
&lt;h1 id="概述">概述&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Deep_learning">Wiki，Deep_learning&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Deep learning(深度学习)&lt;/strong> 是&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.md">机器学习&lt;/a>方法家族的一部分，它基于具有表示学习的人工神经网络。学习可以是监督的、半监督的或无监督的。&lt;/p>
&lt;p>深度神经网络、深度信念网络、深度强化学习、递归神经网络、卷积神经网络和 Transformer 等深度学习架构已应用于计算机视觉、语音识别、自然语言处理、机器翻译、生物信息学、药物设计等领域、医学图像分析、气候科学、材料检验和棋盘游戏程序，它们在这些方面产生的结果可与人类专家的表现相媲美，在某些情况下甚至超过人类专家的表现&lt;/p>
&lt;h1 id="深度学习框架">深度学习框架&lt;/h1>
&lt;p>TensorFlow # 基于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/NumPy.md">NumPy&lt;/a> 构建，谷歌开发&lt;/p>
&lt;p>PyTorch # 基于 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch.md">Torch&lt;/a> 构建，Facebook 开发&lt;/p>
&lt;p>Paddle，百度飞桨&lt;/p>
&lt;h1 id="deepspeed">DeepSpeed&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/DeepSpeed">GitHub 项目，microsoft/DeepSpeed&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>DeepSpeed Chat 一键式RLHF训练，让你的类 ChatGPT 千亿大模型提速省钱15倍&lt;/p>
&lt;h1 id="分类">分类&lt;/h1>
&lt;blockquote>
&lt;p>#人工智能 #机器学习&lt;/p>
&lt;/blockquote></description></item></channel></rss>