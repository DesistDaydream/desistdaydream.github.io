<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>机器学习 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 机器学习 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid><description>概述 参考：
Wiki, Machine_learning Wiki, Data mining Machine learning(机器学习，简称 ML) 是一个致力于理解和构建让机器“学习”的方法的领域 - 就是利用数据提高计算机在某些任务上性能的方法。
就像人需要学习一样，机器也需要学习。机器学习是人工智能的一个广泛子领域。
机器学习通常需要一个模型和训练模型的方法，通过训练好的模型，可以更准确得预测或分类新的未见过的数据。e.g. 自然语言处理中，当我们向模型提交输入的文字后，模型会根据参数，逐步预测将要输出的每一个文字，每个文字都是由模型根据训练好的参数，依据统计学的百分比概率推导出来的。
我们人类好像也是通过这种方式沟通的，每个字都在脑子中依据已有知识，推理出来后，逐一说出来。
TODO: 这都是啥？
Convolutional Neural Network(卷积神经网络简称 CNN) Transformer(变压器) Generative Adversarial Network(对抗网络模型，简称 GAN) TODO: Data mining(数据挖掘)
学习方法 参考：
https://en.wikipedia.org/wiki/Machine_learning#Approaches Wiki, Supervised learning 监督学习 Wiki, Unsupervised learning 无监督学习 Supervised learning(监督学习) Unsupervised learning(无监督学习) Reinforcement learning(强化学习) etc. Claude 交流：
问：AI 领域，监督学习和无监督学习的区别是是否使用训练集么？
答：（多次问答后的个人总结）
不完全正确。让我来解释监督学习和无监督学习的主要区别:
监督学习和无监督学习的核心区别在于训练数据是否有标签，而不是是否使用训练集。两种方法都需要使用训练数据。
监督学习:
训练数据包含输入特征和对应的标签/答案 例如:图片分类中,每张图片都标注了&amp;quot;猫&amp;quot;或&amp;quot;狗&amp;quot; 算法目标是学习输入到标签的映射关系 常见应用：分类、回归预测 最终目标是：给一张新图片,能准确判断是猫还是狗 无监督学习:
训练数据只有输入特征，没有标签，训练数据是 1000 张动物图片，但没有任何标注 模型会基于图片的相似度(如颜色分布、形状特征等)自动分组 最终可能会将图片分成几类: 一类都是毛茸茸、有尖耳朵的(实际上是猫) 一类都是体型较大、有长嘴的(实际上是狗) 但模型并不知道这些类别的具体含义 算法目标是发现数据中的内在结构和模式 常见应用：聚类分析、降维、异常检测 最终目标是：给一张新图片，能够判断它与哪组已有图片最相似，将它自动归类到相应的组别中 简单来说:</description></item><item><title>Dataset</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset/</guid><description>概述 参考：
TODO: Wiki, 没有 Wiki？ https://docs.lanyingim.com/quest/40_20240615_1_73_1718389635.html Datasete(数据集) 是用于 训练模型、测试模型 的一组特定数据的集合。Dataset 中通常包含两部分内容
Unlabeled data(未标记数据) i.e. 原始数据 Labeled data(已标记数据) 也称为 Annotated data(已标注的数据) 通过数据标注，将 Unlabeled data 变为 Labeled data 后，将这些 Labeled data 打包成 Dataset 供模型训练。
有时候，训练模型并需要已标记的数据，比如 无监督学习、etc. 。
Data annotation(数据注释) 参考：
OpenCV 博客，Data Annotation – A Beginner’s Guide Wiki, Labeled data https://www.amantyatech.com/data-annotation-and-labeling-everything-you-need-to-know AWS，What is Data Labeling? https://toloka.ai/blog/annotation-vs-labeling/ Data annotation(数据注释) 是一组数据中的 信息 Annotation(注释)/Label(标签)。这些 信息注释/标签 在不同的场景下有不同的表示含义，e.g. 一张照片中哪部分是牛，哪部分是马；录音中说了哪些词；视频中正在执行什么类型的动作；新闻文章的主题是什么；推文想要表达的是一种什么情绪；X 光片中的一个点是否是肿瘤；etc. 。
[!Note] 上面例子中标记照片中的牛、马通常用于 Object detection(对象检测) 任务、识别音频中的问题通常用于 语音识别 任务、识别动作通常用于 Pose estimation(姿态评估) 任务、etc.</description></item><item><title>Model</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Model/</guid><description>概述 参考：
Wiki, Machine_learning - Models Wiki, Hyperparameter 执行机器学习涉及创建 Model(模型)，这个模型狭义上指数学模型中的统计模型，是一种数学表示，用于描述和解决特定类型的问题。这些模型可以是各种各样的，包括传统的统计学模型，如线性回归和逻辑回归，也可以是基于神经网络的深度学习模型，如卷积神经网络和循环神经网络。
模型通常由 数学公式、超参数、参数 组成，可以根据给定的输入数据进行训练和调整，以使它们能够在未见过的数据上进行准确预测或分类。因此，AI 领域中的模型本质上是一种数学模型，通过使用数学方法来处理和分析数据，以解决各种问题，如分类、预测、图像处理、自然语言处理等。
数学公式 # 模型的结构通常用数学公式表示，e.g. 线性变换、激活函数、etc. 。e.g. 线性层的计算: $y = Wx + b$ ，其中 W 是权重矩阵，x 是输入向量，b 是偏置。 Hyperparameter(超参数) # 训练和模型架构设置中手动配置的参数，影响模型的性能和训练过程。常见的超参数包括：学习率、批量大小、网络层数和每层的神经元数量、激活函数类型、训练轮数、etc. 。而其他参数（例如节点权重）的值是通过训练得出的。 Parameters(参数) # 模型训练过程中学习到的一系列数值，e.g. 权重、etc. 。它们决定了输入数据如何影响模型的输出。 模型需要训练，训练后得到的模型文件是一系列的权值（权重值），通常是大量(上亿)个浮点数，如果进行了模型量化，也可以是整数。
创建模型 想要创建一个可用的模型，通常至少需要如下几步：
定义模型结构 # 选择模型类型等。比如 nn.Linear(10, 1) 定义了一个简单的全连接层。 TODO：定义损失函数和优化器 # 如交叉熵损失、均方误差，以及优化算法如 SGD、Adam。 激活函数 # 每个神经元应用的非线性函数，用于引入非线性，使模型能够学习复杂的模式。 损失函数 # 用于衡量模型输出与实际目标之间的差异。在训练过程中，模型会尝试最小化损失函数。 标注数据 # 标注数据以生成数据集用以训练模型 训练模型 # 利用数据集训练模型。通过给模型输入数据集和目标，让模型经过计算后调整自身参数（权重）。 保存模型 # 在训练完毕后保存模型，以便后续测试或部署。 暂时先用下面的代码尝试理解一下，随着后续深入学习逐步完善：
import torch from torch import nn # 一、定义模型结构 # Linear() 可以暂时理解为使用 Linear 模型，可以假设模型是 y = xA^T + b； # 10, 1 可以理解为 超参数。也可以简单理解为是在训练模型以检查返回值 fc 是否满足预期 fc = nn.</description></item><item><title>PyTorch</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</guid><description>概述 参考：
GitHub 项目，pytorch/pytorch 官网 PyTorch 是一个使用 Torch 构建的 Python 包，提供两个高级特性：
带有强大 GPU 加速的张量计算（类似于 NumPy） 基于计算图的自动微分系统构建的深度神经网络 安装 PyTorch 参考：
官方文档，开始 安装 PyTorch 分为使用 GPU 和 CPU 两种，比如：
CPU pip3 install torch torchvision torchaudio GPU pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 GPU 版的 PyTorch 依赖 CUDA
Note: 如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：Torch not compiled with CUDA enabled。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。
[!Tip] 若安装速度太慢，可以在 pip install 命令中看到 Downloading 的 URL，手动下载，比如 https://download.</description></item><item><title>Transformers</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</guid><description>概述 参考：
GitHub 项目，huggingface/transformers Wiki, Transformer_(machine_learning_model) Hugging Face 创始人亲述：一个 GitHub 史上增长最快的 AI 项目 官方文档 Transformer 是 Hugging Face 开源的是一种深度学习模型，它采用自注意力机制，对输入数据的每一部分的重要性进行差异加权。它主要用于 自然语言处理(NLP) 和 计算机视觉(CV) 领域。
Transformers 提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。它的宗旨是让最先进的 NLP 技术人人易用。
Transformers 提供了便于快速下载和使用的 API，让你可以把预训练模型用在给定文本、在你的数据集上微调然后通过 model hub 与社区共享。同时，每个定义的 Python 模块均完全独立，方便修改和快速研究实验。
Transformers 支持三个最热门的深度学习库： Jax, PyTorch 以及 TensorFlow — 并与之无缝整合。你可以直接使用一个框架训练你的模型然后用另一个加载和推理。
安装 Transformers 安装 Transformers 本质就是安装 Transformers 的模型，并且还需要一些可以调用模型的代码(通常都是 Python 包)。
Transformers 模型可以对接多种热门的深度学习库：
PyTorch 注意：安装 PyTorch 时，安装 GPU 版的。如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：Torch not compiled with CUDA enabled。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。 TensorFlow 只安装 Transformers</description></item><item><title>深度学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid><description>概述 参考：
Wiki, Deep_learning Deep learning(深度学习) 是机器学习方法家族的一部分，它基于具有表示学习的人工神经网络。学习可以是监督的、半监督的或无监督的。
深度神经网络、深度信念网络、深度强化学习、递归神经网络、卷积神经网络和 Transformer 等深度学习架构已应用于计算机视觉、语音识别、自然语言处理、机器翻译、生物信息学、药物设计等领域、医学图像分析、气候科学、材料检验和棋盘游戏程序，它们在这些方面产生的结果可与人类专家的表现相媲美，在某些情况下甚至超过人类专家的表现
深度学习框架 TensorFlow # 基于 NumPy 构建，谷歌开发
PyTorch # 基于 Torch 构建，Facebook 开发
Paddle，百度飞桨
DeepSpeed 参考：
GitHub 项目，microsoft/DeepSpeed DeepSpeed Chat 一键式RLHF训练，让你的类 ChatGPT 千亿大模型提速省钱15倍</description></item></channel></rss>