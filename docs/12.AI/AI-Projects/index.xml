<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – AI Projects</title><link>https://desistdaydream.github.io/docs/12.AI/AI-Projects/</link><description>Recent content in AI Projects on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/AI-Projects/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: AI Projects</title><link>https://desistdaydream.github.io/docs/12.AI/AI-Projects/AI-Projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/AI-Projects/AI-Projects/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://stability.ai/">https://stability.ai/&lt;/a>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Stability-AI/generative-models">https://github.com/Stability-AI/generative-models&lt;/a> # 补帧，通过静态图片生成动图。&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/labring/FastGPT">labring/FastGPT&lt;/a>&lt;/p>
&lt;ul>
&lt;li>一个快速使用 openai api 的平台。支持一键构建AI知识库，支持多用户、多模型管理。&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/binary-husky/gpt_academic">https://github.com/binary-husky/gpt_academic&lt;/a> # 为 GPT/GLM 等 LLM 大语言模型提供实用化交互接口，特别优化论文阅读/润色/写作体验，模块化设计，支持自定义快捷按钮&amp;amp;函数插件，支持Python 和 C++ 等项目剖析 &amp;amp; 自译解功能，PDF/LaTex 论文翻译&amp;amp;总结功能，支持并行问询多种 LLM 模型，支持 chatglm3 等本地模型。接入通义千问, deepseek coder, 讯飞星火, 文心一言, llama2, rwkv, claude2, moss 等。&lt;/p>
&lt;p>&lt;strong>NovelAI&lt;/strong> # &lt;a href="https://novelai.net/">https://novelai.net/&lt;/a> 写故事、作图&lt;/p>
&lt;p>&lt;strong>ChatGPT&lt;/strong> # &lt;a href="https://chat.openai.com/">https://chat.openai.com/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Bard&lt;/strong>，google # &lt;a href="https://bard.google.com/">https://bard.google.com/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Claude&lt;/strong>，Anthropic # 在 Slack 中创建名为 Claude 的应用。&lt;/p>
&lt;p>&lt;strong>文心一言&lt;/strong>，百度 # &lt;a href="https://yiyan.baidu.com/">https://yiyan.baidu.com/&lt;/a>&lt;/p>
&lt;p>&lt;strong>通义千问&lt;/strong>，阿里 # &lt;a href="https://tongyi.aliyun.com/">https://tongyi.aliyun.com/&lt;/a>&lt;/p>
&lt;h1 id="用于解决复杂任务的-ai">用于解决复杂任务的 AI&lt;a class="td-heading-self-link" href="#%e7%94%a8%e4%ba%8e%e8%a7%a3%e5%86%b3%e5%a4%8d%e6%9d%82%e4%bb%bb%e5%8a%a1%e7%9a%84-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://blog.x-agent.net/blog/xagent/">https://blog.x-agent.net/blog/xagent/&lt;/a>&lt;/p>
&lt;p>虽然开创性项目（e.g., &lt;a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT&lt;/a>, &lt;a href="https://github.com/yoheinakajima/babyagi">BabyAGI&lt;/a>, &lt;a href="https://github.com/camel-ai/camel">CAMEL&lt;/a>, &lt;a href="https://github.com/geekan/MetaGPT">MetaGPT&lt;/a>, &lt;a href="https://github.com/microsoft/autogen">AutoGen&lt;/a>, &lt;a href="https://github.com/stanfordnlp/dspy">DSPy&lt;/a>, &lt;a href="https://github.com/Link-AGI/AutoAgents">AutoAgents&lt;/a>, &lt;a href="https://github.com/xlang-ai/OpenAgents">OpenAgents&lt;/a>, &lt;a href="https://github.com/aiwaves-cn/agents">Agents&lt;/a>, &lt;a href="https://github.com/OpenBMB/AgentVerse">AgentVerse&lt;/a>, &lt;a href="https://github.com/OpenBMB/ChatDev">ChatDev&lt;/a>）已经展示了这个方向的潜力，但完全自主的 AI 代理之旅仍然面临着巨大的挑战。&lt;/p>
&lt;p>&lt;a href="https://github.com/OpenBMB/XAgent">GitHub 项目，OpenBMB/XAgent&lt;/a>&lt;/p>
&lt;ul>
&lt;li>OpenBMB开源社区由清华大学自然语言处理实验室和&lt;a href="https://modelbest.cn/">面壁智能&lt;/a>共同支持发起&lt;/li>
&lt;/ul>
&lt;h1 id="claude">Claude&lt;a class="td-heading-self-link" href="#claude" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/7YJ7B6JTV7U1gXeLOiZsLw">公众号-OSC 开源社区，Anthropic推出 “更理性的 Claude”，正面硬刚ChatGPT&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Anthropic 公司推出的&lt;/p>
&lt;p>Claude 早期可以作为 &lt;a href="https://desistdaydream.github.io/docs/Utils/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1/Slack.md">Slack&lt;/a> 的应用被添加到 Workspace 中并无条件使用。&lt;/p>
&lt;h1 id="deepseek">DeepSeek&lt;a class="td-heading-self-link" href="#deepseek" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/deepseek-ai/DeepSeek-V3">GitHub 项目，deepseek-ai/DeepSeek-V3&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/inference/model.py">https://github.com/deepseek-ai/DeepSeek-V3/blob/main/inference/model.py&lt;/a> 核心&lt;/p>
&lt;p>模型解释: &lt;a href="https://www.bilibili.com/opus/1027408073324494885">B 站 - 秋葉aaaki，动态&lt;/a>&lt;/p></description></item><item><title>Docs: ChatGPT</title><link>https://desistdaydream.github.io/docs/12.AI/AI-Projects/ChatGPT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/AI-Projects/ChatGPT/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://zblogs.top/how-to-register-openai-chatgpt-in-china">https://zblogs.top/how-to-register-openai-chatgpt-in-china&lt;/a>
&lt;ul>
&lt;li>注册 ChatGPT 教程&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>使用虚拟号码接收短信验证码：&lt;a href="https://sms-activate.org/">https://sms-activate.org/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="扩展-chatgpt-的项目">扩展 ChatGPT 的项目&lt;a class="td-heading-self-link" href="#%e6%89%a9%e5%b1%95-chatgpt-%e7%9a%84%e9%a1%b9%e7%9b%ae" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="web-增强">Web 增强&lt;a class="td-heading-self-link" href="#web-%e5%a2%9e%e5%bc%ba" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://github.com/xcanwin/KeepChatGPT">https://github.com/xcanwin/KeepChatGPT&lt;/a> # 让我们在使用 ChatGPT 的时候更顺畅，不会老断，不会老报错&lt;/p>
&lt;h2 id="auto-gpt">Auto GPT&lt;a class="td-heading-self-link" href="#auto-gpt" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Torantulino/Auto-GPT">GitHub 项目，Torantulino/Auto-GPT&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1HV4y1Z7dm">https://www.bilibili.com/video/BV1HV4y1Z7dm&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Auto-GPT 是一个实验性开源应用程序，展示了 GPT-4 语言模型的功能。该程序由 GPT-4 驱动，将 LLM 的“思想”链接在一起，以自主实现您设定的任何目标。作为 GPT-4 完全自主运行的首批示例之一，Auto-GPT 突破了 AI 的可能性界限。&lt;/p>
&lt;p>用白话说，就是根据一个给定的目标，在没有人为干预的情况下自动完成，比如自动生成一整个项目，Auto GPT 会自动创建目录与文件，并逐步实现最终目标。&lt;/p>
&lt;p>这里是一个类似 Auto GPT 的项目，但是可以通过 web 控制：&lt;a href="https://github.com/reworkd/AgentGPT">https://github.com/reworkd/AgentGPT&lt;/a>&lt;/p>
&lt;ul>
&lt;li>OPENAI_API_KEY # 来源: &lt;a href="https://platform.openai.com/account/api-keys">https://platform.openai.com/account/api-keys&lt;/a>&lt;/li>
&lt;li>GOOGLE_API_KEY=XXXXXX # 来源: &lt;a href="https://console.cloud.google.com/apis/credentials?project=manifest-pulsar-287701">https://console.cloud.google.com/apis/credentials?project=manifest-pulsar-287701&lt;/a>
&lt;ul>
&lt;li>CUSTOM_SEARCH_ENGINE_ID=YYYY # 来源: &lt;a href="https://console.cloud.google.com/apis/api/customsearch.googleapis.com/metrics?project=manifest-pulsar-287701">https://console.cloud.google.com/apis/api/customsearch.googleapis.com/metrics?project=manifest-pulsar-287701&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://programmablesearchengine.google.com/controlpanel/all">https://programmablesearchengine.google.com/controlpanel/all&lt;/a> 添加搜索引擎并获取 ID&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>PINECONE_API_KEY # 来源: &lt;a href="https://app.pinecone.io/">https://app.pinecone.io/&lt;/a>&lt;/li>
&lt;li>HUGGINGFACE_API_TOKEN # 来源: &lt;a href="https://huggingface.co/settings/tokens">https://huggingface.co/settings/tokens&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="chrom-插件">Chrom 插件&lt;a class="td-heading-self-link" href="#chrom-%e6%8f%92%e4%bb%b6" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://github.com/gragland/chatgpt-chrome-extension">https://github.com/gragland/chatgpt-chrome-extension&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://chrome.google.com/webstore/detail/monica-%E2%80%94-your-chatgpt-cop/ofpnmcalabcbjgholdjcjblkibolbppb">https://chrome.google.com/webstore/detail/monica-%E2%80%94-your-chatgpt-cop/ofpnmcalabcbjgholdjcjblkibolbppb&lt;/a>&lt;/p>
&lt;h3 id="chatgpt-box">ChatGPT Box&lt;a class="td-heading-self-link" href="#chatgpt-box" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://github.com/josStorer/chatGPTBox/">GitHub 项目，josStorer/chatGPTBox&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.bilibili.com/video/BV1524y1x7io">https://www.bilibili.com/video/BV1524y1x7io&lt;/a>&lt;/p>
&lt;h2 id="ide-增强">IDE 增强&lt;a class="td-heading-self-link" href="#ide-%e5%a2%9e%e5%bc%ba" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="vscode-chatgpt">vscode-chatgpt&lt;a class="td-heading-self-link" href="#vscode-chatgpt" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/gencay/vscode-chatgpt">GitHub 项目，gencay/vscode-chatgpt&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>vscode-chatgpt 是一个 VS Code 插件。&lt;/p>
&lt;p>凸(艹皿艹 )，居然停用了。&lt;a href="https://github.com/gencay/vscode-chatgpt/issues/239">https://github.com/gencay/vscode-chatgpt/issues/239&lt;/a>&lt;/p>
&lt;p>3月19日，有人 fork 后并构建了一个新的插件：&lt;a href="https://github.com/Christopher-Hayes/vscode-chatgpt-reborn">https://github.com/Christopher-Hayes/vscode-chatgpt-reborn&lt;/a>&lt;/p>
&lt;h2 id="结合私有知识库">结合私有知识库&lt;a class="td-heading-self-link" href="#%e7%bb%93%e5%90%88%e7%a7%81%e6%9c%89%e7%9f%a5%e8%af%86%e5%ba%93" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="docsgpt">DocsGPT&lt;a class="td-heading-self-link" href="#docsgpt" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/arc53/DocsGPT">GitHub 项目，arc53/DocsGPT&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/HJ1LHGCjPL0qjf8e7bMLjg">公众号-云原生实验室，我让 ChatGPT 化身为全知全能的文档小助理&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://github.com/yangchuansheng/DocsGPT">https://github.com/yangchuansheng/DocsGPT&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>DocsGPT 是 GPT 驱动的聊天，用于文档搜索和帮助。&lt;/p>
&lt;h3 id="chatdoc">ChatDoc&lt;a class="td-heading-self-link" href="#chatdoc" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>官网：https://chatdoc.com/&lt;/p>
&lt;h2 id="chatpdf">ChatPDF&lt;a class="td-heading-self-link" href="#chatpdf" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://www.chatpdf.com/">https://www.chatpdf.com/&lt;/a>&lt;/p>
&lt;h2 id="微信接入">微信接入&lt;a class="td-heading-self-link" href="#%e5%be%ae%e4%bf%a1%e6%8e%a5%e5%85%a5" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://github.com/fuergaosi233/wechat-chatgpt">https://github.com/fuergaosi233/wechat-chatgpt&lt;/a>&lt;/p>
&lt;ul>
&lt;li>用法：https://mp.weixin.qq.com/s/dLzemMUcIfjvWd_AF_yDJw&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/AutumnWhj/ChatGPT-wechat-bot">https://github.com/AutumnWhj/ChatGPT-wechat-bot&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/wangrongding/wechat-bot">https://github.com/wangrongding/wechat-bot&lt;/a>&lt;/p>
&lt;h2 id="逆向">逆向&lt;a class="td-heading-self-link" href="#%e9%80%86%e5%90%91" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://github.com/acheong08/ChatGPT">https://github.com/acheong08/ChatGPT&lt;/a>&lt;/p>
&lt;h2 id="简单的-web-页面">简单的 web 页面&lt;a class="td-heading-self-link" href="#%e7%ae%80%e5%8d%95%e7%9a%84-web-%e9%a1%b5%e9%9d%a2" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://huggingface.co/spaces/yuntian-deng/ChatGPT">https://huggingface.co/spaces/yuntian-deng/ChatGPT&lt;/a> 好像是不用 OpenAI key 就能调用 GPT-3.5 的 ChatGPT。&lt;/p>
&lt;p>&lt;a href="https://github.com/GaiZhenbiao/ChuanhuChatGPT">https://github.com/GaiZhenbiao/ChuanhuChatGPT&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/Chanzhaoyu/chatgpt-web">https://github.com/Chanzhaoyu/chatgpt-web&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/ourongxing/chatgpt-vercel">https://github.com/ourongxing/chatgpt-vercel&lt;/a>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/CODEisArrrt/chatgpt-dark">https://github.com/CODEisArrrt/chatgpt-dark&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="其他">其他&lt;a class="td-heading-self-link" href="#%e5%85%b6%e4%bb%96" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://github.com/lencx/nofwl">https://github.com/lencx/nofwl&lt;/a> # 桌面版&lt;/p>
&lt;p>&lt;a href="https://github.com/lencx/ChatGPT">https://github.com/lencx/ChatGPT&lt;/a> # 桌面版&lt;/p>
&lt;p>&lt;a href="https://github.com/didiplus/ChatGPT_web">https://github.com/didiplus/ChatGPT_web&lt;/a> # 像微信聊天一样跟 ChatGPT 聊天&lt;/p>
&lt;p>&lt;a href="https://github.com/microsoft/visual-chatgpt">https://github.com/microsoft/visual-chatgpt&lt;/a> # 微软官方可以生成和上传图片&lt;/p></description></item><item><title>Docs: YOLO</title><link>https://desistdaydream.github.io/docs/12.AI/AI-Projects/Yolo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/AI-Projects/Yolo/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/ultralytics">GitHub 组织，ultralytics&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/ultralytics/ultralytics">GitHub 项目，ultralytics/ultralytics&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/ultralytics/assets">GitHub 项目，ultralytics/assets&lt;/a> Ultralytics 的模型、数据集、etc. 资产&lt;/li>
&lt;li>&lt;a href="https://www.ultralytics.com/">ultralytics 官网&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/@gary.tsai.advantest/yolo-%E7%B3%BB%E5%88%97%E5%A4%A7%E8%A3%9C%E5%B8%96-yolov7-b1ce83a7035">YOLO 的歷史進程！YOLO 大補帖！&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1sCtHewEw7">https://www.bilibili.com/video/BV1sCtHewEw7&lt;/a> v8 与 v10 的选择，为什么不要用 v10 而是用 v8，为什么 v10 的检测效果不好&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://arxiv.org/abs/1506.02640">YOLO&lt;/a>(You Only Look Once）是一种流行的物体检测和图像分割模型，由华盛顿大学的约瑟夫-雷德蒙（Joseph Redmon）和阿里-法哈迪（Ali Farhadi）开发。YOLO 于 2015 年推出，因其高速度和高精确度而迅速受到欢迎。&lt;/p>
&lt;p>2015 年 &lt;em>Joseph Redmon&lt;/em> 提出的 YOLO 橫空出世，从诞生的那一刻起就标榜「高精度」、「高效率」、「高实用性」，為 One-Stage 方法在物体侦测演算法里拉开序幕。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>YOLOv1&lt;/strong> (2016) Joseph Redmon
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/longcw/yolo2-pytorch">&lt;strong>YOLOv2&lt;/strong>&lt;/a> (2017) Joseph Redmon
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/1612.08242">YOLO9000: Better, Faster, Stronger&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/ultralytics/yolov3">&lt;strong>YOLOv3&lt;/strong>&lt;/a> (2018) Joseph Redmon
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/1804.02767">YOLOv3: An Incremental Improvement&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>突发
&lt;ul>
&lt;li>然而，2020 年 &lt;em>约瑟夫·雷德蒙&lt;/em> 突然投下一枚重磅炸弹，他受够 YOLO 不断被运用在军事应用以及个人隐私，宣布停止电脑视觉相关的研究。&lt;/li>
&lt;li>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ai/yolo/202410151103187.png" alt="https://x.com/pjreddie/status/1230524770350817280|400">&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/AlexeyAB/darknet">&lt;strong>YOLOv4&lt;/strong>&lt;/a> (2020) Alexey Bochkovskiy
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2004.10934">YOLOv4: Optimal Speed and Accuracy of Object Detection&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/ultralytics/yolov5">&lt;strong>YOLOv5&lt;/strong>&lt;/a> 进一步提高了模型的性能，并增加了超参数优化、集成实验跟踪和自动导出为常用导出格式等新功能。&lt;/li>
&lt;li>&lt;a href="https://github.com/meituan/YOLOv6">&lt;strong>YOLOv6&lt;/strong>&lt;/a> (2022) 由&lt;a href="https://about.meituan.com/">美团&lt;/a>开源，目前已用于该公司的许多自主配送机器人。
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2209.02976">YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/WongKinYiu/yolov7">&lt;strong>YOLOv7&lt;/strong>&lt;/a> 增加了额外的任务，如 COCO 关键点数据集的姿势估计
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2301.05586">YOLOv6 v3.0: A Full-Scale Reloading&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://arxiv.org/abs/2207.02696">YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://pypi.org/project/ultralytics/8.0.0/">&lt;strong>YOLOv8&lt;/strong>&lt;/a> (2023-01) 由 Ultralytics 提供。YOLOv8 支持全方位的视觉 AI 任务，包括&lt;a href="https://docs.ultralytics.com/tasks/detect/">检测&lt;/a>、&lt;a href="https://docs.ultralytics.com/tasks/segment/">分割&lt;/a>、&lt;a href="https://docs.ultralytics.com/tasks/pose/">姿态估计&lt;/a>、&lt;a href="https://docs.ultralytics.com/modes/track/">跟踪&lt;/a>和&lt;a href="https://docs.ultralytics.com/tasks/classify/">分类&lt;/a>。这种多功能性使用户能够在各种应用和领域中利用 YOLOv8 的功能。&lt;/li>
&lt;li>&lt;a href="https://github.com/WongKinYiu/yolov9">&lt;strong>YOLOv9&lt;/strong>&lt;/a> (2024) 由原YOLOv7团队打造，引入了可编程梯度信息 （PGI） 和广义高效层聚合网络 （GELAN） 等创新方法。
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2402.13616">YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/THU-MIG/yolov10">&lt;strong>YOLOv10&lt;/strong>&lt;/a> (2024) 是由清华大学的研究人员使用 Ultralytics Python 包创建的。该版本通过引入消除非极大值抑制 (NMS) 要求的端到端头，提供了实时对象检测方面的改进。
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2405.14458">YOLOv10: Real-Time End-to-End Object Detection&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>YOLO11&lt;/li>
&lt;/ul>
&lt;h1 id="训练">训练&lt;a class="td-heading-self-link" href="#%e8%ae%ad%e7%bb%83" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://docs.ultralytics.com/modes/train/">https://docs.ultralytics.com/modes/train/&lt;/a>&lt;/p>
&lt;p>训练前需要准备如下内容：&lt;/p>
&lt;ul>
&lt;li>data.yaml 文件&lt;/li>
&lt;li>dataset&lt;/li>
&lt;/ul>
&lt;p>最基本的训练代码如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">ultralytics&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">YOLO&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 加载预训练模型（建议用于训练）&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">YOLO&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;yolo11n.pt&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># 训练模型。指定 coco.yaml 为 data.yaml。训练周期 100，TODO: 640 是干什么的？好像是图片大小？&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">results&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">model&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">train&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">data&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;coco.yaml&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">epochs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">imgsz&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">640&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="数据集">数据集&lt;a class="td-heading-self-link" href="#%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.ultralytics.com/datasets/">https://docs.ultralytics.com/datasets/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.ultralytics.com/datasets/#contribute-new-datasets">https://docs.ultralytics.com/datasets/#contribute-new-datasets&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Ultralytics 提供对各类 &lt;strong>Dataset(数据集)&lt;/strong> 的支持，以便进行计算机视觉任务，如 对象检测、实例分割、姿态估计、分类、多目标跟踪、etc.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="#Object%20detection">Object detection&lt;/a>(对象检测) 数据集&lt;/strong> # 通过在每个对象周围绘制边界框来检测和定位图像中的对象。&lt;/li>
&lt;li>&lt;strong>&lt;a href="#Instance%20segmentation">Instance segmentation&lt;/a>(实例分割) 数据集&lt;/strong> # 在像素级别识别和定位图像中的对象。Object detection 在识别到对象后是用矩形框框起来的，而 Instance segmentation 则是在识别到对象的基础上，在像素级别对物体进行染色&lt;/li>
&lt;li>&lt;strong>&lt;a href="#Pose%20estimation">Pose estimation&lt;/a>(姿态估计) 数据集&lt;/strong> # 在识别到对象后，识别对象的姿态。&lt;/li>
&lt;li>etc.&lt;/li>
&lt;/ul>
&lt;p>Ultralytics YOLO 的 检测、分段、姿势 模型在 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset.md#COCO">COCO&lt;/a> 数据集上预训练，而 分类 模型在 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset.md#ImageNet">ImageNet&lt;/a> 数据集上预训练。&lt;/p>
&lt;h2 id="创建自己的数据集">创建自己的数据集&lt;a class="td-heading-self-link" href="#%e5%88%9b%e5%bb%ba%e8%87%aa%e5%b7%b1%e7%9a%84%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://docs.ultralytics.com/datasets/#contribute-new-datasets">https://docs.ultralytics.com/datasets/#contribute-new-datasets&lt;/a>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Collect Images(收集图像)&lt;/strong> # 收集用于训练的图像。&lt;/li>
&lt;li>&lt;strong>Annotate Images(注释图像)&lt;/strong> # 根据想要训练的任务，使用 边界框、片段、关键点 为图像添加注释。人话：&lt;strong>数据标注&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Export Annotations(导出注释)&lt;/strong> # 将这些注释转换为 Ultralytics 支持的 YOLO &lt;code>*.txt&lt;/code> 文件格式。&lt;/li>
&lt;li>&lt;strong>Organize Dataset(组织数据集)&lt;/strong> # 将图像、注释以如下目录结构存放。应该有 images/ 和 labels/ 顶级目录，并在每个目录中都有一个 train/ 和 val/ 子目录。 images 存放收集到的图像，labels 存放导出的注释。images/ 下的如果有 000000000009.jpg 文件，那对应的 labels/ 下应该有个同名不同后缀的 000000000009.txt 文件。
&lt;ol>
&lt;li>Notes: 这个目录结构在由于实际情况可能有的类型的数据集并不完全相同，基于数据组织的便利性，可能会把 train/ 和 val/ 放在顶级目录，下级目录可能是以对象类型命名。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>datasets/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>└── coco8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── images
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── train
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   ├── 000000000009.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   └── 000000000034.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── val
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000036.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── 000000000061.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> └── labels
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── train
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000009.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── 000000000034.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> └── val
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    ├── 000000000036.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── 000000000061.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="5">
&lt;li>&lt;strong>创建 &lt;code>data.yaml&lt;/code> 文件&lt;/strong> # 创建一个描述数据集、类和其他必要信息的 &lt;a href="#data.yaml">data.yaml&lt;/a> 文件。&lt;/li>
&lt;li>&lt;strong>Optimize Images(优化图像)(可选的)&lt;/strong> # 如果您想减小数据集的大小以提高处理效率，可以使用以下代码优化图像。这不是必需的，但建议用于较小的数据集大小和更快的下载速度。&lt;/li>
&lt;li>&lt;strong>压缩数据集&lt;/strong> # 将整个数据集文件夹压缩为 zip 文件。&lt;/li>
&lt;li>&lt;strong>Document and PR&lt;/strong> # 创建一个文档页面来描述数据集以及它如何适应现有框架。之后，提交 Pull Request (PR)。有关如何提交 PR 的更多详细信息，请参阅 &lt;a href="https://docs.ultralytics.com/help/contributing/">Ultralytics 贡献指南&lt;/a>。&lt;/li>
&lt;/ol>
&lt;p>第 6 和 7 步，ultralytics 提供了函数可以直接使用代码处理。通过遵循这些步骤，可以提供一个与 Ultralytics 现有结构良好集成的新数据集&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">pathlib&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">Path&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">ultralytics.data.utils&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">compress_one_image&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">ultralytics.utils.downloads&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">zip_directory&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># Define dataset directory&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">path&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">Path&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;path/to/dataset&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># Optimize images in dataset (optional)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#000">f&lt;/span> &lt;span style="color:#204a87;font-weight:bold">in&lt;/span> &lt;span style="color:#000">path&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">rglob&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;*.jpg&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">):&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">compress_one_image&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">f&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># Zip dataset into &amp;#39;path/to/dataset.zip&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">zip_directory&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">path&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="datayaml">data.yaml&lt;a class="td-heading-self-link" href="#datayaml" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>data.yaml 时 Ultralytics YOLO 数据集使用的 &lt;a href="https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/YAML.md">YAML&lt;/a> 格式文件，可以定义数据集所在目录、训练、验证、测试 图像目录、数据集中对象分类的字典。在 &lt;a href="https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/datasets">这里&lt;/a> 找到各类数据集的 data.yaml。&lt;/p>
&lt;blockquote>
&lt;p>Notes: data.yaml 是一种抽象的叫法，本质就是配置文件。各种数据集使用 data.yaml 时，可以指定任意名称但只要符合文件内容格式的 YAML 文件。&lt;/p>
&lt;/blockquote>
&lt;p>e.g. 对象检测 类型的数据集配置通常是下面这样的：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">path&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">../datasets/coco8&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic"># 数据集根目录&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">train&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">images/train&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic"># 相对于 path 的训练目录&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">val&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">images/val&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic"># 相对于 path 的验证目录&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">test&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic"># （可选的）相对于 path 的测试目录&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># 类型&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">names&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">person&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic"># ......略&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">5&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">bus&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic"># ......略&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">79&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">toothbrush&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>下图是使用上面示例的 data.yaml 训练后模型识别的结果，可以看到有 person 和 bus，并不是单纯的数字了，在右边官网&lt;a href="https://docs.ultralytics.com/datasets/detect/coco/#sample-images-and-annotations">示例图片&lt;/a>中，识别出的对象都是&lt;strong>数字注释&lt;/strong>的。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ai/yolo/detected_bus.png" alt="400">&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ai/yolo/mosaiced-coco-dataset-sample.jpg" alt="400">&lt;/p>
&lt;p>当我们训练模型时，下面代码就会指定要使用的 data.yaml 文件（这示例的 data.yaml 名为 coco.yaml）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87;font-weight:bold">from&lt;/span> &lt;span style="color:#000">ultralytics&lt;/span> &lt;span style="color:#204a87;font-weight:bold">import&lt;/span> &lt;span style="color:#000">YOLO&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># Load a model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">YOLO&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;yolo11n.pt&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#8f5902;font-style:italic"># load a pretrained model (recommended for training)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#8f5902;font-style:italic"># Train the model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">results&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">model&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">train&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">data&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;coco.yaml&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">epochs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">imgsz&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">640&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后根据 data.yaml 中的 path、train、val 定义的路径，从目录中读取 图像文件 及 图像注释文件。这些文件组织结构像这样：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>datasets/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>└── coco8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── images
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── train
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   ├── 000000000009.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   └── 000000000034.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── val
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000036.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── 000000000061.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> └── labels
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── train
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000009.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── 000000000034.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> └── val
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    ├── 000000000036.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── 000000000061.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="数据集种类">数据集种类&lt;a class="td-heading-self-link" href="#%e6%95%b0%e6%8d%ae%e9%9b%86%e7%a7%8d%e7%b1%bb" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="object-detection">Object detection&lt;a class="td-heading-self-link" href="#object-detection" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://docs.ultralytics.com/datasets/detect/">https://docs.ultralytics.com/datasets/detect/&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object%20detection.md">Object detection&lt;/a>(对象检测)&lt;/p>
&lt;p>images 是图片，labels 图片的标签&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>datasets/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>└── coco8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── LICENSE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── README.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── images
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── train
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   ├── 000000000009.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   ├── 000000000025.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   ├── 000000000030.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   │   └── 000000000034.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── val
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000036.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000042.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000049.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── 000000000061.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> └── labels
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── train
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000009.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000025.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000030.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── 000000000034.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── train.cache
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ├── val
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000036.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000042.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   ├── 000000000049.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> │   └── 000000000061.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> └── val.cache
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>label 是对应相同文件名的图片中的 ROI，共 5 个数字&lt;/p>
&lt;ul>
&lt;li>ROI 类型&lt;/li>
&lt;li>ROI 左上角 x 轴坐标&lt;/li>
&lt;li>ROI 左上角 y 轴坐标&lt;/li>
&lt;li>ROI 右下角 x 轴坐标&lt;/li>
&lt;li>ROI 右下角 y 轴坐标&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># cat datasets/coco8/labels/train/000000000025.txt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">23&lt;/span> 0.770336 0.489695 0.335891 0.697559
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">23&lt;/span> 0.185977 0.901608 0.206297 0.129554
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="instance-segmentation">Instance segmentation&lt;a class="td-heading-self-link" href="#instance-segmentation" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://docs.ultralytics.com/datasets/segment/">https://docs.ultralytics.com/datasets/segment/&lt;/a>&lt;/p>
&lt;h2 id="pose-estimation">Pose estimation&lt;a class="td-heading-self-link" href="#pose-estimation" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://docs.ultralytics.com/datasets/pose/">https://docs.ultralytics.com/datasets/pose/&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose%20estimation.md">Pose estimation&lt;/a>(姿态估计)&lt;/p>
&lt;p>YAML 格式 &lt;a href="https://docs.ultralytics.com/datasets/pose/#dataset-yaml-format">https://docs.ultralytics.com/datasets/pose/#dataset-yaml-format&lt;/a>&lt;/p>
&lt;h1 id="模型">模型&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.ultralytics.com/models/">ultralytics 文档，模型&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://docs.ultralytics.com/models/yolov10/#model-variants">https://docs.ultralytics.com/models/yolov10/#model-variants&lt;/a>&lt;/p>
&lt;p>Ultralytics 的 YOLO 有多种模型规模，以满足不同的应用需求：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>YOLO-N&lt;/strong> # &lt;strong>Nano&lt;/strong> 适用于资源极其有限的环境的。适合移动设备和快速测试&lt;/li>
&lt;li>&lt;strong>YOLO-S&lt;/strong> # &lt;strong>Small&lt;/strong> 平衡速度和准确性的小型版本。适合嵌入式设备和一般性测试&lt;/li>
&lt;li>&lt;strong>YOLO-M&lt;/strong> # &lt;strong>Medium&lt;/strong> 用于通用用途。&lt;/li>
&lt;li>&lt;strong>YOLO-B&lt;/strong> # &lt;strong>Balanced&lt;/strong> 增加宽度以提高精度。&lt;/li>
&lt;li>&lt;strong>YOLO-L&lt;/strong> # &lt;strong>Large&lt;/strong> 增加计算资源为代价获得更高的精度。&lt;/li>
&lt;li>&lt;strong>YOLO-X&lt;/strong> # &lt;strong>Extra-large&lt;/strong> 可实现最大精度和性能。适合服务器处理高精度任务&lt;/li>
&lt;/ul>
&lt;h1 id="关联文件与配置">关联文件与配置&lt;a class="td-heading-self-link" href="#%e5%85%b3%e8%81%94%e6%96%87%e4%bb%b6%e4%b8%8e%e9%85%8d%e7%bd%ae" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>%APPDATA%/Ultralytics/&lt;/strong> # Ultralytics 出的 YOLO 模型在使用时保存的 字体、配置 所在目录&lt;/p>
&lt;ul>
&lt;li>&lt;strong>./settings.json&lt;/strong> # 有一些保存文件的目录配置。&lt;/li>
&lt;/ul>
&lt;h1 id="cli">CLI&lt;a class="td-heading-self-link" href="#cli" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://docs.ultralytics.com/usage/cli/">https://docs.ultralytics.com/usage/cli/&lt;/a>&lt;/p>
&lt;h2 id="syntax语法">Syntax(语法)&lt;a class="td-heading-self-link" href="#syntax%e8%af%ad%e6%b3%95" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;strong>SubCommand&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>train&lt;/strong> # Train(训练) 模型&lt;/li>
&lt;li>&lt;strong>predict&lt;/strong> # 使用经过训练的 YOLO11n 模型对图像进行 predictions(预测)。&lt;/li>
&lt;li>&lt;strong>val&lt;/strong> # 在 COCO8 数据集上 Validate(验证) 经过训练的 YOLO11n 模型的准确性。不需要参数，因为模型保留其训练数据和参数作为模型属性。&lt;/li>
&lt;li>&lt;strong>export&lt;/strong> # 将 YOLO11n 模型导出为不同的格式，例如 ONNX、CoreML、etc. 。&lt;/li>
&lt;/ul>
&lt;h1 id="最佳实践">最佳实践&lt;a class="td-heading-self-link" href="#%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=7YRJIAIhMpw">https://www.youtube.com/watch?v=7YRJIAIhMpw&lt;/a>&lt;/p></description></item></channel></rss>