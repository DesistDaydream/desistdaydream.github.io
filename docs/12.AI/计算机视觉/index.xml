<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>计算机视觉 on 断念梦的站点</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><description>Recent content in 计算机视觉 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.xml" rel="self" type="application/rss+xml"/><item><title>计算机视觉</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</guid><description>概述 参考：
Wiki, Computer vision Wiki 类别，Computer vision Wiki 类别，Applications of computer vision Computer vision(计算机视觉) 任务包括获取、处理、分析和理解数字图像的方法，以及从现实世界中提取高维数据以产生数字或符号信息的方法，例如以决定的形式。 在这种情况下，理解意味着将视觉图像（视网膜的输入）转化为对思维过程有意义并可以引发适当行动的世界描述。这种图像理解可以看作是使用借助几何、物理学、统计学和学习理论构建的模型从图像数据中分离出符号信息。
视觉模型 YOLO
Segment Anything Model 这个怎么样？
etc.
Halcon 与 OpenCV OpenCV Halcon 开发语言 C++、C#（emgu）、Python、Ruby、MATLAB等语言 C，C++，C#，Visual basic和Delphi等语言 应用场合 侧重计算机视觉领域，侧重研究领域 侧重机器视觉领域，侧重应用领域 费用 免费 收费 开放性及版本更新速度 开源（可看底层源码），版本和功能更新慢 商业软件（底层代码封装），版本和功能更新快 对使用者的门槛 偏科研，有难度，有深度，完全从底层开发，对使用者门槛高，开发效率低，开发慢 偏工程应用，使用封装好的功能函数，对使用者门槛低，开发效率高，开发快 资料及技术支持 资料少。遇到问题，难以获得技术支持 资料多。遇到问题，可以及时、有效的获得技术支持 学习资料 B 站，唐宇迪，【唐宇迪AI分享】CV和NLP两大板块一定要先选CV！！！
Tasks 计算机视觉任务通常包括 Object detection、Keypoint detection、Pose estimation、etc.</description></item><item><title>Dataset</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Dataset/</guid><description>概述 参考：
https://opencv.org/blog/data-annotation/ Data annotations 参考：
OpenCV 博客，Data Annotation – A Beginner’s Guide 计算机视觉 中的数据注释常见如下几种：
Bounding box Segmentation KeyPoint Lines and Splines etc. TODO 下图中各种颜色的方框都是注释（数字代码是在模型训练时由数据集配置文件中定义其含义），通过 Object detection 识别出对象并添加对象注释
下图的注释除了有检测到的对象外，还有对象的姿态。识别出对象后，再通过 Pose estimation 进行姿态估计并添加姿态注释
上面只是用两种类型举例，还有很多其他的注释类型，这些都属于图像的 Annotations(注释)
Bounding box 参考：
https://www.ultralytics.com/glossary/bounding-box https://encord.com/glossary/bounding-box-definition/ Bounding box(边界框) 也称为 Bounding volume 或 Bounding region，是一种 几何形状 的 Label，用于在数字图像中包围或环绕一个或一组对象。Bounding box 的目的是在2D 或 3D 空间中定义对象的位置和大小，以执行各种 CV 任务，e.g. 对象检测、分割、分类。这是 CV 领域的基本概念，特别是在涉及图像和视频分析的应用中。
在 2D 图像中，Bounding box 通常用矩形表示，其长边与图像的 x 轴和 y 轴平行。矩形的大小由 x 轴和 y 轴的最小值和最大值决定，这些值由矩形的角坐标指定。矩形的大小和中心点也可用于创建 enclosing box(封闭框)。</description></item><item><title>Keypoint detection</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Keypoint-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Keypoint-detection/</guid><description>概述 参考：
https://blog.roboflow.com/what-is-keypoint-detection/ Keypoint detection(关键点监测) 可用来进行 Pose estimation 和 Facial recognition(面部识别)
Notes: 某些可以利用 Keypoint detection 实现的任务，并不止局限于这一种。还有可能有其他方式实现，比如面部识别不一定需要依赖关键点监测。</description></item><item><title>Object detection</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object-detection/</guid><description>概述 参考：
Wiki, Object detection Ultralytics 文档，术语 - 对象监测 Google 学术 https://scholar.google.com/scholar?q=Object+detection&amp;hl=zh-CN&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart Object detection(对象检测) 是一种与计算机视觉和图像处理相关的计算机技术，用于检测数字图像和视频中特定类别（例如人类、建筑物或汽车）的语义对象的实例。
Image Classification(图像分类) # 确定图像中是否存在特定对象。
Bounding Box(边界框) # 用于突出显示图像中对象的位置的矩形。它由坐标 (x, y)、宽度和高度定义。
对象监测架构 One-Stage Detectors(单级检测器) 例如 YOLO、SSD：一步执行对象定位和分类，提供更快的推理速度，但有时会牺牲准确性。
Two-Stage Detectors(两阶段检测器) （例如 Faster R-CNN）：涉及区域提议阶段，然后进行对象分类，通常可以实现更高的准确度，但推理时间可能会更慢。</description></item><item><title>OCR</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</guid><description>概述 参考：
Wiki, Optical_character_recognition https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/models.md Optical character recognition(光学字符识别，简称 OCR) 是将图像以电子或机械方式转换为机器编码文本，无论是来自扫描文档、文档照片、场景照片、叠加在图像上的字母文字等。目前是文字识别的统称，已不限于文档或书本文字识别，更包括识别自然场景下的文字，又可以称为 Scene Text Recognition(场景文字识别，简称 STR)。
OCR 文字识别一般包括两个部分，文本检测和文本识别
文本检测首先利用检测算法检测到图像中的文本块 然后文本识别利用识别算法去识别文本块中的具体文字 Detection Model(检测模型) 文本检测就是要定位图像中的文字区域，然后通常以边界框的形式将单词或文本行标记出来。传统的文字检测算法多是通过手工提取特征的方式，特点是速度快，简单场景效果好，但是面对自然场景，效果会大打折扣。当前多是采用深度学习方法来做。
基于深度学习的文本检测算法可以大致分为以下几类：
基于目标检测的方法；一般是预测得到文本框后，通过NMS筛选得到最终文本框，多是四点文本框，对弯曲文本场景效果不理想。典型算法为EAST、Text Box等方法。 基于分割的方法；将文本行当成分割目标，然后通过分割结果构建外接文本框，可以处理弯曲文本，对于文本交叉场景问题效果不理想。典型算法为DB、PSENet等方法。 混合目标检测和分割的方法； Recognition Model(识别模型) OCR 识别算法的输入数据一般是文本行，背景信息不多，文字占据主要部分，识别算法目前可以分为两类算法：
基于 CTC 的方法；即识别算法的文字预测模块是基于 CTC 的，常用的算法组合为 CNN+RNN+CTC。目前也有一些算法尝试在网络中加入 transformer 模块等等。 基于 Attention 的方法；即识别算法的文字预测模块是基于 Attention 的，常用算法组合是 CNN+RNN+Attention 预处理 为了可以让程序快速检测到字符块后精准识别字符，有的时候还需要对图片进行预处理
比如图片是斜的，我们可以把图片正过来 若是图片有干扰，可以去掉干扰 等等&amp;hellip;&amp;hellip; 总结 用稍微简单一些的话说，检测模型用来检查一个图片中，哪些地方可以被识别模型识别；然后交给识别模型。若将图片直接交给识别模型，那么是无法获得任何结果的
用 PaddleOCR 的识别识别逻辑举例，至少需要用到两种模型：文本检测模型 和 文本识别模型。提供给 PaddleOCR 一张图后，首先先检测图片中包含的文字信息并定位为文本框，然后识别文本框中的文本。
Tips: 若想要识别倒转的文字，还可以通过 方向分类器 模型进行预处理。有的 OCR 程序还有很多其他的预处理操作，比如去斑、二值化、线条去除、布局分析 等等。
如下图：
用红框框起来的就是检测到的文本框，每个文本框都由 [[196.0, 10.0], [237.0, 10.</description></item><item><title>Pose estimation</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose-estimation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose-estimation/</guid><description>概述 参考：
Wiki, Pose Wiki, 3D pose estimation 通过 Object detection 检测到对象后，利用 Pose estimation(姿态估计) 确定对象的位置和方向，通常是在三维空间中。姿态通常以变换矩阵的形式在内部存储。术语 pose(姿态) 在很大程度上与 transform(变换) 同义，但 transform 常常包含 缩放，而姿态通常不包含。</description></item></channel></rss>