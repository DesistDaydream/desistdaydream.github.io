<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>断念梦的站点 – 计算机视觉</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><description>Recent content in 计算机视觉 on 断念梦的站点</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 计算机视觉</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Computer_vision">Wiki, Computer vision&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Category:Computer_vision">Wiki 类别，Computer vision&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Category:Applications_of_computer_vision">Wiki 类别，Applications of computer vision&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Computer vision(计算机视觉)&lt;/strong> 任务包括获取、处理、分析和理解数字图像的方法，以及从现实世界中提取高维数据以产生数字或符号信息的方法，例如以决定的形式。 在这种情况下，理解意味着将视觉图像（视网膜的输入）转化为对思维过程有意义并可以引发适当行动的世界描述。这种图像理解可以看作是使用借助几何、物理学、统计学和学习理论构建的模型从图像数据中分离出符号信息。&lt;/p>
&lt;h1 id="视觉模型">视觉模型&lt;a class="td-heading-self-link" href="#%e8%a7%86%e8%a7%89%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://desistdaydream.github.io/docs/12.AI/AI%20Projects/YOLO.md">YOLO&lt;/a>&lt;/p>
&lt;p>Segment Anything Model 这个怎么样？&lt;/p>
&lt;p>etc.&lt;/p>
&lt;h1 id="halcon-与-opencv">Halcon 与 OpenCV&lt;a class="td-heading-self-link" href="#halcon-%e4%b8%8e-opencv" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>OpenCV&lt;/th>
&lt;th>Halcon&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>开发语言&lt;/td>
&lt;td>C++、C#（emgu）、Python、Ruby、MATLAB等语言&lt;/td>
&lt;td>C，C++，C#，Visual basic和Delphi等语言&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>应用场合&lt;/td>
&lt;td>侧重计算机视觉领域，侧重研究领域&lt;/td>
&lt;td>侧重机器视觉领域，侧重应用领域&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>费用&lt;/td>
&lt;td>免费&lt;/td>
&lt;td>收费&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>开放性及版本更新速度&lt;/td>
&lt;td>开源（可看底层源码），版本和功能更新慢&lt;/td>
&lt;td>商业软件（底层代码封装），版本和功能更新快&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>对使用者的门槛&lt;/td>
&lt;td>偏科研，有难度，有深度，完全从底层开发，对使用者门槛高，开发效率低，开发慢&lt;/td>
&lt;td>偏工程应用，使用封装好的功能函数，对使用者门槛低，开发效率高，开发快&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>资料及技术支持&lt;/td>
&lt;td>资料少。遇到问题，难以获得技术支持&lt;/td>
&lt;td>资料多。遇到问题，可以及时、有效的获得技术支持&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="学习资料">学习资料&lt;a class="td-heading-self-link" href="#%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://www.bilibili.com/video/BV1is4y1D7oU">B 站，唐宇迪，【唐宇迪AI分享】CV和NLP两大板块一定要先选CV！！！&lt;/a>&lt;/p>
&lt;h1 id="tasks">Tasks&lt;a class="td-heading-self-link" href="#tasks" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>计算机视觉任务通常包括 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object%20detection.md">Object detection&lt;/a>、&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Keypoint%20detection.md">Keypoint detection&lt;/a>、&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose%20estimation.md">Pose estimation&lt;/a>、etc.&lt;/p></description></item><item><title>Docs: OpenCV</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/</guid><description/></item><item><title>Docs: Dataset</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Dataset/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://opencv.org/blog/data-annotation/">https://opencv.org/blog/data-annotation/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;img src="https://opencv.org/wp-content/uploads/2024/02/Data-annotation-types-1536x864.png" alt="800">&lt;/p>
&lt;h1 id="data-annotations">Data annotations&lt;a class="td-heading-self-link" href="#data-annotations" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://opencv.org/blog/data-annotation/">OpenCV 博客，Data Annotation – A Beginner’s Guide&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89.md">计算机视觉&lt;/a> 中的数据注释常见如下几种：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Bounding box&lt;/strong>&lt;/li>
&lt;li>Segmentation&lt;/li>
&lt;li>KeyPoint&lt;/li>
&lt;li>Lines and Splines&lt;/li>
&lt;li>etc. TODO&lt;/li>
&lt;/ul>
&lt;p>下图中各种颜色的方框都是注释（数字代码是在模型训练时由数据集配置文件中定义其含义），通过 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object%20detection.md">Object detection&lt;/a> 识别出对象并添加对象注释&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ai/yolo/mosaiced-coco-dataset-sample.jpg" alt="https://github.com/ultralytics/docs/releases/download/0/mosaiced-coco-dataset-sample.avif|500">&lt;/p>
&lt;p>下图的注释除了有检测到的对象外，还有对象的姿态。识别出对象后，再通过 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose%20estimation.md">Pose estimation&lt;/a> 进行姿态估计并添加姿态注释&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ai/yolo/mosaiced-coco-dataset-sample_pose-estimation.jpg" alt="https://github.com/ultralytics/docs/releases/download/0/mosaiced-training-batch-6.avif|500">&lt;/p>
&lt;p>上面只是用两种类型举例，还有很多其他的注释类型，这些都属于图像的 &lt;strong>Annotations(注释)&lt;/strong>&lt;/p>
&lt;h2 id="bounding-box">Bounding box&lt;a class="td-heading-self-link" href="#bounding-box" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.ultralytics.com/glossary/bounding-box">https://www.ultralytics.com/glossary/bounding-box&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://encord.com/glossary/bounding-box-definition/">https://encord.com/glossary/bounding-box-definition/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Bounding box(边界框)&lt;/strong> 也称为 Bounding volume 或 Bounding region，是一种 &lt;em>几何形状&lt;/em> 的 Label，用于在数字图像中包围或环绕一个或一组对象。Bounding box 的目的是在2D 或 3D 空间中定义对象的位置和大小，以执行各种 CV 任务，e.g. 对象检测、分割、分类。这是 CV 领域的基本概念，特别是在涉及图像和视频分析的应用中。&lt;/p>
&lt;blockquote>
&lt;p>在 2D 图像中，Bounding box 通常用矩形表示，其长边与图像的 x 轴和 y 轴平行。矩形的大小由 x 轴和 y 轴的最小值和最大值决定，这些值由矩形的角坐标指定。矩形的大小和中心点也可用于创建 enclosing box(封闭框)。&lt;/p>
&lt;p>在 3D 图像中，边界框通常用平行六面体（3D 矩形）表示，其各个面与图像的 x、y 和 z 轴平行。平行六面体的尺寸由其角的坐标决定，这些坐标表示 x、y 和 z 轴的最小值和最大值。平行六面体的大小和中心也可用于确定 Bounding box。&lt;/p>
&lt;/blockquote>
&lt;p>Bounding box 对于 对象检测 任务及衍生任务至关重要，尤其是对于让模型可以识别和分类图像中的物体。这些 Bounding box 作为真实标注，提供了模型训练时所需的信息（i.e. 确定物体的位置以及如何区分不同的物体）。在像 Ultralytics YOLO 这样的框架中，Bounding box 不仅用于标注，还用于在推理过程中预测物体的位置（也可说是为对象添加 Annotations(注释)）。&lt;/p>
&lt;p>Bounding box 效果如下图所示，各种矩形框配上数字，以表示出图像中的对象及该对象的分类或名称。&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ai/yolo/mosaiced-coco-dataset-sample.jpg" alt="500">&lt;/p>
&lt;blockquote>
&lt;p>Tip: Bounding box 就像 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/OpenCV.md">OpenCV&lt;/a> 的 Region Of Interest(感兴趣的区域，简称 ROI)，然后会生成图片对应的 Label，每个 ROI 都有一个数字表示的类别、以及用来定位 ROI 的坐标。&lt;/p>
&lt;/blockquote>
&lt;h1 id="常见公开的数据集">常见公开的数据集&lt;a class="td-heading-self-link" href="#%e5%b8%b8%e8%a7%81%e5%85%ac%e5%bc%80%e7%9a%84%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h3 id="coco">COCO&lt;a class="td-heading-self-link" href="#coco" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://cocodataset.org/">官网&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Common Objects in Context(COCO)&lt;/strong> 是一个大规模的对象检测、分割和字幕数据集。 COCO 有几个特点：&lt;/p>
&lt;ul>
&lt;li>Object segmentation&lt;/li>
&lt;li>Recognition in context&lt;/li>
&lt;li>Superpixel stuff segmentation&lt;/li>
&lt;li>330K images (&amp;gt;200K labeled)&lt;/li>
&lt;li>1.5 million object instances&lt;/li>
&lt;li>80 object categories&lt;/li>
&lt;li>91 stuff categories&lt;/li>
&lt;li>5 captions per image&lt;/li>
&lt;li>250,000 people with keypoints&lt;/li>
&lt;/ul>
&lt;p>COCO 数据集常见任务类型：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object%20detection.md">Object detection&lt;/a>(对象监测)&lt;/strong> # 简称 Detection
&lt;ul>
&lt;li>&lt;a href="https://cocodataset.org/#detection-2020">https://cocodataset.org/#detection-2020&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>DensePose&lt;/strong> # COCO DensePose 任务旨在推动在具有挑战性、不受控制的条件下对人体姿势进行密集估计的最先进技术。
&lt;ul>
&lt;li>&lt;a href="https://cocodataset.org/#densepose-2020">https://cocodataset.org/#densepose-2020&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Keypoint detection(关键点监测)&lt;/strong> # 简称 Keypoints。COCO 关键点检测任务需要在具有挑战性、不受控制的条件下定位人物关键点。关键点任务涉及同时检测人员并定位其关键点（测试时未给出人员位置）。有关此任务的完整详细信息，请参阅&lt;a href="https://cocodataset.org/#keypoints-eval">关键点评估&lt;/a>页面。
&lt;ul>
&lt;li>&lt;a href="https://cocodataset.org/#keypoints-2020">https://cocodataset.org/#keypoints-2020&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Stuff Segmentation(东西分割)&lt;/strong> # 简称 Stuff。COCO Stuff Segmentation Task 旨在推动 stuff 类语义分割的最新技术。对象检测任务针对的是事物类别（人、汽车、大象），而该任务则侧重于事物类别（草、墙壁、天空）。有关内容分割任务的完整详细信息，请参阅内容评估页面。注意：新引入的全景分割任务同时解决了事物和事物类别的识别。&lt;/li>
&lt;li>&lt;a href="https://cocodataset.org/#stuff-2019">https://cocodataset.org/#stuff-2019&lt;/a>&lt;/li>
&lt;li>&lt;strong>Panoptic Segmentation(全景分割)&lt;/strong> # 简称 Panoptic。全景分割解决了事物和事物类别，统一了通常不同的语义和实例分割任务。其目的是生成丰富且完整的连贯场景分割，这是迈向自动驾驶或增强现实等现实世界视觉系统的重要一步。有关全景分割任务的完整详细信息，请参阅&lt;a href="https://cocodataset.org/#panoptic-eval">全景评估&lt;/a>页面。
&lt;ul>
&lt;li>&lt;a href="https://cocodataset.org/#panoptic-2020">https://cocodataset.org/#panoptic-2020&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Image Captioning&lt;/strong> # 简称 Captions。用文字描述图像
&lt;ul>
&lt;li>&lt;a href="https://cocodataset.org/#captions-2015">https://cocodataset.org/#captions-2015&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="imagenet">ImageNet&lt;a class="td-heading-self-link" href="#imagenet" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://www.image-net.org/">https://www.image-net.org/&lt;/a>&lt;/p></description></item><item><title>Docs: Keypoint detection</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Keypoint-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Keypoint-detection/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://blog.roboflow.com/what-is-keypoint-detection/">https://blog.roboflow.com/what-is-keypoint-detection/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Keypoint detection(关键点监测)&lt;/strong> 可用来进行 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose%20estimation.md">Pose estimation&lt;/a> 和 Facial recognition(面部识别)&lt;/p>
&lt;blockquote>
&lt;p>Notes: 某些可以利用 Keypoint detection 实现的任务，并不止局限于这一种。还有可能有其他方式实现，比如面部识别不一定需要依赖关键点监测。&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: Object detection</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object-detection/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Object_detection">Wiki, Object detection&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.ultralytics.com/glossary/object-detection">Ultralytics 文档，术语 - 对象监测&lt;/a>&lt;/li>
&lt;li>Google 学术 &lt;a href="https://scholar.google.com/scholar?q=Object+detection&amp;amp;hl=zh-CN&amp;amp;as_sdt=0&amp;amp;as_vis=1&amp;amp;oi=scholart">https://scholar.google.com/scholar?q=Object+detection&amp;amp;hl=zh-CN&amp;amp;as_sdt=0&amp;amp;as_vis=1&amp;amp;oi=scholart&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Object detection(对象检测)&lt;/strong> 是一种与计算机视觉和图像处理相关的计算机技术，用于检测数字图像和视频中特定类别（例如人类、建筑物或汽车）的语义对象的实例。&lt;/p>
&lt;p>&lt;strong>Image Classification(图像分类)&lt;/strong> # 确定图像中是否存在特定对象。&lt;/p>
&lt;p>&lt;strong>Bounding Box(边界框)&lt;/strong> # 用于突出显示图像中对象的位置的矩形。它由坐标 (x, y)、宽度和高度定义。&lt;/p>
&lt;h2 id="对象监测架构">对象监测架构&lt;a class="td-heading-self-link" href="#%e5%af%b9%e8%b1%a1%e7%9b%91%e6%b5%8b%e6%9e%b6%e6%9e%84" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;strong>One-Stage Detectors(单级检测器)&lt;/strong> 例如 YOLO、SSD：一步执行对象定位和分类，提供更快的推理速度，但有时会牺牲准确性。&lt;/p>
&lt;p>&lt;strong>Two-Stage Detectors(两阶段检测器)&lt;/strong> （例如 Faster R-CNN）：涉及区域提议阶段，然后进行对象分类，通常可以实现更高的准确度，但推理时间可能会更慢。&lt;/p></description></item><item><title>Docs: OCR</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Optical_character_recognition">Wiki, Optical_character_recognition&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/models.md">https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/models.md&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;strong>Optical character recognition(光学字符识别，简称 OCR)&lt;/strong> 是将图像以电子或机械方式转换为机器编码文本，无论是来自扫描文档、文档照片、场景照片、叠加在图像上的字母文字等。目前是文字识别的统称，已不限于文档或书本文字识别，更包括识别自然场景下的文字，又可以称为 &lt;strong>Scene Text Recognition(场景文字识别，简称 STR)&lt;/strong>。&lt;/p>
&lt;p>OCR 文字识别一般包括两个部分，&lt;strong>文本检测&lt;/strong>和&lt;strong>文本识别&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>文本检测首先利用检测算法检测到图像中的文本块&lt;/li>
&lt;li>然后文本识别利用识别算法去识别文本块中的具体文字&lt;/li>
&lt;/ul>
&lt;h2 id="detection-model检测模型">Detection Model(检测模型)&lt;a class="td-heading-self-link" href="#detection-model%e6%a3%80%e6%b5%8b%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>文本检测就是要定位图像中的文字区域，然后通常以边界框的形式将单词或文本行标记出来。传统的文字检测算法多是通过手工提取特征的方式，特点是速度快，简单场景效果好，但是面对自然场景，效果会大打折扣。当前多是采用深度学习方法来做。&lt;/p>
&lt;p>基于深度学习的文本检测算法可以大致分为以下几类：&lt;/p>
&lt;ol>
&lt;li>基于目标检测的方法；一般是预测得到文本框后，通过NMS筛选得到最终文本框，多是四点文本框，对弯曲文本场景效果不理想。典型算法为EAST、Text Box等方法。&lt;/li>
&lt;li>基于分割的方法；将文本行当成分割目标，然后通过分割结果构建外接文本框，可以处理弯曲文本，对于文本交叉场景问题效果不理想。典型算法为DB、PSENet等方法。&lt;/li>
&lt;li>混合目标检测和分割的方法；&lt;/li>
&lt;/ol>
&lt;h2 id="recognition-model识别模型">Recognition Model(识别模型)&lt;a class="td-heading-self-link" href="#recognition-model%e8%af%86%e5%88%ab%e6%a8%a1%e5%9e%8b" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>OCR 识别算法的输入数据一般是文本行，背景信息不多，文字占据主要部分，识别算法目前可以分为两类算法：&lt;/p>
&lt;ol>
&lt;li>基于 CTC 的方法；即识别算法的文字预测模块是基于 CTC 的，常用的算法组合为 CNN+RNN+CTC。目前也有一些算法尝试在网络中加入 transformer 模块等等。&lt;/li>
&lt;li>基于 Attention 的方法；即识别算法的文字预测模块是基于 Attention 的，常用算法组合是 CNN+RNN+Attention&lt;/li>
&lt;/ol>
&lt;h2 id="预处理">预处理&lt;a class="td-heading-self-link" href="#%e9%a2%84%e5%a4%84%e7%90%86" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>为了可以让程序快速检测到字符块后精准识别字符，有的时候还需要对图片进行预处理&lt;/p>
&lt;ul>
&lt;li>比如图片是斜的，我们可以把图片正过来&lt;/li>
&lt;li>若是图片有干扰，可以去掉干扰&lt;/li>
&lt;li>等等&amp;hellip;&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结&lt;a class="td-heading-self-link" href="#%e6%80%bb%e7%bb%93" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>用稍微简单一些的话说，检测模型用来检查一个图片中，哪些地方可以被识别模型识别；然后交给识别模型。若将图片直接交给识别模型，那么是无法获得任何结果的&lt;/p>
&lt;p>用 PaddleOCR 的识别识别逻辑举例，至少需要用到两种模型：文本检测模型 和 文本识别模型。提供给 PaddleOCR 一张图后，首先先检测图片中包含的文字信息并定位为文本框，然后识别文本框中的文本。&lt;/p>
&lt;blockquote>
&lt;p>Tips: 若想要识别倒转的文字，还可以通过 方向分类器 模型进行预处理。有的 OCR 程序还有很多其他的&lt;strong>预处理&lt;/strong>操作，比如去斑、二值化、线条去除、布局分析 等等。&lt;/p>
&lt;/blockquote>
&lt;p>如下图：&lt;/p>
&lt;p>&lt;img src="https://notes-learning.oss-cn-beijing.aliyuncs.com/ocr/202310311306270.png" alt="image.png|800">&lt;/p>
&lt;p>用红框框起来的就是检测到的文本框，每个文本框都由 &lt;code>[[196.0, 10.0], [237.0, 10.0], [237.0, 28.0], [196.0, 28.0]]&lt;/code> （这里用 驯兽师 三个字的文本块为例）这样的多维数组进行定位&lt;/p>
&lt;ul>
&lt;li>外层数组共 4 个元素，分别表示文本框的 4 个顶点；0 号元素为 &lt;strong>左上角&lt;/strong>，1 号元素为 &lt;strong>右上角&lt;/strong>，2 号元素为 &lt;strong>右下角&lt;/strong>，3 号元素为 &lt;strong>左下角&lt;/strong>。&lt;/li>
&lt;li>内层数组共 2 个元素，分别表示顶点的横/纵坐标；0 号元素为像素点的&lt;strong>横轴&lt;/strong>坐标，1 号元素为像素点的&lt;strong>纵轴&lt;/strong>坐标。&lt;/li>
&lt;/ul>
&lt;p>然后对每个文本框进行文字识别，以识别出其中的文字。&lt;/p>
&lt;h1 id="paddleocr">PaddleOCR&lt;a class="td-heading-self-link" href="#paddleocr" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/PaddlePaddle/PaddleOCR">GitHub 项目，PaddlePaddle/PaddleOCR&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1iY4y1s7fx">https://www.bilibili.com/video/BV1iY4y1s7fx&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>PaddleOCR 是百度开源的 OCR 工具。旨在打造一套丰富、领先、且实用的OCR工具库，助力开发者训练出更好的模型，并应用落地。&lt;/p>
&lt;h2 id="模型说明">模型说明&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e5%9e%8b%e8%af%b4%e6%98%8e" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>PaddleOCR 中集成了很多OCR算法，文本检测算法有 DB、EAST、SAST 等等，文本识别算法有CRNN、RARE、StarNet、Rosetta、SRN等算法。&lt;/p>
&lt;p>其中PaddleOCR针对中英文自然场景通用OCR，推出了PP-OCR系列模型，PP-OCR模型由DB+CRNN算法组成，利用海量中文数据训练加上模型调优方法，在中文场景上具备较高的文本检测识别能力。并且 PaddleOCR 推出了高精度超轻量 PP-OCRv2 模型，检测模型仅3M，识别模型仅8.5M，利用 &lt;a href="https://github.com/PaddlePaddle/PaddleSlim">PaddleSlim&lt;/a> 的模型量化方法，可以在保持精度不降低的情况下，将检测模型压缩到 0.8M，识别压缩到 3M，更加适用于移动端部署场景。&lt;/p>
&lt;h2 id="关联文件与配置">关联文件与配置&lt;a class="td-heading-self-link" href="#%e5%85%b3%e8%81%94%e6%96%87%e4%bb%b6%e4%b8%8e%e9%85%8d%e7%bd%ae" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;strong>~/.paddleocr/whl/&lt;/strong> # 模型保存路径。注意：第一次运行调用 PaddleOCR 包运行代码时，会自动下载最新的模型。详见 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/paddleocr.py#L58">paddleocr.py 文件的 MODEL_URLS 变量&lt;/a>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>./cls/&lt;/strong> # Direction Classification(方向分类器) 模型保存路径&lt;/li>
&lt;li>&lt;strong>./det/&lt;/strong> # Detection(检测) 模型保存路径&lt;/li>
&lt;li>&lt;strong>./rec/&lt;/strong> # Recognition(识别) 模型保存路径&lt;/li>
&lt;/ul>
&lt;h2 id="模型下载">模型下载&lt;a class="td-heading-self-link" href="#%e6%a8%a1%e5%9e%8b%e4%b8%8b%e8%bd%bd" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>在 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_ch/models_list.md">PP-OCR系列模型列表&lt;/a> 处可以找到三个基本模型以及一个超轻量模型的简介、配置文件、下载地址。&lt;/p>
&lt;ul>
&lt;li>基本模型
&lt;ul>
&lt;li>文本检测模型&lt;/li>
&lt;li>文本识别模型&lt;/li>
&lt;li>文本方向分类模型&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>轻量模型&lt;/li>
&lt;/ul>
&lt;p>模型都分为多个种类&lt;/p>
&lt;ul>
&lt;li>推理模型 # 用于预测引擎推理。通常默认下载这种模型。&lt;/li>
&lt;li>训练模型 与 预训练模型 # 训练过程中保存的模型的参数、优化器状态和训练中间信息，多用于模型指标评估和恢复训练
&lt;ul>
&lt;li>训练模型 # 是基于预训练模型在真实数据与竖排合成文本数据上finetune得到的模型，在真实应用场景中有着更好的表现&lt;/li>
&lt;li>预训练模型 # 则是直接基于全量真实数据与合成数据训练得到，更适合用于在自己的数据集上finetune。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>nb模型 # 经过飞桨Paddle-Lite工具优化后的模型，适用于移动端/IoT端等端侧部署场景（需使用飞桨Paddle Lite部署）。&lt;/li>
&lt;/ul>
&lt;p>选择自己感兴趣的模型，下载即可。下载后，将对应的模型，解压到 &lt;code>ch_PP-OCRv4_server_rec&lt;/code> 目录下对应模型的目录中。比如在 &lt;code>2.1 中文识别模型&lt;/code> 章节中，找到 &lt;code>ch_PP-OCRv4_server_rec&lt;/code> 推理模型，下载并解压到 &lt;code>ch_PP-OCRv4_server_rec/rec/&lt;/code> 目录下即可。其他两个模型同理。这样就可以更换我们感兴趣的模型。&lt;/p>
&lt;h2 id="python-库">Python 库&lt;a class="td-heading-self-link" href="#python-%e5%ba%93" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>详见：Python 第三方库 &lt;a href="https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python%20%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/paddleocr.md">paddleocr&lt;/a> 包&lt;/p>
&lt;h1 id="实用-ocr工具">实用 OCR工具&lt;a class="td-heading-self-link" href="#%e5%ae%9e%e7%94%a8-ocr%e5%b7%a5%e5%85%b7" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="umi-ocr">Umi-OCR&lt;a class="td-heading-self-link" href="#umi-ocr" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/hiroi-sora/Umi-OCR">GitHub 项目，hiroi-sora/Umi-OCR&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/lkoBOAYCdIY8F2Y6FCR-7w">公众号-差评，完全免费，不用联网，这套 OCR 工具比微信的还好用！&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>OCR 图片转文字识别软件，完全离线。截屏/批量导入图片，支持多国语言、合并段落、竖排文字。可排除水印区域，提取干净的文本。基于 PaddleOCR 。&lt;/p></description></item><item><title>Docs: Pose estimation</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose-estimation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose-estimation/</guid><description>
&lt;h1 id="概述">概述&lt;a class="td-heading-self-link" href="#%e6%a6%82%e8%bf%b0" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Pose_(computer_vision)">Wiki, Pose&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/3D_pose_estimation">Wiki, 3D pose estimation&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>通过 &lt;a href="https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object%20detection.md">Object detection&lt;/a> 检测到对象后，利用 &lt;strong>Pose estimation(姿态估计)&lt;/strong> 确定对象的位置和方向，通常是在三维空间中。姿态通常以&lt;strong>变换矩阵&lt;/strong>的形式在内部存储。术语 &lt;strong>pose(姿态)&lt;/strong> 在很大程度上与 &lt;strong>transform(变换)&lt;/strong> 同义，但 transform 常常包含 &lt;strong>缩放&lt;/strong>，而姿态通常不包含。&lt;/p></description></item></channel></rss>