<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>首页 on 断念梦的站点</title><link>https://desistdaydream.github.io/</link><description>Recent content in 首页 on 断念梦的站点</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://desistdaydream.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>📹11.多媒体</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/11.%E5%A4%9A%E5%AA%92%E4%BD%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/11.%E5%A4%9A%E5%AA%92%E4%BD%93/</guid><description>概述 参考：
Multimedia Multimedia(多媒体) 是一种通信形式，它使用不同的内容形式（例如文本、音频、图像、动画或视频）组合成一个单一的交互式演示，这与传统的大众媒体（例如印刷材料或录音）不同，后者的功能很少用户之间没有交互。流行的多媒体示例包括视频播客、音频幻灯片和动画视频。多媒体还包含有效交互通信的原理和应用，例如软件、硬件和其他技术的构建块。多媒体的五个主要组成部分是文本、图像、音频、视频和动画。
学习 B 站-差评君，从上传到被观看，一个视频到底都经历了什么？【差评君】
名词解释 帧
帧宽度
帧高度
帧率
编解码器
帧总数
格式
模式
亮度
对比度
饱和度
色调
增益
曝光
RGB
白平衡
矫正
摩尔纹
B 站 - 影视飓风，这是什么？摩尔纹。 分辨率、帧率、码率
4D 高斯
https://www.bilibili.com/video/BV1k85NzMEv4 帧率 影视飓风将停止制作25帧视频 介绍了各种帧率的历史
25 50
30 60
29.97 59.94</description></item><item><title>12.AI</title><link>https://desistdaydream.github.io/docs/12.AI/12.AI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/12.AI/</guid><description>概述 参考：
Wiki, Artificial_intelligence Artificial intelligence(人工智能，简称 AI) 是机器所展示的智能，与人类和其他动物的智能相对应。AI 通常包含语音识别、计算机视觉、自然语言处理、以及其他输入的映射
随着机器的能力越来越强，被认为需要“智能”的任务通常从 AI 的定义中删除，这种现象被称为 AI 效应。例如，OCR 经常被排除在被认为是人工智能的事物之外，已成为一项常规技术。
AI 好像不等于机器。。不像机器精确执行 01 指令。。AI 的本质好像是数学，并且是数学中的统计学，AI 的每一次判断都是一次概率统计然后输出概率大的内容。
TODO: 本质上是将 数学问题转为数值计算问题？因为机器不认识加减乘除这些符号，但是又要训练机器学会这些，那么机器就要学会 101 如何变成 111 这类？
人工智能发展阶段 https://zhuanlan.zhihu.com/p/24811027
运算智能、感知智能、认知智能
一是运算智能，即快速计算和记忆存储能力。人工智能所涉及的各项技术的发展是不均衡的。现阶段计算机比较具有优势的是运算能力和存储能力。1996 年 IBM 的深蓝计算机战胜了当时的国际象棋冠军卡斯帕罗夫，从此，人类在这样的强运算型的比赛方面就不能战胜机器了。
二是感知智能，即视觉、听觉、触觉等感知能力。人和动物都具备，能够通过各种智能感知能力与自然界进行交互。自动驾驶汽车，就是通过激光雷达等感知设备和人工智能算法，实现这样的感知智能的。机器在感知世界方面，比人类还有优势。人类都是被动感知的，但是机器可以主动感知，如：激光雷达、微波雷达和红外雷达。不管是 Big Dog 这样的感知机器人，还是自动驾驶汽车，因为充分利用了 DNN 和大数据的成果，机器在感知智能方面已越来越接近于人类。
早期的计算机视觉属于感知智能，只能认识图片，而无法知道图片中所表达的意思。 三是认知智能。通俗讲是“能理解会思考”。人类有语言，才有概念，才有推理，所以概念、意识、观念等都是人类认知智能的表现。典型的自然语言处理，就需要认知智能。
第一层是语言理解 第二层是分析、推理 第三层是人格和情感 技术脉络关系 个人总结：
如果人工智能的本质是数学计算，那么首先出现的是辅助计算的工具，比如 NumPy、Torch，然后利用这些计算能力，发展出让机器学习的工具，TensorFlow、PyTorch 等，最后通过机器学习，训练出来可用的各种基本模型，比如 Transformer。
NumPy、Torch 提供计算能力 TensorFlow、PyTorch 依赖计算能力实现的用于机器学习的框架 Transformer 使用学习框架生成模型，Transformer 一般是指一个过程、工具集，而不是单指一种模型，很多模型是通过 Transformer 工具使用或训练。 机器学习 机器学习源于对 AI 的探索。在人工智能作为一门学科的早期，一些研究人员对让机器从数据中学习很感兴趣。他们试图用各种符号方法以及当时称为“神经网络”的方法来解决这个问题。
后来，机器学习更多的依赖模型。
AGI 参考：
Wiki, Artificial general intelligence Artificial General Intelligence(通用人工智能，简称 AGI) 是一种假设的智能体，它可以理解或学习人类或其他动物可以完成的任何智力任务。</description></item><item><title>Access Control</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Access-Control/Access-Control/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Access-Control/Access-Control/</guid><description>概述 参考：
Access Control(访问控制)
Authorization 和 Delegation Authorization 名词。更多时候用来形容授权本身
Delegation 动词。更多时候用来形容授权的过程
AI 回答：
Authorization 与 Delegation 都有”授权“的含义
Authorization(授权) 是指验证和确定某个主体是否有权限执行特定操作或访问特定资源的过程。
特点：
基于身份和角色的权限控制 通常是静态的权限分配 权限由系统管理员或权限管理系统预先定义 权限检查发生在资源访问时 权限通常绑定到用户的身份或角色 例子：
用户A被授权可以读取文件X 管理员角色被授权可以删除用户账户 某个API key被授权可以访问特定的服务端点 Delegation(授权) 是指一个主体将自己的部分或全部权限临时赋予给另一个主体的机制。
特点：
权限的动态转移 通常是临时性的 原权限持有者主动发起 可以设置时间限制、范围限制等条件 委托者仍保留原始权限 例子：
OAuth中，用户委托第三方应用代表自己访问某些资源 经理将审批权限临时委托给副经理 系统管理员委托某个用户临时执行维护任务 关键区别 权限来源：Authorization 是系统分配的，Delegation 是用户主动转让的 持续性：Authorization 通常是持久的，Delegation 通常是临时的 控制权：Authorization 由管理员控制，Delegation 由权限拥有者控制 灵活性：Delegation 更加灵活和动态 在实际应用中，这两个概念经常结合使用，比如 OAuth 2.0 就同时涉及授权和委托机制。
基于角色的访问控制（RBAC）：演进历史、设计理念及简洁实现（Tailscale, 2021） https://arthurchiao.art/blog/rbac-as-it-meant-to-be-zh/
RBAC 的演进历史、设计理念及简洁实现
译者序 本文翻译自 2021 年的一篇英文博客： RBAC like it was meant to be 。</description></item><item><title>Access Control(访问控制)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</guid><description>概述 参考：
Wiki, DAC Linux 使用 Discretionary Access Control(自主访问控制，简称 DAC) 概念控制所有文件的基本权限。
Linux 中每个文件都具有三个拥有者：
user # 文件的属主，拥有文件的一个 Linux Account(账户) group # 文件的属组，拥有文件的一组 Linux Account(账户) other # 文件的其他，拥有该文件的其他 Linux Account(账户) 上述三个角色，可以被赋予三个基本权限
read # 读，简写为 r write # 写，简写为 w execute # 执行，简写为 x 我们使用 ls -l 命令查看文件，可以从第 1 列看到文件的类型与权限
~]# ls -lh total 20K lrwxrwxrwx. 1 root root 7 May 24 2019 bin -&amp;gt; usr/bin dr-xr-xr-x. 5 root root 4.0K May 24 2019 boot drwxr-xr-x 20 root root 3.</description></item><item><title>Account Manager(账户管理)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Account-Manager%E8%B4%A6%E6%88%B7%E7%AE%A1%E7%90%86/Account-Manager%E8%B4%A6%E6%88%B7%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Account-Manager%E8%B4%A6%E6%88%B7%E7%AE%A1%E7%90%86/Account-Manager%E8%B4%A6%E6%88%B7%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
红帽官方文档，RedHat7 - 管理用户账户的基础知识 红帽官方文档，RedHat7 - 系统管理员指南-第四章-管理用户和组 红帽官方文档，RedHat7 - 安全指南 Linux 操作系统是一个多用户操作系统，所以除了 Terminal(终端) 以外，还需 Account(账户) 才可以登录上去，Linux 操作系统允许多个用户访问安装在一台机器上的单个系统。每个 User(用户) 都在自己的 Account(账户) 下操作。因此，Account Manager 代表了 Linux 系统管理的核心要素。
User 与 Account 傻傻分不清楚，在 Linux 操作系统中，通常都会将 Account 称为 User，但是，这个称呼实际上并不准确。因为一个 User，比如 root，可以被多个现实世界中多个人使用，那么 root 这个 User 就会对应多个真实的 User。这种描述是非常矛盾的。。。
只不过，随着时间的推移，人们慢慢叫习惯了，各种文档和源码也都一直使用 UID 这种名称，也就不再特别区分 Account 和 User 了。只需要知道，UID 更准确的描述应该是 AID。
同时，一个 Linux Account 也可以不代表一个真实的 User，这样的 Account 只被应用程序使用，一个应用程序使用某个 Account 运行，以便让系统更方便得对程序进行精细化控制。这种控制方式称为 Access Control(访问控制)，所以，从这种角度看，Account 也可以称为 Role(角色)，详见 Access Control(访问控制) 章节。
为了方便得对多个 Account 管理，可以将多个 Account 组合起来，称为 Group(组)，一个 Group 就是一个或多个 Account 的集合。</description></item><item><title>ACME</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/ACME/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/ACME/</guid><description>概述 参考：
RFC 8555, Automatic Certificate Management Environment (ACME) RFC 8737, Automated Certificate Management Environment (ACME) TLS Application‑Layer Protocol Negotiation (ALPN) Challenge Extension RFC 8738, Automated Certificate Management Environment (ACME) IP Identifier Validation Extension Wiki, ACME Automatic Certificate Management Environment(自动证书管理环境，简称 ACME) 是一种通信协议，用于自动化证书颁发机构与其用户的 Web 服务器之间的交互，允许以非常低的成本自动部署 PKI。它是由 ISRG 为他们的 Let&amp;rsquo;s Encrypt 服务设计的。
ACME 服务提供商 支持免费或低成本基于 ACME 的证书服务的提供商包括 Let&amp;rsquo;s Encrypt、Buypass Go SSL、ZeroSSL 和 SSL.com。许多其他证书颁发机构和软件供应商提供 ACME 服务，作为 Entrust 和 DigiCert 等付费 PKI 解决方案的一部分。
ACME 的实现 想要实现自动签证书，要经过如下几个步骤</description></item><item><title>AI Projects</title><link>https://desistdaydream.github.io/docs/12.AI/AI-Projects/AI-Projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/AI-Projects/AI-Projects/</guid><description>概述 参考：
AI 开源方案库-传递最新 AI 应用落地解决方案｜AIGCLINK # 收集各种 AI 相关的开源项目
https://github.com/Stability-AI/generative-models # 补帧，通过静态图片生成动图。
labring/FastGPT # 一个快速使用 openai api 的平台。支持一键构建 AI 知识库，支持多用户、多模型管理。
https://github.com/binary-husky/gpt_academic # 为 GPT/GLM 等 LLM 大语言模型提供实用化交互接口，特别优化论文阅读/润色/写作体验，模块化设计，支持自定义快捷按钮&amp;amp;函数插件，支持Python 和 C++ 等项目剖析 &amp;amp; 自译解功能，PDF/LaTex 论文翻译&amp;amp;总结功能，支持并行问询多种 LLM 模型，支持 chatglm3 等本地模型。接入通义千问, deepseek coder, 讯飞星火, 文心一言, llama2, rwkv, claude2, moss 等。
NovelAI # https://novelai.net/ 写故事、作图
即时通信 中的 Chatbot 还有很多有趣的 AI 项目
IDE 工具 Cline # IDE中的自主编码代理，能够在每一步的每一步中使用浏览器来创建/编辑文件，使用浏览器以及更多内容。实现了 MCP
https://github.com/cline/cline 用于解决复杂任务的 AI https://blog.x-agent.net/blog/xagent/
虽然开创性项目（e.g., AutoGPT, BabyAGI, CAMEL, MetaGPT, AutoGen, DSPy, AutoAgents, OpenAgents, Agents, AgentVerse, ChatDev）已经展示了这个方向的潜力，但完全自主的 AI 代理之旅仍然面临着巨大的挑战。</description></item><item><title>Alertmanager</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager/</guid><description>概述 参考：
GitHub 项目，prometheus/alertmanager 官方文档 学习资料 公众号 - 运维开发故事，深入剖析Alertmanager：解锁告警管理的核心逻辑 Prometheus Alert 介绍详见 Prometheus Server Alert 说明
Alertmanager 处理由客户端应用程序（例如 Prometheus 服务器）发送的警报。它负责将重复数据删除，分组和路由到正确的接收者集成，例如电子邮件，PagerDuty 或 OpsGenie。它还负责沉默和禁止警报。
Alertmanager 特性
Prometheus 发送过来的每一个告警，都会由 Alertmanager 进行重复数据删除、分组、路由到正确的接收者(e.g.邮件、钉钉等)上。
Alertmanager 除了提供基本的告警通知能力以外，还主要提供了如：分组、抑制以及静默等告警特性：
分组
分组机制可以将详细的告警信息合并成一个通知。在某些情况下，比如由于系统宕机导致大量的告警被同时触发，在这种情况下分组机制可以将这些被触发的告警合并为一个告警通知，避免一次性接受大量的告警通知，而无法对问题进行快速定位。
例如，当集群中有数百个正在运行的服务实例，并且为每一个实例设置了告警规则。假如此时发生了网络故障，可能导致大量的服务实例无法连接到数据库，结果就会有数百个告警被发送到 Alertmanager。
而作为用户，可能只希望能够在一个通知中中就能查看哪些服务实例收到影响。这时可以按照服务所在集群或者告警名称对告警进行分组，而将这些告警内聚在一起成为一个通知。
告警分组，告警时间，以及告警的接受方式可以通过 Alertmanager 的配置文件进行配置。
抑制
抑制是指当某一告警发出后，可以停止重复发送由此告警引发的其它告警的机制。
例如，当集群不可访问时触发了一次告警，通过配置 Alertmanager 可以忽略与该集群有关的其它所有告警。这样可以避免接收到大量与实际问题无关的告警通知。
抑制机制同样通过 Alertmanager 的配置文件进行设置。
静默
静默提供了一个简单的机制可以快速根据标签对告警进行静默处理。如果接收到的告警符合静默的配置，Alertmanager 则不会发送告警通知。
静默设置需要在 Alertmanager 的 Web 页面上进行设置。
Alertmanager 告警分组 每一个告警进入 Alertmanager 后，都会进行分组处理，可以根据规则将多条告警合并为一个通知。这是为了可以让相关的告警可以合并在一起，一次性收集和发送，以便运维人员的故障排查。
Alertmanager 告警路由 告警路由，顾名思义，路由就是根据“目的接收者”将每个告警发送到指定的接收者上的过程。
每一个告警进入到 Alertmanager 都会由顶级的 route 进入路由树，需要注意的是顶级的 route 必须匹配所有告警(即不能有任何的匹配设置 match 和 match_re)，在一个路由树中，将每个被路由的目标称为 Node(节点)。</description></item><item><title>ANSI</title><link>https://desistdaydream.github.io/docs/Standard/IT/ANSI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/IT/ANSI/</guid><description>概述 参考：
Wiki, ANSI American National Standards Institute(美国国家标准协会，简称 ANSI) 是一家私人非营利组织，负责监督美国产品、服务、流程、系统和人员自愿共识标准的制定。 该组织还将美国标准与国际标准相协调，以便美国产品可以在全球范围内使用。</description></item><item><title>Ansible</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible/</guid><description>概述 参考：
官网 GitHub 项目，ansible/ansible 官方文档 公众号 - 程序员面试吧，快速入门 Ansible 自动化运维工具 https://www.zsythink.net/archives/tag/ansible/ Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems
Ansible 是一个非常简单的 IT 自动化系统。它处理配置管理、应用程序部署、云供应、临时任务执行、网络自动化和多节点编排。Ansible 可以轻松得批量进行复杂的更改，例如使用负载均衡器进行零停机滚动更新。而这一过程使用 SSH 实现，无需在远程系统上安装代理程序。
Ansible 的主要目标是简单易用。它还非常注重安全性和可靠性，具有最少的移动部件，使用 OpenSSH 进行传输（使用其他传输和拉模式作为替代），以及一种围绕人类可审计性设计的语言 - 即使是那些不熟悉的人该程序。</description></item><item><title>Ansible Collection</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Collection/Ansible-Collection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Collection/Ansible-Collection/</guid><description>概述 参考：
官方文档，使用 Ansible collections 官方文档，参考 - Collection 索引 Collection(集合) 是对 Ansible Plugins 和 Ansible Modules 的高层抽象。还可以包括 Playbooks、Role、Modules、Plugins。
随着 Ansible 的发展，越来越多的模块、插件被开发并加入到 Ansible 的大家庭，这时候难免会出现命名上的冲突，或者调用上的重复。所以，从 2.10 版本之后，提出了 Collections 的概念。
Collections 最大的一个功能就是将模块分类，比如以前 核心模块 command，现在的全名就叫 ansible.builtin.command，前面的 ansible.builtin 就是 command 的 Collections。这种全名称为 Full Qualified Class Name(完全限定类名，简称 FQCN)。
在 Ansible Galaxy 中可以找到非常多用户公开的 Collection。
关联文件与配置 ansible.builtin 参考：
官方文档，参考 - Collection 索引 - Ansible.Builtin Ansible 的内置 Collection，包括了全部的内置模块与内置插件（比如最常用的连接插件、文件模块等等）</description></item><item><title>Ansible Modules</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/Ansible-Modules/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/Ansible-Modules/</guid><description>概述 参考：
官方文档，使用 Ansible 模块和插件 - 模块介绍 2.10 版本 Modules(模块) 也被称为 Task Plugins(任务插件) 或 Library Plugins(插件库)，Modules 是可以从 Ansible 的命令行或 Playbook 的任务中使用的代码块。Ansible 通常在受管理节点上执行每个模块以完成任务，并收集返回值。
注意：在 Ansible 2.10 及以上的版本中，大多数模块都被托管到 Collection(集合) 中。
我们可以通过命令行使用模块执行任务，比如
ansible webservers -m service -a &amp;#34;name=httpd state=started&amp;#34; ansible webservers -m ping ansible webservers -m command -a &amp;#34;/sbin/reboot -t now&amp;#34; 也可以在 Playbooks 中使用模块执行任务，比如
- name: restart webserver service: name: httpd state: restarted 等效于
ansible webservers -m service -a &amp;#34;name=httpd state=started&amp;#34; 每个模块都可以接受参数，以空格分割的 KEY=VALUE 格式。</description></item><item><title>Ansible 管理</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E7%AE%A1%E7%90%86/Ansible-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E7%AE%A1%E7%90%86/Ansible-%E7%AE%A1%E7%90%86/</guid><description>实际案例： 批量关闭/开启虚拟机 - name: 获取虚拟机列表 virt: command: list_vms register: info - name: 循环开启虚拟机 virt: name: &amp;#34;{{ item }}&amp;#34; command: start loop: &amp;#34;{{ info.list_vms }}&amp;#34;</description></item><item><title>AnsiblePlugins</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Plugins/Ansible-Plugins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Plugins/Ansible-Plugins/</guid><description>概述 参考：
官方文档，使用插件 插件是增强 Ansible 核心功能的代码段。Ansible 使用插件架构来启用丰富，灵活和可扩展的功能集。
Ansible 附带了许多方便的插件，您可以轻松编写自己的插件。
本节介绍 Ansible 随附的各种类型的插件：
Action Plugins Become Plugins Cache Plugins Callback Plugins Cliconf Plugins Connection Plugins Httpapi Plugins Inventory Plugins Lookup Plugins Netconf Plugins Shell Plugins Strategy Plugins Vars Plugins Filters Plugins Tests Plugin Filter Configuration</description></item><item><title>API</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/API/</guid><description>概述 参考：
Wiki, API Application Programming Interface(应用程序接口，简称 API)。它定义了可以进行的调用或请求的类型，如何进行调用，应使用的数据格式，遵循的约定等。它还可以提供扩展机制，以便用户可以通过各种方式扩展现有功能。在不同程度上。API 可以是完全自定义的，特定于组件的，也可以基于行业标准设计以确保互操作性。通过信息隐藏，API 支持模块化编程，从而使用户可以独立于实现使用接口。
目的 在构建应用程序时，API（应用程序编程接口）通过抽象化底层实现并仅公开开发人员需要的对象或动作来简化编程。电子邮件客户端的图形界面可能会为用户提供执行获取和突出显示新电子邮件的所有步骤的按钮，而用于文件输入/输出的 API 可能会为开发人员提供一种将文件从一个位置复制到另一个位置的功能，而无需要求开发人员了解幕后发生的文件系统操作。
术语的历史 1978 年的一张图建议将 API 的概念扩展为一个通用的编程接口，而不仅仅是应用程序。
“API” 一词的含义已经扩展了其历史。首先，它仅描述了面向面向最终用户的程序（称为应用程序）的接口。此起源仍反映在名称“应用程序编程接口”中。如今，术语 API 的范围更广，不仅包括实用程序软件，甚至包括硬件接口。
API 的概念比该术语要古老得多。英国计算机科学家 Wilkes 和 Wheeler 在 1940 年代为 EDSAC 计算机开发了模块化软件库。约书亚·布洛赫（Joshua Bloch）声称威尔克斯和惠勒（Wilker and Wheeler）“潜在地发明”了该 API，因为它更多地是被发现而不是被发明的概念。
尽管创造 API 一词的人是在 Univac 1108 上实现软件，但他们的 API 的目标是使独立于硬件的程序成为可能。
术语“应用程序接口”（没有-ing后缀）首先被记录在称为纸张数据结构和技术对于远程计算机图形在呈现 AFIPS 在 1968 年会议[6] [4]所述的本文使用的作者该术语描述应用程序（在这种情况下为图形程序）与计算机系统其余部分的交互。一致的应用程序接口（包括 Fortran 子例程调用）旨在使程序员摆脱处理图形显示设备的特性，并在更换计算机或显示器时提供硬件独立性。
术语被引入到的场数据库由 CJ 日期中称为 1974 纸的关系和网络途径：应用程序编程接口的比较。 API 成为用于数据库管理系统的 ANSI/SPARC 框架的一部分。该框架将应用程序编程接口与其他接口（例如查询接口）分开对待。1970 年代的数据库专业人员发现，这些不同的接口可以组合在一起。一个足够丰富的应用程序接口也可以支持其他接口。
这种观察导致 API 支持所有类型的编程，而不仅是应用程序编程。到 1990 年，API 被技术专家 Carl Malamud 定义为“程序员可以用来执行某些任务的一组服务” 。</description></item><item><title>API Server</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-Server/API-Server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-Server/API-Server/</guid><description>概述 参考：
官方文档，概念 - 概述 - Kubernetes 组件 - kube-apiserver 官方文档，参考 - 通用组件 - kube-apiserver API Server 是实现 kubernetes API 的应用程序，它是 Kubernetes 控制平面的一个组件，用以对外暴露 Kubernetes API。Kubernetes API Server 验证和配置 API 对象的数据，包括 pod、service、replicationcontroller 等。 API Server 为 REST 操作提供服务，并为集群的共享状态提供前端，所有其他组件通过该前端进行交互。
如果是通过 kubeadm 安装的 k8s 集群，那么 API Server 的表现形式就是一个名为 kube-apiserver 的静态 pod。kube-apiserver 可以水平扩展，i.e. 部署多个 kube-apiserver 以实现高可用，应对高并发请求，到达 kube-apiserver 的流量可以在这些实例之间平衡。
API Server 启动后，默认监听在 6443 端口(http 默认监听在 8080 上)。API Server 是 Kubernetes 集群的前端接口 ，各种客户端工具（CLI 或 UI）以及 Kubernetes 其他组件可以通过它管理集群的各种资源。kubectl 就是 API Server 的客户端程序，实现对 k8s 各种资源的增删改查的功能。各个 node 节点的 kubelet 也通过 master 节点的 API Server 来上报本节点的 Pod 状态。</description></item><item><title>API 参考</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/API-%E5%8F%82%E8%80%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/API-%E5%8F%82%E8%80%83/</guid><description>概述 参考：
官方文档，参考 - API 概述 - API(这里是通过单一页面显示 API 资源各字段详解) 链接里是 1.23 的，想查看其他版本 API，改变 URL 中的版本即可。随着版本更新，老版本的页面会删除。 该页面的原始文件是符合 OpenAPI 格式的 swagger.json，位置在 kubernetes/kubernetes 仓库的 kubernetes/api/openapi-spec/swagger.json 官方文档，参考 - KubernetesAPI(这里是通过多级页面显示 API 资源各字段详解) 这些连接的内容，其实是 kubectl explain 命令的内容显示在浏览器中了。 GitHub 项目，kubernetes/api - core/v1/types.go 在本部分笔记后面的章节，各资源 Manifest 详解，其实已经描述了 API 中各个字段的含义。所以本篇文章不会详解每个 API，而是记录一下如何通过 Kubernetes 官网来查找 API 详解，以及如何使用官方文档查看 API 详解。
如果笔记中记录得不够详细，kubectl explain 命令也看着不方便，那么通过这篇文章中介绍的官方文档中的 API 详解来查看，将会更加直观。
Kubernetes API 参考中将会描述每种资源的 Manifests 中每个字段(即.YAML 中的节点)的含义。
这是单一页面的样子。左侧是根据对资源的分类而形成的目录，右侧是完整的页面
这是多级页面的样子，该 API 详解是内含在官方文档中的，并且对 API 进行了细致的分类
字段的类型占位符 官方文档中，将每个字段的类型，放在字段名称后面的 () 中，效果如图：
详见：PKM 中关于对各种文档的使用说明示例。</description></item><item><title>API 访问控制</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</guid><description>概述 参考：
官方文档，概念 - 安全 - Kubernetes API 的访问控制 认证用于身份验证，授权用于权限检查，准入控制机制用于补充授权机制
客户端与服务端的概念：谁向谁发请求，前者就是客户端，所在在这里，客户端与服务端没有绝对。一个服务既可以是客户端也可以是服务端，kubectl 在控制集群需要给 apiservice 发送 get，creat，delete 等指令的时候，kubectl 就是 apiservice 的客户端；而 apiservice 需要往 etcd 写入数据的时候，apiservice 就是 etcd 的客户端。
当客户端向服务端发起请求的时候，服务端需要对客户端进行认证以便确认客户端身份是否可以接入；接入后再进行授权检查，检查该身份的请求是否可以在服务端执行。所以后面介绍的 认证 与 授权 是相辅相成，不可分隔，创建完认证之后，需要为这个认证信息进行授权，才是一套完整的鉴权机制
比如现在有这么一个场景，张三要去商场买酱油。当张三到达商场后，保安人员首先要对张三进行认证，确认张三这个人可以进入商场；然后张三到达货柜拿走酱油去结账，收银人员进行授权检查，核验张三是否有权力购买酱油。
在 kubernetes 集群中，就是类似张三买酱油的场景。。。各个组件与资源对象之间的互相访问，在大多数时候，都需要进行认证与授权的检查。
API Server 是集群的入口，不管是对资源对象的增删改查，还是访问集群中的某些对象，不可避免得只能与 API Server 交互，虽然在访问某些管理组件的 https 端口时，也需要进行认证，但是这种访问是属于基本的 https 访问。所以，在与其说是 k8s 的认证与授权，不如说是 kubernetes API 的访问控制。因为不管是从外部(kubeclt 等)、还是内部(controller-manager、某个 pod 访问集群资源)，都逃不开与 kubernetes API，也就是 api-server 这个组件的交互。毕竟 kubernetes API 是集群的唯一入口。。。就算是在集群内部署的 pod，如果想要访问集群内的资源，也逃不开 kubernetes API~~
当然，使用 curl 命令来访问 controller、scheduler 时、或者 etcd 互相交互，都属于 认证与授权 的概念范畴~只不过这种情况不占大多数，所以就不再单独讨论了。这些认证授权方式与 API 的认证授权类似。</description></item><item><title>API 与 Resource</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E4%B8%8E-Resource/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E4%B8%8E-Resource/</guid><description>概述 参考：
官方文档，概念 - 概述 - Kubernetes API 官方文档，参考 - API 概述 Kubernetes API 使我们可以查询和操纵 Kubernetes API 中资源的状态。Kubernetes API 符合 RESTful 规范。
Kubernetes 把自身一切抽象理解为 Resource(资源)，也叫 API Resource(有地方也叫 Group Resource)。对集群的所有操作都是通过对 Kubernetes API 的 HTTP(s) 请求来实现的。可以使用命令 kubectl api-resources 命令查看所有支持的资源。
kubernetes 控制平面的核心是 API Server。API Server 是实现了 Kubernets API 的应用程序，并为 Kubernetes 公开了一个 HTTP(s) 的 API，以供用户、集群中的不同部分和集群外部组件相互通信。
Kubernetes 中各种资源(对象)的数据都通过 API 接口被提交到后端的持久化存储（etcd）中，Kubernetes 集群中的各部件之间通过该 API 接口实现解耦合，同时 Kubernetes 集群中一个重要且便捷的管理工具 kubectl 也是通过访问该 API 接口实现其强大的管理功能的。
Note：kubectl 就是代替用户执行各种 http 请求的工具
在 Kubernetes 系统中，在大多数情况下，API 定义和实现都符合标准的 HTTP REST 格式，比如通过标准的 HTTP 动词（POST、PUT、GET、DELETE）来完成对相关资源对象的查询、创建、修改、删除等操作。但同时，Kubernetes 也为某些非标准的 REST 行为实现了附加的 API 接口，例如 Watch 某个资源的变化、进入容器执行某个操作等。另外，某些 API 接口可能违背严格的 REST 模式，因为接口返回的不是单一的 JSON 对象，而是其他类型的数据，比如 JSON 对象流或非结构化的文本日志数据等。</description></item><item><title>Authentication(认证)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authentication%E8%AE%A4%E8%AF%81/Authentication%E8%AE%A4%E8%AF%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authentication%E8%AE%A4%E8%AF%81/Authentication%E8%AE%A4%E8%AF%81/</guid><description>概述 参考：
官方文档，参考 - API 访问控制 - 认证 Authentication(名词)/Authenticating(动词)(身份验证)，指明客户端是否有权限访问 API Server。
就好比我们在登录一个网站时，需要输入账户和密码的概念类似。在使用 API Server 时，也是通过类似的方式，使用账户来登录 API server(虽然不是真的登录)。
Accounts - Kubernetes 集群中的账号 Accounts 是一个在认证授权系统里的逻辑概念。Accounts 需要通过认证概念中的东西(比如证书、token、或者用户名和密码等)来建立。类似于登陆系统的账户。而在 Kubernetes 中，Accounts 分为如下两类
UserAccount(用户账户，简称 User) ServiceAccount(服务账户，简称 SA) [!Tip] UA 与 SA 的对比在 官方文档，参考 - API 访问控制 - 管理服务账号, User accounts 与 Service accounts 有提到，官方并没有对 UserAccount 进行明确的定义，偏向于一个没有实体的抽象概念，更多的时候是用 KubeConfig 这个词来作为 UserAccount 功能的实现。
UA 用来给人。SA 用来给运行在 pod 中的进程 UA 作用于全局，UA 的名字在集群的所有 namespace 中必须是唯一的。SA 作用于 namespace UA 于 SA 的账户审核注意事项是不同的，UA 的凭证信息需要在使用 kubectl config 命令时候的手动指定；SA 的凭证信息在创建 SA 后会自动生成对应的 secret 并把凭证信息保存其中。 User Account(用户账号) 详见：User Account(KubeConfig)</description></item><item><title>Authorization(授权)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authorization%E6%8E%88%E6%9D%83/Authorization%E6%8E%88%E6%9D%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authorization%E6%8E%88%E6%9D%83/Authorization%E6%8E%88%E6%9D%83/</guid><description>概述 参考：
官方文档，参考 - API 访问控制 - 授权 在 Kubernetes 中，在 Authorization(i.e.授予访问权限，简称：授权) 之前必须进行过 Authentication(认证)
授权流程 确定是允许还是拒绝请求 Kubernetes 使用 API 服务器授权 API 请求。它根据所有策略评估所有请求属性来决定允许或拒绝请求。 一个 API 请求的所有部分必须被某些策略允许才能继续。这意味着默认情况下拒绝权限。
（尽管 Kubernetes 使用 API 服务器，但是依赖于特定种类对象的特定字段的访问控制和策略由准入控制器处理。）
配置多个授权模块时，将按顺序检查每个模块。 如果任何授权模块批准或拒绝请求，则立即返回该决定，并且不会与其他授权模块协商。 如果所有模块对请求没有意见，则拒绝该请求。一个拒绝响应返回 HTTP 状态代码 403 。
审查您的请求属性 Kubernetes 仅审查以下 API 请求属性：
user - 身份验证期间提供的 user 字符串。 group - 经过身份验证的用户所属的组名列表。 extra - 由身份验证层提供的任意字符串键到字符串值的映射。 API - 指示请求是否针对 API 资源。 Request path - 各种非资源端点的路径，如 /api 或 /healthz。 API request verb - API 动词 get，list，create，update，patch，watch，proxy，redirect，delete 和 deletecollection 用于资源请求。要确定资源 API 端点的请求动词，请参阅确定请求动词。 HTTP request verb - HTTP 动词 get，post，put 和 delete 用于非资源请求。 Resource - 正在访问的资源的 ID 或名称（仅限资源请求） - 对于使用 get，update，patch 和 delete 动词的资源请求，您必须提供资源名称。 Subresource - 正在访问的子资源（仅限资源请求）。 Namespace - 正在访问的对象的名称空间（仅适用于命名空间资源请求）。 API group - 正在访问的 API 组（仅限资源请求）。空字符串表示核心 API 组。 确定请求动词 要确定资源 API 端点的请求动词，需要检查所使用的 HTTP 动词以及请求是否对单个资源或资源集合起作用：</description></item><item><title>Automation</title><link>https://desistdaydream.github.io/docs/12.AI/Automation/Automation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Automation/Automation/</guid><description>概述 参考：
Wiki 分类，Automation Wiki, Automation Automation(自动化) 描述了一系列减少流程中人为干预的技术</description></item><item><title>Bash</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash/</guid><description>概述 参考：
GNU 官网 Wiki, Bash 网道，Bash 脚本教程 Bourne Again Shell(简称 Bash) 是 Brian Fox 为 GNU 项目编写的 Unix Shell 和编程语言，作为 Bourne shell(简称 sh) 的免费软件替代品，于 1989 年首次发布，已被用作绝大多数 Linux 发行版的默认登录 Shell。Bash 是 Linus Torvalds 在移植 GCC 到 Linux 时最先移植的程序之一。
Bash 是一种 Shell，学习 Bash，其实也算是学习一种脚本式的编程语言，Bash 本身就是一种类似编译器似的存在。
Bash 关联文件与配置 全局配置文件，对所有用户生效的配置 /etc/environment # 系统的环境变量，所有登录方式都会加载的文件。
/etc/profile # 任何用户使用 shell 时都会加载的配置。linux 不推荐直接修改该文件。加载该配置时自动加载 /etc/profile.d/*.sh 的所有文件
/etc/bashrc # 常用于设置登录功能和命令别名。linux 不推荐直接修改该文件。加载该配置时自动加载 /etc/profile.d/*.sh 的所有文件
/etc/profile.d/*.sh # 类似于 include 的效果。通常用来创建自定义配置。
在 /etc/profile 和 /etc/bashrc 中都会有如下代码块</description></item><item><title>Blockchain</title><link>https://desistdaydream.github.io/docs/Blockchain/Blockchain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Blockchain/Blockchain/</guid><description>概述 参考：
Wiki, Blockchain Wiki, Cryptocurrency Blockchain(区块链)
2008 年 10 月 31 日 《Bitconi: A Peer-to-Peer Electronic Cash System 》
保证信息的完整性和真实性 保证信息的不可否认性 数字加密货币 参考：
如何把狗狗币|柴犬币 shib|放在 imtoken 钱包和 metamask 狐狸钱包中？ 这里教如何添加代币，如何添加钱包中的网络 https://www.youtube.com/watch?v=Gn4FCh5DEvg 【狐狸钱包】一分钟学会，如何一键添加各种主网？ https://www.youtube.com/watch?v=f1JU8TGImA0 钱包 参考：
Wiki, Cryptocurrency wallet https://support.metamask.io/start/learn/what-is-a-secret-recovery-phrase-and-how-to-keep-your-crypto-wallet-secure/ 什么是助记词以及如何保护加密钱包的安全 https://support.metamask.io/start/learn/metamask-is-a-self-custodial-wallet/ Metamask 是一个自托管钱包 Cryptocurrency wallet(加密货币钱包，简称 钱包) 本质上是一个具有唯一性的密钥对。私钥用来消费代币，公钥生成的地址用来接收代币。钱包本身不保存一共有多少加密货币。我们只能查看一条区块链中，某个地址的钱包的所有交易记录，通过这些交易记录计算出该钱包实际拥有多少代币。
一个钱包可以是 物理介质、程序、在线服务、etc. 只要该钱包可以生成一个地址，符合条件接入区块链网络即可。可以是任何形态。
一个钱包通常包含如下几个内容
PrivateKey(私钥) # 与公钥一同生成。也可以根据 BIP39 标准，由助记词生成 Secret Recovery Phrase(密钥恢复短语，也称：助记词) # 根据 BIP39 标准，通过助记词可以计算出私钥，但是私钥无法计算出助记词。助记词用来找回钱包的私钥 PublicKey(公钥) # 与私钥一同生成。可用于生成一个地址。 Address(地址) # 由公钥生成的用来标识钱包的唯一标识符。 钱包分为两种</description></item><item><title>Bootloader</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Bootloader/Bootloader/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Bootloader/Bootloader/</guid><description>概述 参考：
Wiki, Bootloader Bootloader(引导加载程序) 是负责 booting(引导) 计算器的软件。通常也被称为 Bootstrap Loader、Bootstrap。
当计算机关闭时，操作系统、应用程序代码和数据 ‍‌ 仍存储在非易失性存储器中。当计算机开机时，它通常没有操作系统或其随机存取存储器 (RAM) 中的加载程序。计算机首先执行存储在只读存储器（ROM，以及后来的 EEPROM、NOR 闪存）中的相对较小的程序以及一些需要的数据，以初始化 RAM（特别是在 x86 系统上），访问非易失性设备（通常是块设备，例如 NAND 闪存）或可以将操作系统程序和数据加载到 RAM 中的设备。
关联文件与配置 /boot/ # 所有关于系统引导启动的配置信息，都在该目录下
/boot/grub2/ #
/etc/default/grub # TODO: 好像不同系统路径不同？这是啥？
引导管理命令行工具 grub2-*
grubby
grub2-mkconfig</description></item><item><title>BPF</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF/</guid><description>概述 参考：
Wiki, BPF GitHub 项目,bcc-BPF 特性与 LInux 内核版本对照表 《Linux 内核观测技术 BPF》
Berkeley Packet Filter(伯克利包过滤器，简称 BPF)，是类 Unix 系统上数据链路层的一种原始接口，提供原始链路层封包的收发。在 Kernel 官方文档中，BPF 也称为 Linux Socket Filtering(LInux 套接字过滤，简称 LSF)。BPF 有时也只表示 filtering mechanism(过滤机制)，而不是整个接口。
注意：不管是后面描述的 eBPF 还是 BPF，这个名字或缩写，其本身所表达的含义，其实已经没有太大的意义了，因为这个项目的发展远远超出了它最初的构想。
在 BPF 之前，如果想做数据包过滤，则必须将所有数据包复制到用户空间中，然后在那里过滤它们，这种方式意味着必须将所有数据包复制到用户空间中，复制数据的开销很大。当然可以通过将过滤逻辑转移到内核中解决开销问题，我们来看 BPF 做了什么工作。
实际上，BPF 最早称为 BSD Packet Filter，是很早就有的 Unix 内核特性，最早可追溯到 1992 年发表在 USENIX Conference 上的一篇论文《BSD 数据包过滤：一种新的用户级包捕获架构》，这篇文章作者描述了他们如何在 Unix 内核实现网络数据包过滤，这种技术比当时最先进的数据包过滤技术快了 20 倍。这篇文章描述的 BPF 在数据包过滤上引入了两大革新：
一个新的虚拟机设计，可以有效得工作在基于寄存器结构的 CPU 之上。 应用程序使用缓存只复制与过滤数据包相关的数据，不会复制数据包的宿友信息。这样可以最大程度得减少 BPF 处理的数据。 随后，得益于如此强大的性能优势，所有 Unix 系统都将 BPF 作为网络包过滤的首选技术，抛弃了消耗更多内存和性能更差的原有技术实现。后来由于 BPF 的理念逐渐成为主流，为各大操作系统所接受，这样早期 &amp;ldquo;B&amp;rdquo; 所代表的 BSD 便渐渐淡去，最终演化成了今天我们眼中的 BPF(Berkeley Packet Filter)。</description></item><item><title>BPF 流量控制机制</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/</guid><description>概述 参考：
Kernel 网络官方文档：LInux Socket Filtering aka Berkeley Packet Filter</description></item><item><title>Browser</title><link>https://desistdaydream.github.io/docs/Web/Browser/Browser/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser/Browser/</guid><description>概述 参考：
Wiki, Web_browser 在访问一个网页时，除非收到 3XX 重定向的响应，否则浏览器地址栏中的地址是不会改变的。比如 Nginx 中的 rewrite 功能，如果不使用 redirect 或 permanent 标志，那么所有的 URL 改变都是针对 Nginx 内部来说的。
解决网页播放【鼠标移开屏幕或点击屏外视频暂停播放】 原文： https://www.jianshu.com/p/945851ea95da
从网页的 F12 中，元素-事件监听器 中
将【blur】所有内容【remove】掉 单击【mouseout】左边的倒三角，将出现的子元素全部remove掉， 将【mouseup】也用同样的操作移除掉子元素，现在就可以成功切换页面而不受限制啦! （点击Remove要精准，remove会把blur清除，不会进入其他设置）
注：可同时点开多个网页播放器并行播放不暂停，提高效率</description></item><item><title>Browser automation</title><link>https://desistdaydream.github.io/docs/Web/Browser-automation/Browser-automation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser-automation/Browser-automation/</guid><description>概述 参考：
实现浏览器自动化机制的 Awesome 项目
https://github.com/angrykoala/awesome-browser-automation WebDriver WebDriver 是一种浏览器自动化机制，通过模拟真实的人使用浏览器的动作来远程控制浏览器。它被广泛用于网络应用的跨浏览器测试。
详见 WebDriver
其他 Cypress # 多用于测试场景。
Playwright https://github.com/microsoft/playwright
Playwright 是一个由 Microsoft 开发的用于浏览器测试和网页抓取的开源自动化库，于 2020 年 1 月 31 日推出
基于 DevTools 的协议
使用 connectOverCDP 方法通过 Chrome DevTools Protocol(CDP) 连接</description></item><item><title>C</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/C/</guid><description>概述 参考：
ISO C 工作组官网 https://www.learn-c.org/ Wiki, C Programming Language 网道，C Hello World 代码：hello_world.c
#include &amp;lt;stdio.h&amp;gt; int main(void) { printf(&amp;#34;Hello World\n&amp;#34;); return 0; } 编译
gcc hello_world.c 运行
$ ./a.out Hello World</description></item><item><title>C 环境安装与使用</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/C-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/C-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/C-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/C-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>概述 参考：
安装 C 的环境一般指的是安装 GCC 或 Clang</description></item><item><title>Ceph</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph/</guid><description>概述 参考：
官网 官方文档 Wiki, Ceph https://blog.csdn.net/younger_china/article/details/73410727 Ceph 是一个开源的分布式存储系统，可以提供 对象存储、快存储、文件存储 能力。是一个 Software Defined Storage(软件定义存储) 的代表性产品。
一个 Ceph 存储集群至少需要 Ceph Monitor、Ceph Manager、Ceph OSD 这三个组件；如果要运行 Ceph 文件系统客户端，则也需要 Ceph MDS。
Monitor # Ceph Monitor(Ceph 监视器，简称 ceph-mon) 负责维护集群状态的映射关系。通常至少需要 3 个 ceph-mon 以实现高可用，多节点使用 Paxos 算法达成共识。 可以这么说，Ceph 集群就是指 ceph-mon 集群。ceph-mon 负责维护的集群状态，就是用来提供存储服务的。 ceph-mon 映射、ceph-mgr 映射、ceph-osd 映射、ceph-mds 映射、ceph-crush 映射。这些映射是 Ceph 守护进程相互协调所需的关键集群状态，说白了，就是映射关系。 这里的映射，英文用的是 Map，其实也有地图的意思，就是表示这个集群有多少个 ceph-mon、有多少个 ceph-mgr 等等，还有底层对象属于哪个 PG，等等等等，这些东西构成了一副 Ceph 的运行图。 ceph-mon 还负责管理守护进程和客户端之间的身份验证。 Manager # Ceph Manager(Ceph 管理器，简称 ceph-mgr) 负责跟踪运行时指标和 Ceph 集群的当前状态，包括存储利用率、性能、系统负载等。通常至少需要 2 个 ceph-mgr 以实现高可用。 ceph-mgr 可以提供 Web 管理页面、关于 Ceph 集群的 Prometheus 格式的监控指标 OSD Daemon # Ceph OSD Daemon(Ceph OSD 守护进程，简称 ceph-osd) 负责向 OSD 读写数据、处理数据复制、恢复、重新平衡，并通过检查其他 ceph-osd 的心跳向 ceph-mon 和 ceph-mgr 提供一些监控信息。通常至少需要 3 个 ceph-osd 以实现高科用。 Object Storage Device(对象存储设备，简称 OSD) 是一个物理或逻辑上的存储单元(比如一块硬盘)，这是 Ceph 得以运行的最基本的存储单元。 有的时候，人们容易把 OSD 理解为 Ceph OSD Daemon，这俩是有本质区别的。因为在最早的时候，OSD 有两种含义，一种是 Object Storage Device 另一种是 Object Storage Daemon。由于这种称呼的模糊性，后来就将 Object Storage daemon 扩展为 OSD Daemon。OSD 则仅仅代表 Object Storage Device。只不过运行 OSD Daemon 的程序名称，依然沿用了 osd 的名字。 注意，为了让每一个 OSD 都可以被单独使用并管理，所以每个 OSD 都有一个对应的 ceph-osd 进程来管理。一般情况，Ceph 集群中每个节点，除了系统盘做 Raid 以外，其他硬盘都会单独作为 OSD 使用，且一个节点会有大量磁盘来对应 OSD。 MDS # Ceph Metadata Server(Ceph 元数据服务器，简称 ceph-mds) 代表 Ceph 文件系统元数据。ceph-mds 允许 POSIX 文件系统用户执行基本命令(比如 ls、find 等)，而不会给 Ceph 集群带来巨大负担。 注意，Ceph 提供的 块存储 和 对象存储 功能并不使用 ceph-mds。 架构 参考：</description></item><item><title>Cilium</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Cilium/Cilium/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Cilium/Cilium/</guid><description>概述 参考：
GitHub 项目，cilium/cilium 官网 官方文档 https://docs.google.com/presentation/d/1cZJ-pcwB9WG88wzhDm2jxQY4Sh8adYg0-N3qWQ8593I/edit#slide=id.g7608b8c2de_0_0 https://www.youtube.com/watch?v=bIRwSIwNHC0 http://arthurchiao.art/blog/ebpf-and-k8s-zh/
常见问题 如果在设备 A 添加了到 PodIP 段的静态路由，从集群外部直接访问 pod ip 是不通的。。。。。icmp 行。。。其他不行。。好像在 datapath 处理的时候，给略过了。。。。</description></item><item><title>Cipher</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cipher/Cipher/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cipher/Cipher/</guid><description>概述 参考：
Wiki, Cipher Cipher 在密码学中表示一种用于执行加密或解密的 algorithm(算法)。Cipher 不太好翻译中文，password 是密码，Cipher 可以理解为一套密码系统，i.e. 一系列可以作为过程遵循的明确定义的步骤
注意：cipher 和 cypher 是同一个意思，两种不同的拼写方法
Block cipher 与 Stream cipher 随着时代的发展，曾经对每个字节进行加密的方式不再显示，一个动辄几个 G 的文件，如果使用与明文相同的密钥进行加密，那么密钥也需要几个 G，这给密钥的分发造成了苦难，这时，可以将原始明文划分成多个长度相同的小块（也就是分组），然后使用和这些小块长度相同改的密钥依次和所有分组中的明文进行异或运算以进行加密，这就是早期的 Block cipher 加密算法。解密时，先对密文进行同样大小的分组，然后用相同的密钥和所有的密文块异或，再合并得到明文。
TODO: Stream cipher 算法是基于什么痛点出现的呢？</description></item><item><title>ClickHouse</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/ClickHouse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/ClickHouse/</guid><description>概述 参考：
GitHub 项目，ClickHouse/ClickHouse 官网 存算分离，查询性能过剩
https://clickhouse.com/docs/en/guides/sre/network-ports
端口号 描述 2181 ZooKeeper default service port. Note: see 9181 for ClickHouse Keeper 8123 HTTP default port 8443 HTTP SSL/TLS default port 9000 原生协议端口（也称为 ClickHouse TCP 协议）。由 ClickHouse 生态的应用程序和进程使用（e.g. 各种语言利用 SDK 编写的程序、clickhouse-client 等自带程序、etc.）。也用于分布式查询的内部服务器之间的通信。 9440 与 9000 的功能相同，但是带有 SSL/TLS 9004 MySQL emulation port 9005 PostgreSQL emulation port (also used for secure communication if SSL is enabled for ClickHouse). 9009 Inter-server communication port for low-level data access.</description></item><item><title>CNI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/CNI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/CNI/</guid><description>概述 参考：
GitHub 项目 GitHub,containernetworking-cni-规范 CNI 与 OCI 是类似的东西，都是一种规范。
Container Network Interface(容器网络接口，简称 CNI) 是一个 CNCF 项目，用于编写为 Linux 容器配置网络接口的插件。CNI 由两部分组成：
CNI Specification(规范) CNI Libraries(库) 由于 CNI 仅仅关注在容器的网络连接以及在删除容器时移出通过 CNI 分配的网络资源。所以，CNI 具有广泛的支持，并且该规范易于实现。
CNI Specification(规范) 每个 CNI 插件必须由 二进制文件 来实现，且这些文件应该可以被容器管理系统(比如 Kubernetes)调用。
CNI 插件负责将网络接口插入容器网络名称空间(例如 veth 对的一端)中，并在主机上进行任何必要的更改(例如将 veth 的另一端连接到网桥)。然后通过调用适当的 IPAM 插件，将 IP 分配给接口并设置与 IP 地址管理部分一致的路由。
CNI Libraries(库) 任何程序都可以调用 CNI 库来实现容器网络，比如 nerdctl、kubelet 等
CNI 的部署和使用方式 官方文档：https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#installation
CNI 规范与编程语言无关，并且 CNI 自身仅仅维护标准配置文件和基础插件，想要使用 CNI 来实现容器网络，只需根据标准，调用 CNI 库，即可在程序中实现(比如 nerdctl、kubelet 等)。这些通过 CNI 库实现了容器网络的程序，通过 CNI 插件为其所启动的容器，创建关联网络。</description></item><item><title>Cobbler</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/Cobbler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/Cobbler/</guid><description>前言 网络安装服务器套件 Cobbler(补鞋匠) 出现以前，我们一直在做装机民工这份很有前途的职业。自打若干年前 Red Hat 推出了 Kickstart，此后我们顿觉身价倍增。不再需要刻了光盘一台一台地安装 Linux，只要搞定 PXE、DHCP、 TFTP，还有那满屏眼花缭乱不知所云的 Kickstart 脚本，我们就可以像哈里波特一样，轻点魔棒，瞬间安装上百台服务器。这一堆花里胡哨的东西可不是一般人都能整明白的，没有大专以上学历，通不过英语四级， 根本别想玩转。
总而言之，这是一份多么有前途，多么有技术含量的工作啊。
很不幸，Red Hat 最新（Cobbler 项目最初在 2008 年左右发布）发布了网络安装服务器套件 Cobbler(补鞋匠)，它已将 Linux 网络安装的技术门槛，从大专以上文化水平，成功降低到初中以下，连补鞋匠都能学会。
对于我们这些在装机领域浸淫多年，经验丰富，老骥伏枥，志在千里的民工兄弟们来说，不啻为一个晴天霹雳。
概述 参考：
GitHub 项目，cobbler/cobbler 官网 Cobbler 是一个 Linux 服务器快速网络安装的服务，而且在经过调整也可以支持网络安装 windows。
该工具使用 python 开发，小巧轻便（才 15k 行 python 代码），可以通过网络启动(PXE)的方式来快速安装、重装物理服务器和虚拟机，同时还可以管理 DHCP，DNS，TFTP、RSYNC 以及 yum 仓库、构造系统 ISO 镜像。
Cobbler 可以使用命令行方式管理，也提供了基于 Web 的界面管理工具(cobbler-web)，还提供了 API 接口，可以方便二次开发使用。
Cobbler 是较早前的 kickstart 的升级版，优点是比较容易配置，还自带 web 界面比较易于管理。
Cobbler 内置了一个轻量级配置管理系统，但它也支持和其它配置管理系统集成，如 Puppet，暂时不支持 SaltStack。
Cobbler 客户端 Koan 支持虚拟机安装和操作系统重新安装，使重装系统更便捷。
Cobbler 可以干啥 使用 Cobbler，您无需进行人工干预即可安装机器。Cobbler 设置一个 PXE 引导环境（它还可以使用 yaboot 支持 PowerPC），并 控制与安装相关的所有方面，比如网络引导服务（DHCP 和 TFTP）与存储库镜像。当希望安装一台新机器时，Cobbler 可以：</description></item><item><title>Collector</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Collector/Collector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Collector/Collector/</guid><description>概述 参考：
GitHub 项目，open-telemetry/opentelemetry-collector 官方文档，Collector OpenTelemetry Collector 提供了一种与供应商无关的 receive(接收)、process(处理) 和 export(导出) 遥测数据的实现。它消除了运行、操作和维护多个代理/收集器的需要。这具有改进的可扩展性，并支持开源可观测性数据格式（例如 Jaeger、Prometheus、Fluent Bit、etc. ）发送到一个或多个开源或商业后端。
Collector 会根据配置定时采集数据或被动接收数据以缓存，然后可以主动推送或被动等待拉取。Prometheus 可以配置 static_configs 从 OTel Collector 抓取其缓存的最新数据。
架构 参考：
官方文档，Collector - 架构 OTel Collector 是一种 DataPipeline 的实现程序，通常分为如下几种 Pipeline component(管道组件)
Receiver(接收器) # Receivers 从一个或多个来源收集遥测数据。ta 们可以是基于 pull 或 push 的，并且可以支持一个或多个数据源。 Processor(处理器) # 处理 Receivers 收到的数据 Exporter(导出器) # Exproters 将数据发送到一个或多个后端或目的地。Exproters 可以是基于 pull 或 push 的，并且可以支持一个或多个数据源。 --- title: Pipeline --- flowchart LR R1(Receiver 1) --&amp;gt; P1[Processor 1] R2(Receiver 2) --&amp;gt; P1 RM(.</description></item><item><title>Common Definitions(通用定义)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/</guid><description>概述 参考：
官方文档，参考-KubernetesAPI-通用定义 Common Definitions(通用定义)
DeleteOptions DeleteOptions may be provided when deleting an API object.
LabelSelector A label selector is a label query over a set of resources.
ListMeta ListMeta describes metadata that synthetic resources must have, including lists and various status objects.
LocalObjectReference LocalObjectReference contains enough information to let you locate the referenced object inside the same namespace.
NodeSelectorRequirement A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.</description></item><item><title>通信协议</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Communication-protocol/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Communication-protocol/</guid><description>概述 参考：
Wiki, Communication Protocol(通信协议) Wiki, Encapsulation(封装) Wiki, PDU 注：Wiki 中将网络层 PDU 描述为 Packet 不够准确，详见 RFC 1594 中 13 节 Packet 的名词解释 Wiki, SDU RFC 1325、RFC 1594、RFC 2664 这几个 RFC 是一些关于互联网的仅供参考的常见问答，里面包含一些名词解释，2664 是最新版 Communication Protocol(通信协议) 是一个规则系统，允许通信系统的两个或多个实体通过物理量的任何变化来传输信息。该协议定义了通信的规则、语法、语义和同步以及可能的错误恢复方法。协议可以通过硬件、软件或两者的组合来实现。
网络系统的分层架构 因特网是一个极为复杂的系统，这个系统有许多部分：大量的应用程序和协议、各种类型的端系统、分组交换机和各种类型的链路级媒体 等等等等。面对这种巨大的复杂性，我们迫切得需要组织整个网络体系结构。
网络设计者以 Layer(分层) 的方式组织协议以及实现这些协议的硬件/软件。每个协议属于这些层次之一，各层的所有协议被统称为 Protocol Stack(协议栈)。
Encapsulation(封装) Encapsulation(封装) 是一种设计模块化通信协议的方法，是将上层数据经过处理，变为下层数据的过程。处理完成后的实体称为 Protocol Data Unit(协议数据单元，简称 PDU) 或 Service Data Unit(服务数据单元，简称 SDU)。
PDU 与 SDU 通常来说可以一起理解，楞要说区别，可有有以下几点
SDU 并不会跨主机，可以说，比如说同一个主机应用层往传输层发送的内容。而 PDU 则是两个不同主机，由 A 主机应用层发送到 B 主机应用层的内容。 SDU 是 PDU 的一个子集 SDU 是 PDU 中的一个 Payload(有效载荷) 比如，主机 A 要向主机 B 发送一条信息。这条信息就称为 Data(数据)/Payload(有效载荷)。这条消息从主机 A 发送出去之前，会被各种协议进行处理，这个处理的过程，就是 Encapsulation(封装)，封装之后的产物就是 PDU，不同网络层的 PDU 叫法不同：</description></item><item><title>Compose</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/Compose/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/Compose/</guid><description>概述 参考：
官方文档 菜鸟教程 Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以通过该配置文件创建并启动所有服务。
Compose 使用的三个步骤：
使用 Dockerfile 定义应用程序的环境。 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。 最后，执行 docker-compose up 命令来启动并运行整个应用程序。 docker-compose.yml 的配置案例如下（配置参数参考下文）：
compose 文件示例 # yaml 配置实例 version: &amp;#39;3&amp;#39; services: web: build: . ports: - &amp;#34;5000:5000&amp;#34; volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redis volumes: logvolume01: {} Compose 安装 Compose 安装就是 compose CLI
安装 Docker 的 Compose 插件 官方推荐以 Docker CLI Plugin 的方式使用 Compose</description></item><item><title>Computer</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Computer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Computer/</guid><description>概述 参考：
Wiki, Computer 冯·诺依曼
CPU
Memory
Disk
计算机工作的原理 参考：
公众号-码农的荒岛求生，你管这破玩意叫 CPU ？ B 站-幼麟实验室，迷你计算机(小白入门)：计算机工作的原理 每次回家开灯时你有没有想过，用你按的简单开关实际上能打造出复杂的 CPU 来，只不过需要的数量会比较多，也就几十亿个吧。
伟大的发明-晶体管 过去 200 年人类最重要的发明是什么？蒸汽机？电灯？火箭？这些可能都不是，最重要的也许是这个小东西：
这个小东西就叫晶体管，你可能会问，晶体管有什么用呢？
实际上晶体管的功能简单到不能再简单，给一端通上电，那么电流可以从另外两端通过，否则不能通过，其本质就是一个开关。
就是这个小东西的发明让三个人获得了诺贝尔物理学奖，可见其举足轻重的地位。
无论程序员编写的程序多么复杂，软件承载的功能最终都是通过这个小东西简单的开闭完成的，除了神奇二字，我想不出其它词来。
AND、OR、NOT 现在有了晶体管，也就是开关，在此基础之上就可以搭积木了，你随手搭建出来这样三种组合：
两个开关只有同时打开电流才会通过，灯才会亮 两个开关中只要有一个打开电流就能通过，灯就会亮 当开关关闭时电流通过灯会亮，打开开关灯反而电流不能通过灯会灭 天赋异禀的你搭建的上述组合分别就是：与门，AND Gate、或门，OR gate、非门，NOT gate，用符号表示就是这样：
道生一、一生二、二生三、三生万物
最神奇的是，你随手搭建的三种电路竟然有一种很 amazing 的特性，那就是：任何一个逻辑函数最终都可以通过 AND、OR 以及 NOT 表达出来，这就是所谓的逻辑完备性，就是这么神奇。
也就是说**给定足够的 AND、OR 以及 NOT 门，就可以实现任何一个逻辑函数，除此之外我们不需要任何其它类型的逻辑门电路，**这时我们认为 AND、OR、NOT 门就是逻辑完备的。
这一结论的得出吹响了计算机革命的号角，这个结论告诉我们计算机最终可以通过简单的 AND、OR、NOT 门构造出来，这些简单的逻辑门电路就好比基因。 老子有云：道生一、一生二、二生三、三生万物，实乃异曲同工之妙。
虽然，我们可以用 AND、OR、NOT 来实现所有的逻辑运算，但我们真的需要把所有的逻辑运算都用 AND、OR、NOT 门实现出来吗？显然不是，而且这也不太可行。
逻辑门 计算能力是怎么来的 现在能生成万物的基础元素与或非门出现了，接下来我们着手设计 CPU 最重要的能力：计算，以加法为例。
由于 CPU 只认知 0 和 1，也就是二进制，那么二进制的加法有哪些组合呢：</description></item><item><title>Containerd</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd/</guid><description>概述 参考：
官网 GitHub 项目，containerd/containerd GitHub 项目文档，containerd/docs/PLUGINS.md 云原生实验室，Containerd 使用教程 架构小白，Containerd 标签 公众号-云原生实验室，容器中的 Shim 到底是个什么鬼 Containerd 是行业标准的容器运行时，着重于简单性，健壮性和可移植性。
Containerd 的前世今生 很久以前，Docker 强势崛起，以“镜像”这个大招席卷全球，对其他容器技术进行致命的降维打击，使其毫无招架之力，就连 Google 也不例外。Google 为了不被拍死在沙滩上，被迫拉下脸面（当然，跪舔是不可能的），希望 Docker 公司和自己联合推进一个开源的容器运行时作为 Docker 的核心依赖，不然就走着瞧。Docker 公司觉得自己的智商被侮辱了，走着瞧就走着瞧，谁怕谁啊！
很明显，Docker 公司的这个决策断送了自己的大好前程，造成了今天的悲剧。
紧接着，Google 联合 Red Hat、IBM 等几位巨佬连哄带骗忽悠 Docker 公司将 libcontainer 捐给中立的社区（OCI，Open Container Intiative），并改名为 runc，不留一点 Docker 公司的痕迹。。。这还不够，为了彻底扭转 Docker 一家独大的局面，几位大佬又合伙成立了一个基金会叫 CNCF（Cloud Native Computing Fundation），这个名字想必大家都很熟了，我就不详细介绍了。CNCF 的目标很明确，既然在当前的维度上干不过 Docker，干脆往上爬，升级到大规模容器编排的维度，以此来击败 Docker。Docker 公司当然不甘示弱，搬出了 Swarm 和 Kubernetes 进行 PK，最后的结局大家都知道了，Swarm 战败。然后 Docker 公司耍了个小聪明，将自己的核心依赖 Containerd 捐给了 CNCF，以此来标榜 Docker 是一个 PaaS 平台。
很明显，这个小聪明又大大加速了自己的灭亡。</description></item><item><title>Containerd 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Containerd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Containerd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
Manual(手册),containerd-config.toml(5) Debian Manual Containerd 使用 TOML 作为配置文件的格式，默认配置文件为 /etc/containerd/config.toml，我们可以通过命令来生成一个包含所有配置字段的默认配置文件
mkdir -p /etc/containerd containerd config default &amp;gt; /etc/containerd/config.toml 配置文件详解 [通用] 配置 version = 2 # root = &amp;lt;STRING&amp;gt; # Containerd 持久化数据路径。默认值：/var/lib/containerd。 state = &amp;lt;STRING&amp;gt; # Containerd 临时数据路径。默认值：/run/containerd。 oom_score = 0 # 设置 Containerd 的 OOM 权重。默认值：0。 Containerd 是容器的守护者，一旦发生内存不足的情况，理想的情况应该是先杀死容器，而不是杀死 Containerd。所以需要调整 Containerd 的 OOM 权重，减少其被 OOM Kill 的几率。最好是将 oom_score 的值调整为比其他守护进程略低的值。这里的 oom_socre 其实对应的是 /proc/&amp;lt;pid&amp;gt;/oom_socre_adj，在早期的 Linux 内核版本里使用 oom_adj 来调整权重, 后来改用 oom_socre_adj 了。该文件描述如下： 在计算最终的 badness score 时，会在计算结果是中加上 oom_score_adj ,这样用户就可以通过该在值来保护某个进程不被杀死或者每次都杀某个进程。其取值范围为 -1000 到 1000。如果将该值设置为 -1000，则进程永远不会被杀死，因为此时 badness score 永远返回 0。建议 Containerd 将该值设置为 -999 到 0 之间。如果作为 Kubernetes 的 Worker 节点，可以考虑设置为 -999。</description></item><item><title>Containerization</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Containerization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Containerization/</guid><description>概述 参考：
Wiki, Containerization Wiki, OS-level virtualization MoeLove，一篇搞懂容器技术的基石： cgroup Container(容器) 是一种基础工具；泛指任何可以用于容纳其它物品的工具，可以部分或完全封闭，被用于容纳、储存、运输物品。物体可以被放置在容器中，而容器则可以保护内容物。人类使用容器的历史至少有十万年，甚至可能有数百万年的历史。
自 1979 年，Unix 版本 7 引用 Chroot Jail 以及 Chroot 系统调用开始，直到 2013 年开源出的 Docker，2014 年开源出来的 Kubernetes，直到现在的云原生生态的火热。容器技术已经逐步成为主流的基础技术之一。
一、什么是容器 IT 里的容器技术是英文单词 Linux Container 的直译。Container 这个单词有集装箱、容器的含义（主要偏集装箱意思）。不过，在中文环境下，咱们要交流要传授，如果翻译成“集装箱技术” 就有点拗口，所以结合中国人的吐字习惯和文化背景，更喜欢用容器这个词。不过，如果要形象的理解 Linux Container 技术的话，还是得念成集装箱会比较好。我们知道，海边码头里的集装箱是运载货物用的，它是一种按规格标准化的钢制箱子。集装箱的特色，在于其格式划一，并可以层层重叠，所以可以大量放置在特别设计的远洋轮船中（早期航运是没有集装箱概念的，那时候货物杂乱无章的放，很影响出货和运输效率）。有了集装箱，那么这就更加快捷方便的为生产商提供廉价的运输服务。
因此，IT 世界里借鉴了这一理念。早期，大家都认为硬件抽象层基于 hypervisor 的虚拟化方式可以最大程度上提供虚拟化管理的灵活性。各种不同操作系统的虚拟机都能通过 hypervisor（KVM、XEN 等）来衍生、运行、销毁。然而，随着时间推移，用户发现 hypervisor 这种方式麻烦越来越多。为什么？因为对于 hypervisor 环境来说，每个虚拟机都需要运行一个完整的操作系统以及其中安装好的大量应用程序。但实际生产开发环境里，我们更关注的是自己部署的应用程序，如果每次部署发布我都得搞一个完整操作系统和附带的依赖环境，那么这让任务和性能变得很重和很低下。
基于上述情况，人们就在想，有没有其他什么方式能让人更加的关注应用程序本身，底层多余的操作系统和环境我可以共享和复用？换句话来说，那就是我部署一个服务运行好后，我再想移植到另外一个地方，我可以不用再安装一套操作系统和依赖环境。这就像集装箱运载一样，我把货物一辆兰博基尼跑车（好比开发好的应用 APP），打包放到一容器集装箱里，它通过货轮可以轻而易举的从上海码头（CentOS7.2 环境）运送到纽约码头（Ubuntu14.04 环境）。而且运输期间，我的兰博基尼（APP）没有受到任何的损坏（文件没有丢失），在另外一个码头卸货后，依然可以完美风骚的赛跑（启动正常）。
二、容器技术的实现方式，lxc、runc、kata 等 Linux Container(LXC) 容器技术的诞生（2008 年）就解决了 IT 世界里“集装箱运输”的问题。Linux Container（简称 LXC）它是一种 内核轻量级的操作系统层 虚拟化技术，也称为容器的运行时(runtime 运行环境)。Linux Container 主要由 Namespace 和 Cgroup 两大机制来保证实现。那么 Namespace 和 Cgroup 是什么呢？刚才我们上面提到了集装箱，集装箱的作用当然是可以对货物进行打包隔离了，不让 A 公司的货跟 B 公司的货混在一起，不然卸货就分不清楚了。那么 Namespace 也是一样的作用，做隔离。光有隔离还没用，我们还需要对货物进行资源的管理。同样的，航运码头也有这样的管理机制：货物用什么样规格大小的集装箱，货物用多少个集装箱，货物哪些优先运走，遇到极端天气怎么暂停运输服务怎么改航道等等&amp;hellip; 通用的，与此对应的 Cgroup 就负责资源管理控制作用，比如进程组使用 CPU/MEM 的限制，进程组的优先级控制，进程组的挂起和恢复等等。</description></item><item><title>Containerization implementation</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerization-implementation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerization-implementation/</guid><description>概述 参考：
OCI Runtime 规范的实现 参考：
公众号-k8s 技术圈，Containerd 深度剖析-runtime 篇 当人们想到容器运行时，可能会想到一连串的相关概念；runc、runv、lxc、lmctfy、Docker（containerd）、rkt、cri-o。每一个都是基于不同的场景而实现的，均实现了不同的功能。如 containerd 和 cri-o，实际均可使用 runc 来运行容器，但其实现了如镜像管理、容器 API 等功能，可以将这些看作是比 runc 具备的更高级的功能。
可以发现，容器运行时是相当复杂的。每个运行时都涵盖了从低级到高级的不同部分，如下图所示
根据功能范围划分，将其分为 Low level Container Runtime(低级容器运行时) 和 High level Container Runtime(高级容器运行时)
低级容器运行时 # 只关注容器的本身运行 高级容器运行时 # 支持更多高级功能的运行时，如镜像管理及一些 gRPC/Web APIs，通常被称为 需要注意的是，低级运行时和高级运行时有本质区别，各自解决的问题也不同。
低级运行时 低级运行时的功能有限，通常执行运行容器的低级任务。大多数开发者日常工作中不会使用到。其一般指按照 OCI 规范、能够接收可运行 roofs 文件系统和配置文件并运行隔离进程的实现。这种运行时只负责将进程运行在相对隔离的资源空间里，不提供存储实现和网络实现。但是其他实现可以在系统中预设好相关资源，低级容器运行时可通过 config.json 声明加载对应资源。低级运行时的特点是底层、轻量，限制也很一目了然：
只认识 rootfs 和 config.json，没有其他镜像能力 不提供网络实现 不提供持久实现 无法跨平台等 RunC 参考：
GitHub 项目，opencontainers/runc runc 是一个 CLI 工具，用于根据 OCI 规范生成和运行容器。
youki 参考：
GitHub 项目，containers/youki 使用 Rust 语言写的，类似于 Runc 的容器运行时，</description></item><item><title>Control structure</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/Control-structure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/Control-structure/</guid><description>概述 参考:
官方文档，参考 - 语言规范 - 语句 Go 语言提供了 4 种条件结构和分支结构用作 Control structure(控制结构)。在结构中，可以使用 break 和 continue 这样的关键字来中途改变结构的状态。还可以使用 return 来结束某个函数的执行，或使用 goto 和标签来调整程序的执行位置
Tips: 在 Go 语言种，将这种控制结构描述为 flow of control
for 循环 参考：
Go 官方文档，参考 - 语言规范 - For 语句 知乎，Golang那些坑 - 使用 for 循环的注意事项 用于测试某个条件(布尔型或逻辑型)的语句，初始化语句执行完成之后；如果该条件成立，则会执行 if 后由大括号括起来的代码块，然后执行修饰语句，之后再次判断条件语句是否成立，如此循环；直到条件语句不成立时，就忽略该代码块继续执行后续的代码。
基本格式：for 初始化语句;条件语句;修饰语句 {代码块} for range [!Warning] 注意 for range 的 内存逃逸 问题
if else 判断 switch 判断 给定一个变量，当该变量满足某个条件时执行某个代码。
select 与 switch 类似
break 与 continue break 用于退出当前当前代码块 continue 用于忽略当前循环，继续执行后续循环，只用于 for 结构体中 Note：注意！是退出当前代码块，如果循环有多层嵌套，那么只是退出当前循环；如果循环中套用 select 等，则也是退出当前控制结构。 标签与 goto 标签用于在出现标签关键字的时候，代码回到标签定义行再继续执行下面的代码。某一行以:冒号结尾的单词即可定义标签。标签区分大小写</description></item><item><title>Controller</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/Controller/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/Controller/</guid><description>概述 参考：
官方文档，概念 - 集群架构 - 控制器 Controller(控制器) 是 Kubernetes 的大脑
在机器人和自动化技术中，控制环是一个控制系统状态不终止的循环。
比如：房间里的温度自动调节器，当我设置了温度，告诉温度调节器我的期望状态。房间的实际温度是当前状态。温度自动调节器就会让当前状态一直去接近期望状态。
kubernetes 的 Controller 就是这样一种东西，通过 apiserver 监控集群的期望状态，并致力于将当前状态转变为期望状态。而 controller 是一个更高层次的抽象概念，指代多种具有 controller 功能的资源，比如 deployment、statefulset 等等。
可以用一段 Go 语言风格的伪代码，来描述这个控制循环：
for { 实际状态 := 获取集群中对象 X 的实际状态（Actual State） 期望状态 := 获取集群中对象 X 的期望状态（Desired State） if 实际状态 == 期望状态{ 什么都不做 } else { 执行编排动作，将实际状态调整为期望状态 } } 在具体实现中，实际状态一般来自于 kubernetes 集群本身，e.g.kubelet 收集所在节点上容器状态和节点状态。而期望状态，一般来自于用户提交的 YAMl 文件。
以 Deployment 这种控制器为例，简单描述一下它对控制器模型的实现：
控制器从 Etcd 中获取到所有携带了“app: nginx”标签的 Pod，然后统计它们的数量，这就是实际状态； 用户提交的 yaml 文件中 Replicas 字段的值就是期望状态(提交的 yaml 也会保存到 etcd 中)； 控制器将两个状态做比较，然后根据比较结果，确定是创建 Pod，还是删除已有的 Pod 。 这个对比的操作通常被叫作 Reconcile(调和)。这个调谐的过程，则被称作 Reconcile Loop(调和循环) 或者 Sync Loop(同步循环)。这些词其实都代表一个东西：控制循环。</description></item><item><title>CPU</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/CPU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/CPU/</guid><description>概述 参考：
Wiki, Central_processing_unit Central Processing Unit(中央处理器，简称 CPU)。
如同华硕主板示意图上半部的中央部分，那就是 CPU 插槽。由于 CPU 负责大量运算，因此 CPU 通常是具有相当高发热量的元件。所以如果你曾经拆开过主板，应该就会看到 CPU 上头通常会安插一颗风扇来主动散热的。
x86 个人电脑的 CPU 主要供应商为 Intel 与 AMD，目前（2015）主流的 CPU 都是双核以上的架构了！原本的单核心 CPU 仅有一个运算单元，所谓的多核心则是在一颗 CPU 封装当中嵌入了两个以上的运算核心， 简单的说，就是一个实体的 CPU 外壳中，含有两个以上的 CPU 单元就是了。
不同的 CPU 型号大多具有不同的脚位（CPU 上面的插脚），能够搭配的主板芯片组也不同， 所以当你想要将你的主机升级时，不能只考虑 CPU，你还得要留意你的主板上面所支持的 CPU 型号喔！不然买了最新的 CPU 也不能够安插在你的旧主板上头的！目前主流的 CPU 有 Intel 的 i3/i5/i7 系列产品中，甚至先后期出厂的类似型号的脚位也不同， 例如 i7-2600 使用 LGA1155 脚位而 i7-4790 则使用 FCLGA1150 脚位，挑选时必须要很小心喔！
我们前面谈到 CPU 内部含有微指令集，不同的微指令集会导致 CPU 工作效率的优劣。除了这点之外， CPU 性能的比较还有什么呢？那就是 CPU 的频率了！什么是频率呢？简单的说， 频率就是 CPU 每秒钟可以进行的工作次数。所以频率越高表示这颗 CPU 单位时间内可以作更多的事情。举例来说，Intel 的 i7-4790 CPU 频率为 3.</description></item><item><title>CPU</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/CPU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/CPU/</guid><description>概述 参考：
极客时间，Linux 性能优化实战-03 基础篇：经常说的 CPU 上下文切换是什么意思 LinuxPerformance 博客，进程切换：自愿与强制 在 Linux Kernel 中，CPU 的管理，绝大部分时间都是在进行任务的调度，所以很多时候也称为调度管理。
CPU 多线程、并发、并行 概念 Node：在这里时间片只是一种描述，理解 CPU 的并行与并发概念就好
1、CPU 时间分片、多线程？
如果线程数不多于 CPU 核心数，会把各个线程都分配一个核心，不需分片，而当线程数多于 CPU 核心数时才会分片。
2、并发和并行的区别
并发：当有多个线程在操作时,如果系统只有一个 CPU，把 CPU 运行时间划分成若干个时间片,分配给各个线程执行，在一个时间段的线程代码运行时，其它线程处于挂起状态。这种方式我们称之为 Concurrent(并发)。并发=间隔发生 并行：当系统有一个以上 CPU 时,则线程的操作有可能非并发。当一个 CPU 执行一个线程时，另一个 CPU 可以执行另一个线程，两个线程互不抢占 CPU 资源，可以同时进行，这种方式我们称之为 Parallel(并行)。 并行=同时进行 区别：并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔内发生。
并行是同时做多件事情。
并发表示同时发生了多件事情，通过时间片切换，哪怕只有单一的核心，也可以实现“同时做多件事情”这个效果。
根据底层是否有多处理器，并发与并行是可以等效的，这并不是两个互斥的概念。
举个我们开发中会遇到的例子，我们说资源请求并发数达到了 1 万。这里的意思是有 1 万个请求同时过来了。但是这里很明显不可能真正的同时去处理这 1 万个请求的吧！
如果这台机器的处理器有 4 个核心，不考虑超线程，那么我们认为同时会有 4 个线程在跑。也就是说，并发访问数是 1 万，而底层真实的并行处理的请求数是 4。如果并发数小一些只有 4 的话，又或者你的机器牛逼有 1 万个核心，那并发在这里和并行一个效果。也就是说，并发可以是虚拟的同时执行，也可以是真的同时执行。而并行的意思是真的同时执行。
结论是：并行是我们物理时空观下的同时执行，而并发则是操作系统用线程这个模型抽象之后站在线程的视角上看到的“同时”执行。
time slice(时间片) 概念 参考：https://en.</description></item><item><title>CPU 管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/CPU-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/CPU-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：</description></item><item><title>Crawler</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Crawler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Crawler/</guid><description>概述 参考：
Wiki, Web crawler Web crawler(网络爬虫)，大家习惯性简称 Crawler(爬虫)。Web crawler 是一种可以系统浏览互联网的机器人，通常都是被搜索引擎用来抓取网络资源做成搜索索引。
Crawler 与 Reverse engineering、Browser 都紧密相连。
学习资料 Spider Box # 爬虫逆向资源整合的网站
https://www.bilibili.com/video/BV1ub4y157g1 介绍视频 B 站视频
B 站，【B站最全Python爬虫教程】整整748集，从0基础小白到爬虫大神只要这套就够了！（JS逆向/APP逆向/爬虫实战零基础到精通） 更好一些 B 站，【全268集】清华大佬终于把Python爬虫讲明白了，从JS逆向、APP逆向、逆向算法、爬虫实战，这还学不会我退出IT圈！！ 实用工具 WebDriver # 自动控制浏览器
Easy Scrapper 浏览器插件
Easy Scraper - 可视化网络爬虫，不写代码，鼠标点点获取数据 https://github.com/NanmiCoder/MediaCrawler
小红书笔记 | 评论爬虫、抖音视频 | 评论爬虫、快手视频 | 评论爬虫、B 站视频 ｜ 评论爬虫、微博帖子 ｜ 评论爬虫 https://github.com/unclecode/crawl4ai
Crawl4AI 简化了异步网络爬行和数据提取，使其可供大型语言模型 (LLM) 和 AI 应用程序使用。</description></item><item><title>Cryptography</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cryptography/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cryptography/</guid><description>概述 参考：
Wiki, Cryptography Cryptography(密码学)。大多数现代密码可以通过多种方式进行分类
第一种分类方式：依据加密时对明文的分解方式 具有固定大小的块，称为 Block cipher 适用于连续的符号留，称为 Stream cipher 第二种分类方式：依据密钥的使用方式 使用相同密码加密/解密的，称为 对称密钥加密 使用不同密钥加密/解密的，称为 公开密钥加密 或 非对称密钥加密 密码学背景 在现代时代之前，密码学着眼于消息的机密性（即加密），即将消息从一种可理解的形式转换为一种难以理解的形式，然后又在另一端再次转换，从而使拦截器或窃听者在没有秘密知识（即所需的密钥）的情况下无法读取该消息。用于解密该消息）。加密试图确保保密的通信，如那些间谍，军事领导人和外交官。在最近的几十年中，该领域已经超出了对机密性的关注范围，包括消息完整性检查，发送者/接收者身份验证，数字签名，交互式证明和安全计算等。
经典密码学 现代密码学 现在我们谈论的密码学，都是现代密码学的范畴
Public-key cryptography(公开密钥加密、非对称密钥加密)，以及根据公开密钥加密方式而衍生出的其他认证授权等基础设施，是当代最常见，也是最常用的方式.
现代加密方式 Symmetric Key Algorithm(对称密钥算法) 参考：
Wiki, Symmetir Key Algorithm 使用相同的密钥来加密明文和解密密文。Symmetric Key Algorithm 也称为 对称密钥加密
加密规范：
DES # Data Encryption Standard 数据加密标准。已被破解 3DES # 3 倍的 DES。最常用 AES # Advanced Encryption Standard(高级加密标准)。最常用 Blowfish Twofish IDEA # 商业加密算法 SKA 特点 特性：
加密和解密使用同一个密钥，效率高 将原始数据分割成固定大小的块，逐个进行加密 缺点：
密钥过多 密钥分发(分发密钥过程无法保证),为了解决对称加密算法每个人需要保存密钥过多的问题，可以使用公钥加密 数据来源无法确认 Public Key Cryptography(公开密钥密码学) 参考：</description></item><item><title>CSI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/CSI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/CSI/</guid><description>概述 参考：
公众号-阿里云云原生，一文读懂容器存储接口 CSI 导读： 在《一文读懂 K8s 持久化存储流程》一文我们重点介绍了 K8s 内部的存储流程，以及 PV、PVC、StorageClass、Kubelet 等之间的调用关系。接下来本文将将重点放在 CSI（Container Storage Interface）容器存储接口上，探究什么是 CSI 及其内部工作原理。
背景 K8s 原生支持一些存储类型的 PV，如 iSCSI、NFS、CephFS 等等（详见链接），这些 in-tree 类型的存储代码放在 Kubernetes 代码仓库中。这里带来的问题是 K8s 代码与三方存储厂商的代码强耦合：
更改 in-tree 类型的存储代码，用户必须更新 K8s 组件，成本较高 in-tree 存储代码中的 bug 会引发 K8s 组件不稳定 K8s 社区需要负责维护及测试 in-tree 类型的存储功能 in-tree 存储插件享有与 K8s 核心组件同等的特权，存在安全隐患 三方存储开发者必须遵循 K8s 社区的规则开发 in-tree 类型存储代码 CSI 容器存储接口标准的出现解决了上述问题，将三方存储代码与 K8s 代码解耦，使得三方存储厂商研发人员只需实现 CSI 接口（无需关注容器平台是 K8s 还是 Swarm 等）。
CSI 核心流程介绍 在详细介绍 CSI 组件及其接口之前，我们先对 K8s 中 CSI 存储流程进行一个介绍。《一文读懂 K8s 持久化存储流程》一文介绍了 K8s 中的 Pod 在挂载存储卷时需经历三个的阶段：Provision/Delete（创盘/删盘）、Attach/Detach（挂接/摘除）和 Mount/Unmount（挂载/卸载），下面以图文的方式讲解 K8s 在这三个阶段使用 CSI 的流程。</description></item><item><title>Dashboard</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Dashboard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Dashboard/</guid><description>概述 参考：
官方文档，仪表盘 借助 Grafana Play，您可以探索并了解 Grafana 的各种 Panel 工作原理，从实际示例中学习以加速您的开发 https://play.grafana.org/dashboards/f/PGJ1Fr4Zz/demo3a-grafana-features 这是各种 Panel 的 Demo 集合。 Panel(面板) 与 Dashboard(仪表盘)
Panel(面板) 是 Grafana 用于展示的基本 Visualization(可视化) 模块。多个 Panel(面板) 组成了一个 Dashboard(仪表盘)。每个面板都有各种各样的样式和格式设置选项。 面板可以在仪表板上拖放和重新排列。 它们也可以调整大小
对于 Grafana 来说，页面处理的数据实际上是一个一个的 Field(字段)。从 Grafana 数据模型 章节，可以发现，Grafana 从数据源拿到的数据都是统一的格式，Grafana 在面板处理数据时，其实就是对一堆 Field(字段) 来操作。从各个数据源获取到的数据，统一被放在 Field 中了。
时间选择器 Panels(面板) 的类型 其实就是说有多少种 Visualizations
Alert list 警报列表面板允许您显示仪表板警报。您可以配置列表以显示当前状态或最近的状态更改。您可以在“警报”概述中了解有关警报的更多信息。
Bar gauge 条形表通过将每个字段减小为单个值来简化数据。您选择 Grafana 如何计算减少量
Dashboard list 仪表板列表面板允许您显示指向其他仪表板的动态链接。可以将列表配置为使用加星标的仪表板，最近查看的仪表板，搜索查询和仪表板标签。
Gauge 仪表是一个单值面板，可以为每个系列，列或行重复一个仪表。
Time series - 最常用的面板 该可视化是 Grafana 生态系统中最常用的。它可以渲染为一条线，一条点的路径或一系列条形图。这种类型的图具有足够的通用性，几乎可以显示任何时间序列数据。
详见: Time series 面板</description></item><item><title>Data Link Layer</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Data-Link-Layer/Data-Link-Layer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Data-Link-Layer/Data-Link-Layer/</guid><description>概述 参考：
Broadcast storm(广播风暴) # https://en.wikipedia.org/wiki/Broadcast_storm
STP 参考:
Wiki, Spanning_Tree_Protocol 公众号 - K8S 中文社区，图解 STP ：你可能不用，但是不能不懂</description></item><item><title>Disk</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Disk/Disk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Disk/Disk/</guid><description>概述 参考：
对很多 PC 的使用者来说，UEFI 就像是一颗深水炸弹，表面风平浪静，暗地里却早已引发了巨大的震动。多亏了 Microsoft 的强横，预装 WIN8 的电脑指定需要 GPT 分区这一举措，让人们不禁发出感慨：哦天哪，我的电脑里还有这东西？一些好学的人对 GPT 进行了解以后，进一步发现了我们的幕后功臣：UEFI。本期文章我们就来说说，硬盘和硬盘分区这点事。
简单地说，硬盘分区是就使用分区编辑器（partition editor）将一个硬盘上划分几个独立的逻辑部分，盘片一旦划分成数个分区，不同类的目录与文件可以存储进不同的分区。越多分区，也就有更多不同的地方，可以将文件的性质区分得更细，按照更为细分的性质，存储在不同的地方以管理文件；但太多分区就成了麻烦。
硬盘分区就像给一间空荡的房子划分出卧室，厨房，客厅等相互隔离的空间一样。主要是为了方面用户的使用。另一方面，通过合理的硬盘分区，有效保护系统盘空间，确实能够提高系统运行速度，再者，硬盘分区也可以有效地对数据进行保护。你当然可以不分区，只不过，当你面对越来越多的子目录，或者是越来越慢的 Windows，不得不费功夫去管理你的文件，或者重装 Windows 的时候，恐怕会悔不当初。 “不要把所有的鸡蛋放在同一个篮子里”这句至理名言在经济学以外的其他领域也同样是句警世恒言。
在讲解 MBR 之前，有必要讲讲机械硬盘的一些相关概念，毕竟 MBR 作为 20 世纪最棒的磁盘管理方式，与机械硬盘可是联系紧密的
（这样可以更好地理解后面的内容）。
机械硬盘原理 机械硬盘由坚硬金属材料制成的涂以磁性介质的盘片，盘片两面称为盘面或扇面，都可以记录信息，由磁头对盘面进行操作（如果你有坏的硬盘，可以动手拆开看。嗯？为什么用坏的？用好的可能费钱……）一般用磁头号区分。结构特性决定了机械硬盘如果受到剧烈冲击（摔在地上或是勤奋的你想拆开学习），磁头与盘面可能产生的哪怕是轻微撞击都有可能报废。
继续讲原理：假设磁头不动，硬盘旋转，那么磁头就会在磁盘表面画出一个圆形轨迹并将之磁化，数据就保存在这些磁化区中，称之为磁道，将每个磁道分段，一个弧段就是一个扇区。一个硬盘可以包含多个扇面，扇面同轴重叠放置，每个盘面磁道数相同，具有相同周长的磁道所形成的圆柱称之为柱面，柱面数与磁道数相等。如下图
了解了这些，我们就可以对最初的硬盘地址管理方式作一个原理层面的了解：
最初的寻址方式称为 CHS，在 LBA（Logical Block Address）概念诞生之前，由他负责管理磁盘地址。所谓 CHS 即柱面（cylinder），磁头（header），扇区（sector），通过这三个变量描述磁盘地址，需要明白的是，这里表示的已不是物理地址而是逻辑地址了。这种方法也称作是 LARGE 寻址方式。该方法下：
硬盘容量=磁头数 × 柱面数 × 扇区数 × 扇区大小（一般为 512byte）。 后来，人们通过为每个扇区分配逻辑地址，以扇区为单位进行寻址，也就有了 LBA 寻址方式。但是为了保持与 CHS 模式的兼容，通过逻辑变换算法，可以转换为磁头/柱面/扇区三种参数来表示，和 LARGE 寻址模式一样，这里的地址也是逻辑地址了。（固态硬盘的存储原理虽然与机械硬盘不同，采用的是 flash 存储，但仍然使用 LBA 进行管理，此处不再详述。）
科普到这里，我们可以试图去理解 MBR 分区了。现在我们来看看 MBR 分区的技术原理。
MBR 原理 MBR：Master Boot Record，主分区引导记录。最早在 1983 年在 IBM PC DOS 2.</description></item><item><title>Docker</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker/</guid><description>概述 参考：
官方文档，指南 官方文档，手册 官方文档，参考 Docker 是一个基于 Containerization(容器化) 的开放式平台，可以 开发、分享、运行应用程序。Docker 分为两个版本
Docker-CE # 社区版 Docker-EE # 商业版 Docker 为了解决 LXC 无法批量管理、复刻容器等问题应运而生，简化用户对容器的应用。Docker 是 Docker.inc 公司开源的一个基于 LXC 技术之上构建的 Container 引擎，不再使用模板技术，而是使用了 Docker Image 文件的方式来创建。Image 是放在统一的互联网仓库中，当需要使用 Container 的时候，直接 run 或者 creat 等即可从仓库中下载到该 Image，然后基于该 Image 再运行 Container。
Note：一开始，Docker 在 linux 上实现容器技术的后端使用的是 lxc，后来使用 runc 来代替。
Docker 架构 Docker 对使用者来讲是一个 C/S 模式的架构，Client 和 Server 使用 REST API 通过 UNIX Socket 或者网络进行通信。Compose 同样也可以作为客户端。
官方将这种架构称为 Docker Engine(引擎)，通常这个引擎具有：
一个 Server 进程 dockerd，长时间以 Daemon 形式运行 与 dockerd 通信的 API 一个 CLI 程序 docker dockerd 是实现容器能力的核心，用来管理 Docker Objects(Docker 对象)，e.</description></item><item><title>Docker CLI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/Docker-CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/Docker-CLI/</guid><description>概述 参考：
官方文档，参考 - CLI - docker Syntax(语法) docker [OPTIONS] COMMAND [ARG&amp;hellip;]
OPTIONS &amp;ndash;config=~/.docker # Location of client config files # 客户端配置文件的位置 -D, &amp;ndash;debug=false # Enable debug mode # 启用 Debug 调试模式 -H, &amp;ndash;host=[] # Daemon socket(s) to connectto # 守护进程的套接字（Socket）连接 -l, &amp;ndash;log-level=info # Set the logging level # 设置日志级别 &amp;ndash;tls=false # Use TLS; implied by&amp;ndash;tlsverify # &amp;ndash;tlscacert=~/.docker/ca.pem # Trust certs signed only by this CA # 信任证书签名 CA &amp;ndash;tlscert=~/.docker/cert.pem # Path to TLS certificate file # TLS 证书文件路径 &amp;ndash;tlskey=~/.</description></item><item><title>DPDK</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DPDK/DPDK/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DPDK/DPDK/</guid><description>概述 参考：
GitHub 项目，DPDK/dpdk 官网 官方文档，API Wiki, Data Plane Development Kit DPDK 开发中文网 Data Plane Development Kit(数据平面开发套件，简称 DPDK) 是一个由 Linux 基金会 管理的开源软件项目。用于将 TCP 数据包的处理能力从内核空间移动到用户空间中的进程。主要是跳过了内核的 Interrupts(中断) 逻辑。
处理数据包的传统方式是 CPU 中断方式，即网卡驱动接收到数据包后通过中断通知 CPU 处理，然后由 CPU 拷贝数据并交给协议栈。在数据量大时，这种方式会产生大量 CPU 中断，导致 CPU 无法运行其他程序。
而 DPDK 则采用轮询方式实现数据包处理过程：DPDK 程序加载了网卡驱动，该驱动在收到数据包后不中断通知 CPU，而是将数据包通过零拷贝技术存入内存，这时应用层程序就可以通过 DPDK 提供的接口，直接从内存读取数据包。
这种处理方式节省了 CPU 中断时间、内存拷贝时间，并向应用层提供了简单易行且高效的数据包处理方式，使得网络应用的开发更加方便。但同时，由于需要重载网卡驱动，因此该开发包目前只能用在部分采用 Intel 网络处理芯片的网卡中。
DPDK 主要包含如下几个部分（https://doc.dpdk.org/guides/prog_guide/source_org.html#libraries）
Environmental Abstraction Layer(环境抽象层，简称 EAL) # 负责为应用间接访问底层的资源，比如内存空间、线程、设备、定时器等。如果把我们使用了 DPDK 的应用比作一个豪宅的主人的话，EAL就是这个豪宅的管家。 DPDK API Library # DPDK 的 API 库 etc. NIC Driver(网卡驱动程序) # 如名，只不过是轮询模式的驱动。 etc.</description></item><item><title>Driver</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Driver/Driver/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Driver/Driver/</guid><description>概述 参考：
官方文档，驱动程序 市面上有多种虚拟化平台，比如 KVM/QEMU、Hyper-V、等等，Libvirt 想要调用这些虚拟化平台的能力，需要对应平台的 Driver(驱动程序)，这个 Driver 可以对接虚拟化平台的的 Hypervisor(虚拟机监视器) 以控制整个虚拟化环境。这就好比 Windows 系统想要使用显卡的能力，就需要对应的显卡驱动程序一样。
想要连接到 Driver，我们需要使用 Libvirt API 开发的客户端应用程序（e.g. virsh、virt-manager、等等）。Drivers 通常作为服务端都暴露了 Libvirt API，这些客户端通过 URI 找到并连接到 Driver，这就好像 mysql 客户端连接 mysql 也需要 IP 端口、etcdctl 连接 etcd 同理，很多客户端都是同样的逻辑。
Libvirt 有如下几类 Drivers
Hypervisor drivers(Hypervisor 驱动) Storage drivers(存储驱动) Node device driver Secret driver 一般情况应该始终有一个活跃状态的 Hypervisor driver，如果 libvirtd 进程可用的话，通常还会有一个活动状态的网络驱动和存储驱动
除了 Hypervisor 驱动有用以外，其他的几种驱动暂时没找到用途 —— 2023.7.5
使用 Libvirt 时，我们最常见的 virsh 和 libvirtd 就是一个客户端和服务端结构，virsh 是用 LIbvirt API 实现的客户端程序、libvirtd 则是暴露 LIbvirt API 的驱动程序。virsh 使用 URI 连接到 libvirtd 的指定驱动后，可以像 libvirtd 发出命令以管理虚拟化平台。</description></item><item><title>ECMAScript</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript/</guid><description>概述 参考：
Wiki, ECMAScript JavaScript 官网 TypeScript 官网 ECMAScript 是一种编程语言的标准，起源于 JavaScripts。
1996 年 8 月，微软模仿 JavaScript 开发了一种相近的语言，取名为 JScript（JavaScript 是 Netscape 的注册商标，微软不能用），首先内置于 IE 3.0。Netscape 公司面临丧失浏览器脚本语言的主导权的局面。
1996 年 11 月，Netscape 公司决定将 JavaScript 提交给国际标准化组织 ECMA（European Computer Manufacturers Association），希望 JavaScript 能够成为国际标准，以此抵抗微软。ECMA 的 39 号技术委员会（Technical Committee 39）负责制定和审核这个标准，成员由业内的大公司派出的工程师组成，目前共 25 个人。该委员会定期开会，所有的邮件讨论和会议记录，都是公开的。
1997 年 7 月，ECMA 组织发布 262 号标准文件（ECMA-262）的第一版，规定了浏览器脚本语言的标准，并将这种语言称为 ECMAScript。这个版本就是 ECMAScript 1.0 版。之所以不叫 JavaScript，一方面是由于商标的关系，Java 是 Sun 公司的商标，根据一份授权协议，只有 Netscape 公司可以合法地使用 JavaScript 这个名字，且 JavaScript 已经被 Netscape 公司注册为商标，另一方面也是想体现这门语言的制定者是 ECMA，不是 Netscape，这样有利于保证这门语言的开放性和中立性。因此，ECMAScript 和 JavaScript 的关系是，前者是后者的规范，后者是前者的一种实现。在日常场合，这两个词是可以互换的。</description></item><item><title>ECMAScript 第三方库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/ECMAScript-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/ECMAScript-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</guid><description>Postman // 将响应体解析为 JSON 格式 respBodyJSON = JSON.parse(responseBody) respBodyJSON.data.forEach(function (item) { console.log(item.title) }) Axios 参考：
GitHub 项目，axios/axios 官网 Axios 是用于浏览器和 node.js 的基于 Promise 的 HTTP 客户端，它是基于 XHR 进行的二次封装，传统的 XHR 并没有使用到 Promise</description></item><item><title>ECMAScript 环境安装与使用</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>概述 参考：
有两种运行时环境可以运行 ECMAScript 代码(Javascript、Typescript)
Browser# 浏览器就是 ECMAScript 的运行时环境。 Node.js # 在服务器或 PC 上安装 Node.js 环境以运行 ECMAScript 代码 Deno # GtiHub 项目，denoland/deno。据说要替代 Node.js，很尴尬的是。。。早期 18 年的 issue 中被各种国人无意义灌水 Bun # GtiHub 项目，oven-sh/bun 但是这两者可以提供的 API 能力各不相同
Browser 可以提供的 dockument、window 和其他关于 DOM 或其他 Web 平台 API 的对象。 Node.js 则可以提供很多操作系统相关的 API，比如文件的读写、进程管理、网络通信等等。 Node.js 与 Browser 都是基于 Chrome V8 引擎的 ECMAScript 运行时环境
你也许会想，直接在我的硬盘上创建好 HTML 和 JavaScript 文件，然后用浏览器打开，不就可以看到效果了吗？
这种方式运行部分 JavaScript 代码没有问题，但由于浏览器的安全限制，以 file:// 开头的地址无法执行如联网等 JavaScript 代码，最终，你还是需要架设一个 Web 服务器，然后以 http:// 开头的地址来正常执行所有 JavaScript 代码。</description></item><item><title>Electron</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Electron/Electron/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Electron/Electron/</guid><description>概述 参考：
GitHub 项目，electron/electron 官网 Electron（以前称为 Atom Shell）是由 OpenJS 基金会开发和维护的免费开源软件框架。该框架旨在使用 Web 技术（主要是 HTML、CSS 和 JavaScript，尽管也可以使用前端框架和 Web Assembly 等其他技术）创建桌面应用程序，这些技术使用 Chromium 浏览器引擎版本和后端使用 Node.js 运行时环境。它还使用各种 API 来实现与 Node.js 服务的本机集成和进程间通信模块等功能。
Electron 最初是 GitHub 为 Atom 构建的，是多个开源项目背后的主要 GUI 框架，包括 Atom、GitHub Desktop、Light Table、Visual Studio Code、WordPress Desktop 和 Eclipse Theia。</description></item><item><title>Etcd</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Etcd/Etcd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Etcd/Etcd/</guid><description>概述 参考：
Etcd 作为 kubernetes 集群的存储系统使用(也可以算是集群的注册中心)，保存了集群的所有配置信息，需要高可用，如果需要在生产环境下使用，则需要在单独部署
Note：Etcd 只接收 API Server 的请求
每个 etcd 一般使用两个端口进行工作，一个端口面向客户端提供服务(port/2379)，另一个端口集群内部通信(port/2380)
想要正常运行 ETCD，需要注意以下几点：
配置 etcd 的证书，如果不使用证书，则不法分子有可能直接去修改 etcd 数据 ca.crt(证书 CN：etcd-ca) # 给 apiserver 发客户端证书，给 etcd 发服务端证书以及对等证书 peer.crt(证书 CN：HostName) # etcd 集群各节点属于对等节点，使用 peer 类型证书(一般分为 server 证书和 client 证书，但是 etcd 集群之间不存在服务端和客户端的区别) apiserver-etcd-client.crt(证书 CN：kube-apiserver-etcd-client) # 与 server.crt 证书对应。apiserver 作为 etcd 的客户端所用的证书 server.crt(证书 CN：HostName) # 与 apiserver-etcd-client.crt 证书对应。etcd 作为 apiserver 的服务端所用的证书 修改 etcd 的配置文件 Etcd Metrics 详见：k8s 主要组件 metrics 获取指南
etcdctl 命令行工具使用说明 详见：etcdctl 命令行工具</description></item><item><title>Etcd</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd/</guid><description>概述 参考：
GitHub 项目，etcd-io/etcd GitHub 项目，etcd-io/website 官网 官方文档 掘金 etcd 万字长文 腾讯云社区上的 etcd 万字长文 Etcd 是 CoreOS 基于 Raft 共识算法 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障(如数据库选主、分布式锁等)。
基本的 key-value 存储，后端存储采用的是 BBolt 存储引擎，其前身是 BoltDB ，这是一款 golang 实现的嵌入式 KV 存储引擎，参考的是 LMDB，支持事务、ACID、MVCC、ZeroCopy、BTree 等特性。 监听机制 key 的过期及续约机制，用于监控和服务发现 原子 CAS 和 CAD，用于分布式锁和 leader 选举 选举机制详见：Etcd 基于 RAFT 的一致性 Glossary(术语) 参考：
官方文档：https://github.com/etcd-io/etcd/blob/master/Documentation/learning/glossary.md Raft # etcd 所采用的保证分布式系统强一致性的算法。 Endpoint(端点)# 指向 etcd 服务或资源的 URL 。比如 http://172.38.40.212:2379 就是 etcd 中的一个 endpoint ，这个 endpoint 指向了 172.</description></item><item><title>etcdctl</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl/</guid><description>概述 参考：
官方文档：https://github.com/etcd-io/etcd/tree/master/etcdctl etcd 可用的库和客户端 Syntax(语法) etcdctl [GlobalOptions] COMMAND [CommandOptions] [Arguments&amp;hellip;]
使用说明：
export ETCDCTL_API=3 使用该命令使得 etcdctl 通过 v3 版本来进行操作 如果在 etcd 的配置文件中的 Security 段落，开启了验证证书，则在使用命令时，需要使用&amp;ndash;cert、&amp;ndash;key、&amp;ndash;cacert 选项来指定验证所需证书，否则无法操纵服务器 v2 版本中使用如下方式 etcdctl &amp;ndash;key-file=/etc/kubernetes/pki/etcd/peer.key &amp;ndash;cert-file=/etc/kubernetes/pki/etcd/peer.crt &amp;ndash;ca-file=/etc/kubernetes/pki/etcd/ca.crt &amp;ndash;endpoints=&amp;ldquo;https://IP:PORT&amp;rdquo; COMMAND v3 版本中使用如下方式 etcdctl &amp;ndash;key=/etc/kubernetes/pki/etcd/peer.key &amp;ndash;cert=/etc/kubernetes/pki/etcd/peer.crt &amp;ndash;cacert=/etc/kubernetes/pki/etcd/ca.crt &amp;ndash;endpoints=&amp;ldquo;https://IP:PORT&amp;rdquo; COMMAND 在下面的 EXAMPLE 则不再输入认证相关参数，以便查阅方便。但是实际使用中需要使用，否则无法连接 etcd 服务端 GLOBAL OPTIONS &amp;ndash;cacert=/PATH/FILE # 使用此 CA 包验证启用 TLS 的安全服务器的证书。即 etcd 的 ca，用该 ca 来验证 cert 选项中提供的证书是否正确 &amp;ndash;cert=/PATH/FILE# 使用指定的 TLS 证书文件鉴定客户端是否安全。即 etcd 的 peer 证书，peer 证书对于 etcdctl 来说就是与它交互的服务端的证书 &amp;ndash;key=/PATH/FILE # 使用指定的 TLS 证书的密钥文件鉴定客户端是否安全。即 etcd 的 peer 证书的私钥 &amp;ndash;endpoints=[IP1:PORT1,IP2:PORT2,&amp;hellip;.</description></item><item><title>File System 管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/File-System-%E7%AE%A1%E7%90%86/File-System-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/File-System-%E7%AE%A1%E7%90%86/File-System-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
https://www.howtogeek.com/318177/what-is-the-appdata-folder-in-windows/ APPDATA ${USERPROFILE}/AppData/ #
./Local/ # ./LocalLow/ # ./Roaming/ # 刚装完的 win10 专业版，用户的 AppData 中将会有如下结构：
$USERPROFILE/AppData/Local $USERPROFILE/AppData/LocalLow $USERPROFILE/AppData/Roaming $USERPROFILE/AppData/Local/Comms $USERPROFILE/AppData/Local/ConnectedDevicesPlatform $USERPROFILE/AppData/Local/D3DSCache $USERPROFILE/AppData/Local/Microsoft $USERPROFILE/AppData/Local/Packages $USERPROFILE/AppData/Local/Temp $USERPROFILE/AppData/LocalLow/Microsoft $USERPROFILE/AppData/LocalLow/MSLiveStickerWhiteList $USERPROFILE/AppData/Roaming/Adobe $USERPROFILE/AppData/Roaming/Microsoft 最主要的是这三个目录下的 Microsfot 目录，还有 Packages 目录。在整理 AppData 时，不要误删了。
LocalAppData ${LocalAppData} 在 ${UserProfile}/AppData/Local/
IconCache.db # 图标缓存数据。若图标变白板，可删除缓存，并重启资源管理。
Program Files 该目录存储安装在计算机上的大多数应用程序的执行文件。
Program Files(x86) 该目录存储在 64 位 Windows 系统上安装的 32 位应用程序的执行文件。
ProgramData 该目录存储全局数据，包括应用程序的配置文件，以及系统的安装和更新信息。
Users 该目录存储在 Windows 系统上创建的每个用户的个人文件夹，如桌面、文档和图片。
Windows Windows 操作系统的核心文件和 DLL 文件都存储在此目录中。
./System32/ # 类似于 Linux 中的 /usr/sbin/ 目录，系统自带的命令、服务、msc 的可执行文件都在这里。</description></item><item><title>File transfer</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/File-transfer/File-transfer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/File-transfer/File-transfer/</guid><description>概述 参考：
Wiki, File_transfer Wiki, Protocol for file transfer File transfer(文件传输) 是通过数据通信的通道将计算机文件从一个计算机系统传输到另一个计算机系统的行为。文件传输是通过Communication protocol协调的。许多文件传输协议是针对不同环境而设计的
File transfer protocol(文件传输协议) 是描述如何在两个计算 endpoint 之间传输文件的约定。除了作为单个单元存储在文件系统中的文件的比特流之外，有些还可能发送相关元数据，例如文件名、文件大小和时间戳，甚至文件系统权限和文件属性。
文件传输协议分为两大种
Packet switched Protocol(分组交换网络协议) FTP Serial Protocol(串行协议) Modems(拨号调制解调器) 使用 XMODEM、YMODEM、ZMODEM 和类似的空调制解调器链接。TODO 其他 USB 等外部存储设备与计算机之间文件互传 etc. X/Y/Z Modem 参考:
Wiki, XMODEM Wiki, YMODEM Wiki, ZMODEM https://pauillac.inria.fr/~doligez/zmodem/ymodem.txt 知乎，Xmodem 协议介绍及应用（基于 ESP-IDF） X/Y/Z Modem 并不依赖于 TCP/IP 进行传输，早期是用来在串行通信（比如调制解调器）中点对点传输文件的协议
下载 Aria2 参考：
GitHub 项目，aria2/aria2 aria2 是一个轻量级的多协议和多源跨平台下载实用程序，在命令行中运行。它支持 HTTP/HTTPS、FTP、SFTP、BitTorrent 和 Metalink。
可以下载 BT 种子
aria2c xxx.torrnet
使用 Aria2 的客户端</description></item><item><title>Filesystem</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Filesystem/Filesystem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Filesystem/Filesystem/</guid><description>概述 参考：
Wiki, Filesystem Filesystem(文件系统，简称 FS) 是操作系统用来控制数据存储和检索方式的方法，也是一种数据结构。
不同的操作系统类型，使用的文件系统各不相同
Unix-like OS 中 Kernel 管理的 Filesystem Microsoft OS 创建的 Windows 的 File System 管理 etc. FUSE 参考：
Wiki, Filesystem_in_Userspace Filesystem in Userspace(用户空间中的文件系统，简称 FUSE)</description></item><item><title>Filesystem</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/Filesystem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/Filesystem/</guid><description>概述 参考：
Wiki - Category，Computer file systems Linux 性能优化实践 - 文件系统 公众号，小林 coding - 一口气搞懂「文件系统」，就靠这 25 张图了 图片来源: https://www.thomas-krenn.com/en/wiki/Linux_Storage_Stack_Diagram
从上面的结构可以看到，文件系统的作用就是用来接收用户的操作，并将数据保存到物理硬盘的。可以想见，如果没有文件系统帮助用户操作，那么人们又怎么能将数据保存到存储设备上呢~
File System(文件系统，简称 FS) 是一种对存储设备上的数据，进行组织管理的机制。组织方式的不同，就会形成不同的文件系统。
如果没有文件系统，放置在存储介质中的数据将是一个庞大的数据主体，无法分辨一个数据在哪里停止以及下一个数据在哪里开始。通过将数据分成多个部分并给每个部分命名，可以轻松地隔离和识别数据。每组数据称为 File(文件)。所以，用于管理这些文件及其名称的结构和逻辑规则，称为 File System(文件系统)。
什么是 File(文件) 详见《文件管理》章节
文件组织结构 文件管理详解见 文件管理
为了方便管理，Linux 的文件系统为每个文件都分配了两个数据结构。
index node(索引节点，简称 inode) # 记录文件的元数据。inode 编号、文件大小、访问权限、修改日期、数据的位置等。 inode 和文件一一对应，它跟文件内容一样，都会被持久化到存储的磁盘中。所以inode 同样占用磁盘空间。 inode 包含文件的元数据，具体来说有以下内容： 文件的字节数 文件拥有者的 User ID 文件的 Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime 指 inode 上一次变动的时间，mtime 指文件内容上一次变动的时间，atime 指文件上一次打开的时间。 链接数，即有多少文件名指向这个 inode 文件数据 block 的位置 directory entry(目录项，简称 dentry) # 记录文件的名字、inode 指针、与其他目录项的关联关系。 多个关联的目录项，就构成了文件系统的目录结构(一个层次化的树形结构)。不过，不同于 inode，目录项是由内核维护的一个内存数据结构，所以通常也被叫做 dentries(目录项缓存)。 这个层次化的树形结构就像下图一样：</description></item><item><title>fio 磁盘性能测试工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</guid><description>概述 参考:
GitHub 项目，axboe/fio 官方文档
[!Attention] ！！当使用 fio 的 filename 参数指定某个要测试的裸设备（硬盘或分区），切勿在系统分区做测试，会破坏系统分区，从而导致系统崩溃。若一定要测试系统分区较为安全的方法是：在根目录下创建一个空目录，在测试命令中使用 directory 参数指定该目录，而不使用 filename 参数。现在假设 /dev/vda3 设备挂载在 / 目录下，那么不要执行 fio --filename=/dev/vda 这种操作！！
1 性能的基本概念 1.1 什么是一个 IO IO 即 Input 和 Output，可以分为读 IO 和写 IO。读 IO，就是发指令，从磁盘读取某段扇区的内容。指令一般是通知磁盘开始扇区的位置，然后给出需要从这个初始扇区往后读取的连续扇区个数，同时给出的动作是读，还是写。磁盘收到这条指令，就会按照指令的要求，读或者写数据。控制器发出的这种指令+数据，就是一次 IO，读或者写。
1.2 顺序 IO 和随机 IO 顺序和随机，可以简单地理解为本次 IO 给出的初始扇区地址，和上一次 IO 的结束扇区地址，是否是按顺序的，如果相差很大，就算一次随机 IO。
1.3 IO 大小 一次 IO 需要读或者写的数据块大小。
1.4 带宽 每秒读出或写入的数据量。常用单位包括 KB/s、MB/s、GB/s 等。
1.5 延时 客户端发出 IO 请求直到收到请求并响应是需要一段时间的，这段时间就是 IO 延时。IO 延 时一般都是毫秒级的。随着 IO 压力的增大，IO 延时也会随之增大。对于存储来说，由于写 是前台操作，而读是后台操作，因此通常写的 IO 延时要低于读。相同 IO 模型下，IO 延时越小，存储性能越好。一般，IO 延时如果超过 30ms 就说明存储已经比较吃力了。</description></item><item><title>Foundation</title><link>https://desistdaydream.github.io/docs/Standard/Foundation/Foundation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Foundation/Foundation/</guid><description>概述 参考:
公众号 - OSC开源社区，你知道哪些开源基金会？ Gitee 项目，开源中国/GOTO-开源长廊-第二部分：国际开源趋势 / 第1部分-国际开源基金会.md Information Technology(信息技术，简称 IT) 的发展离不开全球各地的 Foundation(基金会) 的支持，没有这些基金会无私的奉献，开源软件不会像现在一样如此蓬勃发展。
从 RMS 创立 FSF 发起自由软件运动，再到 OSI 成立并明确开源软件定义，这种崇尚开放协作的软件开发模式迅速席卷全球。
除 FSF 与 OSI 外，还陆续诞生了许多致力于推广和发展开源的基金会。
开源基金会对于开源软件和开源社区的组织、发展、协同创新提供了主导作用。开源基金会遵循公开、透明、开放等理念，为开源软件的孵化提供技术、运营、法律等全方位支持，为开源的社区建设和运营提供指导，发挥了孵化器和加速器的作用，开源基金会已成为开源生态最重要的组织者。
以下罗列了一些有代表性的基金会：
1985 年 —— 自由软件基金会成立 自由软件基金会（Free Software Foundation，简称 FSF）由 RMS 于 1985 年创立，这是一个非营利组织，其主要工作是运行 GNU 计划，使命是促进计算机用户的自由。基金会的员工编写并维护着一些 GNU 软件包。
1999 年 —— Apache 软件基金会成立 Apache 软件基金会（Apache Software Foundation，简称 ASF）正式创建于 1999 年，其前身是由一群开发爱好者构成的 &amp;ldquo;Apache Group&amp;rdquo;，他们通过 Brian Behlendorf 创建的邮件列表进行技术交流。
托管于 ASF 的项目均遵循 Apache License，ASF 对行业和开源的贡献除了开源项目，还包括开源治理方面的贡献，例如在 Apache 社区内外被广泛使用的 Apache License、主导社区协作管理的 Apache Way，以及通过非营利组织的身份来支持 Apache 项目及社区。</description></item><item><title>Framework</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Framework/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Framework/</guid><description>概述 参考：
Framework(框架) 对于编程领域而言，就像其名字，框架，编程时使用已经存在的框架，便于开发者更好得编写代码。框架提供了一种程序骨架，用什么可以通过框架提供的方式直接取用。
Web 开发框架 参考：
MDN，指南-工具和测试-了解客户端 JS 框架 为什么存在框架？
桌面软件开发框架 https://www.bilibili.com/video/BV1Kr4y1u7Yx
传统开发框架 Qt # 推荐 wxWidgets GTK FLTK Swing JavaFX 新兴开发框架 MAUI Flutter Desktop # 推荐 Compose Multiplatform 基于浏览器的桌面软件开发框架 Electron # 推荐 NW.js CEF # 推荐 Sciter WebView2 WebView TAURI 及时渲染桌面软件开发框架 Dear ImGui Nuklear RmIUi # 推荐 其他 https://github.com/flipped-aurora/gin-vue-admin # Gin-vue-admin 是一个基于 vue 和 gin 开发的全栈前后端分离的开发基础平台，集成jwt鉴权，动态路由，动态菜单，casbin鉴权，表单生成器，代码生成器等功能，提供多种示例文件，让您把更多时间专注在业务开发上。</description></item><item><title>Function</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Function/Function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Function/Function/</guid><description>概述 参考：
Wiki, Subroutine(子程序) Wiki, Function 概念被合并到 Subroutine 中 Wiki, Parameter(参数) Wiki, Evaluation strategy(评估策略) 公众号，码农的荒岛求生-函数调用时底层发生了什么？ 在计算机编程中，比 Function(函数) 更官方（更早期）的称呼应该是 Subroutine(子程序) 是执行特定任务的程序指令序列，打包为一个单元。然后，该单元可用于应执行特定任务的程序中。
子程序可以在程序中定义，也可以在可以被许多程序使用的库中单独定义。在不同的编程语言中，子例程可以称为 Routine(例程)、Subprogram(子程序)、Function(函数)、Method(方法) 或 Procedure(过程)。从技术上讲，这些术语都有不同的定义。有时会使用通用的总称 Callable Unit(可调用单元)。
Function call(函数调用) Parameter(参数) 在计算机编程中，Parameter(参数) 是函数中使用的一种特殊变量，用于在引用函数时，提供给函数的输入数据。
actual parameter(实际参数，简称 实参) # 一般用 arguments 表示，在调用函数时使用实参 formal parameter(形式参数，简称 形参) # 一般用 parameter 表示，在定义函数时使用形参 如何将 Arguments 的值传递给子程序的 Parameters 是由编程语言的 Evaluation strategy(评估策略) 决定的。每次调用子程序时，都会评估本次调用的 Arguments，并将评估结果分配给相应的 Parameters。这种分配机制，称为 Argument passing(参数传递)。
例如：现在定义一个名为 add 的子程序：
def add(x, y){ return x + y } 这里的 x 和 y 是 形式参数</description></item><item><title>Garbage Collection(垃圾收集)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/</guid><description>概述 参考：
官方文档，概念-Kubernetes 架构-垃圾收集 宋净超-云原生资料库-Kubernetes 基础教程，集群资源管理-垃圾收集 Garbage Collection(垃圾收集) 功能用来删除曾经拥有 owner(拥有者) 但不再拥有 owner 的某些对象。
比如张三拥有 100 块钱，则张三就是这 100 块钱的 owner，当张三死亡后，那么这 100 块钱则不再具有 owner。
注意：垃圾收集是 beta 特性，在 Kubernetes 1.4 及以上版本默认启用。
Garbage Collector 垃圾收集器 Garbage Collector 是 k8s 垃圾收集功能的具体实现。Garbage Collector 属于 Kubernetes Controller 的一部分。kube-controller-manager 的 --controllers 命令行标志的值中包含 garbagecollector，用以控制是否启用该控制器。
垃圾收集器在 kubernetes 的代码中的位置在这里：pkg/controller/garbagecollector。
Owner 和 Dependent 参考：
官方文档，概念-概述-使用 Kubernetes 对象-属主与从属 在 Kubernetes 中
Owner(拥有者/属主) # 一些 Kubernetes 对象是其它对象的 Owner。例如，一个 Deployment 是一组 Pod 的 Owner(i.e.deployment 拥有这些 pod)。 Dependent(依赖他人者/从属) # 被 Owner 拥有的对象被称 Dependent(从属) 对象，该 Dependent 属于该 Owner。 每个 Dependent 对象具有一个指向其 owner 对象的 metadata.</description></item><item><title>GitHub</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub/</guid><description>概述 参考：
官方文档 官方文档，中文 在代码仓库中，点击 . 即可进入 Web 版的 VS Code，在线编辑当前仓库的代码。
GitHub Desktop https://desktop.github.com/
专注于重要的事情，而不是与 Git 对抗。无论您是 Git 新手还是经验丰富的用户，GitHub Desktop 都能简化您的开发工作流程。</description></item><item><title>GitHub Actions</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/GitHub-Actions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/GitHub-Actions/</guid><description>概述 参考：
官方文档 官方文档，学习 GitHub Actions - GitHub Actions 简介 域名中的路径改成 理解 GitHub Actions GitHub Actions 官方市场：Actions Marketplace 阮一峰老师的一篇文章：GitHub Actions 入门教程 https://blog.csdn.net/sculpta/article/details/104142607 GitHub Actions 是在 GitHub Universe 大会上发布的，被 Github 主管 Sam Lambert 称为 “再次改变软件开发” 的一款重磅功能（“we believe we will once again revolutionize software development.”）。于 2018 年 10 月推出，内测了一段时间后，于 2019 年 11 月 13 日正式上线
GitHub 会提供一个以下配置的服务器做为 runner：
2-core CPU 7 GB of RAM memory 14 GB of SSD disk space （免费额度最多可以同时运行 20 个作业，心动了有木有 💘）</description></item><item><title>GitLab</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab/</guid><description>概述 参考：
官方文档 https://www.qikqiak.com/post/gitlab-install-on-k8s/ GitLab 部署 官方文档：https://docs.gitlab.com/ee/install/README.html
通过官方的 linux 软件包安装 https://about.gitlab.com/install/ 根据该页面选择想要运行 GitLab 的 Linux 发行版，可以通过 yum、apt 等方式直接安装 GitLab 及其所需的依赖。
使用 Docker 运行 GitLab 官方文档：https://docs.gitlab.com/omnibus/docker/
docker run --detach \ --hostname 10.10.100.151 \ --publish 443:443 --publish 80:80 --publish 9022:22 \ --name gitlab \ --restart always \ --volume /root/gitlab/config:/etc/gitlab \ --volume /root/gitlab/logs:/var/log/gitlab \ --volume /root/gitlab/data:/var/opt/gitlab \ gitlab/gitlab-ce:latest 部署完成后，使用 root 和 第一次打开 web 页面时设置的密码，即可登录管理员账户。
最佳实践 从 GitHub 导入仓库到 GitLab 并定时同步 https://www.jianshu.com/p/0959d021c281
Notes: GitLab 中有镜像仓库的能力，在 项目设置 - 仓库 - 镜像仓库 中。但是只有商业版才能使用从别的 git 仓库同步到 GitLab 的功能。</description></item><item><title>GitLab CI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab-CI/GitLab-CI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab-CI/GitLab-CI/</guid><description>概述 参考:
官方文档，主题 - 使用 CI/CD 构建你的应用 在 WebUI 左侧导航栏 Build 标签中可以看到下面几个标签
Pipelines # 查看根据 .gitlab-ci.yml 生成的流水线 Jobs # 查看 Pipelines 中的所有 Jobs Pipeline editor # 在线编辑 gitlab-ci.yml 文件 Pipeline schedules Artifacts # 查看 Artifacts</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Glossary/</guid><description>概述 参考：
RFC 4949(互联网安全术语) Crypto(密码学) # 算是 Cryptographic 的前缀简写吧
Entity(实体) # 是任何存在的东西（anything that exists） —— 即使 只在逻辑或概念上存在（even if only exists logically or conceptually）。 例如，
你的计算机是一个 entity， 你写的代码也是一个 entity， 你自己也是一个 entity， 你吃的杂粮饼也是一个 entity， 你六岁时见过的幽灵也是一个 entity —— 即使你妈告诉你幽灵并不存在，这只是你的臆想。 所以 CA 也算一个实体 Identity(身份) # 每个 entity（实体）都有一个 identity（身份）。 要精确定义这个概念比较困难，这么来说吧：identity 是使你之所以为你 （what makes you you）的东西。
具体到计算机领域，identity 通常用一系列属性来表示，描述某个具体的 entity， 这里的属性包括 group、age、location、favorite color、shoe size 等等。 Identifier(身份标识符) # Identifier 跟 identity 还不是一个东西：每个 identifier 都是一个唯一标识符， 也唯一地关联到某个有 identity 的 entity。</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/Standard/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Glossary/</guid><description>概述 参考：
Wiki, Glossary Wiki, Standardization Standardized(标准化) 与 Standard(标准)
Standardized 更多用来行用指定标准的过程 Standard 是经过标准化后产生的结果，已经定义好的标准是在 执行、构建、生产 各种 任务、流程、产品 时的最佳方式或期望 学习某项技术时，有些名词，比如某某可以是技术、规范、标准、行为、协议(协议其实从广义角度看也是标准)、等。
IDC https://en.wikipedia.org/wiki/Data_center
Internet data center(互联网数据中心，简称 IDC)，也可以简称为 Data center(数据中心)，并不用只限制在互联网。IDC 是一座建筑物、建筑物内的专用空间或一组建筑物，用于容纳计算机系统和相关设备。通常用于对外或对内提供 计算、存储、通信 这最基本的三大能力。
ISP https://en.wikipedia.org/wiki/Internet_service_provider
Internet service provider(互联网服务提供商，简称 ISP) 是提供访问、使用、管理或参与 Internet 服务的组织。 ISP 可以以多种形式组织，例如商业、社区所有、非营利或其他私人所有。比如 中国移动、中国联通、中国电信、etc. 都属于 ISP
版本信息 英文 中文 缩写 说明 Portable 便携式、可移植 一个程序如果不需要安装，直接使用二进制文件运行，通常称为 Portable。 全部 英文 中文 缩写与简称 链接 解释 5-tuple 五元组 RFC 6146 源 IP，源 PORT，目的 IP，目的 PORT，传输层协议，这五个量组成的一个集合 Advanced Telecommunications Computing Architecture 高级电信计算架构 ATCA Wiki atca架构本身就是一组工业标准框架，只要是基于这个国际统一标准做的板卡都可以集成到一起 Architecture 架构 arch Broadband Remote Access Server 宽带远程接入服务器 BRAS Wiki 是一种用于管理和控制带宽接入用户的网络设备 Call detail record 通话详细记录 CDR Wiki 中文常简称为 &amp;ldquo;话单&amp;rdquo;。随着发展，话单的含义也逐步扩展，包含了不止是通话的详细信息。有时候也用 xDR 描述。 Data Plane Development Kit 数据平面开发套件 DPDK DPDK Deep packet inspection 深度数据包检测 DPI DPI Call Detail Record 通话详细记录 CDR(话单) CDR 后期随着发展该名词逐渐包含了 网络、等 通信之间的详细记录，而不是单指通话。可以写为 xDR(wiki 上没有 xDR，自己造的) Cyberspace Situation Awareness 网络态势感知 CSA Mellanox Technologies 一家以色列裔美国跨国供应商，提供基于 InfiniBand 和以太网技术的计算机网络产品。Mellanox 为高性能计算、数据中心、云计算、计算机数据存储和金融服务 Remote Authentication Dial-In User Service 远程用户拨号认证 RADIUS Wiki Situational awareness 态势感知 SA Wiki Service Level Indicator 服务等级指标 SLI Sevice Level Objective 服务等级目标 SLO Switched Port Analyzer SPAN Transaction</description></item><item><title>Go</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go/</guid><description>概述 参考：
GitHub 项目，golang/go 官网 Google 开放源代码 GitHub 项目，avelino/awesome-go(收录了优秀的 Go 框架、库、软件) 中文版，GitHub 项目，yinggaozhen/awesome-go-cn 另一个 go awesome: https://github.com/shockerli/go-awesome Go 是一种开源编程语言，可以轻松构建 simple(简单)、reliable(可靠) 和 efficient(高效) 的软件。
学习资料 Go 语言之旅(官方在线教程)
Go 官方 FAQ
Go by Example
中文 Go by Example GitHub 组织，golang-china(Go 语言中国)
公众号-HelloGitHub，适合 Go 新手学习的开源项目
地鼠文档系列文章
Go 编程模式 电子书
GitHub 项目，unknowon/the-way-to-go(Go 入门指南) GitHub 项目，gopl-zh/gopl-zh.github.com(Go 语言圣经) The Go Programming Language 视频
B 站-幼麟实验室-Golang 合辑 https://github.com/avelino/awesome-go
Hello World 代码：hello_world.go
package main import &amp;#34;fmt&amp;#34; func main() { fmt.</description></item><item><title>Go 工具</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B7%A5%E5%85%B7/Go-%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B7%A5%E5%85%B7/Go-%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，命令文档 go 是用来管理 Go 编程语言源代码的工具
go 参考：
Go 包，标准库 - cmd - go go 是一个工具，用来管理 Go 语言编写的代码。该工具由多个子命令组成。每个子命令可以实现不同类型的功能。
bug - start a bug report build - 编译 package 及其依赖 https://pkg.go.dev/cmd/go#hdr-Compile_packages_and_dependencies
默认编译当前路径下的代码包及其依赖，生成一个可执行文件
OPTIONS
-ldflags [PATTERN=]ARG # 向链接器传递一些参数。这些参数可用于指定编译时需要使用的一些信息，例如项目版本号、Git 提交 ID、构建时间、构建平台和架构等元数据信息 比如： -ldflags &amp;quot;-X 'main.version=1.0.0' -X 'main.buildTime=$(date)'&amp;quot; # 为 main 包中的 version 和 buildTime 变量设置值 -ldflags &amp;quot;-s -w&amp;quot; # 告诉链接器在生成可执行文件时忽略调试信息和符号表，从而使得你的二进制文件更加紧凑而且不再可读。 -gcflags [PATTERN=]ARG # 每次执行&amp;quot;go tool compile&amp;quot;时要传递的参数。 -o NAME # 指定构建完成后生成的文件名为 NAME -x # 输出 Go 程序编译、链接、打包的全过程。包括都使用了哪些库、执行了什么命令、等等 EXAMPLE</description></item><item><title>Go 规范与标准库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</guid><description>概述 参考：
官方文档，参考 - 规范 官方文档，参考 - 规范 的翻译 go.dev, Tour(Go 语言之旅，通过在线解析器体验 Go 语言的各种特性) 公众号，11个现代Go特性：用 gopls/modernize 让你的代码焕然一新 Go 是一种通用语言，专为系统编程而设计。它是一种强类型且自带垃圾回收功能的语言，并具有显式支持并发编程的能力(称为 goroutine)。Go 程序由 Packages(包) 构建，其属性允许有效得管理依赖关系。
Go 语言参考描述了 Go 语言的具体语法和语义 Go 标准库则是与 Go 语言一起发行的一些可选功能，以便人们可以从一开始就轻松得使用 Go 进行编程。 Keywords 参考：
官方文档，参考 - 规范 - 关键字 Go 语言非常简单，只有 25 个关键字(Keywords)可以使用，记住这 25 个关键字，就掌握了最基本的 Go 语言用法。这些关键字是 go 语言保留的，不能用作标识符
关键字在编程语言中是指该语言的一个功能，比如下文面的 var，就是指声明一个变量，func 就是定义一个函数等等。
Note: if-else 算两个关键字所以在这里一共只写了 24 个。
break # 控制结构 case # 控制结构 chan # 用于 channel 通讯 const # 语言基础里面的常量申明 continue # 用在 for 控制结构中，用以忽略本次循环的后续所有逻辑，执行下一次循环 default # 控制结构 defer # 用于在函数退出之前执行某语句的功能 fallthrough # 控制结构 for # 控制结构 func # 用于定义函数和方法 go # 用于并发 goto 控制结构 if-else # 控制结构 import 用于定义该文件引用某个包 interface # 用于定义接口 map # 用于声明 map 类型数据 package # 用于定义该文件所属的包 range # 用于读取 slice、map、channel 数据 return # 用于从函数返回。有时候也用来直接跳出当前函数，回到主程序继续执行 select # 用于选择不同类型的通讯 struct # 用于定义抽象数据类型 switch # 控制结构 type # 用于 Type Declarations(类型声明)，有两种形式： Definitions(定义) 自定义类型 Declarations(声明) 一个类型的别名。 其实所谓的类型的别名，也可以当作一种自定义的类型。 var # 用于 Declarations(声明) 变量 Lexical elements(词汇元素) 一些 Go 语言中抽象或具象名词，用于描述某些实体或行为。</description></item><item><title>Go 环境安装与使用</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>概述 参考：
官方文档，下载并安装 Go 官方文档，安装多个版本的 Go Go 包，标准库 - cmd - go 我们可以通过一个名为 go 的二进制文件实现绝大部分日常的 编码、编译 等工作，只要安装好 Go 的环境即可。
安装 Go Linux 安装 从官网下载 linux 版的 .tar.gz 包
export GoVersion=1.20.2 wget https://go.dev/dl/go${GoVersion}.linux-amd64.tar.gz sudo tar -C /usr/local -xvzf go${GoVersion}.linux-amd64.tar.gz 配置环境变量，以便让 shell 可以执行 go 命令并立刻生效
sudo tee /etc/profile.d/go.sh &amp;gt; /dev/null &amp;lt;&amp;lt;-&amp;#34;EOF&amp;#34; # export GOPATH=/opt/gopath # export PATH=$PATH:\$GOPATH/bin:/usr/local/go/bin export PATH=$PATH:/usr/local/go/bin export GO111MODULE=on export GOPROXY=https://goproxy.cn,https://goproxy.io,direct export CGO_ENABLED=0 EOF source /etc/profile.d/go.sh CGO_ENABLED 开启后 Go 代码最终编译的可执行文件都是要有外部依赖的。不过我们依然可以通过 disable CGO_ENABLED 来编译出纯静态的 Go 程序，常用于交叉编译 CGO_ENABLED 关闭即可编译出纯静态的 Go 程序，可以用于 alpine 镜像中。</description></item><item><title>GPU</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/GPU/GPU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/GPU/GPU/</guid><description>概述 参考：
Wiki, Graphics processing unit Wiki, Graphics card Graphics card (也称为 video card, display card, graphics accelerator, graphics adapter, VGA card/VGA, video adapter, display adapter, 或者通俗的说 GPU)
Graphics Processing Unit(图形处理单元，简称 GPU) 是 Graphics card 的核心计算组件，执行计算功能
显卡常见配置 垂直同步 在不开启垂直同步的情况下，某些游戏可能会无线拉高游戏帧率。开启后，会让游戏的帧率限制到显示器的刷新率，某种程度上，关闭垂直同步会降低显卡的利用率
AI：
开启垂直同步时：
显卡帧率被限制在显示器刷新率（通常60Hz/144Hz等） 如果显卡性能过剩，使用率会降低，因为它不需要全力渲染超过刷新率的帧数 如果显卡性能刚好或不足，使用率可能保持较高水平 关闭垂直同步时：
显卡会尽全力渲染，追求最高帧率 使用率通常会提高，特别是在性能要求高的游戏中 可能出现画面撕裂，但帧率更高 实际影响：
高端显卡玩轻量游戏：开启V-Sync会明显降低使用率 中低端显卡玩大型游戏：开启V-Sync对使用率影响较小 竞技游戏玩家通常关闭V-Sync以获得更高帧率和更低延迟 现在还有自适应同步技术（如G-Sync、FreeSync），可以在防止撕裂的同时避免传统V-Sync的缺点，对显卡使用率的影响更加智能化。</description></item><item><title>Grafana</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana/</guid><description>概述 参考：
官网 GitHub 项目，grafana/grafana Grafana 是开源的可视化和分析软件。它使我们可以查询，可视化，警报和浏览指标，无论它们存储在哪里。它为您提供了将 时间序列数据 转换为精美的图形和可视化效果的工具。
Grafana 部署 参考：
官方文档，安装 - 安装 Grafana docker 方式运行 grafana 获取配置文件
mkdir -p /opt/monitoring/server/config/grafana mkdir -p /opt/monitoring/server/data/grafana chown -R 472 /opt/monitoring/server/data/grafana docker run -d --name grafana --rm grafana/grafana docker cp grafana:/etc/grafana /opt/monitoring/server/config docker stop grafana 运行 Grafana
docker run -d --name grafana \ --network host \ -v /opt/monitoring/server/config/grafana:/etc/grafana \ -v /opt/monitoring/server/data/grafana:/var/lib/grafana \ -v /etc/localtime:/etc/localtime \ grafana/grafana Grafana 关联文件与配置 /etc/grafana/ # Grafana 配置文件保存路径</description></item><item><title>Grafana Configuration</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-Configuration/Grafana-Configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-Configuration/Grafana-Configuration/</guid><description>概述 参考：
官方文档，Setup - 配置 Grafana Grafna 可以通过 INI 格式的配置文件、命令行标志、环境变量来配置运行时行为。
环境变量 与 配置文件 中的配置具有一一对应的关系。环境变量可以覆盖配置文件中的配置(即.环境变量的优先级更高，如果有相通配置，以环境变量的配置为主)。
环境变量格式：GF_&amp;lt;SectionName&amp;gt;_&amp;lt;KeyName&amp;gt;
SectionName 对应配置文件中 [ ] 中的内容 KeyName 对应配置文件中的关键字。 配置文件中的 . 和 - 两个符号，到环境变量中则变为 _ 符号。环境变量的文本全是大写的 假如现在的配置文件内容如下：
# default section instance_name = ${HOSTNAME} [security] admin_user = admin [auth.google] client_secret = 0ldS3cretKey [plugin.grafana-image-renderer] rendering_ignore_https_errors = true 对应环境变量，则是：
GF_DEFAULT_INSTANCE_NAME=my-instance GF_SECURITY_ADMIN_USER=owner GF_AUTH_GOOGLE_CLIENT_SECRET=newS3cretKey GF_PLUGIN_GRAFANA_IMAGE_RENDERER_RENDERING_IGNORE_HTTPS_ERRORS=true 可以看到，Grafana 的配置具有层次感，配置文件中 [ ] 表示一套配置环境，配置环境下方，有具体的配置关键字。
备注 Grafana 容器镜像会默认配置一些环境变量，以指定一些基本的配置路径。此处是官方对镜像的解释
grafana.ini 配置文件详解 Grafana 的配置文件开头 ; 表示注释
paths data = &amp;lt;STRING&amp;gt; # Grafana 数据存储路径。默认值：/var/lib/grafana/data</description></item><item><title>Helm</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm/</guid><description>概述 参考：
GitHub 项目，helm/helm 官方文档 其他后期发现的文章 https://www.cnblogs.com/liugp/p/16659802.html Helm 是 Kubernetes 的 Package Manager(包管理器)。Kubernetes 在希腊语中，意为舵手或飞行员，是一个蓝色的舵轮图标。所以 Helm 就以类似的概念命名，Helm 称为舵柄，图标与 Kubernetes 类似，寓意把握着 Kubernetes 航行的方向。
主要概念 参考：
官方文档，介绍-使用 Helm Helm 与 Kubernetes 的关系，就好比 yum 与 RedHat，apt 与 Ubuntu 一样，是一个 Kubernetes 专用的包管理器，安装专用于 k8s 集群之上的软件包。Helm 使用 Chart 帮助我们管理应用，Chart 就像 RPM 一样，里面描述了应用及其依赖关系。
Chart(图表) 是由 Helm 管理的应用部署包。Chart 是在一个结构相对固定的目录中，包含用于描述一个应用的一组 manifests 文件。
Chart Archive(图标归档) # 是一个将 Chart 打包成 .tgz 格式的压缩文件。 实际上，Chart 就是很多 manifests 的集合，里面有一个应用程序所需的 yaml 文件。而对于 kubernetes 来说，所谓的应用程序(软件包)也就是一堆 manifests，每个 manifest 代表一种资源(比如 deployment、service、ingress、configmap 等等)，这些 manifests 组合起来，就构成了一个应用。 Chart 包 就像 RPM 包一样。这不过没有类似 rpm 的命令，而是直接使用类似 yum 的 helm 命令来管理这些包。并且，Chart 包 也和 RPM 包一样，具有依赖关系。 Release(发布) 是将 Chart 部署到 Kubernets 集群中运行的实例，每一次 helm install CHART 就会生成一个 Release</description></item><item><title>Helm CLI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/Helm-CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/Helm-CLI/</guid><description>概述 参考：
官方文档，Helm 命令 - Helm Syntax(语法) helm COMMANDS [FLAGS]
Flags 与 Options 一样，是标志、标记的意思，就是指该命令的各个选项
FLAGS 全局 Flags
&amp;ndash;add-dir-header If true, adds the file directory to the header &amp;ndash;alsologtostderr log to standard error as well as files &amp;ndash;debug # 开启详细的输出信息 -h, &amp;ndash;help help for helm &amp;ndash;kube-context string name of the kubeconfig context to use &amp;ndash;kubeconfig STRING # 指定 helm 运行所需的 kubeconfig 文件路径为 STRING。默认为 /root/.kube/config &amp;ndash;log-backtrace-at traceLocation when logging hits line file:N, emit a stack trace (default :0) &amp;ndash;log-dir string If non-empty, write log files in this directory &amp;ndash;log-file string If non-empty, use this log file &amp;ndash;log-file-max-size uint Defines the maximum size a log file can grow to.</description></item><item><title>HTM</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/HTML/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/HTML/</guid><description>概述 参考：
WHATWG，HTML 标准 MDN，参考 - HTML Wiki, HTML HyperText Markup Lanugage(超文本标记语言，简称 HTML) 是构成 Web 世界的一砖一瓦。它定义了网页内容的含义和结构。除 HTML 以外的其它技术则通常用来描述一个网页的表现与展示效果（如 CSS），或功能与行为（如 JavaScript）。
“超文本”（hypertext）是指连接单个网站内或多个网站间的网页的链接。链接是网络的一个基本方面。只要将内容上传到互联网，并将其与他人创建的页面相链接，你就成为了万维网的积极参与者。
HTML 准确来说并不是一门编程语言，而是一种用于定义内容结构的 Markup language(标记语言)。
HTML 使用“标记”（markup）来注明文本、图片和其他内容，以便于在 Web 浏览器中显示。HTML 标记包含一些特殊“元素”如 &amp;lt;head&amp;gt;、&amp;lt;title&amp;gt;、&amp;lt;body&amp;gt;、&amp;lt;header&amp;gt;、&amp;lt;footer&amp;gt;、&amp;lt;article&amp;gt;、&amp;lt;section&amp;gt;、&amp;lt;p&amp;gt;、&amp;lt;div&amp;gt;、&amp;lt;span&amp;gt;、&amp;lt;img&amp;gt;、&amp;lt;aside&amp;gt;、&amp;lt;audio&amp;gt;、&amp;lt;canvas&amp;gt;、&amp;lt;datalist&amp;gt;、&amp;lt;details&amp;gt;、&amp;lt;embed&amp;gt;、&amp;lt;nav&amp;gt;、&amp;lt;output&amp;gt;、&amp;lt;progress&amp;gt;、&amp;lt;video&amp;gt;、&amp;lt;ul&amp;gt;、&amp;lt;ol&amp;gt;、&amp;lt;li&amp;gt; 等等。
HTML Element(元素) 通过 Tag(标签) 将文本从文档中引出，标签由在 &amp;lt; 和 &amp;gt; 中包裹的元素名组成，HTML 标签里的元素名不区分大小写。也就是说，它们可以用大写，小写或混合形式书写。例如，&amp;lt;title&amp;gt; 标签可以写成 &amp;lt;Title&amp;gt;，&amp;lt;TITLE&amp;gt; 或以任何其他方式。然而，习惯上与实践上都推荐将标签名全部小写。
学习资料 MDN，HTML
W3schools，HTML 教程
网道，HTML
菜鸟教程，HTML
各种 HTML、CSS、Vue 等代码示例 菜鸟教程里对应代码的的示例非常多 https://gitee.com/wyanhui02/html_css_demo Hello World HTML 语言关键字 参考：
MDN 学习 Web 开发，HTML-HTML 基础 MDN Web 开发技术，HTML-参考-HTML 元素 HTML 的关键字又称为 Tag(标签)，有时候又称为 Element(元素)。</description></item><item><title>HTTP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP/</guid><description>概述 参考：
RFC 2616 Mozilla 官方 HTTP 开发文档 公众号-小林 coding，硬核！30 张图解 HTTP 常见的面试题 公众号-码海，51 张图助你彻底掌握 HTTP 协议 HyperText Transfer Protocol(超文本传输协议，简称 HTTP)。是基于 TCP 的用于分布式、协作式、超媒体的信息系统的应用层协议。HTTP 是 World Wide Web(万维网,简称 WWW.就是我们俗称的 Web) 的数据通信基础。
HTTP 标准的演化 参考：
InfoQ 中的消息 在 2014 年之前，HTTP/1.1 版本的标准为 RFC 2616，但由于某些原因，为了让标准更规范，HTTP/1.1 被拆分成了 6 个部分：
RFC7230 - HTTP/1.1: Message Syntax and Routing(消息语法和路由)。这里包含 低级的消息解析 和 链接管理。 RFC7231 - HTTP/1.1: Semantics and Content(语意和内容)。这里面包含了 Methods、Status Codes、Headers RFC7232 - HTTP/1.1: Conditional Requests - e.g., If-Modified-Since RFC7233 - HTTP/1.</description></item><item><title>HTTP 会话状态管理</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
HTTP 会话状态管理包含认证/授权
傻傻分不清之 Cookie、Session、Token、JWT 原文：掘金，傻傻分不清之 Cookie、Session、Token、JWT
什么是认证（Authentication） 通俗地讲就是验证当前用户的身份，证明“你是你自己”（比如：你每天上下班打卡，都需要通过指纹打卡，当你的指纹和系统里录入的指纹相匹配时，就打卡成功） 互联网中的认证： 用户名密码登录 邮箱发送登录链接 手机号接收验证码 只要你能收到邮箱/验证码，就默认你是账号的主人 什么是授权（Authorization） 用户授予第三方应用访问该用户某些资源的权限 你在安装手机应用的时候，APP 会询问是否允许授予权限（访问相册、地理位置等权限） 你在访问微信小程序时，当登录时，小程序会询问是否允许授予权限（获取昵称、头像、地区、性别等个人信息） 实现授权的方式有：cookie、session、token、OAuth 什么是凭证（Credentials） 实现认证和授权的前提 是需要一种 媒介(证书) 来标记访问者的身份 在战国时期，商鞅变法，发明了照身帖。照身帖由官府发放，是一块打磨光滑细密的竹板，上面刻有持有人的头像和籍贯信息。国人必须持有，如若没有就被认为是黑户，或者间谍之类的。 在现实生活中，每个人都会有一张专属的居民身份证，是用于证明持有人身份的一种法定证件。通过身份证，我们可以办理手机卡/银行卡/个人贷款/交通出行等等，这就是认证的凭证。 在互联网应用中，一般网站（如掘金）会有两种模式，游客模式和登录模式。游客模式下，可以正常浏览网站上面的文章，一旦想要点赞/收藏/分享文章，就需要登录或者注册账号。当用户登录成功后，服务器会给该用户使用的浏览器颁发一个令牌（token），这个令牌用来表明你的身份，每次浏览器发送请求时会带上这个令牌，就可以使用游客模式下无法使用的功能。 什么是 Cookie HTTP 是无状态的协议（对于事务处理没有记忆能力，每次客户端和服务端会话完成时，服务端不会保存任何会话信息）：每个请求都是完全独立的，服务端无法确认当前访问者的身份信息，无法分辨上一次的请求发送者和这一次的发送者是不是同一个人。所以服务器与浏览器为了进行会话跟踪（知道是谁在访问我），就必须主动的去维护一个状态，这个状态用于告知服务端前后两个请求是否来自同一浏览器。而这个状态需要通过 cookie 或者 session 去实现。 cookie 存储在客户端： cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。 cookie 是不可跨域的： 每个 cookie 都会绑定单一的域名，无法在别的域名下获取使用，一级域名和二级域名之间是允许共享使用的（靠的是 domain）。 cookie 重要的属性
name=value # 键值对，设置 Cookie 的名称及相对应的值，都必须是字符串类型- 如果值为 Unicode 字符，需要为字符编码。- 如果值为二进制数据，则需要使用 BASE64 编码。
domain # 指定 cookie 所属域名，默认是当前域名
path # 指定 cookie 在哪个路径（路由）下生效，默认是 &amp;lsquo;/&amp;rsquo;。如果设置为 /abc，则只有 /abc 下的路由可以访问到该 cookie，如：/abc/read。</description></item><item><title>Hugo</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/Hugo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/Hugo/</guid><description>概述 参考：
GitHub 项目，gohugoio/hugo GitHub 项目，coderzh/gohugo.org（一个从19年停更的 Hugo 中文网） 官网 Wiki, Hugo(软件) Hugo 是用 Go 语言编写的静态站点生成器。Steve Francia 最初于 2013 年将 Hugo 创建为开源项目。
Hugo 创建站点时主要依赖两部分，Content(内容) 与 Layout(布局)
Content(内容) 表示数据。存在 content/ 目录下。 该目录下的每个文件都会抽象为一个 Page(页面)。其实我们在浏览到的页面就是 Hugo 中的 Page 的概念，而 content/ 目录就是存放这些 Page 的地方。内容的管理详见内容管理章节 Layout(布局) 表示页面。存在 layouts/ 目录下。 该目录下的每个文件都会抽象为一个 Template(模板) 通过多种渠道获取到数据(i.e. Content)后，需要在页面(i.e. Layout)中填充数据，这就是模板渲染的过程，渲染完成后，可供浏览的页面称之为 View(视图)。
Hugo 的这种渲染行为与 Go 的模板渲染机制一致，并提供了更丰富的功能。
Hugo 的基本使用 参考：
官方文档，入门-快速开始 这里的示例并没有安全按照官方文档走，而是在我学习之后改编的，官方文档的示例其实会让新手对于渲染逻辑和顺序产生迷惑。
hugo new site hello_world 命令将会创建一个包含以下元素的目录结构，这些目录的作用可以在下文找到：
hello_world/ ├── archetypes/ │ └── default.md ├── assets/ ├── content/ ├── data/ ├── layouts/ ├── public/ ├── static/ ├── themes/ └── config.</description></item><item><title>IDE</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/IDE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/IDE/</guid><description>概述 参考：
Wiki, Integrated development environment Integrated development environment(集成开发环境，简称 IDE) 是一种为软件开发提供全面设施的软件应用程序。</description></item><item><title>Ingress</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress/</guid><description>概述 参考：
官方文档，概念-服务，负载均衡和网络-Ingress 参考：https://zhangguanzhang.github.io/2018/10/06/IngressController/ Ingress 可以简单理解为是 Service 的 Service，是 Kubernetes 对“反向代理”概念的抽象。是一个专门给 kubernetes 用的 haproxy
举个例子，假如我现在有这样一个站点：https://cafe.example.com。其中，https://cafe.example.com/coffee，对应的是“咖啡点餐系统”。而，https://cafe.example.com/tea，对应的则是“茶水点餐系统”。这两个系统，分别由名叫 coffee 和 tea 这样两个 Deployment 来提供服务。
那么现在，我如何能使用 Kubernetes 来创建一个代理系统，从而实现当用户访问不同的域名时，能够访问到不同的 Deployment 呢？
上述功能，在 Kubernetes 里就需要通过 Ingress 对象来描述
Service 都是工作在 4 层模型上的，如果在 k8s 上的应用基于 https 来提供服务，那么在调度到 pod 上的时候就需要使用 7 层调度，这时候可以创建一个独特的 pod，略过 service，直接通过这个独特的 pod 进行反向代理把请求调度给用户，把 service 放在这个特殊的 pod 前端，但是这样经过的调度算法过多，导致性能过差；这时候可以把整个独特的 Pod 通过设置，把端口直接暴露，作为 node 上的一个进程来占用一个端口使用，然后通过 daemonset 给集群中某些需要的节点各自部署一个该 Pod(可以给一部分 node 加污点不让 pod 调度到此，并让该独特的 pod 容忍这个污点并调度上来)
这种独特的 Pod 统称 IngressController，由于 Pod 都是无状态的，随时可能会被摧毁后重建，这时候 HAProxy 和 Nginx 基于配置文件中 IP 地址的方式，在云环境下就没法用了。这时候可以创建一个 Service 关联上后端 Pod 与 Ingress Controller，该 Service 不做代理，仅作为分类来用，可以让 Ingress Controller 来正确找到自己所管理提供服务的 Pod。</description></item><item><title>Instrumenting</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting/</guid><description>概述 参考：
官方文档，Instrumenting - Exporter 官方文档，最佳实践 - Instrumentation Prometheus 可以从如下几类 Intrumenting 中 Scrape(抓取) 指标：
Instrumentation(检测仪/仪表化) # 内部仪表。本质上是 Prometheus 的 Client Libraries(客户端库) 添加到程序代码中，以此暴露一个 endpoint，Prometheus Server 可以通过该 Endpoiint 抓取到指标。 可以理解为内嵌的 Exporter，比如 Prometheus Server 的 9090 端口的 /metrics 就属于此类。 说白了，就是被监控目标自己就可以吐出符合 Prometheus 格式的指标数据 Exporters # 外部仪表。 概念更为宽泛，除了使用到 Instrumentation 实现的各种程序外，还有一些通过脚本产生的符合 Prometheus Data Model(数据模型) 的纯文本的程序也可以称为 Exporter。 Pushgateway # 针对需要推送指标的应用 Instrumentation 参考:
官方文档，Instrumentation - 客户端库 Instrumentation(仪表化)，顾名思义，将某个东西变为 Instrumenting（也可以说变为 Exporter）。所以 Instrumentation 是一组 Library，当我们在编写的程序代码中引入了 Instrumentation，并使用其提供的各种方法、接口，那么我们的程序就可以变成像仪表一样的东西，以展示出想要的 观测或监控 数据。
Prometheus 官方维护了某些语言的 Library:</description></item><item><title>Inter Process Communication</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Inter-Process-Communication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Inter-Process-Communication/</guid><description>概述 参考：
Wiki, IPC Wiki, LPC 公众号，操作系统是如何一步步发明进程间通信的？ Inter Process Communication(进程间通信，简称 IPC) 是一种允许多个进程共享数据的机制。IPC 的两个应用可以被分为客户端和服务端，客户端进程请求数据，服务端响应客户端的数据请求。有一些应用本身既是服务器又是客户端，这在分布式计算中，时常可以见到。这些进程可以运行在同一计算机上或网络连接的不同计算机上。
IPC 对微内核和 nano 内核的设计过程非常重要。 微内核减少了内核提供的功能数量。 然后通过 IPC 与服务器通信获得这些功能，与普通的宏内核相比，IPC 的数量大幅增加。
IPC 可以分为如下两类：
Local Procedure Call(本地过程调用，简称 LPC) # Remote Procedure Call(远程过程调用，简称 RPC) # IPC 可以通过多种方式实现：
file(文件) # 多个进程可以通过磁盘上的文件共享数据。 Signal(信号)# 从一个进程发送到另一个进程的系统消息，通常不用于传输数据，而是用于远程命令伙伴进程。Signal(信号) pipe(管道)# 使用标准输入和输出的单向数据通道。写入管道的写入端的数据由操作系统进行缓冲，直到从管道的读取端读取数据为止。通过使用相反“方向”上的两个管道可以实现过程之间的双向通信。详见 管道符等组合命令 Socket(套接字) # Socket 是计算机领域中，数据通信的一种约定，或者说是一种方法 Shared Memory(共享内存) # Message Queue(消息队列) # 类似于 Socket 的数据流，但这通常保留了信息的边界。通常由操作系统实现，它们允许多个进程读写消息队列，而不需要彼此直接连接。 Mesage Passing(消息传递) # 允许多个程序使用消息队列和/或非 OS 托管通道进行通信。常用于并发模型。比如 LPC、RPC 等等。 等等 IPC 实现方式概述 公众号 - 小林 Coding，进程间通信 每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。</description></item><item><title>Internet</title><link>https://desistdaydream.github.io/docs/Standard/Internet/Internet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Internet/Internet/</guid><description>概述 参考：
Wiki, Internet Internet(互联网)
互联网治理组织 参考：
Wiki-Category,Internet governance organizations(互联网治理组织) Internet Assigned Numbers Authority(互联网号码分配局，简称 IANA) 是一个标准组织，负责监督全球IP 地址分配、自治系统号码分配、域名系统 (DNS) 中的根区管理、媒体类型以及其他与互联网协议相关的符号和互联网号码。
Internet Corporation for Assigned Names and Numbers(互联网名称与数字地址分配机构，简称 ICANN) 是一个美国多利益相关方团体和非营利组织，负责协调与Internet 的命名空间和数字空间相关的多个数据库的维护和程序，确保网络稳定安全运行。ICANN 执行中央互联网地址池和DNS 根区注册管理机构的实际技术维护工作互联网号码分配机构(IANA) 功能合同。ICANN 与美国商务部国家电信和信息管理局(NTIA)之间关于 IANA管理职能的合同于 2016 年 10 月 1 日结束，正式将职能移交给全球多利益相关方社群。
Interne Engineering Task Force(互联网工程工作组，简称 IETF) 是一个开放标准组织，其开发和促进自愿互联网标准，特别是包括互联网协议套件(TCP/IP)的标准。它没有正式的会员名单或会员要求。所有参与者和经理都是志愿者，尽管他们的工作通常由雇主或赞助商资助。IETF 是首屈一指的互联网标准组织。它遵循设置这些标准的开放且有据可查的流程。一旦发布，这些标准将免费提供。
Internet Research Task Force(互联网研究任务组，简称 IRTF) 专注于 与 互联网相关的长期研究问题，而平行组织 互联网工程任务组 ( IETF ) 则专注于工程和标准制定的短期问题。
Internet Archive(互联网档案馆) 参考：
Wiki, Internet_Archive 官网 Internet Archive(互联网档案馆) 是一个美国数字图书馆，其使命是“普及所有知识”。拥有数百万册免费书籍、电影、软件、音乐、网站等。
其他 W3C 与 WHATWG</description></item><item><title>Interrupts(中断)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Interrupts%E4%B8%AD%E6%96%AD/Interrupts%E4%B8%AD%E6%96%AD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Interrupts%E4%B8%AD%E6%96%AD/Interrupts%E4%B8%AD%E6%96%AD/</guid><description>概述 参考：
Wiki, Interrupt 公众号-云原生实验室，Linux 中断（IRQ/softirq）基础：原理及内核实现 Interrupte Request(终端请求，简称 IRQ)，是一种信号，该信号来源于外围硬件(相对于 CPU 和内存)的异步信号或者来自软件的同步信号，收到该信号后进行相应的硬件、软件处理。中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。
Linux 内核对计算机上所有的设备进行管理，进行管理的方式是内核和设备之间的通信。解决通信的方式有两种：
轮询。轮询是指内核对设备状态进行周期性的查询 中断。中断是指在设备需要 CPU 的时候主动发起通信 从物理学的角度看，中断是一种电信号，由硬件设备产生，并直接送入中断控制器（如 8259A）的输入引脚上，然后再由中断控制器向处理器发送相应的信号。处理器一经检测到该信号，便中断自己当前正在处理的工作，转而去处理中断。此后，处理器会通知 OS 已经产生中断。这样，OS 就可以对这个中断进行适当的处理。不同的设备对应的中断不同，而每个中断都通过一个唯一的数字标识，这些值通常被称为中断线。
中断可以分为 NMI(不可屏蔽中断) 和 INTR(可屏蔽中断)。其中 NMI 通常用于电源掉电和物理存储器奇偶校验；INTR 是可屏蔽中断，可以通过设置中断屏蔽位来进行中断屏蔽，它主要用于接受外部硬件的中断信号，这些信号由中断控制器传递给 CPU。
常见的两种中断控制器：
Programmable Interrupt Controller(可编程中断控制器，简称 PIC) 8259A Advanced Programmable Interrupt Controller(高级可编程中断控制器，简称 APIC) 传统的 PIC 是由两片 8259A 风格的外部芯片以“级联”的方式连接在一起。每个芯片可处理多达 8 个不同的 IRQ。因为从 PIC 的 INT 输出线连接到主 PIC 的 IRQ2 引脚，所以可用 IRQ 线的个数达到 15 个
硬中断与软中断 中断处理分为两部分，上半部与下半部。
硬中断，也就是中断处理的上半部 外围硬件发给 CPU 或者内存的异步信号就称之为硬中断 由与系统相连的外设(比如网卡、硬盘)自动产生的。主要是用来通知操作系统系统外设状态的变化。比如当网卡收到数据包的时候，就会发出一个中断。我们通常所说的中断指的是硬中断(hardirq)。 软中断：也就是中断处理的下半部 由软件系统本身发给操作系统内核的中断信号，称之为软中断。通常是由硬中断处理程序或进程调度程序对操作系统内核的中断，也就是我们常说的系统调用(System Call) 为了满足实时系统的要求，中断处理应该是越快越好。linux 为了实现这个特点，当中断发生的时候，硬中断处理那些短时间就可以完成的工作，而将那些处理事件比较长的工作，放到中断之后来完成，也就是软中断(softirq)来完成。 也就是说，如果在一个完整的中断流程中，硬中断首先产生，然后硬中断的处理程序将会发出中断信号后，再有软中断进行处理。</description></item><item><title>ip</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ip/ip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ip/ip/</guid><description>概述 参考：
Manual(手册)，ip(8) ip 命令行工具可以控制各种 Object(对象)，这些对象包括：路由、网络设备、接口、隧道 等
Syntax(语法) ip [Global OPTIONS] OBJECT [COMMAND]
ip 程序的语法有点复杂，对 Object 控制的命令中，有非常多的参数，不像普通命令一样，把参数称为 FLAGS 或 OPTIONS，且都是以 - 或者 -- 符号开头的。
ip 的手册中使用 大写字符串 来描述 一个参数 或 一个具体的值。参数中还可以包含一个或多个其他参数，每个参数的值，同样使用大写字母表示。
在后面的文章中，凡是这种复杂的参数，都使用这类格式表示：参数 := 参数 | 值，这就有点像编程中初始化变量一样。在这里就是等于是定义一个参数，并为参数赋值。比如 ip address 命令中，就有这种样子的写法：
这里面有一个 IFADDR （红框）表示一个参数，IFADDR 参数又是由 PREFIX、SCOPE-ID 等参数组成，而 SCOPE-ID 则表示有具体含义的值。其实，本质上，命令行工具的参数，就是要传入代码内 Function 的实际参数。
Global OPITONS 注意：这里的 OPTIONS 是全局选项，要用在 ip 与 OBJECT 之间，比如：
~]# ip -c route default via 172.19.42.1 dev ens3 proto static metric 100 10.</description></item><item><title>IP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/IP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/IP/</guid><description>概述 参考：
RFC 791， INTERNET PROTOCOL PROTOCOL SPECIFICATION Wiki, Internet Protocol Wiki, IPv4 Wiki, Mask(掩码) Wiki, Classful Network(分类网络) IANA,IPv4 地址空间分配情况 APNIC(管理亚太地区的 IP 地址注册机构) APNIC,帮助-FTP 数据库(亚太地区所有分配的 IP 地址信息) IANA,IPv4 特殊用途地址注册表 Internet Protocol(互联网协议，简称 IP) 是互联网协议套件(其中包含 TCP/IP)中的主要通信协议，用于跨网络边界中继数据报。它的路由功能可实现互联网络，并实质上建立了 Internet。
Internet protocol suite(互联网协议套件) 是互联网和类似计算机网络中使用的概念模型和通信协议集。由于该套件中的基本协议是 TCP(传输控制协议) 和 IP(互联网协议)，因此通常被称为 TCP/IP。在其开发过程中，其版本被称为国防部（DoD）模型，因为联网方法的开发是由美国国防部通过 DARPA 资助的。它的实现是一个协议栈。
IP 基于数据包的 Header 中的 IP 地址，将数据包从源主机发送到目标主机。基于此目的，IP 还定义了数据包的封装结构、以及一种寻址方法。寻址方法用来使用源和目标的信息标记数据报。
从历史上看，IP 是在 1974 年由 Vint Cerf 和 Bob Kahn 引入的原始 Transmission Control Program(传输控制程序) 中的无连接数据报服务。该服务由一项面向连接的服务补充，成为 Transmission Control Protocol(传输控制协议，简称 TCP) 的基础。因此 IP 套件通常称为 TCP/IP。IP 的第一个版本是 IPv4，继任者是 IPv6</description></item><item><title>Iproute 工具包</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/</guid><description>概述 参考：
官方文档 Wiki, Iproute2 Iprtoue2 是一组应用程序的集合，用于管理 Linux 网络栈。可以控制、监控 LInux 内核中网络栈的各个方面，包括路由、网络接口、隧道、流量控制、与网络相关的设备驱动程序。
Iproute2 基于 Linux 的 Netlink 接口与 LInux 内核通信，以实现网络栈管理功能。Iproute2 的发展与内核网络组件的发展密切相关，原作者 Alexey Kuznetsov 负责 Linux 内核中的 QoS 实现，并且各种文档由 Linux 基金会 Wiki 维护，且代码也存在于 Linux 内核代码中
该工具包包含如下工具 arpd bridge # 显示或操纵 Linux 网桥 地址和设备 cbq ctstat devlink genl ifcfg ifstat ip # 显示或操纵 routing, devices, policy routing and tunnels lnstat nstat rdma routef routel rtacct rtmon rtpr rtstat ss # 转存 Socket 信息 tipc # tc # 实现 TC 模块 进行流量控制的程序 关联文件与配置 /etc/iproute2/ #</description></item><item><title>iptables</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/iptables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/iptables/</guid><description>概述 参考：
Manual(手册)，iptables(8) Netfilter 官方文档，iptables 教程 https://www.zsythink.net/archives/1199 iptables 是 Netfilter 团队开发的一组用于与 netfilter 模块进行交互的 CLI 工具，其中包括 iptables、ip6tables、arptables、ebtables 等。
iptables 和 ip6tables 用于建立、维护和检查 Linux 内核中的 IPv4 和 IPv6 包过滤规则表。可以定义几个不同的表中的各种规则，也可以定义用户定义的链。并把已经定义的规则发送给 netfilter 模块。
四表(Table) 注意：四表是 iptables 框架中的概念，不是 Netfilter 中的
iptables 框架将流量抽象分为 4 类：过滤类、网络地址转换类、拆解报文类、原始类。每种类型的链作用在 Netfilter 系统中的 Hook 各不不相同，每种类型具有不同的功能。每一类都称为一张表。比如 fileter 表用来在指定链上检查流量是否可以通过，nat 表用来在指定链上检查流量是否可以进行地址转换，等等。Note：不是所有表都可以在所有链上具有规则，下表是 4 个表在 5 个 Hook 上的可用关系。
表名\链名 PREROUTING INPUT FORWARD OUTPUT POSTROUTING filter 可用 可用 可用 nat 可用 可用 可用 可用 mangle 可用 可用 可用 可用 可用 raw 可用 可用 iptables 中有默认的内置 4 个表，每个表的名称就是其 chain 类型的名称</description></item><item><title>IT</title><link>https://desistdaydream.github.io/docs/Standard/IT/IT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/IT/IT/</guid><description>概述 参考：
Wiki-类别，计算机标准 Wiki-类别，信息技术 IT 技术的基础
Operating system 数据结构 数据通信 PICMG 参考：
官网 Wiki, PICMG PCI Industrial Computer Manufacturers Group(PCI工业计算机制造商组织) 是由计算机科学和工程领域的 140 多家公司组成的联盟。该小组成立于 1994 年，最初成立的目的是为了将 PCI 技术应用于高性能电信、军事和工业计算应用，但其工作现已发展到包括更新的技术。 PICMG 目前专注于开发和实施各种互连的基于开放标准的计算机架构的规范和指南。</description></item><item><title>Java</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Java/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Java/</guid><description>概述 参考：
官网 廖雪峰-Java教程，Java简介 Java 分三个版本：
Java Standard Edition(标准版，简称 JSE) Java Enterprise Edition(企业版，简称 JEE) Java Micro Edition(微型版，简称 JME) ┌───────────────────────────┐ │Java EE │ │ ┌────────────────────┐ │ │ │Java SE │ │ │ │ ┌─────────────┐ │ │ │ │ │ Java ME │ │ │ │ │ └─────────────┘ │ │ │ └────────────────────┘ │ └───────────────────────────┘ Java 名词 JDK # Java Development Kit（Java 开发工具包）
JRE # Java Runtime Environment（Java 运行时环境）
JVM # Java Virtual Machin（Java 虚拟机）</description></item><item><title>Java 环境安装与使用</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Java%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Java%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Java%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Java%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>概述 参考：
廖雪峰-Java 教程，安装 JDK 安装 Java 安装好的 JavaSE 包含很多可执行程序
java：这个可执行程序其实就是JVM，运行Java程序，就是启动JVM，然后让JVM执行指定的编译后的代码； javac：这是Java的编译器，它用于把Java源码文件（以.java后缀结尾）编译为Java字节码文件（以.class后缀结尾）； jar：用于把一组.class文件打包成一个.jar文件，便于发布； javadoc：用于从Java源码中自动提取注释并生成文档； jdb：Java调试器，用于开发阶段的运行调试。 Windows 安装 从这里下载 JavaSE
解压到指定目录(我通常是在 D:/Tools/Java/jdk-${VERSION})，将该目录添加到 JAVA_HOME 环境变量
将 %JAVA_HOME%/bin 添加到 PATH 变量中。</description></item><item><title>JavaScript 规范与标准库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</guid><description>概述 参考：
GitHub,DesistDaydream/javascript-learning(个人学习代码) MDN 官方文档，Web 开发技术-Web APIs JavaScript 语言参考描述了 JavaScript 语言的具体语法和语义 JavaScript 标准库则是与 JavaScript 语言一起发行的一些可选功能，以便人们可以从一开始就轻松得使用 JavaScript 进行编程。 JavaScript 语言的标准库不像其他语言似的，由于运行时只有一个，所以也只有一个标准库，JavaScript 可以通过 Node.JS 在系统中运行，也可以通过浏览器运行，后来出的 Deno 运行时与 Node.js 还不一样。
所以，JavaScript 的标准库根据运行时环境的不同而不同。但是 JavaScripts 代码本身的关键字还是通用的。
JavaScript 的基本语法 参考：
网道，JavaScript-JavaScript 的基本语法 语句 JavaScript 程序的执行单位为行（line），也就是一行一行地执行。一般情况下，每一行就是一个语句。
语句（statement）是为了完成某种任务而进行的操作，比如下面就是一行赋值语句。
var a = 1 + 3; 这条语句先用var命令，声明了变量a，然后将1 + 3的运算结果赋值给变量a。
1 + 3叫做表达式（expression），指一个为了得到返回值的计算式。语句和表达式的区别在于，前者主要为了进行某种操作，一般情况下不需要返回值；后者则是为了得到返回值，一定会返回一个值。凡是 JavaScript 语言中预期为值的地方，都可以使用表达式。比如，赋值语句的等号右边，预期是一个值，因此可以放置各种表达式。
语句以分号结尾，一个分号就表示一个语句结束。多个语句可以写在一行内。
var a = 1 + 3 ; var b = &amp;#39;abc&amp;#39;; 分号前面可以没有任何内容，JavaScript 引擎将其视为空语句。
;;; 上面的代码就表示 3 个空语句。</description></item><item><title>Job</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Job/Job/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Job/Job/</guid><description>概述 参考：
-Wiki, Job_(computing)
在计算中，Job 是一个工作单元或执行单元（执行所述工作）。Job 的组成部分（作为工作单元）称为任务或步骤（如果是连续的，称为 Job Stream）。作为执行单元，Job 可以具体地标识为单个进程，该进程又可以具有子进程，这些子进程执行构成作业的工作的任务或步骤。
Job 调度 参考：
Wiki, Job_scheduler 大多数操作系统（例如 Unix-like OS 和 Microsoft OS）都提供基本的作业调度功能，特别是通过 批处理、cron 和 Windows 任务调度程序。 Web 托管服务通过控制面板或 webcron 解决方案提供作业调度功能。许多程序（例如 DBMS、备份、ERP 和 BPM）还包含相关的作业调度功能。操作系统（“OS”）或点程序提供的作业调度通常不会提供超出单个操作系统实例或超出特定程序范围的调度能力。需要自动化不相关 IT 工作负载的组织还可以利用作业调度程序的更多高级功能
Job 的衍生 Cron 是类 Unix 系统中的 Job 调度工具
GitHub 的 Action 使用 Workflow(工作流) 称呼多个多个 Job 组成的任务。</description></item><item><title>JSON</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/JSON/JSON/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/JSON/JSON/</guid><description>概述 参考：
Go 包，标准库 - encoding/json Go 官方博客《JSON and Go》 骏马金龙 在线 JSON 转 Go Struct Go 语言内置了 encoding 标准库，并使用其中的 json 包来实现 JSON 的 Encoding(编码) 和 Decoding(解码) 逻辑，这里面的 JSON 符合 RFC 7159 标准。
这里面说的编码则是指将 Go 自身可以识别的数据类型编码为 JSON 格式的数据；解码主要是指解码后数据编程 Go 可以理解的数据格式，比如 struct、slice、map 等。
说白了，Go 编完的码，是编成人类可读的，自己不认识；解码才是将数据解成 Go 自己认识的。
JSON类型 与 Go类型 对应关系
boolean &amp;gt;&amp;gt; bool number &amp;gt;&amp;gt; float32,float64,int, int64, uint64 string &amp;gt;&amp;gt; string null &amp;gt;&amp;gt; nil array &amp;gt;&amp;gt; []interface{} object &amp;gt;&amp;gt; map[string]interface{} 使用 json 包，可以轻松地从 Go 程序中读取和写入 JSON 数据。</description></item><item><title>K3S</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S/</guid><description>概述 参考：
GitHub 项目，k3s-io/k3s 官方文档 中文官方文档 公众号-云原生实验室，K3S 工具进阶完全指南 K3S 是一个轻量的 Kubernetes，具有基本的 kubernetes 功能，将 kubernetes 的主要组件都集成在一个二进制文件中(apiserver、kubelet 等)，这个二进制文件只有不到 100m。内嵌 Containerd，可以通过 Containerd 来启动 coredns 等 kubernetes 的 addone。直接使用 k3s 的二进制文件，即可启动一个 kubernetes 的节点。
Note: K3S 的 kubelet 不支持 systemd 作为 cgroup-driver，原因详见 https://github.com/rancher/k3s/issues/797 ，说是 systemd 的类型无法放进二进制文件里。
k3s 二进制文件包含 kubelet、api-server、kube-controller-manager、kube-scheduler，然后会通过 containerd 拉起 coredns 与 flannel。
K3S 封装的组件 官方文档，安装 - 管理封装的组件
K3S 封装了部分非 K8S 核心组件，比如 coredns、traefik、local-storage、metrics-server、servicelb。这些组件通常都会以 manifests 文件的方式保存在 /var/lib/rancher/k3s/server/manifests/ 目录中，当 K3S 启动时，自动拉起这些组件。
嵌入式 servicelb LoadBalancer controller 没有 manifests 文件，但由于历史原因，它可以像 AddOn 一样被禁用</description></item><item><title>Kernel</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Kernel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Kernel/</guid><description>概述 参考：
操作系统 OS 与内核 Kernel 有什么区别？ 原文链接：https://mp.weixin.qq.com/s/-5tDn2-IS6Xo6DwQJN4c3Q
通用底盘技术
Canoo 公司有一项核心技术专利，这就是它们的通用电动底盘技术，长得是这个样子，非常像一个滑板：
这个带轮子、有电池、能动的滑板已经包含了一辆车最核心的组件，差的就是一个外壳。这个看起来像滑板的东西就是所谓的电池系统和底盘一体化技术，Canoo 公司在它们的通用底盘上加装不同的外壳就能制造出不同的车型。
什么是内核？ 在上面这个示例中，包含轮子以及电池系统的底盘就好比内核，而套上外壳加上椅子以及内饰后的整体成品就好比操作系统。内核仅仅是操作系统的一部分，是真正与硬件交互的那部分软件，与硬件交互包括读写硬盘、读写网盘、读写内存以及任何连接到系统中的硬件。除了与硬件交互外，内核还负责分配资源，分配什么资源呢？所谓资源就是硬件，比如 CPU 时间、内存、IO 等等，这些都是资源。
因此，内核的职责就是以进程的形式来分配 CPU 时间，以虚拟内存的形式来分配物理内存，以文件的形式来管理 IO 设备。
什么是操作系统？ 然而只有一个内核实际上是做不了什么真正有用的事情，就像上面示例中那个通用底盘一样，这个底盘确实能跑起来，但你没办法开着这样一个底盘出去浪，因为这个底盘很难用。因此，你不得不加装上方向盘、座椅以及车身外壳等，同样的道理，内核是给人用的，为了与内核交互，发明了命令行以及图形界面 GUI。
在 Windows 平台就是给程序员提供编程接口的是 Windows API，这层 API 包罗万象，不但包括上文提到对系统调用的封装，还包括其它功能，像创建带有图形界面的应用程序等等。但在 Linux 世界你找不到一种类似 Windows API 的东西，毕竟 Windows 是微软自家产品，什么都可以打包起来，Linux 只是一个开源的内核，如果一定要找一个类似的东西话那就是 libc，也就是 C 标准库，这里同样包括了对系统调用的封装以及一些库函数，但 libc 不包含创建带有图形界面应用程序的功能。现在我们知道了，操作系统需要提供两种接口：
给用户提供操作接口。 给程序员提供编程接口。 这些就是好比汽车的外壳，我们(用户和程序员)看得见摸得着，外壳加上底盘——也就是内核，才是功能完善的操作系统。
各种各样的操作系统 实际上我们熟悉的 Linux 只是内核而不能称得上是操作系统，Ubuntu 则可以认为是操作系统，其内核是 Linux；RedHat 也是操作系统，其内核同样是 Linux；我们可以看到，尽管 Ubuntu 和 RedHat 是不同的操作系统，但其内核可以是相同的。这就好比它们可以基于同样的底盘打造出不同的车型。而我们熟悉的 Windows 也是操作系统，其内核是 Windows NT 内核。
总结 内核就像本文开头提到的电动底盘，包含了一个汽车的最核心元素；但这样一个底盘并没有什么实际用处，当搭配上外壳以及座椅后才是一辆真正有用的车，这就好比操作系统。值得注意的是，不同的操作系统可以有相同的内核。
宏内核与微内核 原文链接：公众号-码农的荒岛求生，操作系统的实现：什么是宏内核、微内核</description></item><item><title>Kernel 参数</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/Kernel-%E5%8F%82%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/Kernel-%E5%8F%82%E6%95%B0/</guid><description>概述 参考：
官方文档，Linux 内核用户和管理员指南-/proc/sys 文档 内核参数是以 key/value 的方式储存在 sysfs 文件系统中。key 就是 . /proc/sys/ 目录下的某个文件，value 就是该文件的内容。
比如 net.ipv4.ip_forward 这个 key，就在 /proc/sys/net/ipv4/ 目录下。以.分隔的就是字符就是目录名，最后一个字段就是某某目录下的文件名。
可以通过修改 /proc/sys/ 目录下的文件中的值来修改内核的参数。每个文件就是内核的一种功能，文件中的内容就是该内核功能的参数。
注意事项：
一般情况下，内核参数的 0 和 1 这两个值表示如下含义： 0 表示 否，即错误、拒绝、关闭等等 1 表示 是，即正确、允许、开启等等 sysctl 工具用来配置与显示在 /proc/sys 目录中的内核参数．如果想使参数长期保存，可以通过编辑 /etc/sysctl.conf 文件来实现。 修改 /proc 下内核参数文件内容，不能使用编辑器来修改内核参数文件，理由是由于内核随时可能更改这些文件中的任意一个，另外，这些内核参数文件都是虚拟文件，实际中不存在，因此不能使用编辑器进行编辑，而是使用 echo 命令，然后从命令行将输出重定向至 /proc 下所选定的文件中。参数修改后立即生效，但是重启系统后，该参数又恢复成默认值。因此，想永久更改内核参数，需要修改 /etc/sysctl.conf 文件。 echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward sysctl -w net.ipv4.ip_forward=1 永久的方法： echo &amp;quot;net.ipv4.ip_forward=1&amp;quot; &amp;gt;&amp;gt; /etc/sysctl.conf 如果想使参数马上生效，也可以执行如下命令 sysctl -p /proc/sys 目录的组成 /proc/sys/ 目录下的每一个子目录，都表示一种内核参数的分类，大体可以分为如下几类：</description></item><item><title>Keystone</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Keystone/Keystone/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Keystone/Keystone/</guid><description>概述</description></item><item><title>kube-proxy</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/kube-proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/kube-proxy/</guid><description>概述 参考：
官方文档，概念-概述-Kubernetes 组件-kube-proxy kube-proxy 是实现 Service(服务) 功能的组件，可以转发 Service 的流量到 POD
kube-proxy 有三种模式，userspace、iptables、ipvs。
service 在逻辑上代表了后端的多个 Pod，外界通过 service 访问 Pod。service 接收到的请求是如何转发到 Pod 的呢？这就是 kube-proxy 要完成的工作。接管系统的 iptables，所有到达 Service 的请求，都会根据 proxy 所定义的 iptables 的规则，进行 nat 转发 每个 Node 都会运行 kube-proxy 服务，它负责将访问 service 的 TCP/UPD 数据流转发到后端的容器。如果有多个副本，kube-proxy 会实现负载均衡。 每个 Service 的变动(创建，改动，摧毁)都会通知 proxy，在 proxy 所在的本节点创建响应的 iptables 规则，如果 Service 后端的 Pod 摧毁后重新建立了，那么就是靠 proxy 来把 pod 信息提供给 Service。 Note:
kube-proxy 的 ipvs 模式为 lvs 的 nat 模型 如果想要在 ipvs 模式下从 VIP:nodePort 去访问就请你暴露的服务的话，需要将 VIP 的掩码设置为 /32。 参考 issue：https://github.</description></item><item><title>kubeadm 命令行工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，参考 - kubeadm kubeadm 库 v1beta2 版本的 kubeadm 包的配置文件字段详解 Kubeadm 是一个工具，它提供了 kubeadm init 以及 kubeadm join 这两个命令作为快速创建 Kubernetes 集群的最佳实践。
kubeadm 通过执行必要的操作来启动和运行一个最小可用的集群。它被故意设计为只关心启动集群，而不是准备节点环境的工作。同样的，诸如安装各种各样的可有可无的插件，例如 Kubernetes 控制面板、监控解决方案以及特定云提供商的插件，这些都不在它负责的范围。
相反，我们期望由一个基于 kubeadm 从更高层设计的更加合适的工具来做这些事情；并且，理想情况下，使用 kubeadm 作为所有部署的基础将会使得创建一个符合期望的集群变得容易。
kubeadm 中的资源 实际上，kubeadm 继承了 kubernetes 的哲学，一切介资源，只不过由于 kubeadm 并没有控制器逻辑、也并不需要将这些资源实例化为一个个的对象。这些资源主要是为了让 kubeadm 的概念以及使用方式，更贴近 Kubernetes，所以 kubeadm 的资源仅仅作为定义配置所用。在 kubeadm 的 API 代码中，也可以看到这些资源的结构体定义。
kubeadm 的运行时行为通常由下面几个 API 资源来控制：
InitConfiguration(初始化配置) # ClusterConfiguation(集群配置) # KubeletConfiguration(kubelet 程序配置) # KubeProxyConfiguration(kube-proxy 程序配置) # JoinConfiguration(加入集群配置) # 其中 InitConfiguration、ClusterConfiguation、JoinConfiguration 资源属于 kubeadm 在控制集群时所用的配置
而 KubeletConfiguration 与 KubeProxyConfiguration 资源，实际上就是 kubelet 和 kube-proxy 程序的配置文件，kubeadm 可以通过其自身的配置文件，在控制集群时，修改 kubelet 与 kube-proxy 程序的配置文件。</description></item><item><title>Kubeapps</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Kubeapps/Kubeapps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Kubeapps/Kubeapps/</guid><description>概述 参考：
官网 GitHub 项目，kubeapps/kubeapps Kubeapps 是一个基于 Web 的 UI，用于在 Kubernetes 集群中部署和管理应用程序。
Kubeapps 可以实现下述功能：
从 Chart 仓库浏览和部署 Helm 检查、升级、删除集群中已经安装的基于 Helm 的应用程序。 可以看到，Kubeapps 与原生 Helm 结合比较紧密，这一点是 Rancher 做不到的。 添加自定义和自由 Chart 仓库 浏览和部署 Kubernetes Operator 使用 OAuth2/OIDC 提供程序对 Kubeapps 进行安全身份验证 基于 Kubernetes RBAC 的安全授权 Kubeapps 组件 Kubeapps 抽象了一个 Asset(资产) 的概念，Asset 是多种事物的集合，比如一个 Chart 仓库就属于一个资产。
一个完整的 Kubeapps 服务，通常包含如下组件：
Apprepository-controller # 应用仓库管理 Asset-syncer # 扫描 Helm 仓库，并在 PostgreSQL 中填充 Chart 元数据的工具，然后 Assetsvc 组件将会提供这些元数据 Assetsvc # 暴露 API，用于访问 PostgreSQL 中的 Chart 仓库中的 Chart 元数据 Dashboard # Web UI Kubeops # 暴露 API 来访问 Helm API 和 Kubernetes 资源 PostgreSQL # 存储 Chart 仓库的信息，其他组件都是无状态的 Kubeapps 权限管理 参考：</description></item><item><title>kubectl 命令行工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，参考-kubectl 官方文档，任务-安装工具-kubectl 官方推荐常用命令备忘录 kubectl 所用的 kubeconfig 文件，默认在 ~/.kube/confg，该文件用于定位 Kubernetes 集群以及与 API Server 交互时进行认证，如果没有认证文件则 API Server 无法处理 kubectl 发出的任何指令并返回错误信息。
如果该文件不存在或配置不全(比如没有指定 current-context 字段)，kubectl 则会向 localhost:8080 发起请求(该端口是 API Server 默认监听的不安全端口，该端口不需要认证即可对集群执行所有操作)。
由于 API Server 默认不开启不安全端口，所以在没有配置文件时，就会报如下错误：The connection to the server localhost:8080 was refused - did you specify the right host or port?
如果 kubectl 使用的 KubeConfig 文件中，没有集群的 ca 信息，则会报如下错误：Error from server (BadRequest): the server rejected our request for an unknown reason
kubeclt 安装 在 Linux 上安装 kubectl Ubuntu</description></item><item><title>Kubelet</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet/</guid><description>概述 参考：
官方文档，参考-组件工具-kubelet Kubelet 是在每个节点上运行的主要 节点代理。它可以使用以下之一向 APIServer 注册节点：用于覆盖主机名的标志；或云提供商的特定逻辑。
kubelet 根据 PodSpec 起作用。 PodSpec 是一个描述 Pod 的 YAML 或 JSON 对象。 kubelet 接受通过各种机制（主要是通过 apiserver）提供的一组 PodSpec，并确保这些 PodSpec 中描述的容器正在运行且运行状况良好。 Kubelet 不管理不是 Kubernetes 创建的容器。一般情况， PodSpec 都是由在 k8s 对象的 yaml 文件中定义的。
kubelet 负责维护容器(CNI)的生命周期，同时也负责 Volume（CVI）和 Network（CNI）的管理。kubernetes 集群的宿主机上，启动的每一个 pod 都有由 kubelet 这个组件管理的。
kubelet 在每个 Node 上都会启动一个 kubelet daemon 进程，默认监听在 10250 端口。该进程用于处理 Master 节点(主要是 apiserver)下发到本节点的任务，管理 Pod 以及 Pod 中的容器。每个 kubelet 进程会在 APIServer 上注册节点自身信息，定期向 Master 节点汇报节点资源的使用情况，并通过 cAdvisor(kubelet 内部功能) 监控容器和节点资源。10248 为 kubelet 健康检查的 healthz 端口</description></item><item><title>Kubelet</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/Kubelet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/Kubelet/</guid><description>概述 参考：
田飞雨博客，源码阅读笔记-kubernetes-kubelet 公众号，CNCF-Kubernetes 源码分析之 kubelet(一) https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&amp;__biz=Mzk0NTE4OTU0Ng==&amp;scene=1&amp;album_id=1632443286688677893&amp;count=3#wechat_redirect 博客 - 一直肥羊的思考，kubelet 内部实现解析 博客 - ljchen&amp;rsquo;s Notes，Kubelet 源码结构简介 更新时间：2022 年 2 月 23 日，Kubernetes 的源码目录随着更新迭代，也在不断变化中
目录结构 kubelet 代码分两部分，在 cmd/kubelet 和 pkg/kubelet 中
cmd/kubelet/* $ tree -L 2 -p cmd/kubelet cmd/kubelet ├── [-rwxrwxrwx] BUILD ├── [-rwxrwxrwx] OWNERS ├── [drwxrwxrwx] app │ ├── [-rwxrwxrwx] BUILD │ ├── [-rwxrwxrwx] OWNERS │ ├── [-rwxrwxrwx] auth.go │ ├── [-rwxrwxrwx] init_others.go │ ├── [-rwxrwxrwx] init_windows.go │ ├── [-rwxrwxrwx] init_windows_test.</description></item><item><title>Kubernetes</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes/</guid><description>概述 参考：
官方文档，概念 - 概述 play with kubernetes Kubernetes 是一套编排系统，编排目标是实现了 Containerization(容器化) 的容器。
Borg 是谷歌内部的容器管理系统，Kuberntes 根据 Borg 的思路使用 Go 语言重新开发，2015 年 7 月份发布
特性：
自我修复：一个 pod 崩了，可以在 1 秒启动，pod 比较轻量，kill 掉崩的容器再启动一个，所以一般情况一个 deployment 会启动多个 pod 自动实现水平扩展：一个 pod 不够，再起一个 自动服务发现和自动负载均衡：当在 k8s 上运行很多程序的时候，通过服务发现，找到所依赖的服务，且多个相同 pod 可以实现自动负载均衡 自动发布与回滚 支持密钥和配置管理：云原声应用，基于环境变量进行配置，需要一个外部组件，当镜像启动为容器的时候，可以自动去外部组件加载相关配置，这个配置中心就是 etcd 存储编排 任务的批量处理执行 Google 成立 CNCF，让各大公司共同管理，并把 Kubernetes 贡献给 CNCF，所以 Kubernetes 不会闭源。
Kubernetes 架构 参考：
官方文档，概念 - 集群架构
Kubernetes 集群由代表 Control Palne(控制平面) 和 一组 Nodes(节点) 的机器组成。
Control Plane Components(控制平面组件) API Server 实现程序：kube-apiserver</description></item><item><title>Kubernetes DNS</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/Kubernetes-DNS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/Kubernetes-DNS/</guid><description>概述 参考：
官方文档，概念-服务,负载均衡,网络-service 与 pod 的 DNS DNS 是 kubernetes 中 Service Discovery(服务发现，简称 SD) 的重要实现方式，虽然 K8S SD 还可以通过其他协议和机制提供，但 DNS 是非常常用的、并且是强烈建议的附加组件。
Kubernetes 集群中创建的每个 service 对象 和 pod 对象 都会被分配一个 DNS 名称，Kubernetes 中实现 DNS 功能的程序需要自动创建 DNS Resource Records(域名解析服务的资源记录)。基于此，我们可以通过 DNS 名称连接我们部署到集群中的服务，而不用通过 IP 地址。
kubernetes 实现 DNS 的方式：新版本默认使用 CoreDNS，1.11.0 之前使用的是 kube-dns。Kubernetes DNS 的实现必须符合既定的规范，规范详见 基于 DNS 的 Kubernetes 服务发现的规范 文章。
也就是说，任何可以用于实现 Kubernetes DNS 功能的应用程序，至少需要满足规范中描述的 Resource Records 格式标准。
Service 对象的 DNS A/AAAA 记录 Normal(正常) Service(除了 Headless 类型以外的所有 Service) 会以 my-svc.</description></item><item><title>Kubernetes 部署与清理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</guid><description>概述 参考：
官方文档，快速开始 GitHub 项目，easzlab/kubeasz(ansible 部署项目) 官方文档，入门-生产环境-使用部署工具安装 Kubernetes-使用 kubeadm 引导集群-使用 kubeadm 支持 IPv4 与 IPv6 双栈 注意事项：
不要使用 nftables Kubernetes 关联文件 下面这些是逐步总结的，应该是准确的，但是没有官方说明
/etc/kubernetes/ # 系统组件运行时配置
/var/lib/etcd/ # Etcd 数据目录
/var/lib/kubelet/ # Kubelet 运行时配置及数据持久化目录
CNI 目录
/etc/cni/net.d/# 默认配置文件保存目录 /opt/cni/bin/ # 默认 CNI 插件保存目录 /var/lib/cni/ # 默认 CNI 运行时产生的数据目录 部署 Kubernetes 集群 配置安装环境 (可选)更新内核以解决 ipvs 的(在 k8s-1.11.0 版本)BUG [参考内核部署文档](1.Linux%20Kernel.md Kernel.md) 关闭 iptables 和 firewalld 服务 由于 kubernetes 的 kube-proxy 会接管防火墙生成相关规则，所以最好关闭系统自带的 systemctl stop firewalld.</description></item><item><title>Kubernetes 存储</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Kubernetes-%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Kubernetes-%E5%AD%98%E5%82%A8/</guid><description>概述 参考：
官方文档，概念-存储 公众号-CNCF，卷扩展现在是个稳定特性 公众号-CNCF，存储容量跟踪在 Kubernetes1.24 中正式 GA 在 Container 中的文件在磁盘上是临时存储的(这与 Docker 一样，容器删除后，容器内的文件也随着删除)，这给 Container 中运行的需要持久化存储的应用程序带来了很多问题。
第一，当 Container 崩溃时，kubelet 会重启它，但是文件都将丢失并且 Container 以最干净的状态启动 第二，当在 Pod 中运行多个 Container 的时候，这些 Container 需要共享文件以实现功能。 Volume(卷) 就是为了解决上面两种情况出现的。
从本质上讲，Volume(卷) 只是一个包含一些数据目录，Pod 中 Container 可以访问这个目录。至于该目录是如何形成的是由所使用的 Volume 类型决定的。这个 Volume 的类型可以是：host 的内存，host 的文件，host 的目录，nfs、glusterfs、甚至是云厂商所提供的各种类型的存储
可以说，Kubernetes 存储功能的基础，就是 Volume(卷)。
Volume 功能详解见 Volume 章节
与 Docker 中的 Volume 的概念比较 Kubernetse 为什么不直接复用 Docker 中的 Volume，而是要自己实现呢?~
Kubernetes Volume 和 Docker Volume 概念相似，但是又有不同的地方，Kubernetes Volume 与 Pod 的生命周期相同，但与容器的生命周期不相关。当容器终止或重启时，Volume 中的数据也不会丢失。当 Pod 被删除时，Volume 才会被清理。并且数据是否丢失取决于 Volume 的具体类型，比如 emptyDir 类型的 Volume 数据会丢失，而持久化类型的数据则不会丢失。另外 Kubernetes 提供了将近 20 种 Volume 类型。</description></item><item><title>Kubernetes 管理案例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description>概述 参考：
资源删除场景 处于 Terminating 状态的对象处理 使用 kubectl edit 命令来编辑该对象的配置，删除其中 finalizers 字段及其附属字段，即可.
也可以使用 patch 命令来删除 finalizers 字段
kubectl patch -n NS Resource ResourceName -p &amp;#39;{&amp;#34;metadata&amp;#34;:{&amp;#34;finalizers&amp;#34;:null}}&amp;#39; -n log 或
kubectl patch -n test configmap mymap \ --type json \ --patch=&amp;#39;[ { &amp;#34;op&amp;#34;: &amp;#34;remove&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/metadata/finalizers&amp;#34; } ]&amp;#39; 资源无法删除 首先使用命令找到该 ns 还有哪些对象，最后的 NAMESPACE 改为自己想要查找的 ns 名
export NAMESPACE=&amp;#34;test&amp;#34; kubectl api-resources \ --verbs=list --namespaced -o name | xargs -n 1 \ kubectl get --show-kind --ignore-not-found -n NAMESPACE 找到对象后，删除，如果删不掉，使用处理 Terminationg 状态对象的方法进行处理</description></item><item><title>Kubernetes 监控</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/Kubernetes-%E7%9B%91%E6%8E%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/Kubernetes-%E7%9B%91%E6%8E%A7/</guid><description>概述 参考：
官方文档 对于 Kubernetes 集群的监控一般我们需要考虑以下几个方面：
Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标 集群系统组件的状态：比如 kubelet、kube-scheduler、kube-controller-manager、kubedns/coredns 等组件的详细运行状态 Pod 的监控：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标 Kubernetes 中，应用程序监控不依赖于单个监控解决方案，目前主要有以下几种方案：
Resource Metrics Pipeline# 通过 API Server 中的 Metrics API 暴露的一个用于显示集群指标接口，该接口在集群刚部署完成时，并不是默认自带的。需要通过其他方式来启用这个 API 可以通过 Resource Metrics 或 Full Metrics Pipelines 来收集监控指标数据 cAdvisor # cAdvisor 是 Google 开源的容器资源监控和性能分析工具，它是专门为容器而生，本身也支持 Docker 容器，在 Kubernetes 中，我们不需要单独去安装，cAdvisor 作为 kubelet 内置的一部分程序可以直接使用。kubelet 中的子组件 cAdvisor 来收集资源用量信息，并暴露 OpemMetrics 格式的监控指标。 metrics-server # metrics-server 是一个集群范围内的资源数据聚合工具，其前身是 Heapster。以 Pod 的形式运行在集群中，通过查询每个节点的 kubelet 以获取 CPU 和内存使用情况。 项目地址：https://github.com/kubernetes-sigs/metrics-server Heapster # 由于 Heapster 无法通过 Metrics API 的方式提供监控指标，所以被废弃了。1.</description></item><item><title>Kubernetes 日志</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E6%97%A5%E5%BF%97/Kubernetes-%E6%97%A5%E5%BF%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E6%97%A5%E5%BF%97/Kubernetes-%E6%97%A5%E5%BF%97/</guid><description>概述 参考
官方文档，概念 - 集群管理 - 日志架构 集群级日志架构需要一个单独的后端来存储、分析和查询日志。Kubernetes 不提供日志数据的原生存储解决方案。相反，有许多与 Kubernetes 集成的日志记录解决方案。
Kubernetes 日志管理机制 在 Kubernetes 中日志也主要有两大类：
应用 Pod 日志； Kuberntes 集群组件日志； 应用 Pod 日志 Kubernetes Pod 的日志管理是基于 Docker 引擎的，Kubernetes 并不管理日志的轮转策略，日志的存储都是基于 Docker 的日志管理策略。k8s 集群调度的基本单位就是 Pod，而 Pod 是一组容器，所以 k8s 日志管理基于 Docker 引擎这一说法也就不难理解了，最终日志还是要落到一个个容器上面。
假设 Docker 日志驱动为 json-file，那么在 k8s 每个节点上，kubelet 会为每个容器的日志创建一个软链接，软连接存储路径为：/var/log/containers/，软连接会链接到 /var/log/pods/ 目录下相应 pod 目录的容器日志，被链接的日志文件也是软链接，最终链接到 Docker 容器引擎的日志存储目录：/var/lib/docker/container 下相应容器的日志。另外这些软链接文件名称含有 k8s 相关信息，比如：Pod id，名字空间，容器 ID 等信息，这就为日志收集提供了很大的便利。
举例：我们跟踪一个容器日志文件，证明上述的说明，跟踪一个 kong Pod 日志，Pod 副本数为 1
/var/log/containers/kong-kong-d889cf995-2ntwz_kong_kong-432e47df36d0992a3a8d20ef6912112615ffeb30e6a95c484d15614302f8db03.log
&amp;mdash;&amp;mdash;-&amp;gt;
/var/log/pods/kong_kong-kong-d889cf995-2ntwz_a6377053-9ca3-48f9-9f73-49856908b94a/kong/0.log
&amp;mdash;&amp;mdash;-&amp;gt;
/var/lib/docker/containers/432e47df36d0992a3a8d20ef6912112615ffeb30e6a95c484d15614302f8db03/432e47df36d0992a3a8d20ef6912112615ffeb30e6a95c484d15614302f8db03-json.log</description></item><item><title>Kubernetes 网络</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-%E7%BD%91%E7%BB%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-%E7%BD%91%E7%BB%9C/</guid><description>概述 参考：
官方文档，概念-集群管理-集群网络 Kubernetes 的整体网络分为以下三类
Node IP(各节点网络) # Cluster IP(Service 网络) # 虚拟的，在 Netfilter 结构上，就是主机上 iptables 规则中的地址 Pod IP(Pod 网络) # 网络是 Kubernetes 的核心部分，Kubernetes 中有下面几个点需要互相通信
同一个 Pod 内的多个容器间通信，通过各容器的 lo 通信 Pod 之间的通信，Pod IP&amp;lt;&amp;ndash;&amp;gt;Pod IP overlay 叠加网络转发二层报文，通过隧道方式转发三层报文 Pod 与 Service 之间的通信，Pod IP&amp;lt;&amp;ndash;&amp;gt;Cluster IP。详见 Service(服务)。 Service 与集群外部客户端的通信。详见 Service(服务)。 Kubernetes 的宗旨就是在应用之间共享机器。 通常来说，共享机器需要两个应用之间不能使用相同的端口，但是在多个应用开发者之间 去大规模地协调端口是件很困难的事情，尤其是还要让用户暴露在他们控制范围之外的集群级别的问题上。
动态分配端口也会给系统带来很多复杂度 - 每个应用都需要设置一个端口的参数， 而 API 服务器还需要知道如何将动态端口数值插入到配置模块中，服务也需要知道如何找到对方等等。 与其去解决这些问题，Kubernetes 选择了其他不同的方法。
Kubernetes 网络模型 每一个 Pod 都有它自己的 IP 地址，这就意味着你不需要显式地在每个 Pod 之间创建链接， 你几乎不需要处理容器端口到主机端口之间的映射。 这将创建一个干净的、向后兼容的模型，在这个模型里，从端口分配、命名、服务发现、 负载均衡、应用配置和迁移的角度来看，Pod 可以被视作虚拟机或者物理主机。</description></item><item><title>Kubernetes 证书管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Kubernetes-%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/Kubernetes-%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Kubernetes-%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/Kubernetes-%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
PKI 证书和要求 参考：
官方文档，入门-最佳实践-PKI 证书和要求 Kubernetes 需要 PKI 证书才能进行基于 TLS 的身份验证。如果你是使用 kubeadm 安装的 Kubernetes， 则会自动生成集群所需的证书。你还可以生成自己的证书。 例如，不将私钥存储在 API 服务器上，可以让私钥更加安全。此页面说明了集群必需的证书。
集群是如何使用证书的 Kubernetes 需要 PKI 才能执行以下操作：
Kubelet 的客户端证书，用于 API 服务器身份验证 API 服务器端点的证书 集群管理员的客户端证书，用于 API 服务器身份认证 API 服务器的客户端证书，用于和 Kubelet 的会话 API 服务器的客户端证书，用于和 etcd 的会话 控制器管理器的客户端证书/kubeconfig，用于和 API 服务器的会话 调度器的客户端证书/kubeconfig，用于和 API 服务器的会话 前端代理 的客户端及服务端证书 说明： 只有当你运行 kube-proxy 并要支持 扩展 API 服务器 时，才需要 front-proxy 证书
etcd 还实现了双向 TLS 来对客户端和对其他对等节点进行身份验证。
证书存放的位置 如果你是通过 kubeadm 安装的 Kubernetes，所有证书都存放在 /etc/kubernetes/pki 目录下。本文所有相关的路径都是基于该路径的相对路径。</description></item><item><title>Kustomize</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Kustomize/Kustomize/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Kustomize/Kustomize/</guid><description>概述 参考：
GitHub 项目，kubernetes-sigs/kustomize 官网 官方文档，任务-管理 K8S 对象-使用 Kustomize 对 Kubernetes 对象进行声明式管理 Kustomize 是一个通过 Kustomization 文件来管理 Manifests 的应用程序，Manifests 就是用来生成 K8S 对象的 YAML 格式的文件。Kustomize 可以让我们自定义原始的，无模板的 YAML 文件，以用于多种用途，而原始的 YAML 则保持不变并可以使用。
从 K8S 的 1.14 版本开始，Kustomize 被集成在 kubectl 工具中，可以通过下面几种方式来使用 Kustomize
kustomize 子命令 -k,&amp;ndash;kustomize 标志来代替 kubectl apply 命令中的 -f 标志。 比如 kubectl apply -k &amp;lt;KustomizationDIR&amp;gt; Kustomize 与 Helm 非常类似，都可以用来渲染声明 Kubernetes 资源的 Manifests 文件，并部署到集群中，只不过，Kustomize 更轻便，更易用，但是，不像 Helm，并不能包装成 Chart 并统一上传到仓库中。
Kustomization Kustomize 就是通过 Kustomization 实现其功能的。Kustomization 有多种理解方式：
一个名为 kustomization.</description></item><item><title>KVM/QEMU</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU/</guid><description>概述 参考：
KVM 官网 Ubuntu 官方文档，虚拟化-qemu KVM 背景 Kernel-based Virtual Machine(基于内核的虚拟化机器，简称 KVM)， 是 Linux 的一个内核模块，就叫 kvm，只用于管理虚拟 CPU 和内存。该内核模块使得 Linux 变成了一个 Hypervisor。
它由 Quramnet 开发，该公司于 2008 年被 Red Hat 收购。 它支持 x86 (32 and 64 位), s390, Powerpc 等 CPU。 它从 Linux 2.6.20 起就作为一模块被包含在 Linux 内核中。 它需要支持虚拟化扩展的 CPU。 它是完全开源的。 KVM 实际是 Linux 内核提供的虚拟化架构，可将内核直接充当 Hypervisor 来使用。KVM 需要宿主机的 CPU 本身支持虚拟化扩展，如 intel VT 和 AMD AMD-V 技术。KVM 自 2.6.20 版本后已合入主干并发行。除了支持 x86 的处理器，同时也支持 S/390,PowerPC,IA-61 以及 ARM 等平台。</description></item><item><title>KVM/QEMU 命令行工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，QEMU 用户文档 官方文档，系统模拟-Invocation 官方文档，工具 KVM/QEMU 的虚拟机的生命周期是通过一系列 KVM/QEMU 工具集管理的，包括
qemu-img # 虚拟机镜像管理工具 qemu-system-$ARCH # 虚拟机运行时管理工具。 注意：在 CentOS 系统中，该二进制文件的名字是 qemu-kvm，并且是一个在 /usr/local/bin/qemu-kvm 指向 /usr/libexec/qemu-kvm 的软链接 等等 通常情况下，我们不管是通过 virt-manager 程序创建的虚拟机、还是使用 Libvirt 工具包创建的虚拟机，本质上，都是调用的 qemu-img、qemu-system-x86_64 等工具。
如果用容器比较的话
qemu-img 像各种容器镜像管理工具 qemu-system-x86_64 像 runc qemu-img qemu-img
qemu-system qemu-system</description></item><item><title>Label and Selector(标签和选择器)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/Label-and-Selector%E6%A0%87%E7%AD%BE%E5%92%8C%E9%80%89%E6%8B%A9%E5%99%A8/Label-and-Selector%E6%A0%87%E7%AD%BE%E5%92%8C%E9%80%89%E6%8B%A9%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/Label-and-Selector%E6%A0%87%E7%AD%BE%E5%92%8C%E9%80%89%E6%8B%A9%E5%99%A8/Label-and-Selector%E6%A0%87%E7%AD%BE%E5%92%8C%E9%80%89%E6%8B%A9%E5%99%A8/</guid><description>概述 参考：
官方文档，概念-使用 Kubernetes 对象-标签和选择器 官方文档，概念-使用 Kubernetes 对象-推荐的标签 官方文档，参考-常见的内置标签、注释、污点 官方文档，参考-Kubernets API-通用定义-标签选择器 官方文档，参考-Kubernets API-通用定义-节点选择器请求 Label(标签) 是 键/值对 的集合，在 Kubernetes 中，每一个对象都可以具有一个或多个 Label(标签)。Label 主要用来让用户定义对象的属性，以便为所有对象进行分类，并且还可以组织和选择对象的子集。标签可以在创建对象的同时添加，也可以随时修改对象上的标签。
Kubernetes 中的 Label 功能与 时间序列数据 中标签功能有异曲同工之妙，说白了，就是用来描述一个东西的。而且通过 Label，我们可以以松耦合的方式将我们自己想要的组织方式组织集群中的 Pod，而并不需要自己维护这些。
Kubernetes 中标签概念的重要性不亚于 API 资源和对象的概念。Pod 要运行在哪个 Node 上、下文将会提到的标签选择器，以及 Kubernetes 的调度系统等等等等，想要实现这些功能，都要依赖于标签。
标签 是键值对。有效的标签键有两个段：可选的前缀和名称，用斜杠 / 分隔。 名称段是必需的，必须小于等于 63 个字符，以字母数字字符（[a-z0-9A-Z]）开头和结尾， 带有破折号 -，下划线 _，点 . 和之间的字母数字。 前缀是可选的。如果指定，前缀必须是 DNS 子域：由点 . 分隔的一系列 DNS 标签，总共不超过 253 个字符， 后跟斜杠 /。
如果省略前缀，则假定标签键对用户是私有的。 向最终用户对象添加标签的自动系统组件（例如 kube-scheduler、kube-controller-manager、 kube-apiserver、kubectl 或其他第三方自动化工具）必须指定前缀。
有效标签值：
必须为 63 个字符或更少（可以为空） 除非标签值为空，必须以字母数字字符（[a-z0-9A-Z]）开头和结尾 包含破折号 -、下划线 _、点 .</description></item><item><title>Libvirt</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt/</guid><description>概述 参考：
GitHub 组织，libvirt 官网 Libvirt 项目是用于管理虚拟化平台的工具包，包括开源的 API，后台程序和管理工具。它可以用于管理 KVM、Xen、VMware ESX，QEMU 和其他虚拟化技术。Libvirt 将虚拟机统一称为 Domain。
Libvirt 提供了管理虚拟机和其它虚拟化功能（如：存储和网络接口等）的便利途径。这些软件包括：一个长期稳定的 C 语言 API、一个守护进程（libvirtd）和一个命令行工具（virsh）。Libvirt 的主要目标是提供一个单一途径以管理不同类型的虚拟化环境(也称为 drivers 或者 hypervisors )，包括：KVM/QEMU，Xen，VMware， VirtualBox hypervisors，LXC，OpenVZ
Libvirt 包含 3 个东西：
Libvirt API # API 库使得其他人可以开发基于 Libvirt 的高级工具，比如 virt-manager、virt-install、virt-viewer 等。 Driver # 虚拟化平台的驱动程序，暴露了 Libvirt API。由驱动程序对接各种不同的虚拟化平台的 Hypervisor 以管理虚拟化环境。 libvirtd # libvirtd 是一个集合了多种驱动程序守护进程，暴露了 Libvirt API，可以接收和处理客户端发送的请求 Client APP # 客户端应用程序，典型的代表是 virsh virsh # 使用 Libvirt API 编写的客户端程序，用来连接 Driver 后发送命令以控制虚拟化环境。 Note：其实 libvirtd 在绝大部分情况下是与 qemu/kvm 相搭配来使用，都是开源的，并且 redhat 官方推荐的也是使用 libvirt 管理 kvm 虚拟机</description></item><item><title>Libvirt API</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/Libvirt-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/Libvirt-API/</guid><description>概述 参考：
官网，API 参考 官网，使用 libvirt 的应用程序 在官方的 API 参考中，包含所有 C 语言表示的 API 信息，这些 API 分为如下几类：
common # libvirt 和 libvirt-admin 库的常用宏和枚举 domain # 用于管理 Domain 的 API domain checkpoint # 用于管理 Domain 检查点的 API domain snapshot # 用于管理 Domain 快照的 API error event host # 用于管理主机的 API interface network node device network filter secret storage stream and admin QEMU LXC libs 在我们使用非 C 代码，比如 Python、Go 的时候，如果想要找到 API 的说明，可以参考官方的 C 语言的 API 文档，函数名基本差不多，用一个最常见的“列出所有 Domain”举例：</description></item><item><title>Linux Kernel</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Linux-Kernel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Linux-Kernel/</guid><description>概述 参考：
Linus Torvalds GitHub 项目，torvalds/linux 官网 官方文档 https://www.infradead.org/~mchehab/kernel_docs/index.html 这是哪里的官方文档？ 官方 Manual(手册) LWN.net 是一个由读者支持的新闻网站，致力于在 Linux 和 自由软件开发社区 中提供最佳报道。 Wiki, Kernel Wiki, /boot Wiki, vmlinux Wiki, Initial ramdisk Wiki, System.map 树莓派 Linux RedHat 官方文档，8 - 管理、监控和更新内核 http://www.linfo.org/vmlinuz.html 知乎，initrd 和 initramfs 的区别 Kernel(内核) 是一个作为操作系统核心的计算机程序，对系统中的一切具有完全控制权。它负责管理系统的进程、内存、设备驱动程序、文件和网络系统，决定着系统的性能和稳定性。
Kernel 是计算器启动时首先加载程序之一，在 Bootloader并处理硬件和软件之间的交互。并且处理启动过程的其余部分、以及内存、外设、和来自软件的输入/输出请求，将他们转换为 CPU 的数据处理指令。
Kernel 组成及系统调用 Linux 内核由如下几部分组成：内存管理、进程管理、设备驱动程序管理、文件系统管理、网络管理等。如图：
System Call Interface(系统调用接口，简称 SCI) 层提供了某些机制执行从用户空间到内核的函数调用。这个接口依赖于体系结构，甚至在相同的处理器家族内也是如此。SCI 实际上是一个非常有用的函数调用多路复用和多路分解服务。
系统调用介绍详见 System Call(系统调用) 章节
Linux Manual 使用说明 Linux 的 Manual(man 手册) 来自于 Linux man-pages project 项目，该项目的 HTML 渲染结果可以在 man7.</description></item><item><title>Linux 管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
GNU Manual(手册) — Linux 中很多核心程序，都是 GNU 组织下的软件。 系统管理员可以通过 一系列用户空间的二进制应用程序来管理 Linux 操作系统。Linux 内核自带了一个名为 coreutils 包，包含了很多最基本的管理工具。
除了 Coreutils 包，还有很多很多的应用程序，一起组成了一套工具栈，系统管理员可以根据自身的需求，有选择得安装并使用它们。
Coreutils 参考：
Wiki, GNU Core Utilies 官方文档 GNU Core Utilities 是 GNU/Linux 操作系统的基本文件、Shell、文本操作的实用程序。同时，也是现在绝大部分 Linux 发行版内置的实用程序。
Coreutils 通常可以通过各种 Linux 发行版的包管理器直接安装。
root@desistdaydream:~/downloads# apt-cache show coreutils Package: coreutils Architecture: amd64 Version: 8.30-3ubuntu2 Multi-Arch: foreign Priority: required Essential: yes Section: utils Origin: Ubuntu Maintainer: Ubuntu Developers &amp;lt;ubuntu-devel-discuss@lists.ubuntu.com&amp;gt; Original-Maintainer: Michael Stone &amp;lt;mstone@debian.org&amp;gt; Bugs: https://bugs.launchpad.net/ubuntu/+filebug Installed-Size: 7196 Pre-Depends: libacl1 (&amp;gt;= 2.</description></item><item><title>Linux 管理案例</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description>重置 Linux 的 root 密码 进入紧急模式 详见 紧急模式或救援模式
修改密码 切换到原系统执行：chroot /sysroot/ 更改 root 密码：passwd root 在/目录下创建一个.autorelabel 文件，而有这个文件存在，系统在重启时就会对整个文件系统进行 relabeling touch /.autorelabel exit reboot 修改网卡名 centos 系统
vi /etc/default/grub GRUB_CMDLINE_LINUX=&amp;ldquo;net.ifnames=0 biosdevname=0 crashkernel=auto rd.lvm.lv=myvg/root rd.lvm.lv=myvg/swap rhgb quiet&amp;rdquo; 注意，标红位置改为自己的 lvm 中 volume group 的名字 主要就是添加紫色内容的字符串 grub2-mkconfig -o /boot/grub2/grub.cfg mv /etc/sysconfig/network-scripts/ifcfg-ens33 /etc/sysconfig/network-scripts/ifcfg-eth0 sed -i &amp;ldquo;s/ens33/eth0/g&amp;rdquo; /etc/sysconfig/network-scripts/ifcfg-eth0 ubuntu 系统
修改 grub 文件 vim /etc/default/grub 查找 GRUB_CMDLINE_LINUX=&amp;quot;&amp;quot; 修改为 GRUB_CMDLINE_LINUX=&amp;ldquo;net.ifnames=0 biosdevname=0&amp;rdquo; 重新生成 grub 引导配置文件 grub-mkconfig -o /boot/grub/grub.cfg 修改网络配置 ens32 为 eth0 vim /etc/netplan/01-netcfg.</description></item><item><title>Linux 图形处理</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/</guid><description>概述 参考：
Xorg, X11, Wayland? Linux Display Servers And Protocols Explained 原文链接：https://linuxiac.com/xorg-x11-wayland-linux-display-servers-and-protocols-explained/
Have you ever wondered what exactly X server, Xorg, X11, Wayland and stuff like that does? Wayland vs Xorg, what is better? This guide is for you. You always stumble upon those terms, and know they have something to do regarding the graphics, but you’d like to know more.
What is display server in Linux? A display server is a program whose primary task is to coordinate the input and output of its clients to and from the rest of the operating system, the hardware, and each other.</description></item><item><title>Linux 网络流量控制</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/</guid><description>概述 参考：
Wiki, Network Traffic Control arthurchiao.art 的文章： 连接跟踪（conntrack）：原理、应用及 Linux 内核实现 [译] 《Linux 高级路由与流量控制手册（2012）》第九章：用 tc qdisc 管理 Linux 网络带宽 《Linux 高级路由与流量控制手册（2003）》 中文翻译 在计算机网络中，Traffic Control(流量控制，简称 TC) 系统可以让服务器，像路由器一样工作，这也是 SDN(软件定义网路) 中重要的组成部分。通过精准的流量控制，可以让服务器减少拥塞、延迟、数据包丢失；实现 NAT 功能、控制带宽、阻止入侵；等等等等。
Traffic Control(流量控制) 在不同的语境中有不同的含义，可以表示一整套完整功能的系统、也可以表示为一种处理网络数据包的行为
背景 众所周知，在互联网诞生之初都是各个高校和科研机构相互通讯，并没有网络流量控制方面的考虑和设计，TCP/IP 协议的原则是尽可能好地为所有数据流服务，不同的数据流之间是平等的。然而多年的实践表明，这种原则并不是最理想的，有些数据流应该得到特别的照顾， 比如，远程登录的交互数据流应该比数据下载有更高的优先级。
针对不同的数据流采取不同的策略，这种可能性是存在的。并且，随着研究的发展和深入， 人们已经提出了各种不同的管理模式。IETF 已经发布了几个标准， 如综合服务(Integrated Services)、区分服务(Diferentiated Services)等。其实，Linux 内核从 2 2 开始，就已经实现了相关的 Traffic Control(流量控制) 功能。
实际上，流量控制系统可以想象成 Message Queue(消息队列) 的功能。都是为了解决数据量瞬间太大导致处理不过来的问题。
Traffic Control 的实现 想要实现 Traffic Control(流量控制) 系统，通常需要以下功能中的一个或多个：
Queuing(队列) # 每个进出服务器的数据包，都排好队逐一处理。 Hook(钩子) # 也可以称为DataPath。用于拦截进出服务器的每个数据包，并对数据包进行处理。 每种实现流量控制的程序，在内核中添加的 Hook 的功能各不相同，Hook 的先后顺序也各不相同，甚至可以多个 Traffic Control 共存，然后在各自的 Hook 上处理数据包 Connection Tracking(连接跟踪) # 每个被拦截到的数据包，都需要记录其信息以跟踪他们。 通过对数据包进行 Queuing(排队)，我们可以决定数据的发送方式。我们只能对发送的数据进行整形。</description></item><item><title>Linux 网络设备</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/</guid><description>概述 参考：
Linux 内核文档，管理员指南 - ABI -sysfs-class-net Manual(手册)，netdevice(7) 脚注在文末
Linux 网络设备归属于 PCI 总线类型。
关联文件 sysfs 中的网络设备信息 每个网络设备，都会在 sysfs 中注册（主要是与 PCI 相关），有一系列文件用来描述或定义这些网络设备。
在 /sys/class/net/${NetDeviceName}/ 目录下可以找到已在内核注册的关于网络设备的信息
Note: ${NetDeviceName} 是指向 /sys/devices/pciXXX/XXX/.../XXX/${NetDeviceName}/ 的 Symbolic link
./type # 网络设备的类型。文件内容是 10 进制数字。从 if_arp.h1 代码中（stackoverflow 也有相关问题）找到数字对应的设备类型表和该设备的定义（e.g. 1 表示 ARPHRD_ETHER），这个 C 的头文件将网络设备分为如下几大块
ARP 协议硬件定义 # ARP 的 RFC 标准中，定义了这些，并且 IANA2 中也维护了这些注册信息。 比如 #define ARPHRD_ETHER 1 这行代码意味着，type 文件的内容为 1 的话，表示该网络设备是 ARPHRD_ETHER（也就是常见的网卡设备） 非 ARP 硬件的虚拟网络设备 # Linux 自身实现的一些虚拟网络设备 TODO: 其他信息待整理 .</description></item><item><title>Linux 网络栈管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
Kernel 文档-Linux Networking Documentation Kernel 文档-Linux Networking and Network Devices APIs arthurchiao.art 的文章 [译] Linux 网络栈监控和调优：接收数据（2016） [译] Linux 网络栈监控和调优：发送数据（2017） 和磁盘设备类似，Linux 用户想要使用网络功能，不能通过直接操作硬件完成，而需要直接或间接的操作一个 Linux 为我们抽象出来的设备，即通用的 Linux 网络设备来完成。一个常见的情况是，系统里装有一个硬件网卡，Linux 会在系统里为其生成一个网络设备实例，如 eth0，用户需要对 eth0 发出命令以配置或使用它了。更多的硬件会带来更多的设备实例，虚拟的硬件也会带来更多的设备实例。
网卡本身并不会连接连接任何网络，网卡需要相应的配置文件来告诉他们如何实现网络连接。而让网卡与配置文件关联的过程，就是 network.service 这类服务来实现的
在 Linux Kernel 中，一般使用“网络设备”这种称呼，来描述硬件物理网卡设备在系统中的实例。在不同的语境中，有时也简称为 “设备”、“DEV” 等等。网络设备可以是一块真实机器上的网卡，也可以是创建的虚拟的网卡。
而网络设备与网卡之间如何建立关系，就是网卡驱动程序的工作了，不同的网卡，驱动不一样，可以实现的功能也各有千秋。所以，想要系统出现 eth0 这种网络设备，网卡驱动程序是必须存在的，否则，没有驱动，也就无法识别硬件，无法识别硬件，在系统中也就不知道如何操作这个硬件。
常见术语 DataPath(数据路径) 网络数据在内核中进行网络传输时，所经过的所有点组合起来，称为数据路径。
Socket Buffer(简称 sk_buff 或 skb) 在内核代码中是一个名为 sk_buff 的结构体。内核显然需要一个数据结构来储存报文的信息。这就是 skb 的作用。
sk_buff 结构自身并不存储报文内容，它通过多个指针指向真正的报文内存空间:
sk_buff 是一个贯穿整个协议栈层次的结构，在各层间传递时，内核只需要调整 sk_buff 中的指针位置就行。
DEVICE(设备) 在内核代码中，是一个名为 net_device 的结构体。一个巨大的数据结构，描述一个网络设备的所有 属性、数据 等信息。
Linux 网络功能的实现 数据包的 Transmit(发送) 与 Receive(接收) 过程概览 Receive(接收) 过程 本文将拿 Intel I350 网卡的 igb 驱动作为参考，网卡的 data sheet 这里可以下 载 PDF （警告：文件很大）。 从比较高的层次看，一个数据包从被网卡接收到进入 socket 接收队列的整个过程如下：</description></item><item><title>Linux 文本处理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/</guid><description>概述 参考：
文本处理三剑客：
grep sed awk cat - 用于把标准输入的内容输出到屏幕上 Note: 如果标准输入的内容是一个文件，那么就把文件中的内容当作标准输入发送给 cat 命令，然后再输出到屏幕上
执行完 cat 命令后，屏幕上会等待我输入内容，当我输入完成按回车后，会在屏幕上输出同样的内容，这就是 cat 最基本的作用，效果如下图，第一行是我主动输入的，按下回车后，自动输出内容
~]$ cat 我在标准输入上输入了一些内容，按下回车后，输入的内容原样输出出来 我在标准输入上输入了一些内容，按下回车后，输入的内容原样输出出来 Syntax(语法) cat [OPTIONS] [FILE]
OPTIONS
-A, &amp;ndash;show-all # 与 -vET 选项的效果相同 -b, &amp;ndash;number-nonblank # number nonempty output lines, overrides -n -e # 与 -vE 选项的效果相同 -E, &amp;ndash;show-ends # 在每行末尾显示 $。 -n, &amp;ndash;number # 显示行号。 -s, &amp;ndash;squeeze-blank # suppress repeated empty output lines -t # 等价于 -vT -T, &amp;ndash;show-tabs # 将 TAB 字符显示为 ^|。TAB 字符就是按下键盘 TAB 键产生的内容，是一个制表符。也就是说将空白的制表符以 ^| 形式显示 -u (ignored) -v, &amp;ndash;show-nonprinting # 常用于查看该文件的换行符是否是 windows 下的 ^M。use ^ and M- notation, except for LFD and TAB EXAMPLE</description></item><item><title>Linux 硬件管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
dmidecode
lshw 详见 lshw
lspci 详见: lspci
smartctl smartctl -a /dev/sda
网卡 mii-tool USB 管理工具 usbutils 参考：
GitHub 项目，gregkh/usbutils 官网 Manual(手册)，lsusb(8) 适用于 Linux 的 USB 实用程序，包括 lsusb。这是在 Linux 和 BSD 系统上使用的 USB 工具的集合，用于查询连接到系统的 USB 设备类型。这将在 USB 主机 (即您插入USB设备的机器) 上运行，而不是在 USB 设备 (即您插入USB主机的设备) 上运行。
包括如下几个工具
lsusb usb-devices usbhid-dump usbreset lsusb Syntax(语法) 列出系统上的USB总线和USB设备的详细信息。在输出中，您将看到USB控制器的制造商、型号和当前的状态。
sudo lshw -class bus -class usb 只查看有关USB设备的更详细信息
lshw -class usb 从文件中获取 Linux 硬件信息获取 参考：
jouyouyun 博客， Linux 硬件信息获取 在 linux 上可以通过 dmidecode 或是 lshw 来获取硬件信息，能够方便的查看系统配置。但它们的输出信息过多，解析起来有些麻烦，另外 lshw 对 usb 接口的网卡支持不好，显示的信息不够，所以在此整理下通过读文件或是一些简单命令来获取硬件信息的方法。</description></item><item><title>Linux 源码解析</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Linux-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Linux-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</guid><description>概述 参考：
源码快查网站 公众号，仅8670行代码，Linux内核第一版 (v0.01) 开源代码解读
原文: https://seiya.me/blog/reading-linux-v0.01</description></item><item><title>LogQL</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/LogQL/LogQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/LogQL/LogQL/</guid><description>概述 参考：
官方文档，查询 公众号，Loki 查询语言 LogQL 使用 Log Query Language(日志查询语言，简称 LogQL) 受 PromQL 启发，可以看作是分布式的 grep 命令，用来从汇总的日志源筛选日志。LogQL 通过 Labels(标签) 和 Operators(运算符) 进行过滤。
LogQL 查询有两种类型：
Log Queries(日志查询) # 根据查询语句返回日志条目，每行是一条日志。 Metric Queries(指标查询) # 用于扩展日志查询并根据 Log Queries 中的日志计数计算值。通过这种查询语句，可以计算将日志数据量化成指标信息，并且，Promtail 可以通过这种查询语句将指标信息，填充到自己暴露的 Metrics 端点中。 注意：由于 Loki 的设计，所有 LogQL 查询都必须包含一个 Log Queries 中的 日志流选择器
日志流选择器确定将搜索多少日志流（日志内容的唯一来源，例如文件）。然后，更细粒度的日志流选择器将搜索到的流的数量减少到可管理的数量。这意味着传递给日志流选择器的标签将影响查询执行的相对性能。然后使用过滤器表达式对来自匹配日志流的聚合日志进行分布式 grep。
Log Queries(日志查询) 详见 Log Queries
Metric Queries(指标查询) 详见 Metric Queries</description></item><item><title>Loki</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki/</guid><description>概述 参考：
GitHub 项目，grafana/loki 官方文档，基础 - 概述 Loki 是受 Prometheus 启发的水平可扩展，高度可用的多租户日志聚合系统。它的设计具有很高的成本效益，并且易于操作。它不索引日志的内容，而是为每个日志流设置一组标签。 与其他日志聚合系统相比，Loki 有以下特点：
不对日志进行全文本索引。通过存储压缩的，非结构化的日志以及仅索引元数据，Loki 更加易于操作且运行成本更低。 使用与 Prometheus 相同的标签对日志流进行索引和分组，从而使您能够使用与 Prometheus 相同的标签在指标和日志之间无缝切换。 特别适合存储 Kubernetes Pod 日志。诸如 Pod 标签之类的元数据会自动被抓取并建立索引。 在 Grafana 中具有本机支持（需要 Grafana v6.0）。 基于 Loki 的日志包含 3 个程序：
Loki 是主服务器，负责存储日志和处理查询。 Client Agent 客户端代理，负责收集日志并将其发送给 Loki。promtail 是其中一种 agent，是 loki 原配。 Grafana 用于查询和显示日志。 Loki 像 Prometheus 一样，但是是用于处理日志的：我们更喜欢基于多维标签的索引方法，并且希望使用没有依赖关系的单一二进制，易于操作的系统。Loki 与 Prometheus 的不同之处在于，它侧重于日志而不是指标，并通过推送而不是拉取交付日志。
Loki 与 Promtail 加一起才相当于 Prometheus，因为 Promtail 是发现目标，采集日志的程序。然后主动 Push 给 Loki，由 Loki 存储日志数据。 而 Promtheus，可以自己发现目标，采集指标，存储指标。
Loki Observability(可观察性) 参考：</description></item><item><title>LVS</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/LVS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/LVS/</guid><description>概述 参考：
Wiki, LVS Wiki, IPVS 官网 官网,中文 官方文档，HOWTO Linux Virtual Server(Linux 虚拟服务器，简称 LVC) 是一个可以实现虚拟的服务器集群功能的项目，用于实现负载均衡的软件技术。一般情况下，LVS 代之一组服务器，对于外部客户端来说，这似乎是一台服务器，所以，也称为 。
目前，LVS 项目已经被集成到 Linux 内核中，并通过 IPVS模块实现。LVS 具有良好的可靠性、可扩展性和可操作性，加上其实现最优的集群服务性能所需的低廉成本， LVS 的负载均衡功能经常被用于高性能、高可用的服务器群集中。
LVS 项目在 1998 年 5 月由章文嵩博士成立，是中国国内最早出现的自由软件项目之一。在 linux2.2 内核时，IPVS 就已经以内核补丁的形式出现。从 2.4 版本以后 IPVS 已经成为 Linux 内核官方标准内核的一部分
名词解释 调度器的称呼：scheduler，director，dispatcher，balancer
Director(指挥器) # 运行 IPVS 的节点。
IPVS(IP 虚拟服务) # 实现调度功能的程序。是一个 Linux 内核模块。实际上，IPVS 就是一个 Schedulers(调度器)。 Forwarding Method(转发方法) # Forwarding Method 用来确定 Director 如何将数据包从客户端转发到 Real Servers。如果把 Director 比做路由器，其转发数据包的规则与普通路由器有所不同。 Forwarding Method 其实就是指 LVS 的工作模式，当前有 LVS-NAT、LVS-DR、LVS-TUN 这几种。 ipvsadm # 为 IPVS 程序配置调度规则的用户端应用程序。 Real Server(真实服务器，简称 RS) # 处理来自客户端请求的节点</description></item><item><title>Memory</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory/</guid><description>概述 参考：
Linux Kernel 文档，子系统 - 内存管理文档 Linux Kernel 文档，管理员指南 - 内存管理 《操作系统导论》 公众号-小林coding，真棒！ 20 张图揭开内存管理的迷雾，瞬间豁然开朗 该文是对《操作系统导论》一书中内存部分的提炼与总结。 公众号-码农的荒岛求生，神秘！申请内存时底层发生了什么？(malloc 简介) Linux Memory Management Subsystem(Linux 内存管理子系统) 负责管理系统中的内存。这包括 virtual memory(虚拟内存) 和 demand paging(请求分页) 的实现、Linux Kernel内部结构和用户空间程序的内存分配、将文件映射到进程地址空间、etc.
Linux 内存管理是一个非常复杂系统，有很多可以配置的设置，这些设置可以通过 proc 修改，还可以使用 sysctl 程序进行查询和调整，具体参数详见 Kernel 参数中的 vm(内存相关参数)。
基础概念 Linux 中的内存管理是一个经过多年发展的复杂系统，包含越来越多的功能来支持从 微控制器(nommu) 到 超级计算机 的各种系统，下面是一些常见的内存管理中的概念和术语
没有 Memory management unit(内存管理单元，简称 MMU) 的系统的内存管理称为 nommu，它绝对值得一个专门的文档。然而，随着时代的发展，nommu 的系统或设备已经基本不存在了，这里我们假设 MMU 可用并且 CPU 可以将虚拟地址转换为物理地址。
Virtual Memory(虚拟内存) Huge Pages(大页) # Huge Pages 是一种解决 Page table 过大、TLB 未命中过多、etc.</description></item><item><title>Method AND Interface</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/Method-AND-Interface/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/Method-AND-Interface/</guid><description>概述 参考：
公众号-新亮笔记，回答连个被频繁问道的代码写法问题 1.强制检查类型是否实现接口 2.强制接口中所有方法只能在本包中实现 Method 与 Interface 是 Go 语言是想面向对象编程的一种解决方式，但是更轻量。
Go 是面向对象的编程语言吗？
官方 FAQ 给出了标准答案: Yes and No。
当然，Go 有面向对象编程的类型和方法的概念，但是它没有继承(hierarchy)一说。Go 语言的接口实现和其它的编程语言不一样，Go 开发者的初衷就是保证它易于使用，用途更广泛。
还有一种“模拟”产生子类的方法，拿就是通过在类型中嵌入其它的类型，但是这是一种“组合”的方式，而不是继承。
没有了继承， Go 语言的对象变得比 C++和 Java 中更轻量级。
在 Go 语言中，接口定义了一套方法的集合，任何实现这些方法的对象都可以被认为实现了这个接口，这也称作 Duck Type。这不像其它语言比如 java 需要预先声明类型实现了某个或者某些接口，这使得 Go 接口和类型变得很轻量级，它解耦了接口和具体实现的硬绑定。显然这是 Go 的开发者深思熟虑的一个决定。
if something looks like a duck, swims like a duck and quacks like a duck then it’s probably a duck.
因为没有继承，你也只能通过 Go 接口实现面向对象编程的多态。本身 Go 接口在内部实现上也是一个(其实是两种,其中一种专门处理 interface{})结构体，它的虚函数指向具体的类型的实现。在编译代码的时候，Go 编译器还会做优化，不需要接口的时候，它会使用具体的方法来代替接口使用，这样进一步优化性能，这叫做 devirtualize 调用。</description></item><item><title>Microsoft Management Console</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Microsoft-Management-Console/Microsoft-Management-Console/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Microsoft-Management-Console/Microsoft-Management-Console/</guid><description>概述 参考：
Wiki, Microsoft Management Console Microsoft Management Console(微软管理控制台，简称 MMC) 是 Microsoft Windows 的一个组件，它为系统管理员和高级用户提供了一个用于配置和监控系统的界面。它于 1998 年首次与 Windows NT 4.0 的 Option Pack 一起推出，后来与 Windows 2000 及其后续版本预捆绑在一起。
MSC https://jingyan.baidu.com/article/7e440953dcc56e6ec1e2ef17.html
MSC(Microsoft Snap-In Control) 是 MMC(Microsoft Management Console) 用来添加/删除的嵌入式管理单元文件。通常通过 MMC 来管理，可点击“文件”菜单中的“添加/删除管理单元”操作来管理当前系统中已经安装的 MSC 文件。可以点击开始/运行，然后输入下列文件名就可以打开相应的控制窗口。
这些文件通常都以 .msc 为后缀。
除第三个文件外，其他均在 C:\WINDOWS\system32 文件夹下
certmgr.msc 作用：系统认证证书编辑。 ciadv.msc 作用：索引服务，链接文件*:\System Volume Information comexp.msc 所在文件夹：C:\WINDOWS\system32\Com 作用：组件服务，可以打开本地服务。 compmgmt.msc 作用：本地计算机硬件和服务管理，功能很强大。 devmgmt.msc 作用：设备管理器 dfrg.msc 作用：磁盘碎片整理程序 diskmgmt.msc 作用：磁盘管理器，可以修改盘符，格式化和分区等。 eventvwr.msc 作用：事件查看器 fsmgmt.msc 作用：共享文件夹管理 gpedit.msc 作用：组策略管理器，功能强大。TODO: 家庭版没有咋办？ lusrmgr.</description></item><item><title>Microsoft OS</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Microsoft-OS/Microsoft-OS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Microsoft-OS/Microsoft-OS/</guid><description>概述 参考 Microsoft OS 也是 Operating system(操作系统)
DOS 系统 Windows 系统 学习资料 官方学习
培训 认证 文档</description></item><item><title>MinIO</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/MinIO/MinIO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/MinIO/MinIO/</guid><description>概述 参考：
官网 GitHub 项目，minio/minio https://mp.weixin.qq.com/s/aRTE_UUQ0GMXhqiemxQnsg 采集指标
curl -H &amp;#34;Authorization: Bearer ${TOKEN}&amp;#34; http://localhost:9000/minio/v2/metrics/cluster Notes: TOKEN 通过 mc admin prometheus generate ${REMOTE} 命令生成
MinIO 部署 参考：
官方文档，安装 docker 启动单点 MinIO docker run -p 9000:9000 \ -e &amp;#34;MINIO_ACCESS_KEY=minioadmin&amp;#34; \ -e &amp;#34;MINIO_SECRET_KEY=minioadmin&amp;#34; \ -v /mnt/disk1:/disk1 \ -v /mnt/disk2:/disk2 \ -v /mnt/disk3:/disk3 \ -v /mnt/disk4:/disk4 \ minio/minio server /disk{1...4} MINIO_ACCESS_KEY 与 MINIO_SECRET_KEY 指定连接 MinIO 时所需的认证信息，AK、SK
本地 /mnt 下的 4 个目录</description></item><item><title>Mobile device</title><link>https://desistdaydream.github.io/docs/Mobile-device/Mobile-device/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Mobile-device/Mobile-device/</guid><description>概述 参考：
Wiki, Mobile_device Mobile device(移动设备) 也称为 Handheld computer(掌上电脑) 是一种足够小的可以手持和操作的计算机
有的时候有称为 Digital assistant(数字助理，简称 DA)、Portable device(便携设备)，也是 Electronics(电子产品) 的一种。
Types 移动设备的类型有很多种，Cellphone(手机) 是一种典型 Modible device。
Mobile computers Tablet computer Netbook Digital media player Enterprise digital assistant (EDA) Graphing calculator Handheld game console Handheld PC Laptop Mobile Internet device (MID) Personal digital assistant (PDA) Pocket calculator Portable media player Ultra-mobile PC Mobile phones Camera phones Feature phones Smartphones Phablets Digital cameras Digital camcorder Digital still camera (DSC) Digital video camera (DVC) Front-facing camera Pagers Personal navigation device (PND) Wearable computers Calculator watch Smartwatch Smartglasses Head-mounted display Smart cards</description></item><item><title>Motherboard</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/Motherboard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/Motherboard/</guid><description>概述 参考：
Wiki, Motherboard Motherboard(主板) 是通用计算机和其他可扩展系统中的 Printed circuit board(印刷电路板，简称 PCB)。主板用于承载一套系统中许多关键电子组件之间的通信，例如 CPU、Memory，并为其他外围设备提供连接器。与 Backplane(背板) 不同，主板通常包含重要的子系统，例如中央处理器、芯片组的输入/输出和内存控制器、接口连接器以及其他为通用应用集成的组件。
主板还有很多其他英文单词：mainboard, main circuit board, mb, mboard, backplane board, base board, system board, logic board (only in Apple computers) or mobo
主板特指具有扩展能力的 PCB。顾名思义，这块板通常被称为连接到它的所有组件的“母板”，通常包括外围设备、接口卡和子板：声卡、视频卡、网卡、主机总线适配器、电视调谐器卡, IEEE 1394 卡；以及各种其他自定义组件。
类似地，术语主板是指具有单板且没有额外扩展或能力的设备，例如激光打印机、电视机、洗衣机、手机和其他扩展能力有限的嵌入式系统中的控制板。
USB Universal Serial Bus(通用串行总线，简称 USB) 是一种用于连接计算机和外部设备的通用接口标准。USB 接口已经成为现代电子设备中最为常用的接口之一，可用于连接键盘、鼠标、打印机、扫描仪、移动硬盘、闪存驱动器、智能手机等各种设备。</description></item><item><title>MySQL</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL/</guid><description>概述 参考：
官网 MySQL 的社区版本 MariaDB ，使用安装 MySQL 的 时候，会自动安装 MariaDB 。同时安装 mariadb-server ，即可开始使用了
MySQL 关联文件与配置 /etc/my.cnf # MariaDB 基础配置文件
/var/lib/myql/ # 数据存储路径
MySQL 数据类型 MySQL 中定义数据字段的类型对你数据库的优化是非常重要的。 MySQL 支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。
数值类型 MySQL 支持所有标准 SQL 数值数据类型。
这些类型包括严格数值数据类型(INTEGER、SMALLINT、DECIMAL 和 NUMERIC)，以及近似数值数据类型(FLOAT、REAL 和 DOUBLE PRECISION)。
关键字 INT 是 INTEGER 的同义词，关键字 DEC 是 DECIMAL 的同义词。
BIT 数据类型保存位字段值，并且支持 MyISAM、MEMORY、InnoDB 和 BDB 表。
作为 SQL 标准的扩展，MySQL 也支持整数类型 TINYINT、MEDIUMINT 和 BIGINT。下面的表显示了需要的每个整数类型的存储和范围。
类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 byte (-128，127) (0，255) 小整数值 SMALLINT 2 bytes (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 bytes (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT 或 INTEGER 4 bytes (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 bytes (-9,223,372,036,854,775,808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 FLOAT 4 bytes (-3.</description></item><item><title>NAT</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/NAT/NAT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/NAT/NAT/</guid><description>概述 参考：
Wiki, Network Address Translation RFC 4787 RFC 5382,TCP 的 NAT 行为要求 RFC 5508,ICMP 的 NAT 行为要求 Network address translation(网络地址转换，简称 NAT) 是一种通过修改数据包的 IP 报头中的网络地址信息，将一个 IP 地址空间重新映射到另一个 IP 地址空间的方法，同时它们在流量路由设备中传输。该技术最初用作快捷方式，以避免在移动网络时重新寻址每个主机。面对 IPv4 地址耗尽，它已成为保护全球地址空间的流行和必不可少的工具。NAT 网关的一个可互联网路由的 IP 地址可用于整个专用网络。
IP 伪装是一种隐藏整个 IP 地址空间的技术，通常由私有 IP 地址组成，位于另一个 IP 地址的后面，通常是公共地址空间。必须隐藏的地址被更改为单个（公共）IP 地址作为传出 IP 数据包的“新”源地址，因此它看起来不是来自隐藏主机而是来自路由设备本身。由于这种技术的普及，以节省 IPv4 地址空间，术语 NAT 实际上已成为 IP 伪装的同义词。
由于网络地址转换修改了数据包中的 IP 地址信息，因此对 Internet 连接的质量产生严重影响，需要特别注意其实现的细节。NAT 实现在各种寻址情况下的特定行为及其对网络流量的影响方面差异很大。包含 NAT 实现的设备供应商通常不记录 NAT 行为的细节。
NAT 实现分类 NAT 按照 NAT 映射行为 和 有状态防火墙行为 可以分为多种类型</description></item><item><title>Net-SNMP</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/Net-SNMP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/Net-SNMP/</guid><description>概述 参考：
GitHub 项目，net-snmp/net-snmp/ 官网 [!Attention] 官网大量页面错误 Exception encountered, of type &amp;ldquo;mysqli_sql_exception&amp;rdquo;，e.g. https://www.net-snmp.org/wiki/,
Net-SNMP 是实现 SNMP(传统监控标准) 的工具和库的集合。包含如下内容：
net-snmp # SNMP 代理，用于采集设备的 SNMP 信息。包含两个守护程序。 net-snmp-utils # 是一组工具的集合，包括下面这些命令行工具： snmpwalk # 获取 SNMP 信息，可以根据 OID 获取指定 OID 的 SNMP 信息 snmptranslate # 转换 OID 的两种格式 encode_keychange、snmpbulkget、snmpbulkwalk、snmpdelta、snmpdf、snmpget、snmpgetnext、snmpinform、snmpnetstat、snmpset、snmpstatus、snmptable、snmptest、snmptls、snmptrap、snmpusm、snmpvacm net-snmp 是一种可以通过 snmp 协议来实现基础监控功能的守护程序。包含两个守护程序以及几个命令行工具
snmpd # 用于响应请求的 SNMP 代理。说白了提供 SNMP 数据的程序。监听一个端口(默认监听 161/udp)，当别人向 161 发送 SNMP 请求时，snmpd 会将采集到的数据发送给对方。 snmptrapd # 用于接收 SNMP 通知的通知接收器 agentxtrap # net-snmp-create-v3-user # 创建 v3 用户 snmpconf # 用于生成配置文件 Net-SNMP 安装 Net-SNMP 提供了各种安装文件，对于 Linux 系统来说，直接使用 yum、apt 等工具安装即可</description></item><item><title>net(网络相关参数)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</guid><description>概述 参考：
Manual(手册)，/proc/sys 部分 Linux Kernel 文档，管理员指南 - /proc/sys 文档 - /proc/sys/net 文档 官方文档，内核子系统文档-Networking-IP Sysctl 这里包含 net 下的 ipv4、ipv6、bridge 等相关参数，但是没有 netfilter 等的相关参数 /proc/sys/net/ 目录下通常包含下面的一个或多个子目录
目录名 用处 目录名 用处 802 E802 protocol mptcp Multipath TCP appletalk Appletalk protocol netfilter Network Filter ax25 AX25 netrom NET/ROM bridge Bridging rose X.25 PLP layer core General parameter tipc TIPC ethernet Ethernet protocol unix Unix domain sockets ipv4 IP version 4 x25 X.25 protocol ipv6 IP version 6 ipv4 参数 参考：</description></item><item><title>Netfilter</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/Netfilter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/Netfilter/</guid><description>概述 参考：
Netfilter 官网 Netfilter 官方文档 Wiki, Netfilter arthurchiao.art 的文章： [译] 深入理解 iptables 和 netfilter 架构 连接跟踪（conntrack）：原理、应用及 Linux 内核实现 [译] NAT - 网络地址转换（2016） Netfilter Netfilter 是 Linux 操作系统核心层内部的一个数据包处理模块集合的统称, 是一种流量控制系统。一种网络筛选系统，对数据包进入以及出去本机进行的一些控制与管理。该功能的所有模块可以通过下图所示的目录进行查找，其中还包括 ipvs 等。
~]# find /usr/lib/modules/$(uname -r)/kernel -name netfilter -exec realpath {} \; /usr/lib/modules/5.15.0-102-generic/kernel/net/bridge/netfilter /usr/lib/modules/5.15.0-102-generic/kernel/net/netfilter /usr/lib/modules/5.15.0-102-generic/kernel/net/ipv6/netfilter /usr/lib/modules/5.15.0-102-generic/kernel/net/ipv4/netfilter Netfilter 项目支持如下功能
网络地址转换(Network Address Translate) 数据包过滤 数据包日志记录 用户空间数据包队列 其他数据包处理 等等 Netfilter Hooks 是 Linux 内核中的一个框架，它会让 Netfilter 的模块在 Linux 网络堆栈的不同位置注册回调函数。然后，为遍历 Linux 网络堆栈中相应 Hook 的每个数据包调用已注册的回调函数。
用白话说：内核加入了 Netfilter 模块后，每个数据包进来之后，都会经过五个 Hooks 点来处理，以便决定每个数据包的走向。 Hooks hooks function(钩子函数) 是 Linux 网络栈中的流量检查点。所有流量通过网卡进入内核或从内核出去都会调用 Hook 函数来进行检查，并根据其规则进行过滤。Netfilter 框架中一共有 5 个 Hook，就是下文定义的“五链”。</description></item><item><title>Netplan</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Netplan/Netplan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Netplan/Netplan/</guid><description>概述 参考：
GitHub 项目，canonical/netplan 官网 Netplan 是一个网络配置抽象渲染器。属于 netplan.io 包，通过 yaml 文件来管理 Linux 的网络配置。
Netplan 是用于在 Linux 系统上轻松配置网络的实用程序。只需为每个网络设备应该具有的配置，创建一个 YAML 格式的描述文件。 Netplan 将根据此描述为指定的 Renderer(渲染器) 生成所有必要的配置。剩下的工作，就是由这些 Renderer 来处理配置，并配置网络了。
Netplan 的工作方式 Netplan 从 /etc/netplan/*.yaml 文件中读取配置信息。Netplan 启动初期，在 /run 目录中生成特定于后端的配置文件，以便让这些后端的网络守护程序根据这些配置文件管理网络设备。在 Netplan 中，这些特定的 后端被称为 Renderers(渲染器)。
Netplan 当前支持如下 Renderers(渲染器)：
networkd # 默认 Renderer。该 Renderers 是 systemd 管理的网络管理程序 systemd-networkd，它属于 systemd 包 Network Manager # 详见：NetworkManager 注意：殊途同归，就算是 systemd-networkd，同样是会在 d-bus 中保存信息的
~]# busctl get-property org.freedesktop.network1 /org/freedesktop/network1/network/_310_2dnetplan_2dens3 org.freedesktop.network1.Network MatchName as 1 &amp;#34;ens3&amp;#34; ~]# busctl get-property org.</description></item><item><title>Network analysis</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Network-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Network-analysis/</guid><description>概述 参考：
Network analysis(网络分析) 依赖很多基础的流量处理功能以组成完整的系统
Port mirroring # 流量镜像是网络分析的基础。没有端口镜像将流量镜像出来，那么所有的流量分析程序都要使用原始流量，这是绝对不可接受的。除了具体的流量封堵外，任何分析，都应该使用镜像出来的流量。 etc. 最佳实践 基于 DPI 的网络分析 在网络分析系统中，DPI 设备除了数据包的检查与处置外，通常还可能具有 Port mirroring(端口镜像)、Fiber-optic splitter、etc. 相关的流量复制能力，这些被 DPI 复制的流量将会送到 Network packet broker 设备中以进行聚合、过滤，然后再转发给后端的业务系统。这是一种常见的网络流量分析系统，拿到了流量就相当于有了数据，至于数据如何用，根据具体业务情况而定。
这些业务系统通常包括
僵木蠕监测与处置系统 流控系统 话单系统 流量深度分析系统 etc.</description></item><item><title>Network Virtualization</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/Network-Virtualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/Network-Virtualization/</guid><description>概述 参考：
Wiki, Network_virtualization 在传统网络环境中，一台物理主机包含一个或多个网卡（NIC），要实现与其他物理主机之间的通信，需要通过自身的 NIC 连接到外部的网络设施，如交换机上；为了对应用进行隔离，往往是将一个应用部署在一台物理设备上，这样会存在两个问题：
是某些应用大部分情况可能处于空闲状态， 是当应用增多的时 候，只能通过增加物理设备来解决扩展性问题。不管怎么样，这种架构都会对物理资源造成极大的浪费。 为了解决这个问题，可以借助虚拟化技术对一台物理资源进行抽象，将一张物理网卡虚拟成多张虚拟网卡（vNIC），通过虚拟机来隔离不同的应用。
针对问题 1），可以利用虚拟化层 Hypervisor 的调度技术，将资源从空闲的应用上调度到繁忙的应用上，达到资源的合理利用； 针对问题 2），可以根据物理设备的资源使用情况进行横向扩容，除非设备资源已经用尽，否则没有必要新增设备。 综上所述：SDN 主要是通过系统的功能，模拟出网络设备中的路由器，交换机，端口，网线等等，这些现实中的数通设备都可以通过软件来模拟实现
网络虚拟化的几种最基础模型：
隔离模型：在 host 上创建一个 vSwitch(bridge device)：每个 VM 的 TAP 设备直接添加至 vswitch 上，VM 通过 vSwitch 互相通信，与外界隔离 路由模型：基于隔离模型，在 vSwitch 添加一个端口，作为 host 上的虚拟网卡使用(就是 VMware workstation 中创建的那些虚拟网卡，其中的 IP 作为虚拟机的网关)，并打开 host 的核心转发功能，使数据从 VM 发送到 host；该模型数据包可以从 VM 上出去，但是外界无法回到 VM，如果想让外部访问 VM，需要添加 NAT 功能，变成 NAT 模型 NAT 模型：配置 Linux 自带的 NAT(可通过 iptables 定义)功能，所有 VM 的 IP 被 NAT 成物理网卡 IP，这是一种常用的虚拟网络模型 桥接模型：可以想象成把物理机网卡变成一台 vSwitch，然后给物理机创建一个虚拟网卡，虚拟机和物理机都连接到 vSwitch，相当于把虚拟机直接接入到网络中，从网络角度看，VM 相当于同网段的一台 host 隧道模型：VM 的数据包在经过某个具备隧道功能的虚拟网络设备时，可以在数据包外层再封装一层 IP，以 IP 套 IP 的隧道方式，与对方互通 网络虚拟化术语</description></item><item><title>Networking device</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Networking-device/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Networking-device/</guid><description>概述 参考：
Wiki, Networking hardware Networking device(网络设备) 也成为 Networking hardware(网络硬件) 是计算机网络上的设备之间进行通信和交互所需的电子设备。具体来说，它们调解计算机网络中的数据传输。最后接收或产生数据的单元称为主机、端系统或数据终端设备。
Router(路由器) 与 Switch(交换机) 是常见的基础网络设备。 ATCA 参考：
PICMG 官网，开放标准 - advancedtca Wiki, Advanced Telecommunications Computing Architecture Advanced Telecommunications Computing Architecture(高级的电信计算架构，简称 ATCA or AdvancedTCA) 是一系列 PICMG 规范，官方规范名称 PICMG 3.x 被称为 AdvancedTCA。
AdvancedTCA 是基于模块化结构的、兼容的、并可扩展的硬件构架。模块化体现在：只要符合 ATCA 标准研发出来的刀片，都可以插入到 ATCA 标准的机框中。AdvancedTCA 主要用于构建电信和网络设备，如基站控制器、传输设备、数据交换机等。它采用了模块化的设计理念，可以容纳多个处理器、存储设备、网络接口等功能模块，并提供了高速互联和热插拔功能，以支持系统的灵活性和可维护性。
随着时代的发展，ATCA 标准甚至将期范围扩展到面向军事/航空航天工业的更坚固的应用上。
大体上 ATCA 规范的硬件分为两部分
Shelf(机架、机框) Blade(刀片) Blade Blade(刀片) 是可以插入 Shelf 中的硬件，可以是处理器、交换机、AMC 托架、etc. 。一个典型的 ATCA 设备将包含一个或多个交换机刀片和多个处理器刀片。
Blade 也可以称为 Board(板卡)，常见的形容有 DPI 板、分流板、etc. 。
辅助材料 以太网双绞线 参考：</description></item><item><title>NetworkManager</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/NetworkManager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/NetworkManager/</guid><description>概述 参考：
GitHub 项目，NetworkManager/NetworkManager GitLab 项目，freedesktop-NetworkManager/NetworkManager Manual(手册),NetworkManager.conf(5) 官网 NetworkManager daemon 是管理网络的守护进程。该守护进程尝试通过管理主网络连接和其他网络接口（如以太网，WiFi 和移动宽带设备），使网络配置和操作尽可能轻松自动。 除非禁用该行为，否则 NetworkManager 将在该设备的连接可用时连接任何网络设备。 有关网络的信息通过 D-Bus 接口导出到任何感兴趣的应用程序，提供丰富的 API，用于检查和控制网络设置和操作。
Connection 参考：
Manual(手册),nm-settings-nmcli(5) Manual(手册),nm-settings-dbus(5) Manual(手册),nm-settings-keyfile(5) Manual(手册),nm-settings-ifcfg-rh(5) NetworkManager 将所有网络配置抽象成 Connection(连接)，这些 Connection 的配置中包含网络配置(比如 IP 地址、网关等)。当 NetworkManager 激活网络设备上的 Connection 时，将为这个网络设备应用配置文件中的内容，并建立活动的网络连接。所以，可以创建多个 Connection 来关联到一个网络设备上；这样，它们就可以灵活地具有用于不同网络需求的各种网络配置。
用白话说就是：Connection 就是“网络配置”，网络设备(device)关联并使用“网络配置”来实现联网。而 NetworkManager 就是管理这些 Connection 的。Connection 可以表示一个概念，也可以表示一个配置文件。
Connection 插件 NetworkManager 通过 Plugins(插件) 的方式来管理 Connection 配置文件。在不同的 Linux 发行版中，所使用的插件各不相同，但是默认情况下，NetworkManager 使始终启用名为 keyfile 的插件，这是一个通用插件，当其他插件无法支持某些类型的 Connection 配置时，keyfile 插件将会自动提供支持。keyfile 插件会将 Connection 文件保存到 /etc/NetworkManager/system-connections/、/usr/lib/NetworkManager/system-connections/、/run/NetworkManager/system-connections/ 这三个目录中。
可以在 /etc/NetworkManager/NetworkManager.conf 文件中配置想要使用的插件，插件用于读写系统范围的连接配置文件。当指定多个插件时，将从所有列出的插件中读取 Connections。写入 Connections 时，会要求插件按照此处列出的顺序保存连接；如果第一个插件无法写出该连接类型（或无法写出任何连接），则尝试下一个插件。如果没有插件可以保存连接，则会向用户返回错误。</description></item><item><title>Nginx</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx/</guid><description>概述 参考：
GitHub 项目，nginx/nginx 原始代码：https://hg.nginx.org/nginx/ org 官方网站 官方网站 官方网站,动态模块列表 Nginx 称为 Engine X，可以做为 Web 服务器、代理服务器、缓存服务器、负载均衡器 等来使用。
传统上基于进程或线程模型架构的 web 服务通过每进程或每线程处理并发连接请求，这势必会在网络和 I/O 操作时产生阻塞，其另一个必然结果则是对内存或 CPU 的利用率低下。生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用 CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。
在设计的最初阶段，nginx 的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，nginx 采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在 nginx 中，连接请求由为数不多的几个仅包含一个线程的进程 worker 以高效的回环(run-loop)机制进行处理，而每个 worker 可以并行处理数千个的并发连接及请求。
Nginx 会按需同时运行多个进程：一个主进程(master)和几个工作进程(worker)，配置了缓存时还会有缓存加载器进程(cache loader)和缓存管理器进程(cache manager)等。所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。主进程以 root 用户身份运行，而 worker、cache loader 和 cache manager 均应以非特权用户身份运行。
Nginx 特性：
模块化设计，较好的扩展性，所有配置均有指定的模块进行处理。 高可靠 master &amp;ndash;&amp;gt; worker，主控进程不接收和响应用户请求，主控进程负责解析配置文件并生成多个工作进程，工作进程来响应用户请求 主控进程读取并验证配置，创建或绑定套接字，启动及终止和维护 worker 进程的个数，无须重启进程让新配置的配置文件进行加载，以及完成平滑版本升级等等 工作进程，负责缓存加载的(反向代理时候用)，负责响应用户请求，cache manager 缓存管理 低内存消耗，10000 个 keep-alive 模式下的 connection，仅需 2.5MB 内存 支持热部署，不停机而更新配置文件，日志文件滚动，升级程序版本 支持事件驱动、AIO、mmap 基本功能：
静态资源的 web 服务器，能缓存打开的文件描述符 http、SMTP、pop3 协议的反向代理服务器 缓存加速、负载均衡 支持 FastCGI(fpm，LNMP)，uWSGI(Python)等 模块化(非 DSO 机制)、过滤器 zip、SSI 及图像的大小调整 支持 SSL(https) 扩展功能</description></item><item><title>Nginx 配置详解</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
org 官方文档，初学者指南-配置文件结构 org 官方文档，全部指令列表 org 官方文档，全部变量列表 官方文档，管理指南-基础功能-创建 NGINX 配置文件 Nginx 由 Modules(模块) 组成， Modules 由配置文件中的 Directives(指令) 控制其运行行为。有的 Directives 可以控制多个模块，只不过在控制不同模块时，产生的效果也许会不尽相同。
Directives(指令) Directives(指令) 分为如下几种：
Simple Directives(简单指令) Block Directives(块指令) Conexts(配置环境 | 上下文) Simple Directives(简单指令) 由空格分割的 Name(指令名称) 和 Parameters(指令参数)，以 ; 符号结尾。
如果从 Nginx 的代码角度看，指令就相当于结构体中的属性，参数就是该属性的值。 Block Directives(块指令) 将多个相关的简单指令组合在一起的容器，并将它们用 {} 符号包围起来。
Top Level Directives(顶级指令) - 也称为 Contexts(配置环境 | 上下文) 将多个相关的 块指令 和 简单指令 组合在一起的指令，也是使用 {} 符号将这些指令包围起来。一共分为 4 类 Contexts：
events {} # 用于配置如何处理常规连接。 http {} # http 流量处理配置，通常用来配置 7 层代理。由 ngx_http_core_module 模块处理其中配置 mail {} # mail 流量处理配置。由 ngx_mail_core_module 模块处理其中配置 stream {} # TCP 和 UDP 流量处理配置，通常用来配置 4 层代理。由 ngx_stream_core_module 模块处理其中配置 main # 如果某些指令在上述 4 类 Contexts 之外，则称之为 main Context。可以说，events{}、http{}、mail{}、stream{} 四个 Contexts，都属于 main 上下文中的指令。说白了，main 上下文就是 Nginx 的配置文件~其实，main 就是指最顶层的 core 模块指令</description></item><item><title>Nova</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Nova/Nova/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Nova/Nova/</guid><description>Nova 的子组件以及工作流程 Nova 的子组件
API
nova-api 接收和响应客户的 API 调用。 除了提供 OpenStack 自己的 API，nova-api 还支持 Amazon EC2 API。 也就是说，如果客户以前使用 Amazon EC2，并且用 EC2 的 API 开发了些工具来管理虚机，那么如果现在要换成 OpenStack，这些工具可以无缝迁移到 OpenStack，因为 nova-api 兼容 EC2 API，无需做任何修改。 Compute Core
nova-scheduler # 虚机调度服务，负责决定在哪个计算节点上运行虚机
nova-compute # 管理虚机的核心服务，通过调用 Hypervisor API 实现虚机生命周期管理
Hypervisor # 计算节点上跑的虚拟化管理程序，虚机管理最底层的程序。 不同虚拟化技术提供自己的 Hypervisor。 常用的 Hypervisor 有 KVM，Xen， VMWare 等
nova-conductor # nova-compute 经常需要更新数据库，比如更新虚机的状态。 出于安全性和伸缩性的考虑，nova-compute 并不会直接访问数据库，而是将这个任务委托给 nova-conductor，这个我们后面详细讨论。
Console Interface
nova-console 用户可以通过多种方式访问虚机的控制台：nova-novncproxy，基于 Web 浏览器的 VNC 访问 nova-spicehtml5proxy，基于 HTML5 浏览器的 SPICE 访问 nova-xvpnvncproxy，基于 Java 客户端的 VNC 访问</description></item><item><title>Object 管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/Object-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/Object-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
官方文档，概念-概述-使用 Kubernetes 对象-Kubernetes 对象管理 官方文档，任务-管理 Kubernetes 对象 公众号-k8s 技术圈，理解 K8s 中的 Client-Side Apply 和 Server-Side Apply 原文：掘金 使用 kubectl 等是传统的 Client-Side Apply(简称 CSA)，添加 &amp;ndash;server-side 标志后，为 Server-Side Apply(简称 SSA)。
如果你经常与 kubectl 打交道，那相信你一定见过 kubectl.kubernetes.io/last-applied-configuration annotation，以及那神烦的 managedFields，像这样：
$ kubectl get pods hello -oyaml apiVersion: v1 kind: Pod metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {&amp;#34;apiVersion&amp;#34;:&amp;#34;v1&amp;#34;,&amp;#34;kind&amp;#34;:&amp;#34;Pod&amp;#34;,&amp;#34;metadata&amp;#34;:{&amp;#34;annotations&amp;#34;:{},&amp;#34;creationTimestamp&amp;#34;:null,&amp;#34;labels&amp;#34;:{&amp;#34;run&amp;#34;:&amp;#34;hello&amp;#34;},&amp;#34;name&amp;#34;:&amp;#34;hello&amp;#34;,&amp;#34;namespace&amp;#34;:&amp;#34;default&amp;#34;},&amp;#34;spec&amp;#34;:{&amp;#34;containers&amp;#34;:[{&amp;#34;image&amp;#34;:&amp;#34;nginx&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;hello&amp;#34;,&amp;#34;resources&amp;#34;:{}}],&amp;#34;dnsPolicy&amp;#34;:&amp;#34;ClusterFirst&amp;#34;,&amp;#34;restartPolicy&amp;#34;:&amp;#34;Always&amp;#34;},&amp;#34;status&amp;#34;:{}} creationTimestamp: &amp;#34;2022-05-28T07:28:51Z&amp;#34; labels: run: hello managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:metadata: f:annotations: .: {} f:kubectl.kubernetes.io/last-applied-configuration: {} f:labels: .</description></item><item><title>Observability</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Observability/Observability/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Observability/Observability/</guid><description>概述 参考：
CNCF 博客，What was observability again? 中文翻译：公众号，云原生技术爱好者社区-什么是可观测性 CNCF 可观测性白皮书(中文) CNCF 全景图 Wiki, Observability 宋净超-云原生资料库-OpenTelemetry 可观测性的未来 公众号，云原生社区-构建适合组织的云原生可观测性能力 Goole 文章 想象一下，在没有财务预测的情况下经营企业，甚至不知道银行剩下多少钱。您怎么知道您是在巨大的现金缓冲中游泳还是由于资金不足而需要跳过客户午餐？如果不注意自己的财务状况，根本就不可能开展健康的业务。同样，如果不观察您的计算基础架构，就不可能保持应用程序运行正常。
事实上，Observability(可观测性) 非常重要，到 2021 年 2 月，云原生计算基金会(CNCF)列出了 102 个可观察性项目。可观测性不仅重要，而且昂贵。Netflix 被戏称为一个产生大量日志的平台，同时也是一个流视频平台。可观测性之所以昂贵，有两个原因:
可观测性比被观测系统至少可靠一个数量级。否则，你将继续调试你的可观察性堆栈，而不是使用它来保持你的应用程序运行。 因为你永远不知道要观察什么，直到事件发生后，观察多于需要的东西是很常见的。一个好的汽车司机不仅要向前看，而且还要不断扫视周围以避免事故。 什么是可观测性 可观测性有许多名称，如监测、审计、遥测、仪器。忽略这些细微差别，所有这些词本质上的意思都是一样的：度量您的基础设施、平台和应用程序，以了解它是如何运行的。正如彼得·德鲁克(Peter Drucker)曾经说过的：如果你无法量化它，你就无法管理它。
如果你熟悉精益思维——即构建-度量-学习——那么可观察性就会自然而然地出现在你身上。可观测性通过测量阶段闭合反馈回路。它允许您的团队对应用程序进行快速更改，快速适应其用户基础和环境，而不会产生不必要的意外。良好的可观测性可以将凌晨 2 点被唤醒转换为日常检查。
可观测性的三大支柱 具有可观测的系统通常具有三个部分
Metrics(指标) 监控 # 随着时间推移产生的一些与监控相关的可聚合数据点 Logging(日志) 监控 # 离散式的日志或事件 Tracing(链路追踪) 监控 # 追踪程序的函数 CNCF 将 可观测性 和 数据分析 归类为一个单独的类别，且划分成 4 个子类
监控系统 # 以 Prometheus 等为代表 日志系统 # 以 Elastic Stack 和 PLG Stack 等为代表 追踪系统 # 以 Jaeger、Zipkiin、SkyWalking、Pinpoint 等为代表 可以监控两个程序之间调用时，程序内部都调用了哪些函数。类似 Linux 的 Strace 命令，只不过这些监控是实时的。 混沌工程系统 # 以 ChaosMonkey 和 ChaosBlade 等为代表 Metrics(指标) 指标 —— 也称为服务水平指标(SLI)或关键性能指标(KPI) —— 是数字值的时间序列。可以把它想象成每小时记录所有大城市的室外温度。指标使用最少的空间，提供最多的洞察力(为它们使用的空间)。它们可以记录每小时活动用户的数量、应用程序收到的请求的数量、可用磁盘空间的数量等。关注指标可以确保您的用户在使用应用程序时获得良好的体验，同时还可以降低基础设施的成本。</description></item><item><title>OOP</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Object-oriented-Programming/OOP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Object-oriented-Programming/OOP/</guid><description>概述 参考
公众号，码农的荒岛求生-为什么抽象在计算机科学中如此重要 喜马拉雅,10-万物介对象，编程的关键就是找对象(对建模的理解) 喜马拉雅,13-从程序员到产品经理，产品经理是干什么的？(对建模的理解) Wiki, Object-oriented programming(面向对象编程) Wiki, Object(对象) Wiki, Instance 与 Instantiate(实例 and 实例化) Object-oriented Programming(面向对象编程，简称 OOP)
抽象 与 建模 计算科学中的所有问题都可以通过增加一层抽象来解决。
All problems in computer science can be solved by another level of indirection.
没有抽象的世界
想象这样一种场景，如果我们的语言中没有代词这种形式，那么我们想表达“张三是个好人“该怎么说呢？可能是这样的：
”你还记得我说过的人吧，穿着邋邋遢遢的，公司在中关村，整天背着个双肩包，写代码的，天天 996，这个人是个好人“，看到了吧，在没有代词的情况下我们想表达一件事是非常困难的，因为我们需要具体的描述清楚所有细节，但是有了”张三“这种抽象后，一切都简单了，我们只需要针对张三这种抽象进行交流，再也不需要针对一堆细节进行交流了，抽象大大增强了表现力，这就是抽象的力量。
接下来回到计算机世界。
计算机使用层面
我们在使用计算机时其实抽象就在发挥作用，在 Word 中编辑文档时我们不会去考虑 CPU 是如何处理这些字符的，这些字符是如何被保存到磁盘的。在浏览网页时我们不需要关心网页中的数据是如何在网络中传输的、浏览器是怎样把这些数据适当的渲染出来的，我们需要做的仅仅就是在 Word 中简单的输入字符，用鼠标或者手指滑动网页。
因此只要在使用计算机，那么抽象就在发挥作用，只不过是我们没有意识到而已，而之所以我们没有意识到是因为抽象工作的太好了。
编程语言层面
程序员也可以从抽象中获得极大好处，因为软件是复杂的，但程序员可以通过抽象来控制复杂度，方法就是抽象。
比如一个好的设计就是对某项功能抽象出一组简单的 API，这样其它程序员在使用这个模块时只需要关注这几个简单的 API 而不是一堆内部实现细节。
不同的编程语言提供了不同的机制来让程序员实现这种抽象。
比如面向对象语言(OOP)的一大优势就是让程序员方便进行抽象，这样类的使用者就无需关心类的实现了，更不用提 OOP 中的多态、抽象类等，有了这些程序员可以只针对抽象而不是具体实现进行编程，这样的程序会有更好的可扩展性，也能更好的应对需求的变化。
系统设计层面
计算机从本质上将就是在抽象的基础上建立起来的。计算机科学中的一大主题其实就是在不同层面提供抽象表示从而对外屏蔽实现细节。
对于 CPU 来说，其对外提供的是一堆指令集，程序员只需要使用这些指令就可以指挥 CPU 工作了，这样就无需从细节上知道 CPU 是如何取出指令、执行指令的。
在操作系统层面，我们将 I/O 设备抽象成了文件、把程序的运行抽象成了进程、把程序运行时占用的内存抽象成了虚拟内存、又把进程和进程运行以来的环境抽象成了容器、最后把所有的一切包括操作系统、进程、CPU、内存、磁盘、网络抽象成了虚拟机。现在虚拟机技术是云计算的基石，实际上这种技术在上世纪 60 年代就出现了，并在当前火热的云计算中大放异彩。</description></item><item><title>OpenCV</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/OpenCV/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/OpenCV/</guid><description>概述 参考：
GitHub 项目，opencv/opencv 官网 官方文档，从左侧 Nightly 中选择想要查看的版本 https://zhuanlan.zhihu.com/p/115321759 手把手教你使用OpenCV库（附实例、Python代码解析） Open Source Computer Vision Library(开源计算机视觉库，简称 OpenCV) 是一个包含数百种计算机视觉算法的开源库。
各语言的库 官方提供了 Python、C++ 的 OpenCV 库
go https://github.com/hybridgroup/gocv
Modules(模块) 参考：
4.x 官网文档，主页 4.x 官方文档，介绍 4.x 官方文档，模块 4.x 官方文档，Class 列表 https://zhuanlan.zhihu.com/p/19988205 OpenCV 具有模块化的结构，整个 OpenCV 的功能由一个个模块提供，每个模块具有自己的类、函数、方法，并且可以多个模块共享使用。这种模块化的结构可以让 OpenCV 像一门编程语言一样，具有自己的标准库和第三方库，标准库中的标准模块可以实现自身的核心功能，第三方库的模块可以基于核心功能扩展其他功能。就像 https://pkg.go.dev/ 中的各种包，可以看到类型、方法、函数等等的描述。
所有 OpenCV 的类和函数都放在 cv Namespace 中(Namespace 是 C++ 编程语言的基本概念)，如果我们要使用 C++ 代码调用 OpenCV 的模块，需要使用 cv:: 或在头部添加 using namespace cv; 指令。
模块分为两类：
Main Modules(主模块) Extra Modules(额外模块) Main Modules(主模块) core # 核心功能模块，全称 Core functionality 。定义了基本的数据结构，包括最重要的 Mat 类、XML 读写、opengl三维渲染等。 imgproc # 图像处理模块，全称 Image processing。包括图像滤波、集合图像变换、直方图计算、形状描述、物体检测、等等。图像处理是计算机视觉的重要工具。 imgcodecs # 图像文件读写模块，全称 Image file reading and writing。 videoio # 视频文件读写模块，全称 Video I/O。也包括摄像头、Kinect 等的输入。 highgui # 高级图形界面及与 QT 框架的整合。 High-level GUI video # 视频分析模块。包括背景提取、光流跟踪、卡尔曼滤波等，做视频监控的读者会经常使用这个模块。 Video Analysis calib3d.</description></item><item><title>Opensatck 介绍</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Opensatck-%E4%BB%8B%E7%BB%8D/Opensatck-%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Opensatck-%E4%BB%8B%E7%BB%8D/Opensatck-%E4%BB%8B%E7%BB%8D/</guid><description>概述 参考
GitHub 项目，openstack/openstack 官网 原文：OpenStack 关键技术系列: 最全 OpenStack 知识科普 OpenStack 是一套编排系统，编排目标是实现了 Virtualization(虚拟化) 的虚拟机。
Ubuntu 成为 OpenStack 部署排名第一的操作系统
https://cn.ubuntu.com/blog/ubuntu-becomes-number-one-os-for-openstack-deployment-post-1
OpenStack 关键技术系列: 最全 OpenStack 知识科普 最近几年，OpenStack 这个词大家早都熟的不能再熟，越来越多人开始关注。
对于大部分人来说，这还是一个很陌生的词，不知道它到底是什么，从哪里来，有什么用，和自己的工作有什么关系。
有人可能知道，它和现在非常火的云计算有很大的关系。伴随它一起出现的，还有很多新词，例如NFV、Nova、Neutron、Horizon等，更加让人云里雾里。
为了消除大家的疑惑，今天我们就来一个“大揭秘”——通过这篇通俗易懂的科普文，帮助大家轻松入门OpenStack。
OpenStack 的起源
这玩意到底是从哪冒出来的？
我们先来说说OpenStack的起源吧。
2002年，美国著名的电商公司亚马逊（Amazon）干了一件“不务正业”的事。他们向客户推出了一项全新的业务——包括存储空间、计算能力等资源服务的Web Service。这就是大名鼎鼎的 AWS（Amazon Web Service）。
说白了，这个Web Service服务，就是为大家提供“远程电脑”。你可以远程控制它，有硬盘，有CPU，有内存啥的。你在上面配置你的各种服务，然后给你的用户使用，例如网站、FTP等。这个就是云计算的一种早期形式。
后来，到了2006年，亚马逊又推出了弹性计算云（Elastic Compute Cloud），也称 EC2 。EC2配置界面更简单，使用起来更方便，关键一点，它开始有了“弹性”！
什么是“弹性”？别急哈，等会我们再解释。
同样是 2006 年，8 月 9 日，Google 首席执行官埃里克·施密特在搜索引擎大会上首次提出“云计算”（Cloud Computing）的概念。从此，云计算进入了高速发展阶段。
云计算
到了 2010 年，当时有一家名叫 Rackspace 的公司，他们一直在做和亚马逊一样的云主机和云储存服务，但是始终都干不过亚马逊，排名第二。他们一气之下，干脆就把它们的云储存服务给开源了。
啥叫开源（Open Source）？开源就是开放源代码，把程序的代码公开了，给所有人免费查看和使用。和他们一起开放源代码的，还有一个家伙，就是——NASA。
好吧，又是一个“不务正业”的家伙。
NASA 之前在云计算方面投入了大量的资金，但是后来发现这玩意好像是个无底洞，太烧钱了。而且，他们也似乎意识到这不是他们该干的事。所以，NASA 和 Rackspace 一起，选择开放源代码。
其实还有一个原因：以前 NASA 是使用 Eucalyptus 云计算管理平台，不过这个平台分成两个版本，一个开源的版本，一个收费的版本。这就导致 NASA 很不爽，向 Eucalyptus 贡献代码，结果 Eucalyptus 认为这个代码和收费版本冲突，不接受。NASA 给气得不行，所以选择了将代码开源。</description></item><item><title>OpenSSH</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/OpenSSH/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/OpenSSH/</guid><description>概述 参考：
官网 官方文档，Manual(手册) OpenSSH 是 Secure Shell Protocol 的开源实现方案，该工具为 C/S 架构，服务端默认监听在 22/tcp 端口上。如果想要连接到服务端，同样需要一个客户端来进行连接。
比如，现在有两台主机，主机 A 和主机 B，如果想要在 B 上可以操作 A，那么就需要在 A 机上安装服务端工具(openssh-server)，在 B 机上安装客户端工具(openssh-client)，然后通过 ssh 工具进行互联
Note：现在 OpenSSH 一般作为 Linux 发行版的标准远程登录工具默认安装在系统中且开机自启动。
OpenSSH 安装 OpenSSH 关联文件与配置 /var/log/secure # 登录信息日志所在位置
可以通过该日志获取到尝试暴力破解的 IP /etc/ssh/ssh_config # OpenSSH 的 client 端配置(ssh、scp 等程序)
/etc/ssh/sshd_config # OpenSSH 的 server 端配置(sshd 程序)
~/.ssh/know_hosts # 已知的曾经连接过的主机的信息。凡是使用 ssh 连接过该主机，都会将信息记录在其中
~/.ssh/authorized_keys # 已经认证的公钥。如果其他 client 想要连接服务端，凡是在该文件中的公钥，都可以免密连接。
注意：OpenSSH 使用非对称加密的方式，与传统互联网的 https 使用方式相反。https 的公钥是交给客户端，用来验证服务端返回的网页是否可信。而 OpenSSH 则是将公钥交给服务端，用来验证客户端发送的信息是否可信。 这也确实符合逻辑 ssh 是一个客户端需要登录多个服务端，服务端要验证客户端发送的信息的真实性，要是不验证，那么就可以随便在自己服务器上执行命令了，这是不对的~ 而互联网通过 https 访问，则是多个客户端对应一个服务端。 ~/.</description></item><item><title>OpenSSL</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/OpenSSL/OpenSSL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/OpenSSL/OpenSSL/</guid><description>概述 参考：
官网 GitHub 项目，openssl/openssl OpenSSL 是一个商业级且功能齐全的工具包，用于通用密码学和安全通信
OpenSSL 可以实现 TLS(传输层安全性) 和 SSL(安全套接字层) 协议的预期功能，类似于 OpenSSH 是 ssh 协议的实现
OpenSSL 主要包含两组东西：
openssl # 多用途的命令行工具 libraries # OpenSSL 库 libcrypto # 加密解密库 libssl # ssl 库，实现了 ssl 及 tls 的功能 OpenSSL 关联文件与配置 /etc/ssl/openssl.cnf # OpenSSL 的“命令行工具”和 “库”默认使用的配置文件。
RedHat 系默认配置文件在 /etc/pki/tls/openssl.cnf
如果想要使用 CA 功能，需要进行如下配置
touch /etc/pki/CA/index.txt echo 01 &amp;gt; /etc/pki/CA/serial openssl 命令行工具 参考：
Manual(手册)，openssl openssl 程序提供了丰富的子命令，以实现 TLS/SSL 网络协议以及它们所需要的相关加密标准。
Syntax(语法) openssl Command [ OPTIONS ] [ ARGUMENTS ]</description></item><item><title>OpenStack 部署与清理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/OpenStack-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/OpenStack-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/OpenStack-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/OpenStack-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</guid><description>概述 参考：
https://ithelp.ithome.com.tw/articles/10269737 https://ithelp.ithome.com.tw/articles/10270784 https://ithelp.ithome.com.tw/articles/10271345 部署方式 手动部署 OpenStack 中的每一个组件 https://docs.openstack.org/xena/install/
使用自动化部署工具，部署工具有多种类型可供选择 由大型公司维护的部署工具
TripleO # 由 RedHat 公司维护。是 RedHat OpenStack Platform(RHOSP) 的上游版本。 OpenStack Charms # 由 Canonical 公司维护(Ubuntu 发行版公司)。使用 MAAS 和 Juju 部署。 由社区驱动的部署工具
OpenStack Kolla # 通过 Ansible 部署，并将大部分组件以容器的方式启动 非常简单高效得部署一个用来 生产、开发、测试 的 OpenStack。支持 all-in-one 和 multinode 两种模式(即所有组件都在一个节点或分散在多个节点) OpenStack Ansible # 通过 Ansible 部署。 其他
原始的 OpenStack 不管是什么部署方式，通常都需要至少两张网卡。
对于小规模部署，还可以使用其他 OpenStack 的发行版：
MicroStack 支持的操作系统 从 Ussuri 版本开始，OpenStack 不再支持 CentOS 7 作为主机操作系统。Train 版本同时支持 CentOS 7 和 8，并提供了迁移路径。有关迁移到 CentOS 8 的信息，请参阅 Kolla Ansible Train 文档。</description></item><item><title>OpenTelemetry</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/OpenTelemetry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/OpenTelemetry/</guid><description>概述 参考：
GitHub 组织，OpenTelemetry 官网 官方文档 公众号-OpenTelemetry，OpenTelemetry 核心原理篇 ：怎么理解分布式链路追踪技术？ 公众号-OpenTelemetry，在生产环境如何选择靠谱的 APM 系统 OpenTelemetry(开放式遥测技术，简称 OTel) 是一组 API、SDK、工具、更是一种遥测标准，旨在创建和管理 Telemetry Data(遥测数据)。通过 OpenTelemetry 标准创建的程序，可以采集 OpenTelemetry 标准的遥测数据，并发送到我们指定的后端中。OpenTelemetry 支持各种流行的开源后端项目，比如 Prometheus、Jaeger 等。
遥测数据包括
Logs(日志数据) # 日志系统 Metrics(指标数据) # 监控系统 Traces(链路追踪数据) # 追踪系统 Baggage # TODO: 这是啥 Notes：OpenTelemetry 不是像 Prometheus、Jaeger 那样的可观测性后端。相反，OpenTelemetry 支持将数据导出到各种开源和商业的后端产品中，它提供了一个可插拔的架构，因此可以轻松添加其他技术协议和格式。
OTel 之于可观测性系统，类似 OCI 之于容器。但是能比 OCI 提供更多。
OpenTelemetry 组件 目前，OpenTelemetry 主要包含如下组件：
规范 # 与编程语言无关的规范，规定了遥测数据格式等 工具 # 用于 采集/接收、转换、导出 遥测数据的工具。比如官方提供的 OTel Collector SDK # 用于为各种编程语言提供编写符合 OpenTelemetry 规范的工具 自动 instrumentation 和 贡献包 # TODO: 没搞懂这是什么？ Signals https://opentelemetry.</description></item><item><title>Operating system</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Operating-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Operating-system/</guid><description>概述 参考：
Wiki, Operating_system Operating system(操作系统，简称 OS) 也是一种软件，用来管理计算机硬件和其他以及自身软件资源的。
学习 《操作系统导论》
Time Sharing System(分时系统) 概述 Time Sharing Operating System(分时操作系统，简称 TSOS) 的出现是为了弥补批处理方式不能向用户提供交互式快速服务的缺点而发展起来的，并且成为了当今(2021 年) 的主流操作系统。
在分时系统中，一台计算机主机连接了多个终端，每个终端可由一个用户使用。用户通过终端交互式地向系统发出命令请求，系统接受用户的命令之后，采用时间片轮转方式处理服务请求，并通过交互方式在终端上向用户显示结果。
这样的系统现在(2021 年)仍然占据着大量的市场，Windos、MacOS，Linux 都属于分时操作系统。分时系统的典型代表就是 UNIX，它对后续操作系统的设计产生了重大影响。
分时共享是出于这样的认识而开发的：即尽管任何单个用户都会低效地使用计算机，但一大群用户在一起却不会。这是由于交互模式所致: 通常，单个用户会输入大量信息，然后进行长时间的暂停，但是一组用户同时工作将意味着一个用户的暂停将被其他用户的活动所填补。给定最佳的群体规模，整个过程可能非常有效。同样，可以将等待磁盘，磁带或网络输入所花费的一小部分时间授予其他用户。
分时的概念与实现 分时操作系统将 CPU 的运行时间划分为若干个小片段，称为 Time slice(时间片)。Time slice(时间片) 是系统规定进程一次使用 CPU 的最长时间(时间片的长短可以因不同系统而异)。
最开始，时间片通常是 100ms 左右，这是一个实验统计值(不能太大也不能太小)。另外，在硬件方面设立一个中断时钟，它每过时间片便向 CPU 发一次中断信号。于是，假设现在有多个用户程序 A、B、C，CPU 在一个 A 执行完一个时间片后便被中断，然后去执行 B 一个时间片，再执行 C 一个时间片，一次循环，直到 A、B、C 三个程序全部执行完成。操作系统会保护被中断程序的运行现场，转去执行另一个用户程序。
就这样，操作系统可以把 CPU 按时间片依次分配给系统中的各个用户程序。由于系统中用户程序的数目是有限的，所以，只要时间片大小选取合适，就能给用户以独占系统资源的感觉，可以使每个用户能及时与自己的作业交互，使用户的请求得到及时响应。其实，为了实现人机交互，分时操作系统对早起批处理系统的运行方式进行了两大改进：一是作业直接进内存；二是作业不能长期占用 CPU，而是以时间片为单位交替使用 CPU。
分时系统的原理，同样也适用于多任务上，当系统中 1 个用户同时运行了多个程序时，也可以使用时间片的概念，让多个程序形成逻辑上的“并行”执行。
UNIX 就是典型的通用的分时操作系统。
Real Time System(实时操作系统) 概述 参考：Wiki, Real-time OS</description></item><item><title>Package 管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Package-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Package-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
概述 参考：
在 Linux 操作系统中，Package 就是指应用程序的安装包。保存 Package 的地方(网站、ISO 等)称为 Repository(简称 Repo)，我们可以从各种 Linux 发行版的官方 Repo 中下载对应的可用的 Package，以安装到这些发行版的 Linux 系统中。
注意：哪怕两个发行版的包管理器相同，也不代表他们的 Package 是可以公用的，比如 CentOS 和 OpenEuler 都用 yum，但是 CentOS 的 Package 是无法装在 OpenEuler 上的，安装时将会报错(比如包与包之间 conflict(冲突))
Linux 各发行版的官方 Repo 站点 包含很多发行版的 Repo 站点: https://pkgs.org/ OpenEuler: https://repo.openeuler.org/ CentOS: https://centos.pkgs.org/ Ubuntu: https://packages.ubuntu.com/ 在这里可以找到 jammy 版本(20.04 TLS)的所有软件包列表: https://packages.ubuntu.com/jammy/allpackages</description></item><item><title>Packet analyzer</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/Packet-analyzer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/Packet-analyzer/</guid><description>概述 参考：
Wiki, Packet analyzer(包分析器) Packet analyzer(包分析器) 是一种计算器程序或计算机硬件，可以拦截和记录通过计算机网络的流量，有的地方也称之为 Packet sniffer(包嗅探器)。数据包捕获是拦截和记录流量的过程。随着数据流跨网络流流，分析器捕获每个数据包，如果需要，可以解码分组的原始数据，显示分组中的各种字段的值，并根据适当的 RFC 或其他规范分析其内容。
Packet Analyzer 的实现 各种实现的对比: https://en.wikipedia.org/wiki/Comparison_of_packet_analyzers
TCPDump WireShark &amp;hellip;&amp;hellip;等等 抓包工具 Reqable
https://github.com/reqable/reqable-app # 非开源，只是有个仓库 官网 https://reqable.com/ 图标是 小黄鸟，有 移动端 和 PC 端。宣传自己是 Fiddler + Charles + Postman Fiddler
Charles
mitmproxy
GitHub 项目，mitmproxy/mitmproxy Python 编写，为渗透测试人员和软件开发人员提供的交互式、支持 TLS 的拦截 HTTP 代理。 HTTP Debugger
https://www.httpdebugger.com/ 可以抓进程的包，而不是通过代理的方式抓包 openQPA
https://github.com/l7dpi/openQPA, https://gitee.com/l7dpi/openQPA http://www.l7dpi.com/ 基于进程抓包 SunnyNetTools
Sunny网络中间件-抓包工具</description></item><item><title>PAM</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM/</guid><description>概述 参考：
GitHub 项目，linux-pam 官方文档已停止更新不再维护 Manual(手册)，PAM(8) Wiki, PAM Wiki, Linux PAM 博客园，Linux 下 PAM 模块学习总结 博客园，PAM(Pluggable Authentication Modules)认证机制详情 https://www.redhat.com/sysadmin/pluggable-authentication-modules-pam 金步国，Linux PAM 学习笔记 Pluggable Authentication Modules(可插入式认证模块，简称 PAM) 是由 Sun 提出的一种认证机制。它通过提供一些动态链接库和一套统一的 API，将系统提供的服务和该服务的认证方式分开，使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序，同时也便于向系统中添加新的认证手段。
在过去，我们想要对一个使用者进行 Authentication(认证)，得要要求用户输入账号密码，然后通过自行撰写的程序来判断该账号密码是否正确。也因为如此，我们常常使用不同的机制来判断账号密码，所以搞的一部主机上面拥有多个各别的认证系统，也造成账号密码可能不同步的验证问题！为了解决这个问题因此有了 PAM 的机制！
以常见的 su 命令来说，它可以实现用户切换，从 root 切换至其他用户不需要密码、从非 root 用户切换至其他用户则需要验证目标用户的密码，一旦认证成功就以目标用户身份启动 shell 以供使用。本质上，su 只做两件事：(1)认证；(2)启动 shell 。按照传统思路，两件事都很容易实现，例如认证逻辑可以用伪代码这样简单的描述：
if ( uid == 0 ) 认证成功 elseif ( 输入的密码 == 目标用户的密码 ) 认证成功 else 认证失败 但是，认证需求不是一成不变的。例如：
(1)为了方便运维团队成员(也就是 wheel 组)，希望 wheel 组中的用户无需输入密码也能直接进行用户切换； (2)为了加强安全性，希望额外验证手机短信； (3)为了避免频繁输入难记的用户密码，希望可以选用指纹方式进行验证； (4)为了方便某个特定的用户测试，希望仅凭手机短信也能完成验证 &amp;hellip;&amp;hellip; 这样一来， su 的开发者将会被迫不断更改 su 的源代码，然后再重新调试、编译、分发，非常辛苦。这种情况下，PAM 就可以对 su 开发者说：&amp;ldquo;认证的事交给我，能不能通过认证由我说了算，你只需做好其他事情(启动 shell)即可&amp;rdquo;；同时又对用户(系统管理员)说：&amp;ldquo;只要学会了 PAM 配置语法，就可以利用各种 PAM 模块，编写出千变万化的认证策略。无需打扰 su 开发者，就能立即得到想要的效果&amp;rdquo;。通过把与认证相关的脏活累活都交给 PAM 来干， su 的开发者与用户之间实现了解耦，彼此皆大欢喜。</description></item><item><title>Panel</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Panel/Panel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Panel/Panel/</guid><description>概述 参考：
官方文档，面板与可视化 官方文档，面板与可视化 - 面板编辑器 当我们开始创建一个新的 Panel 时，可以看到下图所示的界面，这个界面分为三大部分，分别用三种颜色的框体括起来
Header(标题), 绿色部分 # 左边是面板的名称，右侧有 4 个按钮，分别是 设置整个 Dashboard、放弃、保存、应用 Visualization preview(可视化的预览), 蓝色部分 # 在 数据处理 与 面板样式处理 两部分设置的内容将会反应在这个预览部分 Data section(数据处理), 红色部分 # 通过数据查询语句来获取数据，以便在面板展示 Panel dispaly options(面板显示选项), 黄色部分 # 用来配置面板的信息。包括 面板类型、面板名称、展示效果 等等 Header 标题部分列出了面板所在的仪表板的名称和一些仪表板命令。您还可以单击返回箭头以返回仪表板。
标题的右侧是以下选项：
⚙齿轮图标(设置) - 单击以访问仪表板设置。 Discard(放弃) - 放弃自上次保存仪表板以来对面板所做的所有更改。 Save(保存) - 保存仪表板，包括您在面板编辑器中所做的所有更改。 Apply(应用) - 应用您所做的更改，然后关闭面板编辑器，将您返回到仪表板。您必须保存仪表板以保留应用的更改。 Visualization preview https://grafana.com/docs/grafana/latest/panels-visualizations/panel-editor-overview/#visualization-preview
在可视化的预览部分，可以图像的形式查看从数据源获取到的数据。包含如下几个部分
Axes 横、纵 坐标轴 横轴是时间 纵轴是值。即该时间点上，数据源中的值。 Panel title 面板标题 Legend 图例(即 图片的文字说明) 时间范围控件 在左上角是 Grafana 模板</description></item><item><title>Percona</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Percona/Percona/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Percona/Percona/</guid><description>概述 参考：
GitHub 组织，Percona 官网 Wiki, Percona Percona是一家位于北卡罗来纳州达勒姆的美国公司，为 MySQL、MariaDB、PostgreSQL、MongoDB 和 RocksDB用户开发了许多开源软件项目。该公司每年约 2500 万美元的收入来自数据库系统的支持、咨询和托管服务。
该公司由 Peter Zaitsev 和 Vadim Tkachenko 于 2006 年创立。
Percona Monitoring and Management # 用于管理和监控 MySQL、PostgreSQL、MongoDB 和 ProxySQL 性能的开源平台 Percona XtraDB cluster # 用于 MySQL 集群和高可用性的高扩展性解决方案 https://github.com/percona/percona-xtradb-cluster</description></item><item><title>Percona XtraDB Cluster</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Percona/Percona-XtraDB-Cluster/Percona-XtraDB-Cluster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Percona/Percona-XtraDB-Cluster/Percona-XtraDB-Cluster/</guid><description>概述 参考：
GitHub 项目，percona/percona-xtradb-cluster 官网 PXC Operator 参考：
GitHub 项目，percona/percona-xtradb-cluster-operator 部署 PXC 参考：
官方文档，安装 PXC 集群 使用 Docker 部署 参考：
Running Percona XtraDB Cluster in a Docker Container - Percona XtraDB Cluster 使用 PXC Operator 在 Kubernetes 中部署 参考：
官方文档，快速开始指南-使用 kubectl 安装 PXC Operator 官方文档，高级安装指南-通用 Kubernetes 安装 快速体验 部署 Operator
kubectl apply -f https://raw.githubusercontent.com/percona/percona-xtradb-cluster-operator/v1.12.0/deploy/bundle.yaml
部署 PXC
kubectl apply -f https://raw.githubusercontent.com/percona/percona-xtradb-cluster-operator/v1.12.0/deploy/cr.yaml
高级安装 创建名称空间
kubectl create namespace pxc
kubectl apply -f crd.yaml</description></item><item><title>perf 性能分析工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
GitHub 项目，torvalds/linux - /tools/perf Kernel Wiki, perf perf 事件列表中的内核 pmu 事件是什么 https://unix.stackexchange.com/questions/326621/what-are-kernel-pmu-event-s-in-perf-events-list https://qastack.cn/unix/326621/what-are-kernel-pmu-event-s-in-perf-events-list brendangregg 博客，perf Linux Performance Events(Linux 性能事件，简称 LPE) 是用来分析 Linux Kernel 性能的工具，通常称为 perf。perf 随 Kernel 2.6+ 一同发布。通过它，应用程序可以利用 PMU，tracepoint 和内核中的特殊计数器来进行性能统计。它不但可以分析指定应用程序的性能问题 (per thread)，也可以用来分析内核的性能问题，当然也可以同时分析应用代码和内核，从而全面理解应用程序中的性能瓶颈。
perf 主要是通过 Tracing(追踪) 的方式来实现性能数据的采集。
perf 和其他调试工具一样，需要 symbol(符号信息)。它们用于将内存地址转换为函数和变量名称，以便我们人类可以读取它们。如果没有符号，您将看到代表所分析的内存地址的十六进制数字。
[!Note] perf 命令甚至有时候可以跟 strace 工具 实现类似的效果，比如 perf stat -e syscalls:* 统计系统调用的计数，就很像 strace -c XX
Events 使用 perf list 命令可以列出可以分析的所有事件。
TODO: perf 可用的 Events 列表是从如何获取到的？
perf_event_open() 系统调用？ /sys/kernel/debug/tracing/events/ 目录？是特定于 tracepoint 类型事件的？ 由于 perf 本身就是与 Linux 内核强耦合的工具，所以获取 Events 应该也是通过某种方式动态获取的？ perf_event_open 系统调用用以设置性能监控，其中 perf_event_attr 参数（源码: include/uapi/linux/perf_event.</description></item><item><title>Peripheral</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Peripheral/Peripheral/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Peripheral/Peripheral/</guid><description>概述 参考：
Wiki, Peripheral Computer peripherals(计算机外围设备) 可以根据信息对于计算机的流动方向进行分类:
Input device(输入设备) # e.g. Output device(输出设备) # e.g. Computer monitor 鼠标 罗技鼠标 在设备管理器中看到 Logitech Cordless Device 驱动异常，无法自动安装。现象为 Logitech 的 Unifying 设备（i.e. 无线接收器）无法被软件识别；但是鼠标还是可以用的。
https://priesdelly.medium.com/logitech-cordless-device-fix-driver-not-installed-db328b6f6bb2 https://www.reddit.com/r/Windows10/comments/5s1m2w/comment/difegn3/?utm_source=share&amp;utm_medium=web2x&amp;context=3 在 https://support.logi.com/hc/en-us/articles/360025141274 安装 SetPoint 即可让驱动正常。 键盘 樱桃键盘 Cheey(樱桃) 键盘一按 F1 就是静音该如何解决？
使用 Ctrl + Fn 即可切换 F1 的作用，其他 F 功能键效果同理
攀升兄弟，名龙堂，宁美国度，京天华盛这四个哪个的主机好一些，自己不会组装，懒得组装，买个便宜的玩玩？ 原文: https://www.zhihu.com/question/435429789
SAS 卡 SAS 的全称是 串行附加SCSI（Serial Attached SCSI）。它是一种用于连接硬盘驱动器、光盘驱动器等设备的接口标准。SAS卡提供了高速、高性能、高可靠性和高灵活性的数据传输解决方案。</description></item><item><title>Persistent Volume(持久卷)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/</guid><description>PersistentVolume(持久卷) https://kubernetes.io/docs/concepts/storage/persistent-volumes/ kubernetes 的 volume 有一个问题就是不够灵活，且使用 volume 的用户必须要明确知道要使用的 volume 后端是用的什么类型的存储系统(例如 NFS 就需要配置 IP 和 PATH)。这与 kubernetes 的向用户和开发隐藏底层架构的目的有所背离，对存储资源最好的使用方式是能向计算资源一样，用户和开发人员无需了解 pod 资源究竟运行于哪个节点，也无需了解存储系统是什么类型的设备以及位于何处。他们只需要提出容量大小的需求(i.e.PVC)，k8s 管理员可以为其分配所需的空间。这就是 PV 与 PVC 的作用，抽象了底层的存储，使得存储系统的使用和管理两个职能互相解耦。这就好比创建一台虚拟机，并需求 20G 的存储空间，然后虚拟机管理系统就会自动创建出来，而不用去手动指定使用哪个存储空间了。
PersistentVolume(持久卷,简称 PV) 与 PersistentVolumeClaims(持久卷申请,简称 PVC) 是 kubernetes 中的一个 Resource(资源)，PVC 与 volume 不同，volume 的定义需要写进 Pod 的 manifest 中。而 PVC 对于 volume 来说就是一种 &amp;ldquo;volume 的类型&amp;rdquo;。
PV 就相当于虚拟机中的存储卷，虚拟了宿主机或者远程存储的存储资源。PVC 就相当于虚拟机里的一个物理磁盘。虚拟机里的磁盘其实就是通过存储卷来实现的，这与 PV 与 PVC 的关系基本一致。而下文讲的 StorageClass(存储类) 则相当于虚拟机中的存储池的概念了。 PV 与 PVC 为用户和管理员提供了一个 API 接口，抽象定义了存储的消费者-生产者模型(即从 k8s 系统来说，管理员使用 PV 生产一个 storage 资源，用户使用 PVC 消费一个 storage 资源) PV 与 PVC 的生命周期 详见：PV 与 PVC 的状态变化示例</description></item><item><title>PKM</title><link>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/PKM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/PKM/</guid><description>概述 参考：
Wiki, Personal knowledge management Personal knowledge management(个人知识管理，简称 PKM) 是一个收集信息的过程
个人知识记录规范 配置文件与命令行参数 各种类型的配置文件（包括 INI、JSON、等等）、命令行参数是类似 Key/Value 的结构。在我的笔记中，记录格式一般都是这样的：
键的名称(值的类型)
--命令行参数名称(参数值类型)
对于配置文件来说，有的值的类型比较复杂（比如是一个 OBJECT 类型），可以再创建一个自定义的名称以在单独的章节下记录。
node1(STRING) node2(sub_node1) node3([]configs) node4(OBJECT) node5(map[STRING]STRING) node6(map[STRING]sub_node2) 笔记中的配置内容通常符合如下我自己定义的规范：
加粗的是 Key 括号中是 Value 的类型，Value 一般是非 Scalar 类型的节点。 若 Value 的类型是 Object，那么一般类型名称是自定义的。 由于 Object 类型的节点中，Value 也可以是一个节点，那么 Value 就有可能是由一个或多个内容组成，为了可以方便得复用这些内容，所以给它们起了一个名字。这就好像编程中的使用函数一样。 若 OBJECT 类型的字段下的字段非常多，我会在单独的标题中记录，Pod Manifest 是典型的例子。不但在单独的标题记录，而且还为这些字段进行了分组。在我们理解时，只有带有 (XXX) 这种写法的，才是 YAML 中真正的字段，而标题，通常不作为真正的字段，只是作为该字段的一个指示物，用以记录该字段下还有哪些字段。 若 Object 类型的字段比较简单，没有复杂的子字段，那么笔记中就直接用 OBJCET 这几个字符表示。 若 Value 的类型是 STRING、INT、etc. 简单类型，但是其含义很复杂，也会将该字段值的类型写作连接，在独立章节记录。 这种规范为了文档的整洁性，让相同层级的字段在一起，可以一眼看到同级内容，让 Value 与 Key 分开，将 Value 所包含的具体内容放在单独链接（i.</description></item><item><title>Playbook</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Playbook/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Playbook/</guid><description>概述 参考：
官方文档，Playbook指南 - Playbook 介绍 官方文档，Playbook 指南 - 使用 Playbook Ansible Galaxy 类似于 playbook 仓库的地方 公众号，任务中心之Ansible进阶篇 与通过命令行来执行 Ansbile 任务模式相比，Playbook 是 Ansible 执行任务的另一种方式，而且功能非常强大。
playbook 可以通过定义一个或多个文件，然后让 ansible 使用这些文件来完成一系列复杂的任务。如果说通过命令行是对多台设备执行一个任务，那么 Playbook 则是可以对多台设备按顺序执行不同任务。
playbook 称为&amp;quot;剧本&amp;quot;。每个 playbook 都包含一个或多个 plays(戏剧)。拿拍电影举例，一部电影会有一部“剧本 playbook”来描述电影情节，而整部电影都是由一场一场的“戏剧 play”拼凑起来的。每一场戏剧又需要执行多种“任务 task”(比如亲嘴、打架、聊天、上床~~~)
首先，下面是一个 playbook 的样例。这个 playbook 中包含两个 play，一个叫 webservers，另一个叫 databases。其中 webservers 中包含两个 tasks，一个要使用 yum 模块执行动作，另一个要使用 template 模块，向文件中写入内容
- hosts: webservers remote_user: root tasks: - name: ensure apache is at the latest version yum: name: httpd state: latest - name: write the apache config file template: src: /srv/httpd.</description></item><item><title>Pod</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod/</guid><description>概述 参考：
官方文档，概念 - 工作负载 - Pods Pod 是 Kubernetes 集群内最小的工作单元，是一个逻辑概念。Kubernetes 真正处理的，还是通过 CRI 在 HostOS 上的 Namespace 和 Cgroups。所谓的 Pod 只是一组共享了某些资源的 Container，这一组 Container 共享同一个 NetworkNamespace 并且可以声明共享同一个 Volume。
Infrastructure(基础设施，简称 Infra) 容器：为了保证多个 Container 在共享的时候是对等关系(一般情况可以先启动 ContainerA，再启动 ContainerB 并共享 ContainerA 的资源，但是这样 A 与 B 不对等，A 是必须先启动才能启动 B)，需要一个中间 Container，即 Infra 容器，Infra 容器 永远是第一个被创建的 Container，想要共享某些资源的 Container 则通过加入 NetworkNamespce 的方式，与 Infra 容器 关联在一起。效果如图
Infra 类型的 Container 使用一个名为 pause 的镜像，就像它的名字一样，永远处于&amp;quot;暂停&amp;quot;状态 Kubernetes 为每个 Pod 都附属了 k8s.gcr.ip/pause，这个 Container 只接管 Pod 的网络信息，业务 Container 通过加入网络 Container 的网络来实现网络共享。此容器随着 pod 创建而创建，随着 Pod 删除而删除。该容器是对业务 pod 的命名空间的解析。Note：如果想要更改该容器，则需要在 kubelet 中使用&amp;ndash;pod-infra-container-image 参数进行配置 与 Infra 关联的 Container 的所有 NetworkNamespace 必然是完全一样的。 该链接有一种详细的解释 Note：对于 kubelet 来说，这种容器称为 Sandbox。每次 kubelet 创建 pod 时，首先创建的也是 sandbox(i.</description></item><item><title>Pod 的资源管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%9A%84%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/Pod-%E7%9A%84%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%9A%84%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/Pod-%E7%9A%84%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
官方文档，概念 - 配置 - Pod 和容器的资源管理 Pod 中 Container 的资源需求与资源限制 可以在 Pod 的 yaml 中定义该 Pod 中各个 Container 对内存与 CPU 的最低需求量和最大使用量
requests：资源需求，最低保障，资源最少需要多少 limits：限制，硬限制，限额，资源最大不能超过多少 当对 Container 进行资源制定后，会出现 QoS(服务质量)的属性，下列 3 个属性从上往下优先级下降；当节点资源不够时，优先级越高，越会保证其正常运行，其余不够提供资源的 Container 则不再运行
Guarateed：有保证的，Pod 中每个 Container 同时设置 CPU 和内存的 requests 和 limits，且 request 和 limits 的值相同 Burstable：超频，Pod 中至少有一个 Container 设置了 CPU 或内存资源的 requests 属性 BestEffort：尽力努力(尽力而为)没有任何一个 Container 设置了 requests 和 limits 属性 关于在 yaml 中如何写资源限制中数值的说明：
kubernetes 中的一个 CPU 是一个逻辑 CPU，1CPU 的核心数=1000millicores 毫核心(也就是说 500m 相当于 0.</description></item><item><title>PostgreSQL</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/PostgreSQL/PostgreSQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/PostgreSQL/PostgreSQL/</guid><description>概述 参考：
官网 PostgreSQL 新手入门-阮一峰 PostgreSQL 是一个功能强大的开源对象关系数据库系统，经过 30 多年的积极开发，在可靠性、特性健壮性和性能方面赢得了很高的声誉。
一个 Database(库) 中包含多个 Schemas(模式)，一个 Schema(模式) 中包含多个 Tables(表)
Schema https://www.postgresql.org/docs/current/ddl-schemas.html
PostgreSQL 的数据库中包含 1 个或多个 Schema，所有的 Table 是归属在 Schema 下的。
可以讲 Schema 理解为 Namespace（PostgreSQL 也是通过 pg_namespace 元表（元数据表）查看所有 Schema）
默认情况下，创建的 Table 自动放入名为 public 的 Schema 下。每个数据库都会包含 public Schema。
要访问非 public Schema 下的 Table，使用 . 符号。e.g. SchemaName.TableName，如果用最简单的 SQL 举例就是: select * from schema_demo.table_one 列出名为 schema_demo 模式中的 table_one 表下的所有列。
PostgreSQL 内置了如下几个 Schemas
public # 在不指定 Schema 的情况下，新建的 Table 都默认保存在 public Schema 中。 pg_catalog # System catalogs(系统目录)，保存 PostgreSQL 运行常见的 information_schema # 与 Schema 相关的内部信息 PostgreSQL 部署 部署 Redhat 包部署 https://www.</description></item><item><title>PowerShell</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/PowerShell/PowerShell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/PowerShell/PowerShell/</guid><description>概述 参考：
官方文档 官方文档，关于 PowerShell 是一种跨平台的任务自动化解决方案，由命令行 shell、脚本语言和配置管理框架组成。 PowerShell 在 Windows、Linux 和 macOS 上运行。
PowerShell 的独特之处在于，它接受并返回 .NET 对象，而非纯文本。这个特点让 PowerShell 可以更轻松地在一个管道中串联不通的命令。
[!Notes] 这里面所说的对象，就是面向对象编程中常说的“对象”，就像 Go 语言中的 Struct 类似的东西，只不过是 .NET 语言中的对象。
这些对象在被接收后，再交给格式化函数处理，以人类可读的方式，输出出来。
我们可以在 PowerShell 官方文档的参考 - 关于 部分找到对 PowerShell 的基本概念的描述。
PowerShell 变量 详见 PowerShell 变量 章节
PowerShell 命令 参考：
官方文档，PowerShell 命令是什么？ about_Command_Precedence 介绍 PowerShell 如何确定要运行的命令。 about_Command_Syntax 介绍 PowerShell 中使用的语法关系图 about_Core_Commands 列出设计用于 PowerShell 提供程序的 cmdlet PowerShell 中可以执行的命令分两类
操作系统中的可执行文件 cmdlet PowerShell 内置了一组 cmdlet(全称 command-lets)，cmdlet 是一种命令的统称，并不是一个独立的可执行文件。cmdlet 被收集在 PowerShell 模块中，可以按需加载它们。可以用任何编译的 .</description></item><item><title>PowerShell 内置管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，PowerShell 模块参考 PowerShell 内置的管理工具都是 cmdlet，以模块形式提供，这个目录下记录的笔记中，每个文件或目录名都是一个模块的名称
CimCmdlets https://learn.microsoft.com/en-us/powershell/module/cimcmdlets
通用模块 Core
Management
Security
CimCmdlets
Utility
etc.
特定于 Windows 的模块 https://learn.microsoft.com/en-us/powershell/module/?view=windowsserver2025-ps
NetTCPIP 参考：
官方文档 - PowerShell，参考 - NetTCPIP Get-NetTCPConnection https://learn.microsoft.com/en-us/powershell/module/nettcpip/get-nettcpconnection
Syntax(语法) OPTIONS
-LocalPort([]INT) # 查看指定的端口，多个端口以 , 分割。 -State([]STRING) # 查看指定 TCP 状态的端口。可用的值有: Bound, Closed, CloseWait, Closing, DeleteTCB, Established, FinWait1, FinWait2, LastAck, Listen, SynReceived, SynSent, TimeWait Example 利用该模块可以比 netstat 命令更方便得获取各种基于网络连接的信息以及监听该端口的进程信息
获取监听在 1080 端口上的程序的路径
(get-process -id (Get-NetTCPConnection -LocalPort 10800 -State Listen).OwningProcess).path 甚至可以像这样组合出人类可读的信息
PS C:\Users\DesistDaydream&amp;gt; Get-NetTCPConnection -LocalPort 1080 -State Listen | Select-Object LocalAddress, LocalPort, @{Name=&amp;#34;PID&amp;#34;;Expression={$_.</description></item><item><title>pprof</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B7%A5%E5%85%B7/pprof/pprof/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B7%A5%E5%85%B7/pprof/pprof/</guid><description>概述 参考：
Go 官方文档，诊断 GitHub 项目，google/pprof GitHub 项目-文档，google/pprof/doc Go 包，net/http/pprof Go 博客，分析 Go 程序 思否，Golang 大杀器之性能剖析 PProf 公众号-云原生实验室，忙碌的开发人员的 Go Profiling、跟踪和可观察性指南 pprof 是 go 程序的性能分析器，一个可视化和分析 Profiling 数据的工具。pprof 可以从目标获取运行数据并生成 profile.proto 格式的 Profiles 文件，还可以读取 profile.proto 格式的 Profiling 样本集合，并生成报告。
profile.proto 是一个协议缓冲区，描述了一组调用堆栈和符号化信息。详见 https://developers.google.com/protocol-buffers
可以通过本地文件或 HTTP 读取 Profiles 文件。同时也可以聚合或比较多个 Profiles 文件。每个 profile.prot 格式的 Profile 样本的集合。
使用 pprof 想要使用 pprof 程序非常简单，只需要引入 net/http/pprof 包，并启动监听即可
package main import ( &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; _ &amp;#34;net/http/pprof&amp;#34; ) func main() { if err := http.</description></item><item><title>Process</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Process/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Process/</guid><description>概述 参考：
Wiki, Process_(computing) 原文连接，本文为 IBM RedBook 的 Linux Performanceand Tuning Guidelines 的 1.1 节的翻译 阿里技术，CPU 飙高，系统性能问题如何排查？ 进程管理是操作系统的最重要的功能之一。有效率的进程管理能保证一个程序平稳而高效地运行。它包括进程调度、中断处理、信号、进程优先级、上下文切换、进程状态、进度内存等。
Process(进程) 实际是运行在 CPU 中的一个 Program(程序) 的实体。在 Linux 系统中，能够同时运行多个进程。
Program(程序) 和 Process(进程) 的区别是什么呢?
在很久很久以前，计算机刚出现的时候，是没有操作系统的，那时候一台机器只是运行一个程序，计算后得出数据，后来人们为了同时运行多个程序从而研究出了操作系统，在操作系统之上可以运行多个程序 进程是程序的一个具体实现。类似于按照食谱，真正去做菜的过程。同一个程序可以执行多次，每次都可以在内存中开辟独立的空间来装载，从而产生多个进程。不同的进程还可以拥有各自独立的 IO 接口。 举例说明：
比如:
root 839 1 0 Mar07 ? Ssl 28:50 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 这就是一个 Processs(进程)，包括其 ID、启动时间、等等信息的集合体。进程的唯一标识符就是 ID，而启动该进程的程序是 dockerd
至于 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 这一串则是启动进程的 Command(命令) 其中命令中的 dockerd 就是启动该进程的 Program(程序)，/usr/bin/ 是程序所在路径，后面的 -H fd:// --containerd=/run/containerd/containerd.sock 是程序的参数。 这一整串字符串所组成的命令，就是启动进程的必备条件，操作系统当收到命令后，会被进程分配 ID，并记录下各种状态信息。 Linux 通过在短的时间间隔内轮流运行这些进程而实现“多任务”。这一短的时间间隔称为“时间片”，让进程轮流运行的方法称为“进程调度” ，完成调度的程序称为调度程序。</description></item><item><title>Programming environment</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/Programming-environment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/Programming-environment/</guid><description>概述 参考：
Programming environment(编程环境)
REPL IDE 是一种功能全面的复杂的编程环境。</description></item><item><title>Programming Technology</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/Programming-Technology/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/Programming-Technology/</guid><description>概述 参考：
Programming Technology(编程技术) 包含 XX、YY、etc.
CRUD(增删改查) 参考：
Wiki, CRUD 在计算机编程中，Create、Read、Update、Delete(创建、读取、更新、删除，简称 增删改查(CRUD)) 是持久性存储的四个基本操作。CRUD 有时也用于描述用户界面约定，这些约定便于使用基于计算机的表单和报告查看、搜索和更改信息。这个词很可能是詹姆斯·马丁 (James Martin) 在他的 1983 著作《管理数据库环境》中首次推广的。
Projects(项目) 项目一般就是指开发一个程序。
从写代码的角度看，一个项目就是一个文件夹，该文件夹中包含该项目所需要依赖的第三方库，项目主体的代码，可执行文件等。
前端与后端 后端：一般是用来处理客户端发送的请求，并将前端写的 页面代码 文件，发送给客户端；或者从数据库获取数据，并填充到前端页面中；等等
前端：一般用来展示的，客户端收到的页面文件(比如输入用户名和密码的框，下拉框等等)，都是由前端工程师来写的，一般是 html 等。
前后端交互 前端与后端之间的交互取决于是前后端分离还不分离
前后端不分离时，通常由后端代码渲染 html 等静态资源文件，此时客户端访问的是由后端代码监听的端口 前后端分离时，又分多种情况 将 html 等静态资源放在 Nginx 等可以提供 HTTP 服务的程序中，然后通过后端提供的 API 进行交互，此时客户端访问的是由提供 HTTP 服务程序监听的端口 将 html 等静态资源与后端代码放在一起，这种行为通常称为“XX 语言嵌入静态资源”，此时客户端访问的是由后端程序监听的端口 比如 Go 语言在 1.16 版本中推出的 embed 库即可实现该效果 前后端数据交互 通常来说，HTML 展示出的页面内容中的数据通常分为两大类
静态 动态 在早期互联网不发达的时候，页面内容是不变的，数据也是静态的，但是随着互联网的发展，信息增多，一个页面的数据需要在用户操作时可以变化，此时就需要用到 AJAX 以动态的方式进行数据展示。
现在静态数据的网站已经很少见了，比如 DTCG 卡牌列表（截至 2023.12.19），这种就属于静态数据。静态数据有个弊端，就是哪怕不展示，也是全量加载，比如这个 卡牌列表 网站，虽然也分成了 4 页，但是在访问的时候，实际上是加载了所有页中的所有数据到前端，然后前端通过分页隐藏了其他页的数据。这种做法无形中增加了每次访问的流量，一共 4 页数据全加载了，但是真实情况却并不需要看到。</description></item><item><title>Programming tools</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Programming-tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Programming-tools/</guid><description>概述 参考：
Programming tools(编程工具)
构建系统 Make
Meson # Python 实现的构建系统
https://github.com/mesonbuild/meson https://www.techgrow.cn/posts/68d93948.html Ninja # C++ 编写的小型构件系统
https://github.com/ninja-build/ninja https://www.cnblogs.com/sandeepin/p/ninja.html 辅助 Lint 参考：
Wiki, Lint Lint 或 Linter 是一种静态代码分析工具，用于标记 编程错误、Bug、风格错误、可疑结构 等。该术语源自一个检查 C 语言代码的 Unix 程序。
现在泛指所有可以实现这种功能的程序，通常，每种编程语言都会开发出一个对应的 Linter，比如 Go 语言的 Staticcheck 就是 gopls。
AI 代码补全 https://github.com/getcursor/cursor # 一种基于 VSCode 的 IDE
https://github.com/cline/cline # IDE 插件+命令行工具
https://github.com/codota/TabNine
https://code.fittentech.com/
Copilot 现在网上卖的 Github Copilot 授权程序是什么原理？
cocopilot https://zhile.io/2023/09/09/github-got-banned.html
https://gitee.com/Tzeao/share-copilot
CodeGeeX GitHub 项目，THUDM/CodeGeeX2
介绍: https://www.bilibili.com/video/BV1Mj411676S
清华开源的更强大的多语言代码生成模型
CodeWhisperer https://github.com/aws/aws-toolkit-vscode</description></item><item><title>Promethesu Server</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Configuration/Promethesu-Server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Configuration/Promethesu-Server/</guid><description>概述 参考：
官方文档，配置 - 配置 官方文档，配置 - 命令行 - prometheus Prometheus Server 可通过两种方式来改变运行时行为
命令行标志 配置文件 配置文件热更新 Prometheus Server 可以在运行时重新加载其配置文件(也就俗称的热更新)。如果是新的配置不正确，则 Prometheus Server 则不会应用新的配置，并在日志中显示错误点。
有两种方式可以实现 Prometheus Server 的热更新功能
向 Prometheus Server 进程发送 SIGHUP 信号。 向 Prometheus Server 暴露的 /-/reload 端点发送 HTTP 的 POST 请求 注意：想要实现热更新功能，需要在 Prometheus Server 中指定 --web.enable-lifecycle 标志，这也将重新加载所有的 Rules 配置文件。
Prometheus Server 命令行标志详解 可以通过 prometheus -h 命令查看所有的可以用标志
prometheus 程序在启动时，可以使用一些标志来对程序进行一些基本设定，比如数据存储路径、存储时间等等
&amp;ndash;config.file(STRING) # Prometheus Server 的主配置文件。默认值: prometheus.yml，i.e. 当前目录下的 prometheus.yml 文件 &amp;ndash;enable-feature=&amp;hellip; # 启动指定的功能特性，多个功能以逗号分割。可以开启的功能详见：官方文档，已关闭的功能 &amp;ndash;web.</description></item><item><title>Prometheus</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Prometheus/Prometheus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Prometheus/Prometheus/</guid><description>概述 参考 Prometheus 文中关于 Prometheus Server 的部署我们发现，手动来维护 Prometheus Server 是相当费力的，而在 kubernetes 中，可以借助 operater 帮助我们来完成 Prometheus Server 的创建与维护工作，甚至连自动发现配置都可以。
Prometheus CRD 部署 当在 k8s 中部署了 operator 之后，部署 Prometheus Server 就变成了声明一个 Prometheus 资源。
这是声明一个 Prometheus 类型的资源的 manifest 示例：
apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: test namespace: monitor spec: replicas: 1 serviceAccountName: prometheus 注意：
由于 Prometheus Server 容器需要读取集群内其他资源对象的数据，所以需要给 Prometheus 资源生成的 Pod 一个足够权限的 serviceAccount。 kubectl create -n monitor serviceaccount prometheus kubectl create clusterrolebinding prometheus-admin --clusterrole=cluster-admin --serviceaccount=monitor:prometheus 声明好 Prometheus 资源，则会看到一个名为 test 的 Prometheus 对象；该对象会自动帮助我们创建一个名为 prometheus-test 的 Statefulsets 对象；这个 Statefulsets 中的 pod 包括 2 个容器，1 个 Prometheus Server 容器，和 1 个 sidecar container；还会有一个 service 来关联到这些 pod 上</description></item><item><title>Prometheus</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus/</guid><description>概述 参考：
官方文档 yunlzheng 写的电子书 GitHub 项目，Tencent-Cloud-Native/tkedocs(我个人总结完绝大部分文档后发现的这个项目) Prometheus 纪录片 YouTube B 站翻译 Prometheus 是由 SoundCloud 开发的 开源监控报警系统 和 时间序列数据库(TSDB)。使用 Go 语言开发，是 Google BorgMon 监控系统的开源版本。
题外话：Google 的 Borg 诞生了 kuberntes；Google 的 Borgmon 诞生了 Prometheus
2016 年由 Google 发起 Linux 基金会旗下的 Cloud Native Computing Foundation(云原生计算基金会), 将 Prometheus 纳入其下第二大开源项目。Prometheus 目前在开源社区相当活跃。
Prometheus 架构概述 Prometheus 的基本原理是通过 HTTP 协议周期性抓取被监控组件的状态，任意组件只要提供对应的 HTTP 接口就可以接入监控。不需要任何 SDK 或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如 VM、Docker、Kubernetes 等。输出被监控组件信息的 HTTP 接口被叫做 exporter 。
下面这张图说明了 Prometheus 的整体架构，以及生态中的一些组件作用：
Prometheus 生态圈中包含了多个组件，其中许多组件是可选的，多数 Prometheus 组件是 Go 语言写的，使得这些组件很容易编译和部署：</description></item><item><title>Prometheus API</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/Prometheus-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/Prometheus-API/</guid><description>概述 参考：
官方文档，Prometheus - 管理 API 官方文档，Prometheus - 查询 - HTTP API Prometheus 提供多种类型的 API 以满足不同需求。但是唯独没有可以修改配置的 API，Prometheus 的各种配置，只能通过重新加载修改后的配置文件这种方式来修改
Prometheus API 分两大块
HTTP API # HTTP 接口，用于查询数据、状态等。所以也称为 Querying API Management API # 管理接口，用于简单管理 Prometheus Server，重载配置，健康检查等</description></item><item><title>Prometheus Development</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/Prometheus-Development/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/Prometheus-Development/</guid><description>概述 参考：
GitHub 组织，prometheus Prometheus 源码目录结构 更新日期: 2024-12-18. Prometheus 的源码目录随着更新迭代，也在不断变化中
cmd/ # config/ # 用于处理 yaml 格式的配置文件，包含与配置文件对应内容的 struct。 discovery/ docs/ documentation/ model/ notifier/ plugins/ prompb/ promql/ rules/ scrape/ scripts/ storage/ template/ tracing tsdb/ util/ web/ Prometheus 通用包 参考：
GitHub, prometheus/common 该存储库包含在 Prometheus 组件和库之间共享的 Go 库。它们被认为是 Prometheus 内部的，外部使用没有任何稳定性保证。
config : 通用配置文件对应的 struct 很多 Prometheus 的周边都会使用该包中的内容比如 blackbox-exporter 的配置文件中，就引用了该包中的 HTTPClientConfig 结构体，作为配置文件内容的一部分。 expfmt : 展示格式的解码和编码 model：共享数据结构 promlog : go-kit/log 的日志包装器 route：使用 httprouter 的路由包装器 context.Context server：普通服务器 version：版本信息和指标 Go 客户端库 参考：</description></item><item><title>Prometheus MGMT</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/Prometheus-MGMT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/Prometheus-MGMT/</guid><description>概述 参考：
官方文档，介绍 - FAQ 公众号，Prometheus 性能调优：大模型和智能驾驶可观测的高基数问题
Prometheus UTS 时区问题 https://prometheus.io/docs/introduction/faq/#can-i-change-the-timezone-why-is-everything-in-utc
官方表示，为了避免夏令时问题，将 UTS 时区写入代码中，任何外部的配置都无法生效（e.g. 配置 /etc/timezone 无效）。
更多讨论在 issue 500
其实这个限制是不影响使用的：
如果做可视化，Grafana 是可以做时区转换的。 如果是调接口，拿到了数据中的时间戳，想怎么处理都可以。 如果因为 Prometheus 自带的 UI 不是本地时间，看着不舒服，2.16 版本的新版 Web UI 已经引入了 Local Timezone 的选项 如果仍然想改 Prometheus 代码来适应自己的时区，可以参考这篇文章。 对于 Prometheus 生态的程序，e.g. Node Exporter、etc. 也会有 UTS 时区问题，程序的日志时间就是 UTS 时区的，并且无法在程序实例化阶段通过代码修改，因为这些程序引用的是 promlog 库。promlog 在 log.go 中定义了日志的时区。
// This timestamp format differs from RFC3339Nano by using .000 instead // of .999999999 which changes the timestamp from 9 variable to 3 fixed // decimals (.</description></item><item><title>PromQL</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/PromQL/PromQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/PromQL/PromQL/</guid><description>概述 参考：
GitHub 项目，prometheus/prometheus - promql 查询结果数据结构 代码中的查询结果类型，与 Querying API 中描述的一致
从 web/api/v1/api.go 文件可以看到所有可用的 HTTP API，从 r.Get(&amp;quot;/query&amp;quot;, wrap(api.query)) 可以跳转到即时向量表达式的查询逻辑。
func (api *API) query(r *http.Request) (result apiFuncResult) { ...... return apiFuncResult{&amp;amp;queryData{ ResultType: res.Value.Type(), Result: res.Value, Stats: qs, }, nil, res.Warnings, qry.Close} } 代码中的查询结果类型，与 Querying API 中描述的一致，主要是 4 个字段：status、data 中的 resultType 与 result
type queryData struct { ResultType parser.ValueType `json:&amp;#34;resultType&amp;#34;` Result parser.Value `json:&amp;#34;result&amp;#34;` Stats *stats.QueryStats `json:&amp;#34;stats,omitempty&amp;#34;` } parser.Value 是一个接口
type Value interface { Type() ValueType String() string } 一共有 4 个结构体实现了该接口</description></item><item><title>PromQL</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/PromQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/PromQL/</guid><description>概述 参考：
官方文档，Prometheus - 查询 - 基础 Prometheus Query Language(Prometheus 查询语言，简称 PromQL) 是一种提供了查询功能的编程语言，用来实时选择和汇总 时间序列数据。通过 PromQL 可以对监控数据进行筛选、过滤、组合等等操作。使用 PromQL 编写的语句也可以称为 Expression(表达式)，表达式的结果可以通过其他方式显示为图形。
PromQL 体验 在 graph 页面，可以在红框位置输入表达式
点击红框内的对话框 并输入关键字，系统会自动弹出可用的 metrics name
表达式直接使用 MetricsName，则展示此时此刻的以 node_cpu_seconds_total 为指标名的所有 TimeSeries(时间序列) 数据
如果需要筛选则可以输入如下图实例的表达式：node_cpu_seconds_total{job=~&amp;ldquo;external.*&amp;rdquo;}
筛选出来 job 名开头是 external 的 cpu 情况。允许使用正则表达式，=~表示的就是用过正则来匹配后面的值
Prometheus 通过 MetricsName(指标名称) 及其对应的一组 LabelSet(标签集) 定义唯一的一条时间序列。指标名称反映了监控样本的基本标识，而 label 则在这个基本特征上为采集到的数据提供了多种特征维度。用户可以基于这些特征维度过滤，聚合，统计从而产生新的计算后的一条时间序列。
PromQL 是 Prometheus 内置的数据查询语言，其提供对时间序列数据丰富的查询，聚合以及逻辑运算能力的支持。并且被广泛应用在 Prometheus 的日常应用当中，包括对数据查询、可视化、告警处理当中。可以这么说，PromQL 是 Prometheus 所有应用场景的基础，理解和掌握 PromQL 是 Prometheus 入门的第一课。
PromQL 基本语法 PromQL 没有绝对通用的语法，在不同场景查询条件下，语法也不同。但是，语法必须要有语句，这种语句就称为 Expression(表达式)，Expression 可以是简单的字符串，也可以是一个指标名称，甚至是一串基于指标的复杂语法。
在 PromQL 中，任何 Expression(表达式) 或者 subExpression(子表达式) 都可以归为四种类型：</description></item><item><title>Promtail</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Promtail/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Promtail/</guid><description>概述 参考：
官方文档 GitHub 官方文档 公众号，Promtail Pipeline 日志处理配置 [!Attention] Grafana 弃用了 Promtail，推荐迁移到 Grafana Alloy
Promtail 是将本地日志内容发送到私有 Loki 或 Grafana Cloud 的代理。通常将其部署到 有监控需求的应用程序 的每台机器上。
promtail 通过类似于 tail 命令的这种方式来采集日志文件内容，采集完成后，添加 label，然后 push 给 Loki 。
Promtail 是 Loki 官方支持的日志采集端，在需要采集日志的节点上运行采集代理，再统一发送到 Loki 进行处理。除了使用 Promtail，社区还有很多采集日志的组件，比如 fluentd、fluent bit 等，都是比较优秀的。
但是 Promtail 是运行 Kubernetes 时的首选客户端，因为你可以将其配置为自动从 Promtail 运行的同一节点上运行的 Pod 中抓取日志。Promtail 和 Prometheus 在 Kubernetes 中一起运行，还可以实现非常强大的调试功能，如果 Prometheus 和 Promtail 使用相同的标签，用户还可以使用 Grafana 根据标签集在指标和日志之间切换。
此外如果你想从日志中提取指标，比如计算某个特定信息的出现次数，Promtail 效果也是非常友好的。在 Promtail 中一个 pipeline 管道被用来转换一个单一的日志行、标签和它的时间戳。
当前，Promtail 可以从两个来源 tail 日志</description></item><item><title>Python</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python/</guid><description>概述 参考：
官网 GitHub 组织，Python GitHub 项目，python/cpython CPython 源码解析 Python 编程语言最早由 C 语言实现，称为 CPython。还有其它的实现版本，不怎么用就不记了
学习资料 Hello World Python 范儿 Pythonic(Python 范儿)
Python 增强建议 参考：
官网 Python Enhancement Proposals(Python 增强建议，简称 PEP) 是 Python 社区用于提出新特性、改进和决策的标准化文档。每个 PEP 都有一个唯一的编号，通过提交和讨论的过程，最终由 Python 社区接受或拒绝。
PEP 的结构类似于 RFC（Request for Comments）文档，它们提供了一种标准化的方式来描述新功能的设计、实现和其他相关信息。PEP 中包含了详细的说明、背景、动机、语法示例等，以便开发者能够理解和评估提案。
项目结构 在 PEP518 中指定了 Python 项目的最低构建系统要求。
命名规范 代码格式 格式化工具(参考: https://zhuanlan.zhihu.com/p/203307235)：
black # 很好用 autopep8 yapf 知乎，代码规范与美观: Python Linter (Ruff) 和 Formatter (Black)
而 Black 和 Ruff 都支持从 pyproject.</description></item><item><title>Python 第三方库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</guid><description>概述 PyAutoGUI # 基于 opencv、 等工具实现的自动化工具，可以识别图像并调用鼠标和键盘操作这些识别到的图像。
HTTP requests # 由 urllib3 提供支持
文本处理 Beautiful Soup # 处理 HTML 和 XML 格式数据的库
数据处理 python-s3transfer #</description></item><item><title>Python 工具</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python%E5%B7%A5%E5%85%B7/Python-%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python%E5%B7%A5%E5%85%B7/Python-%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
安装 Python 包/模块 参考：
官方文档，安装 Python 模块 https://frostming.com/2019/03-13/where-do-your-packages-go/ 管理 Python 的模块和包所在路径非常乱，不知道是何原因。
PIP 是首选的安装程序。从 Python 3.4 开始，它默认包含在 Python 二进制安装程序中。就算你是用 pipenv，poetry，底层依然是 pip，一律适用。
运行 pip 有两种方式：
pip &amp;hellip; python -m pip &amp;hellip; 第一种方式和第二种方式大同小异，区别是第一种方式使用的 Python 解释器是写在 pip 文件的 shebang 里的，一般情况下，如果你的 pip 路径是 $path_prefix/bin/pip，那么 Python 路径对应的就是 $path_prefix/bin/python。如果你用的是 Unix 系统则 cat $(which pip) 第一行就包含了 Python 解释器的路径。第二种方式则显式地指定了 Python 的位置。这条规则，对于所有 Python 的可执行程序都是适用的。流程如下图所示。
那么，不加任何自定义配置时，使用 pip 安装包就会自动安装到 $path_prefix/lib/pythonX.Y/site-packages 下（$path_prefix 是从上一段里得到的），可执行程序安装到 $path_prefix/bin 下，如果需要在命令行直接使用 my_cmd 运行，记得加到 PATH。
刚刚安装完的 Python 一般只有 pip 和 setuptools 模块，site-packages 目录下内容如下：</description></item><item><title>Python 规范与标准库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</guid><description>概述 参考：
Python 语言参考描述了 Python 语言的具体语法和语义 Python 标准库则是与 Python 语言一起发行的一些可选功能，以便人们可以从一开始就轻松得使用 Python 进行编程。 内置模块 内置模块属于Python 规范与标准库的一部分。这部分内置模块内嵌到解释器里面（也就是说无法在文件系统中找到与模块名相同的同名文件），它们给一些虽并非语言核心但却内嵌的操作提供接口，要么是为了效率，要么是给操作系统基础操作例如系统调入提供接口。 这些模块集是一个配置选项， 并且还依赖于底层的操作系统。 例如，winreg 模块只在 Windows 系统上提供。一个特别值得注意的模块 sys，它被内嵌到每一个 Python 编译器中，sys 模块是 CPython 非常重要的内置模块，也是很多功能的基础模块。
&amp;gt;&amp;gt;&amp;gt; import sys &amp;gt;&amp;gt;&amp;gt; sys.builtin_module_names (&amp;#39;_abc&amp;#39;, &amp;#39;_ast&amp;#39;, &amp;#39;_bisect&amp;#39;, &amp;#39;_blake2&amp;#39;, &amp;#39;_codecs&amp;#39;, &amp;#39;_codecs_cn&amp;#39;, &amp;#39;_codecs_hk&amp;#39;, &amp;#39;_codecs_iso2022&amp;#39;, &amp;#39;_codecs_jp&amp;#39;, &amp;#39;_codecs_kr&amp;#39;, &amp;#39;_codecs_tw&amp;#39;, &amp;#39;_collections&amp;#39;, &amp;#39;_contextvars&amp;#39;, &amp;#39;_csv&amp;#39;, &amp;#39;_datetime&amp;#39;, &amp;#39;_functools&amp;#39;, &amp;#39;_heapq&amp;#39;, &amp;#39;_imp&amp;#39;, &amp;#39;_io&amp;#39;, &amp;#39;_json&amp;#39;, &amp;#39;_locale&amp;#39;, &amp;#39;_lsprof&amp;#39;, &amp;#39;_md5&amp;#39;, &amp;#39;_multibytecodec&amp;#39;, &amp;#39;_opcode&amp;#39;, &amp;#39;_operator&amp;#39;, &amp;#39;_pickle&amp;#39;, &amp;#39;_random&amp;#39;, &amp;#39;_sha1&amp;#39;, &amp;#39;_sha256&amp;#39;, &amp;#39;_sha3&amp;#39;, &amp;#39;_sha512&amp;#39;, &amp;#39;_signal&amp;#39;, &amp;#39;_sre&amp;#39;, &amp;#39;_stat&amp;#39;, &amp;#39;_statistics&amp;#39;, &amp;#39;_string&amp;#39;, &amp;#39;_struct&amp;#39;, &amp;#39;_symtable&amp;#39;, &amp;#39;_thread&amp;#39;, &amp;#39;_tracemalloc&amp;#39;, &amp;#39;_warnings&amp;#39;, &amp;#39;_weakref&amp;#39;, &amp;#39;_winapi&amp;#39;, &amp;#39;_xxsubinterpreters&amp;#39;, &amp;#39;array&amp;#39;, &amp;#39;atexit&amp;#39;, &amp;#39;audioop&amp;#39;, &amp;#39;binascii&amp;#39;, &amp;#39;builtins&amp;#39;, &amp;#39;cmath&amp;#39;, &amp;#39;errno&amp;#39;, &amp;#39;faulthandler&amp;#39;, &amp;#39;gc&amp;#39;, &amp;#39;itertools&amp;#39;, &amp;#39;marshal&amp;#39;, &amp;#39;math&amp;#39;, &amp;#39;mmap&amp;#39;, &amp;#39;msvcrt&amp;#39;, &amp;#39;nt&amp;#39;, &amp;#39;sys&amp;#39;, &amp;#39;time&amp;#39;, &amp;#39;winreg&amp;#39;, &amp;#39;xxsubtype&amp;#39;, &amp;#39;zlib&amp;#39;) 注意：并不是所有内置模块都能在 sys.</description></item><item><title>Python 环境安装与使用</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>概述 参考：
官方文档，Python 的安装与使用 安装 Python Linux 各 Linux 发行版通常都会自带 Python
自定义 Python 由于 Python 模块与包 的管理非常混乱，我们有没有办法像 Go 一样，依靠一个 GOPATH 即可统一管理呢？可以，当我们了解了模块搜索路径的底层原理之后，即可开始着手将 Python 的依赖都移动到指定的目录
对于 root 用户来说，GOPATH 默认在 /root/go，那我们就将 PYTHONHOME 设为 /root/python，开始吧(注意这里要用绝对路径，不要使用 ~)
export PYTHON_VERSION=&amp;#34;3.10&amp;#34; mkdir -p /root/python/lib cp /usr/bin/python${PYTHON_VERSION} /root/python cp -ax -r /usr/lib/python${PYTHON_VERSION} /root/python/lib 准备工作完成了，此时我们只需要修改 ${PYTHONHOME} 或者将 /root/python 加入 ${PATH} 变量中即可
export PATH=/root/python:$PATH ~]# python${PYTHON_VERSION} Python 3.10.6 (main, Nov 14 2022, 16:10:14) &amp;gt;&amp;gt;&amp;gt; import sys &amp;gt;&amp;gt;&amp;gt; sys.prefix &amp;#39;/root/python&amp;#39; &amp;gt;&amp;gt;&amp;gt; sys.</description></item><item><title>RabbitMQ</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ/</guid><description>概述 参考：
官方网址 消息队列模拟器 https://www.yuque.com/noobwo/mq/hpiop0 https://m.6-km.com/next/quorum-queues.html https://zhuanlan.zhihu.com/p/63700605 Rabbit Message Queue(Rabbit 消息队列，简称：RabbitMQ)。是一个在 AMQP 基础上实现的，可复用的消息队列服务。
Advanced Message Queuing Protocol(高级消息队列协议，简称 AMQP) ，是一个提供统消息服务的应用层(7 层)协议。其设计目标是对于消息的排序、路由（包括点对点和订阅-发布）、保持可靠性、保证安全性[1]。AMQP 规范了消息传递方和接收方的行为，以使消息在不同的提供商之间实现互操作性，就像 SMTP，HTTP，FTP 等协议可以创建交互系统一样。与先前的中间件标准（如 Java 消息服务）不同的是，JMS 在特定的 API 接口层面和实现行为上进行了统一，而高级消息队列协议则关注于各种消息如何以字节流的形式进行传递。因此，使用了符合协议实现的任意应用程序之间可以保持对消息的创建、传递。
工作机制概述 在了解消息通讯之前首先要了解 3 个概念：生产者、消费者和代理。
Publisher(生产者)：消息的创建者，负责创建和推送数据到消息服务器；
Consumer(消费者)：消息的接收方，用于处理数据和确认消息；
Broker(代理)：就是 RabbitMQ 本身，用于扮演“快递”的角色，本身不生产消息，只是扮演“快递”的角色。
消息发送原理
首先你必须连接到 Rabbit 才能发布和消费消息，那怎么连接和发送消息的呢？
你的应用程序和 Rabbit Server 之间会创建一个 TCP 连接，一旦 TCP 打开，并通过了认证，认证就是你试图连接 Rabbit 之前发送的 Rabbit 服务器连接信息和用户名和密码，有点像程序连接数据库，使用 Java 有两种连接认证的方式，后面代码会详细介绍，一旦认证通过你的应用程序和 Rabbit 就创建了一条 AMQP 信道（Channel）。
信道是创建在“真实”TCP 上的虚拟连接，AMQP 命令都是通过信道发送出去的，每个信道都会有一个唯一的 ID，不论是发布消息，订阅队列或者介绍消息都是通过信道完成的。
为什么不通过 TCP 直接发送命令？
对于操作系统来说创建和销毁 TCP 会话是非常昂贵的开销，假设高峰期每秒有成千上万条连接，每个连接都要创建一条 TCP 会话，这就造成了 TCP 连接的巨大浪费，而且操作系统每秒能创建的 TCP 也是有限的，因此很快就会遇到系统瓶颈。</description></item><item><title>Rclone</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rclone/Rclone/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rclone/Rclone/</guid><description>概述 参考：
GitHub 项目，rclone/rclone 官网 Rclone 是一个命令行工具，用来管理云存储上的文件。Rclone 也可以看作 rsync for cloud storage(用于云存储的 rsync)。Rclone 支持各种存储类型，包括 商业文件存储服务、标准传输协议(比如 WebDAV、S3 等)、等等。从这里我们可以查看到所有受支持的存储提供者
Rclone 将存储提供者抽象为 Remote，在我们配置 Rclone 时，经常会看到 Remote 这个词，创建、删除 Remote 这种行为，就是在 INI 格式的配置文件中配置 Remote。这些 Remote 由指定类型的 Backend 提供支持。
比如，我们可以这样描述: 我创建了一个名为 alist 的 Remote，使用的是 WebDav 类型的 Backend。
Rclone 还可以将这些 Remote 作为磁盘挂载在 Windows、macOS、Linux 上，并通过 SFTP、HTTP、WebDAV、FTP、DLNA 对外提供存储能力。
Rclone 安装 rclone 的挂载使用 FUSE，需要安装 winfsp。
Rclone 关联文件与配置 rclone.conf # 各种 Remotes 信息。
如果在某些已定义的位置都没有找到 rclone.conf 文件，则会在以下位置创建一个新的配置文件： Windows 上 在 $APPDATA/rclone/rclone.conf 类 Unix 上 如果定义了 $XDG_CONFIG_HOME，则在 $XDG_CONFIG_HOME/rclone/rclone.</description></item><item><title>Redis CLI</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/Redis-CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/Redis-CLI/</guid><description>概述 参考：
官方文档 中文 redis-cli - 命令行客户端 help # 按 TAB 键遍历所有组以及对应的命令
help @ # 获取在指定 group 中的命令列表
help # 获取指定 command 的帮助信息
Group 列表 generic # 通用的 不同数据类型的数据处理命令 string etc. pubsub # 发布与订阅 connection # redis 的客户端与服务端连接相关的命令 server # 关于 redis 服务器的相关命令，包括查看配置等 etc. generic 详见：generic 组
主要是对 key 的操作，比如列出所有 key，删除 key 等等。一般在列出 key 时无法获取对应的 value
不同类型的数据处理命令组 string 详见：string 组
主要是对于 value 的操作，比如对指定的一个或多个 key 的 value 进行增、删、改、查。
list set sorted_set hash hash 组下的所有命令用于管理 hash 数据类型的数据</description></item><item><title>Redis 高可用</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/</guid><description>概述 参考：
原文 知乎 微信公众号 Redis 支持三种高可用方案
Replication(复制) 模式 实际上，该模式并不是绝对的高可用，仅仅保证了数据的不丢失 Sentinel(哨兵) 模式 Cluster(集群) 模式 Cluster(集群) http://www.redis.cn/topics/cluster-tutorial.html
https://redis.io/topics/cluster-tutorial
客户端操作原理(请求路由原理) 请求重定向 在集群模式下，Redis 接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点，如果节点是自身，则处理键命令；否则回复 MOVED 重定向错误，通知客户端请求正确的节点。这个过程称为 MOVED 重定向。
# 如果key经过计算后，其分配的slot就在当前节点，那么可以请求成功，否则，回复重定向消息 [root@node01 redis]# redis-cli -h 10.0.0.100 -p 6379 10.0.0.100:6379&amp;gt; set name tom OK 10.0.0.100:6379&amp;gt; set age 20 (error) MOVED 741 10.0.0.101:6379 重定向信息包含了键所对应的槽以及负责该槽的节点地址，根据这些信息客户端就可以向正确的节点发起请求。在 10.0.0.101:6379 节点上成功执行之前的命令：
[root@node02 redis]# redis-cli -h 10.0.0.101 -p 6379 10.0.0.101:6379&amp;gt; set age 20 OK 使用 redis-cli 命令时，可以加入-c 参数支持自动重定向，简化手动发起重定向的操作：
[root@node01 redis]# redis-cli -c -h 10.</description></item><item><title>Redis 管理</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E7%AE%A1%E7%90%86/Redis-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E7%AE%A1%E7%90%86/Redis-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
官方文档，Redis 管理 https://redis.io/docs/latest/operate/oss_and_stack/management/admin/ 在生产中配置和管理 Redis 的建议。
概述 参考：
官方中文文档 官方优化建议
我们建议使用 linux 部署 Redis。Redis 也在 osx，FreeBSD，OpenBSD 上经过测试，但 Linux 经过所有主要的压力测试，并且最多产品部署。 确保设置 Linux 内核 overcommit memory setting 为 1。向/etc/sysctl.conf 添加 vm.overcommit_memory = 1 然后重启，或者运行命令 sysctl vm.overcommit_memory=1 以便立即生效。 确保禁用 Linux 内核特性 transparent huge pages，它对内存使用和延迟有非常大的负面影响。通过命令 echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled 来完成。 确保你的系统设置了一些 swap（我们建议和内存一样大）。如果 linux 没有 swap 并且你的 redis 实例突然消耗了太多内存，或者 Redis 由于内存溢出会宕掉，或者 Linux 内核 OOM Killer 会杀掉 Redis 进程。 设置一个明确的 maxmemory 参数来限制你的实例，以便确保实例会报告错误而不是当接近系统内存限制时失败 如果你对一个写频繁的应用使用 redis，当向磁盘保存 RDB 文件或者改写 AOF 日志时，redis 可能会用正常使用内存 2 倍的内存。额外使用的内存和保存期间写修改的内存页数量成比例，因此经常和这期间改动的键的数量成比例。确保相应的设置内存的大小。 当在 daemontools 下运行时，使用 daemonize no 即使你禁用持久化，如果你使用复制，redis 会执行 rdb 保存，除非你使用新的无磁盘复制特性，这个特性目前还是实验性的。 如果你使用复制，确保要么你的 master 激活了持久化，要么它不会在当掉后自动重启。slave 是 master 的完整备份，因此如果 master 通过一个空数据集重启，slave 也会被清掉。 Redis 延迟问题疑难解答</description></item><item><title>Reverse engineering</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Reverse-engineering/Reverse-engineering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Reverse-engineering/Reverse-engineering/</guid><description>概述 参考：
Wiki, Reverse engineering(逆向工程) 逆向工程的其他目的包括安全审核、消除复制保护（“破解”）、规避消费电子产品中常见的访问限制、定制嵌入式系统（例如引擎管理系统）、内部维修或改造、低成本“残缺”硬件（例如某些显卡芯片组）上的附加功能，甚至只是满足好奇心。
学习 吾爱破解
https://www.52pojie.cn/thread-1695141-1-1.html 吾爱破解安卓逆向入门教程《安卓逆向这档事》一、模拟器环境搭建 吾爱破解安卓逆向入门教程《安卓逆向这档事》十五、是时候学习一下Frida一把梭了(下) 图灵 Python 何老师相关课程
李玺
https://github.com/lixi5338619 http://www.lxspider.com/ 博客 https://github.com/lixi5338619/lxBook 《爬虫逆向进阶实战》 https://space.bilibili.com/390499740/channel/collectiondetail?sid=468228&amp;ctype=0 实战示例视频 常见安全策略 JS 混淆
在 Fetch/XHR 的请求中，从开发者工具查看该请求的启动器，如果函数名、变量名都是 _0x5601f0 这类以 _0x 开头的，说明代码是经过混淆的 数据 RSA、AES、etc. 加密
APP 加固
APP 加壳
逆向常用工具 x64dbg # 适用于 Windows 的开源用户模式调试器。针对逆向工程和恶意软件分析进行了优化。
GitHub 项目，x64dbg/x64dbg https://x64dbg.com/ 想要程序注册码（密码）？？翻找内存找到它！！——x64dbg 逆向动态调试简单crackme，找注册码（密码） 可以代替 OllyDbg Cheat Engine # Cheat Engine 是一个专注于修改个人使用的游戏和应用程序的开发环境。
GitHub 项目，cheat-engine/cheat-engine Packet analyzer
http://www.cnlans.com/lx/tools 李玺的爬虫逆向工具
https://github.com/BlackINT3/OpenArk # 一款Windows平台上的开源Ark工具. Ark是Anti-Rootkit（对抗恶意程序）的简写, OpenArk目标成为逆向工程师、编程人员的工具，同时也能为那些希望清理恶意软件的用户服务。
反编译 IDA Pro # Interactive Disassembler Professional</description></item><item><title>Rook</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook/</guid><description>概述 参考：
官方文档：https://rook.github.io/docs/rook/master/ Rook 是一个开源的 cloud-native storage orchestrator(云原生存储协调器), 提供平台和框架；为各种存储解决方案提供平台、框架和支持，以便与云原生环境本地集成。Rook 作为云原生存储的编排系统，可以直接帮助维护人员管理有状态的存储程序。可以说是一个 SAAS，Storage as a service。
Rook 将存储软件转变为自我管理、自我扩展和自我修复的存储服务，它通过自动化部署、引导、配置、置备、扩展、升级、迁移、灾难恢复、监控和资源管理来实现此目的。
Rook 目前支持 Ceph、NFS、Minio Object Store、CockroachDB 等。这些存储的作用其中之一就是为各个业务提供存储空间，以便统一管理。e.g.使用 Rook 创建一个分布式的 ceph 集群，然后作为 k8s 集群的 storageClass，在某 Pod 需要使用卷的时候，可以直接从 ceph 集群中，拿去存储空间来使用。
Rook 使用底层云本机容器管理、调度和编排平台提供的工具来实现它自身的功能。
Rook 使用 Kubernetes 原语使 Ceph 存储系统能够在 Kubernetes 上运行。下图说明了 Ceph Rook 如何与 Kubernetes 集成：
随着 Rook 在 Kubernetes 集群中运行，Kubernetes 应用程序可以挂载由 Rook 管理的块设备和文件系统，或者可以使用 S3 / Swift API 提供对象存储。Rook oprerator 自动配置存储组件并监控群集，以确保存储处于可用和健康状态。
Rook oprerator 是一个简单的容器，具有引导和监视存储集群所需的全部功能。oprerator 将启动并监控 ceph monitor pods 和 OSDs 的守护进程，它提供基本的 RADOS 存储。oprerator 通过初始化运行服务所需的 pod 和其他组件来管理池，对象存储（S3 / Swift）和文件系统的 CRD。</description></item><item><title>RPC</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/RPC/RPC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/RPC/RPC/</guid><description>概述 参考：
Wiki, RPC Wiki, gRPC gRPC 官网 在分布式计算中，Remote Procedure Call(远程过程调用，简称 RPC) 是计算机程序使 Subroutine 在不同的地址空间（通常在共享网络上的另一台计算机上）执行时，被编码为 Local Procedure Call(本地过程调用)，而无需程序员为远程交互显式编写细节。也就是说，程序员可以为程序编写相同的代码，而不用关心自己编写的程序将会被本地调用还是远程调用。
其实 LPC 和 RPC 并不是对比的最佳选择，两者都 IPC 的一种方式，也就是说都是两个进程间通讯的一种方式，可能来说，LPC 与 RPC 最大的区别在于是否基于 TCP/IP 来让两个进程进行通信。而如果从网络间两个进程通信的角度看，RPC 又可以与 HTTP 进行对比。
从某种角度来说， HTTP 其实就是一种 RPC
HTTP 发起请求的 URL 就是 RPC 发起请求的函数名 请求体就是函数的参数 响应体就是函数的函数中的处理逻辑或返回值 只不过 HTTP 是一个协议(也可以说是一种交互标准)，而 RPC 是一种方式、方法，可以使用 HTTP 来进行 RPC 通信，也可以使用其他协议进行 RPC 通信。如果使用 HTTP 标准进行 RPC 通信，那 RPC 的 C/S 之间就是通过文本格式进行交互；但是 RPC 通信最常使用的是 Protobuf 数据格式进行通信。
这里说的使用“HTTP 进行 RPC 通信”指的是使用 xml、json 等格式的数据进行 RPC 通信。而在很多 RPC 框架中，RPC 之间交互的信息与 HTTP 之间交互的信息，是可以互通的！~</description></item><item><title>RSA</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/RSA/RSA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/RSA/RSA/</guid><description>概述 参考：
Wiki, RSA RSA 生成的密钥对，私钥用来签名，公钥用来加密。
举个例子，公钥公开出去，加密密码，交给服务端，服务端可以使用私钥解密从中获取密码，加密后续传输的消息后，使用私钥签名；客户端使用公钥验证收到的消息是否是真实客户端的消息，验证成功后，使用密码解密。
这个场景，需要如下几个东西 RSA 的公钥与私钥 用于加密密码的算法，比如 AES 随机生成的 XX 位密码，比如 16 位字符串密钥 想要发送的数据，称为 reqBody 接收到的数据，称为 respBody 首先客户端生成 XX 位的字符串作为密钥，使用公钥加密密码后，得到 key；同时使用密码通过 AES 的算法加密 reqBody。 这样，就保证了数据的隐私性 将 key 与 加密后的 reqBody 一起发送给服务端 服务端使用私钥解密 key 后得到密钥，再使用密码通过 AES 的算法解密接收到的 reqBody 服务端处理请求后，再次使用密码加密 respBody，之后使用私钥对 加密后的 respBody 进行签名 这样，保证了数据的真实性 将 签名后的已加密的 respBody 发送给客户端 客户端使用公钥验证签名以确保数据是服务端发来的没有被拦截篡改，之后使用 key 解密 respBody 后得到真实的响应数据。</description></item><item><title>Rule</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/Rule/Rule/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/Rule/Rule/</guid><description>概述 参考：
GitHub 项目，prometheus/prometheus - rules 公众号 - 运维开发故事，prometheus告警规则管理 接口 代码：./rules/manager.go —— Rule{}
Rule 接口封装了一个向量表达式，在指定的时间间隔评估规则。Prometheus 将规则分为两类：Recording Rule(记录规则) 与 Alerting Rule(告警规则)，所以将处理这两种规则的方法统一成一个接口，如下两个结构体实现了该接口：
./rules/alerting.go —— AlertingRule{} ./rules/recording.go —— RecordingRule{} type Rule interface { // 直接返回规则的名称 Name() string // Labels of the rule. Labels() labels.Labels // 评估规则(规则处理逻辑中最重要的部分) Eval(context.Context, time.Time, QueryFunc, *url.URL) (promql.Vector, error) // String returns a human-readable string representation of the rule. String() string // Query returns the rule query expression. Query() parser.Expr // SetLastErr sets the current error experienced by the rule.</description></item><item><title>Scheduling</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/Scheduling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/Scheduling/</guid><description>概述 参考：
官方文档，概念 - 调度、抢占与驱逐 Scheduling(调度) 是一个行为，用来让 Pod 匹配到 Node，以便 Node 上的 Kubelet 可以运行这些 Pod。如果没有调度系统，Kubernetes 集群就不知道 Pod 应该运行在哪里。这种调度的概念，与 Linux 中调度任务来使用 CPU 是一个意思。可以看看 Scheduler 相关文章，调度是在 IT 行业中，很多程序都很重要的概念。
与 Scheduling(调度) 伴生的，还有 Preemption(抢占) 与 Eviction(驱逐) 两个概念。顾名思义：
Preemption(抢占) 是指终止优先级较低的 Pod 的行为，以便优先级较高的 Pod 可以在节点上调度。 抢占行为通常发生在资源不足时，当一个新 Pod 需要调度，但是资源不足，那么就可能需要抢占优先级低的 Pod，这个低优先级的 Pod 将会被驱逐，以便让优先级高的 Pod 运行在节点上。 Eviction(驱逐) 是指终止节点上一个或多个 Pod 的行为。 由 抢占 与 驱逐 两个行为，还引申出了 Pod Disruption(中断) 的概念。Pod Disruption(中断) 是指节点上的 Pod 自愿或者非资源终止运行的行为。
自愿中断是由应用程序所有者或者集群管理故意启动的(比如.维护节点前手动驱逐 Pod) 非自愿中断是无意的，可能由不可避免的问题触发(比如.节点资源耗尽或意外删除)</description></item><item><title>SCM</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/SCM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/SCM/</guid><description>概述 参考：
SCM(Software Configuration Management，软件配置管理系统)。
SCM(Source Control Management，源代码控制管理系统)。
Git、Subversion(SVN)、CVS、Perforce、ClearCase 等都可以称为 SCM。
可以称为 SCM 的在线网站：
GitLab GitHub SourceForge GNU/git SCM 可以算是源码管理相关工具的统称。</description></item><item><title>Security software</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Security-software/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Security-software/</guid><description>概述 参考：
Snort
Yara
Suricata
Suricata 是由 OISF 和 Suricata 社区开发的网络入侵检测系统、入侵防御系统和网络安全监控引擎。 https://github.com/OISF/suricata 可以把 Snort 规则转成 Suricata 规则，把相同的流量交给 Suricata 和 Snort 分别处理看看结果 Yara 参考：
GitHub 项目，virustotal/yara 官网 Wiki, YARA YARA 是一款旨在（但不限于）帮助恶意软件研究人员识别和分类恶意软件样本的工具。使用 YARA，您可以根据 文本 或 二进制 模式创建恶意软件系列（或您想要描述的任何内容）的描述。每个描述（也称为规则）由一组字符串和一个决定其逻辑的布尔表达式组成。让我们看一个例子：
rule silent_banker : banker { meta: description = &amp;#34;This is just an example&amp;#34; threat_level = 3 in_the_wild = true strings: $a = {6A 40 68 00 30 00 00 6A 14 8D 91} $b = {8D 4D B0 2B C1 83 C0 27 99 6A 4E 59 F7 F9} $c = &amp;#34;UVODFRYSIHLNWPEJXQZAKCBGMT&amp;#34; condition: $a or $b or $c } 安全系统提供商 数美科技 https://www.</description></item><item><title>SNMP Exporter</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/SNMP-Exporter/SNMP-Exporter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/SNMP-Exporter/SNMP-Exporter/</guid><description>概述 参考：
GitHub 项目，prometheus/snmp_exporter Snmp Exporter 通过 snmp 采集监控数据，并转换成[ OpenMetrics 格式](&amp;lt;/docs/6.可观测性/监控系统/监控系统概述/HTTP(新监控标准).md&amp;raquo;)的指标。
在这个项目中，有两个组件，
Exporter(导出器) # 通过 snmp 抓去指标数据并转换成 OpenMetrics 格式 Generator(生成器) # 生成 Exporter 的配置文件。 Exporter(导出器) snmp_exporter 启动后默认监听在 9116 端口上。snmp_exporter 会根据 snmp.yml 配置文件中的配置规则抓取 snmp 数据并转换成 Metrics 格式的数据。
Prometheus Server 抓取 metircs 的 http 请求样例： http://IP:PORT/snmp?module=if_mib&amp;amp;target=TargetIP # 获取 TargetIP 上的 snmp 信息，并转换成 metrics 格式，其中 module=if_mib 是可省的，若不指定 module，则抓取所有 module。
snmp exporter 源码简单解析
// 这个结构体实现了 prometheus.Collector 接口 type collector struct { // ......略 } // 采集 Metrics 的主要逻辑在这里，这里省略了很多不相关的代码 func (c collector) Collect(ch chan&amp;lt;- prometheus.</description></item><item><title>SQL</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/SQL/SQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/SQL/SQL/</guid><description>概述 参考：
ISO/IEC 9075-1:2023 Wiki, SQL 菜鸟教程，SQL Structured Query Language(结构化查询语言，简称 SQL) 是一种特定领域的编程语言，用于管理 RDBMS(关系数据库管理系统) 中保存的数据。使用 SQL 编写的语句也可以称为 Expression(表达式)。
SQL 在 1986 年成为 ANSI 的一项标准，在 1987 年成为国际标准化组织（ISO）标准。
每种关系型数据库所使用的 SQL 基本都一样，但是又有其自身特殊的 SQL。由于 MySQL 的使用率非常高，所以 SQL 文档的各种例子都以 MySQL 为主。
学习资料 w3schools, SQL
菜鸟教程，SQL
GitHub 项目，liyupi/sql-mother
程序员鱼皮，SQL 自学网站 SQL 标准 Year Name Alias Comments 1986 SQL-86 SQL-87 First formalized by ANSI 1989 SQL-89 FIPS 127-1 Minor revision that added integrity constraints adopted as FIPS 127-1 1992 SQL-92 SQL2, FIPS 127-2 主要修订 (ISO 9075), Entry Level SQL-92 adopted as FIPS 127-2 1999 SQL:1999 SQL3 Added regular expression matching, recursive queries (e.</description></item><item><title>SSL 与 TLS</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/SSL_TLS/SSL-%E4%B8%8E-TLS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/SSL_TLS/SSL-%E4%B8%8E-TLS/</guid><description>概述 参考：
Wiki, TLS 为了解决人类在互联网世界信息的安全性，所研究出来的相关技术
安全机制：加密、数字签名、访问控制、数据完整性、认证交换、流量填充、路由控制、公证
安全服务：认证、访问控制、数据保密性(连接保密性、无连接保密性、选择与保密性、流量保密性)、数据完整性、不可否认性
SSL/TLS 介绍 Secure Socket Layer(安全的套接字层，简称 SSL) # 一个安全协议
Transport Layer Security(传输层安全，简称 TLS)# SSL3.0 的升级版
SSL/TLS 就是在应用层与传输层中间又加了半层，应用层协议可以自行决定改层的功能，比如 http 协议用了这半层，就是 https。
SSL/TLS 的分层设计
最底层，基础算法原语的实现，比如 aes，rsa，md5 等 各种算法的实现 组合算法实现的半成品 用各种组件拼装而成的各种成品密码学协议/软件，tls,ssh 等 openssh 也是用 openssl 实现的软件 key(密钥) # 在密码学中，是指某个用来完成加密、解密、完整性验证等密码学应用的秘密信息。对于加密算法，key 指定明文转换成密文；对于解密算法，key 指定密文转换成明文
Plaintext or Cleartext(明文) # 在密码学中，明文是未加密的信息，可以供人类和计算机读取的信息 Ciphertext or Cyphertext(密文)# 在密码学中，密文是明文通过加密算法计算后生成的人类或计算器无法读取的一种信息 PKI：Public Key Infrastructure(公开密钥基础建设，简称 PKI)，又称公开密钥基础架构、公钥基础建设、公钥基础设施、公开密码匙基础建设或公钥基础架构，是一组由硬件、软件、参与者、管理政策与流程组成的基础架构，其目的在于创造、管理、分配、使用、存储以及撤销数字证书。
PKI 是借助 CA（权威数字证书颁发/认证机构）将用户的个人身份跟公开密钥链接在一起，它能够确保每个用户身份的唯一性，这种链接关系是通过注册和发布过程实现，并且根据担保级别，链接关系可能由 CA 和各种软件或在人为监督下完成。PKI 用来确定链接关系的这一角色称为 RA（Registration Authority, 注册管理中心），RA 能够确保公开密钥和个人身份链接，可以防抵赖，防篡改。在微软的公钥基础建设下，RA 又被称为 CA，目前大多数称为 CA。</description></item><item><title>Storage</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Storage/Storage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Storage/Storage/</guid><description>概述 参考：
官方文档，存储 GitHub 项目 prometheus/prometheus，tsdb GitHub 文档，TSDB format 简书，Prometheus 存储机制 公众号，Prometheus 存储流向 以下所有内容均基于 Prometheus 2.27+ 版本 Prometheus 自身就包含一个 Time Series Database(时间序列数据库)，所以 Prometheus 采集完指标数据后，可以保存在本地，由 Prometheus 自身来管理这些数据。当然，Prometheus 也可以通过一种称为 Remote Write 的技术，将数据存储到 Remote Storage Systems(远程存储系统)。
本地存储限制了 Prometheus 的可扩展性，带来了数据持久化、高科用等一系列的问题。为了解决单节点存储的限制，Prometheus 没有自己实现集群存储，而是提供了远程读写的接口，让用户自己选择合适的时序数据库来实现 Prometheus 的扩展性。
Local Storage(本地存储) 注意： Prometheus 的本地存储不支持不兼容 POSIX 的文件系统，因为可能会发生不可恢复的损坏。不支持 NFS 文件系统（包括 AWS 的 EFS）。NFS 可能符合 POSIX，但大多数实现均不符合。强烈建议使用本地文件系统以提高可靠性。Prometheus 启动时会有如下 warn：
并且，经过实践，在数据量足够多时，当 Prometheus 压缩数据时，有不小的概率会丢失某个 Block 中的 meta.json 文件。进而导致压缩失败，并频繁产生告警，详见故障：compaction failed
Prometheus 的本地时间序列数据库将数据以自定义的高效格式存储在本地存储上。也就是说，Prometheus 采集到的指标数据，以文件的形式直接保存在操作系统的文件系统中。On-disk Layout 章节将会详细介绍这些数据在本地存储中布局。
On-disk Layout(磁盘上的布局) 本地存储的目录看起来应该是下面这个样子：</description></item><item><title>Storage Classes(存储类)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/</guid><description>概述 参考：
官方文档，概念-存储-存储类 官方文档，任务-管理集群-改变默认 StorageClass 在介绍的 [PV](/docs/10.云原生/2.3.Kubernetes%20 容器编排系统/9.Kubernetes%20 存储/Persistent%20Volume(持久卷).md Volume(持久卷).md) 时有个问题就是管理员需要先创建 pv 固定好容量，再让用户或者开发创建的 PVC 从中挑选，有时候 PVC 申请的时候未必会有满足容量要求的 PV 可以提供，甚至管理员维护大量的 PV 的工作也是非常繁重的。为了实现在创建完 PVC 后，K8S 可以自动创建 PV 的功能，则可以使用 Storage Class(存储类) 这个资源对象来满足这类需求。
Storage Class(存储类)，就像这个名字一样，Storage Class 是一个抽象的概念，用来抽象存储资源。一般情况都是把同类型的存储归为一类，比如 ssd 类型、hdd 类型等等，也可以按照功能划分，给订单组用的存储，给数据组用的存储等等。说白了，Storage Class 就是一块存储空间。
创建完 StorageClass 后，直接创建 PVC 并指定 storageClassName 参数的值为该 StorageClass 的名字，即可自动生成 PV，而不用手动创建。然后在 pod 中直接使用 PVC 作为 volume 进行挂载即可。
Storage Class 的实现方式 Storage Class Name(名字) Storage Class Name(存储类的名字) 是 PV、PVC 选择的标准，PV 与 PVC 总是会选择具有相同名字的 StorageClass 来进行配对。</description></item><item><title>Storage(存储)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Storage%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Storage%E5%AD%98%E5%82%A8/</guid><description>概述 参考：
官方文档，存储 官方文档，运维 - 存储 https://grafana.com/blog/2023/12/20/the-concise-guide-to-grafana-loki-everything-you-need-to-know-about-labels/ 与其他日志记录系统不同，Loki 是基于仅索引日志的元数据的想法而构建的。从 [Loki 的数据模型](/docs/6.可观测性/日志系统/Loki/Storage(存储)/Data%20Model(数据模型).md Model(数据模型).md)可知，日志是根据标签进行定位的。 日志数据本身会被压缩成 Chunks，并存储在本地的文件系统中；并且 Loki 还提供了一个 Index 数据，用来根据索引定位日志数据。小索引和高度压缩的 Chunks 简化了操作，并显着降低了 Loki 的成本。
所以 Loki 需要存储两种不同类型的数据，当 Loki 收到 Log Stream 时，会存储两类数据：
Chunk(块) # 日志流本身的信息。每一个 Chunk 都是将一段时间的日志流压缩后形成的一个文件。 一个 Chunks 就是一个对象，如果是使用本地文件系统存储 Chunks，则可以抽象得将一个 Chunks 文件当做一个对象。在一个 Chunks 文件中一般包含里一段时间的日志流数据。 Index(索引) # 日志流索引的信息。每一个 Index 都是 键/值 格式的数据库文件，文件中的内容用来关联 日志流的标签 与 Chunks。 Index 中的 Key 就是日志流的标签，Value 就是 Chunks 文件所在的绝对路径。 [!Tip] History Loki 在 2.0 版本之前，这两类数据是分开存放的，只有 Chunk 数据可以存在对象存储中。
直到 2.0 发布，Loki 开发了基于 BoltDB 的 BoltDB-Shipper 数据库用来存储 Index，并且已经可以将 Index 数据也存到对象存储中。也就是 Single stroe(单存储) 架构，此时 Chunk 和 Index 都可以同时存在本地文件系统或者同时存在对象存储中。</description></item><item><title>System Call</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/System-Call/System-Call/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/System-Call/System-Call/</guid><description>概述 参考：
Manual 目录 2 Manual(手册)，syscalls(2) Wiki, System_call http://arthurchiao.art/blog/system-call-definitive-guide-zh/ System Call(系统调用，简称 syscall) 是 Application(应用程序) 和 Linux Kernel(内核) 之间的基本接口。是操作内核的唯一入口。其实，所谓 syscall 就是各种编程语言中的 Function(函数) 概念。一个 syscall 也有名称、参数、返回值。syscall 即可以是名词，用来描述一个具体的 syscall；也可以是动词，用来表示某物调用了某个 syscall。当用户进程需要发生系统调用时，CPU 通过软中断切换到内核态开始执行内核系统调用函数。
syscall 还有另一种意思，是一种编程方式，比如我们常说的 API，就是 syscall 的一种实现。但是通常意义的 API 不包含权限的转变，而普通程序进行系统调用时，会涉及到权限的转变。
在 syscalls(2) 手册中的 System call list 章节可以看到 Linux 可用的完整的 syscall 列表。也就是说所有 Kernel 暴露出来的可供用户调用的 Function。
用户程序、内核和 CPU 特权级别 用户程序（例如编辑器、终端、ssh daemon 等）需要和 Linux 内核交互，内核代替它们完 成一些它们自身无法完成的操作。
例如，如果用户程序需要做 IO 操作（open、read、write 等），或者需要修改它的 内存地址（mmpa、sbrk 等），那它必须触发内核替它完成。
为什么禁止用户程序做这些操作呢？
因为 x86-64 CPU 有一个特权级别 （privilege levels）的概念。这个概念很复杂，完全可以单独写一篇博客。 出于本文讨论目的，我们将其（大大地）简化为如下：</description></item><item><title>Systemd</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Systemd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Systemd/</guid><description>概述 参考：
GitHub 项目，systemd/systemd 官网 Systemd 中文手册, 金步国 Manual(手册)，systemd System daemon(系统守护进程，简称 systemd) 实质上：启动一个服务，就是启动一个程序，可以给该程序添加一些参数，也可以不添加，该程序的可执行文件一般是放在 /usr/lib/systemd/system/ 目录下的
历史上，Linux 的启动一直采用 init 进程。这种命令 /etc/init.d/apache2 start 或者 service apache2 start，就是用来启动服务。
这种方法有两个缺点。
启动时间长。init 进程是串行启动，只有前一个进程启动完，才会启动下一个进程。 启动脚本复杂。init 进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。 Systemd 就是为了解决这些问题而诞生的。它的设计目标是，为系统的启动和管理提供一套完整的解决方案。
根据 Linux 惯例，字母 d 是 daemon(守护进程) 的缩写。 Systemd 这个名字的含义，就是它要守护整个系统。
使用了 Systemd，就不需要再用 init 了。Systemd 取代了 initd，成为系统的第一个进程(PID 等于 1)，其他进程都是它的子进程。
Systemd 的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。事实上，现在还有很多人反对使用 Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反&amp;quot;keep simple, keep stupid&amp;quot;的 Unix 哲学。
注意：Systemd 启动的程序无法获取 shell 中的变量，需要通过在 Unit 的配置文件中设置环境变量。
Unit(单元) Systemd 将各种操作系统启动和运行的相关对象，抽象多种类型的 Units(单元)，并且提供了 Units 之间的依赖关系。大多数 Units 是通过 Unit File(单元文件) 创建的，没有 Unit File，也就不会存在所谓的 Units。可以这么说，在特定目录创建了一个符合 Unit File 格式的文件，也就创建了一个 Unit。</description></item><item><title>Tailscale</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale/</guid><description>WireGuard 相比于传统 VPN 的核心优势是没有 VPN 网关，所有节点之间都可以点对点（P2P）连接，也就是我之前提到的全互联模式（full mesh），效率更高，速度更快，成本更低。
WireGuard 目前最大的痛点就是上层应用的功能不够健全，因为 WireGuard 推崇的是 Unix 的哲学，WireGuard 本身只是一个内核级别的模块，只是一个数据平面，至于上层的更高级的功能（比如秘钥交换机制，UDP 打洞，ACL 等），需要通过用户空间的应用来实现。
所以为了基于 WireGuard 实现更完美的 VPN 工具，现在已经涌现出了很多项目在互相厮杀。Netmaker 通过可视化界面来配置 WireGuard 的全互联模式，它支持 UDP 打洞、多租户等各种高端功能，几乎适配所有平台，非常强大。然而现实世界是复杂的，无法保证所有的 NAT 都能打洞成功，且 Netmaker 目前还没有 fallback 机制，如果打洞失败，无法 fallback 改成走中继节点。Tailscale 在这一点上比 Netmaker 高明许多，它支持 fallback 机制，可以尽最大努力实现全互联模式，部分节点即使打洞不成功，也能通过中继节点在这个虚拟网络中畅通无阻。
概述 参考：
GitHub 项目，tailscale/tailscale 官网 公众号 - 云原声实验室，Tailscal 开源版本让你的 WireGuard 直接起飞 Tailscale 的开源方案 Tailscale 是一种基于 WireGuard 的虚拟组网工具，和 Netmaker 类似，最大的区别在于 Tailscale 是在用户态实现了 WireGuard 协议，而 Netmaker 直接使用了内核态的 WireGuard。所以 Tailscale 相比于内核态 WireGuard 性能会有所损失，但与 OpenVPN 之流相比还是能甩好几十条街的，Tailscale 虽然在性能上做了些许取舍，但在功能和易用性上绝对是完爆其他工具：</description></item><item><title>TC 模块</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/TC-%E6%A8%A1%E5%9D%97/TC-%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/TC-%E6%A8%A1%E5%9D%97/TC-%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
原文链接 Linux 的高级路由和流量控制 Open vSwitch 之 QoS 的实现 arthurchiao.art 的文章： [译] 《Linux 高级路由与流量控制手册（2012）》第九章：用 tc qdisc 管理 Linux 网络带宽 [译] 深入理解 tc ebpf 的 direct-action (da) 模式（2020） Linux 中的 TC 模块已经在内核中存在很多年了，但是直到 eBPF 流行起来之前，文档以及使用者都非常之少，并仍处于活跃开发状态中。Kernel 4.1 版本中添加了一些新的 Hook，并支持将 eBPF 程序作为 tc classifier(也称为 filter) 或 tc action 加载到这些 Hook 点。大概六个月后，Kernel 4.4 版本发布时，iproute2 引入了一个 direct-action 模式，但是关于这个模式的文档依然少得可怜。。。。。
Glossary(术语) TC 是一个强大但复杂的框架。 它的几个核心概念：
queueing discipline(排队规则，简称 qdisc) # 根据某种算法完成限速、整形等功能 class # 用户定义的流量类别 classifier(分类器，也称为 filter) # 分类规则 action # 要对包执行什么动作 组合以上概念，下面是对某个网络设备上的流量进行分类和限速时，所需完成的大致步骤：</description></item><item><title>TCP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/TCP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/TCP/</guid><description>概述 参考：
RFC 675, RFC 793, TRANSMISSION CONTROL PROTOCOL - DARPA INTERNET PROGRAM PROTOCOL SPECIFICATION RFC 9293, Transmission Control Protocol (TCP) Wiki, TCP 极客时间,趣谈网络协议 https://www.jianshu.com/p/1118f497a425 https://www.jianshu.com/p/3c7a0771b67e 公众号-小林coding，通过动图学习 TCP 的滑动窗口和流量控制的工作方式 https://www2.tkn.tu-berlin.de/teaching/rn/animations/gbn_sr/ https://www2.tkn.tu-berlin.de/teaching/rn/animations/flow/ Transmission Control Protocol(传输控制协议，简称 TCP) 是互联网协议套件的最主要协议之一。它起源于最初的网络实现，补充了 Internet Protocol。因此整个套件通常称为 TCP/IP。
IP 地址后面的端口的作用：当从外部访问该 IP 地址的机器时候，是通过该 IP 地址的端口来访问这台机器的某个程序，然后程序向访问者提供该程序所具有的功能（服务）。web 界面默认是 80 端口，那么当你访问一个网页的时候，这个 IP 就会带你访问该机器的占用 80 端口的程序，然后该程序去调用首页脚本本间展示给访问者
例如：你通过远程 SSH 访问一台设备 192.168.0.1 的话，那么需要设置一下这台机器 SSH 服务程序所占用的端口号，比如 22，那么你就是通过 192.168.0.1:22 这个来访问这台机器的 SSH 进程。
上面的描述，就是一个基本的 TCP。
TCP 天然认为网络环境是恶劣的，丢包、乱序、重传，拥塞都是常有的事情，一言不合就可能送达不了，因而要从算法层面来保证可靠性。TCP 是靠谱的协议，但是这不能说明它面临的网络环境好。从 IP 层面来讲，如果网络状况的确那么差，是没有任何可靠性保证的，而作为 IP 的上一层 TCP 也无能为力，唯一能做的就是更加努力，不断重传，通过各种算法保证。也就是说，对于 TCP 来讲，IP 层你丢不丢包，我管不着，但是我在我的层面上，会努力保证可靠性。这有点像如果你在北京，和客户约十点见面，那么你应该清楚堵车是常态，你干预不了，也控制不了，你唯一能做的就是早走。打车不行就改乘地铁，尽力不失约。</description></item><item><title>TCP/IP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP_IP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP_IP/</guid><description>概述 参考：
RFC，791 Wiki, Internet protocol suite Internet protocol suite(互联网协议簇) 通常称为 TCP/IP
封装 当应用程序用 TCP 传输数据时，数据被送入协议栈中，然后逐个通过每一层直到被当做一串比特流送入网络。其中每一层对收到的数据都要增加一些首部信息(有时还需要增加尾部信息)，过程如图所示：
以太网帧的帧头和帧尾下面所标注的数字是典型以太网帧首部的字节查高难度。以太网数据帧的物理特性是其查高难度必须在 46~1500 字节之间(也就是 MTU 的长度)
注意：所有的 Internet 标准和大多数有关 TCP/IP 的书都使用 octe 这个术语来表示字节。使用这个过分雕琢的术语是有历史原因的，因为 TCP/IP 的很多工作都是在 DEC-10 系统上进行的，但是它并不使用 8bit 的字节。由于现在几乎所有的计算机系统都采用 8bit 的字节，因此我们在本书中使用 Byte(字节) 这个术语。
由于应用数据受 MSS 长度限制，IP 首部 + TCP 首部 + 应用数据受 MTU 长度限制。所以，当一个 IP 报文超过 MTU 时就会进行 Packet(分片/分组)。分组既可以是一个 IP 数据报，也可以是 IP 数据报的一个 Fragment(片段)。</description></item><item><title>TCPDump</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/TCPDump/TCPDump/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/TCPDump/TCPDump/</guid><description>概述 参考：
官网 Manual(手册)，tcpdump(1) Manual(手册)，PCAP-FILTER，主要描述过滤表达式的语法 Wiki, tcpdump https://www.middlewareinventory.com/blog/tcpdump-capture-http-get-post-requests-apache-weblogic-websphere/ TCPDump 是一个在命令行界面下的 Packet analyzer(数据包分析器)。tcpdump 适用于大多数类 Unix 操作系统，在这些系统中，tcpdump 使用 libpcap 库来捕获数据包。对于 Windows 操作系统来说，tcpdump 使用的 pcap API 是 WinPcap(即 libpcap 的 Windows 版本)。
tcpdump 最初由Van Jacobson、Sally Floyd、Vern Paxson和Steven McCanne于 1988 年编写，他们当时在劳伦斯伯克利实验室网络研究小组工作。到 1990 年代后期，有许多版本的 tcpdump 作为各种操作系统的一部分分发，以及许多没有很好协调的补丁。 Michael Richardson (mcr)和Bill Fenner于 1999 年创建 www.tcpdump.org
说明：Dump 有 转出，倾卸；转储；内容全部打印 的含义，在官方文档中，通过 TCPDump 程序输出的数据包，通常称为 dump line，转储的行。说白了就是程序抓到的包，每个包都是一行
Syntax(语法) tcpdump [OPTIONS] [Filter-Expression]
OPTIONS -A # 以 ASCII 打印每个数据包 (减去其链接级别标头)。方便捕捉网页。 -c &amp;lt;INT&amp;gt; # 指定程序将会捕获的数据包数量。 -D, &amp;ndash;list-interfaces # 列出可用于抓包的接口。将会列出接口的数值编号和接口名，它们都可以用于&amp;quot;-i&amp;quot;后 -e # 在每条 dump 出来的行上显示二层头信息。这个选项可以输出 以太网 和 IEEE802.</description></item><item><title>Terminal 与 Shell</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Terminal-%E4%B8%8E-Shell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Terminal-%E4%B8%8E-Shell/</guid><description>概述 参考：
Wiki, Shell Manual(手册)，bash https://blog.csdn.net/kangkanglou/article/details/82698177 http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote/ https://www.jianshu.com/p/0c7ea235b473 公众号，阿里技术-一种命令行解析的新思路 Shell(也称为壳层) 是一种计算机程序，向人类用户或其他程序公开操作系统的服务。通常，操作系统的 Shell 程序会根据计算机的角色和特定操作，分为两类：
command-line interface(命令行界面，简称 CLI) graphical user interface(图形用户界面，简称 GUI) Shell 在计算机科学中指“为用户提供用户界面”的软件，通常指的是命令行界面的解析器。一般来说，这个词是指操作系统中提供访问内核所提供之服务的程序。Shell 也用于泛指所有为用户提供操作界面的程序，也就是程序和用户交互的接口。因此与之相对的是 Kernel(内核)，内核不提供和用户的交互功能。
用白话讲：人类操作计算机的地方就是 Shell ，可以是一个输入命令的地方(CLI)，也可以是一个用户用鼠标点点点的图形界面(GUI)。Shell 也是一类程序的统称，实际上，当输入完用户名和密码登录系统的时候，就是 Linux 系统后台自动启动了一个名叫 Bash 的 Shell 程序，来让用户输入指令对计算机进行操作
所以，一个 Shell 也会有一个进程号，在该 Shell 执行的程序的父进程号都是该 Shell 的进程号
如下所示，登录系统时，会启动一个进程标识当前登录的用户，并启动一个子进程，该子进程就是 Bash 这个 Shell，并且会为该 Shell 分配一个终端来与用户进行交互(这里的终端名是 tty1)
root 1067 1 0 11:20 ? Ss 0:00 login -- root root 9622 1067 2 13:19 tty1 Ss+ 0:00 \_ -bash 所有命令都是在这个 shell 下运行的，如下所使，在 bash 下执行了一个 cat 命令</description></item><item><title>Terminal(终端)</title><link>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/Terminal%E7%BB%88%E7%AB%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/Terminal%E7%BB%88%E7%AB%AF/</guid><description>概述 参考：
这里说的 Terminal(终端) 工具是一种可以连接 Shell 的图形话工具。
TODO: xterm 是什么？
TODO 各种 GUI 终端工具都可以配置连接后要使用的终端，用 xterm 或者其他的，操作起来和样式都不一样。 比如使用 vim 的时候。选名为 linux 的 这是啥玩意？ Terminal 增强工具 tmux 参考：
GitHub 项目，tmux/tmux terminal multiplexer(终端多路复用，简称 tmux)，它允许从单个屏幕创建、访问和控制多个终端。 tmux 可能会从屏幕上分离并继续在后台运行，然后再重新连接。
GUI 终端工具 Xmanager https://blog.csdn.net/zhouchen1998/article/details/103424698
Xshell 没有自带的 x11 能力
SecureCRT 参考：
官网 SecureCRT 是 VanDyke Software 开发的商业终端产品。初始发行于 1995 年 10 月 4 日，没有任何免费版可用，且界面样式非常老旧。
问题
ctrl + +/- 无法调整大小 配置 Options - Configure - Default Seession # 可修改默认的会话配置，针对所有会话的
快捷键 # Terminal - Emulation - Mapped Keys 标签样式 # Terminal - Emulation - Advanced - Ignore window title change requests（忽略窗口的标题名称根据实际情况而变化） Options - Global Options # 可修改主题颜色</description></item><item><title>Thanos</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos/</guid><description>概述 参考：
GitHub 项目，thanos-io/thanos 官网 K8S 训练营，Kubernetes 监控-Thanos 公众号-k8s 技术圈，使用 Thanos 集中管理多 Prometheus 实例数据 公众号-k8s 技术圈，Thanos Ruler 组件的使用 首先需要明确一点，Thanos 是一组程序的统称。这一组程序可以组成具有无限存储容量的高可用 Metrics 系统。可以将其无缝添加到现有 Prometheus 之上。
单独使用 Prometheus 可能产生的问题
长、短期数据未分层，一套 Prometheus 在被查询长周期指标时，Prometheus 所在服务器的内存、CPU 使用率飙升，甚至可能导致监控、告警服务不可用，原因在于两点： 查询长周期数据时，Prometheus 会将大量数据载入内存 Prometheus 载入的不是降采样数据 查询的时间范围越大，需要的内存就越多。在另一个生产的方案中，采用 VictoriaMetrics 单机版作为远端存储，服务器内存高达 128G。同时，这种方式还存在丢数据的情况。 Prometheus 联邦的方式，只是结局了将多个 Prometheus 聚合起来的情况，并没有提供抽样的能力，不能加快长周期指标的查询，不适用于当前远端存储的场景。 综上所属
Thanos Compact 组件能对指标数据进行降采样，以提高大时间范围查询的效率 Thanos 的 Sidecar 和 Receiver 组件都可以将指标数据转存到对象存储中 Thanos Querier 组件可以 此时，通过 Thanos 将数据分了层 短期数据保存在 Receiver 或 Prometheus 中，用于告警系统的高频查询以及 Grafana 的展示 长期数据保存在对象存储中，以供后续分析使用 Thanos 架构概述 Thanos 遵循 KISS 和 Unix 哲学，由一组组件组成，每个组件都可以实现特定的功能：</description></item><item><title>Thanos 组件详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/Thanos-%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/Thanos-%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，组件 https://zhuanlan.zhihu.com/p/137248127 Compactor(压实器) 注意：Compactor 在持久运行状态，会对对象存储发起大量的 GET 请求。最好间隔一段时间，运行一次，压缩一次数据即可，不必持久运行
Receiver(接收器) 参考：
官方文档，组件-接收器 Querier(查询器) 参考：
官方文档，组件-查询器 Querier 组件分为两部分
Querier(查询器) # 实现了 Prometheus API，可以通过 Querier 发起 PromQL 查询请求，以获取数据；甚至可以从 Prometheus Server 的时序数据库中删除数据。每个从 Querier 发起的 PromQL 查询请求都会发送到可以暴露 StoreAPI 的组件上，并获取查询结果。 Query Fronted(查询前端) # 实现了 Prometheus API，可以将请求负载均衡到指定的多个 Querier 上，同时可以缓存响应数据、也可以按查询日拆分。有点像 Redis 的效果 Querier 组件向一个或多个暴露 StoreAPI 的组件发起查询请求，并将结果去重后，返回给查询客户端。 Deduplication(重复数据删除) The query layer can deduplicate series that were collected from high-availability pairs of data sources such as Prometheus. A fixed single or multiple replica labels must be chosen for the entire cluster and can then be passed to query nodes on startup.</description></item><item><title>Tunneling Protocol</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tunneling-Protocol/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tunneling-Protocol/</guid><description>概述 参考：
Wiki, Tunneling Protocol Wiki, Overlay Network Tunneling Protocol(隧道协议) 是一种通信协议，允许数据从一个网络移动到另一个网络。该协议通过通信协议中 Encapsulation(封装) 的过程跨公共网络发送专用网络通信。因为隧道涉及将流量数据重新打包为不同的形式，可能以加密为标准，它可以隐藏通过隧道运行的流量的性质。隧道协议通过使用数据包的 Payload(数据部分) 来承载实际提供服务的数据包。隧道使用分层协议模型，例如 OSI 或 TCP/IP 协议套件中的那些，但在使用有效载荷承载网络通常不提供的服务时通常会违反分层。通常，在分层模型中，传送协议在与有效载荷协议相同或更高的级别上运行。
隧道技术是一种通过使用互联网络的基础设施在网络之间传递数据的方式。使用隧道传递的数据（或负载）可以是不同协议的数据帧或包。隧道协议将其它协议的数据帧或包重新封装然后通过隧道发送。新的帧头提供路由信息，以便通过互联网传递被封装的负载数据。
隧道的常见用途
隧道协议可以允许外部协议在不支持该特定协议的网络上运行，例如在 IPv4 上运行 IPv6。 另一个重要用途是提供仅使用底层网络服务提供的不切实际或不安全的服务，例如向其物理网络地址不属于公司网络的远程用户提供公司网络地址。 用户还可以使用隧道“潜入”防火墙，使用防火墙通常会阻止的协议，但“包装”在防火墙不会阻止的协议中，例如 HTTP。如果防火墙策略没有明确排除这种“包装”，则此技巧可以绕过预期的防火墙策略（或任何一组互锁的防火墙策略）。 另一种基于 HTTP 的隧道方法使用 HTTP CONNECT 方法/命令。客户端向 HTTP 代理发出 HTTP CONNECT 命令。然后，代理与特定的 server:port 建立 TCP 连接，并在该 server:port 和客户端连接之间中继数据。 [1]因为这会产生安全漏洞，所以支持 CONNECT 的 HTTP 代理通常会限制对 CONNECT 方法的访问。代理仅允许连接到特定端口，例如 HTTPS 的 443。 应用场景：
一个公司在天津与北京分别有一个办公地点，天津的内网为 10.0.0.0/24，北京的内网为 10.0.1.0/24。那么如何让两个内网互通呢?可以使用 tunnel 技术，在两地公网出口建立隧道连接。天津访问北京的时候，目的内网地址是封装在公网 IP 里面的，这样就可以让私网地址的数据在公网传输。比如大企业都有自己的隧道网络，当使用个人电脑，安装上某些隧道软件后，那么这台电脑就可以访问公司内部网络了。 Overlay Overlay(叠加网络) 实际上是一种隧道封装技术，是对隧道技术的扩展。传统隧道技术仅限于隧道两端通信，而 Overlay 网络则可以实现 N 个端点之间的互相通信。</description></item><item><title>TypeScript 规范与标准库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/TypeScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/TypeScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/TypeScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/TypeScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</guid><description>概述 参考：
TypeScript 官网 TypeScript 语言参考描述了 TypeScript 语言的具体语法和语义 TypeScript 标准库则是与 TypeScript 语言一起发行的一些可选功能，以便人们可以从一开始就轻松得使用 TypeScript 进行编程。 数据类型 https://www.runoob.com/typescript/ts-type.html</description></item><item><title>UDP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/UDP/UDP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/UDP/UDP/</guid><description>概述 参考：
概述 参考：
Wiki, User_Datagram_Protocol RFC 768 UDP 介绍 User Datagram Protocol (用户数据报协议，简称 UDP)。
不保证数据报文是否安全可靠的到达对方</description></item><item><title>Unit File</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/Unit-File/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/Unit-File/</guid><description>概述 参考：
Manual(手册)，systemd.unit(5) # Unit 的介绍 Manual(手册)，systemd.syntax(7) # Unit 的配置语法 金步国 systemd.unit 中文手册 Unit File，是 INI 格式的纯文本文件。在这个文件中，由 Directives(指令) 和 Sections(部分) 组成，这里的 Directve 就是 INI 格式中的 键/值对。
Directives(指令) # 指令由 名称 与 值 组成，以 = 分割 Sections(部分) # 与 INI 中的 Sections 概念一样。是一组 Directives 的集合 Unit File 与 INI 格式文件不同的地方是关于注释，Unit File 使用 # 作为注释行的开头。
Unit File 最简单示例 [Unit] # Unit 的描述 Description=Foo [Service] # 如何启动该 Unit ExecStart=/usr/sbin/foo-daemon [Install] # 当 enable 该 Unit 时，应该在 multi-user.</description></item><item><title>Unix-like OS</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/Unix-like-OS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/Unix-like-OS/</guid><description>概述 参考：
Wiki, Unix Manual(手册)，os-release DistroWatch(类 UNIX 系统的资讯网站) Unix 是一系列多任务、多用户 Operating system(操作系统) 的统称。
最初打算在贝尔系统内部使用，AT&amp;amp;T 在 1970 年代后期将Unix授权给外部各方，导致来自加利福尼亚大学伯克利分校( BSD )、微软( Xenix )、Sun Microsystems 等供应商的各种学术和商业 Unix 变体( SunOS / Solaris )、HP / HPE ( HP-UX ) 和IBM ( AIX )。在 1990 年代初期，AT&amp;amp;T 将其在 Unix 中的权利出售给了Novell，Novell随后将其 Unix 业务出售给了Santa Cruz Operation (SCO) 于 1995 年。[4] UNIX 商标转让给了The Open Group，这是一个成立于 1996 年的行业联盟，允许将该标志用于符合单一 UNIX 规范(SUS) 的认证操作系统。但是，Novell 继续拥有 Unix 版权，SCO Group, Inc. 诉 Novell, Inc.法庭案件 (2010) 证实了这一点。</description></item><item><title>Utility</title><link>https://desistdaydream.github.io/docs/Utils/Utility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/Utility/</guid><description>概述 参考：
Utility(实用工具)
论坛 直播 视频 搜索 电子商务 社交网络 在线游戏 在线教育 定位 金融 国外产品 Facebook
Twitter
Google
Spotify
Snapchat
Instagram
Shopify
Reddit # 论坛
Twitch # 直播
Youtube # 视频
TikTok
Pinterest
IT 工具 GitHub 项目，CorentinTh/it-tools 对于开发人员和 IT 工作人员来说非常有用的工具。比如 数据转换、数据加密、时间转换、etc.</description></item><item><title>Vector</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/Vector/Vector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/Vector/Vector/</guid><description>概述 参考：
GitHub 项目，vectordotdev/vector 官网 https://www.cnblogs.com/ulricqin/p/17762086.html Vector 是一种高性能的用于可观测性的 DataPipeline(数据管道)，让用户能够控制其可观测性数据。收集、转换 所有日志、指标和跟踪，并将其路由到任意 Vendor 以及明天可能需要的其他 Vendor。
Notes: Vendor 指使用这些数据的地方，e.g. 数据库、Web 前端、etc. 这些地方都可以对外提供数据，所以称为 Vendor(供应商)，就像数据供应商似的。
Datadog 在 2021 年左右收购了 Vector。Vector 通常用作 ELK 生态中 logstash 的替代品。
Vector 开箱即用，默认支持 ClickHouse、etc.
Vector 架构 Vector 将数据通道抽象为 3 部分组件：
Sources # 将可观测性数据源中的数据收集或接收到 Vector 中 Transforms # 在可观测性数据通过拓扑时操纵或更改该数据。（拓扑可以理解为一种网状结构，由处理数据的多个节点组成） Sinks # 将可观测性数据从 Vector 向前发送到外部服务或目的地 部署角色 Vector 可以部署为两个角色，既可以作为数据采集的 Agent，也可以作为数据聚合、路由的 Aggregator，架构示例如下：
Agent Aggregator Vector 部署 参考：
官方文档，Setup - 安装 包管理器 容器 二进制文件 Vector 关联文件与配置 /var/lib/vector/ # 持久保存 Vector 状态的目录。e.</description></item><item><title>Vim</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/Vim/Vim/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/Vim/Vim/</guid><description>概述 参考：
GitHub 项目，vim/vim 官网 用户手册 可跳转到 帮助文件 Carlo Teubner 维护的 文档 Syntax(语法) 参考：
vim [OPTIONS]
OPTIONS：
-o FILENAME1 FILENAME2 &amp;hellip;&amp;hellip; # 水平分割使用 vi 打开多个文件 -O FILENAME1 FILENAME2&amp;hellip;&amp;hellip; # 垂直分割使用 vi 打开多个文件 使用 ctrl+w 后，按上下左右箭头，切换编辑哪方向的文件 +# # 打开文件后直接让光标处于第#行的行首，不输入#默认为最后一行 -b # 使用二进制模式打开 vim 三种主要模式 默认命令（Normal）模式，可以移动光标，剪切和粘贴。 插入（Insert）模式，用户可以编辑文本。 扩展（Extended）命令模式（或末行模式）e.g.在编辑器下直接输入:wq 可保存退出，或者:q!强制退出。 Exc 按键可退出当前模式。
默认模式 移动定位光标位置 所有其余命令都可以跟该命令联合使用，表示命令执行到哪个位置
注：在任意移动前加数字则代表该移动模式移动几次（例：#→，向右移动#个字符，#为任意数或者字符）
行跳转
#G 移动光标到指定的 # 行 G 到文件尾 gg 到文件首 w 移至下一个单词的词首 e 移动至当前或下一个单词的词尾(这两项前面跟数字可以移动数字个单词)
b 移动至当前或之前一个单词的词首
0 绝对行首 $绝对行尾 ^ 跳转至行首的第一个非空白字符</description></item><item><title>virsh 命令行工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，手册-virsh GitHub 位置，libvirt/libvirt/docs/manpages/virsh.rst virsh 是 libvirt 核心发行版的一部分，通过 Libvirt API 管理虚拟机的命令行工具。
virsh 有两种使用方式
virsh + 子命令 交互式 shell。不加任何子命令时，进入交互式 shell Syntax(语法) virsh [OPTION]&amp;hellip; [COMMAND_STRING]
virsh [OPTION]&amp;hellip; COMMAND [ARG]&amp;hellip;
注意：
DOMAIN 的说明：libvirt 使用 domain 代指 VM，所有关于 domain 的描述都可以理解为 VM 或者 instance 当指定要操作某个特定 DOMAIN 的时候，可以使用该 DOMAIN 的 ID 号、NAME、UUID，三者任选其一 想要查看 VM 的信息，可以在 virsh 的 shell 中使用 help 命令，找 list 和 info 的关键字，help 中是以不同类型的命令进行分类的比如 DOMAIN 相关的，监控信息，网络存储等 OPTIONS -c, &amp;ndash;connect=URI # 通过 URI 连接远程 Hypervisor -d, &amp;ndash;debug=NUM # debug level [0-4] -e, &amp;ndash;escape &amp;lt;char&amp;gt; # set escape sequence for console -k, &amp;ndash;keepalive-interval=NUM # keepalive interval in seconds, 0 for disable -K, &amp;ndash;keepalive-count=NUM # number of possible missed keepalive messages -l, &amp;ndash;log=FILE output logging to file -q, &amp;ndash;quiet # 安静模式。输出时没有标题 -r, &amp;ndash;readonly # connect readonly -t, &amp;ndash;timing # print timing information COMMAND Note：其中各种命令用法，详见 virsh 命令行工具目录下每个子命令的专题文章</description></item><item><title>Virtualization</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Virtualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Virtualization/</guid><description>概述 参考：
Wiki, Virtualization RedHat 7 虚拟化入门指南 Redhat 8 官方对虚拟化的定义 RedHat 7 对“虚拟化性能不行”这个误区的辟谣 Ubuntu 官方文档，虚拟化-介绍 Virtualization(虚拟化) 是用于运行软件的广义的计算机术语。通常情况下，Virtualization(虚拟化) 体现在让单个可以运行多个操作系统，这些操作系统同时运行，而又是互相独立的。
虚拟化是云计算的基础。简单的说，虚拟化使得在一台物理的服务器上可以跑多台虚拟机，虚拟机共享物理机的 CPU、内存、IO 硬件资源，但逻辑上虚拟机之间是相互隔离的。物理机我们一般称为 Host(宿主机)，宿主机上面的虚拟机称为 Guest(客户机)。那么 Host 是如何将自己的硬件资源虚拟化，并提供给 Guest 使用的呢？这个主要是通过一个叫做 Hypervisor 的程序实现的。
Hypervisor 参考：https://www.redhat.com/zh/topics/virtualization/what-is-a-hypervisor
Hypervisor 是用来创建与运行虚拟机的软件、固件或硬件。被 Hypervisor 用来运行一个或多个虚拟机的设备称为 Host Machine(宿主机)，这些虚拟机则称为 Guest Machine(客户机)。Hypervisor 有时也被称为 Virtual Machine Monitor (虚拟机监视器，简称 VMM)
虚拟化技术的分类 根据 Hypervisor 的实现方式和所处的位置，虚拟化又分为两种：1 型虚拟化和 2 型虚拟化
半虚拟化（para-virtualization）：TYPE1，也叫裸金属虚拟化比如 Vmware ESXi、Xen 等是一款类似于操作系统的 Hypervisor，直接运行在硬件之上，需要修改 Guest OS 的内核，让 VM 知道自己是虚拟机 完全虚拟化（full-virtualization）：TYPE2，物理机上首先安装常规的操作系统，比如 Redhat、Ubuntu 和 Windows。Hypervisor 作为 OS 上的一个程序模块运行，并对管理虚拟机进行管理。比如 Vmware Workstation、KVM 等是一款类似于软件的 Hypervisor，运行于操作系统之上，VM 不知道自己是虚拟机 BT：软件，二进制翻译。性能很差 HVM：硬件，硬件辅助的虚拟化。性能很好。现阶段 KVM 主要基于硬件辅助进行虚拟化 硬件辅助全虚拟化主要使用了支持虚拟化功能的 CPU 进行支撑，CPU 可以明确的分辨出来自 GuestOS 的特权指令，并针对 GuestOS 进行特权操作，而不会影响到 HostOS。 从更深入的层次来说，虚拟化 CPU 形成了新的 CPU 执行状态 —— Non-Root Mode&amp;amp; Root Mode。从上图中可以看见，GuestOS 运行在 Non-Root Mode 的 Ring 0 核心态中，这表明 GuestOS 能够直接执行特却指令而不再需要 特权解除 和 陷入模拟 机制。并且在硬件层上面紧接的就是虚拟化层的 VMM，而不需要 HostOS。这是因为在硬件辅助全虚拟化的 VMM 会以一种更具协作性的方式来实现虚拟化 —— 将虚拟化模块加载到 HostOS 的内核中，例如：KVM，KVM 通过在 HostOS 内核中加载 KVM Kernel Module 来将 HostOS 转换成为一个 VMM。所以此时 VMM 可以看作是 HostOS，反之亦然。这种虚拟化方式创建的 GuestOS 知道自己是正在虚拟化模式中运行的 GuestOS，KVM 就是这样的一种虚拟化实现解决方案。 OS 级别虚拟化：容器级虚拟化，准确来说不能叫虚拟化了，只能叫容器技术无 Hypervisor，将用户空间分隔为多个，彼此互相隔离，每个 VM 中没有独立内核，OpenVZ、LXC(Linux container)、libcontainer 等，比如 Docker，Docker 的基础是 LXC。 模拟(Emulation)：比如 QEMU，PearPC，Bochs 库虚拟化：WINE 应用程序虚拟化：JVM 理论上 Type1 和 Typ2 之间的区别 1 型虚拟化一般对硬件虚拟化功能进行了特别优化，性能上比 2 型要高； 2 型虚拟化因为基于普通的操作系统，会比较灵活，比如支持虚拟机嵌套。嵌套意味着可以在 KVM 虚拟机中再运行 KVM。 虚拟化总结(云计算基础，实现云功能的灵活调度) 所谓的云计算：当一台虚拟机需要跨越多个物理机进行数据交互，比如拿来运行 VM 的物理主机不止一台，在每台物理机上按需启动既定数量的 VM，每个 VM 有多少 CPU 和 MEM，每个 VM 启动在哪个物理机上，启动 VM 需要的存储设备在什么地方，存储设备中的系统是临时安装，还是通过一个已经装好的系统模板直接使用，还有多个 VM 跨物理主机进行网络通信等等一系列工作，可以使用一个虚拟化管理工具(VM Manager)来实现，这个管理器的功能即可称为云计算。在没有这个管理器的时候，人们只能人为手工从把 VM 从一台物理机移动到另一台物理机，非常不灵活。</description></item><item><title>Visual Studio Code</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/Visual-Studio-Code/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/Visual-Studio-Code/</guid><description>概述 参考：
GitHub 项目，microsoft/vscode 官网 官方文档 VS Code 关联文件与配置 ${UserDataDir} # 用户数据目录。
Windows 默认在 %APPDATA%/Code/ Linux 默认在 ${HOME}/.vscode-server/data/ VS Code 运行时生成的持久化数据通常都在同一个目录中。之所以称为用户数据目录，是因为需要以用户为基础来运行一个进程，不同的用户运行的 VS Code，读取的数据应该是不同的。所以这些数据一般就保存在用户的家目录中。
./User/ # ./workspaceStorage/ # 工作空间的配置与持久化数据 ./keybindings.json # 快捷键 ./settings.json # 用户自定义的配置。默认配置在代码内部。 ${ExtensionsDir} # 扩展目录。
Windows 默认在 %USERPROFILE%/.vscode/extensions/ Linux 默认在 %{HOME}/.vscode-server/extensions/ 配置 使用快捷键 Ctrl+Shift+p ，然后搜索 setting，即可看到如下图所示的一些可用的配置。这个编辑的就是 ${UserDataDir}/User/setting.json 文件
首选项：打开默认设置(JSON) # 打开 defaultSettings.json 文件。这个文件是 VS Code 的默认配置，其中还有每个字段的注释 首选项：打开设置(JSON) # 打开 settings.json 文件。一般用户配置都在这个文件中编写。 首选项：打开工作区设置(JSON) # 打开 .vscode/setting 文件。 defaultSettings.json # VS Code 默认配置文件。其中还有每个字段的注释</description></item><item><title>Volume</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Volume/Volume/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Volume/Volume/</guid><description>概述 参考：
官方文档，概念-存储-卷 Volume(卷) 的工作流程：可以把 volume 想象成一个中间人，数据流走向：Container—Volum—StorageResource
要使用 Volume，Pod 的 Manifests 中需要指定要为 Pod 提供卷的类型（.spec.volumes 字段）以及将这些卷挂载到容器的位置（.spec.containers [*].volumeMounts 字段）。
Volume 中数据所在目录 /var/lib/kubelet/pods/PodUID/volumes/XXX # pod 中挂载的 volume，其数据都会保存在该目录下，就算是 nfs 这种远程存储，pod 也是会读取该目录下的某个目录，因为这个目录就是挂载 nfs 的目录。 Volume 的类型 参考：
官方文档，概念-存储-卷-卷类型(全部 Volume 类型的官方介绍) 注意：大量的第三方 In-Tree 类型的第三方卷插件(i.e.非 ConfigMap、Secret 等内置资源的卷插件)将会逐步被弃用，详情参考 Kubernetes 博客，Kubernetes 1.23: Kubernetes In-Tree to CSI Volume Migration Status Update
现阶段(1.21 版本)，Kubernetes 支持以下类型的 Volume：
awsElasticBlockStore azureDisk azureFile cephfs cinder configMap # 一种 Kubernetes 资源，使用 ConfigMap 资源中定义的内容作为 Volume。比如 key 是文件名，value 是文件内容。 downwardAPI emptyDir # 把宿主机上的目录作为 Volume fc (光纤通道) gcePersistentDisk hostPath # 把宿主机上的目录作为 Volume iscsi local # 把宿主机上的目录作为 Volume nfs # 将 NFS 服务提供的目录作为 Volume persistentVolumeClaim # 一种 Kubernetes 资源。详见 Persistent Volume(持久卷) 中关于 PVC 的说明 portworxVolume projected quobyte rbd secret # 一种 Kubernetes 资源。使用 Secret 资源中定义的内容作为 Volume。比如 key 是文件名，value 是文件内容。 storageOS vsphereVolume 上述类型都有各自的用法，常用类型的卷详见本章节下的子章节。</description></item><item><title>Vue</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue/</guid><description>概述 参考：
GitHub 组织，vuejs 官网 官网-中文 Vue 互动教程 Wiki, Vue.js Vue 是一套用于构建用户界面的渐进式 ECMAScript 框架。Vue3 于 2020 年 9 月发布，已全面采用 TypeScript 编写；在 2022 年 2 月份成为默认版本
组件化 Vue 是“组件化”模式，一个页面的各个部分，可以拆分成一个一个的组件：
Single-File Component(单文件组件，简称 SFC)。顾名思义，Vue 的单文件组件会将一个组件的逻辑 (JavaScript)，模板 (HTML) 和样式 (CSS) 封装在同一个文件里。
同时，多个组件可以自由组合拼接，形成一个完整的页面。
单文件组件是 Vue 的标志性功能。如果你的用例需要进行构建，我们推荐用它来编写 Vue 组件。你可以在后续相关章节里了解更多关于单文件组件的用法及用途。但你暂时只需要知道 Vue 会帮忙处理所有这些构建工具的配置就好。
这些组件通常被组织在 XXX.vue 文件中，通常保存在项目根目录的 components/ 目录下。
组件化开发是一个树状结构，从一个“根组件”开始：
App (root component) ├─ TodoList │ └─ TodoItem │ ├─ TodoDeleteButton │ └─ TodoEditButton └─ TodoFooter ├─ TodoClearButton └─ TodoStatistics 就像下面这样：</description></item><item><title>Wayland</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/freedesktop/Wayland/Wayland/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/freedesktop/Wayland/Wayland/</guid><description>概述 参考：
官网 Wiki, Wayland Wayland 是一种通信协议，用来指定显示服务器及其客户端之间的通信。还可以表示该协议的 C 库实现。Wayland 是下一代图形接口</description></item><item><title>Web</title><link>https://desistdaydream.github.io/docs/Web/Web/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Web/</guid><description>概述 参考：
Wiki, World_Wide_Web World Wide Web(万维网，简称 WWW) 常被简称为 Web
Web 还有有很多种理解
Nginx 等软件可以提供 Web 服务。
学习资料 MDN，Web 开发技术(通常指的是网站首页的 References 标签中的文档)
Web 开发技术 Web APIs 不管用什么语言编写 Web 代码，通常都有一些标准的 APIs，有点类似于操作系统的 POSIX。这些 Web API 的标准通常都是由 W3C、IETF、等多个组织和公司一起制定的，其中 W3C 和 IETF 占了很重要的地位。
详见 WebAPIs
编程语言 HTML
CSS
ECMAScript
XML
WebAssembly 详见 WebAssembly
Browser automation 浏览器自动化，是指在 Web 浏览器中 自动执行操作，用于测试、 网页抓取或更快地执行重复性任务。
详见 Browser automation</description></item><item><title>WebAPIs</title><link>https://desistdaydream.github.io/docs/Web/WebAPIs/WebAPIs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/WebAPIs/WebAPIs/</guid><description>概述 参考：
MDN，参考 - Web API 在编写 Web 代码时，有许多 Web APIs 可供调用。下面是开发 Web 应用程序或网站时可能使用的所有 API 和接口（对象类型）的列表。
Web APIs 主要用于 JavaScript，但也可能有例外。
Window https://developer.mozilla.org/zh-CN/docs/Web/API/Window
Window 接口是各种函数、对象、等等的家。window 对象表示一个包含 DOM 的窗口（通常来说都是具有浏览器功能的窗口），document 属性指向窗口中载入的 DOM 文档。
Navigator 接口表示用户代理的状态和标识。它允许脚本查询它和注册自己进行一些活动。用白话说：这里面包含了浏览器相关的信息。
appVersion # 浏览器的版本号 appName # 浏览器的名称 language # 浏览器使用的语言 platform # 浏览器所使用的平台 userAgent # 浏览器的 user-agent 信息。常用来区分浏览网站的人使用了什么设备 webdriver # 当前窗口是否使用了 WebDriver。在爬虫技术中，移除这个是很重要的一点避免被网站识别成 WebDriver。</description></item><item><title>WebSocket</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/WebSocket/WebSocket/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/WebSocket/WebSocket/</guid><description>概述 参考：
RFC 6455, The WebSocket Protocol Wiki, WebSocket 公众号-小林 coding，有了 HTTP 协议，为什么还要有 websocket 协议？ WebSocket 是一种计算机通信协议，通过单个 TCP 连接提供全双工通信通道。
WebSocket 与 HTTP 不同。这两种协议都位于 OSI 模型的第 7 层，并依赖于第 4 层的 TCP。尽管它们不同，但 RFC 6455 指出 WebSocket “旨在通过 HTTP 端口 443 和 80 工作，并支持 HTTP 代理和中介” ，从而使其与 HTTP 兼容。为了实现兼容性，WebSocket 握手使用 HTTP Upgrade 头从 HTTP 协议更改为 WebSocket 协议。
WebSocket 协议支持 Web 浏览器（或其他客户端应用程序）和 Web 服务器之间的交互，其开销比半双工替代方案（例如 HTTP轮询）低，从而促进从服务器到服务器的实时数据传输。这是通过为服务器提供一种标准化的方式来向客户端发送内容而无需客户端首先请求，并允许消息在保持连接打开的同时来回传递而实现的。通过这种方式，可以在客户端和服务器之间进行双向正在进行的对话。通信通常通过 TCP端口完成数字 443（或在不安全连接的情况下为 80），这对于使用防火墙阻止非网络 Internet 连接的环境有益。类似的浏览器-服务器双向双向通信已经使用Comet或Adobe Flash Player等临时技术以非标准化方式实现。[2]
大多数浏览器都支持该协议，包括Google Chrome、Firefox、Microsoft Edge、Internet Explorer、Safari和Opera。[3] 与 HTTP 不同，WebSocket 提供全双工通信。[4][5] 此外，WebSocket 支持基于 TCP 的消息流。TCP 单独处理字节流，而没有消息的固有概念。在 WebSocket 之前，使用Comet通道可以实现端口 80 全双工通信；然而，Comet 的实现并不简单，并且由于 TCP 握手和 HTTP 标头开销，对于小消息来说效率低下。WebSocket 协议旨在在不损害 Web 安全假设的情况下解决这些问题。</description></item><item><title>Windows 管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，Windows Server - 命令 官方文档，PowerShell - 模块参考 所有受支持的 Windows 和 Windows Server 版本都内置了一组 Win32 控制台命令。同时，PowerShell 也内置了一组 cmdlet
本质上，内置的命令就两类：
Win32 控制台命令。一般在保存 C:/Windows/System32/ 目录中，就像 Unix 的 /usr/bin 这种目录似的，都是一些可执行文件。 PowerShell 中的 cmdlet。也就是 PowerShell 的各种模块。这些 cmdlet 虽然不是可见的可执行文件，但是也可以实现类似命令的效果。 就是本笔记的 PowerShell 内置管理工具 部分</description></item><item><title>WindowsShell</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/WindowsShell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/WindowsShell/</guid><description>概述 参考：
官方文档-Windowns Server，Windows 命令 官方文档，Windows Shell 官方文档，PowerShell Wiki, Windows shell Windows 有两个 CLI 的 Shell：Command shell 和 PowerShell。每个 Shell 都是一个软件程序，可在我们与操作系统或应用程序之间提供直接通信，从而自动化 IT 操作的环境。
Windows 有一个 GUI 的 Shell：Windows Shell，这个名词除了表示所有适用于 Windows 的 Shell 以外，还可以单独代表一个 Windows GUI Shell。
在 Windows 的 Shell 中使用的命令可以用来管理 Windows，很多命令的详解可以参见 Windows 管理工具 目录。
Windows Terminal 参考：
官方文档-windows，终端</description></item><item><title>WireGuard</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/WireGuard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/WireGuard/</guid><description>概述 参考：
官网 zx2c4 源码，wireguard-linux GitHub 项目，WrieGuard/wireguard-linux Wiki, WireGuard 张馆长博客，个人办公用 wireguard 组网笔记 米开朗基杨博客，WireGuard 教程：WireGuard 的工作原理 WireGuard 是一种可以实现加密 VPN 的通信协议。通常也表示为实现该通信协议的软件。
WireGuard 是由 Jason Donenfeld 等人用 C 语言编写的一个开源 VPN 协议，被视为下一代 VPN 协议，旨在解决许多困扰 IPSec/IKEv2、OpenVPN 或 L2TP 等其他 VPN 协议的问题。它与 Tinc 和 MeshBird 等现代 VPN 产品有一些相似之处，即加密技术先进、配置简单。
[!Tip] 从 2020 年 1 月开始，Wireguard 已经并入了 Linux 内核的 5.6 版本，这意味着大多数 Linux 发行版的用户将拥有一个开箱即用的 WireGuard。
WireGuard 没有传统的 Server 端、Client 端的概念，在 WireGuard 构建的 VPN 环境中，使用 Peer 来描述 VPN 中的每一个网络节点，这个 Peer 可以是 服务器、路由器、etc.</description></item><item><title>WireShark</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/WireShark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/WireShark/</guid><description>概述 参考
GitLab 项目，wireshark/wireshark GitHub 镜像项目 官网 官方文档，用户指南 官方 Wiki GitLab Wiki B 站，网络顶级掠食者 Wireshark抓包从入门到实战 公众号 - 马哥 Linux 运维，8 个常用的 Wireshark 使用技巧 Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形页面，同时，还内置了一系列的汇总分析工具。
TCPDump 和 Wireshark，这两大利器把我们“看不见”的数据包，呈现在我们眼前，一目了然。这两个工具就是最常用的网络抓包和分析工具，更是分析网络性能必不可少的利器。
tcpdump 仅支持命令行格式使用，常用在 Linux 服务器中抓取和分析网络包。 Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形页面。 tcpdump 虽然功能强大，但是输出的格式并不直观。所以，日常只用 tcpdump 来抓取数据包，不用来分析数据包，而是把 tcpdump 抓取的数据包保存成 pcap 后缀的文件，接着用 Wireshark 工具进行数据包的可视化分析。
Wireshark 视图 https://www.wireshark.org/docs/wsug_html_chunked/ChUseViewMenuSection.html
我们使用 tcpdump -i any port 10443 -nn -w demo-http.pcap 命令，把抓取的数据包保存到 demo-http.pcap 文件，再用 Wireshark 打开它，可以看到三个主要的窗口
Packet List(包列表) Packet Details(包详情) Packet Bytes(包字节流) Packet List 窗口：</description></item><item><title>XML 文件详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，XML 格式 Libvirt API 中的对象使用 XML 格式 的文档进行配置，以便在未来的版本中轻松扩展。每个 XML 文档都有一个关联的 Relax-NG 模式，可用于在使用前验证文档。
这里面的 Libvirt API 对象指的就是 Domain(虚拟机)、存储、快照、网络 等等。对于 Libvirt，所有 VM 相关的资源都会抽象为对象，这样也利于代码编写。
Kubernetes 的 API 对象跟这个有点像，只不过 Kubernetes 中，使用 YAML 格式来声明对象，而不是 XML 格式来配置对象。
下面是所有可用的 Libvirt API 对象，每个 Libvirt 对象 都对应一个 根元素。
Domain # 虚拟机相关的 XML 配置，可以直接使用 Domain XML 文件创建、启动、管理虚拟机。 根元素名称: &amp;lt;domain&amp;gt; Network # 虚拟网络相关的 XML 配置。 根元素名称: &amp;lt;network&amp;gt; Network filtering Network ports Storage Storage encryption Capabilities Domain capabilities Storage Pool capabilities Node devices Secrets Snapshots Checkpoints Backup jobs virt-xml-validate virt-xml-validate 工具是一个简单的检验 XML 文档的工具，直接在命令后面加上 XML 文档的 /PATH/FILE 即可对该文件进行检验，确保其在传递给 libvirt 时是正确的。</description></item><item><title>安装操作系统</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid><description>概述 参考：
Wiki, Windows_Preinstallation_Environment Wiki, Live_USB 我们想要安装操作系统，通常都需要将一个 Bootable Media(启动介质) 放到 Operating System Installation Media(操作系统安装介质) 中，一般使用介质制作工具(UltraISO、Rufus 等)来实现。这个操作系统的安装介质可以是 U盘、光盘、网络存储等。
之后，将需要安装系统的计算机与介质连接，这个介质将会被加载到内存中，从而提供一个临时的环境(这个环境有可能会类似操作系统)，人类在这个环境中可以访问计算机硬件资源和文件系统的环境，从而利用介质中的安装程序，将操作系统安装到计算机中。毕竟，只要能访问到硬件资源了了，剩下的就是将文件写入到硬盘中即可。
除了最基本的启动介质，很多操作系统的发行商还会提供一个具有微型系统能力的启动介质，这种介质除了最基本的安装能力外，还提供了很多额外的工具，以便可以修复、管理计算机，或者修复操作系统。Windows 和 Linux 对这种启动介质有各自的称呼
Preinstallation Environment # Windows 微型系统的称呼。简称 WinPE Live # Linux 微型系统的称呼。比如 Ubuntu Live Ghost 概述 参考：
Wiki, Ghost(disk utility)</description></item><item><title>编程</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E7%BC%96%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E7%BC%96%E7%A8%8B/</guid><description>概述 参考：
Wiki, Computer Programming(计算机编程) Wiki, Programmig Language(编程语言) Programming(编程) 是编写程序的行为。
无论处于上层的软件多么的高级, 想要在 CPU 执行, 就必须被翻译成“机器码”， 翻译这个工作由编译器来执行. 编译器在这个过程中, 要经过“编译”，“汇编”，“链接”几个步骤, 最后生成“可执行文件”。可执行文件中保存的是二进制机器码， 这串机器码可以直接被 CPU 读取和执行。
学习资料 参考：
公众号，微软带头打了 30 年，这场屏幕的大乱斗，终于要结束了(前端浏览器的历史) YouTube, Why Some Projects Use Multiple Programming Languages
B 站，为什么有些项目会使用多种编程语言？ 该视频还介绍了 Compiler 的部分原理。介绍了代码转换为机器码的全过程，并且非常生动。 菜鸟教程 参考：
官网 菜鸟教程提供了基础编程技术教程。
菜鸟教程的 Slogan 为：学的不仅是技术，更是梦想！
记住：再牛逼的梦想也抵不住傻逼似的坚持！
本站域名为 runoob.com, runoob 为 Running Noob 的缩写，意为：奔跑吧！菜鸟。
本站包括了 HTML、CSS、Javascript、PHP、C、Python 等各种基础编程教程。
同时本站中也提供了大量的在线实例，通过实例，您可以更好地学习如何建站。
本站致力于推广各种编程语言技术，所有资源是完全免费的，并且会根据当前互联网的变化实时更新本站内容。
同时本站内容如果有不足的地方，也欢迎广大编程爱好者在本站留言提供意见。
W3school 参考：
官网 W3school 中文 开发者资源网站(各种语言的教程、各种参考手册等等)
MDN 参考：
Wiki, MDN GitHub MDN 组织 Mozilla Developer Network(Mozilla 开发者网络，简称 MDN) 官网，这是一个汇集了众多 Mozilla 基金会产品和网络技术开发文档的网站。</description></item><item><title>编码与解码</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</guid><description>概述 参考：
Wiki, Code 在通信和信息处理中，Code(代码) 是一种规则系统，用于将信息（e.g. 字母、单词、声音、图像、手势、etc.）以另一种形式展示（e.g. 数字、短码、加密、etc.），以便可以通过通信通道或存储在存储器中进行通信。
注意与 编程 中的 Code 概念区分。虽然编程中的 Code 也有类似将一种语言转成另一种语言的概念。但是与这里的 Code 概念并不完全一样。
Encoding(编码) 是信息从一种形式或格式,转换为另一种形式或格式的过程。而 Decoding(解码) 则是编码的逆过程。
首先需要明确一点，计算机的组件处理信息都是基于 二进制 来实现的，也就是说。都是 0 和 1 这种信息，不管电路的一开一关，灯的一亮一灭，都可以用 0 和 1 来表示。而计算机也是通过 0 和 1 来存储以及处理数据的。
但是计算机在使用的时候，我们看到并不是只有 0 和 1，我们打字也不是只输入 0 和 1，不但有文字，还有图片、视频、音频等等。这是为什么呢？
由于计算机只认识 0 和 1 这种二进制数据，其他格式的数据都需要转换成二进制才能被计算机处理，也就是说我们在计算机上看到的文本、视频、可执行程序等格式的文件，最终都会进行编码以转换成二进制数据交给计算机处理；而计算机处理完成后，会进行解码以将二进制数据转换为 文本、图片、视频 等格式，以便人类可以查看。这种来回转换的过程，就称为 Encoding(编码) 与 Decoding(解码)。
总的来说，通常编码与解码是相对人类来说，把人类当做主体，i.e. 人类是数据的发送者和接收者。此时，Encoding 是将来自发送者的信息转换为用于通信和存储的符号。Decoding 是将代码符号转换回接收者可以理解的形式。
而文字、图片、音/视频 等等数据，其编码方式又各不相同。
字符编码 # 用来对文字进行 编/解码 的过程 图形编码 # 对图片进行 编/解码 的过程 音频编码 # 对音频进行 编/解码 的过程 当然，随着时代的发展，Encoding(编码) 与 Decoding(解码) 也不仅仅代指上述三种类型，就如概述中的第一句话，任何格式的数据转换成另一种，都可以称之为编码！ 比如 Base64 编码，则是可以将二进制数据，转换为字符串数据，这种行为，也可以称之为编码。</description></item><item><title>抽象数据类型</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>概述 参考：
Wiki, AbstractDataType(抽象数据类型) 在计算机科学中，Abstract Data Type(抽象数据类型，简称 ADT) 是数据类型的数学模型，从数据用户的角度由其行为（语义）定义，特别是根据可能的值、对数据的可能操作来定义。这种类型，以及这些操作的行为。该数学模型与数据结构形成对比，数据结构是数据的具体表示，并且是实现者而不是用户的观点。例如，堆栈具有遵循后进先出规则的入栈/出栈操作，并且可以使用列表或数组来具体实现。另一个例子是一个存储值的集合，没有任何特定的顺序，也没有重复的值。值本身不是从集合中检索的，而是测试成员资格值以获得布尔值“in”或“not in”。</description></item><item><title>创建虚拟机及创建后常见操作</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%8A%E5%88%9B%E5%BB%BA%E5%90%8E%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%8A%E5%88%9B%E5%BB%BA%E5%90%8E%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/</guid><description>概述 使用 virt-install 在 CLI 创建 VM 时指定 vnc 并监听在 0.0.0.0 上。使用实例中最简单的命令即可，最简单的命令只需要指定网络、连接显示的方式、系统版本、cpu、内存即可，其他虚拟设备都会又 virt-install 自动添加。并不影响性能和使用等方面。
使用 VNC 客户端连接 VM 并安装操作系统。
安装完成后，根据虚拟化调试和优化指南调优，virsh edit XXX 修改文件
使用 systemctl enable serial-getty@ttyS0.service --now 启动 serial-getty 服务，以便通过 virsh console 命令连接虚拟机
压缩 qcow2 文件，创建 backing file 的 qcow2 和 xml 文件当做模板以便批量创建虚拟机所用
qemu-img convert -c -O qcow2 test.qcow2 test.qcow2.new</description></item><item><title>存储的能力</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/</guid><description>概述 参考：
知乎，块存储、文件存储、对象存储这三者的本质差别是什么？ 基于不同的 存储的基础设施架构，我们可以实现形形色色的存储能力，每种存储能力，可以存放的数据内容各不相同。
现阶段，可以提供的存储能力分为三种：
Block Storage(块存储) File Storage(文件存储) Object Storage(对象存储) 块存储、文件存储、对象存储这三者的本质差别是什么？ 它们就是不同的接口。块存储就是最接近存储介质的接口，也就是包装最薄的，或者说没有包装。文件和对象存储都是对块存储的包装。可以简单认为对象存储就是不分层次的文件存储。或者把文件看作对象存储的进一步包装。
Block Storage(块存储) 参考：
Wiki, Block 说白了就是硬盘
File Storage(文件存储) 说白了就是 Filesystem(文件系统)
Object Based Storage(对象存储) 参考：
Wiki, Object storage 说白了就是任何东西，对象可以是任何东西。
Object Based Storage(基于对象的存储，简称 OBS) 是一种为计算机存储数据的能力。通常由分布式存储架构来实现。
与 File Storage 类似，只不过没有目录的层级结构，对象的获取，基于 RESTful 风格的 API 接口。
但是与文件存储不同，对象存储中的数据不支持在存储设备上直接修改，必须要先 GET 到要修改的对象，在本地修改完成后，再 PUT 或 POST 回去。所以，并不适合需要频繁读写的数据(例如关系型数据库的数据)。
而平时我们看到那些所谓的能在线修改的，其实是有一个客户端，我们在客户端操作，操作的时候，客户端是帮我们把对象 GET 出来的。
简单理解 1. 块存储
“虚拟座谈会”中王旭提到：块存储是给虚拟机用的。
这句话深刻地表达了什么是块存储。。不知道有没有被大家忽略过去。
对块存储最简单的理解方法就是：看产品。
例子：
Amazon 的 EC2 中就有块存储，叫做 EBS (Elastic Block Storage)。 什么鬼？</description></item><item><title>登录 Linux 与 访问控制</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</guid><description>概述 参考：
想要登录 Linux，必须通过 Terminal(终端)，我们才可以与操作系统进行交互。
本质上，想要登录 Linux，必然需要调用某些程序(比如 Shell)，以便分配一个终端。通常，我们有多种方式可供选择：
本地命令行登录 远程命令行登录 图形界面登录 Linux 操作系统是一个多用户操作系统，所以除了 Terminal(终端) 以外，还需 Account(账户) 才可以登录上去，Linux 操作系统允许多个用户访问安装在一台机器上的单个系统。每个 User(用户) 都在自己的 Account(账户) 下操作。因此，Account Manager 代表了 Linux 系统管理的核心要素。
登录 Linux 我们可以通过多种方式登录 Linux
本地登录 远程登录 通过本地 TTY 登陆 Linux 系统 登录 Linux 最基本的方式，就是使用 login 程序。
login 程序 由于历史原因，login 可能被包含在两个包中：
util-linux shadow-utils login 的登录行为 当我们刚刚安装完操作系统，systemd-logind.service 服务会让我们看到这样的画面
想要在服务器本地登录系统，则需要进行认证，在输入用户名之后，实际上是调用了 login 这个二进制程序，看到：
此时我们通过远程方式(如果可以的话)登录服务器，查看进程，将会看到名为 login 的进程
~]$ pgrep login -alf 600 /lib/systemd/systemd-logind 1476 /bin/login -p -- 当我们输入完密码，经过 Access Control(访问控制) 相关程序的认证之后，login 工具会为我们分配一个 ttyX 的终端设备，然后我们就可以通过 tty 所关联的 Shell(通常是 bash)，与系统进行交互</description></item><item><title>低级编程语言</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E4%BD%8E%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E4%BD%8E%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E4%BD%8E%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E4%BD%8E%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</guid><description>概述 参考：
Wiki, Low-level programming language</description></item><item><title>对称密钥加密</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/</guid><description>概述 参考：
Wiki, Symmetir Key Algorithm DES 参考：
Wiki, Data_Encryption_Standard B 站，【计算机博物志】DES的生与死 Data Encryption Standard(数据加密标准) 是典型基于 Block cipher(块密码/分组密码) 的加密规范，由于已被破解，被 AES 取代。
AES AES</description></item><item><title>对象存储</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/</guid><description>概述 参考：
Simple Storage Service(简单存储服务) 参考：
AWS 官方文档 Simple Storage Service(简单存储服务，简称 S3) 最早是由 AWS(亚马逊) 提出的一种对象存储服务。现在，S3 几乎称为对象存储的事实标准，各厂家基本上都会兼容 S3。</description></item><item><title>多媒体处理工具</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
知乎，视频录制、视频剪辑、字幕制作&amp;hellip;&amp;hellip;当一名 UP 主需要哪些软件 视频录制
OBS Studio GitHub 项目，alyssaxuu/screenity # 浏览器插件的屏幕录制 https://mp.weixin.qq.com/s/OxKtgIsVDwad6tqvlGnMQw 视频剪辑
Premiere Shotcut 必剪 # B 站的 字幕制作
听见字幕 GitHub 项目，Baiyuetribe/paper2gui
大家有没有遇到过一种情况，在网上好不容易找到一个开源神器，但是用不了。就比如一些 AI 视频补帧、4k 修复工具，它们大部分都是公布了一个算法模型。普通人想上手使用，没点编程基础，难度很大很大。但 GitHub 上，有个大佬把这些上手成本很高的工具，全都做成了直观的 GUI 界面，并集合在一起发布了出来。 这个叫小白兔 AI 的工具箱一共包含视频超分、音频降噪、人像抠图、人脸修复等十几种工具。 OBS Studio 参考：
GitHub 项目，obsproject/obs-studio 官网 Open Broadcaster Software(开放广播软件，简称 OBS) 是一款用于视频录制和直播的免费和开源软件
最佳实践 只录制音频
文件 - 设置 - 输出 - 输出模式 # 简单 改为 高级 录像 - 类型 # 标准 改为 自定义输出（FFmpeg） 容器格式 # 默认 改为 wav（音频） Shotcut 参考：</description></item><item><title>访问虚拟机</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/</guid><description>概述 参考：
RedHat 官方文档，8-配置和管理虚拟化-2.4 章.连接到虚拟机 我们可以通过多种方式与虚拟机进行交互：
Cockpit # 基于 Web 的控制台 Virt Manager 程序 # GUI 程序 Virt Viewer 程序 # GUI 程序 virsh console 子命令 # CLI 程序 众所周知的 ssh Cockpit 参考：
GitHub 项目，cockpit-project 官网 注意： RHEL 8 仍支持虚拟机管理器（virt-manager）应用程序，但已弃用。Web 控制台打算在后续版本中替代它。因此，建议您熟悉用于在 GUI 中管理虚拟化的 Web 控制台。详见：https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/configuring_and_managing_virtualization/index#overview-of-virtual-machine-management-using-the-web-console_using-the-rhel-8-web-console-for-managing-vms Cockpit 是一个基于 Web 的用于管理服务器的图形界面
安装 Cockpit CentOS
yum install cockpit -y &amp;amp;&amp;amp; yum install cockpit-machines -y systemctl start cockpit &amp;amp;&amp;amp; systemctl enable cockpit Ubuntu
apt update apt install -y cockpit cockpit-machines 其中 cockpit-machines 是 cockpit 的插件，用于为 cockpit 添加虚拟机管理功能。</description></item><item><title>复合数据类型</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>概述 参考：
Wiki, Composite_data_type Composite data type(复合数据类型)
原子类型的值是不能分解为组成部分的单个数据项。复合类型 或 聚合类型 的值是可以单独访问的数据项的集合。例如，一个整数通常被认为是原子的，尽管它由一系列位组成，而整数数组肯定是复合的。</description></item><item><title>高级编程语言</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</guid><description>概述 参考：
Wiki, High-level programming language 一门编程语言开发完成后，通常包含两个最关键的部分，规范与标准库
该语言基本的语法和语义，包括一些关键字、表达式、语句的说明 该语言的标准库，定义一些刚上手即常用的功能，比如格式化、网络、文件系统、数学等等。 下面来自 ChatGPT：
编程语言的规范和标准库是开发者学习和使用编程语言的重要组成部分。
规范
编程语言的规范包括语法、语义和运行时行为等方面的细节。通常由语言的开发者或指定的标准化组织制定和维护。常见的编程语言规范包括：
C语言规范 C++语言规范 Java语言规范 Python语言规范 标准库
编程语言的标准库是指开发者可以直接使用的预定义类、函数和数据类型的集合。标准库通常包含操作系统、网络、文件IO、容器、算法等方面的功能实现。常见的编程语言标准库包括：
C语言标准库 C++标准库 Java标准库 Python标准库 开发者可以通过学习编程语言的规范和标准库，更好地理解和掌握编程语言，提高开发效率和代码质量。
高级编程语言列表 C
Go
Python
Rust
Java
ECMAScript
易语言（Easy Programming Language，简称 EPL）
不开源的。语言关键字纯中文，使用中文编写代码 https://www.eyuyan.com/, https://www.dywt.com.cn/ 这俩域名指向了同一个 IP，应该是官网 https://bbs.125.la/ 精益论坛 Perl Perl，一种功能丰富的计算机程序语言，运行在超过 100 种计算机平台上，适用广泛，从大型机到便携设备，从快速原型创建到大规模可扩展开发。 Perl 语言的应用范围很广，除 CGI 以外，Perl 被用于图形编程、系统管理、网络编程、金融、生物以及其他领域。 由于其灵活性，Perl 被称为脚本语言中的瑞士军刀。</description></item><item><title>公开密钥加密</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/</guid><description>概述 参考：
Wiki, PKC 英文 Wiki, 数字签名 阮一峰 知乎,RSA 的公钥和私钥到底那个才是用来加密和哪个用来解密 Wiki, 公开密钥加密 中文 https://arthurchiao.art/blog/everything-about-pki-zh 甲方选择某种加密规则，对信息进行加密 乙方使用同一种规则，对信息进行解密 由于加密和解密使用同样规则（简称&amp;quot;密钥&amp;quot;），这被称为 Symmetric-key algorithm(对称密钥算法)。这种加密模式有一个最大弱点：甲方必须把加密规则告诉乙方，否则无法解密。保存和传递密钥，就成了最头疼的问题。因为大多数情况下，其实两方之间的通信，只有一方是需要加密的，另一方只需要知道信息内容。
1976 年，两位美国计算机学家 Whitfield Diffie 和 Martin Hellman，提出了一种崭新构思，可以在不直接传递密钥的情况下，完成解密。这被称为&amp;quot;Diffie-Hellman 密钥交换算法&amp;quot;。这个算法启发了其他科学家。人们认识到，加密和解密可以使用不同的规则，只要这两种规则之间存在某种对应关系即可，这样就避免了直接传递密钥。
这种新的加密模式就被称为&amp;quot;非对称密钥算法&amp;quot;。
（1）乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。 （2）甲方获取乙方的公钥，然后用它对信息加密。 （3）乙方得到加密后的信息，用私钥解密。
如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。
1977 年，三位数学家 Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做 RSA 算法。从那时直到现在，RSA 算法一直是最广为使用的&amp;quot;非对称加密算法&amp;quot;。毫不夸张地说，只要有计算机网络的地方，就有 RSA 算法。
这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长 RSA 密钥是 768 个二进制位。也就是说，长度超过 768 位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024 位的 RSA 密钥基本安全，2048 位的密钥极其安全。
PKC 特点 这种加密方式，需要一对密钥。只有公钥可以加密，私钥不能用来加密数据。 Public key(公钥) # 公开给所有人。用来加密数据、验证签名。使用公钥把明文加密后所得的密文，只能使用对应的私钥才能解密并得到原本的密文。反之不行。 Secret key(私钥) # 自己留存，必须保证其私密性。用来解密数据、签名。使用私钥创建数字签名，只能使用公钥才能验证该数字签名的有效性。反之不行。 一般情况，密钥对是通过程序自动生成的。首先生成私钥后，公钥包含在私钥当中 Digital signature(数字签名)。签名提供的是真实性，而不是保密性。 所谓的数字签名，就像人们日常生活中在文件上签字一样，都是签名的一种。 而所谓的验证签名，其实就像日常生活中，看看签名的人的笔记与签名是否一致，等等类似的行为 总结一下：既然是加密，那肯定是不希望别人知道发送给我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。</description></item><item><title>公众号,码农的荒岛求生-操作系统话题系列文章</title><link>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/</guid><description>系列文章目录</description></item><item><title>构建 OCI Image</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/%E6%9E%84%E5%BB%BA-OCI-Image/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/%E6%9E%84%E5%BB%BA-OCI-Image/</guid><description>概述 参考：
官方文档，使用 Docker 开发-构建镜像-编写 Dockerfile 的最佳实践 在容器刚刚流行的时候，想要构建一个容器镜像通常只有两种方式：
通过对 Container 执行 commit 命令来创建基于该 Container 的 Image 通过 Dockerfile 功能来构建 Image Dockerfile 构建镜像的方式逐渐成为主流甚至标准，但是随着各个项目的去 Docker 化，大家都想消除自身对 Docker 的依赖，这其中包括 Docker 项目的起源 Moby，从这里(moby/moby 的 issue #34227)可以略窥 12。但是 Dockerfile 的影响已经深入人心，所以各家一时半会也无法完全舍弃，只能说基于 Dockerfile 形式进行优化。时至今日(2022 年 6 月 3 日)，Dockerfile 依然是最常见最通用的构建镜像的方式，不管构建程序是什么，总归是要通过 Dockerfile 文件的。
Dockerfile 参考：
官方文档 Dockerfile 参考 Docker 通过读取 Dockerfile 文件中的指令来构建符合 OCI 标准的容器镜像。Dockerfile 这个称呼有多个理解方式，可以是指一个功能，也可以指一个文件的文件名，也可以代指一类文件的统称。
DockerFile 功能的工作逻辑 找一个专用目录，在目录中放入默认的名为 Dockerfile 的文件，该文件名首字母必须大写 Dockerfile 文件，类似于一个脚本，使用 docker build 命令创建镜像的时候默认使用名为 Dockerfile 的文件，通过该文件中的各种指令来执行操作。（如果想使用其余名字的文件，则需要使用-f 参数来指明需要使用的 DockerFile 的文件，这时候可以使用名字不为 Dockerfile 的文件） 如果该 Image 中需要打包进去很多文件(比如 rpm 包、配置文件等等)，则这些文件必须做好后，放到 Dockerfile 所在的目录中(可以有子目录)。 使用 docker build 命令并用指定目录路径，则该命令会自动查找该目录下的名为 Dockerfile 文件并根据其中内容创建 Image，效果如上图所示 具体过程详解如下 首先在当前目录创建一个名为 Dockerfile 的文件，在该文件中写入需要执行的指令 ~]# ll total 4 -rw-r--r--.</description></item><item><title>机器学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid><description>概述 参考：
Wiki, Machine_learning Wiki, Data mining Machine learning(机器学习，简称 ML) 是一个致力于理解和构建让机器“学习”的方法的领域 - 就是利用数据提高计算机在某些任务上性能的方法。
就像人需要学习一样，机器也需要学习。机器学习是人工智能的一个广泛子领域。
机器学习通常需要一个模型和训练模型的方法，通过训练好的模型，可以更准确得预测或分类新的未见过的数据。e.g. 自然语言处理中，当我们向模型提交输入的文字后，模型会根据参数，逐步预测将要输出的每一个文字，每个文字都是由模型根据训练好的参数，依据统计学的百分比概率推导出来的。
我们人类好像也是通过这种方式沟通的，每个字都在脑子中依据已有知识，推理出来后，逐一说出来。
TODO: 这都是啥？
Convolutional Neural Network(卷积神经网络简称 CNN) Transformer(变压器) Generative Adversarial Network(对抗网络模型，简称 GAN) TODO: Data mining(数据挖掘)
学习方法 参考：
https://en.wikipedia.org/wiki/Machine_learning#Approaches Wiki, Supervised learning 监督学习 Wiki, Unsupervised learning 无监督学习 Supervised learning(监督学习) Unsupervised learning(无监督学习) Reinforcement learning(强化学习) etc. Claude 交流：
问：AI 领域，监督学习和无监督学习的区别是是否使用训练集么？
答：（多次问答后的个人总结）
不完全正确。让我来解释监督学习和无监督学习的主要区别:
监督学习和无监督学习的核心区别在于训练数据是否有标签，而不是是否使用训练集。两种方法都需要使用训练数据。
监督学习:
训练数据包含输入特征和对应的标签/答案 例如:图片分类中,每张图片都标注了&amp;quot;猫&amp;quot;或&amp;quot;狗&amp;quot; 算法目标是学习输入到标签的映射关系 常见应用：分类、回归预测 最终目标是：给一张新图片,能准确判断是猫还是狗 无监督学习:
训练数据只有输入特征，没有标签，训练数据是 1000 张动物图片，但没有任何标注 模型会基于图片的相似度(如颜色分布、形状特征等)自动分组 最终可能会将图片分成几类: 一类都是毛茸茸、有尖耳朵的(实际上是猫) 一类都是体型较大、有长嘴的(实际上是狗) 但模型并不知道这些类别的具体含义 算法目标是发现数据中的内在结构和模式 常见应用：聚类分析、降维、异常检测 最终目标是：给一张新图片，能够判断它与哪组已有图片最相似，将它自动归类到相应的组别中 简单来说:</description></item><item><title>集群与分布式</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/</guid><description>Cluster(集群) 概述 当单独一台主机无法承载现有的用户请求量；或者一台主机因为单一故障导致业务中断的时候，就可以增加服务主机数，这些主机在一起提供服务，就叫集群，而用户所看到的依然是单个的主机，用户并不用知道具体是集群内哪台设备为我提供服务，只需要知道访问集群的入口即可。
集群类型包括：
LB # Load Balancing 负载均衡 HA # High Availability 高可用，双机主备 HP # High Performancing 高性能 构建高可扩展性系统的重要原则：在系统内部尽量避免串行化和交互
Load Balancing(负载均衡) 集群 根据请求报文的目标 IP:PORT 将其转发至后端主机集群中的某一台主机
LB 的作用：将业务请求分摊到多个后端设备进行执行，例如 Web 服务器、FTP 服务器等，当一台 web 服务器为 1W 人提供服务的时候，为了减少单台服务器的压力，可以把 1W 人分成 4 份，增加三台服务器，四台服务器每台 2500 人，共同完成工作任务，就算一台坏掉了，其余三台还能正常提供服务。也是变相实现了高可用，可以解决单点故障
类似于交换机的转发以及路由器的转发，都是把收到的请求转发到另一个地方，LB 可以称为 4 层交换或 4 层路由，工作在 4 网络 7 层模型中 4 层及以上，主要是对协议请求报文进行广播，转发，广播是对于同一个区域来进行的（LB 整个架构中的每一台设备都相当于交换机一个端口，其中一个端口(调度器)收到请求报文，广播给其余的 RS 或选择一个 RS 进行接收该请求）
负载均衡实现方式从软硬件来区分，分两种：
硬件负载均衡：通过硬件设备来实现负载均衡功能，国内常用前三家的设备 F5 厂家的 BIG-IP，最好的，并发承载能力最高，价格也是最好的 Citrix(思捷)厂家的 NetScaleer A10 厂家的 A10 Array 厂家 Redware 等等等 软件负载均衡：通过软件技术来实现负载均衡功能 LVS(Linux virtual server)，Linux 自带的功能 2.</description></item><item><title>计算机科学</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/</guid><description>概述 参考：
王垠博客，解谜计算机科学 Wiki 分类，Computer science(计算机科学) Wiki 分类，Computer programming(计算机编程) Wiki 分类，Programming language concepts(编程语言概念) Wiki 分类，Programming constructs(编程结构) Wiki 分类，Programming languages(编程语言) Wiki, Identifier(标识符) Wiki, Symbol(符号) Wiki, DataType(数据类型) Wiki, Variables(变量) Wiki, Assignment(赋值) Wiki, Declaration(声明) 与 Definition(定义) 要掌握一个学科的精髓，不能从细枝末节开始。人脑的能力很大程度上受限于信念。一个人不相信自己的时候，他就做不到本来可能的事。信心是很重要的，信心却容易被挫败。如果只见树木不见森林，人会失去信心，以为要到猴年马月才能掌握一个学科。
所以我们不从 “树木” 开始，而是引导读者一起来探索这背后的“森林”，把计算机科学最根本的概念用浅显的例子解释，让读者领会到它们的本质。把这些概念稍作发展，你就得到逐渐完整的把握。你一开头就掌握着整个学科，而且一直掌握着它，只不过增添更多细节而已。这就像画画，先勾勒出轮廓，一遍遍的增加细节，日臻完善，却不失去对大局的把握。
一般计算机专业的学生学了很多课程，可是直到毕业都没能回答一个基础问题：什么是计算？这一章会引导你去发现这个问题的答案。不要小看这基础的问题，它经常是解决现实问题的重要线索。世界上有太多不理解它的人，他们走了很多的弯路，掉进很多的坑，制造出过度复杂或者有漏洞的理论和技术。
接下来，我们就来理解几个关键的概念，由此接触到计算的本质。
手指算术 每个人都做过计算，只是大部分人都没有理解自己在做什么。回想一下幼儿园（大概四岁）的时候，妈妈问你：“帮我算一下，4+3 等于几？” 你掰了一会手指，回答：7。当你掰手指的时候，你自己就是一台简单的计算机。
不要小看了这手指算术，它蕴含着深刻的原理。计算机科学植根于这类非常简单的过程，而不是复杂的高等数学。
现在我们来回忆一下这个过程。这里应该有一段动画，但现阶段还没有。请你对每一步发挥一下想象力，增加点 “画面感”。
当妈妈问你 “4+3 等于几” 的时候，她是一个程序员，你是一台计算机。计算机得到程序员的输入：4，+，3。 听到妈妈的问题之后，你拿出两只手，左手伸出四个指头，右手伸出三个指头。 接着你开始自己的计算过程。一根根地数那些竖起来的手指，每数一根你就把它弯下去，表示它已经被数过了。你念道：“1，2，3，4，5，6，7。” 现在已经没有手指伸着，所以你把最后数到的那个数作为答案：7！整个计算过程就结束了。 Identifier(标识符) 和 Model(模型) 这里的幼儿园手指算术包含着深刻的哲学问题，现在我们来初步体会一下这个问题。
当妈妈说 “帮我算 4+3” 的时候，4，+，3，三个字符传到你耳朵里，它们都是 Identifier(标识符)，有的时候也称为 symbol(符号)。符号是 “表面” 的东西：光是盯着 “4” 和“3”这两个阿拉伯数字的曲线，一个像旗子，一个像耳朵，你是不能做什么的。你需要先用脑子把它们转换成对应的“模型”（model）。这就是为什么你伸出两只手，一只手表示 4，另一只表示 3。
这两只手的手势是 “可操作” 的。比如，你把左手再多弯曲一个手指，它就变成 “3”。你再伸开一根手指，它就变成“5”。所以手指是一个相当好的机械模型，它是可以动，可操作的。把符号“4” 和“3”转换成手指模型之后，你就可以开始计算了。</description></item><item><title>计算机视觉</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</guid><description>概述 参考：
Wiki, Computer vision Wiki 类别，Computer vision Wiki 类别，Applications of computer vision Computer vision(计算机视觉) 任务包括获取、处理、分析和理解数字图像的方法，以及从现实世界中提取高维数据以产生数字或符号信息的方法，例如以决定的形式。 在这种情况下，理解意味着将视觉图像（视网膜的输入）转化为对思维过程有意义并可以引发适当行动的世界描述。这种图像理解可以看作是使用借助几何、物理学、统计学和学习理论构建的模型从图像数据中分离出符号信息。
视觉模型 YOLO
Segment Anything Model 这个怎么样？
etc.
Halcon 与 OpenCV OpenCV Halcon 开发语言 C++、C#（emgu）、Python、Ruby、MATLAB等语言 C，C++，C#，Visual basic和Delphi等语言 应用场合 侧重计算机视觉领域，侧重研究领域 侧重机器视觉领域，侧重应用领域 费用 免费 收费 开放性及版本更新速度 开源（可看底层源码），版本和功能更新慢 商业软件（底层代码封装），版本和功能更新快 对使用者的门槛 偏科研，有难度，有深度，完全从底层开发，对使用者门槛高，开发效率低，开发慢 偏工程应用，使用封装好的功能函数，对使用者门槛低，开发效率高，开发快 资料及技术支持 资料少。遇到问题，难以获得技术支持 资料多。遇到问题，可以及时、有效的获得技术支持 学习资料 B 站，唐宇迪，【唐宇迪AI分享】CV和NLP两大板块一定要先选CV！！！
Tasks 计算机视觉任务通常包括 Object detection、Keypoint detection、Pose estimation、etc.</description></item><item><title>假如你来发明编程语言</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</guid><description>原文链接: 公众号 - 码农的荒岛求生, 假如你来发明编程语言
聪明的人类发现把简单的开关组合起来可以表达复杂的bool逻辑，在此基础之上构建了 CPU ，因此 CPU 只能简单的理解开关，用数字表达就是0和1。
创世纪：聪明的笨蛋
CPU 相当原始，就像单细胞生物一样，只能把数据从一个地方搬到另一个地方、简单的加一下，没有任何高难度动作，这些操作虽然看上去很简单很笨，但 CPU 有一个无与伦比的优势，那就是一个字：快，这是人类比不了了的，CPU 出现后人类开始拥有第二个大脑。
就是这样原始的一个物种开始支配起另一个叫做程序员的物种。
干活的是大爷 一般来说两个不同的物种要想交流，比如人和鸟，就会有两种方式：要不就是鸟说人话，让人听懂；要不就是人说鸟语，让鸟听懂；就看谁厉害了。
最开始 CPU 胜出，程序员开始说鸟语并认真感受 CPU 的支配地位，好让 CPU 大爷可以工作，感受一下最开始的程序员是怎么说鸟语的：
程序员按照 CPU 的旨意直接用0和1编写指令，你没有看错，这破玩意就是代码了，就是这么原生态，然后放到打孔纸带上输入给CPU，CPU 开始工作，这时的程序可真的是看得见摸得着，就是有点浪费纸。
这时程序员必须站在 CPU 的角度来写代码，画风是这样的：
`1101101010011010``1001001100101001``1100100011011110``1011101101010010` 乍一看你知道这是什么意思吗？你不知道，心想：“这是什么破玩意？”，但 CPU 知道，心想“这就简直就是世界上最美的语言”。
天降大任 终于有一天程序员受够了说鸟语，好歹也是灵长类，叽叽喳喳说鸟语太没面子，你被委以重任：让程序员说人话。
你没有苦其心志劳其筋骨，而是仔细研究了一下 CPU，发现 CPU 执行的指令集来来回回就那么几个指令，比如加法指令、跳转指令等等，因此你把机器指令和对应的具体操作做了一个简单的映射，把机器指令映射到人类能看懂的单词，这样上面的01串就变成了：
sub $8, %rsp mov $.LC0, %edi call puts mov $0, %eax 这样，程序员不必生硬的记住1011&amp;hellip;..，而是记住人类可以认识的ADD SUB MUL DIV等这样的单词即可。
汇编语言就这样诞生了，编程语言中首次出现了人类可以认识的东西。
这时程序员终于不用再“叽叽喳喳。。”，而是升级为“阿巴阿巴。。”，虽然人类认知“阿巴阿巴”这几个字，但这和人类的语言在形式上差别还是有点大。
细节 VS 抽象 尽管汇编语言已经有人类可以认识的单词，但汇编语言和机器语言一样都属于低级语言。
所谓低级语言是说你需要关心所有细节。
关心什么细节呢？我们说过，CPU 是非常原始的东西，只知道把数据从一个地方搬到另一个地方，简单的操作一下再从一个地方搬到另一地方。
因此，如果你想用低级语言来编程的话，你需要使用多个“把数据从一个地方搬到另一个地方，简单的操作一下再从一个地方搬到另一地方”这样的简单指令来实现诸如排序这样复杂的问题。
有的同学可能对此感触不深，这就好比，本来你想表达“去给我端杯水过来”：
如果你用汇编这种低级语言就得这样实现：</description></item><item><title>监控系统概述</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</guid><description>概述 参考：
马哥视频 公众号，贵司的监控系统处于什么时代 Network Monitor Server(网络监控服务器，简称 NMS)。最早的时候，在产生大规模监控需求前，一般都是通过在本机安装监控系统来实现对单台主机进行监控，后来当主机越来越多，这种让每台设备各自监控的方式显然是不行的，这时候为了解决这个问题，一般采用的方式是通过一个 NMS 来监控各个 node host，这台 NSM 要求能够定期得向每个被监控 node host 的传感器发送数据采集请求，各 node 收到请求后，收集对方请求的本地指标来返回给 NMS
NMS 会周期得完成数据采集，然后进行本地存储。为了实现简单便捷对被监控节点进行管理，就出现了 SNMP 这个协议。SNMP 是一种基于 UDP 的 7 层协议。
监控协议：
SNMP # 详见 SNMP(传统监控标准) HTTP # 详见 HTTP(新监控标准) 时间序列数据 在监控体系里，被采集的数据一般就称为 时间序列数据。通常人们将每一条时序数据，也称为 Metrics(指标)。一系列的指标，就是用来总结被监控目标在一段时间内的运行状态。
Metrics(指标) 就是指随时间变化的数据。不管是通过 SNMP 还是 HTTP 中的任何一种协议，从被监控对象采集到的状态信息，都统称为 Metrics(指标)。
监控系统组件 一套完整的监控系统，通常都包含实现下面几种功能的组件：
指标数据采集(有时候 采集 也称为 刮擦/抓取，英文一般是 Scrape) 指标数据存储 指标数据趋势分析及可视化 告警 常见的监控对象 系统层监控
硬件状态 系统监控：CPU、Load(负载)、Memory、DiskIO、Processes、Kernel Parameters 等等 网络监控：网络设备、网络延迟、丢包率 扽等 端口存活状态、JVM 的状态等 中间件及基础设施类系统监控</description></item><item><title>紧急模式或救援模式</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%B4%A7%E6%80%A5%E6%A8%A1%E5%BC%8F%E6%88%96%E6%95%91%E6%8F%B4%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%B4%A7%E6%80%A5%E6%A8%A1%E5%BC%8F%E6%88%96%E6%95%91%E6%8F%B4%E6%A8%A1%E5%BC%8F/</guid><description>概述 Linux 系统难免出现问题，下面总结了一些在出现问题时，可以用到的修复方式。
比如 单用户模式、GRUB 命令操作、Linux 救援模式 的故障修复案例。
一般的故障修复，都是通过进入一个微型系统，并在微型系统中关联正常系统，来实现对正常系统进行修复操作的。常见的微型系统大体分为两类：
存在于内核中的微型系统，通过内核来启动 通过外部挂载(光盘、usb 等)的方式来启动 Preinstallation Environment 版本与 Live 版本是 Windows 和 Linux 的预安装系统的两种微型系统的称呼。 部分 Linux 发行版的安装 iso 中也会自带一个微型系统（比如 CentOS），而没有专门的 Live 系统。 Emergency(紧急) 模式 Linux 系统提供了紧急模式(类似 Windows 安全模式)，该模式镶嵌在内核中。可以在最小环境中(仅仅运行系统所需的必要程序)进行系统维护。在紧急模式中，Linux 引导进入根 shell，网络被禁用，只有少数进程运行。紧急模式可以用来修改文件系统损坏、还原配置文件、移动用户数据等。
启动紧急模式 在该界面选中想要使用的内核后，按 e 键 ，进入编辑启动参数界面
在上图红框位置将 ro 改为 rw init=/sysroot/bin/sh 。然后按 ctrl+x 来启动。这时候，就进入了紧急模式，紧急模式的界面是像下图这样的
这是一个 sh 的 shell(也可以启动其他 shell，比如 bash 等)，可以执行一些基本命令，目录结构如下
~]# ls bin dev dracut-state.sh etc init lib lib64 proc root run sbin shutdown sys sysroot tmp usr var 其中 sysroot 目录，就是我们正常启动系统时，所看到的 / 目录</description></item><item><title>模板</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E6%9D%BF/%E6%A8%A1%E6%9D%BF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E6%9D%BF/%E6%A8%A1%E6%9D%BF/</guid><description>概述 参考：
官网文档，模板 Hugo 为了将 Content 添加到 Layout 中，将所有的 Content 抽象为如下几种类型的 Page：
Home Page(主页) # $Kind 值为 home。 Regular Pages(常规页) # $Kind 值为 page。 Section Pages(部分页) # $Kind 值为 section。 Taxonomy Pages # $Kind 值为 taxonomy。 Term Pages # $Kind 值为 term。 Hugo 将模板分为如下几种类型：
Base Templates(基本模板) List Templates Homepage Templates Section Templates(部分模板) Taxonomy Templates Single Page Templates Content View Templates Data Templates Partial Templates Shortcode Templates Local File Templates Menu Templates RSS Templates Internal Templates 404 Page Pagination(分页) Template Debugging Hugo 的每种模板都可以渲染一种或多种类型的页面。在开始准备渲染页面时，首先要确定页面的 Kind 变量的值，即.</description></item><item><title>模块</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E5%9D%97/%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E5%9D%97/%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
Hugo 模块是一个类似 Go 模块一样的存在。模块可以是我们的主项目或其他较小的模块，Hugo 的模块可以当作 Hugo 的 7 种组件类型中的一种或多种：
static content layouts data assets i18n archetypes 也就是说，导入某某模块，也可以说是导入一个 static、一个 content、etc.
在 hugo.toml 文件中的 module 字段添加配置，即可为站点设置引用的模块，我们可以将主题当做一个模块。
注意：Hugo 模块与 Go 模块一样，也需要一个代理服务器，我们只需要在 module 部分配置 proxy 指令，值与 go proxy 一样即可
关联文件与配置 ${TMP}/hugo_cache/modules/ # 模块缓存路径</description></item><item><title>内容管理</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E5%86%85%E5%AE%B9%E7%AE%A1%E7%90%86/%E5%86%85%E5%AE%B9%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E5%86%85%E5%AE%B9%E7%AE%A1%E7%90%86/%E5%86%85%E5%AE%B9%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
官方文档，内容管理 Content(内容)
为了让静态站点生成器实现可扩展性和可管理型，我们可以为文章添加 FrontMatter(前页) 和 Templates(模板)。Hugo 基于这种特性，设计时不仅考虑了开发人员，还考虑到了内容管理者和作者。
内容的部分 Content Sections(内容部分) 是根据 content/ 目录下的组织结构定义的页面集合。
所有包含 _index.md 文件的目录都称为一个 Section(部分)。默认情况下 content/ 下的所有一级目录都是自己的 Root Section(根部分)。
比如：
content/ ├── _index.md ├── blog │ └── _index.md ├── docs │ ├── _index.md │ ├── front-matter-demo.md │ └── markdown-demo.md └── posts └── _index.md 整个网站分为三个 Sections，分为是 blog、docs、posts。说白了，blog/_index.md 文件就表示 blog/ 目录及其内的所有文件都属于 blog Section。
部分的嵌套：
content └── blog &amp;lt;-- blog 部分, 因为这是在 content/ 下的一级目录 ├── funny-cats │ ├── mypost.md │ └── kittens &amp;lt;-- kittens 部分, 因为包含 _index.</description></item><item><title>日志系统</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</guid><description>概述 参考:
Wiki, Syslog RFC 5424 - The Syslog Protocol 背景 在系统上，不管是系统本身还是外部程序，在开始、运行、结束的一整套过程中，都会产生信息，这些信息包括：何时、何地(e.g. 来源 IP)、何物(e.g. 什么程序)、发生了什么事情等。i.e. 记录系统在什么时候由哪个程序做了什么样的行为时，发生了何种事件等等。而发生的事情又有等级的区别，哪些信息是危险的，哪些信息是标准可以不用关注的等。这些信息就统称为 Log(日志)。
随着时代发展，操作系统、程序、硬件设备等等都会产生日志，如此众多的日志需要一个标准来进行定义，这个日志标准就是 Syslog Protocol，由 IETF 给定的 RFC 5424 规范来执行。而在 IT 行业，一般也把各个事务所生成的日志称为 syslog。
日志的生成 操作系统、进程和应用程序的编写者完全清楚他们将生成的事件。在某些情况下，生成消息用来说明状态。可以是一段时间一次，也可以由其他方式触发，例如在程序退出时。在其他情况下，消息是由遇到的条件产生的。在这些情况下，不管是状态消息或者包含一些类型的警告都可能被产生。操作系统、进程和应用程序的编写者可能会在详单中确定消息的数量。这些详单中通常包括发出消息的设备，同时包含消息的严重级别。这样，操作员可以有选择地筛选消息，可以更快的定位更加重要的和有处理时间限制的消息，同时可以将状态或消息信息放在文件中，将来阅读他们。其他显示和保存信息的方式也可以存在。
必须在设备中配置一些规则，这些规则可以告诉设备显示还是转发事件消息。这些规则是十分灵活的。管理员可能希望所有的信息都保存在本地，同时所有高优先级的消息都会转发到另一台设备中。他们可能发现，将某些设备的信息发送到一些或所有用户的设备中，同时显示在系统控制台上是很合适的。然而，管理员决定将事件信息发送到 syslog 采集器中，在采集器中包含了组成设备的信息以及发送的严重级别，同时定义了远程接收器。例如，系统管理员可能想让所有由邮件设备发出的消息被转发到一个特定的事件信息采集器中。管理员还可以让所有内核生成的事件信息被发送到另一台 syslog 接收器中，同时，将内核产生的 critical 严重级别的消息发送到第三台设备中。同时，将显示在系统控制台中的信息 email 给部分用户，同时将他们保存在设备本地磁盘的文件中。反之，可以将本地进程产生的消息显示在控制台中，但不保存也不转发。所有事件的规则都在设备中生成。因为管理员知道 collector 会收集到哪种类型的事件，他们会在 syslog 服务器中配置相应的规则。
消息的内容因创建者而异。建议将消息按照一定格式编写，这样人们就可以阅读他们。在消息中加入时间戳和发出消息的设备以及进程的标识符是一个很好的建议。但他们都不是必须的。
假设任何进程和设备都有可能产生事件消息。可能包含没有任何本地存储空间的设备，例如打印机、路由器、集线器、交换机以及无盘工作站。在这种情况下，将事件消息传送到 collector 可能是必要的，以便操作者可以记录并希望看到它们。
日志的收集 日志收集起来，才能方便管理人员进行查看并进行故障排除。如此众多事物的日志如果想要统一管理，就需要一套程序来对所有事物的日志进行收集、处理、保存、过滤、分析等，可以实现该功能的程序有以下几个：
sysLog 程序与 syslog 标准重名，是早期的 Linux 用于处理系统上所有事物日志的程序 RsysLog 是 sysLog 的升级版 ELK/EFK 是很重量级，功能很全的 3 款程序的统称 Eleasticsearch 是一个存储系统和搜索引擎 logstash、Fluentd 日志收集 kibana 日志的前端展示 日志的生成与收集的通用流程 当一个程序生成日志后，一般调用一个 output() 函数，把生成的日志输出到某处，e.</description></item><item><title>时间序列数据</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE/</guid><description>概述 参考：
Wiki, Time series InfluxDB 官网，什么是时间序列数据 论文原文 Time Series(时间序列) 在数学概念中，是按时间顺序索引(或列出或绘制)的一系列数据点。最常见的是，时间序列是在连续的相当间隔时间点上获取的序列。因此，它是一系列 Discrete Time(离散时间) 数据。
Time Series Data(时间序列数据，简称 series) 是在一段时间内通过重复 Measurement(测量) 而获得的观测值的集合；可以将这些观测值绘制于图形之上，它会有一个数据轴和一个时间轴。横轴(也叫 x 轴)代表时间，纵轴(也叫 y 轴)代表观测到的值。
时间序列数据无处不再，因为时间是所有可观察到的事务的组成部分。随着我们对世界的仪器化程度越来越高，传感器和系统不断地发出无休无止的时间序列数据流。这样的数据在各个行业中都有大量的应用。
时间序列数据可用于
跟踪每小时、每日、或每周的天气数据 跟踪应用程序的性能变化 医疗设备可实时观察生命体征 跟踪网络日志 &amp;hellip;&amp;hellip;等等等 时间序列数据示例 示例 1：天气情况 气象记录，经济指标和患者健康发展指标-均为时间序列数据。时间序列数据还可以是服务器指标，应用程序性能监视，网络数据，传感器数据，事件，点击次数和许多其他类型的分析数据。
请注意，如下图底部所示，时间是底部的轴。
示例 2：股票交易所 在下面的下一张图表中，请注意时间作为衡量股价变化的轴。在投资中，时间序列会跟踪数据点的移动，例如在指定时间段内的证券价格，并定期记录数据点。可以短期（例如，一个工作日内每小时的证券价格）或长期（例如五年内每个月的最后一天收盘价）进行跟踪）。
示例 3：群集监视 下面的群集监视示例描述了磁盘操作的写入和使用情况数据，这是 Network Operation Center 团队所熟悉的。请记住，监视数据是时间序列数据。
示例 4：健康监控 时间序列数据的另一个常见示例是患者健康监测，例如心电图（ECG），它可以监测心脏的活动以显示其是否正常工作。
示例 5：日志 除了按固定的时间间隔捕获之外，还可以随时捕获时间序列数据，无论时间间隔如何，例如在日志中。日志是事件，进程，消息以及软件应用程序与操作系统之间的通信的注册表。每个可执行文件都会生成一个日志文件，其中记录了所有活动。日志数据是分类和解决问题的重要上下文资源。例如，在联网中，事件日志有助于提供有关网络流量，使用情况和其他条件的信息。
示例 6：跟踪 跟踪（应用程序在执行过程中执行的子例程调用的列表）也是时间序列数据。在下面的跟踪图中的彩色带上，您可以看到时间序列数据的示例。跟踪的目的是跟踪程序的流程和数据进度。跟踪包含对应用程序的广泛，连续的视图，以查找程序或应用程序中的错误。
上面的示例包含两种不同类型的时间序列数据，如下所述。
时间序列数据的组成 Time Series(时间序列) 有时候简称为 Series。比如有这么几种描述：一系列的书、这一系列操作、等等。可以通过这种语境来理解 series(比如可以这么描述：这一系列数据)。
一条时间序列数据，通常由如下及部分组成：
Metrics(指标) # 用来描述要采集的数据指标。例如：检测各个城市的风力、系统内存已使用的字节数 等等。相当于关系型数据库中的表。 Sample(样本) # 针对监测对象的某项指标(由 Metric 和 Tag 定义)按特定时间间隔采集到的每个 Metric 值就是一个 Sample(样本)。类似关系型数据库中的一行。 Metrics(指标) 有的地方也称为 Metrics(度量)</description></item><item><title>数据存储</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</guid><description>概述 参考：
Data Storage(数据存储)
数据的检索可能与 Hashing 有很大的关系
Metadata(元数据) 又称中介数据、中继数据，为描述数据的数据（data about data），主要是描述数据属性（property）的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能。元数据算是一种电子式目录，为了达到编制目录的目的，必须在描述并收藏数据的内容或特色，进而达成协助数据检索的目的。都柏林核心集（Dublin Core Metadata Initiative，DCMI）是元数据的一种应用，是 1995 年 2 月由国际图书馆电脑中心（OCLC）和美国国家超级计算应用中心（National Center for Supercomputing Applications，NCSA）所联合赞助的研讨会，在邀请 52 位来自图书馆员、电脑专家，共同制定规格，创建一套描述网络上电子文件之特征。
例：一个文件的创建日期，所在位置等，除了文件内容以外的东西都可以称之为元数据。
备份和归档的区别 不同的过程会导致不同的结果。归档最通用的定义是存储有组织的数据。归档的目的是长时间存放有组织的数据集，确保其将来能够被精细地检索。改进的磁带是这种应用最理想的方式。FujiFilm 对它的新一代 BaFe 磁带产品的弹性测试证明其数据保存能力很强，可以存储 30 年以上。 相比之下，磁盘的故障率比其制造商说的还要高，几年前 Carnegie Mellon University 和 Google 的研究记录证明了这一点。
备份是短时间存储那些频繁更换或更新的数据的副本。这相当于一批廉价的离线介质上的数据副本。通过这种方式，可以把数据与那些基于磁盘的数据中断事件隔离开，以免同时遭到损坏，这样，如果原始数据或存储平台损坏的话，数据就可以恢复到任何磁盘阵列。在磁盘到磁盘复制解决方案中，复制只能发生在两个完全相同的设备中。此外，复制过程还可以中断，这样你就可以检查在主数据存储和镜像仓库之间的增量或差异。不过，最好别这样做，因为它可能会导致在磁盘到磁盘的复制过程中产生很多不易察觉的错误。 很遗憾，我发现你在努力保护你的数据时，它已经在阵列之间移动了，而你只镜像复制了一个空白空间
原文链接： https://searchstorage.techtarget.com.cn/6-23590/</description></item><item><title>数据库</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>概述 参考：
DB-Engines(所有数据库的排名、状态等信息的观察网站) 数据库是由特定软件（所谓的数据库管理系统(简称 DBMS)）管理的数据的逻辑集合。数据库和 DBMS 共同构成数据库系统。
A database is a logical collection of data which is managed by a specific software (the so-called database management system or DBMS). Database and DBMS together form the database system.
数据库不仅包括用户数据，还包括对其进行管理所需的对象（例如索引或日志文件）。
A database includes not only user data but also the objects necessary for its management (e.g. indexes or logfiles).
数据库的类型
RDBMS：关系型数据库 Oracle MariaDB/MySQL NoSQL：非关系型数据库 Key/Val NoSQL：redis,etcd Column Family NoSQL 列族：HBase Documentation NoSQL：MongoDB Graph NoSQL：Neo4j NewSQL：分布式数据库 Relational DBMS 详见 关系数据</description></item><item><title>数据库管理工具</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
https://www.zhihu.com/question/36713411/answer/2200534275 DBeaver - 开源、跨平台、功能大合集式，支持的数据库非常多，有中文版。Java 开发的 HeidiSQL - 免费 Win Linux only 功能丰富直给 有中文版。Pascal 开发的 MySQL Workbench - 免费、官方、有付费软件才有的重型功能 Sequel Pro - 免费、小巧、轻量级、Mac Only Beekeeper Studio - 免费、小巧、跨平台、多数据库支持 Navicat - 付费、跨平台、稳定、重型功能、有中文版 dbForge Studio - 付费 Win only 稳定 产品逻辑扎实 SQLyog - 付费 Win Only 付费中的精巧版 中文版 WhoDB # 轻量级的下一代数据浏览器 - Postgres、MySQL、SQLite、MongoDB、Redis、MariaDB 和带有聊天界面的 Elastic Search
https://github.com/clidey/whodb TS 与 Go 开发 Web 端
Yearning Archery MySQL Workbench 参考：
官网 MySQL 官方出的可视化工具</description></item><item><title>数据通信</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/</guid><description>概述 参考：
Wiki, Data communication 公众号-差评，现在性能拉满的手机芯片，原来是被它牵着鼻子走的？(通讯进化简史) Data Communication(数据通信) 是在点对点或点多多上，以 digital bitstream(数字比特流) 或 数字化模拟信号的形式，传输和接收数据的沟通渠道。此类通道的示例是铜线、光纤、使用无线电频谱的无线通信、存储介质和计算机总线。数据表示为电磁信号，例如电压、无线电波、微波或红外信号。
Transimit(发送) # Transmission、Transfer
Receive(接收) # Reception
Signaling(信令) # 通信系统中的控制指令
In-band Signaling(带内信令) # 同一信道上传输用户信息和控制信息 Out-band Signaling(带外信令) # 专用信道上传输控制信息 Dedicated line(专线) # https://en.wikipedia.org/wiki/Dedicated_line
Dedicated Private Line(专用私有线路，简称 DPL)</description></item><item><title>图形处理</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/</guid><description>概述 参考：
手把手教你使用OpenCV库（附实例、Python代码解析） 公众号-差评，为了把游戏接口做进Windows，这位大佬干翻了微软的管理层。 计算机如何读取图像？ 思考以下图片：
我们可以认出它是纽约天际线的图片。 但是计算机可以自己发现这一切吗？答案是不！
计算机将任何图片都读取为一组 0 到 255 之间的值。
对于任何一张彩色图片，有三个主通道——红色(R)，绿色(G)和蓝色(B)。它的工作原理非常简单。
对每个原色创建一个矩阵，然后，组合这些矩阵以提供 R, G 和 B 各个颜色的像素值。
每一个矩阵的元素提供与像素的亮度强度有关的数据。
思考下图： 如图所示，图像的大小被计算为 B x A x 3。
注意：对于黑白图片，只有一个单一通道。
图形接口 有位叫 Eric Engstrom微软大佬去世了。这位老哥没有比尔盖茨这么大的名气，但要是没他，我们现在想要在夜之城夜夜笙歌，估计没那么容易。甚至说 Windows 电脑，可能还只是一台主要的生产力工具，就像苹果 Mac 一样。
DirectX Eric Engstrom 所创立的 DirectX 接口，把 PC 个人电脑，拽进了电子游戏的世界。让玩电脑游戏成为了一种游戏方式。
先是辛辛苦苦从3XM、游 X Sky上找到资源，然后冒着被老妈发现的危险，电脑挂一晚上把游戏下下来。
好不容易下完了解压好，兴奋的打开游戏的 exe 文件，正准备抄起鼠标大杀四方，系统却弹出了这么一个窗口。。。
这个文件其实是 DirectX 的驱动文件，重新装一下 DirectX 最新驱动就行了。
正版游戏在运行之前会有一个自检的环节，来确认电脑中是否有相关的驱动文件。
而上传盗版游戏的黑客，并不会把这部分自检程序放到压缩包里。
这样一来，用户在解压完游戏之后就会发生文件缺失的情况，需要自己去网上找到对应的文件把它补上。
没有 .dll 文件，游戏就跑不起来。
那个时候玩的单机游戏，从CS 、红警、魔兽争霸 3到GTA 罪恶都市、骑马与砍杀、文明 IV等等等等游戏，都是基于DirectX接口开发的。
DirectX的存在，覆盖了整个电脑游戏发展史。
那问题来了，为什么在电脑上的游戏离不开 DirectX 呢？</description></item><item><title>文本处理</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/</guid><description>概述 参考：
格式化输出 像表格一样输出数据，有多个包可以实现这种效果：
https://pkg.go.dev/text/tabwriter https://github.com/olekukonko/tablewriter https://github.com/bndr/gotabulate kubecm 项目使用这个库 格式化占位符 参考：
Go 包，标准库-fmt-hdr 打印 博客园，情三-golang fmt 格式“占位符” 格式化占位符，也可以称为 format verbs(格式化动词)。这些动词可以在输出时，告诉数据应该以什么类型、样式输出。这类似于 C 语言的 printf 和 scanf，但是更简洁。
以下面的代码为例：
type Human struct { Name string } var people = Human{Name:&amp;#34;zhangsan&amp;#34;} 普通占位符 占位符 说明 举例 输出 %v 根据值来自动推断类型的默认格式 Printf(&amp;quot;%v&amp;quot;, people) {zhangsan}， %+v 打印结构体时，会添加字段名 Printf(&amp;quot;%+v&amp;quot;, people) {Name:zhangsan} %#v 相应值的 Go 语法表示 Printf(&amp;quot;#v&amp;quot;, people) main.Human{Name:&amp;ldquo;zhangsan&amp;rdquo;} %T 相应值的类型的 Go 语法表示 Printf(&amp;quot;%T&amp;quot;, people) main.Human %% 字面上的百分号，并非值的占位符 Printf(&amp;quot;%%&amp;quot;) % 布尔占位符 占位符 说明 举例 输出 %t true 或 false。 Printf(&amp;quot;%t&amp;quot;, true) true 整数占位符 占位符 说明 举例 输出 %b 二进制表示 Printf(&amp;quot;%b&amp;quot;, 5) 101 %c 相应 Unicode 码点所表示的字符 Printf(&amp;quot;%c&amp;quot;, 0x4E2D) 中 %d 十进制表示 Printf(&amp;quot;%d&amp;quot;, 0x12) 18 %o 八进制表示 Printf(&amp;quot;%d&amp;quot;, 10) 12 %q 将字符串格式化为带有双引号的字符串。并用双引号将整个字符串包裹起来，</description></item><item><title>文件管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
Wiki, Computer file Wiki-Category,Computer files Wiki, End of file 公众号，小林 coding-一口气搞懂「文件系统」，就靠这 25 张图了 另一个公众号 从文件系统文章可以看出来，File(文件) 是一个组织存储在计算机中数据的逻辑概念，以便让人们可以清楚得知道每一段数据的起始位置、结束位置，甚至可以通过为文件命名来立刻反应过来这段数据的作用。
所谓的查看文件，其实是指找到一段数据的开头和结尾，并查看这段数据。对于程序员来说文件是一个很简单的概念，我们只需要将其理解为一个 N byte 的序列就可以了：**b1, b2, b3, b4, &amp;hellip;&amp;hellip;. bN。**程序员使用 I/O 最终都逃不过文件。
所有的 I/O 设备都被抽象为了文件这个概念，Everything is File(一切皆文件)，磁盘、网络数据、终端，甚至进程间通信工具管道等都被当做文件对待。
所有的 I/O 操作也都是通过文件读写来实现的，这一非常优雅的抽象可以让程序员使用一套接口就能实现所有 I/O 操作。
常用的 I/O 操作接口一般有以下几类：
打开文件，open 改变读写位置，seek 文件读写，read、write 关闭文件，close 程序员通过这几个接口几乎可以实现所有 I/O 操作，这就是文件这个概念的强大之处。
在 Linux 中一切皆文件，目录也是文件的一种类型，就连块设备、套接字、终端、管道等等，都被当做 File(文件)来对待。
下面是一个在 Linux 中最常见的列出文件的命令 ls -l 所能查看的文件基本信息
~]# ls -lh total 20K lrwxrwxrwx. 1 root root 7 May 24 2019 bin -&amp;gt; usr/bin dr-xr-xr-x.</description></item><item><title>文件与文件系统管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
ls - 列出有关文件的信息(默认情况下为当前目录所有文件) 参考：
Manual(手册)，ls(1) Manual(手册)，ls(1p) GNU 官方文档，软件-coreutils-手册-10 目录列表-ls ls 程序包含在 Coreutils 工具集
Syntax(语法) ls [OPTIONS]&amp;hellip; [FILE]&amp;hellip;
OPTIONS 影响列出哪些文件的选项
参考：https://www.gnu.org/software/coreutils/manual/html_node/Which-files-are-listed.html
-a, &amp;ndash;all # 不要忽略以 . 符号开头的条目 影响列出的文件包含哪些信息的选项
参考：https://www.gnu.org/software/coreutils/manual/html_node/What-information-is-listed.html
&amp;ndash;full-time # 显示时间的完整格式 -h, &amp;ndash;human-readable # 将 size 列信息变为人类可读的格式。 -i, &amp;ndash;inode # 显示文件的 inode 号。显示在最左侧。 -l # 输出更多的信息。每列信息所代表的含义详见 《文件管理》章节 -Z, &amp;ndash;context # 显示 SELinux 安全上下文，若该文件不受 SELinux 影响，则显示 ?。 对输出的信息进行排序的选项
参考：https://www.gnu.org/software/coreutils/manual/html_node/Sorting-the-output.html
-r # 对列出的内容反向排序 &amp;ndash;sort=WORD # 按照 WORD 排序，而不是以文件的名称排序。 size # 以文件大小排序。等同于 -S 选项 time # 以时间排序。等同于 -t 选项 -S # 按照文件的大小排序，最大的排在第一个。等同于 &amp;ndash;sort=size -t # 按照文件的最新修改时间排序，最新的时间排在第一个。等同于 &amp;ndash;sort=time -c # 显示文件的 ctime，并按照 ctime 排序 -u # 显示文件的 atime，并按照 atime 排序 影响输出信息的格式</description></item><item><title>系统审计</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/</guid><description>概述 参考：
红帽产品文档，RedHat7 - 安全指南 - 第 7 章 系统审计 Linux 审计系统提供了一种方式来跟踪系统中的安全相关信息。根据预配置的规则，审计会生成日志条目，以记录有关系统上发生事件的尽可能多的信息。对于关键任务环境而言，此信息对于确定安全策略的违反者及其执行的操作至关重要。Audit 不会为您的系统提供额外的安全性，而是可用于发现系统上使用的安全策略违规。通过 SELinux 等其他安全措施可以进一步阻止这些冲突。
以下列表总结了审计可以在其日志文件中记录的一些信息：
事件的日期和时间、类型和结果. 主题和对象的敏感度标签。 事件与触发事件的用户的身份相关联。 对 Audit 配置的所有修改，并尝试访问 Audit 日志文件。 所有身份验证机制的使用，如 SSH 和 Kerberos 等。 对任何受信任数据库的更改，如 /etc/passwd. 尝试从系统导入或导出信息. 根据用户身份、主题和对象标签以及其他属性，包含或排除事件。 使用审计系统也是许多安全相关认证的一项要求。审计旨在满足或超过以下认证或合规指南的要求：
受控访问保护配置文件(CAPP) 标记的安全保护配置文件(LSPP) 规则集基本访问控制(RSBAC) 国家工业安全计划操作手册(NISPOM) 联邦信息安全管理法案(FISMA) 支付卡行业 - 数据安全标准(PCI-DSS) 安全技术实施指南(STIG) 审计还包括：
由国家信息保障合作伙伴(NIAP)和最佳安全行业(BSI)评估。 通过红帽企业 Linux 5 上的 LSPP/CAPP/RSBAC/EAL4+ 认证. 红帽企业 Linux 6 上经过操作系统保护配置文件/评估保证级别 4+(OSPP/EAL4+)认证. 使用案例 监视文件访问 # 审计可以跟踪文件或目录是否已访问、修改、执行或文件属性是否已更改。例如，这可用于检测对重要文件的访问，并在其中一个文件损坏时提供审计跟踪。
监控系统调用 # 可将审计配置为在每次使用特定系统调用时生成日志条目。例如，这可用于通过监控 settimeofday、clock_adjtime 和其他时间相关系统调用来跟踪系统时间的更改。
记录用户运行的命令 # 审计可以跟踪文件是否已执行，因此可以定义规则以记录特定命令的每次执行。例如，可以为 /bin 目录中的每个可执行文件定义规则。然后，可以按用户 ID 搜索生成的日志条目，以生成每个用户所执行命令的审计跟踪。</description></item><item><title>信息安全</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/</guid><description>概述 参考：
Wiki, Information_security Information security(信息安全，简称 infosec) 是通过降低信息风险来保护信息的实践。
Data secruity
Network security
Reverse engineering(逆向工程) Reverse engineering
Software cracking(软件破解)
Wiki, Software cracking(软件破解) Penetration test(渗透测试)
Wiki, Penetration test(渗透测试) 待总结 要研究态势感知或安全运营中心，可以采用 OSSIM
要研究入侵防御技术，可以采用 Snort 或 Security Onion
要研究防火墙技术，可以采用 pfSense 或 OPNsense
要研究 Web 应用防火墙（WAF ），可以采用 ModSecurity
要研究威胁情报技术，可以采用 MISP 或 OpenCTI
要研究漏洞扫描技术，可以采用 OpenVAS 或 W3AF
要研究堡垒机技术，可以采用 JumpServer
要研究蜜罐技术，可以采用 T-Pot 或 Hfish
学习 B 站 - 沈奇教练，【黑客奇谈】第三期：0基础成为黑客有多难？15年网安经验倾囊相授，教你正确入门网络安全
历史漏洞 CVE-2022-0185 https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-0185 漏洞，通过如下操作，可以让普通用户直接重置 root 密码。主要利用的是 bind mount 功能，将 /etc/passwd 文件覆盖</description></item><item><title>信息论</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E4%BF%A1%E6%81%AF%E8%AE%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E4%BF%A1%E6%81%AF%E8%AE%BA/</guid><description>概述 参考：
B 站，信道容量、香农极限、极化码 Wiki, Information Theory(信息论) Wiki, Polar Code(极化码) capacity-achieving 硬科普 | 熵与信息（一）：一个石破惊天的副产品 熵与信息（四）：如何用1 bit信息改变世界？ 信息熵 # 一个答案的最少提问次数
信道容量 # 单位时间内能传输的信息量
$log_2(\frac{1}{2})=-3$
数据通信 的应用建立在信息论基础之上。</description></item><item><title>性能评估与故障处理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>概述 参考：
极客时间，Linux 性能优化实战 公众号，刘超的通俗云计算-读完这篇文章，就再也不怕遇到网络问题啦 常见问题简述 当你发现某台机器无论做什么都慢, 而 cpu 和内核却不是瓶颈的时候, 那有可能是内核慢了。机器上定时任务的执行过多, 内核缓存一直增加, 导致内核速度变慢了. 它一变慢, 引发了 tcp 握手时间变长, 最后造成用户体验下降. 既然发现了问题, 解决方案也比较容易搜索到了, 增加任务, 检查内核是否变慢, 慢了的话就清理一次：sync &amp;amp;&amp;amp; echo 3 &amp;gt; /proc/sys/vm/drop_caches</description></item><item><title>性能优化与故障处理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>概述 参考：
为什么有时候无法 kill 掉容器中 PID 为 1 的进程
容器无法启动时，如何排查 场景：有些时候我们用一个官方的容器直接启动，会报错，或者说效果不是我们想要的，我们大概知道如何排查，比如改改容器里面的配置文件，重新启动什么的，那么问题来了，容器起不来我怎么进去？
如下实例，启动一个 consul 容器报错
[root@10-222-32-122 ~]# docker run -d --name=consul --net=host gliderlabs/consul-server -bootstrap [root@10-222-32-122 ~]# docker ps -a --no-trunc CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 88f8ca844420937fc57c7f46b3b99222a7fdd47591e8a14da34c4110fe3f5c29 gliderlabs/consul-server &amp;#34;/bin/consul agent -server -config-dir=/config -bootstrap&amp;#34; 3 minutes ago Exited (1) 3 minutes ago consul [root@10-222-32-122 ~]# docker logs consul ==&amp;gt; WARNING: Bootstrap mode enabled! Do not enable unless necessary ==&amp;gt; Starting Consul agent.</description></item><item><title>性能优化与故障处理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>概述 参考：
为什么 Pod 突然就不见了？ https://mp.weixin.qq.com/s/bbp3OoEF0_Cc1obFBsROSg
创建测试容器 web apiVersion: v1 kind: Service metadata: name: myapp namespace: test labels: app: myapp spec: ipFamilyPolicy: PreferDualStack ipFamilies: - IPv6 - IPv4 ports: - name: http port: 80 targetPort: 80 nodePort: 30080 type: NodePort selector: app: myapp --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: myapp name: myapp namespace: test spec: replicas: 1 selector: matchLabels: app: myapp template: metadata: name: myapp labels: app: myapp spec: containers: - name: myapp-container # image: lchdzh/network-test image: containous/whoami tty: true --- apiVersion: networking.</description></item><item><title>虚拟化管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/</guid><description>概述 尽管 QEMU 有一个 CLI(qemu-system) 和一个 monior 来与 VM 进行交互，但这些工具通常仅用于开发目的，也就是调试底层逻辑。Libvirt 提供了对特定版本和管理程序的抽象，并封装了一些解决方法和最佳实践
虽然 Libvirt 最终在文件系统中，也是调用 qemu-system 工具启动虚拟机，但是使用起来，不用记很多晦涩的参数，并且还提供 GUI 给用户使用。</description></item><item><title>学习</title><link>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/%E5%AD%A6%E4%B9%A0/</guid><description>概述 参考：
贝佐斯：为什么亚马逊开会拒绝使用PPT
学习方法 从整体到部分（先看深林在入森林看数目、先描述整体的简单易懂甚至可以有一点误差的概念，再深入研究细节）。学整体的时候，最好再跟着研究一下出现这些内容的痛点（为什么会出现）。
样例：
https://www.bilibili.com/video/BV1k4o7YqEEi 讲解 AI 的 Attention is all you need 论文 https://www.bilibili.com/video/BV1uc41117Tu
马林思维 的回复：
我研究心理学，研究学习方法，每个人的观点都源自自己的经历，站在UP自己的学习经历来说，他的观点没问题，因为他自己只要认真学，成绩就不错。但如何解释很多孩子也在认真学，但成绩却千差万别，只要他和学习差的同学，一起学同一个内容时，经过对比就知道他俩的区别不是努力，而是他俩学习的方式就截然不同，区别如下： 一、逻辑框架能力
学霸：一节内容，边学边梳理内在逻辑，最后会在大脑形成一个逻辑框架，用逻辑推理串联几个知识点，既掌握了知识点，而且明白了内在的逻辑，来龙去脉很清楚，那么做题时，就更有层次感和大局观，能看清题目在考什么 学渣：一节内容，眼睛在看，感觉字都认识，意思也都大概知道，看完后只记得一个大概，分不清具体几点，也不清楚内在逻辑，脑子里浆糊一样，迷迷糊糊的，好像会一些什么，再一细究，好像又啥都没有，于是三番五遍的看，花费大量时间精力，累死累活终于死记了几个点，但是因为缺乏框架和逻辑，第二天大脑又空白了，于是学渣学的比驴累，但收获几乎寥寥无几 二、记忆能力
学霸：提取关键字，逻辑串联，用推理来记忆，一篇文章15分钟搞定 学渣：一遍遍读，脑子塞满了碎片化的一个个文字，死记硬背，1小时了，还混乱磕磕绊绊 三、做题能力
学霸：通过一道题，研究这一类题，考察的是哪个知识点，题是如何包装设陷阱的，总结出这类题的通用解题规律 。划重点！！！ 学渣：眼睛看到题，脑子一片空白，于是看答案，死记硬背了具体的数字，只记忆了一道题，而不是一类题，且因为当天做了十几道题，大脑无法记忆那么多题的步骤，于是第二天原题出上，她还是不会 四、复盘总结能力
学霸：知道自己愚蠢且懒惰，想着自己好不容易总结出来的思路秘诀，肯定不容易记住，所以睡前或者早晨，再不济两三天，或者周末会把本周内容在大脑过一遍，检测是否遗忘，及时查漏补缺。 学渣：知道自己聪明且勤奋，像个驴一样埋头疯狂刷题，既没有总结出思路，也没有复习意识，等到一个月后再复习时，大脑犹如重装系统一般，忘了自己曾经竟然还做过这样的题，于是想全部再过一遍，可惜精力也不够，弃！考公考编以及高考，挂！ 大佬博客 知了 人称 秦始皇，自己维护了一个社区 Linux DO
擅长 Reverse engineering、etc. 社区 V2EX
2021-05-31 V2EX 被墙 其他 DeepSeek 创始人专访：中国的 AI 不可能永远在跟随，技术创新永远是第一优先级</description></item><item><title>源码解析</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</guid><description>概述 参考：
GitHub 项目，kubernetes/kubernetes GitHub 项目，kubernetes/design-proposals-archive(K8S 早期设计方案) GitHub 项目，kubernetes/enhancements(K8S 当前设计方案) 田飞雨博客-这位大佬阅读了大部分 k8s 代码，并在博客中写了笔记 kubernetes 源码目录结构 更新日期：2022 年 2 月 23 日 Kubernetes 的源码目录随着更新迭代，也在不断变化中
$ tree -L 1 -p . ├── [-rwxrwxrwx] BUILD.bazel ├── [drwxrwxrwx] CHANGELOG ├── [-rwxrwxrwx] CHANGELOG.md ├── [-rwxrwxrwx] CONTRIBUTING.md ├── [-rwxrwxrwx] LICENSE ├── [drwxrwxrwx] LICENSES ├── [-rwxrwxrwx] Makefile ├── [-rwxrwxrwx] Makefile.generated_files ├── [-rwxrwxrwx] OWNERS ├── [-rwxrwxrwx] OWNERS_ALIASES ├── [-rwxrwxrwx] README.md ├── [-rwxrwxrwx] SECURITY_CONTACTS ├── [-rwxrwxrwx] SUPPORT.md ├── [-rwxrwxrwx] WORKSPACE ├── [drwxrwxrwx] api ├── [drwxrwxrwx] build ├── [drwxrwxrwx] cluster ├── [drwxrwxrwx] cmd ├── [-rwxrwxrwx] code-of-conduct.</description></item><item><title>云原生应用管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
宋净超，云原生应用白皮书-Kubernetes 次世代的云原生应用 重点 云原生基础设施已渡过了野蛮生长期，正朝着统一应用标准方向迈进。 Kubernetes 的原语无法完整描述云原生应用体系，且在资源的配置上开发与运维功能耦合严重。 Operator 在扩展了 Kubernetes 生态的同时导致云原生应用碎片化，亟需一个统一的应用定义标准。 OAM 的本质是将云原生应用定义中的研发、运维关注点分离，资源对象进行进一步抽象，化繁为简，包罗万象。 “Kubernetes 次世代”是指在 Kubernetes 成为基础设施层标准之后，云原生生态的关注点正在向应用层过度，近两年来火热的 Service Mesh 正是该过程中的一次有力探索，而基于 Kubernetes 的云原生应用架构的时代即将到来。 Kubernetes 已成为云原生应用的既定运行平台，本文以 Kubernetes 为默认平台展开，包括云原生应用的分层模型。
云原生的不同发展阶段 Kubernetes 从开源至今已经走过快六个年头（2014 年 6 月开源）了，可以说是 Kubernetes 的诞生开启了整个云原生的时代。我粗略的将云原生的发展划分为以下几个时期。
第一阶段：孵化期（2014 年）
2014 年，Google 开源 Kubernetes，在此之前的 2013 年，Docker 开源，DevOps、微服务已变得十分流行，云原生的概念已经初出茅庐。在开源了 Kubernetes 之后，Google 联合其他厂商发起成立了 CNCF，并将 Kubernetes 作为初创项目捐献给了 CNCF。CNCF 作为云原生的背后推手，开始推广 Kubernetes。
第二阶段：高速发展期（2015 年 - 2016 年）
这几年间，Kubernetes 保持着高速发展，并于 2017 年打败了 Docker Swarm、Mesos，确立了容器编排工具领导者的地位。CRD 和 Operator 模式的诞生，大大增强了 Kubernetes 的扩展性，促进了周边生态的繁荣。
第三阶段：野蛮生长期（2017 年 - 2018 年）</description></item><item><title>运维</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4/</guid><description>print( &amp;#39;&amp;#39;&amp;#39; ********************************************* _ooOoo_ o8888888o 88&amp;#34; . &amp;#34;88 (| -_- |) O\ = /O ____/`---&amp;#34;\____ .&amp;#34; \\| |// `. / \\||| : |||// \\ / _||||| -:- |||||- \\ | | \\\ - /// | | | \_| &amp;#34;&amp;#34;\---/&amp;#34;&amp;#34; | | \ .-\__ `-` ___/-. / ___`. .&amp;#34; /--.--\ `. . __ .&amp;#34;&amp;#34; &amp;#34;&amp;lt; `.___\_&amp;lt;|&amp;gt;_/___.&amp;#34; &amp;gt;&amp;#34;&amp;#34;&amp;#34;. | |: `- \`.; `\ _ /`; .`/ - `: | | \ \ `-.</description></item><item><title>运维管理</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
公众号，统一运维平台建设的一些思路和实践 构建一站式运维平台的目的是为了提升运维效率。首先是运维对象要被管理起来，然后是监控这些对象，接着是这些对象的自动化运维，最后是所有的运维操作都要有所规范。概括起来对应的系统就是 CMDB、Monitor、AutoFlow、ITSM，如下图所示
CMDB # CMDB是运维的基石，也是运维的权威数据库，权威不仅体现在数据准确，也要求数据唯一，不能在多套系统里维护着同样的运维资源数据，这样数据准确性更难保证。CMDB的价值体现在数据被消费，最常见的消费场景就是监控、运维作业的调度执行、ITSM流程类相关的系统。
AutoFlow # AutoFlow(自动化运维平台) 是提升运维效率的利器。简单来说就是可以把机器上的各种运维操作比如：巡检、日志操作、代码部署、文件传输等等重复的运维任务编排成作业，去调度执行。
Monitor # Montiro(统一监控) 是实现系统和业务连续稳定运行的重要技术保障手段。业内比较知名的开源解决方案有zabbix和Prometheus，很多企业的实践也是结合了2者。
ITSM # ITSM 对这些系统进行了一个串联，用流程方式规范IT和运维。 在 ITIL4 的规范和指导下，与 CMDB、Monitor、AutoFlow 高度结合，一同打造一站式运维平台，从公司实际出发，解决流程失误、人员失误，打造贴合的流程工单，提升IT生产力，提供IT新视野，提高IT运维效率。
ITIL 参考：
Wiki, ITIL Information Technology Infrastructure Library (信息技术基础设施库，简称 ITIL) 是 IT 活动的一组实践和框架，例如 IT 服务管理 (ITSM) 和 IT 资产管理 (ITAM)，重点关注使 IT 服务与业务需求保持一致。
CMDB CMDB是运维的权威数据库, 网上对CMDB的建设和落地思路表述各异。其实直接衡量CMDB成功与否标志是其他系统是否愿意消费CMDB，如果是则证明数据是足够权威的。所以CMDB的建设大部分时间可能花在保证数据的正确性上，这个可以通过自动发现和ITSM的流程加以保证。比如主机的从购买、上架、系统初始化、应用部署、各种变更、下线、下架等等一个完整的生命周期，都是可以通过ITSM来进行规范的。
由于企业运维需求和场景各异，因此，要实现一个尽可能通用、灵活、可扩展的运维资源数据的配置和管理系统，系统必须要满足:
运维人员能根据企业的运维场景和需求，自己去构建存储的数据模型，以及模型之间的关系 提供丰富的API，尤其是在数据和关系检索要做到通用，便于二次开发 用户可以方便的订阅自己关心的数据，有丰富的图表展示 数据的自动发现和细粒度的权限控制 基于上述理念，设计并实现了一个CMDB，并开源出来，希望能得到大家的积极反馈，系统将持续不断的改进， 如果您觉得有用处，欢迎在GitHub上点1个小⭐️⭐️。
https://github.com/veops/cmdb
AutoFlow 自动化运维平台简单概括为对运维对象的任何变更操作都是由该平台来实现的，也即运维作业平台。实现该系统的核心是灵活的编排运维任务、任务的调度执行。
首先在系统上可以通过拖拽的方式来编排任务，这个任务节点可能是一个脚本、文件传输、发送邮件等。其次任务的调度执行可以完全关联CMDB来选择执行目标。当然任务执行方式既可以是人工触发也可以是计划任务的方式触发。
Monitor 监控是确保系统和业务连续稳定运行的重要技术保障手段，在运维中，监控是不可或缺的功能。
目前，业界知名的开源解决方案很多，如Zabbix、Prometheus，许多企业在实践中采用了这两者的结合。然而，这些开源监控解决方案在企业实践中一般需要进一步优化和丰富。
首先，单纯的采集、监控带来的收益可能不够明显。为了提升监控的价值，通常需要将监控与企业的配置管理数据库（CMDB）系统进行关联。通过与CMDB系统关联，可以更好地理解监控数据的上下文，从而更准确地识别和解决问题。
数据可视化和报表功能：监控系统应该提供直观的数据可视化和报表功能，以便运维人员能够更好地理解系统的状态和趋势，从而做出更明智的决策。
自动化运维和自愈能力：监控系统可以与自动化运维工具集成，实现自动化的故障诊断和修复。通过自愈能力，可以减少人工干预的需求，提高系统的可靠性和稳定性。
预测性分析和容量规划：监控系统可以通过对历史数据的分析，进行预测性分析和容量规划。这样可以帮助企业更好地预测系统的未来需求，避免资源瓶颈和性能问题。
监控系统最好具备告警管理功能。在大规模告警风暴的情况下，如果没有有效的告警管理，可能会导致大量无效的告警，从而淹没了重要的告警信息。因此，监控系统应该具备灵活的告警策略和管理机制，能够根据实际情况进行智能告警，减少噪音告警的产生，并确保重要的告警能够及时被发现和处理。
总之，监控系统在企业实践中需要与CMDB系统关联，具备告警管理功能，并且可以进一步优化和丰富数据可视化、自动化运维、预测性分析等方面的功能，以提升其价值和效果。</description></item><item><title>自然语言处理</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/</guid><description>概述 参考：
Wiki, Natural_language_processing Natural Language Processing(自然语言处理，简称 NLP) 是语言学、计算机科学和人工智能的跨学科领域，主要关注计算机与人类语言之间的交互，特别是如何编写程序来处理和分析大量的自然语言数据。目标是让计算机能够“理解”文档的内容，包括其中的语言上下文细微差别。技术可以准确提取文档中包含的信息和见解，以及对文档本身进行分类和组织。
语言模型 参考：
Wiki, Language_model Language model(语言模型) 是单词序列的概率分布。
通过语言模型，才可以实现自然语言处理。NLP 程序都会使用语言模型，我们将自然语言作为输入，传递给语言模型，语言模型将会预测其将要输出的每一个单词的出现概率，然后逐一输出这些单词。
想要训练出来一个良好的语言模型，通常会需要类似 Transformers 这种机器学习模型。
Large language model Large language model(大语言模型，简称 LLM) 是由具有许多参数（通常为数十亿或更多权重）的神经网络组成的语言模型，使用自我监督学习对大量未标记文本进行训练。LLM 在 2018 年左右出现，并在各种任务中表现出色。这已经将自然语言处理研究的重点从之前为特定任务训练专门的监督模型的范式转移了。
我们经常看到 LLM 实现的模型后面有 XB 的样式，其中 B 表示 Billions(十亿)，这个 XB 指的就是参数的数量。比如 6B 表示 60 亿参数。
常见模型 参考：
Wiki, Large_language_model-大语言模型列表 公众号-OSC 开源社区，大预言模型精选开源项目 我们常见的语言模型在现阶段（2023.5）可以简单分为如下几大类
BERT 系 类似完形填空，联系上下文直接给出空中的内容 GPT 系 一字一字推测的自回归模型。有 a 推测 b，然后根据 ab 推测 c，根据 abc 推测 d，以此类推 其他系 Bidirectional Encoder Representations from Transformers(来自 Transformers 的双向编码器表示，简称 BERT)</description></item><item><title>ACL</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/ACL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/ACL/</guid><description>概述 参考：
红帽官方文档，RedHat7-系统管理员指南-第五章.访问控制列表 Access Control Lists(访问控制列表，简称 ACL)。Linux 权限管理是 Linux 很重要的一项内容，重则引起用户信息泄露，轻则导致文件错乱和丢失。企业服务器里有些目录下面的东西暂时保密，不希望别人可以进入目录并查看。有些文件希望别人可以看，但不能删除。有些目录只有 root 等管理员权限的账户才能修改，
Linux 服务器供多个人登录使用，要是没有权限管理就乱了，大家都一样的权限。有些维护系统的命令比较复杂，经验丰富的管理员运行这些命令没事，普通新用户运行的话，可以会导致 Linux 服务器瘫痪。
就像咱们日常生活中，全世界人的权限都一样不就乱了吗。
今天我们来介绍一下 Linux 权限管理的 ACL 权限，它是用户管理结束之后必须要经历的一步。Linux 系统的用户管理包括 Linux 用户和用户组管理之相关配置文件，用户管理的相关配置文件，内容有用户信息文件/etc/passwd，用户密码文件/etc/shadow；用户组信息文件/etc/group，用户组密码文件/etc/gshadow。用户的家目录，以及用户的模板目录； Linux 用户和用户组管理之用户管理命令，管理用户和用户组的命令，包括新建、修改、查看等等以及用的比较多的切换用户命令 su。
下面我们正式开始介绍：
1、什么是 ACL 权限？
比如有如下场景：
某大牛在 QQ 群内直播讲解 Linux 系统的权限管理，讲解完之后，他在一个公有的 Linux 系统中创建了一个 /project 目录，里面存放的是课后参考资料。那么 /project 目录对于大牛而言是所有者，拥有读写可执行（rwx）权限，对于 QQ 群内的所有用户他们都分配的一个所属组里面，也都拥有读写可执行（rwx）权限，而对于 QQ 群外的其他人，那么我们不给他访问/project 目录的任何权限，那么 /project 目录的所有者和所属组权限都是（rwx），其他人权限无。
问题来了，这时候直播有旁听的人参与（不属于 QQ 群内），听完之后，我们允许他访问/project 目录查看参考资料，但是不能进行修改，也就是拥有（r-x）的权限，这时候我们该怎么办呢？我们知道一个文件只能有一个所属组，我们将他分配到 QQ 群所在的所属组内，那么他拥有了写的权限，这是不被允许的；如果将这个旁听的人视为目录/project 的其他人，并且将/project 目录的其他人权限改为（r-x），那么不是旁听的人也能访问我们/project 目录了，这显然也是不被允许的。怎么解决呢？
我们想想 windows 系统里面给某个文件分配权限的办法：
如上图，我们想要让某个用户不具备某个权限，直接不给他分配这个目录的相应权限就行了。那么对应到 Linux 系统也是这样，我们给指定的用户指定目录分配指定的权限，也就是 ACL 权限分配。
查看分区 ACL 权限是否开启：dump2fs 我们看某个文件（Linux 系统中目录也是文件，一切皆是文件）是否支持 ACL 权限，首先要看文件所在的分区是否支持 ACL 权限。</description></item><item><title>AJAX</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/AJAX/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/AJAX/</guid><description>概述 参考：
Wiki, Ajax 在 Web 应用程序中（比如浏览器），用户可能需要与服务器进行数据交互，但传统的同步方式在发起 HTTP 请求数据时，会让浏览器在接收到响应后刷新整个页面，导致用户体验变差且不利于更多功能的实现。
所以，如何在不刷新整个页面的情况下更新页面的部分内容呢？
Asynchronous JavaScript and XML(简称 AJAX) 就是为了解决上述问题而提出的编程概念，也可称为 Web 开发技术、Web 标准。最早，实现 AJAX 技术的是 XMLHttpRequest
XMLHttpRequest 参考：
MDN，术语 - XMLHttpRequest MDN，Web API - XMLHttpRequest Wiki, XMLHttpRequest XMLHttpRequest(简称 XHR) 是一种创建 AJAX 请求的 JavaScript API，通过 XHR 可以方便得让浏览器发起异步请求到服务器以更新 Web 页面的部分内容。
使用 XHR 主要依赖于 XMLHttpRequest 对象，该对象下有很多属性和方法用来定义请求、发送请求、处理响应、等等。尽管名称为 XMLHttpRequest，但其可以用于获取任何类型的数据，而不仅仅是 XML。它甚至支持 HTTP 以外的协议（包括 file:// 和 FTP），尽管可能受到更多出于安全等原因的限制。
// 实例化 XMLHttpRequest 对象 let xhr = new XMLHttpRequest() // 配置请求信息 xhr.open(&amp;#34;GET&amp;#34;, &amp;#34;https://api.github.com/users/DesistDaydream&amp;#34;, true) // 绑定 onload 事件，以便在执行 xhr.</description></item><item><title>Alertmanager 配置</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
官方文档，告警 - 配置 alertmanager 程序标志 &amp;ndash;storage.path # 存储运行时数据的路径。默认值: data/ i.e. 工作目录下的 data/ 目录。比如当前工作目录在 /alertmanager/ 运行 /bin/alertmanager 程序，那么数据会存储在 /alertmanager/data/ 目录下
&amp;ndash;data.retention # 数据最长保存时间。默认值: 120h
&amp;ndash;data.maintenance-interval # 垃圾收集与将静默和通知日志快照到磁盘之间的时间间隔。默认值: 15m
Alertmanager 配置文件 下文用到的占位符说明：
BOOLEAN # 可以采用 true 或 false 值的布尔值 DURATION # 持续时间。可以使用正则表达式 ((([0-9]+)y)?(([0-9]+)w)?(([0-9]+)d)?(([0-9]+)h)?((([0-9]+)m)?((([0-9]+)s)?((([0-9]+)ms)?|0)，例如：1d、1h30m、5m、10s。 FILENAME # 当前工作目录中的有效路径 HOST # 由主机名或 IP 后跟可选端口号组成的有效字符串。 INT # 一个整数值 LABELNAME # 与正则表达式 [a-zA-Z _] [a-zA-Z0-9 _] * 匹配的字符串 LABELVALUE # 一串 unicode 字符 PATH # 有效的 URL 路径 SCHEME # 一个字符串，可以使用值 http 或 https SECRET # 作为机密的常规字符串，例如密码 STRING # 常规字符串 TMPL_STRING # 使用前已模板扩展的字符串 顶层字段 global(global) # 全局配置，所有内容作用于所有配置环境中,若其余配置环境中不再指定同样的配置，则 global 中的配置作为默认配置 templates([]templates) # 指定告警模板文件的路径。若不指定则使用默认模板。可以使用通配符，e.</description></item><item><title>Android</title><link>https://desistdaydream.github.io/docs/Mobile-device/Android/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Mobile-device/Android/</guid><description>概述 参考：
官网 Android 是一种 Unix-like OS，主要设计用于触摸屏移动设备，如智能手机和平板电脑。Android由一个名为开放手持设备联盟的开发者联盟开发，但其最广泛使用的版本主要由 Google 开发。它于2007年11月公布，第一款商用 Android 设备 HTC Dream 于2008年9月发布。
Device(设备) 通常指 手机、平板、手表、等等，甚至可以是安卓 Studio 模拟的设备。
目录结构 安卓的目录结构与 Linux 内核的目录结构类似，但是有一些约定俗成的用于保存各类数据的目录
/data # ？ /data/app/ # ? /data/data/ # ? /sdcard 与 /storage/emulated/0 目录一样
/sdcard 软链接到 /storage/self/primary
/storage/self/primary 软链接到 /storage/emulated/0
/storage/emulated/0/ 这个好像是平时打开文件管理后看到的根目录（WSA 的文件管理也是在这个目录）
./Android/data/${应用的包名}/ # 应用的缓存和临时目录？ 旧版本微信、QQ 接收文件存储路径为存储根目录的 Tencent 目录下，而新版微信接收文件路径切换到了 Android/data/com.tencent.mm/MicroMsg/Download 目录下
QQ 接收的文件也切换到了 Android/data/com.tencent.mobileqq/Tencent/QQfile_recv 目录下
Google Play Store 下载时会使用 googleapis.cn 这个域名。若是出现无法安装或更新应用的话，可以点击下载后，关闭代理；或者把域名加入直连规则。</description></item><item><title>Ansible 配置详解</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，安装指南 - 配置 Ansible 官方文档，Ansible 配置设置 Ansible 可以通过多种方式来配置其运行时行为
配置文件，一般是在 /etc/ansible/ 目录下名为 ansible.cfg 的 INI 格式的配置文件 环境变量 命令行选项 playbook 中的关键字和变量 Ansible 的配置文件使用 INI 格式
[defaults] deprecation_warnings(BOOLEAN) # 是否显示某些功能的弃用警告。默认值：TRUE
host_key_checking(BOOLEAN) # 主机 SSH 密钥检查。默认值：TRUE。如果启用检查，则对从未 ssh 登录过的主机执行任务将会失败。
inventory(STRING) # 指定 ansible 运行时所用的主机清单路径。默认值: /etc/ansible/hosts
Note：可以指定文件或者路径，当指定路径时，则会从该路径下所有文件中读取 host 信息 remote_tmp(STRING) # Ansible 运行期间，受管理节点保存临时数据的地方。默认值: https://docs.ansible.com/ansible/latest/collections/environment_variables.html#envvar-ANSIBLE_REMOTE_TMP 也可以在命令行通过 -e 'ansible_remote_tmp=/tmp/ansible-tmp' 的方式修改 [inventory] [privilege_escalation] - 权限提升部分 become(BOOLEAN) # 是否启用以指定用户执行命令。默认值: False
become_method(STRING) # 提升权限的方式。默认值: sudo
become_user(STRING) # 提升权限所使用的 默认值: root</description></item><item><title>ARP 与 NDP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Data-Link-Layer/ARP-%E4%B8%8E-NDP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Data-Link-Layer/ARP-%E4%B8%8E-NDP/</guid><description>概述 参考：
Wiki, ARP Wiki, NDP RFC 826 公众号，36 张图详解 ARP Address Resolution Protoco(地址解析协议，简称 ARP) 是一种通信协议，该协议可以通过给定的网络层地址(通常是 IPv4 地址)，发现与之相关联的链路层地址(通常你是 MAC 地址)。ARP 于 1982 年在 RFC 826 中定义。说白了，就是根据 IP 地址查询对应 MAC 地址的协议。
注意：在 IPv6 网络环境下，APR 的功能已经被 NDP 替代
对应关系：一个 ip 地址对应一个 MAC 地址。多个 ip 地址可以对应一个 MAC 地址(e.g.一个网卡上配置两个 ip)
ARP 报文 在抓包时，可以抓到如下几种 ARP 包
ARP, Request who-has 10.10.100.254 tell 10.10.100.101, length 28 在局域网中询问谁有 10.10.100.254，告诉自己，自己就是 10.10.100.101 ARP, Reply 10.10.100.254 is-at 00:0f:e2:ff:05:92, length 46 当 10.</description></item><item><title>Audit</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/Audit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/Audit/</guid><description>概述 参考：
GitHub 组织，linux-audit GitHub 项目，linux-audit/audit-kernel GitHub 项目，linux-audit/audit-userspace 红帽产品文档，RedHat7 - 安全指南 - 系统审计 红帽产品文档，RedHat9 - 安全强化 - 系统审计 公众号 - kernsec，Linux Audit 子系统解读 linux audit审计（8）&amp;ndash;开启audit对系统性能的影响 Audit 是实现的 Linux 系统审计的软件包，其中包含两个部分：
用户空间应用程序和实用程序 内核端系统调用处理。 当我们安装 Audit 后，会在系统中看到两个进程，一个是内核态的，一个是用户态的。
~]# ps -p $(pgrep audit) PID TTY STAT TIME COMMAND 100 ? S 0:02 [kauditd] 15016 ? S&amp;lt;sl 0:14 /sbin/auditd 并且，不能随意停止 auditd 服务器，内核进程无法通过用户空间的操作终止，使用 systemctl stop auditd.service 将会报错：
Failed to stop auditd.service: Operation refused, unit auditd.service may be requested by dependency only (it is configured to refuse manual start/stop).</description></item><item><title>Chromium</title><link>https://desistdaydream.github.io/docs/Web/Browser/Chromium/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser/Chromium/</guid><description>概述 参考：
源码 GitHub 项目，chromium/chromium Chromium 官网 Chromium 文档源码 文档 https://github.com/chromium/permission.site 用于测试 Web API 和浏览器权限交互的站点。比如通过浏览器调用位置信息、蓝牙、等等。
用户数据 https://chromium.googlesource.com/chromium/src/+/HEAD/docs/user_data_dir.md
Chrome 运行产生的用户数据包含 Profile 数据、运行时状态数据。Chrome 可以支持多人同时使用
Profile 数据则是特定于某个具体用户的数据，包括 历史记录、书签、Cookie、扩展程序、等等。 每个 Profile 数据所在位置都是用户数据目录的一个子目录。 保存用户数据的目录根据不同环境，有不同的默认值，一般来说，取决于如下几点：
操作系统。Linux、Windows、Macos 等等 基于 Chromium 的各种品牌。Chrome、Edge、等等 Release 版本。比如 stable、beta、dev、canary、等等。 不同系统下的默认路径详见官网，这里就不写了，在 Chrome 里有概述
可以通过 &amp;ndash;user-data-dir 命令行标志改变用户数据目录的位置，通过 &amp;ndash;profile-directory 命令行标志改变启动 Chrome 时要使用具体哪个用户运行。</description></item><item><title>Compose 文件规范</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/Compose-%E6%96%87%E4%BB%B6%E8%A7%84%E8%8C%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/Compose-%E6%96%87%E4%BB%B6%E8%A7%84%E8%8C%83/</guid><description>概述 参考：
GitHub 项目，compose-spec/compose-spec Compose 规范 Docker 官方文档，参考 - compose 文件 Compose 文件是一个 YAML 格式的配置文件，Compose 将每个容器抽象为一个 service。顶层字段 service 的下级字段，用来定义该容器的名称。
一个 Docker Compose 文件中通常包含如下顶级字段：
version services(map[STRING]services) networks(networks) volumes(volumes) secrets(secrets) version 指定本 yaml 依从的 compose 哪个版本制定的。
services 详见 services
networks 参考：
官方文档，参考 - Compose 文件参考 - Networks 顶级元素 attachable: BOOLEAN # 该网络是否可以被其他容器加入
external: BOOLEAN # 该网络是否由外部维护。若为 true，则该网络不受本 Compose 的管理。默认值：false
name: STRING # 指定网络名称
volumes configs secrets</description></item><item><title>Computing Virtualization</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Computing-Virtualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Computing-Virtualization/</guid><description>概述 参考：
CPU 虚拟化(vCPU=virtual CPU # 虚拟 CPU)
使用如下命令可以查看该 CPU 是否支持虚拟化
egrep -o &amp;lsquo;(vmx|svm)&amp;rsquo; /proc/cpuinfo
如果有输出 vmx 或者 svm，就说明当前的 CPU 支持 KVM。CPU 厂商 Intel 和 AMD 都支持虚拟化了，除非是非常老的 CPU。
在 CUP 虚拟化的图片中，宿主机有两个物理 CPU，上面起了两个虚机 VM1 和 VM2。 VM1 有两个 vCPU，VM2 有 4 个 vCPU。可以看到 VM1 和 VM2 分别有两个和 4 个线程在两个物理 CPU 上调度。
虚机的 vCPU 总数可以超过物理 CPU 数量，这个叫 CPU overcommit（超配）。 KVM 允许 overcommit，这个特性使得虚机能够充分利用宿主机的 CPU 资源，但前提是在同一时刻，不是所有的虚机都满负荷运行。 当然，如果每个虚机都很忙，反而会影响整体性能，所以在使用 overcommit 的时候，需要对虚机的负载情况有所了解，需要测试。</description></item><item><title>概念</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Concept/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Concept/</guid><description>MTU 与 MSS 参考：
Wiki, MTU Wiki, MSS Maximum Transmission Unit(即最大传输单元，简称 MTU) 是一个二层的概念；以太网最大的 mtu 就是 1500（它是不包含二层头部的，加上头部应该为 1518 bytes，2bit 的以太网类型+6bit 的 DMAC+6bit 的 SMAC+4bit 的 FCS），每个以太网帧都有最小的大小 64bytes，最大不能超过 1518bytes
注：
小于 64Bytes 的数据帧一般是由于以太网冲突产生的 “碎片”或者线路干扰或者坏的以太网接口产生的，对于大于 1518Bytes 的数据帧我们一般把它叫做 Giant 帧，这种一般是由于线路干扰或者坏的以太网口产生 以太网 EthernetII 最大的数据帧是 1518Bytes，是指包含以太网帧的帧头（DMAC 目的 MAC 地址 48bit=6Bytes+SMAC 源 MAC 地址 48bit=6Bytes+Type 域 2bytes）14Bytes 和帧尾 CRC 校验部分 4Bytes （这个部份有时候大家也把它叫做 FCS） IP MTU 是一个三层概念，它包含了三层头部及所有载荷，根据下层为上层服务的，上层基于下层才能做进一步的扩展的原则，尽管 IP MTU 的变化范围很大（68-65535），但也不得不照顾以太网 MTU 的限制,说白了就是 ip 对以太网的妥协。
网络层 IP 协议会检查每个从上层协议下来的数据包的大小，并根据本机 MTU 的大小决定是否作“分片”处理</description></item><item><title>Configuration</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Collector/Configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Collector/Configuration/</guid><description>概述 参考：
官方文档，Collector - 配置 顶层字段
receivers(map[STRING]receivers) # 配置 Receivers 管道组件 processors(map[STRING]processors) # 配置 Processors 管道组件 exporters(map[STRING]exporters) # 配置 Exporters 管道组件 extensions(map[STRING]extensions) # 配置 扩展 connectors(map[STRING]connectors) # TODO: 配置 Connectors 管道组件 service(service) # 配置在处理各类可观测数据时，使用哪些扩展、使用哪些组件。每个 service 可以简单理解为一个 Pipeline(管道)。 在 otelcol/config.go 可以看到顶层字段的 struct
// Config defines the configuration for the various elements of collector or agent. type Config struct { // Receivers is a map of ComponentID to Receivers. Receivers map[component.ID]component.Config `mapstructure:&amp;#34;receivers&amp;#34;` // Exporters is a map of ComponentID to Exporters.</description></item><item><title>Connection Tracking for netfilter</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/Connection-Tracking-for-netfilter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/Connection-Tracking-for-netfilter/</guid><description>概述 参考：
Netfilter 官方文档，连接跟踪工具用户手册 云计算基层技术-netfilter 框架研究 arthurchiao.art 的文章 连接跟踪（conntrack）：原理、应用及 Linux 内核实现 Connection Tracking(连接跟踪系统，简称 ConnTrack、CT)，用于跟踪并且记录连接状态。Linux 为每一个经过网络堆栈的数据包，生成一个 ConnTrack Entry(连接跟踪条目，简称 Entry)，并把该条目记录在一个 ConnnTrack Table(连接跟踪表) 中，条目中主要是包含该连接的协议、源 IP 和 PORT、目标 IP 和 PORT、协议号、数据包的大小等等等信息。此后，在处理数据包时读取该文件，在文件中所有属于此连接的数据包都被唯一地分配给这个连接，并标识连接的状态。该文件中的每一个条目都有一个持续时间，当持续时间结束后，该连接会被自动清除，再有相同的连接进来的时候，则按照新连接来处理。Netfilter 中定义了如下几个连接状态以便对具有这些状态的连接进行处理：
可跟踪的连接状态有以下几个
NEW # 新发出的请求。在连接跟踪文件中(nf_conntrack)不存在此连接。 ESTABLISHED # 已建立的。NEW 状态之后，在 nf_conntrack 文件中为其建立的条目失效之前所进行的通信的状态 RELATED # 有关联的。某个已经建立的连接所建立的新连接；e.g.FTP 的数据传输连接就是控制连接所 RELATED 出来的连接。–icmp-type 8(ping 请求)就是–icmp-type 0(ping 应答) 所 RELATED 出来的。 INVALIED # 无法识别的连接。 UNTRACKED # 不跟踪的链接状态，仅在使用 raw 表的时候该状态才有用，即 raw 不进行链接跟踪的时候，则连接跟踪表中没有记录的数据包就是此状态 其他： NEW 与 ESTABLISHED 的定义：只要第一次请求就算 NEW(e.g.本机往外第一次发送 和 外部第一次发往本机的请求)，哪怕对第一个 NEW 请求再回应的都算 ESTABLISHED。注意在 INPUT 和 OUTPUT 链上定义 NEW 的情况，INPUT 是外部第一次访问本机算 NEW；OUTPUT 是本机第一次访问外部算 NEW。 注意：ConnTrack 中所定义的状态与 TCP 等协议所定义的状态不一样，这里面定义的状态只是为了可以通过一种新的方式来处理每一个数据包，并进行过滤，这是 Netfilter 中所定义的状态</description></item><item><title>Containerd 部署</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
GitHub 文档，containerd/containerd/docs/getting-started.md 我们可以在官方 README 中的 Runtime Requirements 处找到当前 Containerd 版本所依赖的各种组件所需的版本，比如 runc 的版本等。
依赖的 runc 版本通常记录在 containerd/script/setup/runc-version 文件中 安装 Containerd 是否需要 libseccomp2 依赖？待验证
使用包管理器安装 CentOS yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum install -y containerd.io Ubuntu sudo apt-get -y install apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository &amp;#34;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&amp;#34; sudo apt-get -y update sudo apt-get -y install containerd.</description></item><item><title>Cookie AND Session</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/Cookie-AND-Session/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/Cookie-AND-Session/</guid><description>概述 参考：
MDN，参考-HTTP-使用 HTTP cookies Cookie HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据。浏览器会存储 cookie 并在下次向同一服务器再发起请求时携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器——如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。
背景
HTTP 是无状态协议，服务器不能记录浏览器的访问状态，也就是说服务器不能区分两次请求是否由同一个客户端发出 Cookie(小甜饼) 就是解决 HTTP 协议无状态的方案之一 Cookie 实际上就是服务器保存再浏览器上的一段信息。浏览器有了 Cookie 之后，每次向服务器发送请求时都会同时将该信息发送给服务器，服务器收到请求后，就可以根据该信息处理请求 Cookie 由服务器创建，并发送给浏览器，最终由浏览器保存 Cookie 的用途
保持用户登陆状态，由于不够安全，有其他方式替代，比如 JWT 等。 京东未登录的状态下，使用 Cookie 存储购物车中的物品的 淘宝不是这么实现的，淘宝必须登录才能浏览详细商品
上一次连接时打开的页面 与某个账号关联 等等 Cookie 的属性 一个 cookie 将会具有如下字段：
name # cookie 的名称 value# cookie 的值 domain # 可以访问此 cookie 的域名 path# 可以访问此 cookie 的页面路径。比如 domain 是 desistdaydream.ltd，path 是 /cookie，那么只有访问 http://desistdaydream.ltd/cookie 路径下的页面时，才可以读取此 cookie MaxAge或 Expires # 设置 cookie 持久化时的过期时长 注意：Expires 是老式的过期方法， 如果可以，应该使用 MaxAge 设置过期时间，但有些老版本的浏览器不支持 MaxAge。 如果要支持所有浏览器，要么使用 Expires，要么同时使用 MaxAge 和 Expires。 size # cookie 的大小 httpOnly # 是否允许别人通过 js 获取自己的 cookie httpOnly 属性限制了 cookie 对 HTTP 请求的作用范围。特别的，该属性指示用户代理忽略那些通过&amp;quot;非 HTTP&amp;quot; 方式对 cookie 的访问（比如浏览器暴露给 js 的接口）。 secure # 是否只能通过 https 访问 注意：</description></item><item><title>Core</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Core/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Core/</guid><description>概述 参考：
官方文档 - PowerShell，模块 - Core 核心模块包含管理 PowerShell 基本功能的 cmdlet 和提供程序。
Get-Command https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/get-command
获取所有命令
Syntax(语法) Get-Command [OPTIONS]
OPTIONS
-Name(PATTERN) # 列出匹配到名字的命令。支持通配符。默认值：None -CommandType(STRING) # 列出指定类型的命令。默认值：cmdlet,function,alias。可用的类型有：Alias、All、Application、Cmdlet、ExternalScript、Filter、Function、Script EXAMPLE</description></item><item><title>core 模块指令</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/core-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/core-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
org 官方文档，核心功能 main 模块主要用来为 nginx 程序的运行方式进行定义，并不涉及流量处理相关工作。
指令详解 user USERNAME [GROUPNAME]; # 指定运行 work 线程的用户和组
pid /PATH/PidFile; # 指定 nginx 守护进程的 pid 文件
work_rlimit_nofile NUMBER; # 指定所有 work 线程加起来所能打开的最大文件句柄数</description></item><item><title>CSS</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/CSS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/CSS/</guid><description>概述 参考：
Wiki, CSS Cascading Style Sheets(层叠样式表，简称 CSS) 是一种 样式表 语言，用来描述 HTML 或 XML（包括如 SVG、MathML、XHTML 之类的 XML 分支语言）文档的呈现。CSS 描述了在屏幕、纸质、音频等其它媒体上的元素应该如何被渲染的问题。 CSS 是开放网络的核心语言之一，由 W3C 规范 实现跨浏览器的标准化。CSS 节省了大量的工作。样式可以通过定义保存在外部.css 文件中，同时控制多个网页的布局，这意味着开发者不必经历在所有网页上编辑布局的麻烦。CSS 被分为不同等级：CSS1 现已废弃，CSS2.1 是推荐标准， CSS3 分成多个小模块且正在标准化中。
学习资料 MDN 官方文档，Web 开发技术(通常指的是网站首页的 References 标签中的文档)
CSS 菜鸟教程
CSS CSS3</description></item><item><title>Data type</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-type/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-type/</guid><description>概述 参考：
官方文档，参考 - 规范 - 类型 Data Type(数据类型) 用来对一组相关值进行分类，描述可对其执行的操作并定义它们的存储方式。
Go 语言将数据类型分为四类：基础类型、复合类型、引用类型和接口类型。虽然数据类型有很多，但是这些数据类型都是对程序中一个变量或状态的间接引用。这意味着对任一引用类型数据的修改都会影响所有该引用的拷贝。所谓的引用，是对值的引用。注意引用与指针的区别，详见 pointer.go
Underlying Type(基本类型) 数据中最基本的类型，是构成其余数据类型以及对象的最小单位，当定义其他数据类型时，同样需要定义基础数据类型。基础数据类型也是 Go 语言的内置数据类型
Numeric(数字类型) Integer Type(整数类型) Floating Point Numbers(浮点数型) complex 复数共两种复数，complex64 和 complex128，分别对应 float32 和 float64 两种浮点数精度。内置的 complex 函数用于构建复数，内建的 real 和 imag 函数分别返回复数的实部和虚部 Strings(字符类型) Booleans(布尔类型) 注意：很多时候，Booleans 类型的值可以用数字表示 1 表示 true(真) 0 表示 false(假) Composite Type(复合类型) 是通过组合基础数据类型，来表达更复杂的数据结构
Arrays(数组) # 多个相同基础类型的数据组合在一起 Slices(切片) Maps(字典) Functions(函数，这里面主要指的是函数的参数的数据类型) Structs(结构体) # Interfaces(接口) Channels(通道) Pointers(指针) 自定义数据类型(类型定义) 变量或表达式的 Type 定义了对应存储值的属性特征，例如数值在内存的存储大小（或者是元素的 bit 个数），它们在内部是如何表达的，是否支持一些操作符，以及它们自己关联的方法集等。
在任何程序中都会存在一些变量有着相同的内部结构，但是却表示完全不同的概念。例如，一个 int 类型的变量可以用来表示一个循环的迭代索引、或者一个时间戳、或者一个文件描述符、或者一个月份；一个 float64 类型的变量可以用来表示每秒移动几米的速度、或者是不同温度单位下的温度；一个字符串可以用来表示一个密码或者一个颜色的名称。这些基于基本数据类型所生成的新数据类型都叫数据类型。再比如数组、切片、字典等，虽然在有的时候他们的基础数据类型可以使一样的，但是他们本身所表示的数据类型是不同的含义。</description></item><item><title>Docker 部署</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档，安装-概述 Centos 安装 Ubuntu 安装 二进制安装 安装 Docker 套件 方法 1：使用 Linux 的包管理器安装 使用包管理器安装 # centos yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum install -y docker-ce # ubuntu sudo apt-get -y install apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://repo.huaweicloud.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository &amp;#34;deb [arch=amd64] https://repo.huaweicloud.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&amp;#34; sudo apt-get -y update sudo apt-get -y install docker-ce 若 centos8 提示无法安装 contained.</description></item><item><title>Domain</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Domain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Domain/</guid><description>概述 参考：
官方文档，Domain XML 格式 Domain 对象对应 &amp;lt;domain&amp;gt; 根元素，该元素中有如下属性：
type # 指定用于运行域的管理程序。允许的值是特定于驱动程序的，但包括“xen”、“kvm”、“hvf”（自 8.1.0 和 QEMU 2.12 起）、“qemu”和“lxc”。 id # 它是正在运行的客户机的唯一整数标识符。非活动机器没有 id 值。 下列元素都属于 &amp;lt;domain&amp;gt; 这个根元素的子元素
TODO: &amp;hellip;&amp;hellip; name uuid metadata memory os devices &amp;hellip;&amp;hellip; 上面这些元素可以控制整个 Domain，通常可以分为几大类，下面的笔记将以这些类别进行记录
通用元数据 系统引导 SMBIOS 系统信息 CPU 分配 &amp;hellip;&amp;hellip;. 等等 设备 系统引导 有很多种方式可以引导 Domain，不过个人使用中最常见的就是使用 BIOS 引导。官方文档中还有 Host 引导、直接内核引导、容器引导。等有需要了再记录。
支持完全虚拟化的虚拟机管理程序可以通过 BIOS 启动。在这种情况下，BIOS 具有引导顺序优先级 (软盘，硬盘，光盘，网络)，以确定在何处获取/查找所需的引导镜像。
os # 配置操作系统相关信息
type # 操作系统的类型。可用的值有 hvm、linux。 属性： arch # CPU 的架构。比如 x86_64 machine # 机器类型 boot # 指定 Domain 下次如何引导启动。 属性： dev # 指定 Domain 下次启动时的引导设备，可指定多次设置多个引导设备。可用的值有: fd、hd、cdrom、network。（fd 指软盘，hd 指硬盘） 配置示例 &amp;lt;os&amp;gt; &amp;lt;type arch=&amp;#39;x86_64&amp;#39; machine=&amp;#39;pc-q35-6.</description></item><item><title>eBPF</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/eBPF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/eBPF/</guid><description>概述 参考：
官网 Kernel 官方文档，BPF Kernel 官方文档 Cilium 官方文档，BPF Kernel 官方文档中指向的另一个文档，BPF 官方文档什么是 eBPF 最下面也有链接指向这里 GitHub 项目，torvalds/linux/tools/lib/bpf(libbpf 库) 学习资料 arthurchiao.art 的文章：
[译] 大规模微服务利器：eBPF + Kubernetes（KubeCon, 2020） 公众号，深入浅出 BPF
eBPF 概述：第 1 部分：介绍 eBPF 概述：第 2 部分：机器和字节码 eBPF 概述：第 3 部分：软件开发生态 eBPF 概述：第 4 部分：在嵌入式系统运行 eBPF 概述：第 5 部分：跟踪用户进程 高效入门 eBPF
公众号，阿里云云原生-深入浅出 eBPF | 你要了解的 7 个核心问题
GitHub 项目，DavadDi/bpf_study(DavaDi 的 BPF 学习文章)
https://coolshell.cn/articles/22320.html
eBPF 为什么高效 公众号，云原生实验室，为什么 eBPF 如此受欢迎
eBPF 程序比传统程序“跑得”更快，因为它的代码是直接在内核空间中执行的。
设想这样一个场景，假设一个程序想要统计其从 Linux 系统上发送出去的字节数，需要经过哪些步骤？</description></item><item><title>ECMAScript 模块与包</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/ECMAScript-%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/ECMAScript-%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85/</guid><description>概述 参考：
MDN-参考，JavaScript-JavaScript 指南-JavaScript 模块 网道，ES6 教程-Module 的语法 https://www.zhangxinxu.com/wordpress/2018/08/browser-native-es6-export-import-module/ 历史上，JavaScript 一直没有 Module(模块) 体系，无法将一个大程序拆分成互相依赖的小文件，再用简单的方法拼装起来。其他语言都有这项功能，比如 Ruby 的 require、Python 的 import，甚至就连 CSS 都有 @import，但是 JavaScript 任何这方面的支持都没有，这对开发大型的、复杂的项目形成了巨大障碍。
在 ES6 之前，社区制定了一些模块加载方案，最主要的有 2009 年 1 月发起的 CommonJS 和 AMD 两种，前者用于服务器，后者用于浏览器。
2013 年 5 月，npm 的作者宣布 Node.js 已经废弃 CommonJS，详见 GitHub issue-5132，nodejs/node-v0.x-archive &amp;gt; Wiki, Asynchronous_module_definition(异步模块定义，简称 AMD)
比如，CommonJS 模块就是对象，输入时必须查找对象属性。
// CommonJS 标准 let { stat, exists, readfile } = require(&amp;#34;fs&amp;#34;) // 等同于 js 代码 let _fs = require(&amp;#34;fs&amp;#34;) let stat = _fs.</description></item><item><title>FFmpeg</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/FFmpeg/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/FFmpeg/</guid><description>概述 参考：
GitHub 项目，FFmpge/FFmpge 官网 FFmpeg 是一个库和工具的集合，用于处理多媒体内容，比如 音频、视频、字幕、相关元数据 等。
FFmpeg 是视频处理最常用的开源软件。它功能强大，用途广泛，大量用于视频网站和商业软件（比如 Youtube 和 iTunes），也是许多音频和视频格式的标准编码/解码实现。
FFmpeg 本身是一个庞大的项目，包含许多组件和库文件，最常用的是它的命令行工具。本文介绍 FFmpeg 命令行如何处理视频，比桌面视频处理软件更简洁高效。
安装 FFmpeg https://www.bilibili.com/read/cv23895928/
可以根据 官方文档 先完成安装。
首先来到FFmpeg的官网https://ffmpeg.org，根据你使用的电脑平台进行下载。这里我们下载Windows版本，这里有两个版本，具体选择哪个版本可以参考下面这句话自行决定。这里选择 Windows builds by BtbN 版本进行下载。
Notes: 在Windows系统上，Gyan.dev 和 BtbN 都提供了 FFmpeg 的预编译版本。Gyan.dev 通常使用 MSVC 编译器，而 BtbN 使用 MinGW 编译器。因此，Gyan.dev 的版本可能会更符合 Windows 标准，而 BtbN 的版本可能会更加开放和跨平台。
这时候来到 GitHub 页面，选择其中的 Windows 版本下载。这里有两个版本，具体下载哪个版本根据下面这段话自行决定，两者区别如下：
Notes: 完整版适用于终端用户，因为它包含了所有的可执行文件和静态库，用户可以从命令行调用 FFmpeg 的工具来进行视频处理；
Shared 版仅包含共享库和工具，不包含可执行文件和静态库，这使得开发者可以使用 FFmpeg 的功能实现自己的应用程序或集成 FFmpeg 到自己的项目中。
下载完整版 ffmpeg-master-latest-win64-gpl.zip。解压后直接使用 CLI 二进制文件即可开始使用。
命令行工具 参考：</description></item><item><title>Git 配置详解</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方 Book，自定义 Git-Git 配置 官方文档，git-config Git 使用一系列
~/.gitconfig 文件配置详解 该配置文件可以手动修改，也可以通过 git config &amp;ndash;global XXX 命令修改。
[filter &amp;#34;lfs&amp;#34;] required = true clean = git-lfs clean -- %f smudge = git-lfs smudge -- %f process = git-lfs filter-process [user] name = DesistDaydream email = XXXXXXXX@qq.com [core] autocrlf = input [credential] helper = store git config &amp;ndash;global credential.helper store
core 部分 autocrlf(STRING) # 使用 git 时如何处理文件的换行符
input # 如果您使用的是使用 LF 行结尾的 Linux 或 macOS 系统，那么您不希望 Git 在您签出文件时自动转换它们；但是，如果意外引入了以 CRLF 结尾的文件，那么您可能需要 Git 来修复它。您可以通过将 core.</description></item><item><title>gitlab-ci.yml</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab-CI/gitlab-ci.yml/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab-CI/gitlab-ci.yml/</guid><description>概述 参考:
官方文档，CI/CD YAML 语法参考 GitLab 默认使用 .gitlab-ci.yml 作为 Pipeline 的配置文件。
顶层字段
default(OBJECT) # 有些字段可以作为全局定义，以便让其效果作用在该 Pipeline 的所有 Jobs 中。 workflow(workflow) # 控制运行 Pipeline 的时机 include([]include) # 使用 include 在 CI/CD 配置中包含外部 YAML 文件。将文件 gitlab-ci.yml 成多个文件以提高可读性，或减少在多个位置重复相同的配置。 stages([]STRING) # 定义要执行哪些阶段，也就是说要执行哪些 Job。${JOB_NAME}.stage 字段的值，就是被 stages 识别 JOB 的唯一标识符。 variables(map[STRING]STRING) # 定义全局变量，可以被所有 Job 使用。 ${JOB_NAME}(Jobs) # workflow include Jobs https://docs.gitlab.com/ee/ci/yaml/#job-keywords
定义 Pipeline 中每个 Job 如何运行的
与 Job 是否运行以及如何运行的前置条件相关字段
image(STRING) # 运行 Job 要使用的容器镜像。TODO: 若不指定默认使用的时什么？好像是创建 runner 时可以指定默认使用的 image？</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Glossary/</guid><description>概述 参考：
官方文档，概念 - 术语表 Attribute Attribute(属性) 是 OpenTelemetry 中用于表示 Metadata(元数据) 的概念。
[!Note] Metadata(元数据) 在 OpenTelemetry 中就是 key/value pair(键值对) 的抽象描述。本质上，Attribute 就是一堆 key/value 的集合
e.g. Prometheus 系列的 Metrics 的 Labels、某种描述场景下的 Fields、Dimensions(维度)、etc. 都可以称为 Attribute
Attribute 作为遥测数据的键值对信息，可以跨 Signals、Resources、etc. 使用。
Resources, Instrumentation Scopes, Metric points, Spans, Span Events, Span Links and Log Records 可能包含一组属性。每个此类集合中的键都是唯一的，即，不能存在多个具有相同键的键值对。可以通过多种方式来强制执行唯一性，以使其最适合特定实现的限制。
详见 Attribute 规范
Resource Resource 是 Attribute 的一种，是产生遥测数据的实体的 Attribute。e.g. Kubernetes 中容器运行的进程产生的遥测数据，会包含 进程名称、Pod 名称、命名空间、etc. 这些都属于 Resource Attributes(资源属性)
Signal Metrics、Logs、Traces、Baggage、etc. 都是 Signals 之一</description></item><item><title>Go Module</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Go-Module/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Go-Module/</guid><description>概述 参考：
官方文档，参考-Go Modules 参考 公众号，Go Modules 终极入门 https://blog.csdn.net/benben_2015/article/details/82227338 Go Module(Go 模块) 是实现 Modular Programming(模块化编程) 的工具。是 Go 语言中正式官宣的项目依赖解决方案，Go modules（前身为 vgo）发布于 Go1.11，成长于 Go1.12，丰富于 Go1.13，正式于 Go1.14 已经准备好，并且可以用在生产上（ready for production）了，Go 官方也鼓励所有用户从其他依赖项管理工具迁移到 Go modules。
module 是一个相关 Go 包的集合，它是源代码更替和版本控制的单元。模块由源文件形成的 go.mod 文件的根目录定义，包含 go.mod 文件的目录也被称为模块根。moudles 取代旧的的基于 GOPATH 方法来指定在工程中使用哪些源文件或导入包。模块路径是导入包的路径前缀，go.mod 文件定义模块路径，并且列出了在项目构建过程中使用的特定版本。
使用 Go Module 时，GOPATH 不再用于解析导入。但是，它仍然用于存储下载的源代码（在$GOPATH/pkg/mod 中）和编译的命令（在 GOPATH / bin 中）。
当程序编译时，会读取 go.mod 文件中的路径，来加载其编译所需的各种库
Go moudles 目前集成在 Go 的工具链中，只要安装了 Go，自然而然也就可以使用 Go moudles 了，而 Go modules 的出现也解决了在 Go1.11 前的几个常见争议问题：
Go 语言长久以来的依赖管理问题。 “淘汰”现有的 GOPATH 的使用模式(即.</description></item><item><title>GRE</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/GRE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/GRE/</guid><description>概述 参考：
Generic Routing Encapsulation(通用路由封装，简称 GRE) 是一种隧道协议，在数据两端，对数据进行封装和解封装。是 Cisco Systems 开发的隧道协议，可以通过 Internet 协议网络将各种网络层协议封装在虚拟点对点链路中。
如上图，当从本机想要通过隧道发送数据时，会通过 GRE 模块进行封装，然后把对外通信的 IP 地址当做 GRE 的外部地址，封装在最外成变成新的 IP。此时，GRE 还会有一个内部地址用来与隧道的对端进行协商，以便识别公网上的隧道两端的设备
Linux 下实现 GRE 场景一：
如果 Linux1 想要访问 10.10.2.0/24 网段的设备，这时候可以使用 GRE 建立隧道来实 现。比如在 Linux1 上想访问 10.10.2.100 这台设备，把数据包通过手动添加路由的方式，直接送给 tun 设备，tun 设备会直接把数据包发送给其隧道的对端(i.e.Linux2)，当 Linux2 收到这个数据包时，会发现 GRE 的包头，并解开 GRE 后发现真实的目的地址(10.10.2.100)，这时候可以在 Linux2 上做一个 snat，指明源地址 172.16.0.1/32 且目的地址是 10.10.2.0/24 网段的数据包全部把源地址转换成 10.10.2.1(如果不做 snat，源地址是 172.16.0.1，在回包的时候，是无法回去的，否则再添加其余路由条目)
场景二：
10.10.0.1/24 与 10.10.1.1/24 作为网段的网关使用，可以让两边的内网机器，直接互相访问。同样需要手动添加路由，目的地址是对端内网网段的 IP 的数据包送给 tun 设备。
注意：在 Linux1 上 ping172.16.0.2 的时候，在 Linux2 上抓包的话，会显示源地址是 172.</description></item><item><title>Inode</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/Inode/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/Inode/</guid><description>概述 参考：
Wiki, Inode 知乎，本地文件系统小计（二）：inode Index node(索引节点，简称 inode) 是 Unix 风格的文件系统中的一种数据结构。每个索引节点保存了文件系统中的一个文件系统对象(i.e.文件、目录等)的元信息数据，但不包括数据内容或者文件名。
注：数据的内容存放在硬盘的一个 block(区域块) 中，通过 inode(索引节点) 来访问 block，每个索引节点都会命名一个文件名。文件的索引节点通过 ls -i 命令查看
~]# ls -i / 12 bin 1 dev 6029313 home 14 lib32 16 libx32 2097153 media 1572865 opt 1048577 root 17 sbin 1966081 srv 1 sys 4325377 usr 2 boot 1835009 etc 13 lib 15 lib64 11 lost+found 4063233 mnt 1 proc 1 run 4980737 snap 18 swap.img 3801089 tmp 1179649 var 所以，linux 里的所有文件，都相当于一个 Hard link(硬连接)，链接到 inode 号上，展现在屏幕上的只是该文件内容的文件名。就算几个文件名字不一样的文件只要节点号相同，那么这几个文件的内容是就是相同的。想查看文件内容，就要找到该文件名对应的 inode 然后通过 inode 找到 block，找到 block 就能看到其中的内容了。</description></item><item><title>IPsec and L2TP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/IPsec-and-L2TP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/IPsec-and-L2TP/</guid><description>概述 参考：
Wiki, IPsec Wiki, L2TP Internet Protocol Security(因特网协议安全，简称 IPsec) 是一种安全网络协议套件，可对数据包进行身份验证和加密，以通过 Internet 协议网络在两台计算机之间提供安全的加密通信。它用于虚拟专用网络 (VPN)。
Layer 2 Tunneling Protocol(2层隧道协议，简称 L2TP) 是一种隧道协议，用于支持虚拟专用网络 (VPN) 或作为 ISP 提供服务的一部分。它仅对其自己的控制消息使用加密（“隐藏”）（使用可选的预共享秘密），并且其本身不提供任何内容加密或机密性。相反，它为第 2 层提供隧道（可以加密），并且隧道本身可以通过第 3 层加密协议（例如 IPsec）进行传递。
知乎，既然IPsec有隧道模式，为什么还有L2TP+IPsec这样的组合？
您好，这是必应。根据我从网络上搜索到的信息，我给您简单介绍一下 ipsec 和 l2tp 的区别：
ipsec 是一种安全协议，它可以在网络层对数据进行加密、认证和完整性保护，防止数据被窃听、篡改或伪造。 l2tp 是一种隧道协议，它可以在数据链路层对数据进行封装和传输，实现不同网络之间的透明连接。 ipsec 和 l2tp 可以单独使用，也可以结合使用。当单独使用时，ipsec可以提供数据的安全性，但不能跨越不同的网络类型；l2tp可以提供数据的透明性，但不能保证数据的安全性。 当结合使用时，ipsec 和 l2tp 可以互补，实现数据的安全和透明传输。一般有两种组合方式：ipsec over l2tp 和 l2tp over ipsec。前者是先用ipsec加密数据，再用l2tp封装数据；后者是先用l2tp封装数据，再用 ipsec 加密数据。 Libreswan https://github.com/libreswan/libreswan
https://libreswan.org/
https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md
https://github.com/hwdsl2/docker-ipsec-vpn-server/blob/master/README-zh.md IKEv2 客户端 参考：
https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/ikev2-howto-zh.md 现代操作系统支持 IKEv2 协议标准。因特网密钥交换（英语：Internet Key Exchange，简称 IKE 或 IKEv2）是一种网络协议，归属于 IPsec 协议族之下，用以创建安全关联 (Security Association, SA)。与 IKE 版本 1 相比较，IKEv2 的 功能改进 包括比如通过 MOBIKE 实现 Standard Mobility 支持，以及更高的可靠性。</description></item><item><title>iptables 命令行工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/iptables-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/iptables-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
Manual(手册)，iptables(8) Manual(手册)，iptables-extensions(8) Man 手册中，将 iptables 分为两部分，基本的 iptables 和用于描述扩展规则的 iptables-extensions，当使用扩展规则时，需要通过 -m, --match ModuleName 选项指定要使用的扩展模块的名称。
另外，所谓的扩展规则，其实是对原始 iptables 的扩展，并不仅仅扩展了匹配数据包的规则，还有很多其他的功能。
Syntax(语法) iptables [OPTIONS] COMMAND [CHAIN] [RuleSpecifitcation]
Command # 指定要执行的具体操作。比如 增删改查规则/链 等等。 CHAIN # 指定要执行操作的链。在不指定的时候，默认对所有链进行操作。 CHAIN 其实不应该放在这，一般都是 COMMAND 中的组成部分。 RuleSpecifitcation = MATCHES TARGET # 通常用在增加规则时，指定规则的具体规范。由两部分组成：[MATCHES&amp;hellip;] 和 [TARGET] MATCHES = [基本匹配规则] [扩展匹配规则] # 匹配条件，可以指定多个。用以筛选出要执行 TARGET 的数据包的条件 TARGET = -j TargetName [Per-Target-Options] # 指定匹配到规则的数据包的 Target(目标) 是什么。 OPTIONS -t, &amp;ndash;table TALBLE # 指定 iptables 命令要对 TABLE 这个表进行操作。默认值: filter。省略该选项时，表示默认对 filter 表进行操作。 -n, &amp;ndash;numeric # 所有输出以数字的形式展示。IP 地址、端口号等都以数字输出。默认情况下一般是显示主机名、网络名称、服务。 &amp;ndash;line-numbers # 显示每个 chain 中的行号 -v # 显示更详细的信息，vv 更详细，vvv 再详细一些 pkts # 报文数 bytes # 字节数 target # prot # in/out # 显示要限制的具体网卡，* 为所有 source/destination # COMMAND 增 -A, &amp;ndash;append &amp;lt;CHAIN&amp;gt; &amp;lt;RuleSpecification&amp;gt; # 在规则连末尾添加规则 -I, &amp;ndash;insert &amp;lt;CHAIN&amp;gt; [RuleNum] &amp;lt;RuleSpecification&amp;gt; # 在规则链开头添加规则，也可以指定添加到指定的规则号 -N, &amp;ndash;new-chain CHAIN # 创建名为 CHAIN 的自定义规则链 删 -F, &amp;ndash;flush [CHAIN [RuleNum]] # 删除所有 chain 下的所有规则，也可删除指定 chain 下的指定的规则 -D, &amp;ndash;delete &amp;lt;CHAIN&amp;gt; &amp;lt;RULE&amp;gt; # 删除一个 chain 中规则，RULE 可以是该 chain 中的行号，也可以是规则具体配置 -X, &amp;ndash;delete-chain [CHAIN] # 删除用户自定义的空的 chain 改 -P, &amp;ndash;policy &amp;lt;CHAIN&amp;gt; &amp;lt;TARGET&amp;gt; # 设置指定的规则链(CHAIN)的默认策略为指定目标(Targe) -E, &amp;ndash;rename-chain &amp;lt;OldChainName&amp;gt; &amp;lt;NewChainName&amp;gt; # 重命名自定义 chain，引用计数不为 0 的自定义 chain，无法改名也无法删除 -R, &amp;ndash;replace CHAIN [RuleNum] &amp;lt;RuleSpecification&amp;gt; # 替换指定链上的指定规则 查 -L, &amp;ndash;list [CHAIN [RuleNum]] # 列出指定 CHAIN 的规则。默认值: 不指定。i.</description></item><item><title>K3S 部署与清理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</guid><description>概述 参考：
官方文档，快速开始指南 公众号-CNCF，利用 kube-vip 实现 K3s 高可用部署 curl -sfL https://get.k3s.io | sh - 使用该脚本，可以自动创建用于运行 k3s 二进制文件的 service 文件，并通过 systemd 启动。
注意：
k3s 会自动部署 servicelb 服务，该服务与 kube-proxy 的 ipvs 模式冲突。 快速部署体验 获取安装脚本
curl -LO http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh 第一个 master 执行
K3S_TOKEN=SECRET \ INSTALL_K3S_MIRROR=cn \ INSTALL_K3S_VERSION=&amp;#39;v1.20.4+k3s1&amp;#39; \ INSTALL_K3S_EXEC=&amp;#39;server --cluster-init&amp;#39; \ bash k3s-install.sh 其余 master 执行
K3S_TOKEN=SECRET \ INSTALL_K3S_MIRROR=cn \ INSTALL_K3S_VERSION=&amp;#39;v1.20.4+k3s1&amp;#39; \ INSTALL_K3S_EXEC=&amp;#39;server --server https://172.19.42.207:6443&amp;#39; \ bash k3s-install.sh 其余 node 执行
K3S_TOKEN=SECRET \ INSTALL_K3S_MIRROR=cn \ INSTALL_K3S_VERSION=&amp;#39;v1.</description></item><item><title>kube-controller-manager 实现控制器的程序</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/kube-controller-manager-%E5%AE%9E%E7%8E%B0%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E7%A8%8B%E5%BA%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/kube-controller-manager-%E5%AE%9E%E7%8E%B0%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E7%A8%8B%E5%BA%8F/</guid><description>概述 参考：
kube-controller-manager 是实现 Kubernetes Controller(控制器) 的程序。一般在集群启动之前，由 kubelet 使用静态 Pod 以容器方式运行；或者使用 systemd 以 daemon 方式运行。
kube-controller-manager 启动后监听两个端口。
10257 端口是需要身份验证和授权的 https 服务端口。 10252 为不安全的 http 服务端口。 kube-controller-manager 高可用 参考：Leader Election(领导人选举)
我们都知道 k8s 核心组件，其中 apiserver 只用于接收 api 请求，不会主动进行各种动作，所以他们在每个节点都运行并且都可以接收请求，不会造成异常；kube-proxy 也是一样，只用于做端口转发，不会主动进行动作执行。 但是 scheduler, controller-manager 不同，他们参与了 Pod 的调度及具体的各种资源的管控，如果同时有多个 controller-manager 来对 Pod 资源进行调度，结果太美不敢看，那么 k8s 是如何做到正确运转的呢？ k8s 所有功能都是通过 services 对外暴露接口，而 services 对应的是具体的 endpoints ，那么来看下 scheduler 和 controller-manager 的 endpoints 是什么：
[root@node70 21:04:46 ~]$kubectl -n kube-system describe endpoints kube-scheduler Name: kube-scheduler Namespace: kube-system Labels: &amp;lt;none&amp;gt; Annotations: control-plane.</description></item><item><title>kubeadm CLI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-CLI/</guid><description>概述 参考：
Syntax(语法) kubeadm [command]
Command 包括：
alpha Kubeadm experimental sub-commands completion Output shell completion code for the specified shell (bash or zsh). config Manage configuration for a kubeadm cluster persisted in a ConfigMap in the cluster. help Help about any command init Run this command in order to set up the Kubernetes master. join Run this on any machine you wish to join an existing cluster reset Run this to revert any changes made to this host by &amp;lsquo;kubeadm init&amp;rsquo; or &amp;lsquo;kubeadm join&amp;rsquo;.</description></item><item><title>Kubelet 配置</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
官方文档，入门-生产环境-使用工具安装 Kubernetes-使用 kubeadm 引导集群-使用 kubeadm 配置集群中每个 kubelet 官方文档，参考-配置 APIs-Kubelet 配置(v1beta1) 可以通过两种方式配置 kubelet 运行时行为
config.yaml 配置文件 # config.yaml 文件默认路径为 /var/lib/kubelet/config.yaml ，可以通过 &amp;ndash;config &amp;lt;FILE&amp;gt; 来指定其他的文件。 这里是官方文档对于配置文件的概述。在章节中间部分，可以直接看到配置文件对应的代码中结构体，也就是配置文件详细内容 这里是配置文件中每个字段的详解，与代码中的结构体互相对应，只不过是整理后，可以直接在网页上查看，更清晰。 kubelet 命令行标志 这里是官方文档对命令行标志的详解 官方更推荐使用第一种方式，通过 config.yaml 的文件修改，来改变 kubelet 的运行时参数。
很多配置文件的内容与命令行标志具有一一对应的关系，比如：
配置文件 命令行标志 cgroupDriver: systemd &amp;ndash;cgroup-driver=systemd clusterDNS: [10.96.0.10,&amp;hellip;] &amp;ndash;cluster-dns=10.96.0.10,&amp;hellip; authentication.x509.clientCAFile: /etc/kubernetes/pki/ca.crt &amp;ndash;client-ca-file=/etc/kubernetes/pki/ca.crt 等等 等等 但是也有一些是没有对应关系的，只能通过配置文件，或者命令行标志配置。比如命令行标志的 --container-runtime 就无法在配置文件中配置。在命令行标志官方文档中，凡是标着 DEPRECATED 的命令行标志，都是可以在配置文件中配置的。
命令行标志详解 参考：
官方文档，参考 - 组件工具 - kubelet &amp;ndash;cni-conf-dir &amp;lt;STRING&amp;gt; # Warning：Alpha 功能。指定 STRING 目录中搜索 CNI 配置文件。 默认值：/etc/cni/net.</description></item><item><title>Libvirt 守护进程</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Driver/Libvirt-%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Driver/Libvirt-%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/</guid><description>概述 参考：
官方文档，Libvirt 守护进程 官方文档，手册-libvirtd 传统上，Libvirt 项目提供了一个名为 libvirtd 的单一守护进程，它暴露了对所有有状态 Driver 的支持，包括主要虚拟机管理程序驱动程序和辅助支持驱动程序。它还支持监听在 TCP/IP 上，以便主机外运行的客户端进行安全远程访问。
未来，想要将一个整体的 libvirtd 守护进程替换为一组模块化的守护进程，以 virt${DRIVER}d 命令，就是每个驱动都有自己独立的守护进程。还有一个 virtproxyd 守护进程可以提供安全的远程访问。 —— 2023.7.5
libvirtd libvirtd 程序是 libvirt 虚拟化管理系统的服务器端守护进程组件。包含了部分 Hypervisor 驱动，并暴露了 Libvirt API
该守护进程在主机服务器上运行，并为虚拟来宾执行所需的管理任务。这包括启动、停止和在主机服务器之间迁移来宾、配置和操作网络以及管理供来宾使用的存储等活动。
libvirt 客户端库和实用程序连接到此守护进程以发出任务并收集有关主机系统和来宾的配置和资源的信息。
默认情况下，libvirtd 守护进程侦听本地 Unix 域套接字上的请求。使用 -l | &amp;ndash;listen 命令行选项，可以指示 libvirtd 守护进程另外侦听 TCP/IP 套接字。要使用的 TCP/IP 套接字在 libvirtd 配置文件中定义。
这里官方说的其实有一些问题，参考 https://stackoverflow.com/questions/65663825/could-not-add-the-parameter-listen-to-open-tcp-socket ，并且在下面关于启动模式中也有说明。
重新启动 libvirtd 不会影响正在运行的 guest 虚拟机。如果定义了 XML 配置，来宾将继续操作并将被自动接听。任何尚未定义 XML 配置的来宾都将从配置中丢失。
libvirtd 守护进程能够以两种模式启动
传统模式 # 它将自行创建并侦听 UNIX 套接字。 如果给出了 &amp;ndash;listen 参数，它还将根据 /etc/libvirt/libvirtd.</description></item><item><title>Linux libc 库</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Linux-libc-%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Linux-libc-%E5%BA%93/</guid><description>概述 参考：
Manual(手册)，libc(7) Wiki, glibc 术语 libc 通常用作“标准 C 库”的简写，这是所有 C 程序（以及其他语言的程序）可以使用的标准函数库。由于一些历史（见下文），使用术语 libc 来指代标准 C 库在 Linux 上是不够严谨的。
glibc 到目前为止，Linux 上使用最广泛的 C 库是 GNU C 库。这是目前在所有主要 Linux 发行版中使用的 C 库。它也是 C 库，其详细信息记录在手册页项目的相关页面中 (主要在手册的第 3 节中)。glibc 的文档也可在 glibc 手册中找到，可通过命令信息 libc 获得。glibc 的版本 1.0 制作于 1992 年 9 月。(之前有 0.x 版本。)glibc 的下一个主要版本是 1997 年初的 2.0。
路径名 /lib/libc.so.6 (或类似内容) 通常是指向 glibc 库位置的符号链接，执行此路径名将导致 glibc 显示有关系统上安装的版本的各种信息。
CentOS7：
~]# ls -l /lib64/libc.so.6 lrwxrwxrwx. 1 root root 19 Mar 7 16:53 /lib64/libc.</description></item><item><title>Literal</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/Literal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/Literal/</guid><description>概述 参考：
Wiki, Literal(字面量) 在计算机科学中，Literal(字面量) 是表示源代码中固定值的 snotation(表示法)。几乎所有计算机编程语言都具有对基本值的字面量表示，诸如：整数、浮点数以及字符串；而有很多也对布尔类型和字符类型的值也支持字面量表示；还有一些甚至对枚举类型的元素以及像数组、记录和对象等复合类型的值也支持字面量表示法。
// b 为常量，10为字面量,数据类型为整数 const int b = 10 // str 为变量，hello world！为字面量，数据类型为字符串 string str = &amp;#34;hello world！&amp;#34;</description></item><item><title>Log Queries</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/LogQL/Log-Queries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/LogQL/Log-Queries/</guid><description>概述 参考：
官方文档，查询 - 日志查询 基本的日志查询由两部分组成：
Log Stream Selector(日志流选择器) # Log Pipeline(日志管道) # 注意：由于 Loki 的设计原则，所有的 LogQL 查询必须包含 Log Stream Selector(日志流选择器)
日志流选择器决定了有多少日志流将被搜索到，一个更细粒度的日志流选择器将搜索到流的数量减少到一个可管理的数量。所以传递给日志流选择器的标签将影响查询执行的性能。
而日志流选择器后面的日志管道是可选的，日志管道是一组阶段表达式，它们被串联在一起应用于所过滤的日志流，每个表达式都可以过滤、解析和改变日志行内容以及各自的标签。
下面的例子显示了一个完整的日志查询的操作：
{container=&amp;quot;query-frontend&amp;quot;,namespace=&amp;quot;loki-dev&amp;quot;} |= &amp;quot;metrics.go&amp;quot; | logfmt | duration &amp;gt; 10s and throughput_mb &amp;lt; 500
该查询语句由以下几个部分组成：
一个日志流选择器 {container=&amp;quot;query-frontend&amp;quot;,namespace=&amp;quot;loki-dev&amp;quot;}，用于过滤 loki-dev 命名空间下面的 query-frontend 容器的日志 然后后面跟着一个日志管道 |= &amp;quot;metrics.go&amp;quot; | logfmt | duration &amp;gt; 10s and throughput_mb &amp;lt; 500，这管道表示将筛选出包含 metrics.go 这个词的日志，然后解析每一行日志提取更多的表达并进行过滤 为了避免转义特色字符，你可以在引用字符串的时候使用单引号，而不是双引号，比如 \w+1 与 &amp;ldquo;\w+&amp;rdquo; 是相同的。
Log Stream Selector(日志流选择器) Log Stream Selector 用于确定查询结果中应该包括哪些日志流。Log Stream Selector 由一个或多个Label(标签) 组成，Label 是以 = 分割的 Key/Value Paire(键/值对) 。所谓的日志流就是一行一行的日志，组合在一起，形成的一种类似数据流的感觉，从上到下哗哗流水那种感觉~日志流说白了就是日志的集合。stream(流) 的概念如果在 Prometheus 中描述，那就是 series(序列) 的概念。</description></item><item><title>Loki 部署</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档，安装 官方文档，基础知识 - 架构 - 部署模式 使用 docker 运行 Loki docker run -d --rm --name loki \ --network host \ -v /opt/loki/config:/etc/loki \ -v /opt/loki/data:/loki \ -v /etc/localtime:/etc/localtime:ro \ grafana/loki 注意：与 Prometheus 类似，需要修改 /opt/loki 目录权限为 777，否则 pod 内进程对该目录无操作权限
在 Kubernets 集群中部署 添加 loki 的 helm chart 仓库
helm repo add grafana https://grafana.github.io/helm-charts helm repo update Helm 部署 Loki 套件 参考：
官方文档 2.4.x，安装 - helm 部署 Loki 栈
kubectl create ns loki # 创建名称空间 helm pull grafana/loki-stack # 获取 loki-stack 的 charts 压缩包 tar -zxvf loki-stack-X.</description></item><item><title>LVS 配置示例</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/LVS-%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/LVS-%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</guid><description>概述 参考：
DR 模型配置样例 Director 配置
ipvsadm -A -t 10.10.100.107:80 -s rr ipvsadm -a -t 10.10.100.107:80 -r 10.10.100.111 -g ipvsadm -a -t 10.10.100.107:80 -r 10.10.100.112 -g RS 的配置
设置 arp 参数
cat &amp;gt; /etc/sysctl.d/lvs-sysctl.conf &amp;lt;&amp;lt; EOF net.ipv4.conf.all.arp_ignore = 1 net.ipv4.conf.lo.arp_ignore = 1 net.ipv4.conf.all.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 EOF sysctl -p /etc/sysctl.d/* 配置 lo 网卡
cat &amp;gt; /etc/sysconfig/network-scripts/ifcfg-lo:0 &amp;lt;&amp;lt; EOF DEVICE=lo:0 IPADDR=10.10.100.107 NETMASK=255.255.255.255 ONBOOT=yes NAME=loopback EOF ifup ifcfg-lo\:0 其他配置样例 配置一个 NAT 类型（2 台 RS）的集群 LVS(Thinkpad): if1=172.</description></item><item><title>Memory 的分配</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory-%E7%9A%84%E5%88%86%E9%85%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory-%E7%9A%84%E5%88%86%E9%85%8D/</guid><description>概述 参考：
公众号-小林coding，我做了个实验！ Linux 进程的内存分布长什么样？ 在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：
通过这张图你可以看到，用户空间内存从低到高分别是 6 种不同的内存段：
通过这里可以看出：
32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间； 64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。 再来说说，内核空间与用户空间的区别：
进程在用户态时，只能访问用户空间内存； 只有进入内核态后，才可以访问内核空间的内存； 虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。
接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。
我们看看用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：
程序文件段，包括二进制可执行代码； 已初始化数据段，包括静态常量； 未初始化数据段，包括未初始化的静态变量； 堆段，包括动态分配的内存，从低地址开始向上增长； 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 ）； 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小； 在这 6 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。
malloc 是如何分配内存的？ 实际上，malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。
malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。
方式一：通过 brk() 系统调用从堆分配内存 方式二：通过 mmap() 系统调用在文件映射区域分配内存； 方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图：
方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：</description></item><item><title>Memory 管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Memory-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Memory-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
查看 Memory 的使用情况 我们可以通过多种方式查看 Memory 信息。
free 命令 参考：
https://gitlab.com/procps-ng/procps ~]# free -h total used free shared buff/cache available Mem: 3.8Gi 846Mi 506Mi 1.0Mi 2.5Gi 2.9Gi Swap: 0B 0B 0B Mem：设备上的真实内存
total # 总计。该设备的总内存大小 used # 已使用的。linux 对内存的使用量 free # 空闲的。还剩多少内存可用 shared # 共享内存 buff # 缓冲区(buffer)。保存一些将要写入到硬盘中的数据。 cache # 缓存。从硬盘中读出的数据存放到内存中，以便再次读取相同数据时速度更快。 availabel # 可用的。free+buff/cache 合起来就是可用的。 free 命令 与 /proc/meminfo 文件中信息的对应关系 free 命令输出 /proc/meminfo文件的字段 Mem: total MemTotal Mem: used MemTotal - MemFree - Buffers - Cached - SReclaimable Mem: free MemFree Mem: shared Shmem Mem: buff/cache Buffers + Cached + SReclaimable Mem: available MemAvailable Swap: total SwapTotal Swap: used SwapTotal - SwapFree Swap: free SwapFree buff/cache = Buffers + Cached + SReclaimable</description></item><item><title>Mount(挂载)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/Mount%E6%8C%82%E8%BD%BD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/Mount%E6%8C%82%E8%BD%BD/</guid><description>概述 参考：
Manual(手册),fstab(5) Manual(手册),mount(8) 注意：
mount 命令无法列出 bind 类型的挂载(比如 Docker 和 Containerd 的 bind 类型挂载，不知道如何列出)。
不过 findmnt 命令可以列出使用 mount --bind XX XX 挂载的目录，效果如下
~]# findmnt TARGET SOURCE FSTYPE OPTIONS / /dev/vda3 ext4 rw,relatime ...... └─/mnt/cdrom /dev/vda3[/root/downloads/webvirtcloud] ext4 rw,relatime 关联文件与配置 /etc/fstab # 包含各种 file systems 的描述性信息。系统启动时，根据该文件配置挂载分区到指定路径。
/etc/mtab # 是一个软连接，连接到 /proc/self/mounts
XXX.mount # 以 .mount 为后缀的 unit 文件，是由 systemd 管理的文件系统描述信息。systemd 将根据这些 unit 文件，将指定的文件系统挂载到系统中。
fstab 文件详解 File System Table(文件系统表，简称 fstab) 是一个关于文件系统的静态信息文件。默认路径为 /etc/fstab
fstab 包含操作系统中可以挂载的文件系统的描述性信息。每个描述信息占用单独一行，每行的各个字段由制表符或空格分隔。fsck、mount、umount 命令在执行某些操作时将会顺序读取该文件的每一行。</description></item><item><title>NIC</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/NIC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/NIC/</guid><description>概述 参考：
Wiki, Network interface controller Network interface controller(网络接口控制器，简称 NIC) 是将计算机连接到计算机网络的计算机硬件组件。
很多时候口语化表达为 网卡。还有 Network interface card(网络接口卡)、Network adapter(网络适配器)、LAN adapter(LAN适配器)、Physical network interface(物理网络接口) 等描述都是用来形容网卡的。</description></item><item><title>Object</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object/</guid><description>概述 参考：
官方文档，概念 - 使用 Kubernetes 对象 从某些角度看来，Kubernetes 里的一切介 Object(对象)。就像 Linux 里，一切介文件的角度一样。
API Resource(资源) 用于表示 Objectk(对象) 的集合。例如 pod 资源可以用于描述所有 pod 资源类型的对象，比如我创建一个 pod 资源，生成了一个名为 test1 的 pod 类型的对象，如果创建了多个 pod 对象，那么每个对象都是 pod 类型的资源。
Kubernetes Objectk(对象) 是 Kubernetes 系统中，Resource(资源) 的持久化实体。Kubernetes 使用这些实体来表示集群的状态。具体来说，他们可以描述：
哪些容器化应用程序正在运行（以及在哪些节点上） 这些应用可用的资源 有关这些应用程序的行为的策略，例如重新启动策略，升级和容错 Kubernetes 对象是“record of intent(目标性记录)”：即,一旦创建了对象，Kubernetes 系统会确保对象存在。通过创建对象，本质上时告诉 Kubernetes 系统你希望集群的工作负载是什么样的，这就是 kubernetes 集群的 desired state(期望状态)。
要操作 Kubernetes 对象(无论是创建，修改还是删除)，都需要使用 Kubernetes API 。例如，当使用 kubectl 命令管理工具时，CLI 会执行必要的 KubernetesAPI 调用。也可以直接在自己的程序中使用 Client Libraries 来调用 KubernetesAPI。Client Libraries(客户端库)可以理解为编程语言的一个第三方库，通过这个库中的方法，可以直接调用 KubernetesAPI。
用白说描述：每个已经启动的 pod 就是一个 object(对象)，每个已经创建的 namesapce 也是一个 object。而 pod、namespace 本身称为 resource(资源)。所以 object 就叫 kubernetes 系统中持久化的实体。</description></item><item><title>OpenSSH 配置</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/OpenSSH-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/OpenSSH-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
官方文档，手册 - sshd_config 官方文档，手册 - ssh_config sshd_config 文件 Port(NUM) # 设定 sshd 服务监听的端口号
ListenAddress(IP) # 设定 sshd 服务监听的 IP 地址(全 0 为所有 IP)
PermitRootLogin(yes|no) # 设定是否允许 root 用户通过 ssh 直接登录
AllowUsers # 设定允许通过 ssh 登录的用户 User1,2,3 等等
AllowGroups # 设定允许通过 ssh 登录的组 Group1,2,3,等等等
KbdInteractiveAuthentication #
注意：该关键字是已经被启用的 ChallengeResponseAuthentication 关键字的替代品
PermitTunnel(STRING) # 指定是否允许 tun 设备转发。可用的值有 yes、point-to-point、ethernet、no。默认值: no
https://man.openbsd.org/sshd_config#PermitTunnel GatewayPorts # 指定是否允许远程主机连接到为客户端转发的端口。
ForceCommand #
https://man.openbsd.org/sshd_config#ForceCommand Match # 创建一个独立的配置块。满足 Match 指定的匹配条件时，Match 所在行下的所有配置都将覆盖</description></item><item><title>Percona Monitoring and Management</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Percona/Percona-Monitoring-and-Management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Percona/Percona-Monitoring-and-Management/</guid><description>概述 参考：
官网介绍 官方文档 原文链接 分析慢查询的:https://www.percona.com/blog/2020/10/07/how-to-find-query-slowdowns-using-percona-monitoring-and-management/
基于 pmm2 去排查故障的官方文档:https://www.percona.com/blog/2020/07/15/mysql-query-performance-troubleshooting-resource-based-approach/
Percona Monitoring and Management(简称 PMM) 是一个用于管理和监控 MySQL、PostgreSQL、MongoDB 和 ProxySQL 性能的开源平台。它是由 Percona 与管理数据库服务、支助和咨询领域的专家合作开发的。
PMM 是一种免费的开源解决方案，您可以在自己的环境中运行它，以获得最大的安全性和可靠性。它为 MySQL、PostgreSQL 和 MongoDB 服务器提供了全面的基于时间的分析，以确保您的数据尽可能高效地工作。
PMM 平台基于支持可伸缩性的客户机-服务器模型。它包括以下模块:
PMM 客户机安装在您想要监视的每个数据库主机上。它收集服务器指标、一般系统指标和查询分析数据，以获得完整的性能概述。
PMM 服务器是 PMM 的中心部分，它聚合收集到的数据，并在 web 界面中以表格、仪表板和图形的形式显示这些数据。
模块被打包以便于安装和使用。假设用户不需要了解组成每个模块的具体工具是什么，以及它们如何交互。然而，如果您想充分利用 PMM 的潜力，内部结构是重要的。
PMM 是一种工具的集合，它被设计成可以无缝地协同工作。有些是由 Percona 开发的，有些是第三方开源工具。
PMM Server
PMM 服务器在作为中央监视主机的机器上运行。它通过以下方式作为设备分发:
*可用于运行容器的 Docker 映像
*可以在 VirtualBox 或其他管理程序中运行的 OVA(打开虚拟设备)
*您可以通过 Amazon Web 服务运行的 AMI (Amazon Machine Image)
PMM 服务器包括以下工具:
*查询分析(QAN)允许您在一段时间内分析 MySQL 查询性能。除客户端 QAN 代理外，还包括:</description></item><item><title>Playbook Role(角色)</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Playbook-Role%E8%A7%92%E8%89%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Playbook-Role%E8%A7%92%E8%89%B2/</guid><description>概述 参考：
官方文档，Playbook 指南 - Roles Ansible 中文权威指南，Playbooks-Playbook 角色和 Incluede 语句 刚开始学习运用 playbook 时，可能会把 playbook 写成一个内容很多的文件，这种情况不利于扩展和复用。这时候可以使用一种方式，将这个复杂的 playbook 模块化，即拆分一个复杂的 playbook 文件成多个零散的小文件，将其组合成一个一个具有不同功能的 playbook。
这时候就需要用到 ansible playbook 的 roles 概念了。roles 实际上是对 playbook 进行逻辑上的划分，主要依赖于目录的命名和摆放，一个 Role 就是一个目录，Role 名与目录名相同。
当我们开始思考这些概念：tasks, handlers, variables 等等，是否可以将它们抽象为一个更大的概念呢。我们考虑的不再是”将这些 tasks，handlers，variables 等等应用到这些 hosts 中”，而是有了更抽象的概念，比如：”这些 hosts 是 dbservers” 或者 “那些 hosts 是 webservers”（注：dbserver，webservers 即是”角色”）。这种思考方式在编程中被称为”封装”，将其中具体的功能封装了起来。举个例子，你会开车但并不需要知道引擎的工作原理（注：同样的道理，我们只需要知道”这些 hosts 是 dbservers”，而不需要知道其中有哪些 task，handlers 等）。
roles 目录结构 下面是一个最基本的 roles 目录结构。在这个目录结构里，有两个 roles，一个名为 common，另一个名为 webservers
site.yml webservers.yml fooservers.yml roles/ common/ tasks/ handlers/ files/ templates/ vars/ defaults/ meta/ webservers/ tasks/ defaults/ meta/ 每个目录的作用如下</description></item><item><title>Port mirroring</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Port-mirroring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Port-mirroring/</guid><description>概述 参考：
Wiki, Port mirroring Port mirroring(端口镜像) 是交换机上的一个功能，可以将一个端口上经过的所有流量复制一份到另一个端口上。这种方式通常用于需要监控网络流量的环境中，原始流量不受影响，被复制的流量发往后端设备以进一步分析，比如 IDS(入侵监测系统)、etc. 。Cisco 公司生成的交换机上的 Port mirroring 功能称为 Switched Port Analyzer(简称 SPAN) 或 Remote Switched Port Analyzer(简称 RSPAN)，有时候称为 Span Port。
网络工程师或管理员使用端口镜像来分析和调试数据或诊断网络上的错误。它可以帮助管理员密切关注网络性能并在出现问题时向他们发出警报。它可用于镜像单个或多个接口上的入站或出站流量（或两者）。
随着网络分析需求的增加，很多时候也会把 Port mirroring 形容成流量镜像的功能，只有具备了 Port mirroring 的系统，才能真正实现 Network analysis。
SPAN Switched Port Analyzer(简称 SPAN)</description></item><item><title>POSIX</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/POSIX/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/POSIX/</guid><description>概述 参考：
Wiki, POSIX 腾讯云，什么是 POSIX Portable Operating System Interface(便携式操作系统接口，POSIX) 是 IEEE 的计算机协会指定的一系列标准，用于维护操作系统之间的兼容性。 POSIX 定义了应用程序编程接口 (API)，以及命令行 shell 和实用程序接口，以实现与 类 Unix 操作系统 和 其他操作系统的软件兼容性。
一般情况下，应用程序通过应用编程接口(API)而不是直接通过系统调用来编程。这点很重要，因为应用程序使用的这种编程接口实际上并不需要和内核 提供的系统调用对应。一个 API 定义了一组应用程序使用的编程接%% %%口。它们可以实现成一个系统调用，也可以通过调用多个系统调用来实现，而完全不使用任何系 统调用也不存在问题。实际上，API 可以在各种不同的操作系统上实现，给应用程序提供完全相同的接口，而它们本身在这些系统上的实现却可能迥异。
在 Unix 世界中，最流行的应用编程接口是基于 POSIX 标准的。从纯技术的角度看，POSIX 是由 IEEE 的一组标准组成，其目标是提供一套大体上基于 Unix 的可移植操作系统标准。Linux 是与 POSIX 兼容的。
POSIX 是说明 API 和系统调用之间关系的一个极好例子。在大多数 Unix 系统上，根据 POSIX 而定义的 API 函数和系统调用之间有着直接关 系。实际上，POSIX 标准就是仿照早期 Unix 系统的界面建立的。另一方面，许多操作系统，像 Windows NT，尽管和 Unix 没有什么关系，也提供了与 POSIX 兼容的库。
Linux 的系统调用像大多数 Unix 系统一样，作为 C 库的一部分提供如图 5-1 所示。如图 5-1 所示 C 库实现了 Unix 系统的主要 API，包括标 准 C 库函数和系统调用。所有的 C 程序都可以使用 C 库，而由于 C 语言本身的特点，其他语言也可以很方便地把它们封装起来使用。此外，C 库提供了 POSIX 的绝大部分 API。</description></item><item><title>PPTP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/PPTP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/PPTP/</guid><description>概述 参考：
Point-to-Point Tunneling Protocol(点对点隧道协议，简称 PPTP) 是一种过时的实现虚拟专用网络的方法。 PPTP 有许多众所周知的安全问题。
Note：pptpd 存在安全隐患，详情可参考这里
PPTP 使用 TCP 控制通道和通用路由封装隧道来封装 PPP 数据包。许多现代 VPN 使用各种形式的 UDP 来实现相同的功能。
Poptop Poptop 是 The PPTP Server for Linux
官方网址：http://poptop.sourceforge.net/
Poptop 的安装 需要 epel 源
yum install pptpd
Poptop 关联文件与配置 /etc/pptpd.conf # pptpd 主程序的主配置文件
localip IP # 当远程客户端连接到本地服务时，服务端建立虚拟网卡所用的 ip
remoteip IP-Range # 远程客户端连接到本地服务后，可以分配的给客户端的 ip 范围
Note：这俩配置完成后，当客户端连接时，就会出现下面虚拟网卡。
4: ppp0: &amp;lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1396 qdisc pfifo_fast state UNKNOWN group default qlen 3 link/ppp inet 192.</description></item><item><title>Program</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Program/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Program/</guid><description>概述 参考：
Wiki, Program Program(程序) 通常是指计算机程序，是供 Computer 执行的编程语言的指令序列或指令集。
人类可读形式的计算机程序称为源代码。源代码需要另一个计算机程序来执行，因为计算机只能执行其本机机器指令。因此，可以使用为该语言编写的编译器将源代码翻译成机器指令。 （汇编语言程序是使用汇编器翻译的。）生成的文件称为可执行文件。或者，源代码可以在为该语言编写的解释器中执行。
Command 参考：
Wiki, Command Command(命令) 是 Program 执行特定任务的指令，是一种抽象的概念。程序本身可以执行多种行为，通过不同的选项控制该程序所执行的行为，由程序和参数组合成的整体，可以看做是命令。若不指定参数，就相当于该命令执行程序默认的行为。</description></item><item><title>PromQL 常见查询语句</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/PromQL-%E5%B8%B8%E8%A7%81%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/PromQL-%E5%B8%B8%E8%A7%81%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/</guid><description>概述 参考：
GitHub 项目，samber/awesome-prometheus-alerts https://samber.github.io/awesome-prometheus-alerts/ 腾讯云+社区，prometheus 告警指标 对 awesome-prometheus-alerts 的无后续维护的搬运 公众号，云原生小白-监控容器 OOMKill 的正确指标 https://panzhongxian.cn/cn/2023/09/grafana-pannel-skills/ Grafana 常用但难配的图表。一些真实场景的查询语句写法以及对应 Grafana 图标如何用 问题 如何获取范围向量中的第一个和最后一个值。 https://stackoverflow.com/questions/68895729/how-to-get-the-first-and-last-element-of-a-range-vector-in-promql
MetricsQL 中有 first_over_time() 函数 如何获取范围向量中，指定的值。 https://stackoverflow.com/questions/45213745/prometheus-how-to-calculate-proportion-of-single-value-over-time ，比如 count_over_time(my_metric[1m] != 0)获取 1 分钟内所有值中不为 0 的值
MetricsQL 中有 count_ne_over_time(my_metric[1h], 0) 函数 SLO/SLI 根据过去一段时间的统计数据监测异常值 参考 Statistics 中的 “检测和处理异常值”，使用 Z-Score 法，通过下面的公式实现
$$ Z-score = \frac{x - \mu}{\sigma} $$
x 是当前值 μ 是总体的 mean(平均值) σ 是总体的 standard deviation(标准差)。 Tips: 这里的 population(总体) 的意思对应到 Prometheus 中就是指 范围向量</description></item><item><title>Python 模块与包</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Python-%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Python-%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85/</guid><description>概述 参考：
官方文档，教程 - 6.模块 GitHub 项目，pypa/packaging.python.org Python 包管理指南 “Python Packaging User Guide”(PyPUG) 旨在成为有关如何使用当前工具在 Python 中打包和安装发行版的权威资源。 Python Packaging Authority 廖雪峰 Python 教程，模块 在计算机程序的开发过程中，随着程序代码越写越多，在一个文件里代码就会越来越长，越来越不容易维护。
为了编写可维护的代码，我们把很多函数分组，分别放到不同的文件里，这样，每个文件包含的代码就相对较少，很多编程语言都采用这种组织代码的方式。在 Python 中，一个 .py 文件就称之为一个 Module(模块)。
假如现在有 a.py 和 b.py，b.py 中有定义了名为 bFun 的函数，现在想要在 a.py 中使用 bFun 函数，则只需要在开始使用 from b import bFun 即可。
使用模块有什么好处？
最大的好处是大大提高了代码的可维护性。其次，编写代码不必从零开始。当一个模块编写完毕，就可以被其他地方引用。我们在编写程序的时候，也经常引用其他模块，包括 Python 内置的模块和来自第三方的模块。
使用模块还可以避免函数名和变量名冲突。相同名字的函数和变量完全可以分别存在不同的模块中，因此，我们自己在编写模块时，不必考虑名字会与其他模块冲突。但是也要注意，尽量不要与内置函数名字冲突。这里可以查看 Python 的所有内置函数。
如果不同的人编写的模块名相同怎么办？
为了避免模块名冲突，Python 又引入了按目录来组织模块的方法，称为 Package(包)。
举个例子，一个 abc.py 的文件就是一个名字叫 abc 的模块，一个 xyz.py 的文件就是一个名字叫xyz的模块。
现在，假设我们的abc和xyz这两个模块名字与其他模块冲突了，于是我们可以通过包来组织模块，避免冲突。方法是选择一个顶层包名，比如mycompany，按照如下目录存放：
mycompany ├─ __init__.py ├─ abc.py └─ xyz.</description></item><item><title>QEMU 设备模拟逻辑</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/QEMU-%E8%AE%BE%E5%A4%87%E6%A8%A1%E6%8B%9F%E9%80%BB%E8%BE%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/QEMU-%E8%AE%BE%E5%A4%87%E6%A8%A1%E6%8B%9F%E9%80%BB%E8%BE%91/</guid><description>概述 参考：
官方文档，系统模拟-设备模拟 QEMU 模拟设备主要是半虚拟化设备，从这里可以看到简单的介绍。
QEMU Storage Emulation(QEMU 存储模拟) 与 网络模拟 类似，QEMU 想要让虚拟机获得一块硬盘，也需要由两部分组成一个完整的存储功能。
front-end(前端) # VM 中的 块设备 back-end(后端) # 宿主机中的与 VM 中模拟出来的块设备进行交互的设备。 QEMU Network Emulation(QEMU 网络模拟) 参考：
https://wiki.qemu.org/Documentation/Networking https://www.qemu.org/docs/master/system/net.html https://www.qemu.org/2018/05/31/nic-parameter/，老版原理，将弃用 QEMU 想要让虚拟机与外界互通，需要由两部分组成一个完整的网络功能：
front-end(前端) # VM 中的 NIC(Network Interface Controller，即人们常说的网卡)。 VM 中的 NIC 是由 QEMU 模拟出来的，在支持 PCI 卡的系统上，通常可以是 e1000 网卡、rtl8139 网卡、virtio-net 设备。 back-end(后端) # 宿主机中的与 VM 中模拟出来的 NIC 进行交互的设备。 back-end 有多种类型可以使用，这些后端可以用于将 VM 连接到真实网络，或连接到另一个 VM TAP# 将 VM 连接到真实网络的标准方法 User mode network stack 效果如图所示： 基本应用示例 在使用 qemu-kvm 命令创建虚拟机时，通过一组两个选项来为虚拟机创建一个网络设备。比如：</description></item><item><title>REPL</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/REPL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/REPL/</guid><description>概述 参考：
Wiki, REPL read–eval–print loop(读取-评估-打印 循环，简称 REPL) 也称为 语言 Shell，是一种简单的交互式编程环境。像 Python、JavaScript、Shell 编程语言、等等，都有一个可以称为 REPL 的可交互的编程环境。该技术非常具有脚本语言的特征。</description></item><item><title>Rules</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Configuration/Rules/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Configuration/Rules/</guid><description>概述 参考:
Prometheus 规则分为两种：
Recording Rule(记录规则) # Alerting Rule(告警规则) # ！！！注意编写告警规则的逻辑，由于 Prometheus 会定期评估告警，所以会定期读取数据，尽相避免读取大范围的数据，以免造成性能问题 Prometheus 规则配置文件需要在 Prometheus Server 配置 文件中的 rule_files 字段中指定，让 Prometheus 加载指定的文件并读取其配置(这个过程称为 Evaluation(评估))。
一个规则封装了一个向量表达式，该向量表达式在指定的时间间隔内进行评估并采取行动（目前要么记录，要么用于报警）。
可以通过发送 SIGHUP 到 Prometheus 进程在运行时重新加载规则文件。仅当所有规则文件格式正确时，才会应用更改。
[!Tip] 规则语法检查 可以使用 promtool 程序在不启动 Prometheus Server 的情况下检查文件中的语法是否正确。.e.g. promtool check rules /path/to/example.rules.yml
Recording Rule(记录规则) 参考：
官方文档，配置 - 记录规则 在我们使用 Prometheus 的过程中，随着时间的推移，存储在 Prometheus 中的监控指标数据越来越多，查询频率也在不断的增加，当我们用 Grafana 添加更多的 Dashboard 的时候，可能会慢慢的体验到 Grafana 已经无法按时渲染图表，并且偶尔还会出现超时的情况，特别是当我们在长时间汇总大量的指标数据的时候，Prometheus 查询超时的情况可能更多了，这时就需要一种能够类似于后排批处理的机制在后台完成这些复杂运算的计算，对于使用者而言只需要查询这些运算结果即可。
当我们有频繁使用的复杂查询时，如果直接将语句写在 Grafana 的 query 中，Grafana 每次刷新都对 Promethus 提交实时查询，会增加 Prometheus 的性能消耗并且降低了响应速度。 这时候我们就可以用到 Recoding rules 了。</description></item><item><title>Shell 编程语言</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Shell-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Shell-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</guid><description>概述 参考：
Wiki, Shell_script Shell Programming Language(shell 编程语言) 不是编译型的语言，而是一种脚本语言，通常称为 Shell script。
在类 Unix 系统中，我们最常使用的就是 Bash，通常 Shell 编程语言狭义上直接指的是 Bash 编程语言。
而在 Microsoft 系统中，早期是一种 Batch file(批处理) 文件，然后发展出 CMD，到近代可以使用 PowerShell 脚本语言。
Shell 的基本结构与要素 Shell 语言的运行环境依赖于其所使用的 shell，是 bash、sh 还是 zsh 等等。想要执行 shell 语言，并不需要下载一个编译器，直接在指定的 shell 中执行代码即可。
脚本式的语言是编写完代码之后，一条一条执行，所以可以把平时在 Linux 上操作的 Bash Shell 想象成一个大型的文本编辑器，每输入一条命令，就相当于一行代码，直接通过这个 Bash 的 shell 就执行了，而把很多命令组合起来，放在一个文件里，直接运行该文件，与在界面输入很多内容，有异曲同工之妙。
由于 Shell 语言不需要编译器，所以 Shell 代码的第一行，必须指定其内的代码使用什么 Shell 来运行。
Hello World #!/bin/bash # 告诉内该脚本用什么shell运行，必须是脚本第一行 printf &amp;#39;Hello World!&amp;#39; 其实如果是在某个系统下运行代码，第一行也是可以省略的，第一行的意思其实就是代表运行后续命令的环境，而第一行其实也是调用系统 /bin/ 目录下的 bash 二进制文件，来执行后续的代码。</description></item><item><title>Stages(阶段) 详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Pipeline/Stages%E9%98%B6%E6%AE%B5-%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Pipeline/Stages%E9%98%B6%E6%AE%B5-%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，发送数据 - Promtail - 阶段 官方文档，发送数据 - Promtail - 配置 - pipelinie_stages 对于 Stages 的详解，需要配合配置文件来描述。所以，本篇笔记既是 Stages 详解，也是 Promtail 配置 文件中 pipeline_stages 字段的详解。
pipeline_stages 字段配置 pipeline_stages 字段用于配置转换日志条目及其标签。Promtail 工作流程中的 日志发现 步骤完成后，将执行 pipeline。
在大多数情况下，可以使用 regex 或 json 阶段从日志中提取数据。提取的数据将转换为临时 map 对象。这些提取出来的数据可以被 promtail 使用(比如这些数据可以作为标签的值或作为 i 内容直接输出)。此外，除 docker 和 cri 之外的任何其他阶段都可以访问提取的数据。
scrape_configs: - pipeline_stages: - docker: {} - cri: {} - regex: ... - json: .... ...... 阶段太多，其余略 Parsing stages(解析阶段) docker - 根据标准的 docker 日志文件格式来解析每行日志，并提取数据(默认行为) 来自 docker 的每行日志，都是以 JSON 格式编写，该 JSON 格式中有下列几个 key：</description></item><item><title>Util-linux Utilities</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Util-linux-Utilities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Util-linux-Utilities/</guid><description>概述 参考：
GitHub 项目，util-linux/util-linux Wiki, Util-linux util-linux 是由 Linux 内核组织分发的标准软件包，用作 Linux 操作系统的一部分。一个分支 util-linux-ng（ng 的意思是“下一代”）是在开发停滞时创建的，但截至 2011 年 1 月，它已重命名为 util-linux，并且是该软件包的正式版本。
可以在 这里 找到 Util-linux 包中通常包含的所有程序。这些程序可以分为几大类
Namespace 管理，包括 unshare, nsenter, lsns, etc. 。详见 容器运行时管理 etc. 还有一部分已经弃用的程序可以在这里找到列表</description></item><item><title>WebDriver</title><link>https://desistdaydream.github.io/docs/Web/Browser-automation/WebDriver/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser-automation/WebDriver/</guid><description>概述 参考：
MDN，WebDriver WebDriver 是远程控制接口，可以对 User-Agent(用户代理) 进行控制。它提供了一个平台和语言中立的协议，作为浏览器自身进程外的程序远程控制 web 浏览器行为的方法。
WebDriver 符合 W3C 标准。
https://www.w3.org/TR/webdriver1/ 2018 年标准 https://www.w3.org/TR/webdriver2/ 2023 年草案 ChromeDriver 参考：
官网 ChromeDriver 是一个开源项目，由 Chrome 开发团队开发和维护。它是 Chrome 浏览器的一个驱动程序，用于自动化控制和与 Google Chrome 浏览器进行交互。ChromeDriver 允许开发人员使用编程语言（如 Python、Java、C# 等）编写脚本，以控制 Chrome 浏览器的行为。
在 Windows 可以直接下载一个 chromedriver.exe 文件，即可与 Python 库对接，由 Python 控制浏览器。
如果想使用 浏览器自动化程序（e.g. Selenium） 来模拟用户在浏览器中的各种操作，包括但不限于点击、复制、填写等，那么 ChromeDriver 就是 Chrome 浏览器与 Selenium 进行通信的载体之一
Selenium 是一个用于 Web 应用程序测试的工具。它可以直接运行在浏览器中，模拟用户在浏览器中的各种操作，包括但不限于点击、复制、填写等。Selenium 支持市场上所有主流浏览器的自动化，包括 Chrome、Firefox、Safari 等]
Selenium 通过使用 WebDriver 支持市场上所有主流浏览器的自动化。WebDriver 是一个 API 和协议，它定义了一个语言中立的接口，用于控制 web 浏览器的行为。每个浏览器都有一个特定的 WebDriver 实现，称为驱动程序。驱动程序是负责委派给浏览器的组件，并处理与 Selenium 和浏览器之间的通信。这种分离是有意识地努力让浏览器供应商为其浏览器的实现负责的一部分。Selenium 在可能的情况下使用这些第三方驱动程序，但是在这些驱动程序不存在的情况下，它也提供了由项目自己维护的驱动程序。</description></item><item><title>X.509</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/X.509/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/X.509/</guid><description>概述 参考：
Wiki, X.509 RFC 5280, Internet X.509 PKI 证书和 CRL 配置文件 RFC 6125, 在 TLS 场景下，使用 PKIX(在 PKI 中使用 X.509)，对基于域的应用服务进行表示与验证 Arthurchiao 博客，[译] 写给工程师：关于证书（certificate）和公钥基础设施（PKI）的一切（SmallStep, 2018） X.509 是 Cryptography 里定义公钥证书格式的标准。X.509 格式的证书已应用在包括 TSL/SSL 在内的众多网络协议里，它是 HTTPS 的基础。
在大部分时候，人们提到证书而没有加额外的限定词时，通常都是指 X.509 v3 证书。
更准确的说，是 RFC 5280 中描述、 CA/Browser Forum Baseline Requirements中进一步完善的 PKIX 变种。 也可以说，指的是浏览器理解并用来做 HTTPS 的那些证书。 也是那些具有通过 HTTP + TLS 协议交互的程序们所使用的证书 当然，全世界并不是只有 X.509 这一种格式，SSH 和 PGP 都有其各自的格式。
X.509 在 1988 年作为 ITU(国际电信联盟) X.500 项目的一部分首次标准化。 这是 telecom(通信) 领域的标准，想通过它构建一个 global telephone book(全球电话簿)。 虽然这个项目没有成功，但却留下了一些遗产，X.</description></item><item><title>编程范式</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/</guid><description>概述 参考：
Wiki 分类，Programming paradigms(编程范式) 下面这种你属于什么分类？
Scripting language(脚本语言) https://en.wikipedia.org/wiki/Scripting_language Compiled language(编译语言) https://en.wikipedia.org/wiki/Compiled_language 常见编程的非国际定义的标准 为什么那么多公司做前后端分离项目后端响应的 HTTP 状态一律 200？
用于区分内网错误还是外网错误 400、500 被运营商劫持跳转到其他链接 etc. 编程规范 参考：
无法忍受不做单元测试和内卷，我离开了这家在美中国企业 Method Stub 参考：
Wiki, Method stub 在软件开发中，Method stub(方法存根) 是一段代码，用于代替某些其他编程功能</description></item><item><title>常用英文</title><link>https://desistdaydream.github.io/docs/Standard/%E5%B8%B8%E7%94%A8%E8%8B%B1%E6%96%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/%E5%B8%B8%E7%94%A8%E8%8B%B1%E6%96%87/</guid><description>概述 参考：
B 站，TED中字：如何在3个月内学会任何外语并且永远不会忘记?
https://www.bilibili.com/read/cv7989082/
https://zhuanlan.zhihu.com/p/364365898
具有多个发音的字母:
a、e c、g、x、y c 在单词里总共存在四种可能的读音，包括 /k/、/s/、/ʃ/ 和 /tʃ/。
发 /k/ 音 当字母c位于词尾 当字母c位于词首或词中时 如果后跟辅音字母或者元音字母 a, o, u 其中的一个，没有例外。 发 /s/ 音 当字母c位于词首或词中时 如果后跟元音字母 y，没有例外 当字母c的后面只有一个元音字母，它或者是 e 或者是 i，再之后就是辅音字母或者什么都没有了（也就是单词结束了）。 tion, sion, cian 发 /ʃ(ə)n/
I fear your lust for power could get the better of you. You are a hero, not a politician.
编程 英文 中文 缩写 说明 Implementation 实现 impl Go 编程语言中用于表示实现了某个接口的结构体。Implement, Implementing SUITE 复数为 suites，在计算机领域翻译为程序组。通常用于描述一个程序的执行单元。suite 可能是一个函数或者一个脚本，它包含了一系列的语句，这些语句通常在一个缩进的代码块中，这个代码块的开始和结束都使用了相同的缩进级别 Compile 编译 Compiler 编译器 Bundle 打包 常见于前端，与后端编译不同，前端通常是将多个文件打包成一个文件，所以使用 Bundle 而不是 Compile Bundler 打包器 常见缩写 英文 中文 缩写 Business 业务 BIZ Management 管理 MGMT Protocol 协议 符号的英语名称 参考：</description></item><item><title>负载均衡</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Load-balancing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Load-balancing/</guid><description>概述 参考：
Wiki, Load balancing https://www.cnblogs.com/tianyamoon/p/9410697.html Load balancing(负载均衡) 是一种计算机技术，将一组任务分配给一组资源（计算单元）的过程，目的是提高其整体处理效率。
一，什么是负载均衡（Load balancing） 在网站创立初期，我们一般都使用单台机器对台提供集中式服务，但是随着业务量越来越大，无论是性能上还是稳定性上都有了更大的挑战。这时候我们就会想到通过扩容的方式来提供更好的服务。
我们一般会把多台机器组成一个集群对外提供服务。然而，我们的网站对外提供的访问入口都是一个的，比如 www.taobao.com。那么当用户在浏览器输入www.taobao.com的时候如何将用户的请求分发到集群中不同的机器上呢，这就是负载均衡在做的事情。
二，负载均衡按网络七层模型分类 现在我们知道，负载均衡就是一种计算机网络技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁碟驱动器或其他资源中分配负载，以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。那么，这种计算机技术的实现方式有多种。大致可以分为以下几种，其中最常用的是四层和七层负载均衡：
二层负载均衡 负载均衡服务器对外依然提供一个 VIP（虚 IP），集群中不同的机器采用相同 IP 地址，但是机器的 MAC 地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标 MAC 地址的方式将请求转发到目标机器实现负载均衡。 三层负载均衡 和二层负载均衡类似，负载均衡服务器对外依然提供一个 VIP（虚 IP），但是集群中不同的机器采用不同的 IP 地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过 IP 将请求转发至不同的真实服务器。 四层负载均衡：TCP 层的 Load Balance,转发请求 四层负载均衡工作在 OSI 模型的传输层，由于在传输层，只有 TCP/UDP 协议，这两种协议中除了包含源 IP、目标 IP 以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。 应用场景：对于用户请求一个网站的图片，会根据用户请求中 URL 的地址:端口，转发到后端的服务器上，再由后端服务器处理该请求，这时候要求运维人员记住用户请求图片所在的服务器是哪台 七层负载均衡：HTTP 协议层的反向代理，代理请求 七层负载均衡工作在 OSI 模型的应用层，应用层协议较多，常用 http、radius、dns 等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个 Web 服务器的负载均衡，除了根据 IP 加端口进行负载外，还可根据七层的 URL、浏览器类别、语言来决定是否要进行负载均衡。 应用场景：对于用户请求一个网站的图片，会根据用户请求的 URL 来代理用户的该请求，重新构建请求报文，根据自身的缓存规则，比如一致性哈希算法，找到该图片的位置，然后把请求发送给该设备。 对于一般的应用来说，有了 Nginx 就够了。Nginx 可以用于七层负载均衡。但是对于一些大的网站，一般会采用 DNS+四层负载+七层负载的方式进行多层次负载均衡。
三、四层、七层负载均衡对比 所谓四层即运输层，就是基于 IP + 端口的负载均衡；七层即应用层，就是基于 URL 等应用层信息的负载均衡；</description></item><item><title>扩大 KVM 虚拟机 image 镜像</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E6%89%A9%E5%A4%A7-KVM-%E8%99%9A%E6%8B%9F%E6%9C%BA-image-%E9%95%9C%E5%83%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E6%89%A9%E5%A4%A7-KVM-%E8%99%9A%E6%8B%9F%E6%9C%BA-image-%E9%95%9C%E5%83%8F/</guid><description>概述 直接使用 qemu-img resize 的时候一定要先备份镜像。先使用 virsh shutdown VM 关闭镜像再进行如下操作：
给原始系统文件添加磁盘空间 qemu-img resize centos7-baseImage-50G.qcow2 +500G 进入虚拟机操作新建硬盘分区 parted /dev/vda mkpart primary XXX 100%(XX 改为指定的最后一块扇区的容量) 扩容 LVM，注意/dev/vda4 设备为真实情况的设备名称，注意修改 partprobe(可能还需要重启) pvcreate /dev/vda4 vgextend vg0 /dev/vda4 lvextend -l+100%FREE /dev/mapper/vg0-root 这里可以使用 lvextend -l +单元数量 /dev/mapper/vg0-lv101 扩展文件系统大小，注意 /dev/mapper/vg0-root 修改为真实情况的分区路径 XFS 文件系统 xfs_growfs /dev/mapper/vg0-root EXT 文件系统 resize2fs /dev/mapper/vg0-root (-f 强制扩展)</description></item><item><title>写作</title><link>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/%E5%86%99%E4%BD%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/%E5%86%99%E4%BD%9C/</guid><description>概述 参考
GitHub 项目，ruanyf/document-style-guide中文技术文档写作规范 写作技巧 原文链接: https://mp.weixin.qq.com/s/I38Wr-CGEbaMrT-xj3QZ8A
技术写作的价值 写作并不是一件轻松的事情，特别是技术内容创作，它不仅需要兴趣来驱动，而且需要耐心，所以写作这个活动注定不适合所有人。我想无论是写作、演讲，还是录制视频，除了利益驱动无可厚非之外，大家肯定都有一个额外的共同目的：分享。
至于分享之后为了得到什么，那都不重要，比如我就是为了满足自己的虚荣心，说白了就是装 x，看着自己的文章被越来越多的人阅读，越来越多的人认识我，加我微信好友的人越来越多，自己在圈内越来越出名，虚荣心得到了极大的满足。既满足了自己的虚荣心，又造福了广大读者，有何不可呢？
除了我说的这些，写作还有没有其他价值呢？还是拿我亲身经历举例子，我的一部分文章给我带来了全新的工作机会；还有一部分文章吸引了很多社区和团队的目光，主动来和我合作；所有的这一切让我结识了更多志同道合的朋友；当然，获取到大量关注后也给我带来了更多的收入，这个不必避讳。
写作工具 工欲善其事，必先利其器。既然决定了进入“写作”这个战场，首当其冲的就是选一件称手的兵器，对于写作来说，这个兵器就是“写作工具”。选工具之前，先要明确一下自己偏好的排版格式，目前有两种主流的排版格式：
富文本：富文本格式（Rich Text Format, 一般简称为 RTF）是由微软公司开发的跨平台文档格式。最大的特点是：所见即所得，你把格式调整成什么样子，就会直接显示出什么样的效果。这一点和 Word 类似。目前微信公众号文章就是通过富文本来编辑的。 Markdown：Markdown 是一种轻量的标记语法，你可以理解为一种伪编程语言，和 HTML 有点像，只不过是专门为写作准备的极简格式。Markdown 的语法很简单，只有一些简单的符号，我们只需学习这几个简单的符号，然后插入到写作内容中，不用关心排版。 程序员大多都不喜欢使用 Word 这类富文本编辑器，因为不可控因素太多，各种形式、用法和风格，而且花样繁多，强依赖于编辑器，换个编辑器用法又不一样了。
众望所归的选择还是 Markdown，排版都是可复制的，文字的排版只是多打几个符号而已，最终产出的只是一个纯文本，非常利于传播和迁移。所以 Markdown 才是程序员的最爱。
目前市面上比较流行的 Markdown 编辑器琳琅满目，本文也无法为大家一一介绍，这里只推荐几个我认为最最最优秀的。
Obsidian Obsidian 是一个支持双向链接的笔记管理软件，但我们用它来写 Markdown 是极好的！Obsidian 最新版本也实现了即时预览功能，只需在编辑器设置中将默认的编辑模式改为即时预览即可。
可以看到其实时预览功能目前还有一些小缺陷，比如引用的样式渲染不太理想，不过后续这些问题都会被修复的，现在只是开始。
Obsidian
Typora https://www.typora.io/
Typora 最吸引人的特性就是它的即时渲染，也就是所谓的所见即所得。一般的 Markdown 编辑器都分为编辑栏和预览栏，Typora 将其合二为一，实时预览，只要你敲入相应的标记符号就立马为你转换为对应的样式，就像写 Word 一样流畅自如。这是本文在 Typora 中的排版样式：
遗憾的是 Typora 目前已经开始收费，但这是合理的，之前 Typora 发布的都是测试版，免费供大家使用，现在正式版开始取消免费，毕竟开发也需要付出，我们要尊重开发者，优质的产品值得付费。我们可以选择不用 Typora，但不必对其收费行为冷嘲热讽。
Typedown Typora 平替，微软商店可直接安装
https://apps.microsoft.com/store/detail/typedown-%E8%BD%BB%E9%87%8F%E7%BA%A7-markdown-%E7%BC%96%E8%BE%91%E5%99%A8/9P8TCW4H2HB4
VS Code VS Code 虽然是一个代码编辑器，但由于它的功能过于强大，插件过于丰富，扩展性极强，所以人们也常常用它来写作。</description></item><item><title>信息检索</title><link>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/</guid><description>概述 参考：
B 站，超级搜索技术，普通人变强的唯一外挂 | 全套宝藏实操秘技 Google https://kinsta.com/blog/google-search-operators/
https://www.google.com/support/enterprise/static/gsa/docs/admin/70/admin_console_help/serve_query_expansion.html
https://support.google.com/websearch/answer/2466433?hl=en
搜索运算符 &amp;quot;&amp;quot; # 限定关键词 intitle # 限定标题 allintitle # 限定标题多个关键字 intext # 限定内容关键词 inurl # 限定网址关键词 site # 限定网址来源 imagesize # 限定图片尺寸 filetype # 限定文件格式</description></item><item><title>指令集架构</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/%E6%8C%87%E4%BB%A4%E9%9B%86%E6%9E%B6%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/%E6%8C%87%E4%BB%A4%E9%9B%86%E6%9E%B6%E6%9E%84/</guid><description>概述 参考：
Wiki, InstructionSetArchitecture(指令集架构) https://picture.iczhiku.com/weixin/message1583925567196.html https://a-suozhang.xyz/2019/09/27/ISA/ Instruction set architecture(指令集架构，简称 ISA) 是软件和硬件之间的接口，是一套标准规范，并不具备实体，我们可以根据这套规范去设计 CPU 和对应的软件系统，并最终形成产品。
执行 ISA 描述中的指令的设备，称为 implementation(实现)，实现这个功能的设备，通常都是 CPU。
常见的指令集如：
AMD(X86_64) ARM RISC-V 等 如果把软件和硬件看成螺母和螺钉，那么 ISA 就是螺母和螺钉之间对接的规范(e.g.尺寸、螺纹 之类的)。螺母和螺钉都按照相同的尺寸(i.e.相同的规范)去设计，即使是由不同的厂商来生产，也可以保证最终所有的螺钉都能拧到螺母上。
指令集向上承载的是整个软件生态，向下则规范了以处理器芯片为代表的整个硬件生态。根据一份指令集规范，设计一款处理器，其上可以运行同样遵循该指令集规范所编写的软件代码。故而，我们在提到指令集的时候，有时候也指的是其背后的整个软硬件生态系统，包括外围芯片、操作系统、编译器和诸多应用软件（浏览器、游戏软件等）。事实证明，每一种芯片在市场竞争中要取得成功，很大程度上取决于其生态系统。
指令 &amp;amp; 指令集 &amp;amp; 指令集架构 历史 B 站，【差评】乐疯了：为什么美国想用RISC-V搞死中国，是本年度最大的笑话。。。
RISC 与 CISC 参考:
Wiki, Complex instruction set computer Wiki, Reduced instruction set computer Complex instruction set computer(复杂指令集计算机，简称 CISC)
Reduced instruction set computer(精简指令集极端及，简称 RISC)</description></item><item><title>Alertmanager 数据结构</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid><description>概述 参考：
官方文档，告警 - 客户端(接收告警的数据结构) AlertManager 接收告警的数据结构 这个数据结构，其实就是 Prometheus 推送告警的数据结构，详见 Prometheus Alerting 章节
[ { &amp;#34;labels&amp;#34;: { &amp;#34;alertname&amp;#34;: &amp;#34;&amp;lt;requiredAlertName&amp;gt;&amp;#34;, &amp;#34;&amp;lt;labelname&amp;gt;&amp;#34;: &amp;#34;&amp;lt;labelvalue&amp;gt;&amp;#34;, ... }, &amp;#34;annotations&amp;#34;: { &amp;#34;&amp;lt;labelname&amp;gt;&amp;#34;: &amp;#34;&amp;lt;labelvalue&amp;gt;&amp;#34;, }, &amp;#34;startsAt&amp;#34;: &amp;#34;&amp;lt;rfc3339&amp;gt;&amp;#34;, &amp;#34;endsAt&amp;#34;: &amp;#34;&amp;lt;rfc3339&amp;gt;&amp;#34;, &amp;#34;generatorURL&amp;#34;: &amp;#34;&amp;lt;generator_url&amp;gt;&amp;#34; }, ... ] Alertmanager 通过 Webhook 推送告警的数据结构 参考:
官方文档，告警 - 配置 - webhook_config(通过 Webhook 推送告警的数据结构) 下面就是 Alertmanager 在 Webhook 配置中，以 POST 请求发送的 JSON 结构的数据格式：
{ &amp;#34;version&amp;#34;: &amp;#34;4&amp;#34;, &amp;#34;groupKey&amp;#34;: &amp;lt;string&amp;gt;, // key identifying the group of alerts (e.</description></item><item><title>Android 开发</title><link>https://desistdaydream.github.io/docs/Mobile-device/Android-%E5%BC%80%E5%8F%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Mobile-device/Android-%E5%BC%80%E5%8F%91/</guid><description>概述 参考：
安卓开发者资源 AOSP https://source.android.com/
Android Open Source Project(安卓开源项目，简称 AOSP) 提供了创建 Android 操作系统的自定义变体、将设备和配件移植到 Android 平台所需的信息和源代码，并确保设备满足兼容性要求，从而保持 Android 生态系统的健康。为数百万用户提供健康稳定的环境。
Android Studio Andriid Studio(安卓工作室) 是一款用于 Android 应用程序开发的官方 Integrated Development Environment(集成开发环境，简称 IDE)，包含代码编辑器、构建工具、签名工具、SDK 工具等。
SDK 工具 参考：
官方文档，SDK 工具 ADB 详见 ADB
最佳实践 获取 Root 权限 Magisk GitHub 项目，topjohnwu/Magisk
https://github.com/topjohnwu/Magisk/ 对应用隐藏 Root 信息
其他 使用 Magisk 的模块为系统添加 CA 证书
https://github.com/NVISOsecurity/MagiskTrustUserCerts 2 年没更新了 https://github.com/nccgroup/ConscryptTrustUserCerts # 适用于 andriod 14 ？ https://github.com/nccgroup/ConscryptTrustUserCerts/issues/3 有了下面那个仓库 https://github.com/lupohan44/TrustUserCertificates</description></item><item><title>BGP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/BGP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/BGP/</guid><description>概述 参考：
Border Gateway Protocol(边界网关协议，简称 BFP) 是一个 Linux 内核原生就支持的、专门用在大规模数据中心里维护不同的“自治系统”之间路由信息的、无中心的路由协议。
在这个图中，我们有两个自治系统（Autonomous System，简称为 AS）：AS 1 和 AS 2。而所谓的一个自治系统，指的是一个组织管辖下的所有 IP 网络和路由器的全体。你可以把它想象成一个小公司里的所有主机和路由器。在正常情况下，自治系统之间不会有任何“来往”。
但是，如果这样两个自治系统里的主机，要通过 IP 地址直接进行通信，我们就必须使用路由器把这两个自治系统连接起来。
比如，AS 1 里面的主机 10.10.0.2，要访问 AS 2 里面的主机 172.17.0.3 的话。它发出的 IP 包，就会先到达自治系统 AS 1 上的路由器 Router 1。
而在此时，Router 1 的路由表里，有这样一条规则，即：目的地址是 172.17.0.2 包，应该经过 Router 1 的 C 接口，发往网关 Router 2（即：自治系统 AS 2 上的路由器）。
所以 IP 包就会到达 Router 2 上，然后经过 Router 2 的路由表，从 B 接口出来到达目的主机 172.17.0.3。
但是反过来，如果主机 172.17.0.3 要访问 10.10.0.2，那么这个 IP 包，在到达 Router 2 之后，就不知道该去哪儿了。因为在 Router 2 的路由表里，并没有关于 AS 1 自治系统的任何路由规则。</description></item><item><title>C 规范与标准库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/C-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/C-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</guid><description>概述 参考：
位移运算符 可以在 Linux 网络设备 中对 /sys/class/net/${NetDeviceName}/flags 文件含义的解释，找到位移运算的典型示例
1&amp;lt;&amp;lt;0、1&amp;lt;&amp;lt;1 等是位移运算符的表达方式，在许多编程语言（如 C、C++、Go、Python 等）中都有使用。它们表示“位移”操作，这个位移操作需要先将 1 转为 二进制，然后让所有数字向左移动指定的位数，移动后空的位置用 0 补齐。
1&amp;lt;&amp;lt;0 表示将 1 （i.e. 二进制 1）向左移动 0 位，仍然是 1。 1&amp;lt;&amp;lt;1 表示将 1 （i.e. 二进制 1）向左移动 1 位，结果是 10，值为 2。 1&amp;lt;&amp;lt;2 表示将 1 （i.e. 二进制 1）向左移动 2 位，结果是 100，值为 4。 3&amp;lt;&amp;lt;2 表示将 3 （i.e. 二进制 11）向左移动 2 位，结果是 1100，值为 12 位移的用途 利用数字 1 进行位移运算的这种位移操作，通常用于设置标志位。通过将特定位设置为 1 或 0，可以高效地表示多个布尔值（true/false）信息，i.e. 高效设置、存储和处理多个状态标志，尤其是在底层代码和系统编程中广泛使用。它在提高代码效率、节省存储空间、简化状态管理方面非常有用。
位掩码（Bitmask）操作：可以用来对一组位进行操作，常见于标志位的组合使用。通过设置、清除或检测某些位，代码可以很高效地处理多个状态。 高效存储：用一组位来表示多个布尔值时，比使用单独的变量更节省内存。一个整数可以用 32 位或 64 位来存储多种状态。 按位操作：可以方便地进行某些特定的操作，比如对位进行取反、与、或等运算，从而控制状态位或进行权限管理等。 例如：</description></item><item><title>Capabilities(能力) 管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Capabilities%E8%83%BD%E5%8A%9B-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Capabilities%E8%83%BD%E5%8A%9B-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
阳明博客,在 Kubernets 中配置 Container Capabilities Linux Capabilities 要了解 Linux Capabilities，这就得从 Linux 的权限控制发展来说明。在 Linux 2.2 版本之前，当内核对进程进行权限验证的时候，Linux 将进程划分为两类：特权进程（UID=0，也就是超级用户）和非特权进程（UID!=0），特权进程拥有所有的内核权限，而非特权进程则根据进程凭证（effective UID, effective GID，supplementary group 等）进行权限检查。
比如我们以常用的 passwd 命令为例，修改用户密码需要具有 root 权限，而普通用户是没有这个权限的。但是实际上普通用户又可以修改自己的密码，这是怎么回事呢？在 Linux 的权限控制机制中，有一类比较特殊的权限设置，比如 SUID(Set User ID on execution)，允许用户以可执行文件的 owner 的权限来运行可执行文件。因为程序文件 /bin/passwd 被设置了 SUID 标识，所以普通用户在执行 passwd 命令时，进程是以 passwd 的所有者，也就是 root 用户的身份运行，从而就可以修改密码了。
但是使用 SUID 却带来了新的安全隐患，当我们运行设置了 SUID 的命令时，通常只是需要很小一部分的特权，但是 SUID 却给了它 root 具有的全部权限，一旦 被设置了 SUID 的命令出现漏洞，是不是就很容易被利用了。
为此 Linux 引入了 Capabilities 机制来对 root 权限进行了更加细粒度的控制，实现按需进行授权，这样就大大减小了系统的安全隐患。
什么是 Capabilities 从内核 2.2 开始，Linux 将传统上与超级用户 root 关联的特权划分为不同的单元，称为 capabilites。Capabilites 每个单元都可以独立启用和禁用。这样当系统在作权限检查的时候就变成了：在执行特权操作时，如果进程的有效身份不是 root，就去检查是否具有该特权操作所对应的 capabilites，并以此决定是否可以进行该特权操作。比如如果我们要设置系统时间，就得具有 CAP_SYS_TIME 这个 capabilites。下面是从 capabilities man page 中摘取的 capabilites 列表：</description></item><item><title>Chrome</title><link>https://desistdaydream.github.io/docs/Web/Browser/Chrome/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser/Chrome/</guid><description>概述 参考：
官网 Chrome
Headless 模式 https://developer.chrome.com/docs/chromium/new-headless
https://developer.chrome.com/blog/headless-chrome
https://chromium.googlesource.com/chromium/src/+/lkgr/headless/README.md
Headless Chrome 是 Chrome 浏览器的无界面形态，可以在不打开浏览器的前提下，使用所有 Chrome 支持的特性运行你的程序。相比于现代浏览器，Headless Chrome 更加方便测试 web 应用，获得网站的截图，做爬虫抓取信息等。相比于出道较早的 PhantomJS，SlimerJS 等，Headless Chrome 则更加贴近浏览器环境。
Chrome 关联文件与配置 %LOCALAPPDATA%/Google/Chrome/ # 数据存储目录
./User Data/ # 用户数据目录。可以通过 &amp;ndash;user-data-dir 标志指定其他路径。 ./Default/ # 默认用户数据存储目录 ./Profile X/ # 其他用户数据存储目录，X 是从 1 开始正整数。 配置详解 命令行参数
&amp;ndash;user-data-dir(STRING) # 用户数据目录。 Windows 默认值: %LOCALAPPDATA%/Google/Chrome/User Data/ 注意：这个并不是某个具体用户的数据目录，而是整个 Chrome 运行时，所有用户的数据保存目录。 在该目录下有 Default、Profile X 这些目录，这些是具体到某个用户的数据保存路径。 &amp;ndash;profile-directory(STRING) # 特定于某个具体用户的数据目录。 Windows 默认值: Default 注意：这个值并不需要填写绝对路径。只需要填写相对路径，该选项的值是 &amp;ndash;user-data-dir 配置的目录的子目录。 &amp;ndash;remote-debugging-port(INT) # 开启 debug 端口，可以通过其他程序连接浏览器。 插件推荐 GitHub 项目，FelisCatus/SwitchyOmega # 快速切换浏览器要使用的代理</description></item><item><title>compose CLI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/compose-CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/compose-CLI/</guid><description>概述 参考：
官方文档 通过 run 命令，可以在容器启动失败时，进行调试
docker-compose -f docker-compose-backup.yaml run keepalived bash
这样会启动 keepalived 容器，并分配一个终端。</description></item><item><title>Docker Configuration</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Configuration/</guid><description>概述 参考：
官方文档，参考 - 命令行参考 - Daemon CLI https://blog.csdn.net/u013948858/article/details/79974796 Docker 的守护进程为 dockerd，dockerd 可以通过两种方式配置运行时行为
/etc/docker/daemon.json 配置文件 dockerd 命令的 flags ，可以将 flags 添加到 dockerd.service 中。 [!Note] 配置文件中的配置，也可以通过 dockerd 的命令行参数(也就是 flags)指定，比如配置文件中的 data-root 字段，对应的 dockerd flags 为 &amp;ndash;data-root
配置文件示例 dockerd 配置文件是 JSON 格式，基本常用的配置内容如下。
{ // 指定 docker pull 时，首先去连接的 registry。 &amp;#34;registry-mirrors&amp;#34;: [ &amp;#34;http://172.38.40.180&amp;#34;, &amp;#34;https://ac1rmo5p.mirror.aliyuncs.com&amp;#34; ], // 指定运行 docker 操作的不安全的 registry 的列表 &amp;#34;insecure-registries&amp;#34;: [&amp;#34;http://172.38.40.180&amp;#34;], // 指定 docker 运行时其他的选项，这里面指定 docker 的 cgroupdriver 为 systemd &amp;#34;exec-opts&amp;#34;: [&amp;#34;native.cgroupdriver=systemd&amp;#34;], // 指定 docker 的日志驱动为 json-file &amp;#34;log-driver&amp;#34;: &amp;#34;json-file&amp;#34;, // 指定 docker 记录容器日志的参数，这里指定容器日志文件大小最大为100m &amp;#34;log-opts&amp;#34;: { &amp;#34;max-size&amp;#34;: &amp;#34;100m&amp;#34; }, // 指定 docker 的存储驱动类型为 overlay2 &amp;#34;storage-driver&amp;#34;: &amp;#34;overlay2&amp;#34;, // 指定 docker 存储驱动的其他选项 &amp;#34;storage-opts&amp;#34;: [&amp;#34;overlay2.</description></item><item><title>DPI</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/DPI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/DPI/</guid><description>概述 参考：
Wiki, Deep packet inspection Deep packet inspection(深度数据包检测，简称 DPI) 是一种用于 Network analysis(网络分析) 的 行为、技术、方法，它详细检查计算机网络上传输的数据包，并可能根据情况采取 发送警报、阻止数据包传输、重新路由、记录(或者说镜像)流量 等行动。DPI 的这些功能通常用于 确定应用程序行为基线、分析网络使用情况、排除网络性能故障、确保数据格式正确、检查恶意代码、窃听和互联网审查、以及其他目的。
可以通过 软件、硬件、软硬结合 多种方式实现 DPI。
支持 DPI 的设备或程序能够查看 OSI 模型的第 2 层和第 3 层以外的情况。在某些情况下，可以调用 DPI 来查看 OSI 模型的第 2-7 层。这包括标头和数据协议结构以及消息的有效负载。当设备根据 OSI 模型第 3 层之外的信息查找或采取其他操作时，将调用 DPI 功能。 DPI 可以识别的数据包特征又很多：
协议 HTTP 请求类型 数据包中的数据特征 etc. IP数据包有多个报头；网络设备只需要使用其中第一个（IP 标头）即可正常操作，但使用第二个标头（例如 TCP 或 UDP）通常被认为是 Stateful packet inspection(浅层数据包检查)（通常称为状态数据包检查）
用白话说：DPI 不是一种特定的技术或协议，而是一种处理流量的方式。
DPI 始于 20 世纪 90 年代。早期的 DPI 实现有：
RMON Sniffer Wireshark etc.</description></item><item><title>events 模块指令</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/events-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/events-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</guid><description>概述 指令详解 worker_connections NUMBER; # worker 进程最大并发连接数
默认值：worker_connections 512;</description></item><item><title>FHS(文件系统层次标准)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/FHS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1%E6%A0%87%E5%87%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/FHS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1%E6%A0%87%E5%87%86/</guid><description>概述 参考：
Linux 基金会参考标准,文件系统层次标准 Wiki, FHS Filesystem Hierarchy Standard(文件系统层次标准，简称 FHS) 为文件系统的每个区域指定指导原则，指定所需的最少文件和目录
该标准使：
用于预测已安装文件和目录位置的软件 用户预测已安装文件和目录的位置。 我们这样做：
为文件系统的每个区域指定指导原则， 指定所需的最少文件和目录， 列举原则的例外情况，以及 列举发生历史冲突的具体案例。 FHS 文件用于：
独立软件供应商创建符合 FHS 的应用程序，并与符合 FHS 的发行版合作， 操作系统创建者提供符合 FHS 的系统，以及 用户了解并维护系统的 FHS 合规性。 FHS 文件的范围有限：
本地文件的本地放置是本地问题，因此 FHS 不会试图篡夺系统管理员。 FHS 解决了需要在多方（例如本地站点、发行版、应用程序、文档等）之间协调文件放置的问题。 Unix 目录结构的来历 Unix（包含 Linux）的初学者，常常会很困惑，不明白目录结构的含义何在。 举例来说，根目录下面有一个子目录 /bin，用于存放二进制程序。但是，/usr 子目录下面还有 /usr/bin，以及 /usr/local/bin，也用于存放二进制程序；某些系统甚至还有 /opt/bin。它们有何区别？
长久以来，我也感到很费解，不明白为什么这样设计。像大多数人一样，我只是根据《Unix 文件系统结构标准》（Filesystem Hierarchy Standard），死记硬背不同目录的区别。
昨天，我读到了 Rob Landley 的，这才恍然大悟，原来 Unix 目录结构是历史造成的。
话说 1969 年，Ken Thompson 和 Dennis Ritchie 在小型机 PDP-7 上发明了 Unix。1971 年，他们将主机升级到了 PDP-11。</description></item><item><title>ICMP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/ICMP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/ICMP/</guid><description>概述 参考：
公众号,24 张图搞定 ICMP ICMP IP 是尽力传输的网络协议，提供的数据传输服务是不可靠的、无连接的，不能保证数据包能成功到达目的地。那么问题来了：如何确定数据包成功到达目的地？ 不可靠传输 这需要一个网络层协议，提供错误检测功能和报告机制功能，于是出现了 ICMP（互联网控制消息协议）。ICMP 的主要功能是，确认 IP 包是否成功送达目的地址，通知发送过程中 IP 包被丢弃的原因。有了这些功能，就可以检查网络是否正常、网络配置是否正确、设备是否异常等信息，方便进行网络问题诊断。 ICMP 网络诊断功能 举个栗子：如果在传输过程中，发生了某个错误，设备便会向源设备返回一条 ICMP 消息，告诉它发生的错误类型。 ICMP 举例 ICMP 消息是通过 IP 进行传输，但它的目的并不是让 IP 成为一种可靠的协议，而是对传输中发生的问题进行反馈。ICMP 消息的传输同样得不到可靠性保证，也有可能在传输过程中丢失。因此 ICMP 不是传输层的补充，应该把它当做网络层协议。
ICMP 消息封装 ICMP 消息使用 IP 来封装，封装格式如下图。 ICMP 封装格式 其中 type（类型）字段表示 ICMP 消息的类型，code（代码）字段表示 ICMP 消息的具体含义。例如：type 值为 3 表示目的不可达消息（ Destination Unreachable Message ），若 code 值为 0 表示目的网络不可达（ Network Unreachable ）。常见的 ICMP 消息类型如下图。 ICMP 消息类型 从功能上，ICMP 的消息可分为两类：一类是通知出错原因的错误消息，另一类是用于诊断的查询消息。 错误消息和查询消息
常见的 ICMP 消息类型 回送请求消息（ Echo Request ）：是由源设备（主机或路由器等）向一个指定的目的设备发出的请求。这种消息用来测试目的地是否可达。 回送响应消息（ Echo Reply ）：对 Echo Request 的响应。目的设备发送 Echo Reply 来响应收到的 Echo Request 。最常用的 ping 命令就是使用 Echo Request 和 Echo Reply 来实现的。 回送消息</description></item><item><title>Inventory 文件</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Inventory-%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Inventory-%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
官方文档，用户指南 - 如何建立你的 Inventory Ansible 可同时操作属于一个组的多台主机，组和主机之间的关系通过 Inventory 文件配置。默认的文件路径为 /etc/ansible/hosts，也可以在 ansible、ansible-playbook 命令中使用 -i 选项指定其他的 Inventory 文件。
除默认文件外，还可以同时使用多个 inventory 文件，也可以从动态源，或云上拉取 inventory 配置信息。详见动态 Inventory。
Inventory文件格式 最常见的格式是 INI 和 YAML 格式，下面这是一个 INI 格式的 Inventory 示例
# 例1:定义一个单独的主机。未分组的机器。Note:需要在“例2”中中括号定义组之前指定 green.example.com 192.168.100.1 # 例2:定义一个主机组。组名为webservers的主机集合 [webservers] alpha.example.org 192.168.1.100 # 再定义一个主机组。组名为dbservers的主机集合 [dbservers] 192.168.2.100 # 定义一个主机的另一种方式。使用正则表达式来指定多个主机 www[001:006].example.com #www001.example.com一直到www006.example.com一共6台主机 db-[a:f]-node.example.com # 可以在主机ip或主机名后面添加参数，以此来控制Ansible与远程主机的交互方式。 # 详细的参数信息见官网：https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#connecting-to-hosts-behavioral-inventory-parameters # 指定该主机要执行操作的主机ip、用户名和密码 www.desistdaydream.com ansible_host=10.10.100.200 ansible_user=&amp;#34;root&amp;#34; ansible_password=&amp;#34;my@password&amp;#34; # 例3:组的引用,可以把一个或多个组作为另一个组的子成员。all_host 组包含 webservers 与 dbservers 两个组中所有的 hosts [all_host:children] webservers dbservers Note：该文件的第一列为一般推荐使用主机名来表示，如果需要指定该主机的ip地址，则使用 ansbile_ssh_host 或者 ansible_host 参数来指定ip。</description></item><item><title>IPVS</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/IPVS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/IPVS/</guid><description>概述 参考：
Wiki, IPVS 官方文档 IP Virtual Service(IP 虚拟服务，简称 IPVS) 是基于 Netfilter 的 Linux 内核模块，用来实现 LVS 集群中的 Scheduler(调度器) 功能。启动这个模块的 Linux 服务器就变成了 LVS 系统中的 Director，此时，这个服务器可以看作是一种高效的 Layer-4(四层) 交换机。在 Director 上运行 IPVS 代码是 LVS 的基本要素。
IPVS 在服务器上运行，并充当 RS 集群前面的负载均衡器。IPVS 可以将基于 TCP 和 UDP 的服务请求定向到真实服务器，并使真实服务器的服务在单个 IP 地址上表现为虚拟服务。当一个 TCP 连接的初始 SYN 报文到达时，IPVS 就选择一台服务器，将报文转发给它。此后通过查发报文的 IP 和 TCP 报文头地址，保证此连接的后继报文被转发到相同的服务器。这样，IPVS 无法检查到请求的内容再选择服务器，这就要求后端的服务器组是提供相同的服务，不管请求被送到哪一台服务器，返回结果都应该是一样的。但是在有一些应用中后端的服务器可能功能不一，有的是提供 HTML 文档的 Web 服务器，有的是提供图片的 Web 服务器，有的是提供 CGI 的 Web 服务器。这时，就需要基于内容请求分发 (Content-Based Request Distribution)，同时基于内容请求分发可以提高后端服务器上访问的局部性。
一个 ipvs 主机可以同时定义多个 cluster service 一个 cluster service 上至少应该定义一个 real server，定义时指明 lvs-type，以及 lvs scheduler 用白话理解 IPVS： IPVS 就是包括 Director 和 RS 在内的所有设备上的 IP，统一虚拟成一个 IP，这个 IP 就是面向用户的唯一 IP，用户通过这个 IP，就可以访问集群，让集群为其提供服务，这也是负载均衡的体现，也是集群的体现，把很多设备当做一个整体来看。</description></item><item><title>kubeadm Configuration</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-Configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-Configuration/</guid><description>概述 参考：
官方文档，参考 - 安装工具 - kubeadm - kubeadmin init - 结合配置文件使用 kubeadm init 官方文档，参考 - 配置 APIs-kubeadm 配置(v1beta3) kubeadm 库 v1beta2 版本的 kubeadm 包的配置文件字段详解 由于配置文件还在 beta 阶段，但是官方又推荐使用，所以很是纠结，我也不知道为啥。。。文档只有这种通过代码注释生成的内容~~~
kubeadm 库中的 Type 实际上就是配置文件中可用的字段，其实就是 Go 语言中 struct 与 yaml 的对应，配置文件都是 yaml 格式的，kind 中值，其实就是代码中的一个 struct。
kubeadm init 命令初始化集群时，对集群配置的首选方法是使用 --config=FILE 标志传递 YAML 格式的配置文件。
kubeadm 配置文件中定义的某些配置选项在 kubeamd init 的命令行标志中也有对应标志，但是这些标志仅支持最常见/最简单的用例。
kubeadm 的配置文件可以看成是 kubeadm 几个资源的 Manifests 文件的集合。kubeadm 其中包括多种资源，一个文件中可以使用三个破折号 --- 分隔的多种资源(其实就是 yaml 的语法)。每个资源就是一种配置类型。现阶段支持以下配置类型：
InitConfiguration # 初始化集群配置 ClusterConfiguration # 集群通用配置 KubeletConfiguration # 覆盖 kubelet 运行时配置文件 KubeProxyConfiguration # 覆盖 kube-proxy 运行时配置文件 JoinConfiguration # 加入集群配置 InitConfiguration Manifest 详解 参考：v1beta3 版本</description></item><item><title>KVM/QEMU 部署</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档，安装 TODO: 官方文档里没有教安装 qemu-system 的地方呀~o(╯□╰)o 前期准备 查看 CPU 是否支持 KVM，筛选出来相关信息才可以正常使用 KVM
egrep &amp;ldquo;(svm|vmx)&amp;rdquo; /proc/cpuinfo 安装虚拟化组件 CentOS yum install qemu-kvm
Ubuntu 检查环境
sudo apt update sudo apt install -y cpu-checker kvm-ok sudo apt install qemu-system
qemu-system 与 CPU 架构的说明 ARM QEMU 可以模拟 32 位和 64 位 Arm CPU。使用 qemu-system-aarch64 可执行文件模拟 64 位 Arm 机器。您可以使用 qemu-system-arm 或 qemu-system-aarch64 来模拟 32 位 Arm 机器：通常，适用于 qemu-system-arm 的命令行在与 qemu-system-aarch64 一起使用时表现相同。</description></item><item><title>Linux DNS 管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-DNS-%E7%AE%A1%E7%90%86/Linux-DNS-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-DNS-%E7%AE%A1%E7%90%86/Linux-DNS-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
Manual(手册)，resolver(3) Manual(手册)，resolv.conf(5) resolver(5) 手册也指向了 resolv.conf(5) 在 Linux 中，进行域名解析工作的是 Reslover(解析器)。
Reslover(解析器) 是 Linux libc 库 中用于提供 DNS 接口的程序集（其实就是对外暴露了 API 的 C 库），当某个进程调用这些程序时将同时读入 Reslover 的配置文件（resolv.conf），这个文件具有可读性并且包含大量可用的解析参数。
Note：并不是所有程序都会使用 Linux Reslover。比如想要测试 resolv.conf 文件，不要使用 dig, host, nslook 这类工具，因为他们并没有调用 Resolver 的库(i.e. resolv.conf 文件中的 option 内的设置不会生效)。可以使用 getent 来测试。一般情况下正常的应用程序，都会调用 resolver，并使用 resolv.conf 文件(比如 ping 程序)。
Reslover 库定义了下面这些函数
#include &amp;lt;netinet/in.h&amp;gt; #include &amp;lt;arpa/nameser.h&amp;gt; #include &amp;lt;resolv.h&amp;gt; struct __res_state; typedef struct __res_state *res_state; int res_ninit(res_state statep); void res_nclose(res_state statep); int res_nquery(res_state statep, const char *dname, int class, int type, unsigned char answer[.</description></item><item><title>LogRotate(日志轮替)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/LogRotate%E6%97%A5%E5%BF%97%E8%BD%AE%E6%9B%BF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/LogRotate%E6%97%A5%E5%BF%97%E8%BD%AE%E6%9B%BF/</guid><description>概述 参考：
Wiki, Log_rotation 公众号-马哥 Linux 运维，[译] 理解 logrotate 实用工具 为了防止日志文件持续被写入文件导致过于庞大，那么就需要对日志进行拆分，每隔一段时间就把日志文件保存(打包压缩)起来，然后再创建一个新的空文件继续接收日志，来回循环该过程直到通过配置规定的保留日期，来清除存在过久的日志。通过这种方式来进行日志的归档，分类，清理。这就是 LogRotate 所做的事情。是否进行轮替会有一系列的配置，比如文件的大小达到 N 会轮替一次，每隔多少天轮替一次等等。
logrotate 只是一个命令行工具，不以守护进程的方式运行在后台，默认情况下，logrotate 命令作为放在 /etc/cron.daily 中的 cron 任务，每天运行一次，该任务会根据设置的策略进行日志文件的检查，其中达到设置中满足轮替配置的日志文件将被轮替。
关联文件与配置 /etc/logrotate.conf # logrotate 基本配置文件
/etc/logrotate.d/ # 对基本文件的扩展，该目录下的文件的配置会被包含在基本配置文件中。该目录下一般是一个程序一个文件，每个程序都有自己的日志轮替配置。
/etc/cron.daily/logrotate # 该文件定义了 cron 定时任务执行日志轮替工作的时间
/var/lib/logrotate.status # logrotate 的执行历史
logrotate.conf 配置文件详解 /PATH/TO/FILES {&amp;hellip;} # 指定想要轮替的日志文件，可以通过 * 通配指定多个文件名 copytruncate # 把正在输出的日志拷(copy)一份出来，再清空(trucate)原来的日志。 compress # 压缩日志文件的所有非当前版本 dateext # 切换后的日志文件会附加上一个短横线和 YYYYMMDD 格式的日期, daily # 日志文件将每天轮替一次。其它可用值为 monthly(每月)，weekly(每周)、yearly(每年) delaycompress # 在轮替任务完成后，已轮替的归档将使用 gzip 进行压缩 errors &amp;lt;EMAIL&amp;gt; # 给指定邮箱发送错误通知 missingok # 如果日志文件丢失，不要显示错误 notifempty # 如果日志文件为空，则不轮换日志文件 olddir &amp;lt;DIR&amp;gt; # 指定日志文件的旧版本放在 “DIR”目录 中 postrotate 和 endscript # 在所有其它指令完成后，postrotate 和 endscript 里面指定的命令将被执行。在这种情况下，rsyslogd 进程将立即再次读取其配置并继续运行。 rotate N # 共存储 N 个轮替后日志。当产生第 N+1 个轮替后的日志，时间最久的日志将被删除 sharedscripts # 有多个日志需要轮替时，只执行一次脚本 size &amp;lt;LogSize&amp;gt; # 在日志文件大小大于 LogSize（例如 100K，4M）时进行轮替 配置样例</description></item><item><title>Loki Configuration</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-Configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-Configuration/</guid><description>概述 参考：
官方文档，配置 官方文档，告警规则和记录规则 Loki 可以通过两种方式配置 Loki 的运行时行为
命令行标志 配置文件 配置文件的一部分字段的值，可以通过命令行标志设置。在官方文档中，我们可以查看到配置文件中，所有与命令行标志对应的字段，效果如下：
# HTTP server listen host # CLI flag: -server.http-listen-address [http_listen_address(string)] 凡是注释中，有 CLI flag 的字段，都可以通过命令行标签设置其值。
Loki 命令行标志详解 -target &amp;lt;STRING&amp;gt; # 指定要启用的模块
可用的模块有 distributor、ingester、querier、query-frontend、table-manager。 可以使用 read、write 来让 loki 运行在只读或只写的模式 可以使用 all 表示启用所有模块 loki.yaml 配置文件详解 文档中包含配置文件关键字与命令行 flag 的对应值，配置文件中的很多配置，都可以通过命令行 flag 来实现。
顶层字段 target(STRING) # 指定 loki 二进制文件要运行的组件列表。默认值：all，即运行所有组件
可用的值有：all、read、write、ingester、distributor、query-frontend、query-scheduler、querier、index-gateway、ruler、compactor。 auth_enabled(BOOLEAN) # 通过 X-Scope-OrgID 标头启用身份验证，如果为 true，则必须存在。 如果为 false，则 OrgID 将始终设置为“ fake”。默认值：true
server(server) # 用于配置 loki 提供 http 和 gRPC 这两种服务的行为</description></item><item><title>Loki Rules 配置</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-Rules-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-Rules-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
官方文档，告警规则和记录规则 Loki Rules 文件的结构与 Promethues 的 Rules 文件结构一模一样。
Loki Rules 配置详解 Alerting Rules(告警规则) Recording Rules(记录规则)</description></item><item><title>Memory Virtualization</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Memory-Virtualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Memory-Virtualization/</guid><description>概述 参考：
Wiki, Memory_virtualization 为了在一台机器上运行多个虚拟机，KVM 需要实现 VA（虚拟内存） -&amp;gt; PA（物理内存） -&amp;gt; MA（机器内存）之间的地址转换。虚机 OS 控制虚拟地址到客户内存物理地址的映射 （VA -&amp;gt; PA），但是虚机 OS 不能直接访问实际机器内存，因此 KVM 需要负责映射客户物理内存到实际机器内存 （PA -&amp;gt; MA）。内存也是可以 overcommit 的，即所有虚机的内存之和可以超过宿主机的物理内存。但使用时也需要充分测试，否则性能会受影响。</description></item><item><title>Memory 的缓存</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory-%E7%9A%84%E7%BC%93%E5%AD%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory-%E7%9A%84%E7%BC%93%E5%AD%98/</guid><description>概述 参考：
linux 中每个程序启动之后都会占用内存，一般情况下是不会把内存全部占满。那么空闲的这部分内存用来干什么呢？~
Linux 会充分利用这些空闲的内存，设计思想是：内存空闲还不如拿来多缓存一些数据，等下次程序再次访问这些数据速度就快了，而如果程序要使用内存而系统中内存又不足时，这时不是使用交换分区，而是快速回收部分 cached，将它们留给用户程序使用。
比如说：当使用该程序时，就会从硬盘中读取该程序的内容，这一部分读取的内容会加载到内存中(caceh 中)，因为内存比硬盘的读写速度更快，所以当下次再使用该程序需要读取该程序的内容时，直接从内存就能读取了。而 buff 中的数据一般是程序运行中产生的(比如玩游戏的存档)，当程序结束之前，需要把再 buff 中的数据写入到硬盘中以便永久保存(要不再运行这游戏，不就没存档了么~哈哈)。
内存管理做了很多精心的设计，除了对 dentry 进行缓存（用于 VFS，加速文件路径名到 inode 的转换），还采取了两种主要 Cache 方式：Buffer Cache 和 Page Cache，目的就是为了提升磁盘 IO 的性能。从低速的块设备(e.g.硬盘)上读取数据会暂时保存在内存中，即使数据在当时已经不再需要了，但在应用程序下一次访问该数据时，它可以从内存中直接读取，从而绕开低速的块设备，从而提高系统的整体性能。
因此，可以看出，buffers/cached 真是百益而无一害，真正的坏处可能让用户产生一种错觉——Linux 耗内存！其实不然，Linux 并没有吃掉你的内存，只要还未使用到交换分区，你的内存所剩无几时，你应该感到庆幸，因为 Linux 缓存了大量的数据，也许某一次应用程序读取数据时，就会用到这些已经缓存了的数据！
Buffer 与 Cache 在 Memory 管理工具 的 free 命令中，可以看到的 buff 与 cache 是从虚拟文件系统 /proc/meminfo 中获取的数据
buff # 内核缓冲器用到的内存，对应的是 /proc/meminfo 中 Buffers 的值 Buffers 是对原始磁盘块的临时存储，也就是来缓存从磁盘块读写的数据，通常不会特别大(20MB 左右)。 这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写，等等。 cache # 内核 PageCache(页缓存) 和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和 Cached 是从磁盘读写文件时的页缓存，也就是用来缓存从文件读写的数据。 读取过一个文件后会缓存，下次访问过这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。 或者在向文件写入数据时，先将数据写入到内存中，然后系统后台再逐步将数据从内存写入到磁盘中。 SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。 实验示例 写文件时会用到 Cache 缓存数据，写磁盘时则会用到 Buffer 缓存数据</description></item><item><title>Network</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/XML-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Network/</guid><description>概述 参考：
官方文档，Network XML 格式 Network 对象用以控制虚拟网络，对应 &amp;lt;network&amp;gt; 根元素。
使用 virsh net-list 命令列出所有网络，使用 virsh net-edit XXX 即可编辑 network 元素的 XML 内容。
bandwidth &amp;lt;bandwidth&amp;gt;元素允许为特定网络设置服务质量（自0.9.4版起）。只支持为具有 &amp;lt;forward&amp;gt; 模式为route、nat、bridge或没有模式的网络（即“隔离”网络）设置带宽。不支持为forward模式为passthrough、private或hostdev的网络设置带宽。尝试这样做将导致无法定义网络或创建临时网络。
average
peak
burst
最佳实践 限制虚拟机网卡的网速
&amp;lt;interface type=&amp;#39;bridge&amp;#39;&amp;gt; &amp;lt;source bridge=&amp;#39;br0&amp;#39;/&amp;gt; &amp;lt;model type=&amp;#39;virtio&amp;#39;/&amp;gt; &amp;lt;driver name=&amp;#39;vhost&amp;#39; queues=&amp;#39;8&amp;#39;/&amp;gt; &amp;lt;bandwidth&amp;gt; &amp;lt;inbound average=&amp;#39;1000&amp;#39; peak=&amp;#39;5000&amp;#39; burst=&amp;#39;1024&amp;#39;/&amp;gt; &amp;lt;outbound average=&amp;#39;128&amp;#39; peak=&amp;#39;256&amp;#39; burst=&amp;#39;256&amp;#39;/&amp;gt; &amp;lt;/bandwidth&amp;gt; &amp;lt;address type=&amp;#39;pci&amp;#39; domain=&amp;#39;0x0000&amp;#39; bus=&amp;#39;0x01&amp;#39; slot=&amp;#39;0x00&amp;#39; function=&amp;#39;0x0&amp;#39;/&amp;gt; &amp;lt;/interface&amp;gt;</description></item><item><title>OpenSSH Utilities</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/OpenSSH-Utilities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/OpenSSH-Utilities/</guid><description>概述 参考：
官方 Manual(手册) https://www.myfreax.com/how-to-setup-ssh-tunneling/ https://hellolzc.github.io/2020/04/port-forwarding-with-ssh/ http://tuxgraphics.org/~guido/scripts/ssh-socks5-port-forwarding.html ssh、scp、sftp # 客户端管理工具 ssh-add、ssh-keysign、ssh-keyscan、ssh-keygen # 密钥管理工具 sshd、sftp-server、ssh-agent # 服务端管理工具 ssh - OpenSSH 的 ssh 客户端工具(远程登录程序) 详见 ssh
scp - 基于 ssh 协议的文件传输工具 scp 是基于 SSH 的 File transfer 工具
Syntax(语法) scp [OPTIONS] SourceFILE DestinationFILE
Note：远程 FILE 的格式为：USER@IP:/PATH/FILE)
OPTIONS：
-p # -r # 以递归方式复制，用于复制整个目录 EXAMPLE 把本地 nginx 文件推上去复制到以 root 用户登录的 10.10.10.10 这台机器的/opt/soft/scptest 目录下
scp /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest 把以 root 用户登录的 10.10.10.10 机器中的 nginx 文件拉下来复制到本地/opt/soft 目录下</description></item><item><title>Operator</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Operator/</guid><description>概述 参考：
Wiki, Operator(运算符) 喜马拉雅，番外篇06：布尔代数 编程中通过 Operator(运算符) 实现多种 Operation(运算)。
在编程领域中
真 可以用 true 或者 1 来表示 假 可以用 false 或者 0 来表示 常见的简单示例包括算术（例如用 + 加法）、比较（例如“大于”用 &amp;gt;）和逻辑运算（例如 AND，在某些语言中也写成 &amp;amp;&amp;amp;）。更多涉及的示例包括赋值（通常为 = 或 :=）、记录或访问对象中的字段（通常为 .）和范围解析运算符（通常为 :: 或 .）。语言通常会定义一组内置的运算符，并且在某些情况下允许用户为现有运算符添加新的含义甚至定义全新的运算符。
Arithmetic Operators(算数运算) # 最后的运算结果必然是数学概念上的整数、小数等。e.g.1+2=3、2*3=6 等 Boolean Operators(逻辑运算) # 之所以被称为逻辑运算符是因为它们的运算结果总是为布尔值 bool，不是 true 就是 false。e.g.1 是否等于 2、语句是否执行成功、是否有返回值、条件一成立且条件二失败结果四 true 还是 false 布尔代数 由于白马非马这种典故，语言是不可靠的。所以要创建一种符号。
算术运算 下表列出了常用的算术运算符，假定变量 a 为 10，变量 b 为 20：
运算符 说明 举例 - 减法 $a - $b 结果为 -10。 * 乘法 $a * $b 结果为 200。 / 除法 $b / $a 结果为 2。 % 取余 $b % $a 结果为 0。 比较运算 运算符 说明 举例 == 是否等于 !</description></item><item><title>Router And Switch</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Router-And-Switch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Router-And-Switch/</guid><description>概述 参考：
Wiki, Router_(computing) Wiki, Network switch Router(路由器)
Switch(交换机)
华为交换机 创建 trunk sy [HUAWEI] int eth-trunk 1 [HUAWEI-Eth-Trunk1] mode manual load-balance [HUAWEI-Eth-Trunk1] port link-type trunk [HUAWEI-Eth-Trunk1] quit [HUAWEI] int g1/0/0 [HUAWEI-GigabitEthernet1/0/0] eth-trunk 1 [HUAWEI-GigabitEthernet1/0/0] q [HUAWEI] int g 1/0/1 [HUAWEI-GigabitEthernet1/0/1] eth-trunk 1 [HUAWEI-GigabitEthernet1/0/1] q 配置 SNMP
~]# telnet 172.19.42.200 Trying 172.19.42.200... Connected to 172.19.42.200. Escape character is &amp;#39;^]&amp;#39;. Warning: Telnet is not a secure protocol, and it is recommended to use Stelnet.</description></item><item><title>Symbolic link</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/Symbolic-link/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/Symbolic-link/</guid><description>概述 参考：
Wiki, Symbolic link Symbolic link(符号链接，也称为 symlink 或 soft link(软链接)) 是一种文件，其目的是通过指定路径来指向文件或目录（称为“目标”），这也是一种 文件管理 的方式。
Symbolic link 与目标文件本质上是两个文件，两者的 Inode 不一样。</description></item><item><title>Target(目标) 与 Relabeling(重新标记)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Target%E7%9B%AE%E6%A0%87-%E4%B8%8E-Relabeling%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Target%E7%9B%AE%E6%A0%87-%E4%B8%8E-Relabeling%E9%87%8D%E6%96%B0%E6%A0%87%E8%AE%B0/</guid><description>概述 参考：
官方文档，配置 - 配置 简书大佬 Targets(目标) 是 Prometheus 核心概念的其中之一，Targets 是一组 Label(标签) 的集合。
Prometheus 在采集 Targets(目标) 的指标时，会自动将 Target 的标签附加到采集到的每条时间序列上才存储，这样是为了更好的对数据进行筛选过滤，而这些附加的新标签是怎么来的呢？。。。这就是本文所要描述的东西。
如下所示，随便找一条时间序列，就可以看到，原始的指标中没有下图红框中的标签，而通过 Prometheus Server 采集后，就附加了两个新的标签上去。
]# curl -s localhost:9090/metrics | grep build_info # HELP prometheus_build_info A metric with a constant &amp;#39;1&amp;#39; value labeled by version, revision, branch, and goversion from which prometheus was built. # TYPE prometheus_build_info gauge prometheus_build_info{branch=&amp;#34;HEAD&amp;#34;,goversion=&amp;#34;go1.18.6&amp;#34;,revision=&amp;#34;1ce2197e7f9e95089bfb95cb61762b5a89a8c0da&amp;#34;,version=&amp;#34;2.37.1&amp;#34;} 1 这里为什么会多出来两个标签呢，这种现象又是什么功能来实现的呢？假如说 job 是通过配置文件中定义出来的，那 instance 又是怎么来的？
首先，我们在 Prometheus Server 的 web 界面的 Status 标签中的 Targets 页面和 Service Discovery 页面中，可以发现 Prometheus 把标签分为两类：</description></item><item><title>Template</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Configuration/Template/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Configuration/Template/</guid><description>概述 参考：
官方文档，配置 - 模板示例 官方文档，配置 - 模板参考 Prometheus 可以在部分配置文件中（Rules、etc.）使用 Template(模板) 的能力，Prometheus 的模板基于 Go 语言的 Template 能力。
Template Function Prometheus 模板增加了一些函数以便更轻松得处理 PromQL 的查询结果（e.g. 将 Bytes 的数直接转为人类可读的带单位的结果），所有函数列表详见官方文档</description></item><item><title>Variable</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Variable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Variable/</guid><description>概述 参考：
Go 官方文档，参考 - 规范 - 变量 Go 官方文档，参考 - 规范 - 声明和范围 Variable(变量)
How to Name a Variable(如何命名一个变量) Scope(范围) Constants(常量) Defining Multiple Variables 定义多个变量空白标识符_用于抛弃值，e.g.值 5 在：_, b = 5, 7中被抛弃。_空白标识符是一个只写变量，不能获得它的值。这样做是因为 Go 语言中必须使用所有被声明的变量，但有时候并不需要使用从一个函数得到的所有返回值(e.g.上例中的 5 与 7 是通过某个函数获得的值且该函数一定会获得 2 个值，但是其中一个却用不上)。 声明变量 格式：var VarID TYPE = EXP
VarID # 变量的标识符 TYPE # 详见 Data type EXP # 初始化时使用的表达式。i.e.给该变量一个值。 其中 TYPE 或者 = EXP 这两个部分可以省略其中之一，如果省略 TYPE，那么将根据初始化 EXP 来自动推导变量的类型；如果初始化的 EXP
引用变量 Variables Scope(变量范围) Variables Scope(变量范围) 就是变量的作用域，定义在哪里的变量，可以在哪里被引用，不可以在哪里被引用，都是变量范围所决定的。</description></item><item><title>Variables(变量)</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Variables%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Variables%E5%8F%98%E9%87%8F/</guid><description>概述 参考：
官方文档，用户指南 - 目录 - 使用变量 变量基本的定义与引用方式 变量名应为字母、数字、下划线。并且始终应该以字母开头。
基础的定义方式是在一个 play 中使用 vars 关键字定义变量，示例如下
- host: webservers vars: http_port: 80 # 定义一个名为http_port的变量，值为80 tasks: - debug Note: vars 关键字可以用在 host 环境中，也可以用在 tasks 环境中，用在 tasks 环境时，则变量仅对当前任务生效
下面是一个在角色中定义字典类型变量的样例：
~]# cat roles/test/defaults/main.yml docker: version: 18.06.2 dataDir: /var/lib/docker registryMirrors: - https://ac1rmo5p.mirror.aliyuncs.com execOpts: - &amp;#39;native.cgroupdriver=systemd&amp;#39; insecureRegistries: - 100.64.2.52:9999 - 100.64.1.31:9999 变量的引用方式 一般情况使用 {{ VarName }} 来引用变量，特殊情况不用加 {{ }} 而可以直接引用，比如在某些控制结构(比如 when)的语句中。
变量可以通过两种方式引用字典内特定字段的变量
使用方括号 [] 进行引用 docker['registryMirrors'] 变量的值为 https://ac1rmo5p.</description></item><item><title>VRRP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/VRRP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/VRRP/</guid><description>概述 参考：
Virtual Router Redundancy Protocol(虚拟路由冗余协议，简称 VRRP) 是一种容错协议，其主要目的是解决路由单点故障的问题。VRRP 协议将局域网内的一组路由器虚拟为单个路由，通常将其称为一个路由备份组， 而这组路由器内包括一个 Master 路由（ 即活动路由器）和若干个 Backup 路由（即备份路由器）， VRRP 虚拟路由示意图如图 3-3 所示。在图 3-3 中 RouterA 、RouterB 和 RouterC 属于同一个 VRRP 组，组成一个虚拟路由器，而由 VRRP 协议虚拟出来的路由器拥有自己的 IP 地址 10.110.10.1 ，而备份组内的路由器也有自己的 IP 地址（如 Master 的 IP 地址为 10.110.10.5, Backup 的 IP 地址为 10.110.10.6 和 10.110.10.7）。
虚拟 IP：VIP，Virtual IP Address，在实际使用中，局域网内的主机仅仅知道这命虚拟路由器的 IP 地址 10 .110.10.1，而并不知道具体的 Master 路由器的 IP 地址以及 Backup 路由器的 IP 地址。局域网内的主机将自己的默认路由下一跳地址设置为该虚拟路由器的 IP 地址 10.110.10.1 之后，网络内的主机就通过这个虚拟的路由器来与其他网络进行通信。在通信过程中，如果备份组内的 Master 路由器故障，则 Backup 路由器将会通过选举机制重新选出一个新的 Master 路由器，从而继续向网络内的主机提供路由服务，最终实现了路由功能的高可用。</description></item><item><title>精简指令集</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/%E7%B2%BE%E7%AE%80%E6%8C%87%E4%BB%A4%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/CPU/%E7%B2%BE%E7%AE%80%E6%8C%87%E4%BB%A4%E9%9B%86/</guid><description>概述 参考：
不懂精简指令集还敢说自己是程序员？ 在上一篇文章《CPU 进化论：复杂指令集》中我们从历史的角度讲述了复杂指令集出现的必然，随着时间的推移，采用复杂指令集架构的 CPU 出现各种各样的问题，面对这些问题一部分人开始重新思考指令集到底该如何设计。
在这一时期，两个趋势的出现促成一种新的指令集设计思想。
内存与编译器
时间来到了 1980s 年代，此时容量 “高达”64K 的内存开始出现，内存容量上终于不再捉襟见肘，价格也开始急速下降，在 1977 年，1MB 内存的价格高达**$5000**，要知道这可是 1977 年的 5000 刀，但到了 1994 年，1MB 内存价格就急速下降到大概只有 $6，这是第一个趋势。
此外在这一时期随着编译技术的进步，编译器越来越成熟，渐渐的程序员们开始依靠编译器来生成汇编指令而不再自己手工编写。
这两个趋势的出现让人们有了更多思考。
化繁为简
19 世纪末 20 世纪初意大利经济学家 Pareto 发现，在任何一组东西中，最重要的只占其中一小部分，约 20%，其余 80% 尽管是多数，却是次要的，这就是著名的二八定律，机器指令的执行频率也有类似的规律。
大概 80% 的时间 CPU 都在执行那 20% 的机器指令，同时 CISC 中一部分比较复杂的指令并不怎么被经常用到，而且那些设计编译器的程序员也更倾向于组合一些简单的指令来完成特定任务。
与此同时我们在上文提到过的一位计算机科学家，被派去改善微代码设计，但后来这老哥发现有问题的是微代码本身，因此开始转过头来去思考微代码这种设计的问题在哪里。
他的早期工作提出一个关键点，复杂指令集中那些被认为可以提高性能的指令其实在内部被微代码拖后腿了，如果移除掉微代码，程序反而可以运行的更快，并且可以节省构造 CPU 消耗的晶体管数量。
由于微代码的设计思想是将复杂机器指令在 CPU 内部转为相对简单的机器指令，这一过程对编译器不可见，也就是说你没有办法通过编译器去影响 CPU 内部的微代码运行行为，因此如果微代码出现 bug 那么编译器是无能为力的，你没有办法通过编译器生成其它机器指令来修复问题而只能去修改微代码本身。
此外他还发现，有时一些复杂的机器指令执行起来要比等价的多个简单指令要。
这一切都在提示：为什么不直接用一些简单到指令来替换掉那些复杂的指令呢？
精简指令集哲学
基于对复杂指令集的思考，精简指令集哲学诞生了，精简指令集主要体现在以下三个方面：
1，指令本身的复杂度
精简指令集的思想其实很简单，干嘛要去死磕复杂的指令，去掉复杂指令代之以一些简单的指令。
有了简单指令 CPU 内部的微代码也不需要了，没有了微代码这层中间抽象，编译器生成的机器指令对 CPU 的控制力大大增强，有什么问题让写编译器的那帮家伙修复就好了，显然调试编译器这种软件要比调试 CPU 这种硬件要简单很多。</description></item><item><title>通过 veth 设备查找对应的虚拟机</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E9%80%9A%E8%BF%87-veth-%E8%AE%BE%E5%A4%87%E6%9F%A5%E6%89%BE%E5%AF%B9%E5%BA%94%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E9%80%9A%E8%BF%87-veth-%E8%AE%BE%E5%A4%87%E6%9F%A5%E6%89%BE%E5%AF%B9%E5%BA%94%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA/</guid><description>概述 通过 xml 文件查看虚拟机的 mac 地址
~]# grep &amp;#34;mac addr&amp;#34; lchTest.xml &amp;lt;mac address=&amp;#39;52:54:00:6a:86:89&amp;#39;/&amp;gt; 筛选网络设备 mac
~]# ip a | grep &amp;#34;86:89&amp;#34; -B 1 127: vnet1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast master br1 state UNKNOWN group default qlen 1000 link/ether fe:54:00:6a:86:89 brd ff:ff:ff:ff:ff:ff 由此可见，vnet 设备的 mac 与虚拟机的 mac 在后面几位是永远保持一致的，所以可以通过 vnet 设备的 mac ，从所有虚拟机中的 xml 进行筛选就行可以找到 vnet 设备对应的虚拟机了。
应用实例 比如我现在能看到 4 个 vnet 设备。
~]# ip a ..... 62: vnet3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast master br1 state UNKNOWN group default qlen 1000 link/ether fe:54:00:5c:11:85 brd ff:ff:ff:ff:ff:ff inet6 fe80::fc54:ff:fe5c:1185/64 scope link valid_lft forever preferred_lft forever 79: vnet0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc mq master br1 state UNKNOWN group default qlen 1000 link/ether fe:54:00:68:20:51 brd ff:ff:ff:ff:ff:ff inet6 fe80::fc54:ff:fe68:2051/64 scope link valid_lft forever preferred_lft forever 127: vnet1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast master br1 state UNKNOWN group default qlen 1000 link/ether fe:54:00:6a:86:89 brd ff:ff:ff:ff:ff:ff inet6 fe80::fc54:ff:fe6a:8689/64 scope link valid_lft forever preferred_lft forever 139: vnet2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast master br1 state UNKNOWN group default qlen 1000 link/ether fe:54:00:3a:95:ef brd ff:ff:ff:ff:ff:ff inet6 fe80::fc54:ff:fe3a:95ef/64 scope link valid_lft forever preferred_lft forever 我想看看 vnet3 是关联到哪个虚拟机上了，就可以进行如下操作：(首先看到 vnet3 的 mac 为 fe:54:00:5c:11:85)</description></item><item><title>ADB</title><link>https://desistdaydream.github.io/docs/Mobile-device/Android-MGMT/ADB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Mobile-device/Android-MGMT/ADB/</guid><description>概述 参考：
官方文档，SDK 工具-adb 官方文档-中文 Wiki, Android_Debug_Bridge Android Debug Bridge(安卓调试桥，简称 ADB) 是一种功能多样的命令行工具，可让您与设备进行通信。adb 命令可用于执行各种设备操作，例如安装和调试应用。adb 提供对 Unix shell（可用来在设备上运行各种命令）的访问权限。它是一种 C/S 架构程序，包括以下三个组件：
adb 命令行工具，在开发机器上运行 客户端：用于发送命令。客户端在开发机器上运行。您可以通过发出 adb 命令从命令行终端调用客户端。 服务端：用于管理客户端与守护程序之间的通信。服务端在开发机器上作为后台进程运行。默认监听 5037 端口 adbd 守护程序，在设备上运行。守护程序在每个设备上作为后台进程运行，以接收 adb 服务端发来的各种指令。 adb 命令行工具作为客户端运行时，会先检查是否有服务端在运行，如果没有，则会执行 adb -L tcp:5037 fork-server server --reply-fd 4 命令以启动 adb 服务端，默认监听在 5037 端口，并接收 adb 客户端发出的命令。
而 adbd 守护程序，通常是设备上默认自带的进程，但是默认并没有启动，如果想要启用设备上的 adbd，需要开启 USB 调试，该功能通常存在于开发者选项中，参考这里来启用开发者选项。
adb 服务端启动后会自动发现 USB 连接的设备、 安卓 Studio 模拟的设备，然后通过 adb devices -l 可以列出这些设备。
ADB 连接设备 https://blog.51cto.com/u_15549234/5139197
我们可以通过两种方式让 adb 连接到设备
本地连接 无线连接 本利连接一般是通过 USB 连接真实设备或连接本地 安卓 Studio 模拟的设备。打开设备的 USB 调试并插上线，一般电脑都会自动发现设备。</description></item><item><title>Admission Controllers 准入控制器</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Admission-Controllers-%E5%87%86%E5%85%A5%E6%8E%A7%E5%88%B6%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Admission-Controllers-%E5%87%86%E5%85%A5%E6%8E%A7%E5%88%B6%E5%99%A8/</guid><description>概述 参考：
官方文档，参考-API 访问控制-使用准入控制器 官方文档，参考-API 访问控制-动态准入控制 理清 Kubernetes 中的准入控制（Admission Controller） 公众号 - 运维开发故事，开发一个禁止删除 namespace 的控制器 准入控制器是一段代码，它会在请求通过 认证和授权 之后、对象被持久化之前，拦截到达 API Server 的请求。
由于准入控制器是拦截 API Server 中最后的持久化逻辑，所以现阶段 准入控制器在 kube-apiserver 自身中实现，一共由于两大类准入控制器
静态准入控制器 # kube-apiserver 默认内置的准入控制器，可以从 准入控制器列表 查看。 比如 istio 为每个 Pod 注入 Sidecar 的功能，就是通过 Mutating 准入控制器实现的。 动态准入控制器 # 以 Webhook 的形式运行，请求到达 kube-apiserver 后将会根据 ValidatingWebhookConfiguration 资源的定义，将请求转发给自己编写的控制器来处理后再返回给 kube-apiserver。 比如我们编写了一个程序：如果请求是删除 namespace 资源的话，则进制删除。那么将这个程序部署到 k8s 时，再创建一个 ValidatingWebhookConfiguration 对面，以告诉 API Server 将请求转发给咱编写的程序。此时咱的程序处理请求后，会告诉 API Server 是否可以继续执行这个请求。 准入控制器通常用以执行 Validating(验证)、Mutating(变更) 操作
验证操作即验证该请求是否可以执行 变更操作就是类似于 Istion，将创建的 Pod 中加入其他字段或减少某些字段。 目前版本中，默认启用的准入控制器 CertificateApproval CertificateSigning CertificateSubjectRestriction DefaultIngressClass DefaultStorageClass DefaultTolerationSeconds LimitRanger MutatingAdmissionWebhook NamespaceLifecycle PersistentVolumeClaimResize PodSecurity Priority ResourceQuota RuntimeClass ServiceAccount StorageObjectInUseProtection TaintNodesByCondition ValidatingAdmissionWebhook</description></item><item><title>Bypass swtich</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Bypass-swtich/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Bypass-swtich/</guid><description>概述 参考：
Wiki, Bypass switch Bypass switch(旁路交换机) 是一种硬件设备，可以与安全设备并联并串联到网络链路中，为安全设备提供 fail-safe access(故障时可安全访问) 的能力。
tips: Bypass switch 早期也有 Bypass tap(旁路分路器) 的含义，具有一部分 Network tap 的能力，后来随着发展，Bypass 仅仅作为提供高可用所用，Tap 能力由更专业的设备实现。
Bypass tap 通常至少有 4 个端口。
A 和 B 两个端口串联，且中间不经过任何电路，Bypass tap 本身不运行的情况下也可以保证 A 到 B 之间的链路畅通。当安全设备正常运行时，A 到 B 的连接是断开的； C 和 D 是用来监控安全设备的端口，安全设备正常运行时，流量通过 C 和 D 端口，相当于将安全设备串联进网络中。 当检测到安全设备出现异常时，将会切断 C 和 D 的端口，将流量转交给 A 和 B 以保证网络链路上的数据不间断。 通常来说，这两种情况可以用两种模式来概括
Normal mode # 流量经过 Bypass 的 C 与 D 端口，到达其他设备后，再发送到下一跳的设备 有的地方也称为 控制模式 Bypass mode # 流量经过 Bypass 的 A 与 B 端口，直接到达下一跳的设备 有的地方也称为 直通模式 在中文环境中也有的将 Bypass tap 称为 Optical swap(光切换设备，Optiswap)、光开关、etc.</description></item><item><title>Docker Image</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Image/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Image/</guid><description>概述 参考：
思否，走进docker(02)：image(镜像)是什么？ 在虚拟化中，运行程序的地方是一个虚拟的操作系统。而容器技术中，运行程序的地方是一个容器 image(镜像)。
容器的镜像与虚拟机的虚拟系统有异曲同工之妙，基本原理相似，只不过虚拟系统可以像正常安装系统一样进行安装，而容器镜像，则是一个已经打包好的操作系统，可以开箱即用。
由于这种构造，docker 公司研究出一种技术，就是联合文件系统(UnionFS(Union File System))。可以将镜像分为多层(layers)，每层附加一个功能。
实现联合文件系统的驱动程序：docker 本身支持 overlay，overlay2，aufs，btrfs，devicemapper，vfs 等
Container Image 的分层结构(联合文件系统) http://www.cnblogs.com/CloudMan6/p/6806193.html
Container Image 采用分层结构，最底层为 bootfs，其它为 rootfs
bootfs：用于系统引导的文件系统，包括 bootloader 和 kernel，Container 启动完成后会被卸载以节约内存资源 rootfs：位于 bootfs 之上，表现为 Container 的根文件系统； 传统模式中，系统启动时，内核挂载 rootfs 时会先将其挂载为只读模式，完整性自检完成后将其重新挂载为读写模式。 docker 中，rootfs 由内核挂载为“只读”模式，然后通过“联合挂载”技术额外挂载一个“可写(writable)”层。 可以这么理解：
通过一个 Base Image 启动了一个 Container，然后安装一个 vim 编辑器，commit 这个 container，生成的新镜像就是两层，第一层是系统，第二层是 vim。 这时候用这个这个新的 image 启动一个 Container 后，再安装一个 Nginx，然后 commit 这个 Container，生成的新镜像就是三层，1 系统、2vim、3nginx。 以此类推，每一次 Container 的变化被 commit 后都可以当作一层。 对 Container 的操作产生的变化，是在可写的容器层中进行的 可写(writable)的层(layers) 当容器启动时，一个新的“可读写”层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。位于下层的 image 称为父镜像(parent image)，最底层的称为基础镜像(base image)</description></item><item><title>Edge</title><link>https://desistdaydream.github.io/docs/Web/Browser/Edge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser/Edge/</guid><description>概述 参考：
使用 Edge 的用户常会用 newibing 的 AI , 但当用了浏览器自带的搜索时，会访问 cn.bing.com 这时 BING 会把你的位置定位在中国，你再打开 bing.com , 会发现“聊天” 消失了，最筒单的恢复方法是 在浏览器上输入 sg.bing.com 就切回新加坡地点了, 页面上的“聊天”也会重新出现.
问题 无法像 Chrome 一样，在收藏夹中的文件夹上右键点击“将此页添加到收藏夹”
https://answers.microsoft.com/zh-hans/microsoftedge/forum/all/edge%E4%B8%8D%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87/ef685d0b-a348-4556-978d-64937cad0a9f</description></item><item><title>Fiber-optic splitter</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Fiber-optic-splitter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Fiber-optic-splitter/</guid><description>概述 参考：
Wiki, Fiber-optic splitter Wiki, Beam_splitter 百度百科，光纤分路器 百度百科，分光器 Fiber-optic splitter(分光器、光纤分路器) 是基于石英基板的集成波导光功率分配装置，类似于同轴电缆传输系统。光网络系统使用耦合到分支分配的光信号。光纤分路器是光纤链路中最重要的无源器件之一。它是一种具有多个输入和输出端子的光纤汇接设备，特别适用于无源光网络（EPON、GPON、BPON、FTTX、FTTH等）连接主配线架和终端设备并对光信号进行分支。
有的地方也会用 Optical splitter 或 Beam splitter
分光器仅仅是单纯针对物理链路进行按比例分光，不会涉及上层的流量识别和处理，通常按照 2/8 比例分光，80% 的光能量在原始链路传输以保证通信不受影响；20% 的光能量作为复制的流量发送给下一个设备以进一步处理（可以分析流量中恶意数据等）。通常这 20% 的光需要经过 Optical amplifier(光放大器) 才能被其他设备正常使用。</description></item><item><title>File Descriptor(文件描述符)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/File-Descriptor%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/File-Descriptor%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</guid><description>概述 参考
Wiki, FileDescriptor CSDN，Linux 中的文件描述符与打开文件之间的关系 File Descriptor(文件描述符，简称 FD，有的地方也称为Handle(句柄)) 是一个抽象的指示符(也可以称为索引)，用于应用程序便捷得访问文件或其他 I/O 资源。
在 Linux 系统中一切皆可以看成是文件，文件又可分为：普通文件、目录文件、链接文件、设备文件等等。File Descriptor(文件描述符) 是内核为了高效管理已被打开的文件所创建的索引值，其是一个非负整数（通常是小整数），用于指代被打开的文件，所有执行 I/O 操作的系统调用都通过文件描述符。
每个进程(除了 Daemon 进程)，一般总是会打开三个文件(/dev/null 或 /dev/pts/0 或其他等等)，并占用前三个文件描述符，0 是标准输入，1 是标准输出，2 是标准错误。比如现在有这么一个程序，我们打开它:
cat &amp;gt; test-fd.sh &amp;lt;&amp;lt;EOF #!/bin/bash while true; do date sleep 10 done EOF chmod 755 test-fd.sh bash test-fd.sh # 查看该进程的 fd 目录可以看到有如下几个文件 ~]# ll /proc/4082/fd total 0 lrwx------ 1 root root 64 Nov 22 18:27 0 -&amp;gt; /dev/pts/0 lrwx------ 1 root root 64 Nov 22 18:27 1 -&amp;gt; /dev/pts/0 lrwx------ 1 root root 64 Nov 22 18:27 2 -&amp;gt; /dev/pts/0 lr-x------ 1 root root 64 Nov 22 18:27 255 -&amp;gt; /root/test-fd.</description></item><item><title>http 模块指令</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/http-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/http-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
org 官方文档，http core 模块 官方文档，管理指南-负载均衡-HTTP 负载均衡 http 模块及其子模块通过 http {} 配置环境中的指令控制行为
http{} 配置环境下的每个 server{} 指令块控制访问特定域名或者 ip 地址上对资源请求的处理。server{} 指令块中的一个或多个 location{} 指令块定义了根据 URL 来处理流量的规则
比如用户访问 map.baidu.com 和 baike.baidu.com。看上去是访问了两台服务器，但是实际上，这是经过作为代理设备的 ngxin 来进行选择后的虚拟服务器。一般情况下，baike.baidu.com 与 map.baidu.com 这俩域名所解析出来的 ip 应该是同一个公网 ip(比如 123.123.123.123)(baidu 有钱用很多公网 IP 除外)。所以可以想到，用户在浏览器输入任何一个域名，访问请求都会来到 123.123.123.123，然后根据请求报文中的 Request-URL 字段中的域名与 server_name 进行配对，用户输入的 URL 中域名与哪个 server_name 相同，则该请求就会通过这个 server 来进行处理，然后根据该 server 中 location 的关键字来决定把改请求转发给哪里。 对于 http{} 配置环境来说，server{}、server_name、location{}、proxy_pass 是实现 7 层代理的关键指令。server_name 指定接受流量的域名，location{} 匹配路径，然后通过 proxy_pass 将流量代理到指定的后端。
简单的 http{} 配置环境示例 http { access_log /dev/stdout main; upstream backend { # 后端配置 server backend1.</description></item><item><title>ipvsadm 命令行工具</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/ipvsadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/LVS/ipvsadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
Syntax(语法) 处理 Virtual Service 的命令语法：
ipvsadm COMMAND VirtualService [-s Scheduler] [Persistence OPTIONS] 处理指定 Virtual Service 下的 Real Server 的命令语法：
ipvsadm COMMAND VirtualService ServerAddress [PacketForwardingMethod] [Weight Options] ** 命令语法中各参数的含义
VirtuslService # 用于指定基于协议或者地址或者端口号的虚拟服务，通过三元组定义：Protocol、IP、PORT。 格式：-PROTOCOL IP:PORT -PROTOCOL 分两种 -t, &amp;ndash;tcp-service -u, &amp;ndash;udp-service Scheduler # Director 的调度方法 详见 LVS 文章中描述的调度方法，使用其中 10 种任意一种的英文简称来写该参数，注意：是小写字母 ServerAddress # RS 的 IP PacketForwardingMethod # 该位置指明 LVS 的工作模式，不写该参数表明默认 DR 类型 -g, &amp;ndash;gatewaying # 网关，表示 DR 模式 -i, &amp;ndash;ipip # IP 封装 IP，表示 TUN 模式 -m, &amp;ndash;masquerading # 伪装，表示 NAT 模式 Weight Options # 权重选项 COMMAND 管理集群服务的 COMMAND</description></item><item><title>Journal</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Journal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Journal/</guid><description>概述 参考：
Manual, systemd-journald.service(8) 相关服务说明
systemd-Journald.service # 日志功能通过该 Unit 来实现，是一个用于收集和存储日志数据的系统服务，是系统启动前要启动的第一个进程，Journald 会把所有收集到的信息保存在内存中。 rsyslog.service # 另一种日志数据持久化，Journald 会把日志信息转发给 rsyslog.service 进行处理和保存，如果没有 Journald，rsyslog 也可以自动生成日志而不用从 journald 去获取 logrotate # logrotate 会对日志文件进行轮替操作，i.e.把已经非常大的日志文件改名后，创建一个新的日志文件，新产生的日志会保存在新文件中，老文件保留一定时期后会自动清除 Journald 关联文件与配置 /etc/systemd/journal.conf
日志存放路径 /run/log/journal/${MACHINE-ID}/
/var/log/journal/${MACHINE-ID}/
默认情况下，journald 的日志保存在 /run/log/journal 中，系统重启就会清除。通过新建 /var/log/journal 目录，日志会自动记录到这个目录中，并永久存储。
路径中的 MACHINE-ID 的值，可以通过 cat /etc/machine-id 命令获取
~]# ls /run/log/journal c14766a3e9ae49a3872fb9b7e2583710 ~]# cat /etc/machine-id c14766a3e9ae49a3872fb9b7e2583710 所有 journal 程序生成的日志，都会存在 MACHIN-ID 目录下
~]# ll -h /var/log/journal/c14766a3e9ae49a3872fb9b7e2583710 total 153M drwxr-sr-x+ 2 root systemd-journal 4.0K Feb 21 23:15 .</description></item><item><title>kubeadm 实现细节</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubeadm-%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/</guid><description>概述 参考：
kubeadm 核心设计原则 参考：
官方文档，参考 - kubeadm - 实现细节 kubeadm init 和 kubeadm join 结合在一起提供了良好的用户体验。kubeadm init 和 kubeadm join 设置的集群应为：
Secure 安全——应采用最新的最佳做法 加强 RBAC 使用节点授权器 在控制平面组件之间使用安全通信 在 API 服务器和 kubelet 之间使用安全通信 锁定 kubelet API 锁定对系统组件（例如 kube-proxy 和 CoreDNS）的 API 的访问 锁定引导令牌可以访问的内容 Easy to use 易于使用——用户只需要运行几个命令即可 kubeadm init export KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f &amp;lt;network-of-choice.yaml&amp;gt; kubeadm join &amp;ndash;token : Extendable 可扩展 它应该不偏袒任何特定的网络提供商。配置群集网络超出范围 它应该提供使用配置文件来自定义各种参数的可能性 kubeadm 默认所需使用的值和目录 为了降低复杂性并简化基于 kubeadm 的高级工具的开发，它使用一组有限的常量值来存储众所周知的路径和文件名。
Kubernetes 目录 /etc/kubernetes 在应用程序中是一个常量，因为在大多数情况下，它显然是给定的路径，并且是最直观的位置；其他常量路径和文件名是：</description></item><item><title>KVM/QEMU 镜像管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
官方文档，系统模拟-磁盘镜像 GitHub 文档，qemu/qemu/docs/interop/qcow2.txt Wiki, qcow 其他 https://www.unixmen.com/qemu-kvm-using-copy-write-mode/ https://opengers.github.io/virtualization/kvm-libvirt-qemu-5/ KVM/QEMU 通过 qemu-img 命令行工具管理虚拟机镜像。
QEMU Copy On Write 注意：
使用该特性创建出来虚拟机之后，整个快照链的根节点(i.e.backingfile 虚拟机)一定要不有任何更改，否则会导致基于其创建的其他所有虚拟机文件系统出现问题。比如变成 read-only 状态。 QEMU Copy On Write(QEMU 写时复制，简称 QCOW) 是 QEMU 创建的虚拟机使用的磁盘镜像文件的文件格式。
当使用 QCOW 时，不会对原始磁盘映像应用任何更改。所有更改都记录在其他的 QCOW 文件中。多个 QCOW 文件可以指向同一个镜像，而不会危及基本系统。QEMU/KVM 允许将 QCOW 文件的更改合并到原始图像中。
修改 backingfile 后，导致依赖 backingfile 的虚拟机的文件系统崩溃 https://www.cnblogs.com/fengrenzw/p/3383773.html
https://www.cnblogs.com/fengrenzw/p/3383773.html
我们知道 qcow2 的磁盘格式可以带来很大的便利性，因为部署的时候可以减少大量的时间、空间，可以增量备份、快照等非常诱人的特性。
因为下边可能会有点绕：
backing_file：后端，母镜像
qcow2：前端，子镜像
在使用的时候可能会遇到一种情况，就是使用 backing_file 时，如果修改了 backing_file，“可能”会导致前端的 qcow2 的崩溃，出现这种问题个人觉得是很正常的，并且是可以完全避免的。所以，在 openstack 在使用 qcow2 的过程中会使用 glance 镜像管理来保证它的安全和完整性，我们在使用 qcow2 的时候也务必不回去修改它。
至于为什么会出现这种现象，下面简单分析一下，可能会有些纰漏、错误，但感觉整体思路上不会有太大的偏差。</description></item><item><title>nftables</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/nftables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/nftables/</guid><description>概述 参考：
官方 wiki nftables 是一个 Netfilter 项目，旨在替换现有的 {ip,ip6,arp,eb}tables 框架，为 {ip,ip6}tables 提供一个新的包过滤框架、一个新的用户空间实用程序（nft）和一个兼容层。它使用现有的钩子、链接跟踪系统、用户空间排队组件和 netfilter 日志子系统。
nftables 主要由三个组件组成：内核实现、libnl netlink 通信、 nftables 用户空间。 其中内核提供了一个 Netlink 配置接口以及运行时规则集评估，libnl 包含了与内核通信的基本函数，用户空间可以通过 nft 和用户进行交互。
nftables 与 iptables 的区别
nftables 和 iptables 一样，由 table(表)、chain(链)、rule(规则) 组成。nftables 中，表包含链，链包含规则，规则是真正的 action。与 iptables 相比，nftables 主要有以下几个变化：
iptables 规则的布局是基于连续的大块内存的，即数组式布局；而 nftables 的规则采用链式布局。其实就是数组和链表的区别 iptables 大部分工作在内核态完成，如果要添加新功能，只能重新编译内核；而 nftables 的大部分工作是在用户态完成的，添加新功能很 easy，不需要改内核。 iptables 有内置的链，即使你只需要一条链，其他的链也会跟着注册；而 nftables 不存在内置的链，你可以按需注册。由于 iptables 内置了一个数据包计数器，所以即使这些内置的链是空的，也会带来性能损耗。 简化了 IPv4/IPv6 双栈管理 原生支持集合、字典和映射 nftables 没有任何默认规则，如果关闭了 firewalld 服务，则命令 nft list ruleset 输出结果为空。意思就是没有任何内置链或者表
nftables table 与 nftables family https://wiki.</description></item><item><title>package.json</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/package.json/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/package.json/</guid><description>概述 参考：
dev 官网，学习-package.json 指南 pnpm 官方文档，配置-package.json package.json 文件是项目的清单。 它包含包的所有元数据，包括依赖项、标题、作者等等。例如，它是用于工具的配置中心。 它也是 npm 和 yarn 等包管理工具管理依赖的地方。
想要运行带有 ES6 语法规则的代码（比如导入包是使用的 import 关键字），需要添加 &amp;quot;type&amp;quot;: &amp;quot;module&amp;quot; 配置。</description></item><item><title>Templates 模板(Jinja2)</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Templates-%E6%A8%A1%E6%9D%BFJinja2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Templates-%E6%A8%A1%E6%9D%BFJinja2/</guid><description>概述 参考：
官方文档，用户指南 - 传统目录 - 使用剧本 - 模板(Jinja2) 朱双印博客,jinja2 模板 https://www.zsythink.net/archives/2999 https://www.zsythink.net/archives/3021 https://www.zsythink.net/archives/3037 https://www.zsythink.net/archives/3051 骏马金龙，9. 如虎添翼的力量：解锁强大的 Jinja2 模板 Jinja2 的内容较多，但对于学习 Ansible 来说，只需要学习其中和 template 相关的一部分 (其它的都和开发有关或 Ansible 中用不上) 以及 Ansible 对 Jinja2 的扩展功能即可。
详见 Python 编程语言部分的 《Jinja》章节
尽管在编写 Playbook 时可以不用在意是否要用 Jinja2，但 Ansible 的运行离不开 Jinja2，当 Ansible 开始执行 playbook 或任务时，总是会先使用 Jinja2 去解析所有指令的值，然后再执行任务。另一方面，在编写任务的过程中也会经常用到 Jinja2 来实现一些需求。所以，Jinja2 可以重要到成为 Ansible 的命脉。
严格地说，playbook 中所有地方都使用了 Jinja2，包括几乎所有指令的值、template 模板文件、copy 模块的 content 指令的值、lookup 的 template 插件、等等。它们会先经过 Jinja2 渲染，然后再执行相关任务。
例如，下面的 playbook 中分别使用了三种 Jinja2 特殊符号。</description></item><item><title>Variable</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Variable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Variable/</guid><description>概述 参考：
Wiki, Variable_(computer_science) 在计算机编程中，Variable(编程) 是一个抽象的存储位置，与一个相关的符号名称配对，变量中包含一些称为 Value(值) 的已知或未知数量的信息。或者可以说，变量是一个有名字的容器，用于存放特定 Data Type(数据类型) 的数据。
变量是一个可以改变内容的固定规定，比如我定义“这台电脑的名字”叫“XXX”，“这台电脑的名字”就是不变的内容，“XXX”就是可以改变的内容，给不变的内容定义不同的内容
比如 X=1，X=2，X=3 等等，X 就是不变的，1，2，3 等等都是可变的，X 就是一个变量，可以被赋予某些内容 环境变量就是在当前环境下所定义的内容，比如 linux 启动了一个 shell，在 shell 这个环境下，有一些规定被定义了，这些规定就是环境变量；不在这个 shell 下变量就不生效 比如：LANG 是一个语言的规定，你赋予他一个内容，就相当于定义了这个 shell 环境下所显示的语言，比如 LANG=US，LANG=CN 等等。LANG 这叫定义语言，这是不变的，可变的是后面的自定义内容，语言(不变)=英语、汉语、日语(可变)。</description></item><item><title>WebAssembly</title><link>https://desistdaydream.github.io/docs/Web/WebAssembly/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/WebAssembly/</guid><description>概述 参考：
官网 MDN，WebAssembly Go WebAssembly (Wasm) 简明教程
可能是世界上最简单的用 Go 来写 WebAssembly 的教程
生来取代Docker、JS，这项技术发布7年后，现状如何？
公众号 - k8s技术圈，在 Kubernetes 上使用 WebAssembly: 从容器到 Wasm
公众号，组件和容器之争？｜WebAssembly + Kubernetes：云原生的新组合
WebAssembly 文本格式 https://developer.mozilla.org/en-US/docs/WebAssembly/Understanding_the_text_format
WebAssembly 工具 GitHub 项目，webassembly/wabt # WebAssembly Binary Toolkit(WebAssembly 二进制工具包，简称 wabt)。
该工具可以将 wasm 文本格式转为二进制格式、wasm 二进制格式转为 c 代码、etc.</description></item><item><title>在线热迁移</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%81%E7%A7%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%81%E7%A7%BB/</guid><description>概述 参考：
Libvirt 文档，Guest 迁移 客人在主机之间迁移是一个复杂的问题，有许多可能的解决方案，每种解决方案都有自己的优点和缺点。为了实现虚拟机管理程序集成和管理员部署的最大灵活性，libvirt 实现了多种迁移选项。
手动迁移示例 拷贝如下几个文件
/var/lib/libvirt/images/ 目录中的 qcow2 文件 /etc/libvirt/qemy/ 目录中的 xml 文件 /var/lib/libvirt/qemu/snapshot/ 目录中的以 VM 命令的 snapshot 目录 使用 virsh define XXX.xml 命令创建虚拟机
使用 virsh snapshot-create --redefine --xmlfile XXX.xml DOMAIN 命令为虚拟机还原快照的元数据
也可以在 define 虚拟机后，再将 snapshot/ 目录下目录拷贝过来，也是可以识别到的。之所以要 define 后再拷贝，是因为 define 时将会清空 snapshot/${VM_NAME}/ 目录。 KVM 实现虚拟机在线热迁移 参考：
51CTO，KVM 实现虚拟机在线热迁移 KVM 虚拟机的迁移有两种方法：
静态迁移（冷迁移）：对于冷迁移，就是在虚拟机关闭状态下，将虚拟机的磁盘文件及.xml 配置文件（这两个文件组成了一个虚拟机）复制到要迁移到的目标主机上，然后在目标主机上使用“virsh define *.xml”命令重新定义虚拟机即可。 动态迁移（热迁移）：对于热迁移，比较常用，通常是这台服务器上正在跑着一些业务，而这些业务又不允许中断，那么就需要使用热迁移了，这篇博文将详细写出热迁移的步骤。 1、冷迁移
通常我们存放虚拟机磁盘的目录都是挂在的一个 nfs 文件系统的磁盘，而这个磁盘通常是 LVM 文件系统。所以需要进行冷迁移时，只要在目标主机上挂载这个 nfs 文件系统，就可以看到要迁移的那个虚拟机的磁盘文件，通常以.qcow2 或.raw 结尾的，然后，只需将虚拟机的.xml 配置文件发送到目标服务器上，然后重新定义一下即可通过“virsh list &amp;ndash;all”命令查看到迁移过来的虚拟机。</description></item><item><title>Alerting</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Alerting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Alerting/</guid><description>概述 参考：
官方文档，告警 - 告警概述 官方文档，告警 - 客户端 OpenAPI Prometheus 本身不提告警的通知的功能！告警能力在 Prometheus 的架构中被划分成两个独立的部分。如下所示，通过在 Prometheus 中定义 AlertRule（告警规则），Prometheus 会周期性的对告警规则进行 Evaluate(评估)，如果满足告警触发条件就会向 Alertmanager 发送告警信息。
Prometheus 推出的 Alertmanager 作为一个独立的组件，可以实现告警管理功能，负责接收并处理来自 Prometheus Server(也可以是其它的客户端程序) 的告警信息。Alertmanager 可以对这些告警信息进行进一步的处理，比如当接收到大量重复告警时能够消除重复的告警信息，同时对告警信息进行分组并且路由到正确的通知方，Alertmanager 内置了对邮件，Slack 等多种通知方式的支持。同时 AlertManager 还提供了静默和告警抑制机制来对告警通知行为进行优化。
Evaluate(评估) 就是指，Prometheus Server 会定期执行规则配置文件中的 PromQL，获得结果并与阈值进行匹配，当超过设置的阈值时，会产生告警。这个过程，就称为 Evaluate(评估)。在代码中，通过 Eval() 方法来评估规则。 Alertmanager 处理客户端应用程序(如 Prometheus Server)发送的警报。它负责对它们进行重复数据删除，分组和路由，以及正确的接收器集成，例如 email，PagerDuty 或 OpsGenie。它还负责警报的静音和抑制。
即：Prometheus Server 只负责根据 PromQL 语句定义的规则产生告警并发送给 Alertmanager(告警管理器)。
注意：
Alertmanager 是一个单独的程序，需要独立安装使用 Alertmanager 既可以描述为一类具有处理告警功能的应用程序。也可以描述为一个 Prometheus 官方推出的名为 Alertmanager 的程序。以后的描述一般都不加区分 关联 Alertmanager 与 Prometheus 由于 Alertmanager 与 Prometheus 是两个程序。所以需要修改 Prometheus Server 的配置文件，以便让自己产生的告警可以发送到正确地方，配置效果如下（Prometheus 推出的 Alertmanager 默认监听在 9093 端口上）</description></item><item><title>Arrays AND Slices</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Arrays-AND-Slices/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Arrays-AND-Slices/</guid><description>概述 Array(数组) 与 Slice(切片)
Array(数组) 参考：
Go 语言之旅，Arrays Array(数组) 是具有相同的唯一类型的一组 已编号、且长度固定 的数据项序列。每个数据项称为 element(元素)、长度指的是元素的个数、编号指每个元素的 index(索引)，索引号从 0 开始。
[n]T 用以表示一个数组，该数组包含 n 个 T 类型的值。
Array 的声明 var ArrayID [LENGTH]TYPE ArrayID # 标识符(i.e.数组的名字) LENGTH # 数组长度(i.e.元素的个数) TYPE # 每个元素的数据的类型。 **[ ]** # 括号是数组类型的标识符，不要忘记写。 比如：var arr [10]int这定义了一个名为 arr 的数组，这个数组由 10 个 int 类型的数据组成。简化点的口头语，声明了一个长度为 10 的整形数组。
Array 的赋值 arr[0] = &amp;quot;Hello&amp;quot; 为数组的 0 号元素赋值。
Array 的实例化 数组声明后，默认初始化每个元素的值为 0，后续可以对每个元素进行赋值。数组可以有两种初始化方式
每次对一个元素进行赋值，一般使用循环来实现 使用{}大括号，直接对数组进行初始化 e.g.var arr = [5]int{1,5,23,2,10} Array 的引用 引用数组的长度 len(MapID) 使用 len() 函数，括号内为数组标识符。数组的长度也就是元素的数目，必须是固定的并且在声明该数组时就给出，数组长度最大为 2Gb。格式为 len(ARRAYS) len 是 length 的缩写，ARRAYS 是数组变量的名称。</description></item><item><title>Conditionals(条件判断)</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Conditionals%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Conditionals%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/</guid><description>概述 参考：
官方文档，用户指南 - 传统目录 - 条件 通常，play 的结果可能取决于 variable，fact（有关远程系统的知识）或先前的任务结果。在某些情况下，变量的值可能取决于其他变量。可以基于主机是否符合其他条件来创建其他组来管理主机。
Ansible 在条件中使用 Jinja 的 测试 和 过滤器来实现条件判断。详见 Ansible Template 文章中《Ansible 扩展测试函数》章节
基于变量的条件 https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_conditionals.html#conditionals-based-on-variables
您还可以根据剧本或库存中定义的变量创建条件。由于条件需要布尔值输入（必须评估测试以触发条件），因此您必须应用| Bool过滤到非树状变量，例如带有“是”，“ ON”，“ 1”或“ TRUE”的内容的字符串变量。您可以定义这样的变量：
vars: epic: true monumental: &amp;#34;yes&amp;#34; 对于上面的变量，Ansible将运行其中一个任务并跳过另一个任务：
tasks: - name: Run the command if &amp;#34;epic&amp;#34; or &amp;#34;monumental&amp;#34; is true ansible.builtin.shell: echo &amp;#34;This certainly is epic!&amp;#34; when: epic or monumental | bool - name: Run the command if &amp;#34;epic&amp;#34; is false ansible.builtin.shell: echo &amp;#34;This certainly isn&amp;#39;t epic!</description></item><item><title>Control structure</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Control-structure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Control-structure/</guid><description>概述 参考：
Wiki, Control_flow Control structure(控制结构) 有的时候也称为 Control flow(控制流)，在计算机科学中是指，执行或评估命令时程序的各个语句、指令、函数的调用顺序。对显式控制流的强调将命令式编程与声明式编程区分开来。
选择 if else
switch case
循环 Loop(循环)
Recurise(递归)
Iterative(迭代)
Traversal(遍历)
结构化的非局部控制流 异常处理 延续 异步 协程 Coroutines(协程)</description></item><item><title>Docker Runtime</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Runtime/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Runtime/</guid><description>概述 参考：
官方文档，引擎 - 替换 runtime Docker Runtime 和 Docker Image 一样，也有标准，也由 OCI 维护，官方详解地址为：runtime-spec。Docker 默认使用 Containerd 来控制 Container 的配置、执行环境和生命周期，包括创建、启动和停止容器。Containerd 默认使用 runc 作为其容器运行时。
容器的配置被指定为 config.json ，并详细说明了可以创建容器的字段。指定执行环境是为了确保容器内运行的应用程序在运行时之间具有一致的环境，以及为容器的生命周期定义的常见操作。
runtime 规范有如下几个，所有人必须遵守该规范来使用 runtime 。
Filesystem Bundle # 文件系统捆绑。bundle 是以某种方式组织的一组文件，包含了容器所需要的所有信息，有了这个 bundle 后，符合 runtime 标准的程序(e.g.runc)就可以根据 bundle 启动容器了(哪怕没有 docker，也可以启动一个容器)。 Runtime and Lifecycle # Linux-specific Runtime and Lifecycle # 这是关于 linux 平台的 Runtime 与 Lifecycle Configuration # Configuration 包含对容器执行标准操作(比如 create、start、stop 等)所必须的元数据。这包括要运行的过程、要注入的环境变量、要使用的沙盒功能等等。不同平台(linux、window 等)，有不同的规范。 Linux-specific configuration # 这是关于 linux 平台的 Configuration Docker create 有了 image 之后，就可以使用 image 来创建并启动 container 了。</description></item><item><title>KVM/QEMU 运行时管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
KVM/QEMU 通过 qemu-system 命令行工具管理虚拟机运行时</description></item><item><title>Network tap</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Network-tap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Network-tap/</guid><description>概述 参考：
Wiki, Network tap Network tap(网络分流器) 是一种通过类似 Port mirroring 技术实现的流量监听方式。实现了 Network tap 能力的硬件设备可以用来监视本地网络上的事件。Network tap 设备一般至少有 3 个端口：A 端口、B 端口、monitor(监听) 端口。Network tap 可以让数据在 A 与 B 之间的传输实时无阻碍得通过，同时还将相同的数据复制到 monitor 端口，从而使得第三方分析数据。
[!tips] tap 本身有窃听的意思，Network tap 本质上可以算是 网络窃听器、网络监听器。厂商们为了更好的售卖产品而美化了该词的含义，而且也根据 Tap 设备具体的功能（复制流量分到另一个端口就相当于分流了），把 tap 的含义改为了分流。还扩展了一下 tap 这个词成 terminal access point(终端接入点)
Network tap 在狭义上通常只有 1 分 多 的能力，适用在简单的流量不大的网络环境中，若是在流量巨大且复杂的网络中，想实现 多 分 多的能力（汇聚与分流），则需要使用 Network packet broker 技术。
Network tap 与 Network packet broker Network tap 通常是在小流量场景中串接进链路中；而 Network packet broker 则通常是在大流量、复杂的网络场景中，并接到链路上。</description></item><item><title>Optical amplifier</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Optical-amplifier/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Networking-device/Optical-amplifier/</guid><description>概述 参考：
Optical amplifier(光放大器) 是直接放大光信号的设备，无需先将其转换为电信号。光放大器可以被认为是没有光腔的激光器，或者是来自腔的反馈被抑制的激光器。光放大器在光通信和激光物理学中非常重要。它们被用作长距离光缆中的光中继器，这些光缆承载着世界上大部分的电信链路。</description></item><item><title>Storage Virtualization</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Storage-Virtualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Storage-Virtualization/</guid><description>概述 参考：
Wiki, Storage_virtualization 存储虚拟化(I/O) KVM 模式的存储虚拟化 第一种：存储虚拟化是通过存储池（Storage Pool）和卷（Volume）来管理的 Storage Pool 是宿主机上可以看到的一片存储空间，可以是多种类型。 文件目录类型的 Storage Pool 。KVM 将宿主机目录 /var/lib/libvirt/images/ 作为默认的 Storage Pool。 KVM 将 HOST 目录 /var/lib/libvirt/images/ 作为默认的 Storage Pool KVM 所有可以使用的 Storage Pool 都定义在宿主机的 /etc/libvirt/storage 目录下，每个 Pool 一个 xml 文件，默认有一个 default.xml LVM 类型的 Storage Pool。宿主机上 VG 中的 LV 也可以作为虚拟磁盘分配给虚拟机使用。不过，LV 由于没有磁盘的 MBR 引导记录，不能作为虚拟机的启动盘，只能作为数据盘使用。 KVM 还支持 iSCSI，Ceph 等多种类型的 Storage Pool，最常用的就是目录类型，其他类型可以参考文档http://libvirt.org/storage.html Volume 是在 Storage Pool 中划分出的一块空间，宿主机将 Volume 分配给虚拟机，Volume 在虚拟机中看到的就是一块硬盘。Volume 是 Storage Pool 目录下面的文件，一个文件就是一个 Volume(使用文件做 Volume 有很多优点：存储方便、移植性好、可复制)。Volume 分为几种类型，类型如下 qcow2 # 是推荐使用的格式，QEMU V2 磁盘镜像格式，cow 表示 copy on write，能够节省磁盘空间，支持 AES 加密，支持 zlib 压缩，支持多快照，功能很多。 raw # 是默认格式，即原始磁盘镜像格式，移植性好，性能好，但大小固定，不能节省磁盘空间。 vmdk # 是 VMWare 的虚拟磁盘格式，也就是说 VMWare 虚机可以直接在 KVM 上 运行。</description></item><item><title>stream 模块指令</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/stream-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/stream-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
org 官方文档， stream core 模块 官方文档，管理指南-负载均衡-TCP 与 UDP 负载均衡 stream 模块及其子模块通过 stream {} 配置环境中的指令控制行为
简单的 stream{} 配置环境示例 stream { upstream stream_backend { least_conn; server backend1.example.com:12345 weight=5; server backend2.example.com:12345 max_fails=2 fail_timeout=30s; server backend3.example.com:12345 max_conns=3; } upstream dns_servers { least_conn; server 192.168.136.130:53; server 192.168.136.131:53; server 192.168.136.132:53; } server { listen 12345; proxy_pass stream_backend; proxy_timeout 3s; proxy_connect_timeout 1s; } server { listen 53 udp; proxy_pass dns_servers; } server { listen 12346; proxy_pass backend4.</description></item><item><title>Federate(集群联邦)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Federate%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Federate%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6/</guid><description>概述 参考：
官方文档，Prometheus - 联邦 通过 Remote Storage 可以分离监控样本采集和数据存储，解决 Prometheus 的持久化问题。这一部分会重点讨论如何利用联邦集群特性对 Promthues 进行扩展，以适应不同监控规模的变化。
Prometheus Federate 还可以充当代理功能，让 Prometheus Server 获取无法直接访问网段的 Metrics
使用联邦集群 对于大部分监控规模而言，我们只需要在每一个数据中心(例如：EC2 可用区，Kubernetes 集群)安装一个 Prometheus Server 实例，就可以在各个数据中心处理上千规模的集群。同时将 Prometheus Server 部署到不同的数据中心可以避免网络配置的复杂性。
如上图所示，在每个数据中心部署单独的 Prometheus Server，用于采集当前数据中心监控数据。并由一个中心的 Prometheus Server 负责聚合多个数据中心的监控数据。这一特性在 Promthues 中称为联邦集群。
联邦集群的核心在于每一个 Prometheus Server 都包含额一个用于获取当前实例中监控样本的接口/federate(用于 web 打开 localhost:9090/federate 即可，初始是空白的，需要详细指明要匹配的内容，才可以获取 metrics)。对于中心 Prometheus Server 而言，无论是从其他的 Prometheus 实例还是 Exporter 实例中获取数据实际上并没有任何差异。其实其他的 promeheus 就相当于中心 prometheus 的一个 exporter
scrape_configs: - job_name: &amp;#34;federate&amp;#34; scrape_interval: 15s honor_labels: true metrics_path: &amp;#34;/federate&amp;#34; params: &amp;#34;match[]&amp;#34;: - &amp;#39;up{job=~&amp;#34;external.</description></item><item><title>Function</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Function/</guid><description>概述 参考：
Function(函数)
DRY 原则：Don&amp;rsquo;t Repeart Yourself(不要重复你自己)
Golang 有 3 种类型的函数：
普通的带有名字的函数 匿名函数或者 lambda 函数 Methods(方法) 除了 main()、init()函数外，其余所有类型的函数都可以有参数与返回值。函数参数、返回值以及它们的类型统称为函数签名。 Function 的声明 func FunctionName([Parameter]) [(ReturnValue)] { 代码块 } () 里的 Parameter 以及 returnValue 可以省略，但是至少要包含一个()，哪怕这个小括号内没有任何内容。i.e.一个函数可以没有参数，与返回值，仅仅执行本身所提供的功能 Parameter(形式参数) # 这是一个参数列表，包括参数名以及参数类型。参数一般情况是变量、或者另一个函数(这个函数也可以当做变量来使用，是函数类型的变量，在调用时，可以通过实参改变该函数)。 ReturnValue(返回值) # 同样包括参数名以及参数类型，参数一般是变量。可以直接定义变量名与类型，也可以省略变量名直接指明返回值的类型 其中 Parameter 与 returnValue 都是可省的，最简化的定义格式为 function Name(){} Function 的调用 调用函数 就是指 使用函数
格式为：
[Pack.]Function([ARG1, ARG2, ..., ARGn])
其中 Pack 与 ARG 都是可省的，若在同一个包中，则 Pack 可省，若不用传递参数，则 ARG 可省。
包名.函数名(实际参数)。Function是Pack包里的一个函数，括号里的是被调用函数的实参，这些实参的值被传递给被调用函数的形参，参数的传递是一一对应的，第一位传递给第一位，第二位传递给第二位，以此类推。在引用的时候参数可省略为空，但是括号必须要有
actual parameter(实际参数，简称 实参) # 一般用 arguments 表示，在调用函数时使用实参 formal parameter(形式参数，简称 形参) # 一般用 parameter 表示，在定义函数时使用形参 注意：</description></item><item><title>loop(循环)</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/loop%E5%BE%AA%E7%8E%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/loop%E5%BE%AA%E7%8E%AF/</guid><description>概述 参考：
官方文档，用户指南 - 传统目录 - Loops 有时需要重复执行多次任务。在计算机编程中，这称为循环。常见的 Ansible 循环包括使用文件模块更改多个文件和/或目录的所有权，使用用户模块创建多个用户以及重复轮询步骤直到达到特定结果。Ansible 提供了两个用于创建循环的关键字：loop 和 with_XX
with_XX 关键字依赖于 Lookup Plugins(Lookup 插件)。其中 根据插件的不同功能，使用不同的字符串。e.g.with_items 也是 Lookup 插件。 插件的介绍详见：Ansible Plugins loop 关键字与 with_list 等效，是简单循环的最佳选择 循环的简单样例 下面展示了循环的基本功能：通过 loop 或者 with_*来对一个列表中的值逐一操作
- name: 添加几个用户。循环的基本使用方式 user: name: &amp;#34;{{ item }}&amp;#34; state: present loop: - testuser1 - testuser2 等同于
- name: 添加几个用户。先赋值给一个变量，然后在loop关键字中引用变量。 vars: users: [testuser1, testuser2] user: name: &amp;#34;{{ item }}&amp;#34; state: present loop: &amp;#34;{{ users}}&amp;#34; 上述示例与下面的任务相同。这就相当于将两个任务模块相同但是操作内容不同的任务合并成为一个任务
- name: 添加testuser1用户 user: name: &amp;#34;testuser1&amp;#34; state: present - name: 添加testuser2用户 user: name: &amp;#34;testuser2&amp;#34; state: present 从示例可以看出，循环是使用两个部分来组成整个循环的功能</description></item><item><title>Network packet broker</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Network-Packet-Broker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/Network-Packet-Broker/</guid><description>概述 参考：
Wiki, Data monitoring switch 知乎，什么是TAP分流器/交换机，有哪些品牌 Network Packet Broker(网络数据包代理，简称 NPB) 是一种比 Network tap 更强大的流量处置技术，实现了 NPB 的设备接收来自大量链路上的流量，将其汇聚在设备内部处理（e.g. 过滤、etc.）后，再将流量分发给另一侧的其他设备。这种行为也可以称为汇聚分流，对应的，实现了 NPB 的设备可以称为 汇聚分流设备。
Network tap 通常只能是 1 对 2 让流量复制一份；而 NPB 可以实现 1 对 多，多 对 多，且除了基本的窃听流量（i.e. 复制流量）功能外，还可以实现多种多样的流量处理能力
还有一些词汇也是用来描述实现 NPB 功能的设备：Data monitoring switch(数据监控交换机)、Data access switch(数据访问交换机)、Tool aggregator(工具聚合器)、Net tool optimizer(网络工具优化器)、Distributed filter tap(分布式过滤器)、Network Traffic Aggregator(网络流量聚合器)、Aggregation Taps(聚合)
NPB 设备通常是作为 旁路设备 以 并接 的方式接入到主链路中，接收的是来自 DPI、其他 NPB 设备、etc. 的流量。
NPB 内部的核心能力是对来自多条链路的流量实现了 同源同宿，保证多条链路的流量不会混乱。NPB 对接收到的大量流量进行汇聚、过滤、分发，NPB 并不需要串联进进链路中执行具体的像安全设备似的丢弃报文、阻断流量相关的任务。主要是基于如下需求产生的
汇聚分流 参考：
知乎，TAP交换机初探 知乎，谈谈TAP交换机的架构 TAP 交换机其实不是一个合适的叫法，但行业内大部分人都习惯于这个叫法。并且，在国内它还有很多其他叫法，比如：镜像交换机、TAP分流器、流量分流器、流量汇聚分流器、NPB、TAP 等等，一般情况之下，讲的是同一个东西。实际上，这个玩意是从国外传到国内的，由于语言上、理解上、厂商引导上的差异，造成了国内多种不同的叫法。</description></item><item><title>克隆与批量创建虚拟机</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%85%8B%E9%9A%86%E4%B8%8E%E6%89%B9%E9%87%8F%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%85%8B%E9%9A%86%E4%B8%8E%E6%89%B9%E9%87%8F%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA/</guid><description>概述 参考：
https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/virtualization_deployment_and_administration_guide/cloning-a-vm 注意：CentOS7 想要挂载 Ubuntu 20.04 虚拟机内的文件是不行的，内核不支持，报错如下：
~]# guestmount --rw -a /var/lib/libvirt/images/common-ubuntu-test.bj-test.qcow2 -m /dev/ubuntu-vg/lv-0 /mnt/test libguestfs: error: mount_options: mount exited with status 32: mount: wrong fs type, bad option, bad superblock on /dev/mapper/ubuntu--vg-lv--0, missing codepage or helper program, or other error In some cases useful info is found in syslog - try dmesg | tail or so. guestmount: ‘/dev/ubuntu-vg/lv-0’ could not be mounted. guestmount: Did you mean to mount one of these filesystems?</description></item><item><title>其他属于 NGX_CORE_MODULE 类型的模块</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%85%B6%E4%BB%96%E5%B1%9E%E4%BA%8E-NGX_CORE_MODULE-%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%85%B6%E4%BB%96%E5%B1%9E%E4%BA%8E-NGX_CORE_MODULE-%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%A8%A1%E5%9D%97/</guid><description>NGX_CONF_MODULE inclue 语法：include /PATH/FILE http://nginx.org/en/docs/ngx_core_module.html#include
在该配置中包含一个网站-可用的配置文件，即把定义的文件内容引入到这里，(也可以写入多个 include，引入多个配置文件以便管理，包括但不限于 server 配置，还可以是 nginx 的配置文件，mail 的配置文件等)
作用范围：可以作用在任意 Contexts 中 该指令可以写在任意 块指令 中，只要被包含的文件格式，符合当前 块指令 应该包含的语法即可。</description></item><item><title>Ansible 命令行工具</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，用户指南 - 命令行工具 官方文档，用户指南 - 传统目录 - 临时命令简介 由于 Ansible 是基于 SSH 远程管理主机，所以让 Ansible 的控制节点需要对受管理节点进行 ssh 的基于密钥的认证(方法详见 ssh 命令)或者在 inventory 文件中指定认证方式。
Note：Ansible 的控制节点和受管理节点的 Python 版本需要一致，否则 ansible 命令有时候会执行失败
ansible 参考：
官方文档，用户指南 - 使用命令行工具工作 - ansible ansible 是 Ansible 的一个 ad-hoc(临时) 命令，可以在一个或多个受管理节点上自动执行单个任务。ansible 命令即简单又快速，但并不具备可重复性，通过 ansible 命令的使用，我们可以了解到 Ansible 的简单性和强大的功能。并且，可以将类似的操作，直接移植到 Playbooks 中。
临时命令非常适合很少重复，但是又需要大批量执行的任务，比如重启服务器、复制文件、管理服务、管理用户 等等。我们可以在临时任务中使用所有 Ansible 模块
Syntax(语法) ansible &amp;lt;HostPattern&amp;gt; [OPTIONS]
HostPattern # 主机模式,可以是主机名，主机 IP，组名，还有一个 all(所有 hosts 里定义的主机) OPTIONS &amp;ndash;list-hosts # 列出所有 HostPattern 定义的被管理 host 并统计数量，一般用于查看组内的主机有多少 -i, &amp;ndash;inventory, &amp;ndash;inventory-file INVENTORY # 指定具体的 INVENTORY 路径或文件，而不使用配置中默认的。 INVENTORY 可以是 目录、文件、逗号分割的 IP 列表。 可以使用 -i 192.</description></item><item><title>Go 单元测试</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</guid><description>概述 参考：
1 如何写好单元测试 单元测试(Unit Tests, UT) 是一个优秀项目不可或缺的一部分，特别是在一些频繁变动和多人合作开发的项目中尤为重要。你或多或少都会有因为自己的提交，导致应用挂掉或服务宕机的经历。如果这个时候你的修改导致测试用例失败，你再重新审视自己的修改，发现之前的修改还有一些特殊场景没有包含，恭喜你减少了一次上库失误。也会有这样的情况，项目很大，启动环境很复杂，你优化了一个函数的性能，或是添加了某个新的特性，如果部署在正式环境上之后再进行测试，成本太高。对于这种场景，几个小小的测试用例或许就能够覆盖大部分的测试场景。而且在开发过程中，效率最高的莫过于所见即所得了，单元测试也能够帮助你做到这一点，试想一下，假如你一口气写完一千行代码，debug 的过程也不会轻松，如果在这个过程中，对于一些逻辑较为复杂的函数，同时添加一些测试用例，即时确保正确性，最后集成的时候，会是另外一番体验。
如何写好单元测试呢？
首先，学会写测试用例。比如如何测试单个函数/方法；比如如何做基准测试；比如如何写出简洁精炼的测试代码；再比如遇到数据库访问等的方法调用时，如何 mock。
然后，写可测试的代码。高内聚，低耦合是软件工程的原则，同样，对测试而言，函数/方法写法不同，测试难度也是不一样的。职责单一，参数类型简单，与其他函数耦合度低的函数往往更容易测试。我们经常会说，“这种代码没法测试”，这种时候，就得思考函数的写法可不可以改得更好一些。为了代码可测试而重构是值得的。
接下来将介绍如何使用 Go 语言的标准库 testing 进行单元测试。
2 一个简单例子 Go 语言推荐测试文件和源代码文件放在一块，测试文件以 _test.go 结尾。比如，当前 package 有 calc.go 一个文件，我们想测试 calc.go 中的 Add 和 Mul 函数，那么应该新建 calc_test.go 作为测试文件。
example/ |--calc.go |--calc_test.go 假如 calc.go 的代码如下：
package main func Add(a int, b int) int { return a + b } func Mul(a int, b int) int { return a * b } 那么 calc_test.go 中的测试用例可以这么写：</description></item><item><title>HTTPS 和 Authentication</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/HTTPS-%E5%92%8C-Authentication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/HTTPS-%E5%92%8C-Authentication/</guid><description>概述 参考：
官方文档，Prometheus - 配置 - HTTPS 和 认证 官方文档，指南 - 基础认证 Ngxin Ingress Controller 官方文档，认证-基础认证 知乎 认证功能的发展：
Prometheus 从 2.24 版本开始，才支持基本认证，截止 2021 年 8 月 25 日官方已经提供了实验性的 HTTPS 与 认证配置，详见此处。 截止 2021 年 8 月 25 日，Thanos 的 Sidecar 还不支持向 Prometheus 发起请求是携带认证信息，但已经有 issue #3975 提出来该问题，并将在未来 PR #4104 实现 现阶段在 Prometheus 前面添加代理(比如 Nginx)，只暴露 Nginx 端口，所有访问 Prometheus 的请求都经过代理，并在代理上添加认证，这样可以为 Prometheus 的 web 端添加一个基本的基于用户名和密码的认证。
在 kubernetes 中，可以通过 ingress 来实现。其他环境可以直接配置 ngxin 来实现。
通过 ingress controller 配置认证，普通的 nginx 同理 首先需要安装 htpasswd 二进制文件，通过 htpasswd 命令行工具生成保存用户名密码的文件，然后通过该文件创建一个 secret 对象，并在 ingress 引用该 secret 对象</description></item><item><title>Pointer</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Pointer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Pointer/</guid><description>概述 参考：
Go 官方文档，参考 - 指针类型 在 Go 语言中，Pointer(指针) 可以有两种含义：
通过 &amp;amp; 符号获取一个变量的内存地址，即指针。通常使用十六进制数表示。这种方式称为指针引用 指针也可以表示一种数据类型。可以声明一个指针类型的变量，用以存储内存地址。 一个指针变量可以指向任何一个值的内存地址。这个内存地址，在 32 位机器上占用 4 个字节，在 64 位机器上占用 8 个字节，并且与其所指向的值得的大小无关。 在 Go 语言中，不能进行指针运算。
指针的引用 每一个变量都有指针，我们可以通过 &amp;amp; 符号引用该变量的指针，也就是获取该变量的内存地址。
我们平时说引用指针，并不是引用指针类型的变量，指针类型的变量也是一种变量，正常使用变量名称即可引用。
这里说要说的指针的引用是指引用一个变量的内存地址，即变量的指针 **格式：**在变量名称前加上 &amp;amp; 符号，即可获取该变量的内存地址，即该变量的指针。
&amp;amp;VarID 注意：若该变量的值为空，则该变量依然具有内存地址：
var a string fmt.Println(&amp;amp;a) 这将会输出：0xc000010250
指针变量的声明 格式：* 与 数据类型 的组合书写，即代表指针类型：
var VarID *TYPE 这里需要注意的是，当一个指针变量被声明后，它的值为nil，但是这个变量本身是具有指针的
func main() { // 声明一个 `字符串指针` 类型的变量 var VarID *string fmt.Println(VarID) fmt.Println(&amp;amp;VarID) } 输出结果：
&amp;lt;nil&amp;gt; 0xc000014088 一个指针类型的变量可以保存内存地址，同时自己也具有内存地址。
指针变量的赋值 格式：</description></item><item><title>错误处理</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</guid><description>概述 参考：
官方文档，用户指南 - 在 playbook 中的错误处理 忽略失败的任务(ignore_errors) 默认情况下，当任意目标机器上的任务结果失败时，Ansible 都会停止继续执行，我们可以通过 ignore_errors 关键字忽略错误，以便继续执行后续任务。 ignore_errors 指令仅在任务能够运行并返回“失败”值时起作用。它不会让 Ansible 忽略未定义的变量错误、连接失败、执行问题（例如，缺少包）或语法错误。
改变任务状态(failed_when 与 changed_when) Ansible 可以通过特定条件定义任务的执行状态，通过对 failed_when、changed_when 关键字指定的条件进行判断，用以定义 failed、changed、ok 等任务执行状态意味着什么。 failed_when
若结果为真，则任务执行结果变为 fatal 若结果为假，则任务执行结果变为 changed changed_when
若结果为真，则任务执行结果变为 changed 若结果为假，则任务执行结果变为 ok 比如，我们常用 shell 模块执行一些命令，而 shell 模块的任务状态总是 changed 的~~如果一个 shell 命令执行后，没有变化，我们想让他将任务状态设为 ok，就可以通过 changed_when 功能，比如现在有如下两个任务
- name: Changed_when 判断的结果为真时，任务状态为 changed shell: cmd: &amp;#34;docker start changed_when&amp;#34; register: is_started changed_when: &amp;#34;&amp;#39;changed_when&amp;#39; in is_started[&amp;#39;stdout&amp;#39;]&amp;#34; ignore_errors: true - name: Changed_when 判断的结果为假时，任务状态为 ok shell: cmd: &amp;#34;docker start changed_when&amp;#34; register: is_started changed_when: &amp;#34;&amp;#39;changed_when&amp;#39; in is_started[&amp;#39;stderr&amp;#39;]&amp;#34; ignore_errors: true - name: Failed_when 判断的结果为真时，任务状态为 failed shell: cmd: &amp;#34;docker start failed_when&amp;#34; register: is_started failed_when: &amp;#34;&amp;#39;failed_when&amp;#39; in is_started[&amp;#39;stdout&amp;#39;]&amp;#34; ignore_errors: true - name: Failed_when 判断的结果为假时，任务状态为 changed shell: cmd: &amp;#34;docker start failed_when&amp;#34; register: is_started failed_when: &amp;#34;&amp;#39;failed_when&amp;#39; in is_started[&amp;#39;stderr&amp;#39;]&amp;#34; ignore_errors: true 假设目标机器上已经有一个已经停止的，名为 test 的容器，则执行结果如下</description></item><item><title>时间管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Time-and-Language/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Time-and-Language/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
Time 管理
实现 NTP 协议的工具 ntpd # 在 centos8 中已不再支持，推荐使用新工具 Chrony 来实现 NTP 协议
Chrony # Chrony
date - 打印或设置系统日期和时间 参考：
Manual, date(1) Syntax(语法) date [OPTIONS]&amp;hellip; [+FORMAT]
可以通过 FORMAT 设置显示时间的格式
OPTIONS
-s # 从给定的字符串中设定时间。i.e. 设置时间 -d # 从给定的字符串中显示时间，而不是显示现在的时间。常用于判断给定的数字是否符合时间日期的格式 e.g. date -d 9999 +%H%M 不合法，date -d 1011 +%H%M 合法 FORMAT:
%F 年月日（等同于 %+4Y-%m-%d） %T 时分秒（等同于 %H:%M:%S） %Y 年 %m 月 %d 日 %H 小时 %M 分钟 %S 秒 %s # 从 1970-01-01 00:00:00 UTC 时间开始经过的秒。i.</description></item><item><title>Debugger</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Debugger/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Debugger/</guid><description>概述 参考：
官方文档，用户指南 - Debugging 任务 Ansible 提供了一个任务调试器，因此您可以在执行过程中修复错误，而不是编辑 playbook 并再次运行它以查看更改是否有效。您可以在任务上下文中访问调试器的所有功能。您可以检查或设置变量的值，更新模块参数，并使用新的变量和参数重新运行任务。调试器可让您解决故障原因并继续执行 playbook。
Enabling the debugger with thedebuggerkeyword You can use the debugger keyword to enable (or disable) the debugger for a specific play, role, block, or task. This option is especially useful when developing or extending playbooks, plays, and roles. You can enable the debugger on new or updated tasks. If they fail, you can fix the errors efficiently. The debugger keyword accepts five values:</description></item><item><title>GNU C Library 管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/GNU-C-Library-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/GNU-C-Library-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 CentOS 与 Ubuntu 中关于 Linux libc 库(glibc) 的管理工具包的名称不太一样
CentOS 为 glibc-common Ubuntu 为 libc-bin、libc-dev-bin ldd 这个命令可以显示一个可执行文件所使用的动态链接库。如：
~]# ldd /usr/bin/ls linux-vdso.so.1 (0x00007ffd37562000) libselinux.so.1 =&amp;gt; /lib/x86_64-linux-gnu/libselinux.so.1 (0x00007f76b6c46000) libc.so.6 =&amp;gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f76b6a54000) libpcre2-8.so.0 =&amp;gt; /lib/x86_64-linux-gnu/libpcre2-8.so.0 (0x00007f76b69c4000) libdl.so.2 =&amp;gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f76b69be000) /lib64/ld-linux-x86-64.so.2 (0x00007f76b6ca2000) libpthread.so.0 =&amp;gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f76b699b000) ldconfig lbconfig 是一个动态链接库的管理命令。可以创建必要的链接并缓存到指定文件中
关联文件与配置 /lib64/ld-linux.so # 运行时链接器/加载器
/etc/ld.so.conf # 从配置文件中指定的目录中搜索库
/etc/ld.so.conf.d/ # 从配置文件中指定的目录中搜索库
/etc/ld.so.cache # 搜索到的库列表被缓存到该文件中
Syntax(语法) OPTIONS
-p, &amp;ndash;print-cache # 输出当前系统已经加载的动态库</description></item><item><title>Map AND Struct</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Map-AND-Struct/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Map-AND-Struct/</guid><description>概述 参考：
官方文档，参考 - 规范 - Map 类型 官方文档，参考 - 规范 - Struct 类型 Map(映射) map 是 key-value pairs(键值对) 的无序集合。这种结构也称 关联数组(associative array)、字典(dictionary)、散列表/哈希表(hash table)。这是一种快速寻找值的理想结构：给定 Key，对应的 Value 可以迅速定位。
map 的声明 var MapID map[KeyType]ValueType map 的实例化 MapID = make(map[KeyType]ValueType) 赋值 MapID[KEY] = VAL 实例化的同时进行赋值 MapID := map[KeyType]ValType{ KEY_1:VAL_1, KEY_2:VAL_2, ..., KEY_n:VAL_n } 这相当于：
MapID := make(map[KeyType]ValueType) MapID[&amp;#34;KEY_1&amp;#34;] = &amp;#34;VALUE_1&amp;#34; MapID[&amp;#34;KEY_2&amp;#34;] = &amp;#34;VALUE_2&amp;#34; map 的引用 下面是引用 map 中指定 KEY 的 VALUE 的方法：
MapID[KEY] 引用 map 的长度 map 的长度指的是键值对的个数，有几个键值对，长度就是几</description></item><item><title>Playbook 命令行工具</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Playbook-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Playbook-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，用户指南 - 传统目录 - 使用命令行工具 - ansible-playbook ansible-playbook 用来运行运行 Ansible playbook，以便在目标主机上执行定义的任务。
ansible-playbook 运行 Ansible playbooks，并在目标主机上执行剧本中定义的任务
Syntax(语法) ansible-playbook [OPTIONS] PLAYBOOK
OPTIONS &amp;ndash;ask-vault-pass # ask for vault password &amp;ndash;become-method # privilege escalation method to use (default=%(default)s), use ansible-doc -t become -l to list valid choices. &amp;ndash;become-user # run operations as this user (default=root) -C, &amp;ndash;check # 使用检查模式执行任务。不在目标主机上执行任务，仅检查任务是否可以完成 Notes: 可以配置 check_mode 关键字让特定任务不受 -C 影响 -c, &amp;ndash;connection &amp;lt;CONNECTION&amp;gt; # 要使用的连接插件。默认值：smart 可以设置为 local 以便让 playbook 在本地执行而不用去远程机器上运行 &amp;ndash;flush-cache # clear the fact cache for every host in inventory &amp;ndash;force-handlers # run handlers even if a task fails -i, &amp;ndash;inventory, &amp;ndash;inventory-file # 指定 inventory 文件路径或者以逗号分隔的主机列表。(不推荐使用该选项) -l , &amp;ndash;limit &amp;lt;SUBSET&amp;gt; # 限定执行的主机范围。可以对一批主机的其中一台执行操作，但是依然可以使用其他主机的变量。further limit selected hosts to an additional pattern &amp;ndash;list-hosts # 列出执行该剧本所能匹配到的主机，但并不会执行 &amp;ndash;list-tags # 列出所有可用的 tags &amp;ndash;list-tasks # 列出所有即将被执行的任务 &amp;ndash;private-key , &amp;ndash;key-file # use this file to authenticate the connection &amp;ndash;scp-extra-args # specify extra arguments to pass to scp only (e.</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
QEMU 文档，系统模拟-介绍-运行 https://notes.wadeism.net/post/kvm-create-vm-clone-by-overlay/ 注意：本最佳实践仅适用于独立使用 qemu-img、qemu-system 等 KVM/QEMU 的命令行工具，不包括 libvirtd 的工具
QEMU 命令行的一般形式可以表示为：
$ qemu-system-x86_64 [machine opts] \ [cpu opts] \ [accelerator opts] \ [device opts] \ [backend opts] \ [interface opts] \ [boot opts] 在下面的示例中，我们首先定义一台机器，它是用于运行 Aarch64 来宾的通用平台。我们启用虚拟化，因此我们可以在模拟来宾中使用 KVM。由于机器带有一些内置的 pflash 设备，我们给它们命名，以便我们稍后可以覆盖默认值。virtvirt
$ qemu-system-aarch64 \ -machine type=virt,virtualization=on,pflash0=rom,pflash1=efivars \ -m 4096 \ 然后，我们使用为我们提供 QEMU 能够模拟的所有 Arm 功能的选项定义 4 个 vCPU。我们启用了更加仿真友好的 Arm 指针身份验证算法实现。我们明确指定 TCG 加速，即使 QEMU 无论如何都会默认为它。
-cpu max,pauth-impdef=on \ -smp 4 \ -accel tcg \ 由于平台没有任何默认网络或存储设备，我们需要定义它们。我们给他们 id 以便我们稍后可以将他们与后端链接。</description></item><item><title>Go 源码解析</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</guid><description>原文链接：https://mp.weixin.qq.com/s/5GabUkkgIyz7nJ33OjfBkw
本文使用 golang 1.17 代码，如有任何问题，还望指出。
Golang 代码被操作系统运行起来的流程 一、编译 go 源代码首先要通过 go build 编译为可执行文件，在 linux 平台上为 ELF 格式的可执行文件，编译阶段会经过编译器、汇编器、链接器三个过程最终生成可执行文件。
1、编译器：_.go 源码通过 go 编译器生成为 _.s 的 plan9 汇编代码，Go 编译器入口是 compile/internal/gc/main.go 文件的 main 函数； 2、汇编器：通过 go 汇编器将编译器生成的 _.s 汇编语言转换为机器代码，并写出最终的目标程序 _.o 文件，src/cmd/internal/obj 包实现了 go 汇编器； 3、链接器：汇编器生成的一个个 *.o 目标文件通过链接处理得到最终的可执行程序，src/cmd/link/internal/ld 包实现了链接器； 二、运行 go 源码通过上述几个步骤生成可执行文件后，二进制文件在被操作系统加载起来运行时会经过如下几个阶段：
1、从磁盘上把可执行程序读入内存； 2、创建进程和主线程； 3、为主线程分配栈空间； 4、把由用户在命令行输入的参数拷贝到主线程的栈； 5、把主线程放入操作系统的运行队列等待被调度执起来运行； Golang 程序启动流程分析 1、通过 gdb 调试分析程序启动流程 此处以一个简单的 go 程序通过单步调试来分析其启动过程的流程：
main.go
package main import &amp;#34;fmt&amp;#34; func main() { fmt.Println(&amp;#34;hello world&amp;#34;) } 编译该程序并使用 gdb 进行调试。使用 gdb 调试时首先在程序入口处设置一个断点，然后进行单步调试即可看到该程序启动过程中的代码执行流程。</description></item><item><title>Reflect</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Reflect/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Reflect/</guid><description>概述 参考：
Go 包，标准库 - reflect Go 博客，反射法则 博客园-Stefno，深度解密 Go 语言之反射 Reflection(反射) 是用程序检查其所拥有的结构，尤其是类型的一种能力。可以通过反射来分析一个结构体。反射可以在运行时检查类型和变量，例如它的大小、方法和动态的调用这些方法。
reflect.TypeOf() 和 reflect.ValueOf() 两个函数返回被检查对象的类型和值。e.g. var x float64 = 3.4, 那么 reflect.TypeOf(x) 返回 float64，reflect.ValueOf(x) 返回 3.4
忠告：反射是一个强大并富有表达力的工具，但是它应该被小心地使用，原因有三：
基于反射的代码是比较脆弱的。对于每一个会导致编译器报告类型错误的问题，在反射中都有与之相对应的误用问题，不同的是编译器会在构建时马上报告错误，而反射则是在真正运行到的时候才会抛出 panic 异常，可能是写完代码很久之后了，而且程序也可能运行了很长的时间。 即使对应类型提供了相同文档，但是反射的操作不能做静态类型检查，而且大量反射的代码通常难以理解。总是需要小心翼翼地为每个导出的类型和其它接受 interface{} 或 reflect.Value 类型参数的函数维护说明文档。 基于反射的代码通常比正常的代码运行速度慢一到两个数量级。对于一个典型的项目，大部分函数的性能和程序的整体性能关系不大，所以使用反射可能会使程序更加清晰。测试是一个特别适合使用反射的场景，因为每个测试的数据集都很小。但是对于性能关键路径的函数，最好避免使用反射。 什么是反射 反射和 Interface 息息相关，而 Interface 是我们上一篇文章的内容。在开始正文前，和大家说点题外话。
直接看维基百科上的定义：
在计算机科学中，反射是指计算机程序在运行时（Run time）可以访问、检测和修改它本身状态或行为的一种能力。用比喻来说，反射就是程序在运行的时候能够“观察”并且修改自己的行为。
那我就要问个问题了：不用反射就不能在运行时访问、检测和修改它本身的状态和行为吗？
问题的回答，其实要首先理解什么叫访问、检测和修改它本身状态或行为，它的本质是什么？
实际上，它的本质是程序在运行期探知对象的类型信息和内存结构，不用反射能行吗？可以的！使用汇编语言，直接和内层打交道，什么信息不能获取？但是，当编程迁移到高级语言上来之后，就不行了！就只能通过反射来达到此项技能。
不同语言的反射模型不尽相同，有些语言还不支持反射。《Go 语言圣经》中是这样定义反射的：
Go 语言提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法，但是在编译时并不知道这些变量的具体类型，这称为反射机制。
为什么要用反射 需要反射的 2 个常见场景：
有时你需要编写一个函数，但是并不知道传给你的参数类型是什么，可能是没约定好；也可能是传入的类型很多，这些类型并不能统一表示。这时反射就会用的上了。 有时候需要根据某些条件决定调用哪个函数，比如根据用户的输入来决定。这时就需要对函数和函数的参数进行反射，在运行期间动态地执行函数。 在讲反射的原理以及如何用之前，还是说几点不使用反射的理由：
与反射相关的代码，经常是难以阅读的。在软件工程中，代码可读性也是一个非常重要的指标。 Go 语言作为一门静态语言，编码过程中，编译器能提前发现一些类型错误，但是对于反射代码是无能为力的。所以包含反射相关的代码，很可能会运行很久，才会出错，这时候经常是直接 panic，可能会造成严重的后果。 反射对性能影响还是比较大的，比正常代码运行速度慢一到两个数量级。所以，对于一个项目中处于运行效率关键位置的代码，尽量避免使用反射特性。 反射是如何实现的 上一篇文章讲到了 interface，它是 Go 语言实现抽象的一个非常强大的工具。当向接口变量赋予一个实体类型的时候，接口会存储实体的类型信息，反射就是通过接口的类型信息实现的，反射建立在类型的基础上。</description></item><item><title>云厂商</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%82%E5%95%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%82%E5%95%86/</guid><description>阿里云 aliyun 命令行工具 参考：
关联文件与配置 ~/.aliyun/config.json # 包括认证信息等
Syntax(语法)</description></item><item><title>Generic</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Generic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Generic/</guid><description>概述 参考：
公众号-OSC 开源社区，使用 Go 泛型的最佳时机 公众号-OSC 开源社区，Go 语言之父介绍泛型 公众号-InfoQ，Go 中的泛型：激动人心的突破 Go 语言的 Generic(泛型) 让我们在定义接口、函数、结构体时将其中的类型参数化。我们从古老的 Ada 语言的第一个版本就开始使用泛型了，后来 C++ 的模板中也有泛型，直到 Java 和 C# 中的现代实现都是很常见的例子。
通过 类型参数，可以改变某个变量的类型。准确说是赋予某个变量类型，即 让一个变量从 泛型（宽泛的类型） 变为 定型（定义好的类型）。
泛型为 Go 添加了三个新的重要内容：
面向函数和类型的“类型形参” (type parameters) 将接口类型定义为类型集合，包括没有方法的接口类型 类型推断：在大多数情况下，在调用泛型函数时可省略“类型实参” (type arguments) 类型形参与约束 下面是一个初步理解泛型的最简单例子：
// 泛型 // 使用类型形参编写 Go 函数以处理多种类型 // comparable 是一个内置 Constraint(约束)，用来表示类型形参可以接收的类型实参的种类，所谓的“约束”就是指，T 被约束为可以使用哪几种类型。 // comparable 包含所有可以比较类型，包括：booleans、numbers、strings、pointers、channels、可比较的 arrays、structs 中的属性 // comparable 可以改为 any，表示 T 可以是任意类型 func Index[T comparable](s []T, x T) int { for i, v := range s { // 这里的 v 和 x 都是 T 类型 // 若上层调用时，传进来的 T 的约束类型为 string，则 s 和 x 也是 string 类型；若传进来的 T 的约束类型为 int，则 s 和 x 也是 int 类型 if v == x { return i } } return -1 } func main() { // Index() 函数适用于 int 类型的切片 si := []int{10, 20, 15, -10} fmt.</description></item><item><title>Library</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DPDK/DPDK-Library/</link><pubDate>Fri, 18 Apr 2025 18:24:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DPDK/DPDK-Library/</guid><description>概述 参考：
官方文档，开发者指南 - XXX 库 DPDK 的主要对外函数接口通常以 rte_(runtime environment) 作为前缀。
内存管理 Memory Pool Library etc. CPU 管理 etc. CPU 包处理 etc. Device Libraries etc. Protocol Processing Libraries etc. High-Level Libraries Graph Library etc. Utility Libraries Metrics Library Telemetry Library(遥测库) # 遥测库提供了一个接口，用于从各种 DPDK 库中检索信息。该库通过 Unix Socket 提供这些信息，接收来自客户端的请求，并回复包含所请求遥测信息的 JSON 响应。 etc. Telemetry Library 参考：
官方文档，开发者指南 - 遥测库 在 Telemetry Library 相关代码 telemetry_v2_init 进行初始化，注册了几个基本的命令（/, /info, /help）。其他注册的命令则需要到各种 Libraries 的代码中查看。可以通过搜索 init_telemetry 关键字找到各种 Library 注册到 Telemetry 的命令，比如 ethdev, mempool, etc.</description></item><item><title>Engine</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/Engine/</link><pubDate>Tue, 25 Mar 2025 12:47:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/Engine/</guid><description>概述 参考：
官方文档，SQL 参考 - 引擎 流式数据同步：一种PostgreSQL到ClickHouse的高效数据同步方案 Engine(引擎) 是 ClickHouse 实现数据处理功能的核心抽象。数据库 以及 表 都由各种各样的 Engine 实现
Database Engine(数据库引擎) Table Engine(表引擎) Database Engine Table Engine Table Engine(表引擎) 本质上是用来定义表的类型。ClickHouse 的表甚至可以通过 Engine 从其他数据库中读取数据（e.g. 直接读取 PostgreSQL 中某个表的数据）
Table Engine 可以决定：
How and where data is stored, where to write it to, and where to read it from. 数据如何存储、在何处存储、将其写入何处以及从何处读取。 Which queries are supported, and how. 支持哪些查询以及如何支持。 Concurrent data access. 并发数据访问。 Use of indexes, if present. 使用索引（如果存在）。 Whether multithread request execution is possible.</description></item><item><title>Tags</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Tags/</link><pubDate>Mon, 06 Jan 2025 22:09:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/Tags/</guid><description>概述 参考：
官方文档，执行 Playbooks - 标签 如果您有一个很大的剧本，则仅运行其中的特定部分而不是运行整个剧本可能会很有用。您可以使用 Ansible 标签来做到这一点。使用标签执行或跳过选定的任务是一个两步过程：
将标签添加到您的任务中，可以单独添加标签，也可以使用继承自 block、play、role 或 import 的标签 运行 playbook 时选择或跳过标签 继承 Tags https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_tags.html#tag-inheritance-for-includes-blocks-and-the-apply-keyword</description></item><item><title>ClickHouse MGMT</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/ClickHouse-MGMT/</link><pubDate>Sun, 05 Jan 2025 21:03:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/ClickHouse-MGMT/</guid><description>概述 参考：
官方文档，管理和部署 链接有点乱，官网页面关于这部分大改过。截至本文更新可以从页面的 Server Admin 点进来。 备份与恢复 参考：
官方文档，管理与部署 - 备份与恢复 GitHub 项目，AlexAkulov/clickhouse-backup</description></item><item><title>Vector Configuration</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/Vector/Vector-Configuration/</link><pubDate>Sun, 05 Jan 2025 15:55:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/Vector/Vector-Configuration/</guid><description>引言 官方文档的简单食用方式
在每个 Source 的文档中，可以在 Output Data 和 Examples 两个章节看到输出格式和输出内容。比如这种 Source 的日志都有什么元数据，输出格式是什么样的，etc. 。其中有些内嵌的隐藏字段以 _ 开头，可以这些输出的内容可以直接或利用模板使用在 sinks 的定义中。
用一个简单的 Linux 中的 Journal 日志采集输出到 Loki 的场景进行配置演示
sources: test_journald: type: journald sinks: test_loki: type: loki inputs: - test_journald endpoint: &amp;#34;http://localhost:3100&amp;#34; encoding: codec: raw_message labels: source_type: &amp;#34;{{ source_type }}&amp;#34; host: &amp;#34;{{ host }}&amp;#34; systemd_unit: &amp;#34;{{ _SYSTEMD_UNIT }}&amp;#34; 这个配置带有 {{ }} 的是模板语法，_SYSTEMD_UNIT 的值示例可以在 JournalD 文档的 Examples 看到；source_type 和 host 的值可以在文档的 Output Data 看到
概述 参考：</description></item><item><title>反思</title><link>https://desistdaydream.github.io/blog/%E5%8F%8D%E6%80%9D/</link><pubDate>Sat, 11 May 2024 15:02:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/%E5%8F%8D%E6%80%9D/</guid><description>概述 参考：
https://mp.weixin.qq.com/s/VQUEXNJCgj-ydH44QTpeBA
伟大的开发者，你们过得开心吗？
互联网做得太出色了，以至于很多人把它看作某种像太平洋一样的自然资源，而非人造的。—— Alan Kay.</description></item><item><title>ABI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/ABI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/ABI/</guid><description>概述 参考：
Wiki, Application binary interface https://www.jianshu.com/p/bd77c842f281 Application binary interface(应用程序二进制接口，简称 ABI) 是两个二进制程序模块之间的接口。通常，这俩模块一个是库或操作系统设施，另一个是用户运行的程序。
ABI 定义如何以机器代码访问数据结构或计算例程，这是一种低级、依赖于硬件的格式。相比之下，应用程序编程接口 (API) 在源代码中定义这种访问，这是一种相对高级、独立于硬件、通常是人类可读的格式。 ABI 的一个常见方面是调用约定，它确定如何将数据作为计算例程的输入提供或从计算例程读取数据。 x86 调用约定就是这样的示例。
保持一个稳定的 ABI 要比保持稳定的 API 要难得多。比如，在内核中 int register_netdevice(struct net_device *dev) 这个内核函数原型基本上是不会变的，所以保持这个 API 稳定是很简单的，但它的 ABI 就未必了，就算是这个函数定义本身没变，即 API 没变，而 struct net_device 的定义变了，里面多了或者少了某一个字段，它的 ABI 就变了，你之前编译好的二进制模块就很可能会出错了，必须重新编译才行。</description></item><item><title>Actions 配置</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Actions-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Actions-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
在每个仓库的 Setting 页面可以为仓库的 Actions 进行一些配置
Workflow 权限 有的 Action 要想正常运行，要保证 Workflow 使用的默认 GITHUB_TOKEN 具有对 Realease 的读写权限（比如 softprops/action-gh-release 需要将构建结果上传至 Release 中，这个属于写入操作）。可以在 https://github.com/${USER}/${REOP}/settings/actions 页面修改仓库的 Action 中关于 Workflow 的配置
Setting - Actions - General - Workflow permissions
参考: https://github.com/softprops/action-gh-release/issues/232#issuecomment-1375588379</description></item><item><title>AES</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/AES/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/AES/</guid><description>概述 参考：
Wiki, Advanced_Encryption_Standard Advanced Encryption Standard(高级加密标准，简称 AES) 原名 Rijndael，是一种基于 Block cipher(块密码/分组密码) 变体算法的电子数据加密规范。取代了 1977 年发布的 DES(数据加密标准)
AES 规范中，将待加密的明文分为多个块，每块 128 bit，可以使用具有三种不同的密钥长度：128 bit、192 bit 和 256 bit，若我们提供的密钥不足长度，则可以自定规则将密钥补足，若超过长度，则截断超过的部分。
这三种密钥长度换算为字节的话，分别是 16 Byte、24 Byte、32 Byte，也就是说，一般设置 16、24、32 个字符刚刚好。 密钥的不足规则，可以是直接在末尾补 0、补充随机数、甚至可以直接生成 16、24、32 个随机字符。只要满足密钥长度即可，剩下的由个人掌握。 其实常见的做法是丢进哈希函数里，比如你 rar 加密用的 AES-256。在加密之前把你给的密码进行 sha256 哈希（输出刚好是 256 bit），然后当成 AES-256 的密钥使用 描述用语 AES 128 ECB PKCS7 表示采用 128 bit 长度的密钥进行 AES 加密；使用 Block cipher 算法中的 ECB 模式，填充块的标准为 PKCS7，没有初始化向量</description></item><item><title>Aggregation Operators(聚合运算符)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/Aggregation-Operators%E8%81%9A%E5%90%88%E8%BF%90%E7%AE%97%E7%AC%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/Aggregation-Operators%E8%81%9A%E5%90%88%E8%BF%90%E7%AE%97%E7%AC%A6/</guid><description>概述 参考：
官方文档，Prometheus - 查询 - 运算符 - 聚合运算符 Prometheus 还提供了下列内置的聚合运算符，这些运算符仅作用于瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列。
sum (求和) min (最小值) max (最大值) avg (平均值) stddev (标准差) stdvar (标准差异) count (计数) count_values (对 value 进行计数) bottomk (后 n 条时序) topk (前 n 条时序) quantile (分布统计) Syntax(语法) [AggregationOperators] [without|by (LabelName,&amp;hellip;.)] ([Parameter,&amp;hellip;] VectorExpression)
Aggregation Operators # 聚合运算符 without|by (LabelName,&amp;hellip;) # 若不指定该选项，则聚合全部数据的值。如果指定了，则按照指定的 LabelName 进行聚合。通过 without 和 by 可以按照样本的问题对数据进行聚合。该用法的示例图详见文末 by # 聚合 by 后面指定的 LabelName 样本数据，并将聚合以外的标签的移除 without # 与 by 相反，聚合 without 后面没有指定的 LabelName 样本数据。并将聚合以外的标签的移除 Parameter # 参数，其中只有 count_values, quantile, topk, bottomk 支持 VectorExpression # 向量表达式。详见 PromQL 章节 sum, min, max, avg 详解 count 与 count_values 详解 EXAMPLE</description></item><item><title>AI MGMT</title><link>https://desistdaydream.github.io/docs/12.AI/AI-MGMT/AI-MGMT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/AI-MGMT/AI-MGMT/</guid><description>概述 参考：
LM Studio 参考：
GitHub 组织，LM Studio 官网 免费，不开源？
Ollama 参考：
GitHub 项目，ollama/ollama
带你认识本地大语言模型框架Ollama(可直接上手)
Ollama 模型库: https://ollama.com/library
Ollama 关联文件与配置 Linux **~/.ollama/ #
./models/ # 模型储存位置 Windows %LOCALAPPDATA%/Ollama/ # 日志
%LOCALAPPDATA%/Programs/Ollama/ # 二进制程序
%HOMEPATH%/.ollama/ # 模型与配置
./models/ # 模型储存位置。可以设置环境变量 OLLAMA_MODELS 定义新的储存位置 %TEMP%/ # 临时可执行文件
生态支持 https://github.com/ollama/ollama/blob/main/README.md#community-integrations
Web 与 Desktop
https://github.com/ollama/ollama/blob/main/README.md#web--desktop
Chrome 插件
https://github.com/n4ze3m/page-assist Dify 参考：
GitHub 项目，langgenius/dify 官网 Dify 是一个开源的 LLM 应用开发平台。Dify 直观的界面结合了 AI 工作流、RAG 管道、代理功能、模型管理、可观测性特征等，让您能够迅速从原型转向生产。</description></item><item><title>Alertmanager 扩展</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager-%E6%89%A9%E5%B1%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/Alertmanager-%E6%89%A9%E5%B1%95/</guid><description>概述 参考：
Alertmanager 自带一个 UI 界面，可以用来查看报警和静默管理。但是告警发送目标、历史告警、etc. 个性化功能还比较缺，有很多项目可以补充这些能力。
GitHub 项目，prymitive/karma
公众号-k8s 技术圈，超漂亮的 Alertmanager 可视化面板 - karma 比如报警历史记录等等 GitHub 项目，kubesphere/notification-manager # kubesphere 出的，只有 k8s 的。
GitHub 项目，feiyu563/PrometheusAlert # 可以提供更多的通知功能，将告警发送到各种地方。
利用 template.FuncMap 函数在 go tmpl 中加入了一些自定义函数，e.g. toUpper、etc. 该程序在使用 Alertmanager 数据结构 中的 webhook 推送的数据结构时，虽然设计了 struct，但是在模板中调用 struct 中的属性时，开头字母要是小写，这种模板跟很多扩展都不通用。 https://github.com/opsre/WatchAlert # 多数据源监控告警引擎
GitHub 项目，timonwong/prometheus-webhook-dingtalk # 对接钉钉。提供 pr，增加过 feature
利用 template.FuncMap 函数在 go tmpl 中加入了一些自定义函数，e.g. upper、etc. https://github.com/rea1shane/a2w # 对接企业微信
利用 template.FuncMap 函数在 go tmpl 中加入了一些自定义函数，e.g. timeFormat、etc. notification-manager 参考：</description></item><item><title>Algorithm</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Algorithm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Algorithm/</guid><description>概述 参考：
Wiki, Algorithm Algorithm(算法)
Complexity 参考：
Wiki, Computational complexity Wiki, Time complexity B 站，常见的大O表示法有哪些？时间复杂度是什么？ Complexity(复杂度) 指运行某算法所需的资源量。通常不会精确计算，而是用一种表示法来表示一个数值的范围。
特别关注的是计算时间和存储空间。问题的复杂度则是指解决该问题的最佳算法所具有的复杂度。
常用 O() 表示。如下图时间复杂度所示，越靠左上角的复杂度越糟糕。
时间复杂度通常指一个函数运行完成需要执行某些行代码的次数。比如：
恒定时间的复杂度是 $O(1)$ for 循环复杂度是 $O(n)$，i.e. 循环 n 次。查找 嵌套 for 循环复杂度通常是 $O(n^2)$ 二分查找的复杂度是 $O(\log_{}n)$ etc. [!Note]
复杂度的计算并不是一个精确的计算，而是一种在宏观上通过表示法来表示某种无法确定传入参数的算法所需要消耗的资源
比如，上面的嵌套循环 2 次方只是方便描述，是一种抽象的表示法，并不是真的只循环 2 次并且每次都一样，只是用来表示一种宏观上需要消耗的时间。
如果 n 也确定了，2 也确定了，比如 1000 个元素遍历 2 遍，那这种情况的时间复杂度应该用 $O(1)$ 表示，因为传入参数是固定的，没有复杂度。</description></item><item><title>Alloy</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/Alloy/Alloy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/Alloy/Alloy/</guid><description>概述 参考：
GitHub 项目，grafana/alloy 官网 Grafana Alloy 是 OpenTelemetry 的 Collector 实现。
Promtail 迁移到 Alloy https://grafana.com/docs/alloy/latest/set-up/migrate/from-promtail/
Alloy 关联文件与配置 https://grafana.com/docs/alloy/latest/configure/
config.alloy # 配置文件
alloy CLI 官方文档，参考 - CLI
https://grafana.com/docs/alloy/latest/reference/cli/run/
&amp;ndash;disable-reporting # 是否关闭使用数据的上报。默认值: false</description></item><item><title>Alpine</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/Alpine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/Alpine/</guid><description>概述 参考：
官网 GitHub 项目,docker-alpine DockerHub https://mp.weixin.qq.com/s/Qt8ASPefVG-9bZe6FO_YQw APK # 包管理器 参考：
官方文档 Alpine Package Keeper(Alpine 包管理圆，简称 APK) 是 Alpine 发行版的包管理工具。
关联文件 /etc/apk/repositories # 包仓库的配置文件
阿里仓库 sed -i &amp;rsquo;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&amp;rsquo; /etc/apk/repositories 中科大仓库 sed -i &amp;rsquo;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g&amp;rsquo; /etc/apk/repositories /var/cache/apk/ # APK 程序运行时产生的缓存文件保存路径
apk 命令行工具 Syntax(语法) apk [Global OPTIONS] COMMAND [COMMAND OPTIONS]
Global OPTIONS
&amp;ndash;no-cache # 不在 /var/cache/apk/ 目录下生成缓存，并且也不使用该目录下的缓存。 COMMAND
安装和移除包命令
add # 为正在运行的系统添加新包或升级包 del # 从正在运行的系统中删除包 系统维护命令(管理包的元数据)
cache Maintenance operations for locally cached package repository fix # 尝试修复或升级已安装的包 update Update the index of available packages upgrade Upgrade the currently installed packages 查询包的信息</description></item><item><title>Android MGMT</title><link>https://desistdaydream.github.io/docs/Mobile-device/Android-MGMT/Android-MGMT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Mobile-device/Android-MGMT/Android-MGMT/</guid><description>概述 参考：
ADB ADB
Scrcpy 参考:
GitHub 项目，Genymobile/scrcpy Scrcpy 可以显示和控制 Android 设备。
该应用程序镜像通过 USB 或 TCP/IP 连接的 Android 设备（视频和音频），并允许使用计算机的键盘和鼠标控制设备。它不需要任何根访问权限。它适用于 Linux、Windows 和 macOS。
[!Tip]
使用 Scrcpy 连接运行在 Linux 容器中的 Android 系统，配合 YOLO。可以实现在电脑上自动玩手机游戏，比如 https://www.bilibili.com/video/BV1mihkeTEDc
Android 容器镜像
https://hub.docker.com/r/redroid/redroid https://github.com/budtmo/docker-android 好像跑不起来？</description></item><item><title>API 源码</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/API-Server/API-%E6%BA%90%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/API-Server/API-%E6%BA%90%E7%A0%81/</guid><description>概述 参考：
公众号-云原生实验室，深入 Kubernetes API 的源码实现 Kubernetes API 代码在 k8s.io/api 仓库中，该仓库的代码来源于 https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/api 这个核心仓库的目录中。
在 k8s.io/api 仓库定义的 kubernetes API 规范中，Pod 作为最基础的资源类型，一个典型的 YAML 形式的序列化 pod 对象如下所示：
apiVersion: v1 kind: Pod metadata: name: webserver labels: app: webserver spec: containers: - name: webserver image: nginx ports: - containerPort: 80 从编程的角度来看，序列化的 pod 对象最终会被发送到 API-Server 并解码为 Pod 类型的 Go 结构体，同时 YAML 中的各个字段会被赋值给该 Go 结构体。那么，Pod 类型在 Go 语言结构体中是怎么定义的呢？
// source code from https://github.com/kubernetes/api/blob/master/core/v1/types.go type Pod struct { // 从TypeMeta字段名可以看出该字段定义Pod类型的元信息，类似于面向对象编程里面 // Class本身的元信息，类似于Pod类型的API分组、API版本等 metav1.</description></item><item><title>Apifox</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/API-%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7/Apifox/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/API-%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7/Apifox/</guid><description>概述 参考：
内嵌 PostMan 的 Postman Collection SDK，可以直接使用 pm 对象对请求和响应进行控制。
在 https://apifox.com/help/pre-post-processors-and-scripts/scripts/api-references/pm-reference#pm 可以看到 Apifox 对 pm 对象的描述文档
脚本读取/修改接口请求信息 https://apifox.com/help/pre-post-processors-and-scripts/scripts/examples/handling-request
自带的动态变量 参考：
Postman 官方文档 ApiFox 官方文档 {{$timestamp}} # 当前时间戳 程序脚本
参考：
Postman 官方文档 ApiFox 官方文档 Gdas 签名 用于 Apifox 进行 Gdas 签名 // 随机数 var nonce = pm.variables.replaceIn(&amp;#39;{{$randomPassword}}&amp;#39;); // 随机数反序 var nonceReverse = nonce.split(&amp;#39;&amp;#39;).reverse().join(&amp;#39;&amp;#39;); // 接入渠道标识 var appkey = &amp;#34;wo-obs&amp;#34;; var secretKey = &amp;#34;obs123456&amp;#34;; // 毫秒时间戳 var stimestamp =Date.parse(new Date()); // 组合签名 var signOriginal = secretKey + nonce + stimestamp + nonceReverse; var cryptoJs = require(&amp;#34;crypto-js&amp;#34;); // 使用 sha256 加密签名并转换为字符串 var signature = cryptoJs.</description></item><item><title>Archive File(归档文件)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Filesystem/Archive-File%E5%BD%92%E6%A1%A3%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Filesystem/Archive-File%E5%BD%92%E6%A1%A3%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
Wiki, Tar Wiki, Archive_file 在计算机中，Archive File(归档文件) 是由一个或多个文件及元数据组成的一个计算机文件。归档文件用于将多个数据文件放在一起收集到一个文件中，以便于移植和存储。归档文件通常存储目录结构、错误检测和纠正信息、任意注释，有时还使用内置加密。
有的时候归档文件也翻译成 “存档文件”
归档与压缩的概念 首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。
为什么要区分这两个概念呢？这源于 Linux 中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar 命令），然后再用压缩程序进行压缩（gzip bzip2 命令）。
归档程序 Tar 是一种计算机应用程序，用于将许多文件汇集到一个 Archive file(归档文件) 中，通常称为 Tarball。该名称源于 Tape Archive(磁带存档)，取 Tape 中的 t 和 Archive 中的 ar。
利用 tar 命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。利用 tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar 最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。
数据压缩 参考：
Wiki, Data compression(数据压缩)</description></item><item><title>Array</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Array/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Array/</guid><description>概述 参考：
Wiki, Array_data_type Array(数组) 通常默认说的都是 Index array(索引数组)
Index array(索引数组) 参考:
Wiki, Array 为什么很多编程语言要把 0 作为第一个下标索引，而不是直观的 1 呢？
这个问题 Dijkstra 已经解答过了，没错，就是你知道的 Dijkstra，Dijkstra 最短路径算法，荷兰语全名是 Edsger Wybe Dijkstra，于 1972 年获得了图灵奖，除了上面说的最短路径算法，还有众所周知的信号量和 PV 原语、银行家算法等也是这位巨佬提出的。
原文在这里：https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html，感兴趣的小伙伴可以去看下全文，下面我总结几段核心的观点：
首先来看个案例，如何用一个不等式（或者说表达式）来表示 [2,3,4,5,6,7,8,9,10,11,12] 这个连续的整数序列（一共 11 个数）？
假设 i 是一个整数，那么我们能够迅速的写出如下四个符合上述连续序列的不等式：
1）2 &amp;lt;= i &amp;lt; 13
2）1 &amp;lt; i &amp;lt;= 12
3）2 &amp;lt;= i &amp;lt;= 12
4）1 &amp;lt; i &amp;lt; 13
以上四个不等式均满足要求，那是否有理由选择其中的一种而不是另一种？
Dijkstra 说有的，选 1 和 2，因为这俩不等式有个很突出的有点，就是不等式边界的差（不等式右边 - 不等式左边）正好等于连续序列的长度
这里可以排除掉 3 和 4，那么 1 和 2 该如何选出最优的表示？</description></item><item><title>Artifacts</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab-CI/Artifacts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/GitLab-CI/Artifacts/</guid><description>概述 参考:
官方文档，CI - jobs - job 工件 每个 Job 可以输出一些 包含文件和目录的 Archive File(归档文件)、元数据、etc. ，这些输出称为 Artifacts(工件)。
[!Warning] Artifacts 通常指我们构建的二进制文件、打包好的归档文件、etc. 。这些文件对项目来说，通常都是提供给使用者的，比如像 GitHub 的 Release 中的 Assets。
但是 GitLab 不建议将 Artifacts 的作为 Release Assets，因为 Artfacts 通常来说是短暂的，很有可能被轻易删除。因为对于 GitLab 来说，Release 中的 Assets 并不是被上传的文件，仅仅是一个名称和 URL 连接，指向其他地方。
更常见的作法是将 Artifacts 作为 Package 上传到 Package Registry，让 Release Assets 设置为指向 Package 的 URL。参考: https://docs.gitlab.com/ee/user/packages/generic_packages/#publish-a-generic-package-by-using-cicd
创建 Artifact 的最简单示例:
pdf: script: xelatex mycv.tex artifacts: paths: - mycv.pdf 在这个示例中，一个名为 pdf 的 JOB 调用 xelatex 命令从 LaTeX 源文件 mycv.</description></item><item><title>Audit 日志文件详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/Audit-%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%B3%BB%E7%BB%9F%E5%AE%A1%E8%AE%A1/Audit-%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
红帽官方文档，7 - 安全指南 - 了解 Audit 日志文件 日志文件默认保存在 /var/log/audit/ 目录下。</description></item><item><title>B_S 和 C_S 架构</title><link>https://desistdaydream.github.io/docs/Standard/B_S-%E5%92%8C-C_S-%E6%9E%B6%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/B_S-%E5%92%8C-C_S-%E6%9E%B6%E6%9E%84/</guid><description>概述 参考：
Service Side 与 Client Side 参考：
Wiki, Server Side Wiki, Client Side Client/Server 结构(C/S 结构) 是大家熟知的 Client Side(客户端) 与 Server Side(服务端) 结构。它是软件系统体系结构，通过它可以充分利用两端硬件环境的优势，将任务合理分配到 Client Side 和 Server Side 来实现，降低了系统的通讯开销。目前大多数应用软件系统都是 Client/Server 形式的两层结构，由于现在的软件应用系统正在向分布式的 Web 应用发展，Web 和 Client/Server 应用都可以进行同样的业务处理，应用不同的模块共享逻辑组件；因此，内部的和外部的用户都可以访问新的和现有的应用系统，通过现有应用系统中的逻辑可以扩展出新的应用系统。这也就是目前应用系统的发展方向。
B/S 结构（Browser/Server，浏览器/服务器模式），是 WEB 兴起后的一种网络结构模式，WEB 浏览器是客户端最主要的应用软件。这种模式统一了客户端，将系统功能实现的核心部分集中到服务器上，简化了系统的开发、维护和使用。客户机上只要安装一个浏览器（Browser 英 [&amp;lsquo;braʊzə]美 [&amp;lsquo;braʊzɚ]），如 Netscape Navigator 或 Internet Explorer，服务器安装 SQL Server、Oracle、MYSQL 等数据库。浏览器通过 Web Server 同数据库进行数据交互。
Apache 是普通服务器，本身只支持 html 即普通网页。不过可以通过插件支持 php,还可以与 Tomcat 连通(单向 Apache 连接 Tomcat,就是说通过 Apache 可以访问 Tomcat 资源。反之不然)。Apache 只支持静态网页，但像 php,cgi,jsp 等动态网页就需要 Tomcat 来处理。 Tomcat 是由 Apache 软件基金会下属的 Jakarta 项目开发的一个 Servlet 容器，按照 Sun Microsystems 提供的技术规范，实现了对 Servlet 和 JavaServer Page（JSP）的支持，并提供了作为 Web 服务器的一些特有功能，如 Tomcat 管理和控制平台、安全域管理和 Tomcat 阀等。由于 Tomcat 本身也内含了一个 HTTP 服务器，它也可以被视作一个单独的 Web 服务器。但是，不能将 Tomcat 和 Apache Web 服务器混淆，Apache Web Server 是一个用 C 语言实现的 HTTP web server；这两个 HTTP web server 不是捆绑在一起的。Apache Tomcat 包含了一个配置管理工具，也可以通过编辑 XML 格式的配置文件来进行配置。Apache，nginx，tomcat 并称为网页服务三剑客，可见其应用度之广泛。（说白了，tomcat 就是个底层设施软件服务，网页上所有的东西就要放在 tomcat 上，别人才能通过 tomcat 访问，tomcat 占用 80 端口）</description></item><item><title>Bash 内置命令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
Manual(手册)，bash(1) - Shell 内置命令 别名 https://www.man7.org/linux/man-pages/man1/bash.1.html#ALIASES
alias unalias</description></item><item><title>Bastion Host</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Bastion-Host/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Bastion-Host/</guid><description>概述 参考：
Wiki, Bastion host Bastion Host(堡垒机)
JumpServer GitHub 项目，jumpserver/jumpserver
https://jumpserver.org/
OneTerm GitHub 项目，veops/oneterm
公众号 - Kubernetes技术栈，开源推荐｜简洁且强大的开源堡垒机OneTerm
公众号 - Kubernetes技术栈，用了两周开源堡垒机OneTerm，我有一些建议</description></item><item><title>Best practices</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Best-practices/Best-practices/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Best-practices/Best-practices/</guid><description>概述 参考：
ClickHouse + Vector + Grafana 展示 Nginx 数据分析日志
合集 你还用ES存请求日志？CH+Vector打造最强Grafana日志分析看板 基于K8S的大规模日志采集最佳实践：iLogtail/Filebeat +KAFKA+Vector+ClickHouse/ES</description></item><item><title>BIOS</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/BIOS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/BIOS/</guid><description>概述 参考：
Wiki, BIOS Basic Input/Output System(基本输出输出系统，简称 BIOS) 是
UEFI 参考：
官网 Wiki, UEFI Unified Extensible Firmware Interface(统一可扩展接口，简称 UEFI) 用以替代 BIOS
SMBIOS 参考：
Wiki, System_Management_BIOS System Management BIOS (系统管理 BIOSS，简称 MBIOS) 是一种规范，该规范定义了一计算机的 BIOS 中产生的管理信息的数据结构以及读取这些数据的访问方式。这消除了操作系统直接探测硬件以发现计算机中存在哪些设备的需要。SMBIOS 规范由非营利性标准开发组织分布式管理任务组 (DMTF) 制定。
SMBIOS 最初被称为桌面管理 BIOS (DMIBIOS)，因为它与桌面管理界面 (DMI) 交互。
DMI 参考：
Wiki, Desktop_Management_Interface 桌面管理接口 (DMI) 通过从管理它们的软件中抽象出这些组件，生成用于管理和跟踪台式机、笔记本电脑或服务器计算机中的组件的标准框架。 1998 年 6 月 24 日开发的 DMI 2.0 版标志着分布式管理任务组 (DMTF) 向桌面管理标准迈出的第一步。在引入 DMI 之前，没有标准化的信息来源可以提供有关个人计算机组件的详细信息。
从 1999 年开始，Microsoft 要求 OEM 和 BIOS 供应商支持 DMI 接口/数据集才能获得 Microsoft 认证</description></item><item><title>bit 与 Byte</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/bit-%E4%B8%8E-Byte/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/bit-%E4%B8%8E-Byte/</guid><description>概述 参考：
Wiki, bit Wiki, Byte bit（比特） bit 也就是我们不一定听说过的比特，大名鼎鼎的比特币就是以此命名的。它的简写为小写字母 “b” 。
作为信息技术的最基本存储单元，因为比特实在太小了，所以大家生活中并不是经常听到。那么 bit 是什么呢？
电脑是以二进制存储以及发送接收数据的。二进制的一位，就叫做 1 bit。也就是说 bit 的含义就是二进制数中的一个数位，即 “0” 或者 &amp;ldquo;1&amp;rdquo;。
Byte（字节） Byte 是字节的英文写法。它的简写为大写字母 B。
既然名字叫字节，那肯定跟字符有关系。是的。英文字符通常是一个字节，也就是 1B，中文字符通常是两个字节，也就是 2B。
字节 Byte 和比特 bit 的换算关系是 1 Byte = 8 bit 。
KiB （千字节） 需要了解的是，1 KiB 并不是一千字节，因为计算机只认识二进制，所以在这里的 KiB，是 2 的 10 次方，也就是 1024 个字节。
另外很多表示存储单位的地方都把 B 写成 b，造成了大家认知的混乱。其实在存储单位计量中出现 b 的地方，它的意思仍然是 B，不要因为 bit 的缩写是 b 就被误导了，在存储计量中是不会用 比特，千比特 这种单位的。但是在网速计量中，b 的真实意思就是指 比特 了，这个我们下面再说。
单位换算 存储单位换算关系如下</description></item><item><title>Block</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Hardware/Block/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Hardware/Block/</guid><description>概述 参考：
Block(块) 设备 包含的信息常见于如下几处
Sysfs 中的磁盘信息 Proc 中的磁盘信息 I/O 时间 I/O 时间 指 Block(块设备、磁盘、硬盘、etc.) 在执行 I/O 操作上花费的时间。
在 /sys/block/&amp;lt;DEV&amp;gt;/stat 文件中，io_ticks 字段记录了毫秒级的 磁盘 I/O 时间。如果磁盘在 1 秒内持续执行 I/O 操作，那么在 1 秒钟后，io_ticks 的值是 1000；如果 1 秒内磁盘一直空闲，那么 io_ticks 的值是 0。也就是说，io_ticks 的值每秒最多增加 1000。
[!Note] 在 Node Exporter 源码中，这里 可以看到 stats.IOsTotalTicks 对应 diskstatsCollector.descs[10](i.e. node_disk_io_time_seconds_total 指标)。而 IOsTotalTics 对应到 prometheus/procfs 项目，blockdevice/stats.go 中的 IOStats 结构体得 IOsTotalTicks 属性。这些结构体的信息来源遵循以下几个内核文档的说明
https://www.kernel.org/doc/Documentation/iostats.txt, https://www.kernel.org/doc/Documentation/block/stat.txt https://www.kernel.org/doc/Documentation/ABI/testing/procfs-diskstats 一般情况下，io_ticks 的值可以当作磁盘的使用率，比如计算某区间时间中，io_ticks 每秒的变化率（基于上面的逻辑，这个变化率一定是 0 到 1 之间的小数）。比如我们统计 1 分钟时间 io_ticks 增加了 60000，那说明这一分钟的时间中，磁盘一直在执行 I/O，i.</description></item><item><title>Block cipher</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cipher/Block-cipher/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cipher/Block-cipher/</guid><description>概述 参考：
Wiki, Block_cipher Wiki, Block_cipher_mode_of_operation B 站，【计算机博物志】DES的生与死 Block cipher(分组密码) 是一种确定性算法，对固定长度的 bits（也称为 blcok）进行操作。与 Block cipher 相关的另一种算法，是 Stream cipher。
Block cipher 的基本逻辑：将待加密的明文，分为固定 bits 的块，比如 AES 的 128 bit block，然后使用相同长度的密钥（或指定倍数的长度），对每个 block 进行加密。
Block cipher 算法设计了多种模式以适应各种加密需求：
ECB # 最简单的模式，不需要 IV CBC CFB CTR 等等 对于每个加密操作，大多数模式都需要唯一的二进制序列，通常称为初始化向量 (IV)。 IV 必须是非重复的，并且对于某些模式来说，也是随机的。初始化向量用于确保即使使用相同的密钥独立地对相同的明文进行多次加密，也会生成不同的密文。 分组密码可能能够对不止一种块大小进行操作，但在转换过程中块大小始终是固定的。分组密码模式对整个块进行操作，如果数据的最后部分小于当前块大小，则要求将其填充到整个块。然而，有些模式不需要填充，因为它们有效地使用分组密码作为 Stream cipher。
在 Block cipher 算法中，首先要明确几个概念
Padding(填充) Initialization vector((初始化向量，简称 IV) ECB 模式不需要 IV Padding Block cipher 算法在加密时将明文分成固定长度的块（128 bit，i.e. 16 Bytes）进行加密。如果明文的长度不是16 Bytes 的整数倍，就需要进行 Padding(填充) 来补齐。</description></item><item><title>boot目录被清空下物理机无法开机的一次救援</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/boot%E7%9B%AE%E5%BD%95%E8%A2%AB%E6%B8%85%E7%A9%BA%E4%B8%8B%E7%89%A9%E7%90%86%E6%9C%BA%E6%97%A0%E6%B3%95%E5%BC%80%E6%9C%BA%E7%9A%84%E4%B8%80%E6%AC%A1%E6%95%91%E6%8F%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/boot%E7%9B%AE%E5%BD%95%E8%A2%AB%E6%B8%85%E7%A9%BA%E4%B8%8B%E7%89%A9%E7%90%86%E6%9C%BA%E6%97%A0%E6%B3%95%E5%BC%80%E6%9C%BA%E7%9A%84%E4%B8%80%E6%AC%A1%E6%95%91%E6%8F%B4/</guid><description>概述 参考：
今天下午到公司被通知苏州一个节点的客户的裸金属无法开机，14:00 上去到 16:50 终于给整好了，这里记录下笔记分享下
故障现象 物理机裸金属，连上跳板机通过带外连上去 (等同于现场接了一个显示屏 + 键盘一样) 错误为
errorL file `/grub2/i386-pc/normal.mod&amp;#39; not found. Entering rescue mode... grub rescue&amp;gt; 这个物理机是 grub2，这个错误和类似的/grub/i386-pc/normal.mod本质上都是文件丢失，但是也分情况，网上的一些恢复步骤都是在丢失部分文件的情况下恢复的 查看分区
grub rescue&amp;gt;ls (hd0) (hd0,msdos2) (hd0,msdos1) grub rescue&amp;gt;ls (hd0,msdos1)/ ./ ../ grub rescue&amp;gt;ls (hd0,msdos2)/ error: unknown filesystem 这里是等同于你实际的分区，我们这基本是一个 / boot 和一个根，看到(hd0,msdos1)是 / boot 分区，文件是完全丢失的，(hd0,msdos2)/报错未知文件系统是因为这个是 lvm，正常乐观下来讲只是丢失部分文件的话，可以参考下面步骤去恢复
https://www.youtube.com/watch?v=RqRm1bEXO9M https://blog.csdn.net/qq_20545159/article/details/50810089 救援 livecd 进入 rescue 救援 这里我是完全丢失，我利用带外远程挂载了一个 centos7.6 的 iso(最好和目标系统版本一样)，重启物理机进入 cdrom，选择Troubleshooting –&amp;gt; Rescue a CentOS Linux system
下面我引用下别人的图，如果图被拦截了请看文字吧
选择 1 后然后回车会得到一个交互式 shell，查看下分区信息</description></item><item><title>Bridge</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bridge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bridge/</guid><description>概述 参考：
在 /sys/class/net/*/ 目录下，如果有 bridge 目录，则说明这是 Bridge 类型的网络设备。
for dev in /sys/class/net/*; do if [ -d &amp;#34;$dev/bridge&amp;#34; ]; then echo &amp;#34;$(basename $dev) is a bridge device&amp;#34; fi done 聊聊 Linux 上软件实现的 “交换机” - Bridge 参考：
原文：聊聊 Linux 上软件实现的 “交换机” - Bridge！ Linux 中的 veth 是一对儿能互相连接、互相通信的虚拟网卡。通过使用它，我们可以让 Docker 容器和母机通信，或者是在两个 Docker 容器中进行交流。参见《轻松理解 Docker 网络虚拟化基础之 veth 设备！》。
不过在实际中，我们会想在一台物理机上我们虚拟出来几个、甚至几十个容器，以求得充分压榨物理机的硬件资源。但这样带来的问题是大量的容器之间的网络互联。很明显上面简单的 veth 互联方案是没有办法直接工作的，我们该怎么办？？？
回头想一下，在物理机的网络环境中，多台不同的物理机之间是如何连接一起互相通信的呢？没错，那就是以太网交换机。同一网络内的多台物理机通过交换机连在一起，然后它们就可以相互通信了。
在我们的网络虚拟化环境里，和物理网络中的交换机一样，也需要这样的一个软件实现的设备。它需要有很多个虚拟端口，能把更多的虚拟网卡连接在一起，通过自己的转发功能让这些虚拟网卡之间可以通信。在 Linux 下这个软件实现交换机的技术就叫做 bridge（再强调下，这是纯软件实现的）。
各个 Docker 容器都通过 veth 连接到 bridge 上，bridge 负责在不同的 “端口” 之间转发数据包。这样各个 Docker 之间就可以互相通信了！</description></item><item><title>BUG</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/BUG/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/BUG/</guid><description>概述 参考：
已修复 orphaned pod &amp;ldquo;XX&amp;rdquo; found, but volume paths are still present on disk 问题跟踪：issue #60987
kubelet 执行逻辑：https://github.com/kubernetes/kubernetes/blob/release-1.19/pkg/kubelet/kubelet_volumes.go#L173
解决方式：
更新至 1.19.8 版本及以上，ChangeLog 中提到，在 #95301 Merged 中已解决 未更新的话，通过 ali 提供的脚本，进行一些修改，该脚本会手动 umount 和 rm 目录 aggregator_unavailable_apiservice 问题描述：聚合 API 删除之后，依然存在于 kube-apiserver 的 metrics 中，这会导致频繁告警
跟踪连接：https://github.com/kubernetes/kubernetes/issues/92671
解决方式：https://github.com/kubernetes/kubernetes/pull/96421
将在 1.20 版本解决
Scope libcontainer-21733-systemd-test-default-dependencies.scope has no PIDs. Refusing 问题跟踪：https://github.com/kubernetes/kubernetes/issues/71887
解决方式：（1.16 及以后的版本中，无该问题。主要是 18+版本 docker 无该问题）
忽略该告警：https://www-01.ibm.com/support &amp;hellip; .wss?uid=ibm10883724
Error while processing event (&amp;quot;/sys/fs/cgroup/devices/libcontainer_2434_systemd_test_default.slice&amp;quot;: 0x40000100 == IN_CREATE|IN_ISDIR): open /sys/fs/cgroup/devices/libcontainer_2434_systemd_test_default.</description></item><item><title>Bus</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/Bus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/Bus/</guid><description>概述 参考：
Wiki, Bus_(computing) Bus(总线)</description></item><item><title>Cache</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Cache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Cache/</guid><description>概述 参考：
Wiki, Cache(computing) Cache(缓存) 在 Computer(计算机) 中，是指一种用于存储数据的软件或硬件，以便可以更快的满足未来对该数据的请求；存储在缓存中的数据可能是早期计算的结果或存储在其他地方的数据的副本。作为缓存的组件的最低要求就是速度够快，避免对存储原始数据的组件产生过大压力。
缓存是计算机系统中最基本的性能改进技术之一，一次又一次地用于让“常见的情况更快”1。硬件缓存背后的思想是利用指令和数据引用的 Locality(局部性原理)。通常有两种局部性: temporal locality(时间局部性) 和 spatial locality(空间局部性)。时间局部性是指，最近访问过的指令或数据项可能很快会再次访问。想想循环中的循环变量或指令，它们被多次反复访问。空间局部性是指，当程序访问内存地址 x 时，可能很快会访问邻近 x 的内存。想想遍历某种数组，访问一个接一个的元素。当然，这些性质取决于程序的特点，并不是绝对的定律，而更像是一种经验法则。2
硬件缓存，无论是指令、数据还是地址转换（如 TLB），都利用了局部性，在小而快的芯片内存储器中保存一份内存副本。处理器可以先检查缓存中是否存在就近的副本，而不是必须访问（缓慢的）内存来满足请求。如果存在，处理器就可以很快地访问它（例如在几个 CPU 时钟内），避免花很多时间来访问内存（好多纳秒）。2
你可能会疑惑：既然像 TLB 这样的缓存这么好，为什么不做更大的缓存，装下所有的数据？可惜的是，这里我们遇到了更基本的定律，就像物理定律那样。如果想要快速地缓存，它就必须小，因为光速和其他物理限制会起作用。大的缓存注定慢，因此无法实现目的。所以，我们只能用小而快的缓存。剩下的问题就是如何利用好缓存来提升性能。2
写入策略 https://en.wikipedia.org/wiki/Cache_(computing)#Writing_policies
由于缓存中的数据不能长久保持，所以要根据一定的策略将数据写入到后端存储，具体的写入行为，由 Writing policies(写入策略) 决定
Write-throught(直写) # 向缓存和后端存储同步写入 Write-back(回写) # 先写入缓存，直到某一条件触发后，再写入到后端存储。 问 Bing 回写是什么的回答：
感谢您提供更多的信息。我找到了一些关于计算机领域的回写（write back）的资料，希望对您有用。😊
回写（write back）是一种缓存（cache）的写入策略，它指的是在数据更新时只写入缓存，而不写入后端存储（如内存或硬盘）。只有当缓存中的数据被替换出去时，才会把修改过的数据写回后端存储。这样可以提高数据写入的速度，但也有可能造成数据不一致的问题。1 2
回写（write back）通常与写分配（write allocate）一起使用，这意味着当缓存未命中时，会先把数据从后端存储加载到缓存中，然后再更新缓存。这样可以减少对后端存储的访问次数，同时也为后续对同一位置的写入或读取提供便利。3
回写（write back）与另一种缓存写入策略透写（write through）相对，透写指的是在数据更新时同时写入缓存和后端存储，这样可以保持数据的一致性，但也会降低数据写入的速度。透写通常与无写分配（no write allocate）一起使用，这意味着当缓存未命中时，只更新后端存储，而不加载数据到缓存中。3 4
如果您想了解更多关于回写（write back）和透写（write through）的区别和优缺点，请参考以下链接：
1: 计算机的Cache和Memory访问时Write-back，Write-through及write allocate的区别 - 国静德远 - 博客园 2: cache 写回策略_写回cache_xingzhe22222的博客-CSDN博客 3: 透写和回写缓存（Write Through and Write Back in Cache） 4: Cache写机制：Write-through与Write-back - CSDN博客</description></item><item><title>Callback</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Function/Callback/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Function/Callback/</guid><description>概述 参考：
Wiki, Callback_(computer_programming) 博客园，究竟什么是callback function(回调函数) 公众号-码农的荒岛求生，回调函数 callback 的实现原理是什么？ 原文非简化版：《10 张图让你彻底理解回调函数》 Callback function(回调函数) 也是函数，只不过函数的参数不是变量，而是另一个函数。这种调用函数的方式有多种好处
异步调用。调用 A 时，只要传递的参数中的函数没有阻塞逻辑，那就不用等待 A 函数全部执行完成，即可继续处理后续代码。 不同实体调用函数 A 时，想要执行一些不同的特定的代码，不用在函数 A 里加很多 if else 的判断 等等 其实回调函数和普通函数没有本质的区别。
首先让我们来看看普通的函数调用，假设我们在 A 函数中调用函数 func：
void A() { ... func(); ... } 想一想，你怎么知道可以调用 func 呢？哦，原来 func 是你自己定义的：
void func() { blablabla; } 这很简单吧，现在假设你编写的这段代码无比之牛逼，全世界的程序员都无比疯狂的想引入到自己的项目中，这时你会把 A 函数编写成一个库供全世界的码农使用。
但此时所有人都发现一个问题，那就是他们都想在 A 函数中的某个特定点上执行一段自己的代码，作为这个库的创作者你可能会这样实现：
void A() { ... if (张三) { funcA(); } else if (李四) { funcB(); } .</description></item><item><title>CFSSL</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/CFSSL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/CFSSL/</guid><description>概述 参考：
GitHub 项目,cloudflare/cfssll 官网 公众号，白话文说CA原理 · 掌握PKI/TLS瑞士军刀之cfssl cfssl 与 openssl 类似，不过是使用 go 编写，由 CloudFlare 开源的一款 PKI/TLS 工具。主要程序有 cfssl，是 CFSSL 的命令行工具，cfssljson 用来从 cfssl 程序获取 JSON 输出，并将证书，密钥，CSR 和 bundle 写入文件中。
使用 CFSSL 创建 CA 认证步骤 创建认证中心(CA) cfssl 可以创建一个获取和操作证书的内部认证中心。运行认证中心需要一个 CA 证书和相应的 CA 私钥。任何知道私钥的人都可以充当 CA 来颁发证书。因此，私钥的保护至关重要，这里我们以 k8s 所需的证书来实践一下：
cfssl print-defaults config &amp;gt; config.json # 默认证书策略配置模板 cfssl print-defaults csr &amp;gt; csr.json #默认csr请求模板 结合自身的要求，修改证书请求文件csr.json,证书 10 年
{ &amp;#34;CN&amp;#34;: &amp;#34;kubernetes&amp;#34;, &amp;#34;key&amp;#34;: { &amp;#34;algo&amp;#34;: &amp;#34;rsa&amp;#34;, &amp;#34;size&amp;#34;: 2048 }, &amp;#34;names&amp;#34;: [ { &amp;#34;C&amp;#34;: &amp;#34;CN&amp;#34;, &amp;#34;ST&amp;#34;: &amp;#34;BeiJing&amp;#34;, &amp;#34;L&amp;#34;: &amp;#34;BeiJing&amp;#34;, &amp;#34;O&amp;#34;: &amp;#34;k8s&amp;#34;, &amp;#34;OU&amp;#34;: &amp;#34;System&amp;#34; } ], &amp;#34;ca&amp;#34;: { &amp;#34;expiry&amp;#34;: &amp;#34;87600h&amp;#34; } } 知识点:</description></item><item><title>Charles</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/Charles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/Charles/</guid><description>概述 参考：
官网：https://www.charlesproxy.com/ 小米手机安装 Charles 证书：https://blog.csdn.net/yang450712123/article/details/112908643 安卓用不了 2022.9.19 IOS 安装 Charles 证书：https://www.jianshu.com/p/08f602eabb54 苹果的能用 2022.9.19 https://www.charles.ren/ 生成注册码 生成码之后直接使用即可 在手机、pad 上配置 WLAN 代理，访问 chls.pro/ssl 下载证书。
IOS 抓包 IOS 安装证书 为无线连接配置手动代理
IOS 访问 chls.pro/ssl 下载证书并安装
设置 —— 通用 —— 关于本机 —— 证书信任设置，开启信任证书
安卓抓包 bitxeno&amp;rsquo;s notes，通过 WSA 抓取 android 的 https 网络请求包
安卓安装 Charles 证书无效 证书安装成功，但是抓到的包都是 unknow，可能的原因：
Android7.0 之后默认不信任用户级别 CA 证书 此时开启抓包后，很多 APP 都是无网络的情况；但是 chrome 打开网页是可以抓到 https 的包 需要想办法安装在系统级别下的 CA 证书 可能的方法 平行空间 获取系统 Root 权限 HttpCanary 根证书安装(MIUI13 Android 12可用)</description></item><item><title>ChatGPT</title><link>https://desistdaydream.github.io/docs/12.AI/AI-Projects/ChatGPT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/AI-Projects/ChatGPT/</guid><description>概述 参考：
https://zblogs.top/how-to-register-openai-chatgpt-in-china 注册 ChatGPT 教程 使用虚拟号码接收短信验证码：https://sms-activate.org/ 扩展 ChatGPT 的项目 Web 增强 https://github.com/xcanwin/KeepChatGPT # 让我们在使用 ChatGPT 的时候更顺畅，不会老断，不会老报错
Auto GPT 参考：
GitHub 项目，Torantulino/Auto-GPT https://www.bilibili.com/video/BV1HV4y1Z7dm Auto-GPT 是一个实验性开源应用程序，展示了 GPT-4 语言模型的功能。该程序由 GPT-4 驱动，将 LLM 的“思想”链接在一起，以自主实现您设定的任何目标。作为 GPT-4 完全自主运行的首批示例之一，Auto-GPT 突破了 AI 的可能性界限。
用白话说，就是根据一个给定的目标，在没有人为干预的情况下自动完成，比如自动生成一整个项目，Auto GPT 会自动创建目录与文件，并逐步实现最终目标。
这里是一个类似 Auto GPT 的项目，但是可以通过 web 控制：https://github.com/reworkd/AgentGPT
OPENAI_API_KEY # 来源: https://platform.openai.com/account/api-keys GOOGLE_API_KEY=XXXXXX # 来源: https://console.cloud.google.com/apis/credentials?project=manifest-pulsar-287701 CUSTOM_SEARCH_ENGINE_ID=YYYY # 来源: https://console.cloud.google.com/apis/api/customsearch.googleapis.com/metrics?project=manifest-pulsar-287701 https://programmablesearchengine.google.com/controlpanel/all 添加搜索引擎并获取 ID PINECONE_API_KEY # 来源: https://app.pinecone.io/ HUGGINGFACE_API_TOKEN # 来源: https://huggingface.co/settings/tokens Chrom 插件 https://github.</description></item><item><title>ChatGPT 团队是如何使用Kubernetes的</title><link>https://desistdaydream.github.io/blog/copy/%E4%BA%91%E5%8E%9F%E7%94%9F/ChatGPT-%E5%9B%A2%E9%98%9F%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Kubernetes%E7%9A%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E4%BA%91%E5%8E%9F%E7%94%9F/ChatGPT-%E5%9B%A2%E9%98%9F%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Kubernetes%E7%9A%84/</guid><description>原文链接
https://openai.com/research/scaling-kubernetes-to-7500-nodes
在本文中，OpenAI 的工程师团队分享了他们在 Kubernetes 集群扩展过程中遇到的各种挑战和解决方案，以及他们取得的性能和效果。
我们已经将 Kubernetes 集群扩展到 7500 个节点，为大型模型（如 GPT-3、 CLIP 和 DALL·E）创建了可扩展的基础设施，同时也为快速小规模迭代研究（如 神经语言模型的缩放定律）创建了可扩展的基础设施。
将单个 Kubernetes 集群扩展到这种规模很少见，但好处是能够提供一个简单的基础架构，使我们的机器学习研究团队能够更快地推进并扩展，而无需更改代码。
自上次发布关于扩展到 2500 个节点的帖子以来，我们继续扩大基础设施以满足研究人员的需求，在此过程中学到了许多的经验教训。本文总结了这些经验教训，以便 Kubernetes 社区里的其他人也能从中受益，并最后会介绍下我们仍然面临的问题，我们也将继续解决这些问题。
我们的工作负载
在深入探讨之前，我们着重描述一下我们的工作负载。我们在 Kubernetes 上运行的应用程序和硬件与大家在普通公司遇到的可能相当不同。因此，我们的问题及解决方案可能与你自己的设置匹配，也可能不匹配！
一个大型的机器学习作业跨越许多节点，当它可以访问每个节点上的所有硬件资源时，运行效率最高。这允许 GPU 直接使用 NVLink 进行交叉通信，或者 GPU 使用 GPUDirect 直接与 NIC 进行通信。因此，对于我们的许多工作负载，单个 Pod 占用整个节点。任何 NUMA、CPU 或 PCIE 资源争用都不是调度的因素。装箱或碎片化不是常见的问题。我们目前的集群具有完全的二分带宽，因此我们也不考虑机架或网络拓扑。所有这些都意味着，虽然我们有许多节点，但调度程序的负载相对较低。
话虽如此，kube-scheduler 的负载是有波动的。一个新的作业可能由许多数百个 Pod 同时创建组成，然后返回到相对较低的流失率。
我们最大的作业运行 MPI，作业中的所有 Pod 都参与一个单一的 MPI 通信器。如果任何一个参与的 Pod 挂掉，整个作业就会停止，需要重新启动。作业会定期进行检查点，当重新启动时，它会从上一个检查点恢复。因此，我们认为 Pod 是半有状态的——被删掉的 Pod 可以被替换并且工作可以继续，但这样做会造成干扰，应该尽量减少发生。
我们并不太依赖 Kubernetes 的负载均衡。我们的 HTTPS 流量非常少，不需要进行 A/B 测试、蓝 / 绿或金丝雀部署。Pod 使用 SSH 直接通过 Pod IP 地址与 MPI 进行通信，而不是通过服务端点。服务“发现”是有限的；我们只在作业启动时进行一次查找，查找哪些 Pod 参与 MPI。</description></item><item><title>chroot</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Chroot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Chroot/</guid><description>概述 参考：
Wiki, chroot Manual(手册)，chroot(2) Change root(改变根，简称 Chroot) 是 Unix-like OS 的一种操作，用于更改对当前正在运行的进程及其子进程展现出来的 / 目录。在这种修改过的环境中运行的程序无法访问指定目录之外的文件。
Chroot 的意思是改变根路径的位置(Linux 系统中以 / 为根目录位置，但是对于执行 Chroot 的用户或者程序来说，是 Chroot 后 PATH 的位置是新的根目录位置)，比如 Telnet，ssh，如果都定义了 Chroot(PATH)规则，那么远程登录的用户将无法访问到该 linux 系统中除了定义的 PATH 外的其余目录
]# pwd /var/lib/docker/overlay2/72a3b770bf98493a90e2e335adbdc9f92eeb18f19044136f74c5c9138cb13304/merged ]# ls bin dev etc home lib LICENSE NOTICE npm_licenses.tar.bz2 proc prometheus root sys tmp usr var ]# ls /root backup downloads go nohup.out p.pcap projects scripts snap tmp ]# chroot . /bin/sh / # pwd / / # ls /root / # 上面例子中，我们通过 chroot 程序进入了以 /var/lib/docker/overlay2/72a3b770bf98493a90e2e335adbdc9f92eeb18f19044136f74c5c9138cb13304/merged/ 目录作为 / 目录的空间中。这就像是将本地文件系统划分了一块空间给 Chroot 后的使用者。</description></item><item><title>CimCmdlets</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/CimCmdlets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/CimCmdlets/</guid><description>概述 参考：
官方文档 - PowerShell，模块 - CimCmdlets https://learn.microsoft.com/zh-cn/powershell/scripting/learn/ps101/07-working-with-wmi
PowerShell 早期使用 Windows Management Instrumentation(简称 WMI) cmdlet，后改用 CIM cmdlet。可以使用 Get-Command -Module CimCmdlets 命令查看所有可用的 CimCmdlets
CommandType Name Version Source ----------- ---- ------- ------ Cmdlet Get-CimAssociatedInstance 7.0.0.0 CimCmdlets Cmdlet Get-CimClass 7.0.0.0 CimCmdlets Cmdlet Get-CimInstance 7.0.0.0 CimCmdlets Cmdlet Get-CimSession 7.0.0.0 CimCmdlets Cmdlet Invoke-CimMethod 7.0.0.0 CimCmdlets Cmdlet New-CimInstance 7.0.0.0 CimCmdlets Cmdlet New-CimSession 7.0.0.0 CimCmdlets Cmdlet New-CimSessionOption 7.0.0.0 CimCmdlets Cmdlet Register-CimIndicationEvent 7.0.0.0 CimCmdlets Cmdlet Remove-CimInstance 7.0.0.0 CimCmdlets Cmdlet Remove-CimSession 7.</description></item><item><title>Clang</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Clang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Clang/</guid><description>概述 参考：
Wiki, Clang Clang (/ˈklæŋ/) 是 C、C++、Objective-C 和 Objective-C++ 编程语言以及 OpenMP、OpenCL、RenderScript、CUDA、SYCL 和 HIP 的 Compiler(编译器) 前端框架。它充当 GNU 编译器集合 (GCC) 的直接替代品，支持其大部分编译标志和非官方语言扩展。它包括一个静态分析器和几个代码分析工具。</description></item><item><title>CLI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/CLI/CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/CLI/CLI/</guid><description>概述 参考：
https://github.com/spf13/cobra
https://github.com/urfave/cli
github.com/alecthomas/kingpin
Prometheus 使用这个 CLI https://github.com/alecthomas/kong
kingping 的作者改用 kong 在 Linux 中使用命令时会用到 SubCommand 和 Options或Flag，这些子命令和选项，以及命令的帮助信息都是通过命令行参数处理这个功能里的各种函数来实现的。该功能也也叫从命令行读取参数。并且这些子命令以及选项或标志统称为命令行参数。备注：Linux 中的每一个命令其实就是一个已经编译好的程序。
flag 包
使用flag包中的相关函数来实现解析命令行的 flag 或 option，详情见：https://golang.org/pkg/flag/#hdr-Usage
下面是其中几种 flag 包的格式说明
格式 1：flag.TYPE(FlagName, DefaultValue, HelpInfo)。FlagName 为参数名，DefaultValue 为参数的默认值，HelpInfo 为该参数的帮助信息。返回默认值的指针
格式 2：flag.TYPE(Pointername ,FlagName, DefaultValue, HelpInfo)。与上面的格式相同，只不过没有返回值，并且会把DefaultValue赋值给Pointer指针指向的变量，该变量需要提前定义。
test := flag.String(&amp;#34;test&amp;#34;,&amp;#34;testValue&amp;#34;,&amp;#34;请指定test参数&amp;#34;) flag.Parse() //注意必须要有该行才能让test变量获取用户输入的参数，否则一直是默认值 fmt.Println(test) 使用方式：go run test.go -test 123结果为123；若不指定-test 123这个参数，则结果为testValue。如果使用go tun test.go -help则可获得帮助信息请指定test参数
Args
使用 Go 自带的 Args 切片变量获取命令参数。Args 切片的第一个位置为文件名的绝对路径，第二个位置是使用程序时输入的参数，以空格作为分隔符，分隔每个参数。每个参数都会保存到切片中。e.g.go run runCommand.go ip,这时候ip的值就会传递到 Args[1] 的位置上。</description></item><item><title>CLI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/CLI/</guid><description>概述 参考：
你好，这是必应。我可以用中文回答你的问题。
Python 生态中有很多用于 CLI 的库，例如：
pyCLI：一个用于创建简单、正确的命令行应用的框架，提供了标准的命令行解析、日志、测试和性能分析等功能。 好像不更新了？ Python Fire：一个用于自动从任何 Python 对象生成命令行接口的库，是一种在 Python 中创建 CLI 的简单方法。 argparse：Python 标准库中的一个模块，用于快速地创建 CLI 应用，无需安装第三方库。 Click：一个用于创建美观、可组合的命令行接口的 Python 包，代码量很少，配置灵活，提供了很多默认选项。 你可以根据你的需求和喜好选择合适的库。如果你想要更多的信息，你可以点击下面的链接查看相关文档或源码。
- [1]: cli — command line tools — pyCLI devel documentation [2]: GitHub - google/python-fire: Python Fire is a library for automatically &amp;hellip; [3]: Build Command-Line Interfaces With Python&amp;rsquo;s argparse [4]: click · PyPI [5]: Welcome to Click — Click Documentation (8.1.x) - Pallets
根据搜索结果，Go 的 cobra 库是一个用于创建强大的现代 CLI 应用的框架，提供了简单的接口和应用脚手架生成工具1 2 3。</description></item><item><title>CLI</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/CLI/</guid><description>概述 参考：
https://www.wireshark.org/docs/wsug_html_chunked/AppTools.html editcap 万能的 pcap 编辑器，可以过滤、分隔 pcap 文件
Syntax(语法) mergecap 可以将多个 pcap 文件合并为一个
tshark</description></item><item><title>ClickHouse SQL</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/ClickHouse-SQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/ClickHouse/ClickHouse-SQL/</guid><description>概述 参考：
官方文档，SQL 参考 SQL 关键字 可以在 官方文档，SQL 参考 - 语句 看到 ClickHouse 支持的所有 SQL 基础关键字。诸如常见的 SELECT、INSERT、etc. 还有一些独属于 ClickHouse 的关键字，e.g. KILL、OPTIMIZE、etc.
SELECT 有 EXCEPT 修饰符，可以用于排除某些列，比如下面的 SQL 可以从表中排除 domain 与 url 两列（i.e 返回结果没有这俩列）
SELECT * EXCEPT (domain,url) FROM nginx_logs.nginx_access ARRAY JOIN https://clickhouse.com/docs/sql-reference/statements/select/array-join
常用在多表联合查询的场景。下面的 SQL 用来从 my_table_one 表查询出某些结果，并将结果作用在 my_table_two 表中进行多次过滤。具体逻辑是：
从 my_table_one 表中查询 start_time 与 end_time 并组成各自的数组 利用 ARRAY JOIN，对 start_times 和 end_times 进行遍历，每次遍历都查询一次 my_tables_two，数组中的元素作为 WHERE 中的条件。 WITH time_ranges AS ( SELECT groupArray(DISTINCT start_time) AS start_times, groupArray(DISTINCT end_time) AS end_times FROM my_database.</description></item><item><title>Client Libraries</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/Client-Libraries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/Client-Libraries/</guid><description>概述 参考：
官方文档，参考 - 使用 API - 客户端库 Client Libraries(客户端库) 是各种编程语言的第三方库的统称。这些库可以用来让各种编程语言通过代码的方式访问 Kubernetes API。在使用这些库编写代码时，并不需要自己实现对 Kubernetes API 的调用和 处理 Request/Response，这些处理逻辑都在 Client Libraries 中包括了。客户端库还会处理诸如身份验证之类的行为。
如果代码在 Kubernetes 集群中运行，代码中的 Client Libraires 可以发现并使用 Kubernetes 的 ServiceAccount 进行身份验证。
如果代码在 Kubernetes 集群外运行，代码中的 Client Libraires 能够理解 KubeConfig 格式来读取凭据和 API 服务器地址。
Kubernetes 现阶段官方支持 Go、Python、Java、 dotnet、Javascript 和 Haskell 语言的客户端库。还有一些其他客户端库由对应作者而非 Kubernetes 团队提供并维护。 参考客户端库了解如何使用其他语言 来访问 API 以及如何执行身份认证。
Go Client</description></item><item><title>Cluster 命令</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/Cluster-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/Cluster-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
https://redis.io/docs/latest/commands/?group=cluster 一、以下命令是Redis Cluster集群所独有的，执行下面命令需要先登录redis：
[root@manage redis]# redis-cli -c -p 6382 -h 192.168.10.12 （客户端命令：redis-cli -c -p port -h ip）
192.168.10.12:6382&amp;gt; 登录redis后，在里面可以进行下面命令操作
集群
cluster info ：打印集群的信息
cluster nodes ：列出集群当前已知的所有节点（ node），以及这些节点的相关信息。
节点
cluster meet ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。
cluster forget ：从集群中移除 node_id 指定的节点。
cluster replicate ：将当前从节点设置为 node_id 指定的master节点的slave节点。只能针对slave节点操作。
cluster saveconfig ：将节点的配置文件保存到硬盘里面。
槽(slot)
cluster addslots [slot &amp;hellip;] ：将一个或多个槽（ slot）指派（ assign）给当前节点。
cluster delslots [slot &amp;hellip;] ：移除一个或多个槽对当前节点的指派。
cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。
cluster setslot node ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给</description></item><item><title>CMDB</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/CMDB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/CMDB/</guid><description>概述 参考：
Wiki, CMDB Configuration management database(配置管理数据库，简称 CMDB) 是一个 ITIL 术语，指的是组织用来存储有关硬件和软件资产（通常称为配置项）信息的数据库。
CMDB 项目推荐
https://github.com/Combodo/iTop https://github.com/vbkunin/itop-docker https://github.com/TencentBlueKing/bk-cmdb https://github.com/veops/cmdb 维易 CMDB 文章: https://mp.weixin.qq.com/s/6W8DaDb3Y4NmK3rb9NGKAQ 简单的记录功能直接用 WPS 的轻维表即可，专治各种花里胡哨的开源产品。
fiy 参考：
GitHub 项目，lanyulei/fiy 部署问题：
使用 lz270978971/fiy-ui:latest 镜像构建前端
docker run -it lz270978971/fiy-ui:latest /bin/sh vim .env.production 修改其中的 VUE_APP_BASE_API 的值为运行 fiy 服务器机器的 IP npm run build:prod 打包前端页面 详见 issue 11 处理后端
clone fiy 后端代码，并在项目根目录下创建 statci/ui 目录，将容器内的 dist/ 目录的所有文件拷贝到刚创建的 static/ui/ 目录下 修改 config/settings.yml 文件中的数据库配置，如果需要使用搜索功能，还需要配置 es go build -ldflags=&amp;quot;-s -w&amp;quot; -o fiy main.</description></item><item><title>CNCF</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/CNCF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/CNCF/</guid><description>概述 参考:
CNCF 官网 云原生全景图 jimmysong Cloud Native Computing Foundation(云原生计算基金会，简称 CNCF)。成立于 2015 年 7 月 21 日，属于 Linux 基金会旗下的一个非盈利性组织。当年 Google 内部将内部容器编排项目 Borg 开源，为了项目更好的发展，Google 与 Linux 基金会一些创办了 CNCF。同时，Google 把 Borg 用 Go 语言重写，更名为 Kubernetes 并捐赠给 CNCF、
CNCF 项目治理 参考:
官方文档 jimmysong CNCF 根据“鸿沟理论”将其托管的项目分成三个成熟阶段，并设置了项目晋级到更高阶段的标准。
“鸿沟理论”是由 Geoffrey A. Moore 提出的高科技产品的市场营销理论。新技术要想跨越鸿沟，必须能够实现一些跨越式的发展，拥有某一些以前不可能实现的功能，具有某种内在价值并能够赢得非技术人员的青睐。
Graduated(已毕业) Incbating(孵化中) Sandbox(沙盒) CNCF Ambassador(CNCF 大使) 参考：
CNCF 官网 可以通过以下方式成为 CNCF Ambassador：
成为 CNCF 会员或对成为某个 CNCF 的项目的贡献者 以 contributor、blogger、演讲者等身份参与 CNCF 社区项目 在社区中演讲或撰写博客 主持云原生社区 meetup</description></item><item><title>code-server</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/code-server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/code-server/</guid><description>概述 参考：
GitHub 项目，coder/code-server 官网 code-server 可以让 VS Code 运行在任何机器上，并在浏览器中访问。
code-server 是一个免费的基于浏览器的 IDE，而 Coder 是该企业提供的收费版本。
部署 mkdir -p /opt/code-server/user-data-dir nerdctl run --name code-server --network host -d \ -v &amp;#34;/opt/code-server/user-data-dir:/root&amp;#34; \ -u &amp;#34;$(id -u):$(id -g)&amp;#34; \ -e &amp;#34;DOCKER_USER=$USER&amp;#34; \ codercom/code-server:latest 个性部署 nerdctl run --name code-server --network host -d \ -v &amp;#34;/opt/code-server/user-data-dir:/root&amp;#34; \ -v &amp;#34;/usr/local/go:/usr/local/go&amp;#34; \ -v &amp;#34;/root/go:/root/go&amp;#34; \ -v &amp;#34;/root/projects:/root/projects&amp;#34; \ -u &amp;#34;$(id -u):$(id -g)&amp;#34; \ -e &amp;#34;DOCKER_USER=$USER&amp;#34; \ -e &amp;#34;GOPROXY=https://goproxy.cn,https://goproxy.io,https://mirrors.aliyun.com/goproxy/,direct&amp;#34; \ codercom/code-server:latest \ --bind-addr 0.</description></item><item><title>Collector component</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Collector/Collector-component/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/OpenTelemetry/Collector/Collector-component/</guid><description>概述 参考：
GitHub 项目，open-telemetry/opentelemetry-collector-contrib Receivers # https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver
Processors # https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor
Exporters # https://github.com/open-telemetry/opentelemetry-collector/tree/main/exporter
Connector # https://github.com/open-telemetry/opentelemetry-collector/blob/main/connector
Extension # https://github.com/open-telemetry/opentelemetry-collector/blob/main/extension
Receiver Filelog https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/filelogreceiver
从文件读取日志
Processor Attributes https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/attributesprocessor
Resource https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/resourceprocessor
改变 Attributes(属性)
Exporter Connector Extension</description></item><item><title>Compiler</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Compiler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Compiler/</guid><description>概述 参考：
Wiki, Compiler 在计算机中，Compiler(编译器) 是一个计算机程序，它将用一种编程语言（源语言）编写的计算机代码翻译成另一种语言（目标语言）。术语 “编译器” 主要用于指将源代码从高级编程语言翻译成低级编程语言（例如汇编语言、目标代码或机器代码）以创建可执行程序。
Tips: 口语、实践 中常挂在嘴边的编译器通常并不是一个独立的程序，而是一组工具的集合。e.g. GCC, LLVM, etc.</description></item><item><title>Computer monitor</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Peripheral/Computer-monitor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Peripheral/Computer-monitor/</guid><description>概述 参考：
Wiki, Computer monitor Wiki, Display device Computer monitor(计算机显示器) 是一种 Display device(显示设备)
https://www.hangjianet.com/topic/15878877588150143
屏幕 为什么部分人能接受厂商对ips屏幕漏光属正常现象不在昏暗环境和纯黑界面下不影响正常使用这一说法?
va 屏和 ips 屏都是一种液晶显示屏技术，va 屏全称为Vertical Alignment，是一种在液晶分子排列方向上具有垂直对齐的屏幕类型。 ips 屏全称为 In-Plane Switching屏幕，
B 站，【硬核独家】屏幕刺眼原因及应对措施
莱茵认证 https://www.certipedia.com/ 莱茵数据库 护眼显示器 https://www.bilibili.com/video/BV1Y54y1M7rN Low Blue Light（Hardware Solution）低蓝光硬件解决方案
设置 Adaptive-Sync
Over Drive(过驱动，简称 OD) # 是一种通过在液晶分子转向过程中提高驱动电压来加快液晶响应速度的方法。开启OD功能可以有效减少GTG和MPRT指标,提高显示流畅度。OD技术常被用于游戏显示器和高清视频电视中。
Motion Picture Response Time(简称 MPRT) # 动态响应时间,用于衡量显示器在显示动态视频时,像素的变化速度。MPRT越低,意味着动态图像的残影和拖影越少,动态对比度越高,显示动态图像效果越好。MPRT是评价显示器游戏和视频体验的重要指标。</description></item><item><title>ConfigMap 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/ConfigMap-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/ConfigMap-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，用户指南-ConfigMap GitHub 代码中的可用的配置，及其默认值 可以通过 ConfigMap 资源来控制 Nginx Ingress Controller 的运行时行为。Nginx Ingress Controller 将会读取指定 ConfigMap 对象中的 .data 字段下的内容，并解析其中的内容，转换为传统 Nginx 的配置。
.data 字段下的内容由无数的 Key/Value Pairs(键/值对) 组成。绝大部分 Key 都会对应一个 Nginx 的 Directives(指令)。Key 的 Value 就是指令的参数。假如现在有如下 ConfigMap 配置：
data: map-hash-bucket-size: &amp;#34;128&amp;#34; ssl-protocols: SSLv2 这就会生成如下 Ngxin 的配置
http { ······ map_hash_bucket_size 128; ssl_protocols SSLv2; ······ } 可用的 Key 详解 下面每个 Key 的详解中，若没写对应指令，则表示这个 Key 没有对应的老式 Nginx 指令。
enable-undersores-in-headers(BOOLEAN) # 是否接收 key 中带有下划线的请求头。
默认值：&amp;quot;true&amp;quot; 对应指令：underscores_in_headers log-format-escape-json(BOOL) # 是否为 log_format 指令开启 escape(转义) 参数</description></item><item><title>Connection Plugins</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Plugins/Connection-Plugins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Plugins/Connection-Plugins/</guid><description>概述 参考：
官方文档，Connection 插件 连接插件允许 Ansible 连接到目标主机，以便它可以在它们上执行任务。 Ansible 附带了许多连接插件，但每个主机一次只能使用一个。
默认情况下，Ansible 附带了几个连接插件。 最常用的是 ssh 和 local 类型。 所有这些都可以在剧本中使用，并与 /usr/bin/ansible 一起决定你想如何与远程机器交谈。 如有必要，我们可以创建自定义连接插件。
SSH https://docs.ansible.com/ansible/latest/collections/ansible/builtin/ssh_connection.html</description></item><item><title>container</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/container/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/container/</guid><description>概述 参考：
官方文档，参考 - CLI - docker - container run 参考：
官方文档，参考 - 命令行参考 - docker-Docker run 参考 官方文档，参考 - 命令行参考 - docker-docker run run 命令可以启动容器
Syntax(语法) docker run [OPTIONS] ImageName [COMMAND] [ARG&amp;hellip;]
OPTIONS -d, &amp;ndash;detach # 让容器运行在后台并打印出容器的 ID &amp;ndash;entrypoint(STRING) # 覆盖容器镜像的的默认 ENTRYPOINT。即 Dockerfile 指令 中的 ENTRYPOINT。 -e, &amp;ndash;env(LIST) # 设定容器内的环境变量。LIST 格式为 VAR=VALUE，若要指定多个变量，则使用多次 &amp;ndash;env 选项。 &amp;ndash;env-file list Read in a file of environment variables &amp;ndash;expose(LIST) # 等效于 Dockerfile 中的 EXPOSE 指令，仅暴露容器端口，不在宿主机暴露。 -h, &amp;ndash;hostname(STRING) # 指定容器内的 hostname &amp;ndash;init Run an init inside the container that forwards signals and reaps processes -i, &amp;ndash;interactive # 即使没有 attach 到容器，也保持 STDIN(标准输入)开启。通常与 -t 一起使用 &amp;ndash;name(STRING) # 为容器分配一个名称。默认为随机字符串 &amp;ndash;network(STRING) # 连接一个容器到一个容器网络(default &amp;ldquo;default&amp;rdquo;)，可以是 docker network ls 列出的网络，也可以是其余 container 的网络。STRING 包括下面几种 none # 容器使用自己的网络（类似&amp;ndash;net=bridge），但是不进行配置 bridge # 通过 veth 接口将容器连接到默认的 Docker 桥(默认为 docker0 的网桥).</description></item><item><title>Control structure</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/</guid><description>概述 参考：
Python 语言提供了多种条件结构和分支结构用作 Control structure(控制结构)
with 参考：
官方文档，参考 - 8.复合语句 - 8.5 with 语句 with 语句用于包装带有使用上下文管理器 (参见 with 语句上下文管理器 一节) 定义的方法的代码块的执行。 这允许对普通的 try&amp;hellip;except&amp;hellip;finally 使用模式进行封装以方便地重用。语法如下：
with EXPRESSION as TARGET: SUITE EXPRESSION 的返回值赋值给 TARGET 变量，在 SUITE 中可以处理 TARGET。
用白话解释：Python 中的 with 语句用于异常处理，封装了 try…except…finally 编码范式，提高了易用性。with 语句使代码更清晰、更具可读性， 它简化了文件流等公共资源的管理。在处理文件时使用 with 关键字是一种很好的做法。
file = open(&amp;#39;./test_runoob.txt&amp;#39;, &amp;#39;w&amp;#39;) file.write(&amp;#39;hello world !&amp;#39;) file.close() # 使用 try 的话 file = open(&amp;#39;./test_runoob.txt&amp;#39;, &amp;#39;w&amp;#39;) try: file.write(&amp;#39;hello world&amp;#39;) finally: file.close() 以上代码我们对可能发生异常的代码处进行 try 捕获，发生异常时执行 except 代码块，finally 代码块是无论什么情况都会执行，所以文件会被关闭，不会因为执行异常而占用资源。</description></item><item><title>CoreDNS Plugins</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/CoreDNS-Plugins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/CoreDNS-Plugins/</guid><description>概述 参考：</description></item><item><title>CPU 架构引起的问题</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/CPU-%E6%9E%B6%E6%9E%84%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/CPU-%E6%9E%B6%E6%9E%84%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98/</guid><description>概述 参考：
利用 qemu user 模式和 binfmt_misc 构建其他架构的 docker 镜像 https://zhangguanzhang.github.io/2023/03/07/qemu-binfmt_misc/
qemu-user-static 下 cgo go build 卡住的一次解决 https://zhangguanzhang.github.io/2023/08/08/qemu-cgo-build-hang</description></item><item><title>CPU资源的调度和管理(CFS)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%9A%84%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/CPU%E8%B5%84%E6%BA%90%E7%9A%84%E8%B0%83%E5%BA%A6%E5%92%8C%E7%AE%A1%E7%90%86CFS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%9A%84%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/CPU%E8%B5%84%E6%BA%90%E7%9A%84%E8%B0%83%E5%BA%A6%E5%92%8C%E7%AE%A1%E7%90%86CFS/</guid><description>概述 参考：
CSDN，Kubernetes生产实践系列之三十一：Kubernetes基础技术之CPU资源的调度和管理(CFS) 一、前言 在使用 Kubernetes 的过程中，我们看到过这样一个告警信息：
[K8S]告警主题: CPUThrottlingHigh
告警级别: warning
告警类型: CPUThrottlingHigh
故障实例:
告警详情: 27% throttling of CPU in namespace kube-system for container kube-proxy in pod kube-proxy-9pj9j.
触发时间: 2020-05-08 17:34:17
这个告警信息说明 kube-proxy 容器被 throttling 了，然而查看该容器的资源使用历史信息，发现该容器以及容器所在的节点的 CPU 资源使用率都不高：
告警期间容器所在节点 CPU 使用率
告警期间 kube-proxy 的资源使用率
经过我们的分析，发现该告警实际上是和 Kubernetes 对于 CPU 资源的限制和管控机制有关。Kubernetes 依赖于容器的 runtime 进行 CPU 资源的调度，而容器 runtime 以 Docker 为例，是借助于 cgroup 和 CFS 调度机制进行资源管控。本文基于这个告警案例，首先分析了 CFS 的基本原理，然后对于 Kubernetes 借助 CFS 进行 CPU 资源的调度和管控方法进行了介绍，最后使用一个例子来分析 CFS 的一些调度特性来解释这个告警的 root cause 和解决方案。</description></item><item><title>Cron</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Cron/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Cron/</guid><description>概述 参考：
Wiki, Cron 软件实用程序 Cron 也称为 Cron Job(定时任务)，是类 Unix 计算机操作系统中基于时间的 Job 调度 程序。设置和维护软件环境的用户使用 cron 来调度作业 (命令或 shell 脚本)，以便在固定的时间、日期或时间间隔定期运行。
cron 的操作由 Cron Table(计划任务表，简称 crontab) 文件驱动，该文件是一个配置文件，用于指定按给定计划定期运行的命令。 crontab 文件存储在保存作业列表和 cron 守护程序的其他指令的位置。用户可以拥有自己的个人 crontab 文件，并且通常有一个系统范围的 crontab 文件（通常在 /etc 或 /etc 的子目录中），只有系统管理员才能编辑。
Syntax(语法) Cron Table 的格式如下：
# ┌───────────── minute (0 - 59) # │ ┌───────────── hour (0 - 23) # │ │ ┌───────────── day of the month (1 - 31) # │ │ │ ┌───────────── month (1 - 12) # │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday; # │ │ │ │ │ 7 is also Sunday on some systems) # │ │ │ │ │ # │ │ │ │ │ # * * * * * &amp;lt;COMMAND&amp;gt; 一个 crontab 中可以有多行，每行都代表一个 Job。</description></item><item><title>CronJab Manifests</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/CronJab-Manifests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/CronJab-Manifests/</guid><description>概述 参考：
官方文档，参考-KubernetesAPI-工作负载资源-CronJob</description></item><item><title>crypto 库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86/crypto-%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86/crypto-%E5%BA%93/</guid><description>概述 参考：
Go crypto 库 Go crypto/rsa 库 Go crypto/x509 库 Go encoding/pem 库 简书 crypto 标准库中主要有 cipher、rand、aes、rsa、x509、等等用于密码学加密的子包。
cipher 包实现了标准的的 Block cipher、Stream cipher，可以围绕低级分组密码实现进行包装 rand 包 # 顾名思义，用来生成随机数的 aes 包 # 实现了 AES 加密 rsa 包 # 实现 PKCS #1 和 RFC 8017中指定的 RSA 加密 x509 包 # 实现了 X.509 标准的一个子集 AES包 依赖 cipher 包，需要实例化一个 Block cipher，然后使用这个 cipher.Block 下的方法进行加密/解密。
由于国际组织不推荐使用 ECB 的方式，所以该库没有实现 ECB 模式的方法，需要自己手动写函数。
RSA 包 rsa 库大体分为 加密/解密 与 签名/验签 这两大类。</description></item><item><title>cURL</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/cURL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/cURL/</guid><description>概述 参考：
GitHub 项目，curl/curl 官网 Manual(手册) cURL 是一个用于 URL 与 URIs 传输的命令行工具和库，始于 1998 年。
早在 20 世纪 90 年代中期，当时互联网还处于萌芽阶段，瑞典程序员 Daniel Stenberg 开始了一个项目，这个项目最终发展成了我们今天所知道的 curl 程序。
最初，他的目标是开发一种机器人，可以定期从网页上下载货币汇率，并向 IRC 用户提供等值的瑞典克朗美元。这个项目蓬勃发展，在这个过程中添加了几个协议和特性——剩下的就是历史了。
curl 是常用的命令行工具，用来请求 Web 服务器。它的名字就是“客户端(client)的 URL ”工具的意思。
注意：curl 最常见是通过网络 URL 来传输数据。但是，curl 还可以通过 Socket 的 URL 来传输数据，只需要使用 &amp;ndash;unix-socket 选项指定 Socket 路径即可。
Syntax(语法) curl [OPTIONS] URL&amp;hellip;.
如果没有另外说明，curl 将接收到的数据写入标准输出。可以使用 -o、&amp;ndash;output 或 -O、&amp;ndash;remote-name 选项将该数据保存到本地文件中。如果 curl 被赋予多个 URL 以在命令行上传输，它同样需要多个选项来保存它们。curl 不会解析或以其他方式“理解”它作为输出获取或写入的内容。它不进行编码或解码，除非使用专用命令行选项明确要求。
OPTIONS 由于 curl 程序支持多种协议，可以使用各种不同的协议向指定的 URL 发起请求，所以，并不是所有选项都适用于所有协议。在下面的笔记中，每个选项后面会添加一个 ()，括号中说明此选项支持的协议，多个协议以空格分割；没有 () 的表示该选项适用于所有协议。若括号内为 TLS 则表示使用安全的各种协议，比如 https、ftps、imaps 等等</description></item><item><title>D-Bus</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/D-Bus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/D-Bus/</guid><description>概述 参考：
D-Bus 是一个 IPC 及 RPC 机制，可以让多个不同的计算机进程在同一台电脑上同时进行通信。</description></item><item><title>Data Model(数据模型)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Data-Model%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/Data-Model%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考：
官方文档没有专门讲 Log Stream 的章节，Stream 的概念都是在其他章节提到的 官方文档，入门 - 标签 官方文档，运维 - 存储 Log Stream(日志流) 概念 Loki 通过一种称为 Log Stream(日志流) 的概念组织所有日志数据。Log Stream(日志流) 之于 Loki 类似于 Time series(时间序列) 之于 Prometheus
Loki 使用 Stream(流) 这个词来描述保存的日志数据，并根据 Label(标签) 来定位日志流，Label 是日志流的元数据。Label 的概念和用法与 Prometheus 中的 Label 一致。如果 Loki 与 Prometheus 同时使用，那么他们之间得标签是一致的，通过 Label，很容易得就可以将应用程序指标和日志数据关联起来。
Stream 与 Label 是强关联的，在 Loki 中，Label 是唯一可以定义 Log Stream 的东西。每个标签键和值的组合定义了一条 log stream。如果一个标签值发生了变化，则这会生成一个新的 Log stream。在 Prometheus 中，类似 Log Stream 概念的是 time series(stream 对应 series)。但是不同的是，在 Prometheus 中还有一个维度，是 metrics name(指标名称)。但是在 Loki 中则谁 Path，一个 采集日志的 Path 实际上是会采集很多很多日志的。也正是由于此，所以 Loki 将这种概念称为 Stream，而不是 Series。</description></item><item><title>Data Model(数据模型)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Storage/Data-Model%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Storage/Data-Model%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考：
官方文档，概念 - 数据模型 yunlzheng 文档 Prometheus 从根本上将所有数据存储为 时间序列数据：属于同一度量标准和同一组标注维度的带有时间戳的值流。除了存储的时间序列外，Prometheus 可能会生成临时派生的时间序列作为查询的结果。
Time-Series Data(时间序列数据) 概念 参考：
Wiki, Time series InfluxDB 对时间序列数据的定义 这是论文 Time Series(时间序列) 是一组按照时间发生先后顺序进行排列的数据点序列。通常一组时间序列的时间间隔为一恒定值（如 1 秒，5 分钟，12 小时，7 天，1 年），因此时间序列可以作为离散时间数据进行分析处理。时间序列广泛应用于数理统计、信号处理、模式识别、计量经济学、数学金融、天气预报、地震预测、脑电图、控制工程、航空学、通信工程以及绝大多数涉及到时间数据测量的应用科学与工程学。
Time Series Data(时间序列数据，简称 series) 是在一段时间内通过重复 Measurement(测量) 而获得的观测值的集合；可以将这些观测值绘制于图形之上，它会有一个数据轴和一个时间轴。
从另一个角度看，时间序列数据是在不同时间上收集到的数据，用于所描述现象随时间变化的情况。这类数据反映了某一事物、现象等随时间的变化状态或程度。
Prometheus 中时间序列数据的组成 时间序列(Time Series,简称 series) 有序列、系列的意思。比如有这么几种描述：一系列的书、这一系列操作、等等。可以通过这种语境来理解 series(比如可以这么描述：这一系列数据)。
与传统意义上定义的时序数据一样，由两部分组成：
Metrics(指标) # 用来描述要采集的数据指标，是时序数据的唯一标识符。例如：检测各个城市的风力、系统内存已使用的字节数 等等。相当于关系型数据库中的表。 Sample(样本) # 针对监测对象的某项指标(由 Metric 和 Tag 定义)按特定时间间隔采集到的每个 Metric 值就是一个 Sample(样本)。类似关系型数据库中的一行。 首先需要明确一个概念：
Vector(向量)(也称为欧几里得向量、几何向量、矢量)，指具有大小和方向的 Magnitude(量)。它可以形象化地表示为带箭头的线段。箭头所指：代表向量的方向；线段长度：代表向量的大小。与向量对应的量叫做数量（物理学中称标量），数量（或标量）只有大小，没有方向。
Prometheus 会将所有采集到的样本数据以 TimeSeries(时间序列) 的方式保存在内存数据库中，并且定时保存到硬盘上。TimeSeriesData 是按照时间戳和值的序列顺序存放的一条不规则有方向的线段，我们称之为 Vector(向量)。每条 TimeSeriesData 通过 MetricsName(指标名称) 和一组 LabelSet(标签集) 作为唯一标识符。如下所示，可以将 TimeSeries 理解为一个以时间为 x 轴、值为 y 轴的数字矩阵；而这个矩阵中的每一个点都是一个 Sample(样本)，相同 MetricName 和 LabelSet 的多个样本之间连成的线段就是时间序列数据。</description></item><item><title>Data Pipeline</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/DataPipeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/DataPipeline/DataPipeline/</guid><description>概述 参考：
https://www.mezmo.com/blog/what-is-an-observability-data-pipeline https://vector.dev/docs/about/what-is-observability-pipelines/ https://www.dqlabs.ai/blog/what-is-a-data-pipeline-types-architecture-components/ Data Pipeline(数据管道) 是一个抽象概念，通过 Data Pipeline 对多个来源的可观测性数据进行 聚合、处理、并将其路由到各种目的地。这解决了多个问题，包括：
需要将数据集中到一个位置。 结构化和丰富数据的能力，以便更容易理解并从中获取价值。 需要将数据发送到多个目的地或团队以实现多个用例。 需要控制数据量并仅以正确的格式将正确的数据发送到正确的目的地。 不管是 集成在程序内部的一段代码、在外部运行的采集程序，都可以看作是一种 DataPipeline。e.g. Loki 的 Promtail、Prometheus 的 Instrumenting、etc. 都属于一种 DataPipeline 的实现。
用人话说：将数据从一个地方流到另一个地方的行为，就是 Pipeline 行为。就像 Pipeline 名字一样，管道，只不过是用来承载数据的管道，可以让数据从管道的一段流向另一端。
从逻辑上看，可观测数据从采集到入库的过程中，可以存在多级 DataPipeline，采集程序自身也可以当作 DataPipeline 的一部分；然后中间可以经过处理或路由，也可以不经过处理或路由；最后进入到数据库中。</description></item><item><title>Data type</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/Data-type/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/Data-type/</guid><description>概述 参考：
Wiki, DataType 在计算机科学和计算机编程中，Data Type(数据类型，有时也简称 Type) 是数据的一个属性，这些属性将会让编译器知道程序员想要如何使用数据。
Literal(字面量) 与 Variable(变量) 相关，是用于初始化变量时指定的一个值。
数据类型的分类 原始数据类型 复合数据类型 抽象数据类型 其他类型 TODO Primitive Data Types(原始数据类型) 原始数据类型通常是语言实现的内置或基础类型。
Machine Data Type(机器数据类型) 基于数字电子的计算机中的所有数据都表示为最低级别的位（替代 0 和 1）。数据的最小可寻址单元通常是一组称为字节的位（通常是一个八位组，即 8 位）。由机器代码指令处理的单元称为字（截至 2011 年，通常为 32 或 64 位）。大多数指令将字解释为二进制数，因此 32 位字可以表示从 0 到 232 - 1 或有符号整数值来自 -231 到 231 - 1 由于二进制补码，机器语言和机器在大多数情况下不需要区分这些无符号和有符号数据类型。
用于浮点算术的浮点数对字中的位使用不同的解释。有关详细信息，请参阅浮点运算。
机器数据类型需要在系统或低级编程语言中公开或可用，允许对硬件进行细粒度控制。的C 编程语言，例如，建筑材料整数类型不同的宽度，如和。如果目标平台上不存在相应的本机类型，编译器将使用确实存在的类型将它们分解为代码。例如，如果在 16 位平台上请求一个 32 位整数，编译器会默认将其视为两个 16 位整数的数组。 shortlong
在更高级别的编程中，机器数据类型通常被隐藏或_抽象_为一个实现细节，如果暴露，会使代码的可移植性降低。例如，numeric 可以提供泛型类型而不是某些特定位宽的整数。
Boolean Type(布尔类型) Boolean(布尔) 类型表示值 true(真) 和 false(假)。尽管只有两个值是可能的，但出于效率原因，它们很少被实现为单个二进制数字。许多编程语言没有明确的布尔类型，而是将 0 解释为 false，将其他值解释为 true。布尔数据是指如何将语言解释为机器语言的逻辑结构。在这种情况下，布尔值 0 指的是逻辑 False。True 总是非零，尤其是被称为布尔值 1 的一。</description></item><item><title>Data type</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-type/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-type/</guid><description>概述 参考：
MDN 官方文档，JavaScript-JavaScript 数据类型和数据结构 MDN 官方文档，Javascript 标准内置对象(所有类型的对象的列表) 网道，JavaScript 教程-面向对象编程-实例对象与 new 命令 https://www.bilibili.com/video/BV1W54y1J7Ed?p=50 Primitive Type(原始类型，有的地方也称为基本数据类型)
Number(数值) # 十进制数字、科学计数法、其他进程表示方式的数字 String(字符串) # 单引号或双引号内的一切内容 Boolean(布尔) # ture 和 false Null(空) # Undefined Null # Null 类型是 Object，这是由于历史原因造成的。1995 年的 JavaScript 语言第一版，只设计了五种数据类型（对象、整数、浮点数、字符串和布尔值），没考虑 null，只把它当作 object 的一种特殊值。后来 null 独立出来，作为一种单独的数据类型，为了兼容以前的代码，typeof null 返回 object 就没法改变了。 Complex Type(合成类型，有的地方也称为引用数据类型)
object(对象) # 各种值组成的集合，也就是下文提到的 标准内置对象。在很多场景下，第一个 O 是小写的。 object 又划分为很多子类型： Ojbect(对象) # 与 字典、映射 等同义的那个对象。 Array(数组) # Functiom(函数) # JavaScript 中将 Function 当做一种类型来处理 其他 # 通常我们这么描述： Object 类型的 object、Array 类型的 object、String 类型的 object、等等。简化一点就是 Object 对象、Array 对象、String 对象、等等。 数据类型检测</description></item><item><title>Data type</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-type/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-type/</guid><description>概述 参考：
官方文档，参考 - 数据模型 object(对象) 是 Python 中对数据的抽象。Python 程序中的所有数据都是由对象或对象间关系来表示的。 （从某种意义上说，按照冯·诺依曼的“存储程序计算机”模型，代码本身也是由对象来表示的。）
Python 中的 object 概念类似于 JS 中的 object 概念。但是又不完全一样。
Python 变量的本质是对对象的引用
每个 object 都有一个 Identity(标识符)、Type(类型)、Value(值)。一个对象被创建后，它的 Identity 就绝不会改变；你可以将其理解为该对象在内存中的地址。 &amp;lsquo;is&amp;rsquo; 运算符可以比较两个对象的标识号是否相同；id() 函数能返回一个代表其标识号的整数。
CPython 实现细节： 在 CPython 中，id(x) 就是存放 x 的内存的地址。从某个角度来看，获取变量的值，就是获取变量所引用的对象的值。
对于 Python 和 JS 中的 object 来说，这个 object 就像全能的超人一样。。。。o(╯□╰)o。。。而 Go 语言中的全能超人则是 struct
对象的 Type 决定该对象所支持的操作 (例如 &amp;ldquo;对象是否有长度属性？&amp;rdquo; 比如数组类型的长度) 并且定义了该类型的对象可能的取值。type() 函数能返回一个对象的类型 (类型本身也是对象)。与 Identity 一样，一个对象的 Type 也是不可改变的。
下面的代码可以让我们对 Python 对象有更形象的感受：
s = &amp;#34;Hello, World!&amp;#34; # 变量的本质是对象的引用 # 在 Python 中有一个与 ESMAScript 中类似的 object(对象) 概念。 # 在 Python 中，所有的数据都是对象，每一个对象都有唯一的标识符、类型和值。与 JavaScript 不同的是，在 Python 中，变量本身并不拥有内存空间，它只是指向一个对象的引用。因此，我们在 Python 中声明变量时，并不需要显式地指定它的类型。 print(&amp;#34;对象标识符: &amp;#34;, id(s)) print(&amp;#34;对象的类型: &amp;#34;, type(s)) print(&amp;#34;对象的值: &amp;#34;, s) # 由于变量就是对对象的引用，那么就可以调用这个对象的属性和方法。例如： print(s.</description></item><item><title>Dataset</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Dataset/</guid><description>概述 参考：
TODO: Wiki, 没有 Wiki？ https://docs.lanyingim.com/quest/40_20240615_1_73_1718389635.html Datasete(数据集) 是用于 训练模型、测试模型 的一组特定数据的集合。Dataset 中通常包含两部分内容
Unlabeled data(未标记数据) i.e. 原始数据 Labeled data(已标记数据) 也称为 Annotated data(已标注的数据) 通过数据标注，将 Unlabeled data 变为 Labeled data 后，将这些 Labeled data 打包成 Dataset 供模型训练。
有时候，训练模型并需要已标记的数据，比如 无监督学习、etc. 。
Data annotation(数据注释) 参考：
OpenCV 博客，Data Annotation – A Beginner’s Guide Wiki, Labeled data https://www.amantyatech.com/data-annotation-and-labeling-everything-you-need-to-know AWS，What is Data Labeling? https://toloka.ai/blog/annotation-vs-labeling/ Data annotation(数据注释) 是一组数据中的 信息 Annotation(注释)/Label(标签)。这些 信息注释/标签 在不同的场景下有不同的表示含义，e.g. 一张照片中哪部分是牛，哪部分是马；录音中说了哪些词；视频中正在执行什么类型的动作；新闻文章的主题是什么；推文想要表达的是一种什么情绪；X 光片中的一个点是否是肿瘤；etc. 。
[!Note] 上面例子中标记照片中的牛、马通常用于 Object detection(对象检测) 任务、识别音频中的问题通常用于 语音识别 任务、识别动作通常用于 Pose estimation(姿态评估) 任务、etc.</description></item><item><title>Dataset</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Dataset/</guid><description>概述 参考：
https://opencv.org/blog/data-annotation/ Data annotations 参考：
OpenCV 博客，Data Annotation – A Beginner’s Guide 计算机视觉 中的数据注释常见如下几种：
Bounding box Segmentation KeyPoint Lines and Splines etc. TODO 下图中各种颜色的方框都是注释（数字代码是在模型训练时由数据集配置文件中定义其含义），通过 Object detection 识别出对象并添加对象注释
下图的注释除了有检测到的对象外，还有对象的姿态。识别出对象后，再通过 Pose estimation 进行姿态估计并添加姿态注释
上面只是用两种类型举例，还有很多其他的注释类型，这些都属于图像的 Annotations(注释)
Bounding box 参考：
https://www.ultralytics.com/glossary/bounding-box https://encord.com/glossary/bounding-box-definition/ Bounding box(边界框) 也称为 Bounding volume 或 Bounding region，是一种 几何形状 的 Label，用于在数字图像中包围或环绕一个或一组对象。Bounding box 的目的是在2D 或 3D 空间中定义对象的位置和大小，以执行各种 CV 任务，e.g. 对象检测、分割、分类。这是 CV 领域的基本概念，特别是在涉及图像和视频分析的应用中。
在 2D 图像中，Bounding box 通常用矩形表示，其长边与图像的 x 轴和 y 轴平行。矩形的大小由 x 轴和 y 轴的最小值和最大值决定，这些值由矩形的角坐标指定。矩形的大小和中心点也可用于创建 enclosing box(封闭框)。</description></item><item><title>Deno</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Deno/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Deno/</guid><description>概述 参考：
GitHub 项目，denoland/deno GitHub 项目，denolib/awesome-deno 阮一峰，Deno 运行时入门教程：Node.js 的替代品 https://docs.deno.com/runtime/manual/references/vscode_deno/ VSCode 中使用 Deno 的方式 Deno 也是一个服务器运行时，但是支持多种语言，可以直接运行 JavaScript、TypeScript 和 WebAssembly 程序。
它内置了 V8 引擎，用来解释 JavaScript。同时，也内置了 tsc 引擎，解释 TypeScript。它使用 Rust 语言开发，由于 Rust 原生支持 WebAssembly，所以它也能直接运行 WebAssembly。它的异步操作不使用 libuv 这个库，而是使用 Rust 语言的 Tokio 库，来实现事件循环（event loop）。
内置了 V8 引擎意味着可以随时随地运行那些依赖浏览器环境的库，再也不用在 js 代码中补浏览器环境了！内置了 tsc 引擎意味着再也不用面临 Node.js 那些让人头痛的无法运行 .ts 的问题。
Deno 运行代码时，并不依赖 tsconfig.json 文件或 package.json 文件。不用面临 CommonJS 和 ES6 语法的冲突配置问题。
Deno 甚至可以通过命令行工具的 deno compile 命令将程序编译成可执行的二进制文件（比如 windows 下就是 .exe 文件），然后直接执行！！就像 Go 的二进制文件一样。如果是编译了一个使用浏览器操作的文件，那么就会在 Shell 中显示像浏览器似的控制，浏览器弹窗就是 Shell 中的等待输入，诸如此类的效果。</description></item><item><title>Deployment Manifest</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/Deployment-Manifest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/Deployment-Manifest/</guid><description>概述 参考：
API 文档，单页 官方文档，参考-Kubernetes API-工作负载资源-Deployment Manifest 中的顶层字段 apiVersion: apps/v1 kind: Deployment metadata(metadata) spec:(spec) status(status) metadata Deployment 对象的元数据，该字段内容详见通用定义的 [ObjectMeta](/docs/10.云原生/2.3.Kubernetes%20 容器编排系统/1.API、Resource(资源)、Object(对象)/API%20 参考/Common%20Definitions(通用定义)/ObjectMeta.md Definitions(通用定义)/ObjectMeta.md)
spec spec 用来描述一个 Deployment 应该具有的属性。也就是用来定义 Deployment 的行为规范。一共分为如下几类
描述 Deployment 类型的控制器的行为 描述 Deployment 控制器所关联的 Pod 的属性。 控制器行为 minReadySeconds(INT) # 新创建的 Pod 在启动后，经过 minReadySeconds 秒后一直没有崩溃，之后，将该 Pod 视为可用。默认值：0。
默认值 0 表示 Pod 准备就绪后即被视为可用。 progressDeadlineSeconds(INT) # 本 Deployment 对象被视为失败之前的等待时间，单位 秒。默认值：600
replicas(INT) # 该控制器运行的 Pod 数量，默认值：1。
revisionHistoryLimit(INT)# 可以保留的允许回滚的旧 ReplicaSet 对象的数量。默认值：10。控制器的历史可以通过 kubectl rollout 命令控制</description></item><item><title>devfs</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/devfs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/devfs/</guid><description>概述 参考：
非官方 Manual(手册)，devfs(5) Device File System(设备文件系统，简称 devfs)，提供对全局文件系统名称空间中内核设备名称空间的访问。一般挂载到 /dev 目录。
[!Notes] 现在设备文件系统称为 devtmpfs 。devfs 的发展过程中有很多名字，udev、devtmpfs。参考 Linux设备节点创建方式的演变历史 文章。
这个文件系统包含一些目录、链接、符号链接和设备，其中一些是可写的。在 Chroot 环境中，可以使用 devfs 创建一个新的 /dev 挂载点。
The mknod(8) 工具可用于恢复 devfs 下已删除的设备。
/dev/dm-* 参考：
Wiki, Device mapper Device Mapper(设备映射，简称 dm)，是一个由 Linux 内核提供的框架，用于将物理块设备映射到更高级别的虚拟块设备。dm 是 LVM、软 Raid、dm-crypt 磁盘加密的基础。
dm 通过将将数据从虚拟块设备传递到另一个块设备来工作。数据也可以再过渡中进行修改，例如，在设备映射器提供磁盘加密或模拟不可靠硬件行为的情况下，可以执行此操作。
也可以在 /dev/mapper/ 目录中找到设备映射的关系
dmsetup 命令行工具 dmsetup ls # 列出 dm 设备
~]# dmsetup ls vg1-swap (253:1) vg1-root (253:0) 其中 253 后面的数字，就是 dm-X 那个 X。所以 dm-0 对应 vg1-root 这个设备。使用 lsblk 命令可以看到 dm 与 块设备的关联关系。</description></item><item><title>DevOps</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/DevOps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/DevOps/</guid><description>概述 参考：
Developer(开发者)
Operator(操作者(运维))
敏捷开发（Agile Development）、持续集成（Continuous Integration）、持续交付（Continuous Delivery）、开发运维一体化（Development Operations），所覆盖的软件生命周期的阶段不同。
DevOps 是一种文化，是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。
它是一种重视“软件开发人员（Dev）”和“IT 运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。
它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作。
计划-开发-构建-测试-修复-测试-交付运维-部署
CI：持续集成 当程序员开发完提交代码到类似 github 的地方上之后，有一款工具可以自动拉去代码进行构建，当出现问题时，会报告给程序员，重复执行“构建-测试”的过程 CD：持续交付 Delivery 当有一款工具自动把测试好的东西(比如一个容器用的镜像)交付给运维，自动执行“构建-交付”的过程 CD：持续部署 Deployment 当有一款工具，运维都不用了，可以直接部署的时候 GitOps 参考：
公众号-云原声实验室，大妈都能看懂的 GitOps 入门指南 GitOps 这个概念最早是由 Kubernetes 管理公司 Weaveworks 公司在 2017 年提出的，如今已经过去了 5 个年头，想必大家对这个概念早有耳闻，但你可能并不知道它到底是什么，它和 DevOps 到底是啥关系，本文就来帮大家一一解惑。
GitOps = IaC + Git + CI/CD，即基于 IaC 的版本化 CI/CD。它的核心是使用 Git 仓库来管理基础设施和应用的配置，并且以 Git 仓库作为基础设施和应用的单一事实来源，你从其他地方修改配置（比如手动改线上配置）一概不予通过。
Git 仓库中的声明式配置描述了目标环境当前所需基础设施的期望状态，借助于 GitOps，如果集群的实际状态与 Git 仓库中定义的期望状态不匹配，Kubernetes reconcilers 会根据期望状态来调整当前的状态，最终使实际状态符合期望状态。 另一方面，现代应用的开发更多关注的是迭代速度和规模，拥有成熟 DevOps 文化的组织每天可以将代码部署到生成环境中数百次，DevOps 团队可以通过版本控制、代码审查以及自动测试和部署的 CI/CD 流水线等最佳实践来实现这一目标，这就是 GitOps 干的事情。</description></item><item><title>DevTools</title><link>https://desistdaydream.github.io/docs/Web/Browser/DevTools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser/DevTools/</guid><description>概述 参考：
Chrome 开发者工具官方文档 Wiki, Web_development_tools Chrome DevTools 是一组内置于 Chrome 浏览器中的 Web 开发者工具（通常使用 F12 快捷键打开；Ctrl + Shift +i 也是常见的默认快捷键）。
元素 # 当前网页被渲染的数据 控制台 # 可以输入 JS 代码 源代码/来源 # HTML、JS、CSS、字体等静态资源文件 网络 # 数据传输内容 &amp;hellip;.. 应用 # 元素 使用 Ctrl+Shift+C 快捷键可以选定页面上的元素以定位到 HTML 中的位置。
网络 控制台 在控制台中，通过查看日志消息和运行 JS 代码以控制页面的控制。
可以直接输出当前页面 js 代码中的各种变量、函数等等 等等 源代码 参考：
官方文档，源代码 在源代码中可以检查静态资源、打断点、等等。
当浏览器的请求被断点暂停时，我们可以将鼠标悬停后，看到 FunctionLocation 关键字，从这里追踪函数的位置。
在控制台输出该函数，也可以通过点击跳转到函数位置。
代码段 https://developer.chrome.com/docs/devtools/javascript/snippets?hl=zh-cn
若我们需要在控制台反复运行相同的代码，可以将代码保存为代码段，以便随时使用
最常见的用法是替换 JS 中的函数以 Debug，比如下面这个，可以通过 JSON.stringify = function (params) {} 和 JSON.</description></item><item><title>DHCP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/DHCP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/DHCP/</guid><description>概述 参考：
Wiki, DHCP Dynamic Host Configuration Protocol(动态主机设置协议，简称 DHCP) 主要用于由一部主机来自动的分配所有的网络参数给指定网段内的所有设备。
DHCP 可以分配的网络参数有 IP 地址、掩码、网关、DNS 等
DHCP 的运作方式： 他主要由客户端发送广播包给整个物理网段内的所有主机， 若该网段内有 DHCP 服务器时，就会响应客户端的 DHCP 请求。所以，DHCP 服务器与客户端是应该要在同一个物理网段内的，如果想跨网段提供 DHCP 服务，需要在对应网段启用 dhcrelay 服务。
至于整个 DHCP 封包在服务器与客户端的来来回回情况如右图，具体有 4 个步骤
DISCOVER(发现) # 客户端利用广播封包发送搜索 DHCP 服务器的封包： 若客户端网络设定使用 DHCP 协议取得 IP (在 Windows 内为『自动取得 IP』)，则当客户端开机或者是重新启动网络卡时， 客户端主机会发送出搜寻 DHCP 服务器的 UDP 封包给所有物理网段内的计算机。此封包的目标 IP 会是 255.255.255.255， 所以一般主机接收到这个封包后会直接予以丢弃，但若局域网络内有 DHCP 服务器时，则会开始进行后续行为。 OFFER(提供) # DHCP 服务端提供客户端网络相关的租约以供选择 DHCP 服务器在接收到这个客户端的要求后，会针对这个客户端的硬件地址 (MAC) 与本身的设定数据来进行下列工作： 到服务器的登录文件中寻找该用户之前是否曾经用过某个 IP ，若有且该 IP 目前无人使用，则提供此 IP 给客户端； 若配置文件针对该 MAC 提供额外的固定 IP (static IP) 时，则提供该固定 IP 给客户端； 若不符合上述两个条件，则随机取用目前没有被使用的 IP 参数给客户端，并记录下来。 总之，服务器端会针对客户端的要求提供一组网络参数租约给客户端选择，由于此时客户端尚未有 IP ，因此服务器端响应的封包信息中， 主要是针对客户端的 MAC 来给予回应。此时服务器端会保留这个租约然后开始等待客户端的回应。 REQUEST(请求) # 客户端决定选择的 DHCP 服务器提供的网络参数租约并回报服务器 由于局域网络内可能并非仅有一部 DHCP 服务器，但客户端仅能接受一组网络参数的租约。 因此客户端必需要选择是否要认可该服务器提供的相关网络参数的租约。当决定好使用此服务器的网络参数租约后， 客户端便开始使用这组网络参数来设定自己的网络环境。此外，客户端也会发送一个广播封包给所有物理网段内的主机， 告知已经接受该服务器的租约。此时若有第二台以上的 DHCP 服务器，则这些没有被接受的服务器会收回该 IP 租约。至于被接受的 DHCP 服务器会继续进行底下的动作。 Acknowledge(确认，ACK) # 服务端记录该次租约行为并回报客户端已确认的响应封包信息 - 当服务器端收到客户端的确认选择后，服务器会回传确认的响应封包，并且告知客户端这个网络参数租约的期限， 并且开始租约计时喔！那么该次租约何时会到期而被解约，可以这样想： - 客户端脱机：不论是关闭网络接口 (ifdown)、重新启动 (reboot)、关机 (shutdown) 等行为，皆算是脱机状态，这个时候 Server 端就会将该 IP 回收，并放到 Server 自己的备用区中，等待未来的使用； - 客户端租约到期：前面提到 DHCP server 端发放的 IP 有使用的期限，客户端使用这个 IP 到达期限规定的时间，而且没有重新提出 DHCP 的申请时，就需要将 IP 缴回去！这个时候就会造成断线。但用户也可以再向 DHCP 服务器要求再次分配 IP 啰。 这四个步骤也称为 DHCP 分配地址时的需要进行的 DORA 进程</description></item><item><title>DMA 与 零拷贝</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/DMA-%E4%B8%8E-%E9%9B%B6%E6%8B%B7%E8%B4%9D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/DMA-%E4%B8%8E-%E9%9B%B6%E6%8B%B7%E8%B4%9D/</guid><description>概述 参考：
公众号，原来 8 张图，就可以搞懂「零拷贝」了 前言 磁盘可以说是计算机系统最慢的硬件之一，读写速度相差内存 10 倍以上，所以针对优化磁盘的技术非常的多，比如零拷贝、直接 I/O、异步 I/O 等等，这些优化的目的就是为了提高系统的吞吐量，另外操作系统内核中的磁盘高速缓存区，可以有效的减少磁盘的访问次数。
这次，我们就以「文件传输」作为切入点，来分析 I/O 工作方式，以及如何优化传输文件的性能。
正文 为什么要有 DMA 技术? 在没有 DMA 技术前，I/O 的过程是这样的：
CPU 发出对应的指令给磁盘控制器，然后返回； 磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断； CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。 为了方便你理解，我画了一副图：
可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。
简单的搬运几个字符数据那没问题，但是如果我们用千兆网卡或者硬盘传输大量数据的时候，都用 CPU 来搬运的话，肯定忙不过来。
计算机科学家们发现了事情的严重性后，于是就发明了 DMA 技术，也就是 Direct Memory Access(直接内存访问，简称 DMA) 技术。
什么是 DMA 技术？简单理解就是，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。
那使用 DMA 控制器进行数据传输的过程究竟是什么样的呢？下面我们来具体看看。
具体过程：
用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态； 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务； DMA 进一步将 I/O 请求发送给磁盘； 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满； DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务； 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU； CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回； 可以看到， 整个数据传输的过程，CPU 不再参与数据搬运的工作，而是全程由 DMA 完成，但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。</description></item><item><title>dmesg</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/dmesg/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/dmesg/</guid><description>概述 参考：
Manual(手册)，dmesg(1) dmesg 命令是用来在 Unix-like 系统中显示内核的相关信息的。dmesg 全称是 display message (or display driver)，即显示信息。默认操作是显示来自内核环形缓冲区的所有消息。
实际上，dmesg 命令是从内核环形缓冲区中获取数据的。当我们在 Linux 上排除故障时，dmesg 命令会十分方便，它能很好地帮我们鉴别硬件相关的 error 和 warning。除此之外，dmesg 命令还能打印出守护进程相关的信息，已帮助我们 debug。
dmesg [OPTIONS] OPTIONS
-L, &amp;ndash;color # 输入内容带上颜色。 -l, &amp;ndash;level LIST # 指定输出的级别，多个级别以逗号分隔。可用的级别有以下几种 emerg - system is unusable alert - action must be taken immediately crit - critical conditions err - error conditions warn - warning conditions notice - normal but significant condition info - informational debug - debug-level messages -f, &amp;ndash;facility LIST # 指定要输出的 Facility(设施)，多个设施以逗号分隔。可用的 Facility 有Facility(设施) ser - random user-level messages mail - mail system daemon - system daemons auth - security/authorization messages syslog - messages generated internally by syslogd lpr - line printer subsystem news - network news subsystem -H, &amp;ndash;human # 启用人类可读的输出。是 --color、--reltime、--nopager 这三个选项的结合 -T, &amp;ndash;ctime # 打印人类可读的时间戳。 请注意，时间戳记可能不正确！挂起/恢复系统后，用于日志的时间源不会更新。根据引导时间和单调时钟之间的当前增量调整时间戳，这仅适用于上次恢复后打印的消息。 EXAMPLE</description></item><item><title>dmidecode</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/dmidecode/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/dmidecode/</guid><description>概述 参考：
官网 Wiki, dmidecode Manual(手册)，dmidecode dmidecode 命令可以让我们在 Linux 系统下获取有关硬件方面的信息。dmidecode 的作用是将 DMI 数据库中的信息解码，以可读的文本方式显示。由于 DMI 信息可以人为修改，因此里面的信息不一定是系统准确的信息。dmidecode 遵循 SMBIOS/DMI 标准，其输出的信息包括BIOS、系统、主板、处理器、内存、缓存等等。
dmidecode 附带三个额外的工具：
biosdecode 打印它能找到的所有 BIOS 相关信息（参见示例输出）； ownership 检索可以在 Compaq 计算机上设置的“所有权标签”； vpddecode 打印可以在几乎所有 IBM 计算机中找到的“重要产品数据”信息（参见 示例输出）。 DMI 类型 SMBIOS规范定义了以下DMI类型:
Type Information ──────────────────────────────────────────── 0 BIOS 1 System 2 Baseboard 3 Chassis 4 Processor 5 Memory Controller 6 Memory Module 7 Cache 8 Port Connector 9 System Slots 10 On Board Devices 11 OEM Strings 12 System Configuration Options 13 BIOS Language 14 Group Associations 15 System Event Log 16 Physical Memory Array 17 Memory Device 18 32-bit Memory Error 19 Memory Array Mapped Address 20 Memory Device Mapped Address 21 Built-in Pointing Device 22 Portable Battery 23 System Reset 24 Hardware Security 25 System Power Controls 26 Voltage Probe 27 Cooling Device 28 Temperature Probe 29 Electrical Current Probe 30 Out-of-band Remote Access 31 Boot Integrity Services 32 System Boot 33 64-bit Memory Error 34 Management Device 35 Management Device Component 36 Management Device Threshold Data 37 Memory Channel 38 IPMI Device 39 Power Supply 40 Additional Information 41 Onboard Devices Extended Information 42 Management Controller Host Interface Additionally, type 126 is used for disabled entries and type 127 is an end-of-table marker.</description></item><item><title>DMTF</title><link>https://desistdaydream.github.io/docs/Standard/IT/DMTF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/IT/DMTF/</guid><description>概述 参考：
Wiki, Distributed_Management_Task_Force Distributed Management Task Forc(分布式管理任务组，简称 DMTF) 是一个 501(c)(6) 非营利行业标准组织，它创建涵盖各种新兴和传统 IT 基础设施（包括云、虚拟化、网络、服务器和存储）的开放可管理性标准。成员公司和联盟伙伴就标准进行协作，以改进信息技术的互操作管理。
DMTF 总部位于俄勒冈州波特兰，由代表科技公司的董事会领导，这些公司包括：Broadcom Inc.、Cisco、Dell Technologies、Hewlett Packard Enterprise、Intel Corporation、Lenovo、NetApp、Positivo Tecnologia S.A. 和 Verizon。
该组织成立于 1992 年，当时名为 Desktop Management Task Force(桌面管理任务组)，其第一个标准是现在的 Desktop Management Interface(DMI)。随着该组织发展到通过附加标准（例如通用信息模型 (CIM)）解决分布式管理问题，它于 1999 年更名为分布式管理任务组，但现在称为 DMTF。
DMI 参考：
Wiki, Desktop_Management_Interface Desktop Management Interface(桌面管理接口，简称 DMI) 是帮助收集电脑系统信息的管理系统，DMI 信息的收集必须在严格遵照 SMBIOS 规范的前提下进行。SMBIOS（System Management BIOS）是主板或系统制造者以标准格式显示产品管理信息所需遵循的统一规范。SMBIOS 和 DMI 是由行业指导机构 Distributed Management Task Force(DMTF) 起草的开放性的技术标准，其中 DMI 设计适用于任何的平台和操作系统。
DMI 充当了管理工具和系统层之间接口的角色。它建立了标准的可管理系统更加方便了电脑厂商和用户对系统的了解。DMI 的主要组成部分是 Management Information Format(MIF) 数据库。这个数据库包括了所有有关电脑系统和配件的信息。通过 DMI，用户可以获取序列号、电脑厂商、串口信息以及其它系统配件信息。</description></item><item><title>DNS 加密</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DNS-%E5%8A%A0%E5%AF%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DNS-%E5%8A%A0%E5%AF%86/</guid><description>概述 参考：
B 站，DNS污染？SNI阻断？全新网络协议保护隐私安全 HTTPS 协议对网络流量进行了加密，然而这种保护并非完美，事实上。HTTPS 体系存在着两个安全缝隙：DNS 还有 SNI，他们依旧使用着明文传输，因此可能会导致隐私泄露等等的安全风险
DNS 的查询与响应都是 UDP 协议的明文传输，这就意味着可能被网络传输的中间人监听篡改，中间人可以轻易知道用户准备访问哪个网站，用户就会因此泄露隐私
攻击者通过抓取DNS数据包，很轻易的就知道我是要访问哪个网站，中间人甚至可以修改DNS的响应结果，故意误导一个错误的IP地址，让浏览器无法正常工作
这种攻击也就是DNS污染
为了应对这种安全挑战，两种加密版本的DNS协议诞生了
DOT # 利用传输层的安全协议 TLS 来加密 DNS 查询。DOT 通常在853端口上运行 DOH # 通过HTTPS协议传输DNS查询的方法 这两种方法目前更主流的是DOH
因为 DOH 的优点显而易见，DOH 复用了HTTPS协议，使得DNS查询与普通的外部流量是混合在一起的
DOH 与 HTTPS 共用443端口，从而更难被中间人识别攻击
现在国内已经有了比较成熟的DOH供应商，比如阿里云、腾讯的DNS、国际上也有 CloudFlare、谷歌、etc. DOH 供应商
DOH 已经是比较成熟的技术</description></item><item><title>Docker API</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-API/</guid><description>概述 参考：
官方文档，参考 - API - 引擎 Docker API 官方文档：https://docs.docker.com/engine/api/latest/</description></item><item><title>Docker CLI Plugin</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/Docker-CLI-Plugin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/Docker-CLI-Plugin/</guid><description>概述 参考：
https://github.com/docker/cli/issues/1534 文档在 issue 里？ 2024-06-26 依然没找到官方文档 关联文件与配置 Unix-like OS : $HOME/.docker/cli-plugins /usr/local/lib/docker/cli-plugins &amp;amp; /usr/local/libexec/docker/cli-plugins /usr/lib/docker/cli-plugins &amp;amp; /usr/libexec/docker/cli-plugins On Windows: %USERPROFILE%\.docker\cli-plugins C:\ProgramData\Docker\cli-plugins</description></item><item><title>Docker Network</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Network/</guid><description>概述 参考：
官方文档，引擎 - 网络 DNS 容器连接到默认网络时，会使用与主机相同的 DNS Server，继承主机的 /etc/resolv.conf。
容器连接到自定义网络时，会使用 Docker 内嵌的 DNS Server（127.0.0.11:53），将 容器 ID、容器名、别名 注册为 DNS 解析记录，以便其他容器可以通过这些域名访问到自己。示例可以参考下文 ”Bridge“ 驱动程序中的示例
Docker 网络的驱动程序 https://docs.docker.com/engine/network/drivers/
Docker 使用驱动程序实现网络子系统的核心能力，网络子系统是可插拔的。默认存在如下几种驱动程序：
bridge # 默认驱动程序。当应用程序在需要与同一主机上的其他容器通信的容器中运行时，通常会使用 Bridge(桥接) 网络。 host # 取消容器与 Docker 主机之间的网络隔离，直接使用主机的网络 overlay ipvlan macvlan none # 容器与宿主机及其他容器完全隔离。 none 不适用于 Swarm 服务。用人话说就是不使用任何网络驱动程序。 网络插件：我们可以安装和使用第三方网络插件，以实现 Docker 自身无法实现的网络功能 Bridge https://docs.docker.com/engine/network/drivers/bridge
当 Docker 启动时，会自动创建一个名为 brdige，Bridge 驱动类型的网络。默认情况下新启动的容器都会连接到 bridge 网络。
~]# docker network ls NETWORK ID NAME DRIVER SCOPE dadd048eefa0 bridge bridge local 84cab5ef9276 host host local 4718cdfcb116 monitoring bridge local 4d68f227ca5d none null local Notes: 名为 bridge 的是默认 Bridge 类型网络；名为 monitoring 的是用户自定义的 Bridge 类型网络。</description></item><item><title>Docker Storage</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Storage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-Storage/</guid><description>概述 参考：
官方文档，在生产环境运行你的应用 - 管理应用数据 - 存储概述 当关闭并重启 Container 的时候，其内的数据不受影响；但删除 Docker 容器后，则其内对最上面的可写层操作的内容则全部丢失，这时候会存在几个问题
存储于联合文件系统中，不易于宿主机访问 容器间数据共享不便 删除容器会使数据丢失 为了解决这些问题，可以通过三种 Storage 方式来将文件存储于宿主机中
volume volume 类型的 storage 是通过 docker volume 命令显式得创建一个抽象的内容，创建完一个 volume 会，会在 /var/lib/docker/volumes/* 目录下生成与 volume 同名的目录，在将 volume 挂载进 Container 中时，也就是将 /var/lib/docker/volmes/XXX 目录挂载进去。非 Docker 进程不应修改文件系统的这一部分。卷是在 Docker 中持久保存数据的最佳方法。 bind mounts 可以存储在主机系统上的任何位置。它们甚至可能是重要的系统文件或目录。Docker 主机或 Docker 容器上的非 Docker 进程可以随时对其进行修改。 tmpfs mount 仅存储在主机系统的内存中，并且永远不会写入主机系统的文件系统中。 无论使用哪种方式，目的都是让宿主机上的某个“目录或者文件”绕过联合文件系统，与 Container 中的一个或多个“目录或文件”绑定，对目录中的操作，在 Container 和 Host 中都能看到(i.e.在宿主机目录中创建一个文件，Container 中对应的目录也会看到这个文件)，一个 Volume 可以绑定到多个 Container 上去。
这三种方式唯一的差异就是数据在 docker 宿主机上的位置，bind mount 和 volume 会在宿主机的文件系统中、而 tmpfs mount 则在宿主机的内存中。如下图所示：</description></item><item><title>Docker 权限管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
Docker Capabilities Capabilities 详见 Linux Capabilities 权限管理章节
我们说 Docker 容器本质上就是一个进程，所以理论上容器就会和进程一样会有一些默认的开放权限，默认情况下 Docker 会删除必须的 capabilities 之外的所有 capabilities，因为在容器中我们经常会以 root 用户来运行，使用 capabilities 现在后，容器中的使用的 root 用户权限就比我们平时在宿主机上使用的 root 用户权限要少很多了，这样即使出现了安全漏洞，也很难破坏或者获取宿主机的 root 权限，所以 Docker 支持 Capabilities 对于容器的安全性来说是非常有必要的。 不过我们在运行容器的时候可以通过指定 --privileded 参数来开启容器的超级权限，这个参数一定要慎用，因为他会获取系统 root 用户所有能力赋值给容器，并且会扫描宿主机的所有设备文件挂载到容器内部，所以是非常危险的操作。 但是如果你确实需要一些特殊的权限，我们可以通过 --cap-add 和 --cap-drop 这两个参数来动态调整，可以最大限度地保证容器的使用安全。下面表格中列出的 Capabilities 是 Docker 默认给容器添加的，我们可以通过 --cap-drop 去除其中一个或者多个： docker capabilities 下面表格中列出的 Capabilities 是 Docker 默认删除的，我们可以通过--cap-add添加其中一个或者多个： docker drop capabilities
--cap-add和--cap-drop 这两参数都支持ALL值，比如如果你想让某个容器拥有除了MKNOD之外的所有内核权限，那么可以执行下面的命令： $ sudo docker run --cap-add=ALL --cap-drop=MKNOD ...
比如现在我们需要修改网络接口数据，默认情况下是没有权限的，因为需要的 NET_ADMIN 这个 Capabilities 默认被移除了：</description></item><item><title>Dockerfile 指令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/Dockerfile-%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/Dockerfile-%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
官方文档 官方文档 - 构建镜像的最佳实践 FROM - 指定 base 镜像 FROM 指令将会初始化一个新的构建阶段，并设置用于后续指令所使用的 BaseImage(基础镜像)。所以一个有效的 Dockerfile 必须从 FROM 指令开始。ARG 是唯一一个可以在 FROM 指令前面的指令，除此以外，FROM 可以说是必须存在的基础字段且为 DokerFile 文件的第一个非注释行。
一个 Dockerfile 中可以有多个 FROM 指令，每出现一个 FROM 指令，即表示一个老阶段的结束，一个新阶段的开始。
Syntax(语法) from [&amp;ndash;platform=&amp;lt;PLATFORM&amp;gt;] &amp;lt;image&amp;gt;[:&amp;lt;TAG&amp;gt; | @[DIGEST] ] [AS &amp;lt;NAME&amp;gt;] 附加指令：
AS &amp;lt;NAME&amp;gt; # 为当前构建阶段起一个名字。该附加指令有如下几种用法： 在开始构建之前，可是使用 &amp;ndash;target 指令指定指定要从 STRING 这个阶段开始构建镜像。 在构建中，COPY 指令可以使用 &amp;ndash;from=&amp;lt;NAME&amp;gt; 参数来指定数据源是来自某个构建阶段内的数据，也就是说，COPY 指令不止可以从宿主机拷贝文件到容器中，还可以从上一个构建阶段的容器中，拷贝其内容到当前容器中。这也为多阶段构建模式中，减少镜像体积打下来坚实基础。 TAG 和 DIGEST # 该附加指令是可选的，若不指定镜像的 TAG，则默认使用 latest。 用法 Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。
如果以 scratch 为基础镜像的话，意味着本次构建阶段不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。 LABEL - 为镜像添加标签 Syntax(语法) label &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; .</description></item><item><title>Docsy</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E4%B8%BB%E9%A2%98/Docsy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E4%B8%BB%E9%A2%98/Docsy/</guid><description>概述 参考：
GitHub 项目，google/docsy 官网 Kubernetes 的官网就是 Docsy 主题。
注意：Docsy 必须使用 扩展版 hugo，即 hugo_extended。
预览和部署 Docsy 主题网站 参考：
官方文档，预览和部署 准备环境 npm install -D autoprefixer npm install -D postcss-cli npm install -D postcss 若不在本地安装，则使用 hugo 命令构建静态文件时将会报错
生成站点文件 生成模板站点 export MY_SITE_DIR=&amp;#34;docsy&amp;#34; git clone https://github.com/google/docsy-example.git ${MY_SITE_DIR} cd ${MY_SITE_DIR} hugo server 生成空白站点 hugo new site . hugo mod init github.com/me/my-new-site hugo mod get github.com/google/docsy@v0.6.0 cat &amp;gt;&amp;gt; hugo.toml &amp;lt;&amp;lt;EOL [module] proxy = &amp;#34;direct&amp;#34; [[module.imports]] path = &amp;#34;github.</description></item><item><title>Driver</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Hardware/Driver/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Hardware/Driver/</guid><description>概述 参考：
Linux 中的 Driver(驱动) 管理。
部分 BUS_TYPE 可以在 /sys/bus/${BUS_TYPE}/drivers/ 可以找到各类型总线下的驱动。e.g. PCI 设备、USB 设备、etc. 。
Tip: 并不是所有的 BUS_TYPE 都有驱动，e.g. /sys/bus/memory/drivers/ 目录是空的
PCI /sys/bus/pci/drivers/${DRIVER}/ 目录是某个具体驱动下关联的设备的 PCI Addr 以及驱动相关操作
./${PCI_ADDR} # 使用了本驱动的设备的 PCI Addr 软链接，指向 /sys/devices/pciXXX/XXX/... 某个目录 ./bind # 向该文件写入 PCI Addr 将会让设备与内核绑定 ./unbind # 向该文件写入 PCI Addr 将会让设备从内核解绑 最佳实践 网卡的绑定与解绑 我这里用网卡演示绑定和解绑的过程
可以通过 lspci 命令查看该设备在内核中可以使用的驱动。
~]# lspci -s 0000:21:00.1 -v 21:00.1 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 02) Subsystem: Intel Corporation Ethernet Converged Network Adapter X710 .</description></item><item><title>ecs 中毒的一次处理过程</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/ecs-%E4%B8%AD%E6%AF%92%E7%9A%84%E4%B8%80%E6%AC%A1%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/ecs-%E4%B8%AD%E6%AF%92%E7%9A%84%E4%B8%80%E6%AC%A1%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B/</guid><description>概述 参考：
一次客户 ecs 中毒的处理过程，可以给读者参考下中毒的处理过程。
由来 客户机器中毒了，pm 找我来让处理下，记录下，给其他人做个处理过程的参考。
处理过程 机器是 centos ，先利用 rpm -V &amp;lt;pkg_name&amp;gt; 确认基础的排查命令没被修改过：
$ rpm -qf `which ps` procps-ng-3.3.10-23.el7.x86_64 $ rpm -V procps-ng $ rpm -qf `which top` procps-ng-3.3.10-23.el7.x86_64 top 看到异常 cpu 的进程占用 cpu 很高：
$ top top - 19:44:29 up 34 days, 5:08, 4 users, load average: 612.03, 617.15, 482.75 Tasks: 2014 total, 66 running, 1946 sleeping, 0 stopped, 2 zombie %Cpu(s): 96.6 us, 3.1 sy, 0.</description></item><item><title>ethtool</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/ethtool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/ethtool/</guid><description>概述 参考：
Manual(手册)，ethtool(8) ethtool 是一个工具，用来查询或控制网络驱动程序和硬件设备。
Notes: ethtool 无法查看到 DPDK 等程序接管的网卡的网络设备。因为已经绕过了内核，ethtool 只能查询或控制直接由内核管理的网卡。
~]# ethtool em1 Settings for em1: Supported ports: [ TP ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Half 1000baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes Supported FEC modes: Not reported Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Half 1000baseT/Full Advertised pause frame use: Symmetric Advertised auto-negotiation: Yes Advertised FEC modes: Not reported Link partner advertised link modes: 10baseT/Full 100baseT/Full 1000baseT/Full Link partner advertised pause frame use: No Link partner advertised auto-negotiation: Yes Link partner advertised FEC modes: Not reported Speed: 1000Mb/s Duplex: Full Port: Twisted Pair PHYAD: 1 Transceiver: internal Auto-negotiation: on MDI-X: on Supports Wake-on: g Wake-on: d Current message level: 0x000000ff (255) drv probe link timer ifdown ifup rx_err tx_err Link detected: yes Syntax(语法) ethtool [OPTIONS] DeviceName</description></item><item><title>EulerOS 与 OpenEuler</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/EulerOS-%E4%B8%8E-OpenEuler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/EulerOS-%E4%B8%8E-OpenEuler/</guid><description>概述 参考：
EulerOS 官网 OpenEuler 官网 OpenEuler 官方文档 EulerOS 与 OpenEuler
EulerOS # 企业 OpenEuler # 开源 关联文件与配置</description></item><item><title>Event</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Event/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Event/</guid><description>概述 参考：
网道，Javascript 教程-事件 Event(事件) 的本质是程序各个组成部分之间的一种通信方式，也是异步编程的一种实现。DOM 支持大量的事件，
事件语法：
elementObject.onEventType=Function(){} elementObject # 元素对象，也就是事件源，通常是通过类似 getElementByID()之类的方法获取到的 HTML 中的元素 onEventType # 以on开头，后面跟一个事件名称 Function(){} # elementObject 触发 onEventType 时要执行的代码，也就是 HTML 中某一元素触发事件时要执行的操作 比如：
var divElement = document.getElementById(&amp;#34;event&amp;#34;) // click 点击事件 divElement.onclick = function () { console.log(divElement, &amp;#34;元素，被点击了一下&amp;#34;) } 事件类型 鼠标事件 click # 鼠标单击 dblclick # 鼠标双击 contextmenu # 左键单击 mousedown # 鼠标按下 mouseup # 鼠标抬起 mousemove # 鼠标移动 mouseenter # 鼠标移入 mouseleave # 鼠标移出 &amp;hellip;&amp;hellip; 等等 键盘事件 keydown # 键盘按下 keyup # 键盘抬起 keypress # 键盘输入 &amp;hellip;&amp;hellip; 等等 浏览器事件 load # 加载完毕 scroll # 滚动 resize # 尺寸改变 &amp;hellip;&amp;hellip; 等等 触摸事件 touchstart # 触摸开始 touchmove # 触摸移动 touchend # 触摸结束 &amp;hellip;&amp;hellip; 等等 表单事件 focus # 聚焦 blue # 失焦 change # 改变 input # 输入 submit # 提交 reset # 重置 &amp;hellip;&amp;hellip; 等等 事件对象 每个事件触发时，都会记录一组数据，这组数据是事件类型对象，事件对象数据中的数据包括该时间一系列属性信息，比如：</description></item><item><title>Expect</title><link>https://desistdaydream.github.io/docs/12.AI/Automation/Expect/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Automation/Expect/</guid><description>概述 参考：
sourceforge 项目，expect 官网 Manual(手册)，expect(1) Expect 是一个用于自动化交互式应用程序（如 telnet、ftp、passwd、fsck、rlogin、tip 等）的工具。Expect 确实使这些东西变得微不足道。 Expect 对于测试这些相同的应用程序也很有用。通过添加 Tk，您还可以将交互式应用程序封装在 X11 GUI 中。
https://xstarcd.github.io/wiki/shell/expect_handbook.html</description></item><item><title>EXT FileSystem</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/EXT-FileSystem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/EXT-FileSystem/</guid><description>概述 参考：
公众号 - 小林 coding，一口气搞懂「文件系统」，就靠这 25 张图了 骏马金龙，第4章 ext文件系统机制原理剖析 block 的出现 硬盘最底层的读写 I/O 一次是一个扇区 512 字节，如果要读写大量文件，以扇区为单位肯定很慢很消耗性能，所以硬盘使用了一个称作逻辑块的概念。逻辑块是逻辑的，由磁盘驱动器负责维护和操作，它并非是像扇区一样物理划分的。一个逻辑块的大小可能包含一个或多个扇区，每个逻辑块都有唯一的地址，称为 LBA。有了逻辑块之后，磁盘控制器对数据的操作就以逻辑块为单位，一次读写一个逻辑块，磁盘控制器知道如何将逻辑块翻译成对应的扇区并读写数据。
到了 Linux 操作系统层次，通过文件系统提供了一个也称为块的读写单元，文件系统数据块的大小一般为 1024bytes (1KiB) 或 2048bytes (2KiB) 或 4096bytes (4KiB)。文件系统数据块也是逻辑概念，是文件系统层次维护的，而磁盘上的逻辑数据块是由磁盘控制器维护的，文件系统的 IO 管理器知道如何将它的数据块翻译成磁盘维护的数据块地址 LBA。
对于使用文件系统的 IO 操作来说，比如读写文件，这些 IO 的基本单元是文件系统上的数据块，一次读写一个文件系统数据块。比如需要读一个或多个块时，文件系统的 IO 管理器首先计算这些文件系统块对应在哪些磁盘数据块，也就是计算出 LBA，然后通知磁盘控制器要读取哪些块的数据，硬盘控制器将这些块翻译成扇区地址，然后从扇区中读取数据，再通过硬盘控制器将这些扇区数据重组写入到内存中去。
Block(块)，存放数据的最小单位，假如每个块为 4KiB，那大于 5KiB 的块就需要两个块，并且逻辑上占用了 8KiB 的空间。
Block Group(块组)，多个 Block 的集合
Ext 预留了一些 Inode 做特殊特性使用，如下：某些可能并非总是准确，具体的 inode 号对应什么文件可以使用 find /-inum NUM 查看
Ext4 的特殊 inode Inode号 用途 0 不存在0号inode，可用于标识目录data block中已删除的文件 1 虚拟文件系统，如/proc和/sys 2 根目录 # 注意此行 3 ACL索引 4 ACL数据 5 Boot loader 6 未删除的目录 7 预留的块组描述符inode 8 日志inode 11 第一个非预留的inode，通常是 lost+found 目录 所以在 ext4 文件系统的 dumpe2fs 信息中，能观察到 fisrt inode 号可能为 11 也可能为 12。</description></item><item><title>Fact Variables</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Variables/Fact-Variables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Variables/Fact-Variables/</guid><description>概述 参考：
官方文档，Playbook 指南-facts 和 magic 变量 在 ansible 执行任务时，会默认执行名为 Gathering Facts 的任务，以获取目标主机的一些系统信息，如图所示
这些信息以变量的形式体现，每个变量都有其对应的值。可以通过命令 ansible all -m setup 获取这些信息。即通过 setup 模块实现。如下所示
ansible_facts 字段下面的所有字段才是可以直接引用的变量
~]# ansible all -m setup 10.10.100.249 | SUCCESS =&amp;gt; { &amp;#34;ansible_facts&amp;#34;: { &amp;#34;ansible_all_ipv4_addresses&amp;#34;: [ &amp;#34;10.10.100.249&amp;#34; ], &amp;#34;ansible_all_ipv6_addresses&amp;#34;: [ &amp;#34;fe80::47e1:ea44:cfc8:cad0&amp;#34; ], &amp;#34;ansible_devices&amp;#34;: { &amp;#34;fd0&amp;#34;: { &amp;#34;holders&amp;#34;: [], &amp;#34;host&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;model&amp;#34;: null, &amp;#34;partitions&amp;#34;: {}, &amp;#34;removable&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;rotational&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;scheduler_mode&amp;#34;: &amp;#34;deadline&amp;#34;, &amp;#34;sectors&amp;#34;: &amp;#34;0&amp;#34;, &amp;#34;sectorsize&amp;#34;: &amp;#34;512&amp;#34;, &amp;#34;size&amp;#34;: &amp;#34;0.00 Bytes&amp;#34;, &amp;#34;support_discard&amp;#34;: &amp;#34;0&amp;#34;, &amp;#34;vendor&amp;#34;: null }, &amp;#34;sda&amp;#34;: { &amp;#34;holders&amp;#34;: [], &amp;#34;host&amp;#34;: &amp;#34;SCSI storage controller: LSI Logic / Symbios Logic 53c1030 PCI-X Fusion-MPT Dual Ultra320 SCSI (rev 01)&amp;#34;, &amp;#34;model&amp;#34;: &amp;#34;VMware Virtual S&amp;#34;, &amp;#34;partitions&amp;#34;: { &amp;#34;sda1&amp;#34;: { &amp;#34;sectors&amp;#34;: &amp;#34;39843840&amp;#34;, &amp;#34;sectorsize&amp;#34;: 512, &amp;#34;size&amp;#34;: &amp;#34;19.</description></item><item><title>Fiddler</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/Fiddler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/Fiddler/</guid><description>概述 参考：
官网 Wiki, Telerik Fiddler 在 2012 年被 Telerik 收购
安装 Fiddler Classic 版本可免费使用
HTTPS 抓包 打开 Tools - Options
在 HTTPS 标签中，勾选 Capture HTTPS CONNECTs 和 Decrypt HTTPS traffic，Windows 会自动安装 Root 证书。
在 Actions 中可以执行 重置证书、下载证书、等等 操作
在 Connections 标签中，勾选 Allow remote computers to connect 以便通过 PC 的 Fiddler 抓取移动设备的包。在这里还可以配置 Fiddler 的监听端口
取消勾选 Act as system proxy on startup 以便 Fiddler 启动时不要配置系统代理
IOS 安装证书 为无线连接配置手动代理，Fiddler 默认监听在 :8888
IOS 访问 IP:8888 ，点击 FiddlerRoot certificate 下载证书并安装</description></item><item><title>Filter</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/Filter/</guid><description>概述 参考：
WireShark 有两类过滤器
DisplayFilters(显示过滤器) # 过滤已捕获的数据包 捕获过滤器 # 只捕获符合条件的数据包 在 视图 - 内部 - 支持的协议 菜单项中，可以查看当前 WireShark 支持的所有可用于编写过滤表达式的协议关键字和协议中的字段关键（比如 tcp、tcp.port、etc.）。
显示过滤器 参考：
官方 Wiki，显示过滤器 官方文档，6.3 查看时过滤数据包 在 WireShark GUI 过滤器工具栏中，可以通过 Filter Expressions(过滤器表达式) 隐藏不敢兴趣的数据包，仅显示某些特定的包，比如
特定协议的包 特定字段的包 满足某些字段的值进行比较后的包 等等等等 通过 文件 - 导出特定分组 菜单项将过滤的结果导出到一个新的文件中
显示过滤器表达式 参考：
官方文档，6.4 构建显示过滤器表达式 运算符 英文 符号 描述 示例 备注 eq == 完全匹配 ip.addr == 192.168.1.1 contains 模糊匹配 _ws.col.info contains &amp;quot;Client Hello&amp;quot; 仅对 Protocol, field or slice 有效。e.g. ip.</description></item><item><title>Filters Plugins</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Plugins/Filters-Plugins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Plugins/Filters-Plugins/</guid><description>概述 参考：
官方文档，用户指南-目录-使用过滤器操作数据 https://www.zsythink.net/archives/2862 在本博客中，ansible是一个系列文章，我们会尽量以通俗易懂的方式总结ansible的相关知识点。
ansible系列博文直达链接：ansible轻松入门系列
现在我有一个需求，我想要将获取到的变量的值中的所有字母都变成大写，如果想要在playbook中实现这个需求，我该怎么办呢？我可以借助一个叫做&amp;quot;过滤器&amp;quot;的东西，帮助我完成刚才的需求，&amp;ldquo;过滤器（filters）&amp;ldquo;可以帮助我们对数据进行处理，这样解释可能不够直观，不如这样，我们先来看一个过滤器的小例子，然后结合示例解释过滤器是个什么东西，示例如下：
- hosts: test70 remote_user: root gather_facts: no vars: testvar: 1a2b3c tasks: - debug: msg: &amp;#34;{{ testvar | upper }}&amp;#34; 如上例所示，testvar变量的值中包含三个小写字母，在使用debug模块输出这个变量的值时，我们使用了一个管道符，将testvar变量传递给了一个名为&amp;quot;upper&amp;quot;的东西，&amp;ldquo;upper&amp;quot;就是一个&amp;quot;过滤器&amp;rdquo;，执行上例playbook后你会发现，testvar中的所有小写字母都被变成了大写。
通过上述示例，你一定已经明白了，过滤器是一种能够帮助我们处理数据的工具，其实，ansible中的过滤器功能来自于jinja2模板引擎，我们可以借助jinja2的过滤器功能在ansible中对数据进行各种处理，而上例中的upper就是一种过滤器，这个过滤器的作用就是将小写字母变成大写，你一定已经发现了，当我们想要通过过滤器处理数据时，只需要将数据通过管道符传递给对应的过滤器即可，当然，过滤器不只有upper，还有很多其他的过滤器，这些过滤器有些是jinja2内置的，有些是ansible特有的，如果这些过滤器都不能满足你的需求，jinja2也支持自定义过滤器。
这篇文章我们就来总结一些常用的过滤器的用法，在总结时，不会区分它是jinja2内置的过滤器，还是ansible所独有的，我们总结的目的是在ansible中使用这些过滤器，如果你想要了解jinja2中有哪些内置过滤器，可以参考jinja2的官网链接，如下
http://jinja.pocoo.org/docs/2.10/templates/#builtin-filters
字符串操作有关的过滤器 - hosts: test70 remote_user: root vars: testvar: &amp;#34;abc123ABC 666&amp;#34; testvar1: &amp;#34; abc &amp;#34; testvar2: &amp;#39;123456789&amp;#39; testvar3: &amp;#34;1a2b,@#$%^&amp;amp;&amp;#34; tasks: - debug: #将字符串转换成纯大写 msg: &amp;#34;{{ testvar | upper }}&amp;#34; - debug: #将字符串转换成纯小写 msg: &amp;#34;{{ testvar | lower }}&amp;#34; - debug: #将字符串变成首字母大写,之后所有字母纯小写 msg: &amp;#34;{{ testvar | capitalize }}&amp;#34; - debug: #将字符串反转 msg: &amp;#34;{{ testvar | reverse }}&amp;#34; - debug: #返回字符串的第一个字符 msg: &amp;#34;{{ testvar | first }}&amp;#34; - debug: #返回字符串的最后一个字符 msg: &amp;#34;{{ testvar | last }}&amp;#34; - debug: #将字符串开头和结尾的空格去除 msg: &amp;#34;{{ testvar1 | trim }}&amp;#34; - debug: #将字符串放在中间，并且设置字符串的长度为30，字符串两边用空格补齐30位长 msg: &amp;#34;{{ testvar1 | center(width=30) }}&amp;#34; - debug: #返回字符串长度,length与count等效,可以写为count msg: &amp;#34;{{ testvar2 | length }}&amp;#34; - debug: #将字符串转换成列表，每个字符作为一个元素 msg: &amp;#34;{{ testvar3 | list }}&amp;#34; - debug: #将字符串转换成列表，每个字符作为一个元素，并且随机打乱顺序 #shuffle的字面意思为洗牌 msg: &amp;#34;{{ testvar3 | shuffle }}&amp;#34; - debug: #将字符串转换成列表，每个字符作为一个元素，并且随机打乱顺序 # 在随机打乱顺序时，将ansible_date_time.</description></item><item><title>Finalizers</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/Finalizers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Controller/Garbage-Collection%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/Finalizers/</guid><description>概述 参考：
官方文档，概念-概述-使用 Kubernetes 对象-Finalizers 公众号-云原生之路，熟悉又陌生的 k8s 字段：finalizers Kubernetes 博客，使用 Finalizers 控制删除 公众号-云原生实验室，使用 Finalizers 来删除那些死活删不掉的 K8S 资源 Finalizer(终结器) 是一个存放键的列表，不具有任何实际意义，类似于 annotations 字段的功能。它告诉 Kubernetes 在完全删除标记为删除的资源之前等待满足特定条件。终结器提醒控制器清理已删除对象拥有的资源。只有一个对象的 metadata.finalizers 字段的值为空，该对象才可以被删除。
带有 finalizers 字段的对象无法删除的原因大致如下：
对象存在 finalizers，关联的控制器故障未能执行或执行 finalizer 函数 hang 住 : 比如 namespace 控制器无法删除完空间内所有的对象， 特别是在使用 aggregated apiserver 时，第三方 apiserver 服务故障导致无法删除其对象。 此时，需要会恢复第三方 apiserver 服务或移除该 apiserver 的聚合，具体选择哪种方案需根据实际情况而定。 集群内安装的控制器给一些对象增加了自定义 finalizers，未删除完 fianlizers 就下线了该控制器，导致这些 fianlizers 没有控制器来移除他们。此时，有两种方式可以正常删除这些对象，其一，恢复该控制器，控制器会移除 finalizers 字段，其二，手动移除 finalizers 字段(多出现于自定义 operator)，具体选择哪种方案根据实际情况而定。 RabbitMQ Operator 就是这种情况，但是 Prometheus Operator 就没这问题。。。。o(╯□╰)o~~~ 熟悉又陌生的 k8s 字段：finalizers 经常操作 Kubernetes 集群的同学肯定对 finalizers 字段不陌生，每当删除 namespace 或 pod 等一些 Kubernetes 资源时，有时资源状态会卡在 Terminating，很长时间无法删除，甚至有时增加 &amp;ndash;force flag 之后还是无法正常删除。这时就需要 edit 该资源，将 finalizers 字段设置为 []，之后 Kubernetes 资源就正常删除了。</description></item><item><title>find</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/find/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/find/</guid><description>概述 参考：
Manual(手册)，find(1) find 工具可以在目录中搜索文件
Syntax(语法) find [OPTIONS] [PATH&amp;hellip;] [EXPRESSION]
PATH # 路径名，不写上默认表示在当前路径下搜索 OPTIONS 与 EXPRESSION # 详见下文，PATH 可以指定一个或多个想要搜索的路径。 如果没有给出 PATH，则使用当前目录；如果未给出任何表达式，则使用表达式 -print
OPTIONS -H，-L 和-P 选项控制 find 处理 Symbolic link(符号链接) 的行为。这些参数之后的命令行参数将被视为要检查的文件或目录的名称，直到以 - 开头的第一个参数或参数 ( 或 ! 。符号链接的概念详见：
-P # 不跟踪符号链接。该选项为 find 的默认行为。当 find 检查或打印文件信息时，该文件是符号链接，则所使用的信息应取自符号链接本身的属性。 -L # 跟踪符号链接。与 -type l 同时使用时仅搜索失效的符号链接。当 find 检查或打印有关文件的信息时，所使用的信息应从链接指向的文件的属性中获取，而不是从链接本身获取（除非它是断开的符号链接，或者 find 无法检查与之相关的文件）链接点）。使用此选项意味着-noleaf。如果以后使用-P 选项，则-noleaf 仍然有效。如果-L 有效，并且 find 在搜索过程中发现到子目录的符号链接，则将搜索该符号链接所指向的子目录。 当-L 选项生效时，-type 谓词将始终与符号链接指向的文件类型匹配，而不是与链接本身匹配（除非符号链接断开）。使用-L 会使-lname 和-ilname 谓词始终返回 false。 -H # 除了处理命令行参数时，不要跟随符号链接。当 find 检查或打印有关文件的信息时，所使用的信息应取自符号链接本身的属性。唯一的例外情况是在命令行上指定的文件是符号链接并且可以解析该链接时，这种情况下，使用的信息取自链接指向的任何位置（即跟随该链接） ）。如果无法检查符号链接指向的文件，则有关链接本身的信息将用作备用。如果-H 有效，并且在命令行上指定的路径之一是指向目录的符号链接，则将检查该目录的内容（尽管-maxdepth 0 当然可以防止此情况）。 -D debugoptions # Print diagnostic information; this can be helpful to diagnose problems with why find is not doing what you want.</description></item><item><title>firewalld(Iptables 的管理工具)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/firewalld/firewalld/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/firewalld/firewalld/</guid><description>概述 参考：
官网 firewalld 与 iptables 一样，是管理 Linux 内核中的 Netfilter 功能的工具。
FirewallD 使用两个配置模式：“runtime 运行时”和“permanent 持久”。
runtime 模式：默认模式。所有配置即时生效，在重启系统、重新启动 FirewallD 时、使用&amp;ndash;reload 重载配置等操作是，在该模式下的配置都将被清除。 permanent 模式：需要使用 &amp;ndash;permanent 选项生效，配置才会永久保存。如果想让 permanetn 模式下的配置立即生效，需要使用&amp;ndash;reload 命令或者重启 firewalld 服务。 firewalld 中 zone(区域)的概念 “区域”是针对给定位置或场景（例如家庭、公共、受信任等）可能具有的各种信任级别的预构建规则集。不同的区域允许不同的网络服务和入站流量类型，而拒绝其他任何流量。 首次启用 FirewallD 后，public 将是默认区域。
区域也可以用于不同的网络接口。例如，要分离内部网络和互联网的接口，你可以在 internal 区域上允许 DHCP，但在 external 区域仅允许 HTTP 和 SSH。未明确设置为特定区域的任何接口将添加到默认区域。
所以，一般情况下，所有区域都是拒绝所有新的入站流量，对已经建立连接的不再阻止。在使用 firewall-cmd 命令添加某 service、port、ip 等属性时，相当于允许对应属性的流量入站。i.e.添加进去就表示允许
zone 的种类与说明 public（公共） # 默认的 zone。在公共区域内使用，不能相信网络内的其他计算机不会对您的计算机造成危害，只能接收经过选取的连接。 block（限制） # 任何接收的网络连接都被 IPv4 的 icmp-host-prohibited 信息和 IPv6 的 icmp6-adm-prohibited 信息所拒绝。 dmz（非军事区） # 用于您的非军事区内的电脑，此区域内可公开访问，可以有限地进入您的内部网络，仅仅接收经过选择的连接。 drop（丢弃） # 任何接收的网络数据包都被丢弃，没有任何回复。仅能有发送出去的网络连接。 external（外部） # 特别是为路由器启用了伪装功能的外部网。您不能信任来自网络的其他计算，不能相信它们不会对您的计算机造成危害，只能接收经过选择的连接。 home（家庭） # 用于家庭网络。您可以基本信任网络内的其他计算机不会危害您的计算机。仅仅接收经过选择的连接。 internal（内部） # 用于内部网络。您可以基本上信任网络内的其他计算机不会威胁您的计算机。仅仅接受经过选择的连接。 trusted（信任） # 可接受所有的网络连接。 work（工作） # 用于工作区。您可以基本相信网络内的其他电脑不会危害您的电脑。仅仅接收经过选择的连接。 用实际举例：将设备某个网卡放在区域中，则流经该网卡的流量都会遵循该区域中所定义的规则。</description></item><item><title>Free Software Foundation</title><link>https://desistdaydream.github.io/docs/Standard/Foundation/Free-Software-Foundation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Foundation/Free-Software-Foundation/</guid><description>概述 参考：
Wiki, Free Software Foundation Free Software Foundation(自由软件基金会，简称 FSF) 是一个符合 501（c）（3） 非营利组织所创立理查德·斯托曼在 1985 年 10 月 4 日，支持自由软件运动，从而促进普遍自由的学习，分发，创建和修改计算机软件，组织偏爱在Copyleft（“相同方式共享”）条款下分发的软件，例如使用其自己的GNU 通用公共许可证。所述的 FSF 在波士顿并入， 马萨诸塞，美国，它也基于。
从成立到 1990 年代中期，FSF 的资金主要用于聘请软件开发人员为GNU 项目编写免费软件。自 1990 年代中期以来，FSF 的员工和志愿者主要致力于解决自由软件运动和自由软件社区的法律和结构问题。
与其目标一致，FSF 旨在仅在其自己的计算机上使用免费软件。[9]
GNU 参考：
Wiki, GNU 官网 GNU 是一个广泛的自由软件集合，它可以作为一个操作系统使用，也可以与其他操作系统一起使用。使用完整的 GNU 工具导致了操作系统家族的诞生，即俗称的Linux。大部分 GNU 是根据GNU 项目自己的通用公共许可证 ( GPL ) 获得许可的。
GNU/Linux 命名争议 GNU/Linux 命名争议，是在自由及开放源代码软件社区成员内的，关于是应该把使用 GNU 软件与 Linux 内核组合之操作系统称为“GNU/Linux”还是“Linux”的争议。
GNU/Linux这一名称是由自由软件基金会的创立者与GNU 计划的发起人理查德·斯托曼所提出的。GNU 的开发者与其支持者，希望以该名称来作为此操作系统的正式名称。他们认为，此操作系统，包括了 GNU 系统软件包与Linux 核心，使用 GNU/Linux 这个名称，可以良好概括它的主要内容。况且，GNU 项目原本就是以发展一个自由的操作系统为远程项目，但迟迟没有完成。而 Linux 核心的出现刚好可以补足这个缺口。
Linux 内核本身并不是 GNU 计划的一部分，GNU/Linux 这个名称在 Linux 社区中并没有得到一致认同。一些发行版社区例如Debian采用了 GNU/Linux 这一名称，但许多 Linux 社区中的成员认为使用 Linux 这一名称是更好的，为此提出了数项理由，主张 Linux 这个名称朗朗上口，且在公众与媒体中更为通用。Linux 内核项目的发起人林纳斯·托瓦兹偏好于使用 Linux，但对于 GNU/Linux 这个名字并不强烈反感。</description></item><item><title>FRP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/FRP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/FRP/</guid><description>概述 参考：
GitHub 项目，fatedier/frp Fast reverse proxy(快速反向代理，简称 FRP) 一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议，且支持 P2P 通信。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。
重大变化 关于 v2 的一些说明 v2 版本的复杂度和难度比我们预期的要高得多。我只能利用零散的时间进行开发，而且由于上下文经常被打断，效率极低。由于这种情况可能会持续一段时间，我们仍然会在当前版本上进行一些优化和迭代，直到我们有更多空闲时间来推进大版本的重构，或者也有可能放弃一次性的重构，而是采用渐进的方式在当前版本上逐步做一些可能会导致不兼容的修改。
v2 的构想是基于我多年在云原生领域，特别是在 K8s 和 ServiceMesh 方面的工作经验和思考。它的核心是一个现代化的四层和七层代理，类似于 envoy。这个代理本身高度可扩展，不仅可以用于实现内网穿透的功能，还可以应用于更多领域。在这个高度可扩展的内核基础上，我们将实现 frp v1 中的所有功能，并且能够以一种更加优雅的方式实现原先架构中无法实现或不易实现的功能。同时，我们将保持高效的开发和迭代能力。
除此之外，我希望 frp 本身也成为一个高度可扩展的系统和平台，就像我们可以基于 K8s 提供一系列扩展能力一样。在 K8s 上，我们可以根据企业需求进行定制化开发，例如使用 CRD、controller 模式、webhook、CSI 和 CNI 等。在 frp v1 中，我们引入了服务端插件的概念，实现了一些简单的扩展性。但是，它实际上依赖于简单的 HTTP 协议，并且需要用户自己启动独立的进程和管理。这种方式远远不够灵活和方便，而且现实世界的需求千差万别，我们不能期望一个由少数人维护的非营利性开源项目能够满足所有人的需求。
最后，我们意识到像配置管理、权限验证、证书管理和管理 API 等模块的当前设计并不够现代化。尽管我们可能在 v1 版本中进行一些优化，但确保兼容性是一个令人头疼的问题，需要投入大量精力来解决。
非常感谢您对 frp 的支持。
FRP 关联文件与配置 https://gofrp.org/zh-cn/docs/reference/</description></item><item><title>fs(文件系统相关参数)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/fs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/fs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</guid><description>概述 参考：
Linux Kernel 文档，管理员指南 - /proc/sys 文档 - /proc/sys/fs 文档 file-max 与 file-nr fs.file-max = 52706963 max-file 表示系统级别的能够打开的文件描述符的数量。是对整个系统的限制，并不是针对用户的。
ulimit -n 控制进程级别能够打开的文件句柄的数量。提供对 shell 及其启动的进程的可用文件句柄的控制。这是进程级别的。
当系统尝试分配比 file-max 指定的值更多的文件描述符时，通常我们会看到如下报错：VFS: file-max limit &amp;lt;number&amp;gt; reached
fs.file-nr = INT file-nr 中的三个值分别表示：
已分配的文件描述符 已分配但未使用的文件描述符 最大文件描述符 [desistdaydream@hw-cloud-xngy-jump-server-linux-2 ~]$ cat /proc/sys/fs/file-max 9223372036854775807 [desistdaydream@hw-cloud-xngy-jump-server-linux-2 ~]$ cat /proc/sys/fs/file-nr 2400 0 9223372036854775807 通常情况下 已分配但未使用的文件描述符 的值总是为 0，这并不是错误的，只是意味着 已分配的文件描述符=正在使用的文件描述符
由于某些历史原因，内核虽然可以动态分配文件描述符，但是却无法再次释放它们~~~
其他 fs.may_detach_mounts = 1 未知
fs.nr_open = INT64 单个进程可分配的最大文件描述符数量。默认值：1024 * 1024，即 1048576。</description></item><item><title>FTP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/FTP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/FTP/</guid><description>概述 参考：
RFC 959, FILE TRANSFER PROTOCOL (FTP) Wiki, File_Transfer_Protocol File Transfer Protocol(文件传输协议，简称 FTP) 是因特网网络上历史最悠久的网络工具，从 1971 年由 A KBHUSHAN 提出第一个 FTP 的 RFC（RFC114）至今近半个世纪来，FTP 凭借其独特的优势一直都是因特网中最重要、最广泛的服务之一。
FTP 的目标是提高文件的共享性，提供非直接使用远程计算机，使存储介质对用户透明和可靠高效地传送数据。它能操作任何类型的文件而不需要进一步处理，就像 MIME 或 Unicode 一样。但是，FTP 有着极高的延时，这意味着，从开始请求到第一次接收需求数据之间的时间，会非常长；并且不时的必须执行一些冗长的登录进程。
SFTP 参考：
Wiki, SSH_File_Transfer_Protocol SSH File Transfer Protocol(SSH 文件传输协议，简称 SFTP) 也称为 Secure File Transfer Protocol(安全文件传输协议)，是一种网络协议，可通过任何可靠的数据流提供文件访问、文件传输和文件管理。它由 IETF 设计，作为 Secure Shell Protocol(SSH) 2.0 版的扩展，提供安全文件传输功能，并且由于卓越的安全性而被视为文件传输协议 (FTP) 的替代品。
IETF 互联网草案指出，尽管该协议是在 SSH-2 协议的上下文中描述的，但它可以用于许多不同的应用程序，例如通过传输层安全性 (TLS) 进行安全文件传输和管理传输VPN 应用程序中的信息。
该协议假定它在安全通道（例如 SSH）上运行，服务器已经对客户端进行了身份验证，并且客户端用户的身份可供该协议使用。
也就是说，想要使用 SFTP，通常是先建立安全的连接（e.g. SSH、etc.），然后基于该安全的连接实现 FTP 相关能力。
SFTP 不一定是通过 SSH 运行的 FTP（绝大部分都是通过 SSH），而是由 IETF SECSH 工作组从头开始设计的新协议。它有时会与简单文件传输协议混淆。</description></item><item><title>Fyne</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/GUI/Fyne/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/GUI/Fyne/</guid><description>概述 参考：
GitHub 项目，fyne-io/fyne 官网 简书，go fyne 开发桌面应用 稀土掘进，专栏-Fyne ( go跨平台GUI )中文文档 Fyne 是一个易于学习、免费、开源的工具包，用于构建适用于桌面、移动设备及其他设备的图形应用程序。
注意：使用 Fyne 需要安装 MinGW-w64
Hello World package main import ( &amp;#34;fyne.io/fyne/v2/app&amp;#34; &amp;#34;fyne.io/fyne/v2/container&amp;#34; &amp;#34;fyne.io/fyne/v2/widget&amp;#34; ) func main() { // 实例化一个应用 a := app.New() // 为应用创建一个窗口 w := a.NewWindow(&amp;#34;Hello&amp;#34;) // ######## 创建一些应该在窗口中显示的内容，以及设计窗口中的布局 ######## // 创建一个 Label 小部件 labelWidget := widget.NewLabel(&amp;#34;Hello Fyne!&amp;#34;) // 创建一个按钮小部件 buttonWidget := widget.NewButton(&amp;#34;Hi!&amp;#34;, func() { labelWidget.SetText(&amp;#34;Welcome :)&amp;#34;) }) // 创建布局并将指定的对象（小部件、等等）放到这个布局中。 // NewVBox 中会使用 fyne 中自带的 VBox 布局，这种布局会将对象从上到下堆叠。 layout := container.</description></item><item><title>GCC</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/GCC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/GCC/</guid><description>概述 参考：
官网 Wiki, GNU Compiler Collection GNU Compiler Collection(GUN 编译器集合，简称 GCC) 包括了C、C++、Objective-C、Fortran、Ada、Go 以及 D 等语言的前端，同时也包括了这些语言的库（如libstdc++等），是为 GNU 操作系统编写的编译器。GNU 系统是开发成 100% 自由软件的，这里的自由是指它遵循用户的自由原则。
GCC 最初单指 GNU C compiler(GNU C 编译器)
安装 GCC Linux 内核本身就是 C 写的，所以一般都自带 GCC，我们安装的通常都是适用于 Windows 的 GCC，一般是 MinGW-w64
Linux yum install gcc make -y
MinGW-w64 参考：
SourceForge 项目，mingw-w64 GitHub 项目，mingw-w64/mingw-w64 官网 mingw-w64 项目是完整的运行时环境，支持 gcc 编译生成本地运行于 Windows 64 位和 32 位操作系统的二进制文件。
打开 sourceforge 中的 MinGW-w64 页面，在 file 标签页中，下载 x86_64-win32-seh 这个版本并安装即可。这是一个 tar 包，解压完成后，需要在 Windows 的 ${PATH} 环境变量中，添加解压出来的 bin 目录，通常都在 PATH\TO\x86_64-8.</description></item><item><title>Generic</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Generic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Generic/</guid><description>概述 参考：
Wiki, Generic proramming(泛型编程) Generic(泛型) 编程是一种计算机编程的风格，在这种风格中，程序中的数据类型是不固定的（i.e. 广泛的类型），若想让这种不固定的类型固定下来，需要为其提供 类型参数 以便固定成具体的类型。这种编程风格由 1973 年的 ML 编程语言首创，允许编写通用函数或类型，这些函数或类型在使用时仅在操作的类型集上有所不同，从而减少了重复代码。
Generic 也可以看做是以一种特殊的数据类型，就像 string、int 等等数据类型一样，除了具备 Data type 的能力，还多了变化的能力。
假如现在有如下函数：
func g&amp;lt;T any&amp;gt;(i T){ print(typeof(i)) } 其中函数多了 &amp;lt;T any&amp;gt; 这部分，这就表明，这个函数中使用了泛型，这个广泛的类型标识符为 T（就像字符串的标识符为 string 之类的一样），可以让自己变成 any(任意) 的类型。
有的语言，比如 Go 语言，不是使用 [ ] 符号而不是 &amp;lt; &amp;gt; 来标识泛型语法。
此时我们调用 g 函数
g&amp;lt;int&amp;gt;(1) g&amp;lt;string&amp;gt;(&amp;#34;1&amp;#34;) g&amp;lt;int&amp;gt;(1) 输出的结果为 int，g&amp;lt;string&amp;gt;(&amp;quot;string&amp;quot;) 输出的结果为 string。此时，调用是使用的 &amp;lt; &amp;gt; 可以理解为约束，就是让 g 函数中的 T 变为指定的类型。
比如使用 g&amp;lt;int&amp;gt;(1) 调用 g 函数时，这个函数相当于变成了 func g(i int){ print(typeof(i)) }。</description></item><item><title>generic 组</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/generic-%E7%BB%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/generic-%E7%BB%84/</guid><description>概述 参考：
https://redis.io/docs/latest/commands/?group=generic DEL - 删除一个 key since: 1.0.0
DEL key [key &amp;hellip;]
EXAMPLE
DUMP key
summary: Return a serialized version of the value stored at the specified key.
since: 2.6.0
EXISTS - 判断指定的 key 是否存在 since: 1.0.0
EXISTS key [key &amp;hellip;]
EXPIRE key seconds
summary: Set a key&amp;rsquo;s time to live in seconds
since: 1.0.0
EXPIREAT key timestamp
summary: Set the expiration for a key as a UNIX timestamp</description></item><item><title>GeoIP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/GeoIP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/GeoIP/</guid><description>概述 参考：
Wiki, GeoIP 重定向到 Internet geolocation 在 IT 中，Internet geolocation(互联网地理定位，简称 GeoIP) 是能够推断连接到互联网的设备的地理位置的软件。例如，设备的 IP 地址可用于确定国家、城市或邮政编码，从而确定其地理位置。其他方法包括检查 Wi-Fi 热点、
IP 地址分配机制 参考：
IANA, 号码资源 APNIC, 搜索(通过给定的 IP 地址搜索谁拥有这个 IP) 面包板，你知道中国大陆一共有多少 IPv4 地址吗？ 公众号，k8s 中文社区-居然还有 2 亿多 IPv4 地址未分配 IPv4 和 IPv6 地址通常以分层方式分配。ISP(互联网服务提供商) 为用户分配 IP 地址。ISP 从 LIR(本地互联网注册机构) 或 NIR(国家互联网注册机构) 或 RIR(相应的区域互联网注册机构) 获取 IP 地址分配
登记处 覆盖面积 AFRINIC Africa Region(非洲地区) APNIC Asia/Pacific Region(亚洲/太平洋地区，亚太地区) ARIN Canada, USA, and some Caribbean Islands(加拿大、美国、一些加勒比岛屿) LACNIC Latin America and some Caribbean Islands(拉丁美洲、一些加勒比岛屿) RIPE NCC Europe, the Middle East, and Central Asia(欧洲、中东、中亚) 对 IP 地址的主要作用是根据全球政策所述的需求将未分配地址池分配给 RIR，并记录 IETF 所做的协议分配。当 RIR 需要在其区域内分配或分配更多 IP 地址时，我们会向 RIR 进行额外分配。我们不会直接向 ISP 或最终用户进行分配，除非在特定情况下，例如分配多播地址或其他协议特定需求。</description></item><item><title>gettext</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/gettext/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/gettext/</guid><description>概述 参考：
官网 gettext 是 GNU 旗下的一组工具集合，提供了一个框架以帮助其他 GNU 包生成多语言消息。
通常包含如下几个工具：
envsubst gettext gettext.sh ngettext 安装 gettext 一般的发行版都默认自带 gettext 工具集，如果没有，使用包管理器安装 gettext 包即可
Ubuntu
apt install gettext-base envsubst 参考：
官方手册，envsubst envsubst 程序可以用来替换环境变量的值。正常情况下，与 cat 命令类似，所有的标准输入都会复制到标准输出，但是不同的地方在于，如果标准输入中包含变量引用，比如 $VARIABLE 或 ${VARIABLE} 这种形式，则这些引用将会被替换为变量的值：
~]# envsubst HOME HOME $HOME /root ${HOME} /root 若我们将标准输入改为由文件提供，那么我们就可以将文件中的所有变量引用的地方都替换为对应的值。比如：
sudo tee ~/tmp/test.txt &amp;lt;&amp;lt;-&amp;#34;EOF&amp;#34; HOME = ${HOME} PATH = ${PATH} API_URL = ${API_URL} EOF 执行 envsubst &amp;lt; test.txt &amp;gt; test2.txt 命令以替换文件中的环境变量，生成的 test.txt 内容如下：
~]# cat test2.</description></item><item><title>Git</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git/</guid><description>概述 参考：
官网 公众号，Git 各指令的本质 Git 是一个免费的开源分布式版本控制系统，旨在快速高效地处理从小型到大型项目的所有内容。
Git 易于学习，占地面积小，具有闪电般的快速性能。它具有廉价的本地分支，方便的暂存区域和多个工作流等功能，其性能优于 Subversion，CVS，Perforce 和 ClearCase 等 SCM 工具。
Git 优势 Git 是一个分布式代码管理工具，在讨论分布式之前避免不了提及一下什么是中央式代码管理仓库：
中央式：所有的代码保存在中央服务器，所以提交必须依赖网络，并且每次提交都会带入到中央仓库，如果是协同开发可能频繁触发代码合并，进而增加提交的成本和代价。最典型的就是 SVN。 分布式：可以在本地提交，不需要依赖网络，并且会将每次提交自动备份到本地。每个开发者都可以把远程仓库 clone 一份到本地，并会把提交历史一并拿过来。代表就是 Git。 [!Tip] 我们可以使用 git CLI 的 remote 命令创建多个中央仓库（也称为远程仓库），以便将项目代码在多个仓库之间同步
那 Git 相比于 SVN 有什么优势呢？打个比方：“巴拉巴拉写了一大堆代码，突然发现写的有问题，我想回到一个小时之前”，对于这种情况 Git 的优势就很明显了，因为 commit 的成本比较小并且本地会保存所有的提交记录，随时随刻可以进行回退。在这并不是说 SVN 的不能完成这种操作，只是 Git 的回退会显得更加的优雅。Git 相比于中央式工具还有很多优点，就不一一列举了
Git 文件状态 在 Git 中文件大概分为三种状态：
modified(修改) # Git 可以感知到工作目录中哪些文件被修改了，然后把修改的文件加入到 modified 区域 staged(暂存) # 通过 add 命令将工作目录中修改的文件提交到暂存区，等候被 commit committed(提交) # 将暂存区文件 commit 至 Git 目录中永久保存 commit 节点</description></item><item><title>git CLI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/git-CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/git-CLI/</guid><description>概述 参考：
https://git-scm.com/docs/git git 工具通过多个子命令来使用，可以按照功能对这些命令进行划分
设置与配置 Git 获取和创建项目 分支与合并 分享和更新项目 设置与配置 config - 配置 git 获取和设置存储库或全局选项
Syntax(语法) git config [&amp;lt;file-option&amp;gt;] [--type=&amp;lt;type&amp;gt;] [--fixed-value] [--show-origin] [--show-scope] [-z|--null] &amp;lt;name&amp;gt; [&amp;lt;value&amp;gt; [&amp;lt;value-pattern&amp;gt;]] git config [&amp;lt;file-option&amp;gt;] [--type=&amp;lt;type&amp;gt;] --add &amp;lt;name&amp;gt; &amp;lt;value&amp;gt; git config [&amp;lt;file-option&amp;gt;] [--type=&amp;lt;type&amp;gt;] [--fixed-value] --replace-all &amp;lt;name&amp;gt; &amp;lt;value&amp;gt; [&amp;lt;value-pattern&amp;gt;] git config [&amp;lt;file-option&amp;gt;] [--type=&amp;lt;type&amp;gt;] [--show-origin] [--show-scope] [-z|--null] [--fixed-value] --get &amp;lt;name&amp;gt; [&amp;lt;value-pattern&amp;gt;] git config [&amp;lt;file-option&amp;gt;] [--type=&amp;lt;type&amp;gt;] [--show-origin] [--show-scope] [-z|--null] [--fixed-value] --get-all &amp;lt;name&amp;gt; [&amp;lt;value-pattern&amp;gt;] git config [&amp;lt;file-option&amp;gt;] [--type=&amp;lt;type&amp;gt;] [--show-origin] [--show-scope] [-z|--null] [--fixed-value] [--name-only] --get-regexp &amp;lt;name-regex&amp;gt; [&amp;lt;value-pattern&amp;gt;] git config [&amp;lt;file-option&amp;gt;] [--type=&amp;lt;type&amp;gt;] [-z|--null] --get-urlmatch &amp;lt;name&amp;gt; &amp;lt;URL&amp;gt; git config [&amp;lt;file-option&amp;gt;] [--fixed-value] --unset &amp;lt;name&amp;gt; [&amp;lt;value-pattern&amp;gt;] git config [&amp;lt;file-option&amp;gt;] [--fixed-value] --unset-all &amp;lt;name&amp;gt; [&amp;lt;value-pattern&amp;gt;] git config [&amp;lt;file-option&amp;gt;] --rename-section &amp;lt;old-name&amp;gt; &amp;lt;new-name&amp;gt; git config [&amp;lt;file-option&amp;gt;] --remove-section &amp;lt;name&amp;gt; git config [&amp;lt;file-option&amp;gt;] [--show-origin] [--show-scope] [-z|--null] [--name-only] -l | --list git config [&amp;lt;file-option&amp;gt;] --get-color &amp;lt;name&amp;gt; [&amp;lt;default&amp;gt;] git config [&amp;lt;file-option&amp;gt;] --get-colorbool &amp;lt;name&amp;gt; [&amp;lt;stdout-is-tty&amp;gt;] git config [&amp;lt;file-option&amp;gt;] -e | --edit OPTIONS</description></item><item><title>Git 最佳实践</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
git 放弃本地修改，强制拉取更新
git fetch &amp;ndash;all # 指令是下载远程仓库最新内容，不做合并 git reset &amp;ndash;hard origin/master # 指令把 HEAD 指向 master 最新版本 git pull # 可以省略 本地所有修改，没有提交的文件，都返回到原来的状态
git checkout . # 提交修改并上传代码
git add . # git commit -a -m &amp;lsquo;XXXX 修改&amp;rsquo; # git push # git 回滚到之前某一 commit
git log # 查看所有 commit 记录，记录其中的 commit 号，比如 commit 号为：d07466766d46710e54a627f913eea5661382331a git reset &amp;ndash;hard d07466766d46710e54a627f913eea5661382331a # 恢复到这次 commit 的状态 修改 git commit 信息 对自己的提交进行修改
git commit &amp;ndash;amend 将修改强制提交，覆盖原先的提交内容</description></item><item><title>GitHub 管理</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
git clone克隆或下载一个仓库单个文件夹 1、如果是想克隆别人的项目或者自己的 很简单的一个网站就解决了。DownGit： 只需要找到仓库中对应文件夹的 url,输入之后,点击 download 自动打包下载:
（这里说明一下，因为原作者的项目无法使用，这是我修改过的新项目吧，把资源链接改到了国内 CDN，所以访问速度很快！）
2、克隆自己的项目 注意：本方法会下载整个项目，但是，最后出现在本地项目文件下里只有需要的那个文件夹存在。类似先下载，再过滤。
有时候因为需要我们只想 gitclone 下仓库的单个或多个文件夹，而不是全部的仓库内容，这样就很省事，所以下面就开始教程啦
在 Git1.7.0 以前，这无法实现，但是幸运的是在 Git1.7.0 以后加入了 Sparse Checkout 模式，这使得 Check Out 指定文件或者文件夹成为可能。
举个例子：
现在有一个 test 仓库https://github.com/mygithub/test你要 gitclone 里面的tt子目录：在本地的硬盘位置打开Git Bash
git init test &amp;amp;&amp;amp; cd test //新建仓库并进入文件夹 git config core.sparsecheckout true //设置允许克隆子目录 echo &amp;#39;tt*&amp;#39; &amp;gt;&amp;gt; .git/info/sparse-checkout //设置要克隆的仓库的子目录路径 //空格别漏 git remote add origin git@github.com:mygithub/test.git //这里换成你要克隆的项目和库 git pull origin master //下载 ok，大功告成！！！
管理所有通知 管理所有已经订阅的 issue https://github.com/notifications/subscriptions
github上fork了别人的项目后，再同步更新别人的提交 我从 github 网站和用 git 命令两种方式说一下。</description></item><item><title>GitHub 上的 PR 全过程</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub-%E4%B8%8A%E7%9A%84-PR-%E5%85%A8%E8%BF%87%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub-%E4%B8%8A%E7%9A%84-PR-%E5%85%A8%E8%BF%87%E7%A8%8B/</guid><description>概述 参考：
原文链接 今天我准备和你详细介绍如何开始参与开源项目，帮助你在 GitHub 上完成第一个 PR 的合入。
当然，除了正常的 PR 合入流程之外，我还准备详细介绍一下如果一个 PR 提交后遇到了冲突、需要追加 commits、需要合并 commits 等等相对复杂问题该如何解决。
总的来说，本文计划分为 4 个部分：
谈谈为什么要参与开源项目以及我为什么要介绍如何 PR 谈谈怎么开始参与开源项目，也就是如何寻找合适的开源项目、如何寻找贡献点 介绍怎么上手 PR 流程，即从 fork 到 push 全流程 介绍提交了 PR 之后遇到各种常见问题如何解决 Ok, let&amp;rsquo;s get started!
二、为什么要参与开源项目 本文我不打算长篇大论 “为什么要参与开源”，详细介绍参与开源项目的收获，我想仅从“提升编码能力” 角度谈一谈“为什么要参与开源项目”。
在面试的时候我有个习惯，如果候选人在自己的简历里说到自己熟悉某一门语言，我就会习惯性问他一个问题：
你有没有阅读过某个开源项目的源码？或者更进一步，有没有参与过某个开源社区，或者说给开源项目提过 PR？
如果答案是肯定的，比如候选人说自己读过部分 Kubernetes 模块的源码，再进一步我确认他真的读过并且读懂了或者说真的提交过 bugfix/feature 类型的 PR，那我就不再问编程语言层面的问题了，因为我相信能看懂一个成熟的开源项目部分模块源码或者能够提交 bugfix/feature 类型的 PR 已经说明了一切。
我自己在学习 Golang 的时候，大致分为两个阶段：
学习基础语法，开始写项目，直到能够熟练完成各种业务功能的开发； 看了一些开源项目的源码，深感受益颇多，编码水平再上一个台阶。 差不多也就是在看 Kubernetes 项目源码的时候，我深刻认识到一般的企业内部项目和汇集全世界最优秀的程序员智慧结晶的开源项目之间的巨大差距，也意识到学习优秀开源项目源码对于一个程序员编码水平提升的重要性（当然，你可以说 Google 内部也存在非开源的非常优秀的代码，这毫无疑问，但是我想今天我们没有必要讨论特例）。
认真阅读开源项目源码，你总会发现一些小瑕疵，这时候提一个 PR(Pull Request)，让你的代码合入开源项目，运行在 “世界每一个角落”，那是多么有趣的事情！而成功合入第一个 PR 往往就像打开潘多拉魔盒一样，你会进入到另外一个世界，开始接触到开源社区，感受开源的魅力！</description></item><item><title>GitHub 搜索</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-%E6%90%9C%E7%B4%A2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-%E6%90%9C%E7%B4%A2/</guid><description>概述 参考：
官方文档，在 GitHub 上搜索 GitHub 的集成搜索涵盖了 GitHub 上的许多存储库、用户和代码行。
查找 Github 仓库所有者的联系方式 https://juejin.cn/post/6951642072935825439
通过提交记录
查看项目第一次 commit 时间 https://www.cnblogs.com/saysmy/p/7292177.html
这个代码库 commits7855 次，点击进入 commits 发现翻页只有两个按钮不能直接点击翻页到最后一页，那如何查看第一条记录呢？
原来 github为每个commit版本都生成了一个SHA hash值，我们可以通过SHA值来直接搜索到第N次的提交
点击一次 older 发现 url 格式为：
https://github.com/lodash/lodash/commits/master?after=c2616dd4f3ab267d000a2b4f564e1c76fc8b8378+34
后面的 after 即代表展示 SHA 为c2616dd4f3ab267d000a2b4f564e1c76fc8b8378 的后面第35条commit。
那c2616dd4f3ab267d000a2b4f564e1c76fc8b8378 这一串是怎么得到的呢？
在commits列表内的每一条记录后面都有一个copy图标，这里点击即会成功复制此条commit的SHA
c2616dd4f3ab267d000a2b4f564e1c76fc8b8378正式此代码库的最新一条commit的SHA。
于是如果我们想找到第一条记录，总commits记录是7855次，那么搜索url为：
https://github.com/lodash/lodash/commits/master?after=c2616dd4f3ab267d000a2b4f564e1c76fc8b8378+7853
成功搜索到想要的结果。
搜索 Issue 和 PR 纯粹与用户相关的搜索 involves:USERNAME # 搜索所有涉及 USERNAME 的内容。可以用户的东西包括: author(作者)、assignee(分配)、mentions(提及)、commenter(评论者)
author:USERNAME # 搜索由 USERNAME 创建的 ISSUE 和 PR
commenter:USERNAME # 搜索 USERNAME 用户评论过的内容
mentions:USERNAME # 搜索提及 USERNAME 的内容。i.</description></item><item><title>glance</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/glance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/glance/</guid><description>概述 参考：
glance [&amp;ndash;version] [-d] [-v] [&amp;ndash;get-schema] [-f]</description></item><item><title>go rabbitmq 库</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/go-rabbitmq-%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/go-rabbitmq-%E5%BA%93/</guid><description>概述 参考：
http://www.topgoer.com/%25E6%2595%25B0%25E6%258D%25AE%25E5%25BA%2593%25E6%2593%258D%25E4%25BD%259C/go%25E6%2593%258D%25E4%25BD%259CRabbitMQ/Simple%25E6%25A8%25A1%25E5%25BC%258F.html
package RabbitMQ import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;github.com/streadway/amqp&amp;#34; ) //连接信息amqp://kuteng:kuteng@127.0.0.1:5672/kuteng这个信息是固定不变的amqp://事固定参数后面两个是用户名密码ip地址端口号Virtual Host const MQURL = &amp;#34;amqp://kuteng:kuteng@127.0.0.1:5672/kuteng&amp;#34; //rabbitMQ结构体 type RabbitMQ struct { conn *amqp.Connection channel *amqp.Channel //队列名称 QueueName string //交换机名称 Exchange string //bind Key 名称 Key string //连接信息 Mqurl string } //创建结构体实例 func NewRabbitMQ(queueName string, exchange string, key string) *RabbitMQ { return &amp;amp;RabbitMQ{QueueName: queueName, Exchange: exchange, Key: key, Mqurl: MQURL} } //断开channel 和 connection func (r *RabbitMQ) Destory() { r.</description></item><item><title>Go 设计模式</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E6%89%A9%E5%B1%95/Go-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E6%89%A9%E5%B1%95/Go-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid><description>概述 参考：</description></item><item><title>go-simplejson 库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/JSON/go-simplejson-%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/JSON/go-simplejson-%E5%BA%93/</guid><description>概述 参考：
GitHub 项目，bitly/go-simplejson 笔记文档
simplejson 是一个 golang 包， 提供快速和简单的方法来从 JSON 文件中获取值、设置值、删除值。
1. Json 解码编码? // json解码 j, err := simplejson.NewJson([]byte(jsonStr)) // json漂亮编码 s, err := j.EncodeJsonPretty() // json编码 s, err1 := j.EncodeJSON() 2. Json 获取值? // 初始化 j, err := simplejson.NewJson([]byte(jsonStr)) // 获取json object对象值 j.Get(key string).String() // 获取json 多级object对象值 j.Get(key string).Get(key string).Int() // 获取json array数组索引值 j.GetIndex(index int).String() // 获取json 多级array数组索引值 j.GetIndex(index int).GetIndex(index int).Int() // 获取json 多级数组对象组合键索引值 j.GetIndex(index int).Get(key string).GetIndex(index int).</description></item><item><title>Goroutine AND Channel</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/Goroutine-AND-Channel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/Goroutine-AND-Channel/</guid><description>概述 参考:
公众号,马哥 Linux 运维-golang channel 使用总结 公众号，田飞雨-Golang GPM 模型剖析 Go 语言的并发 不要通过共享来通信，而要通过通信来共享。
通过 Goroutines(协程) 与 Channels(通道) 实现 并发编程
并发与并行的区别
Concurrency(并发) # 一个处理器或者内核上，一个并发程序可以使用多个线程来交替运行。反义词为顺序 实际例子：你有一张嘴，电话来了，你停了下来接了电话，吃一口说一句话，直到说完话并且吃完饭，这是并发 Parallelism(并行) # 多个处理器或者多核上，一个程序在某个时间、在多个处理器上同时运行。反义词为串行 实际例子：你有两张嘴，电话来了，你一边打电话一边吃饭，直到说完话并且吃完饭，这是并行 并行是并发的真子集。并发不全是并行，但并行一定并发。(单核并发不并行，多核并行也属于并发)，除非该程序无法使用多线程执行任务。
并行不一定会加快运行速度，因为并行运行的组件之间可能需要相互通信。比如运行在两个 CPU 上的两个组件之间需要互相通信。并发系统上，这种通信开销很小。但在多核的并行系统上，组件间的通信开销就很高了。所以，并行不一定会加快运行速度！
一个程序是运行在机器上的一个进程，进程是一个运行在自己内存空间里的独立执行体。一个进程由一个或多个操作系统线程组成，这些线程其实是共享同一个内存地址空间在一起工作的执行体。几乎所有正式的程序都是多线程的，以便让用户或计算机不必等待，或能够同时服务多个请求(e.g.Web 服务器)，或增加性能和吞吐量。
不要使用全局变量或共享内存，他们会给代码在并发运算的时候带来危险。
Goroutines(协程) 处理应用程序并发功能的就是 Goroutines(协程)
Go 协程是与其他函数或方法一起并发运行的函数或方法。
调用函数或者方法时，在前面加上关键字 go，可以让一个新的 Go 协程并发地运行。i.e.有关键字go的函数或方法，即算协程，可以并发运行。 main()函数算主协程，可以没有go关键字
一个基本的协程代码示例：
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) var wg sync.WaitGroup func hello(m string) { if m == &amp;#34;waitgroup&amp;#34; { // 让 WaitGroup 计数器 -1 defer wg.</description></item><item><title>Grafana Alerting</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-Alerting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-Alerting/</guid><description>概述 参考：
官方文档，告警 Alert rules(警报规则) # 确定是否触发警报的规则。e.g. 评估规则的周期（i.e. 多久检查一次告警是否应该触发）、etc.
Notification policies(通知策略) # 确定警报如何路由到联络点。e.g. 根据什么条件分组、发送前等待多久、相同警报重新发送的时间间隔、etc.
Contack points(联络点) # 当警报实例触发时如何通知联系人。e.g. 设置通过企业微信，使用 XXX 模板渲染消息，并发送给联系人。联系人是真实世界的实体，联络点是通知方式的抽象。
Alert rules 一个完整的 Alert rules 由三部分组成
Query(查询语句) Condition Expressions(条件表达式) # 可选。简称 Expressions Evaluation behavior(评估行为) # 评估行为 与 Prometheus 中的 Alerting 的评估行为类似（有一点不同是：Prom 的评估是决定是否将警报发送出去，但 Grafana 内部集成了类似 Alertmanager 的逻辑，所以评估是决定是否将警报交给 Notifications 组件） Grafana 会评估 Expressions 的处理结果（对 Query 查询结果的处理结果），满足条件的将会交给 Notifications 组件。
Evaluation behavior https://grafana.com/docs/grafana/latest/alerting/fundamentals/alert-rule-evaluation/
为 Alert rules 定义 Evaluation behavior(评估行为)，评估成功后，会改变警报的状态，并将某些状态的警报交给 Notification policies(通知策略) 以便对警报进行后续处理。
等待多久、间隔多久、查询出错或查询没数据时怎么办、etc. 都属于评估行为。包括如下几个部分</description></item><item><title>Grafana MGMT</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-MGMT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-MGMT/</guid><description>概述 参考：
官方文档，管理 Grafana 密码重置 参考：
官方文档，管理 - CLI - 重置 admin 密码 SQLite3 重置 首先需要安装 sqlite3 命令行工具，然后通过 sqlite3 /PATH/TO/grafana.db 命令进入 Grafana 数据库
通过 select login, password, salt from user where login = 'admin'; 语句可以查询到 admin 的当前密码信息
使用下面的 SQL，可以更新 admin 用户的密码为 admin：
sqlite&amp;gt; update user set password = &amp;#39;59acf18b94d7eb0694c61e60ce44c110c7a683ac6a8f09580d626f90f4a242000746579358d77dd9e570e83fa24faa88a8a6&amp;#39;, salt = &amp;#39;F3FAxVm33R&amp;#39; where login = &amp;#39;admin&amp;#39;; API 修改密码 前提是没有忘记密码
curl -X PUT -H &amp;#34;Content-Type: application/json&amp;#34; -d &amp;#39;{ &amp;#34;oldPassword&amp;#34;: &amp;#34;旧密码&amp;#34;, &amp;#34;newPassword&amp;#34;: &amp;#34;新密码&amp;#34;, &amp;#34;confirmNew&amp;#34;: &amp;#34;新密码&amp;#34; }&amp;#39; http://账号:旧密码@IP:PORT/api/user/password grafana-cli 密码重置 grafana-cli admin reset-admin-password 新密码 常用 Dashboard 推荐 Kubernetes</description></item><item><title>Graph Library</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DPDK/Graph-Library/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DPDK/Graph-Library/</guid><description>概述 参考：
官方文档，Graph Library and Inbuilt Nodes https://zhuanlan.zhihu.com/p/604202266 https://zhuanlan.zhihu.com/p/613233087 DPDK 的 Graph(图) Library 将数据处理功能抽象为 Node(节点)，并将这些 Node 被 links(链接) 在一起以创建一张大型的数据处理流程图，以实现可重用的/模块化的数据处理能力。一个 Node 中可以有一个或多个流量处理 Function(功能)，一个 Node 处理完成后，交给下一个或几个其他 Node 继续处理流量数据
假如我们设计了如下一系列功能
decode flow reassemble resource control asset security record drop &amp;hellip;&amp;hellip;略 可以将这些功能分散到多个 Node 中，每个 Node 又可以规划如何如何调用这些功能
&amp;#34;node_m&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;sink&amp;#34;, &amp;#34;next&amp;#34;: [ &amp;#34;flow&amp;#34; ] }, ...... 略 ], &amp;#34;node_n&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;rx&amp;#34;, &amp;#34;next&amp;#34;: [ &amp;#34;decode&amp;#34; ] }, { &amp;#34;name&amp;#34;: &amp;#34;decode&amp;#34;, &amp;#34;next&amp;#34;: [ &amp;#34;traffic_filter&amp;#34; ] }, { &amp;#34;name&amp;#34;: &amp;#34;traffic_filter&amp;#34;, &amp;#34;next&amp;#34;: [ &amp;#34;capture&amp;#34;, &amp;#34;drop&amp;#34; ] }, .</description></item><item><title>GraphQL</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/GraphQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/GraphQL/</guid><description>概述 参考：
GitHub 组织，GraphQL 官网 公众号 - K8S中文社区，我为什么要放弃 RESTful，选择拥抱 GraphQL 原文: https://www.toutiao.com/article/6833818331884028419/ REST 作为一种现代网络应用非常流行的软件架构风格，自从 Roy Fielding 博士在 2000 年他的博士论文中提出来到现在已经有了 20 年的历史。它的简单易用性，可扩展性，伸缩性受到广大 Web 开发者的喜爱。
REST 的 API 配合 JSON 格式的数据交换，使得前后端分离、数据交互变得非常容易，而且也已经成为了目前 Web 领域最受欢迎的软件架构设计模式。
但随着 REST API 的流行和发展，它的缺点也暴露了出来：
滥用 REST 接口 ，导致大量相似度很高（具有重复性）的 API 越来越冗余。 对于前端而言：REST API 粒度较粗 ，难以一次性符合前端的数据要求，前端需要分多次请求接口数据。增加了前端人员的工作量。 对于后端而言：前端需要的数据往往在不同的地方具有相似性，但却又不同 ，比如针对同样的用户信息，有的地方只需要用户简要信息（比如头像、昵称），有些地方需要详细的信息，这就需要开发不同的接口来满足这些需求。当这样的相似但又不同的地方多的时候，就需要开发更多的接口来满足前端的需要。增加了后端开发人员的工作量和重复度。 那我们来分析一下，当前端需求变化，涉及到改动旧需求时 ，会有以下这些情况：
做加法：
产品需求增加，页面需要增加功能，数据也就相应的要增加显示，那么REST接口也需要做增加，这种无可厚非。
做减法：
产品需求减少，页面需要减少功能，或者减少某些信息显示，那么数据就要做减法。
一种通常懒惰的做法是，前端不与后端沟通，仅在前端对数据选择性显示。
因为后端接口能够满足数据需要，仅仅是在做显示的时候对数据进行了选择性显示，但接口的数据是存在冗余的，这种情况一个是存在数据泄露风险，另外就是数据量过大时造成网络流量过大，页面加载缓慢，用户流量费白白消耗，用户体验就会下降。
另外一种做法就是告知后端，要么开发新的接口，要么，修改旧接口，删掉冗余字段。
但一般来说，开发新接口往往是后端开发人员会选择的方案，因为这个方案对现有系统的影响最低，不会有额外的风险。
修改旧接口删除冗余数据的方案往往开发人员不会选择，这是为什么呢？
这就涉及到了系统的稳定性问题了，旧接口往往不止是一个地方在用，很有可能很多页面、设置不同客户端、不同服务都调用了这个接口获取数据，不做详细的调查，是不可能知道到底旧接口被调用了多少次，一旦改动旧接口，涉及范围可能非常大，往往会引起其他地方出现崩溃。改动旧接口成本太高，所以往往不会被采取。
同时做加减法：
既有加法，又有减法，其实这种就跟新需求没啥区别，前端需要重做页面，后端需要新写接口满足前端需要，但是旧接口还是不能轻举妄动（除非确定只有这一处调用才可以删除）。
往往这个时候，其实用到的数据大多都是来自于同一个DO或者DTO，不过是在REST接口组装数据时，用不同的VO来封装不同字段，或者，使用同样的VO，组装数据时做删减。
看到这些问题是不是觉得令人头大？
所以需求频繁改动是万恶之源 ，当产品小哥哥改动需求时，程序员小哥哥可能正提着铁锹赶来&amp;hellip;&amp;hellip;
那么有没有一种方案或者框架，可以使得在用到同一个领域模型（DO或者DTO）的数据时，前端对于这个模型的数据字段需求的改动，后端可以根据前端的改动和需要，自动适配，自动组装需要的字段，返回给前端呢？如果能这样做的话，那么后端程序猿小哥可能要开心死了，前端妹子也不用那么苦口婆心地劝说后端小哥哥了。所以GraphQL隆重出世了！那么问题来了！
Part 1 What is GraphQL GraphQL简介 GraphQL是一种新的API标准，它提供了一种比REST更有效、更强大和更灵活的替代方案。</description></item><item><title>grep</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep/</guid><description>概述 参考：
Manual(手册)，grep(1) grep 是文本搜索工具，可以使用正则表达式在文件内查找符合条件的字串行
Syntax(语法) grep [OPTIONS] PATTERNS [FILE&amp;hellip;]
grep 根据 PATTERNS(模式) 过滤给定的内容。其实就是使用正则表达式，过滤内容。
OPTIONS Pattern Syntaz(模式语法) 用于定义过滤时所解析的正则表达式语法
-E, &amp;ndash;extended-regexp # 将 PATTERNS 解释为扩展的正则表达式（ERE，请参见下文）。 -P,&amp;ndash;perl-regexp # 将 PATTERNS 解释为与 Perl 兼容的正则表达式(PCREs)。与-z（&amp;ndash;null-data）选项结合使用时，此选项是实验性的，并且 grep -P 可能会警告未实现的功能。 Matching Control(配置控制) -i # 忽略大小写 -v, &amp;ndash;invert-match # 反向选择，选择没有要匹配的字符串的行 General Output Control(通用输出控制) 选项 -c, &amp;ndash;count # 计算找到的符合行的次数 &amp;ndash;color=auto # 把查找到内容自动表上默认颜色，auto 可改成别的颜色英文 -l,&amp;ndash;files-with-matches # 只输出匹配到的文件的文件名。常用来在一堆文件中，筛选指定内容，只查看哪些文件有指定的内容。 -m, &amp;ndash;max-count=NUM # 在 NUM 个匹配行后停止读取文件。i.e. -o, &amp;ndash;only-matching # 仅显示被匹配到的字符串，不显示整行 -s, &amp;ndash;no-messages # 不显示错误信息 Output Line Prefix Control(控制输出行的前缀) -h, &amp;ndash;no-filename # 当过滤多个文件时，不要输出文件名，仅输出过滤到的内容。 -n, &amp;ndash;line-number # 顺便输出行号 Context Line Control(控制输出内容的上下行) -A NUM, &amp;ndash;after-context=NUM # 打印出查找到的行的下面 NUM 行 -B NUM, &amp;ndash;before-context=NUM # 打印出查找到的行的上面 NUM 行 -C NUM, &amp;ndash;context=NUM # -A 与 -B 选项的结合体，控制输出内容的 上面 和下面 NUM 行 File and Directory Selection(文件和目录选择) -a, &amp;ndash;text # 像对待文本一样处理二进制文件；这等效于&amp;ndash;binary-files = text 选项。 &amp;ndash;exclude FILE # 跳过指定文件，不让 grep 处理跳过的文件。可以使用通配符。 &amp;ndash;exclude-dir=DIR # 跳过指定目录，不让 grep 处理跳过的目录。可以使用通配符。 -R, &amp;ndash;dereference-recursive # 递归地阅读每个目录下的所有文件并进行 grep 操作;该选项相当于-d recurse EXAMPLE 查看 accesslog 文件的实时更新，并筛选出不包含两个字符串的行 tailf accesslog | grep -vE &amp;lsquo;(miguvideo|mgtv)&amp;rsquo; grep &amp;ndash;color=auto -i R.</description></item><item><title>grub 文件</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Bootloader/grub-%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Bootloader/grub-%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
RedHad 系
/etc/grub2.cfg /etc/grub2-efi.cfg Debian 系
TODO:
/boot/grub2/
/boot/grub/</description></item><item><title>Hacking</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Hacking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Hacking/</guid><description>概述 参考：
B 站合集，【黑客奇谈】现实黑客的世界是什么样的？ Flipper Zero 是一款玩具般的便携式多功能工具，适合渗透测试人员和极客。它喜欢破解数字内容，例如无线电协议、访问控制系统、硬件等。它是完全开源和可定制的，因此您可以按照自己喜欢的方式扩展它。
名词解释 补充一个小知识点，软件漏洞在英文里不是 Hole——孔洞，而是 Vulnerability(脆弱性)，因为软件里的漏洞往往不会是一个明晃晃的“洞”，而是一个不起眼的“脆弱性”。
Robo Hacking Game(机器人网络安全大赛，简称 RHG) 是中国版的 CGC 大赛。
Cyber Grand Challenge(网络空间超级挑战赛，简称 CGC) 是 Defense Advanced Research Projects Agency(国防高级研究计划局，简称 DARPA) 举办的比赛。
网络空间资产测绘搜索引擎 # 网络空间资产测绘引擎是一种通过技术手段对全球网络空间中的资产进行探测、识别和分析的工具对全球暴露在互联网上的服务器和设备进行资产探 测、端口探活、协议解析、应用识别通过网络空间测绘技术，将地理空间、社会空间、网络空间相互映射，绘制动态其自主研发的扫描引擎可全端口扫描
CMS 指纹识别 # Content Management System(内容管理系统) 旨在通过分析目标网站呈现出的各种特征信息，来准确判断指纹识别其是基于哪种 CMS 搭建的。比如是 WordPress、Drupal、Joomla 等常见的 CMS，以及具体使用的是哪个版本
0day 漏洞 # 是指在软件、硬件或操作系统等产品中被攻击者发现并利用。但软件供应商或开发者还未知晓，因而尚未发布补丁或其他修复程序的安全漏洞。
之所以被称为 “0day”，是因为从漏洞被发现并利用，到开发人员知晓并着手修复。这期间留给开发人员的时间几乎为零，意味着开发人员没有时间提前准备应对措施 GetShell # 通常是指在网络安全领域，攻击者通过各种手段获取目标服务器的命令执行权限或者可交互式的Shell环境
攻击者一旦获取Shell权限，便可肆意操作服务器资源 比如窃取敏感信息（如用户数据、数据库内容等）、篡改服务器上的网页文件、安装恶意程序进一步控制服务器，甚至利用该服务器作为跳板去攻击其他关联的网络目标等 WebShell # 是一种网页脚本木马，它通过网页脚本（如ASP、PHP、JSP等）形式存在。可以在被攻击的服务器上执行命令，攻击者利用Web应用程序的漏洞（如文件上传漏洞、SQL注入漏洞等）将Webshell脚本上传到目标服务器，从而获得对服务器的一定控制权
https://github.com/BeichenDream/Godzilla https://github.com/rebeyond/Behinder https://github.com/AntSwordProject/antSword Bobalt strike # 是一款以团队协作形式进行网络攻击模拟及渗透测试的平台。旨在帮助安全专业人员评估目标网络的安全性，发现潜在漏洞并验证防御机制的有效性。它集成了众多先进的功能模块涵盖了从信息收集、漏洞利用到权限维持等整个网络渗透流程中的多个环节
https://www.cobaltstrike.com/ 蜜罐 # 蜜罐是一种被设计用来吸引攻击者、捕获攻击行为信息的虚拟或真实的网络资源。它看似存在有价值的信息或系统漏洞，就像放置在网络环境中的“诱饵”，诱导攻击者对其发起攻击，进而收集攻击者的攻击手段、行为习惯、工具使用等相关信息，帮助安全人员更好地了解潜在的安全威胁，完善防御策略。</description></item><item><title>Hash</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/Hashing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/Hashing/</guid><description>概述 参考：
Wiki 类别，Hashing Wiki, Hash function Hashing 是一种实现数据 Retrieval(检索) 的算法，有多种 Hashing 算法，比如
Consistent hashing Hash table 参考：
Wiki, Hash table Hash table(哈希表) 也称为 hash map(哈希映射) 或 hash set(哈希集)，是一种实现关联数组的数据结构，也称为 dictionary(字典)，它是一种将键映射到值的抽象数据类型。哈希表使用哈希函数来计算索引（也称为哈希码）到桶或槽数组中，从中可以找到所需的值。在查找过程中，对键进行哈希处理，生成的哈希值指示相应值的存储位置。
理想情况下，哈希函数会将每个键分配给一个唯一的存储桶，但大多数哈希表设计都采用不完善的哈希函数，这可能会导致哈希冲突，即哈希函数为多个键生成相同的索引。此类冲突通常以某种方式进行调节</description></item><item><title>Heap and Stack</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Heap-and-Stack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Heap-and-Stack/</guid><description>概述 参考：
StackOverflow Heap(堆) 与 Stack(栈)
汇编语言 这里有一些 堆栈 的通俗解释，非常好理解
内存模型：Heap 寄存器只能存放很少量的数据，大多数时候，CPU 要指挥寄存器，直接跟内存交换数据。所以，除了寄存器，还必须了解内存怎么储存数据。
程序运行的时候，操作系统会给它分配一段内存，用来储存程序和运行产生的数据。这段内存有起始地址和结束地址，比如从0x1000到0x8000，起始地址是较小的那个地址，结束地址是较大的那个地址。
程序运行过程中，对于动态的内存占用请求（比如新建对象，或者使用malloc命令），系统就会从预先分配好的那段内存之中，划出一部分给用户，具体规则是从起始地址开始划分（实际上，起始地址会有一段静态数据，这里忽略）。举例来说，用户要求得到 10 个字节内存，那么从起始地址0x1000开始给他分配，一直分配到地址0x100A，如果再要求得到 22 个字节，那么就分配到0x1020。
这种因为用户主动请求而划分出来的内存区域，叫做 Heap（堆）。它由起始地址开始，从低位（地址）向高位（地址）增长。Heap 的一个重要特点就是不会自动消失，必须手动释放，或者由垃圾回收机制来回收。
内存模型：Stack 除了 Heap 以外，其他的内存占用叫做 Stack（栈）。简单说，Stack 是由于函数运行而临时占用的内存区域。
请看下面的例子。
int main() { int a = 2; int b = 3; } 上面代码中，系统开始执行main函数时，会为它在内存里面建立一个帧（frame），所有main的内部变量（比如a和b）都保存在这个帧里面。main函数执行结束后，该帧就会被回收，释放所有的内部变量，不再占用空间。
如果函数内部调用了其他函数，会发生什么情况？
int main() { int a = 2; int b = 3; return add_a_and_b(a, b); } 上面代码中，main函数内部调用了add_a_and_b函数。执行到这一行的时候，系统也会为add_a_and_b新建一个帧，用来储存它的内部变量。也就是说，此时同时存在两个帧：main和add_a_and_b。一般来说，调用栈有多少层，就有多少帧。
等到add_a_and_b运行结束，它的帧就会被回收，系统会回到函数main刚才中断执行的地方，继续往下执行。通过这种机制，就实现了函数的层层调用，并且每一层都能使用自己的本地变量。
所有的帧都存放在 Stack，由于帧是一层层叠加的，所以 Stack 叫做栈。生成新的帧，叫做 &amp;ldquo;入栈&amp;rdquo;，英文是 push；栈的回收叫做 &amp;ldquo;出栈&amp;rdquo;，英文是 pop。Stack 的特点就是，最晚入栈的帧最早出栈（因为最内层的函数调用，最先结束运行），这就叫做 &amp;ldquo;后进先出&amp;rdquo; 的数据结构。每一次函数执行结束，就自动释放一个帧，所有函数执行结束，整个 Stack 就都释放了。</description></item><item><title>helm template 模板相关命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/helm-template-%E6%A8%A1%E6%9D%BF%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/helm-template-%E6%A8%A1%E6%9D%BF%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
https://helm.sh/docs/helm/helm_template/ template - 在本地渲染 chart 模板，并展示输出 helm template [NAME] [CHART] [FLAGS]
FLAGS -a, &amp;ndash;api-versions stringArray Kubernetes api versions used for Capabilities.APIVersions &amp;ndash;atomic if set, the installation process deletes the installation on failure. The &amp;ndash;wait flag will be set automatically if &amp;ndash;atomic is used &amp;ndash;ca-file string verify certificates of HTTPS-enabled servers using this CA bundle &amp;ndash;cert-file string identify HTTPS client using this SSL certificate file &amp;ndash;create-namespace create the release namespace if not present &amp;ndash;dependency-update run helm dependency update before installing the chart &amp;ndash;description string add a custom description &amp;ndash;devel use development versions, too.</description></item><item><title>hping</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/hping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/hping/</guid><description>概述 参考：
GitHub 项目，antirez/hping https://www.kali.org/tools/hping3/ https://salsa.debian.org/debian/hping3 Wiki, Hping 原始 GitHub 项目截至 2024-04-18 已经有 10 年没更新了。
hping 不支持 IPv6
https://github.com/TeddyGuo/tping 像 hping，但支持 IPv6，Python 编写
nping 由 Nmap
hping 是由 Salvatore Sanfilippo（也称为 Antirez）创建的 TCP/IP 协议的开源数据包生成器和分析器。它是用于防火墙和网络安全审计和测试的常用工具之一，用于利用空闲扫描扫描技术（也是由 hping 作者发明的），现在在 Nmap Security Scanner 中实现。新版本的 hping，hping3，可以使用 Tcl 语言编写脚本，并实现一个基于字符串的、人类可读的 TCP/IP 数据包描述引擎，以便程序员可以编写与低级 TCP/IP 数据包操作和分析相关的脚本。很短的时间。
Syntax(语法) EXAMPLE https://www.cnblogs.com/Higgerw/p/16469371.html
通过 eth1，发送 SYN 报文到 172.24.194.179 的 80 端口。源地址伪造为 192.168.180.131，时间间隔 1000us
hping3 -I eth0 -S 172.24.194.179 -p 80 -a 192.168.180.131 -i u1000 通过 eth1, 发送 SYN 报文到 192.</description></item><item><title>HTTP(新监控标准)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/HTTP%E6%96%B0%E7%9B%91%E6%8E%A7%E6%A0%87%E5%87%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/HTTP%E6%96%B0%E7%9B%91%E6%8E%A7%E6%A0%87%E5%87%86/</guid><description>概述 参考：
由于 SNMP 的种种不便，现在更多的是基于 HTTP 协议来实现监控指标的采集。
同样，也是需要一个 Client 采集指标，需要一个 Server 端接收指标后存储指标。
像 SNMP 协议一样，光有协议还不行，基于 HTTP 协议的监控也需要一个数据模型的标准，就像 MIB 和 OID 类似。而现阶段，从 Prometheus 的 Data Model(数据模型) 演化过来的 OpenMetrics 标准，就是这么一种东西。
OpenMetrics 详见 OpenMetrics</description></item><item><title>HTTP2</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP2/</guid><description>概述 参考：
RFC，7540 官网 51 张图助你彻底掌握 HTTP 协议 https://mp.weixin.qq.com/s/a83_NE-ww36FZsy320MQFQ HTTP 2.0 在性能上实现了很大的飞跃，更难得的是它在改进的同时保持了语义的不变，与 HTTP 1.1 的语义完全相同！比如请求方法、URI、状态码、头字段等概念都保留不变，这样就消除了再学习的成本，在我们的日常软件升级中，向下兼容非常重要，也是促进产品大规模使用的一个前提，不然你一升级，各种接口之类的全换了，谁还敢升。 HTTP 2.0 只在语法上做了重要改进，完全变更了 HTTP 报文的传输格式
在语法上主要实现了以下改造
1、头部压缩 HTTP 1.1 考虑了 body 的压缩，但没有考虑 header 的压缩, 经常出现传了头部上百，上千字节，但 Body 却只有几十字节的情况，浪费了带宽，而且我们知道从 1.1 开始默认是长连接，几百上千个请求都用的这个连接，而请求的头部很多都是重复的，造成了带宽的极大浪费!想象一下面的这个请求，为了传输区区 「name=michale 」这几个字节，却要传输如此巨量的头部，浪费的带宽确实惊人。
那么 HTTP 2.0 是如何解决的呢？它开发了专门的 「HPACK」算法，在客户端和服务器两端建立字典，用索引号表示重复的字符串，还采用哈夫曼编码来压缩数字和整数，可以达到最高达 90% 的压缩率
这里简单解释下，头部压缩需要在支持 HTTP 2.0 的客户端和服务器之间：
维护一份静态的字典（Static table），包含常见的头部名称，以及特别常见的头部名称与值的组合。这样的话如果请求响应命中了静态字典，直接发索引号即可 维护一份相同的动态字典（Dynamic table），可以动态地添加字典，这样的话如果客户端首次请求由于「User-Agent: xxx」,「host:xxx」,「Cookie」这些的动态键值对没有命中静态字典，还是会传给服务器，但服务器收到后会基于传过来的键值对创建动态字典条目，如上图的「User-Agent: xxx」对应数字 62，「host:xxx」对应数字 63，这样双方都创建动态条目后，之后就可以用只传 62，63 这样的索引号来通信了！显而易见，传输数据急遽降低，极大地提升了传输效率！需要注意的是动态字典是每个连接自己维护的，也就是对于每个连接而言，首次都必须发送动态键值对 支持基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）：对于静态、动态字典中不存在的内容，可以使用哈夫曼编码来减小体积。HTTP/2 使用了一份静态哈夫曼码表（详见），也需要内置在客户端和服务端之中。 2、二进制格式 HTTP 1.1 是纯文本形式，而 2.0 是完全的二进制形式，它把 TCP 协议的部分特性挪到了应用层，把原来的 Header+Body 消息打散为了数个小版的二进制&amp;quot;帧&amp;quot;（Frame）,“HEADERS”帧存放头数据、“DATA”帧存放实体数据</description></item><item><title>HTTP3</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP3/</guid><description>概述 参考：
Wiki, HTTP/3 HTTP/3 是用于在万维网上交换信息的超文本传输​​协议的第三个主要版本，是对广泛部署的 HTTP/1.1 和 HTTP/2 的补充。与之前依赖完善的 TCP（于 1974 年发布）的版本不同，HTTP/3 使用 QUIC（于 2021 年正式引入），一种基于 UDP 构建的多路复用传输协议。</description></item><item><title>Huge Pages</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Huge-Pages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Huge-Pages/</guid><description>概述 参考:
Linux Kernel 文档，管理员指南 - 内存管理 - 概念 - Huge pages Wiki, Huge pages Huge Pages(大页) 是指每个 Page 的容量都远超默认大小(4 KiB)的 Page。比如 2 MiB、1 GiB、etc. 都是常见的大页内存空间中的每页容量。Huge Pages Memory 则是指每个 Page 的容量都超过 4 KiB 的内存的统称。
在 x86 架构上，可以使用 第二级 和 第三级 页表中的条目来映射 2MiB 甚至 1GiB 的 Page。
HugePages 可以减少页表开销、减轻 TLB 压力并提高 TLB 的命中率、减轻内存数据查询压力、避免使用 Swap 降低性能。但是前提是保证使用大页的程序可以完善得利用大页，否则就会造成内存的极大浪费。
[!Notes] 为什么已经分页了还要用大页？ 如果一个程序（比如数据库），把大量数据加载到内存中，这时候其查询的数据量一定远超 TLB 的容量，这必然会导致 TLB 的未命中急速上升，严重影响性能。还有很多其他的方面就不一一举例了。
所以大页并不是所有程序都适用的，而是针对特定场景，需要处理大量数据，亲自管理内存的程序，才要配置大页。比如 DPDK 处理流量也需要使用大页的内存空间
Linux Kernel 中有两种机制可以实现 物理内存 与 Huge Pages 的映射</description></item><item><title>Hugging Face</title><link>https://desistdaydream.github.io/docs/12.AI/Hugging-Face/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Hugging-Face/</guid><description>概述 参考：
GitHub 组织，huggingface 官网 Wiki, Hugging_Face 知乎，Huggingface 超详细介绍 Hugging Face 即是一个工具包的集合，也是一个社区。
在 2017 年在 GitHub 上开源了非常著名的 Transformers 库。 在 2019 年推出了 Hugging Face Hub，一个用于共享和加载预训练模型和数据集的平台 后续也陆续开发了其他的工具包，例如 tokenizers、datasets、huggingface_hub、accelerate和peft，以及一个公共的推理API，为机器学习开发者提供了更多的便利和资源。 它提供了多种工具包，例如：
transformers：一个用于构建和使用预训练语言模型的 Python 库，支持 PyTorch 和 TensorFlow。 tokenizers：一个用于快速和高效地创建和使用词法分析器的 Python 库。 datasets：一个用于轻松共享和加载数据集和评估指标的 Python 库。 huggingface_hub：一个用于创建、删除、更新和检索仓库信息的 Python 库，也可以从仓库下载文件或将它们集成到你的库中。 accelerate：一个用于轻松地训练和使用 PyTorch 模型的 Python 库，支持多 GPU、TPU 和混合精度。 peft：一个用于实现参数高效微调（PEFT）方法的 Python 库，可以有效地将预训练语言模型（PLMs）适应于各种下游应用，而无需微调所有模型参数6。 使用 Hugging Face 可以帮助我们在 NLP 领域进行创新和探索。
Hugging face 起初是一家总部位于纽约的聊天机器人初创服务商，他们本来打算创业做聊天机器人，然后在github上开源了一个Transformers库，虽然聊天机器人业务没搞起来，但是他们的这个库在机器学习社区迅速大火起来。目前已经共享了超100,000个预训练模型，10,000个数据集，变成了机器学习界的github。
最佳实践 Hugging Face下载大模型的相关文件说明
如何理解仓库中的模型文件
在Hugging Face的模型存储库中，这些文件通常用于表示预训练模型及其相关配置、模型权重、词汇表和分词器等。下面是这些文件的一般作用：
.gitignore ：是一个纯文本文件，包含了项目中所有指定的文件和文件夹的列表，这些文件和文件夹是Git应该忽略和不追踪的 MODEL_LICENSE：模型商用许可文件 REDAME.</description></item><item><title>Hugo 配置</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/Hugo-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/Hugo-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
官方文档，入门 - 配置 Hugo 支持 TOML、YAML、JSON 格式的配置文件，默认配置文件名为 hugo.SUFFIX。所有的配置指令都可以写在 hugo.SUFFIX 文件中。
我们可以拆分配置文件，并将其保存在 ${ConfigDir} 目录下(默认为站点根目录下的 config/ 文件夹)。 ConfigDir 下的每个文件名代表配置中的根指令，比如：
hugo.toml 文件中有如下指令
[Params] foo = &amp;#39;bar&amp;#39; 那么拆分到 ConfigDir 目录时，则使用 params.toml 文件，内容为：
foo = &amp;#39;bar&amp;#39; 除了 Hugo 本身会用到配置文件，有些主题也会使用，并具有各自可以识别的配置指令。比如 Docsy 主题。
在官方文档，配置-所有配置设置我们可以找到 Hugo 的所有配置指令
config 目录结构 ├── config │ ├── _default │ │ ├── hugo.toml │ │ ├── languages.toml │ │ ├── menus.en.toml │ │ ├── menus.zh.toml │ │ └── params.toml │ ├── production │ │ ├── hugo.</description></item><item><title>Hyper-V</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Hyper-V/Hyper-V/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Hyper-V/Hyper-V/</guid><description>概述 参考： virtmgmt 命令行工具打开图形化的 Hyper-V 图形界面
关联文件与配置 编辑会话设置 # 用以设置连接信息。基本都是 tsclient 的设置。
共享 参考：
官方文档-虚拟化，与你的虚拟机共享设备 增强会话模式可通过 RDP（远程桌面协议）将 Hyper-V 与虚拟机连接起来。 这不仅会改善你的整体虚拟机查看体验，而且使用 RDP 连接还可以使虚拟机与你的计算机共享设备。 由于 RDP 在 Windows 10 中默认打开，所以与 Windows 虚拟机连接时，你可能已经在使用 RDP。 本文着重介绍了一些好处和连接设置对话框中的隐藏选项。
RDP/增强会话模式：
使虚拟机实现可调整大小和高 DPI 感知。 改进虚拟机集成 共享的剪贴板 通过拖放和复制粘贴进行文件共享 允许设备共享 麦克风/扬声器 USB 设备 数据磁盘（包括 C:） 打印机 想要共享宿主机的磁盘，最好的方法是使用 RDP 的 tsclient 功能，效果如下图：
使用 PowerShell 模块管理 Hyper-V 参考：
官方文档-PowerShell，模块-hyper-v https://learn.microsoft.com/zh-cn/virtualization/hyper-v-on-windows/quick-start/try-hyper-v-powershell New-VM 参考：
https://learn.microsoft.com/en-us/powershell/module/hyper-v/new-vm 创建一个新的虚拟机
Get-VM 参考：
https://learn.microsoft.com/en-us/powershell/module/hyper-v/get-vm 从一个或多个 Hyper-V 主机获取虚拟机
PS ~&amp;gt; get-vm Name State CPUUsage(%) MemoryAssigned(M) Uptime Status Version ---- ----- ----------- ----------------- ------ ------ ------- win10 Off 0 0 00:00:00 正常运行 11.</description></item><item><title>I_O</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/I_O/I_O/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/I_O/I_O/</guid><description>概述 参考：
公众号 - 码农的荒岛求生，读取文件时，程序经历了什么？ 极客时间 - Linux 性能优化实战，24 | 基础篇：Linux 磁盘I/O是怎么工作的（上） 极客时间 - Linux 性能优化实战，25 | 基础篇：Linux 磁盘I/O是怎么工作的（下） 承接上文《看完这篇还不懂高并发中的线程与线程池你来打我》，这是高性能、高并发系列的第二篇文章，在这里我们来到了 I/O 这一话题。
你有没有想过当我们执行 I/O 操作时计算机底层都发生了些什么？
在回答这个问题之前，我们先来看下为什么对于计算机来说 I/O 是极其重要的。
不能执行 I/O 的计算机是什么？ 相信对于程序员来说 I/O 操作是最为熟悉不过的了：
当我们使用 C 语言中的 printf、C++中的&amp;quot;&amp;laquo;&amp;quot;，Python 中的 print，Java 中的 System.out.println 等时，这是 I/O；当我们使用各种语言读写文件时，这也是 I/O；当我们通过 TCP/IP 进行网络通信时，这同样是 I/O;当我们使用鼠标龙飞凤舞时，当我们扛起键盘在评论区里指点江山亦或是埋头苦干努力制造 bug 时、当我们能看到屏幕上的漂亮的图形界面时等等，这一切都是 I/O。
想一想，如果没有 I/O 计算机该是一种多么枯燥的设备，不能看电影、不能玩游戏，也不能上网，这样的计算机最多就是一个大号的计算器。
既然 I/O 这么重要，那么到底什么才是 I/O 呢？详见 I/O 中的 “什么是 I/O”
I/O 与 CPU 本文主要说的是 Disk(磁盘) 的 I/O，更多关于磁盘 I/O 的基础概念详见 Block</description></item><item><title>I/O</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/I_O/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/I_O/</guid><description>概述 参考：
Wiki, Input/output 在计算中，Input/Output(输入/输出，简称 I/O。或非正式的 io 或 IO) 是信息处理系统（例如计算机）与外部世界（例如另一个计算机系统、外围设备或计算机）之间的通信。人类操作员。输入是系统接收的信号或数据，输出是系统发送的信号或数据。该术语也可以用作动作的一部分； “执行I/O”是执行输入或输出操作。
I/O 设备是人类（或其他系统）用来与计算机通信的硬件。例如，键盘或计算机鼠标是计算机的输入设备，而监视器和打印机是输出设备。用于计算机之间通信的设备（例如调制解调器和网卡）通常执行输入和输出操作。交互者与系统的任何交互都是输入，系统响应的反应称为输出。
将设备指定为输入或输出取决于视角。鼠标和键盘接收人类用户输出的物理动作，并将其转换为计算机可以理解的输入信号；这些设备的输出就是计算机的输入。同样，打印机和显示器将计算机输出的信号作为输入，并将这些信号转换为人类用户可以理解的表示形式。从人类用户的角度来看，阅读或查看这些表示的过程就是接收输出；计算机和人类之间的这种类型的交互是在人机交互领域进行研究的。更复杂的是，传统上被视为输入设备的设备，例如读卡器、键盘，可以接受控制命令以例如选择堆叠器、显示键盘灯，而传统上被视为输出设备的设备可以提供状态数据（例如，状态数据）。碳粉不足、缺纸、卡纸）。
在计算机体系结构中，CPU 和主存储器的组合被认为是计算机的大脑，CPU 可以使用单独的指令直接读取或写入主存储器。与 CPU/内存组合之间的任何信息传输（例如通过从磁盘驱动器读取数据）都被视为 I/O。CPU及其支持电路可以提供在低级计算机编程中使用的存储器映射 I/O，例如在设备驱动程序的实现中，或者可以提供对 I/O 通道的访问。 I/O 算法是一种设计用于利用局部性并在与辅助存储设备（例如磁盘驱动器）交换数据时高效执行的算法。
什么是 I/O https://mp.weixin.qq.com/s/EYc7PcxukBKOx8U5X8Sh8w
I_O 就是简单的数据 Copy，仅此而已。I/O 仅仅就是数据 copy、I/O 仅仅就是数据 copy。
既然是 copy 数据，又是从哪里 copy 到哪里呢？
如果数据是从外部设备 copy 到内存中，这就是 Input。
如果数据是从内存 copy 到外部设备，这就是 Output。
内存与外部设备之间不嫌麻烦的来回 copy 数据就是 Input and Output(输入/输出，简称 I/O)，仅此而已。</description></item><item><title>I/O</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/I_O/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/I_O/</guid><description>概述 参考：
Go 标准库，io Go 标准库，bufio 公众号 - 云原生生态圈，Go 写文件的几种姿势，你喜欢哪一种？ Introduction to bufio package in Golang Go 语言中文网，Go 语言 bufio 包介绍 [!Notes] 想要理解 io 标准库的逻辑，必须要理解 Method AND Interface 中的 Interface(接口) 的概念，这是理解 I/O 的前提，否则不要往下阅读！
io.Reader、io.Writer 是 io 包中的接口，用于处理 I/O 操作。
所有实现了 io.Reader 接口的类型都可以作为输入源，例如 文件、网络连接、etc. 所有实现了 io.Writer 接口的类型都可以作为输出目标，例如 文件、网络连接、etc. bufio 包用来帮助处理 buffered I/O(I/O 缓存)，通过 I/O 缓存我们可以减少对系统调用，提高性能。
读取用户的输入 大多数的程序都是处理输入，产生输出；这也正是计算的定义。但是程序如何获取要处理的输入数据呢？有一些程序生成自己的数据，但是通常情况下，输入来自于程序外部，e.g.文件、网络连接、其他程序的输出、敲键盘的用户、命令行参数或其它类似的输入源。想要使用 Go 语言的输入输出功能，一般不外乎下面 3 步
获取输入源的定位符，e.g.文件描述符、用户的标准输入、etc. 通过输入源的定位符，把输入内容放到缓冲区并充缓冲器发送给变量 打印缓冲区的变量即可实现输出输入源提供的数据 fmt 包的 Scan 和 Sscan 开头的函数。
Scanln 扫描来自标准输入的文本，将空格分隔的值一次存放到后续的参数内，直到碰到换行。Scanf 与 Scanln 类似，除了 Scanf 的第一个参数作用格式字符串，用来决定如何读取。以 Sscan 和以 Sscan 开头的函数则是从字符串读取，除此之外，与 Scanf 相同。</description></item><item><title>I/O Virtualization</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/I_O-Virtualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/I_O-Virtualization/</guid><description>概述 参考：
Wiki, I/O virtualization I/O Virtualization(输入/输出虚拟化) 是一种广义的虚拟化概念。
VFIO 是 I/O 虚拟化的一种具体实现方式，专注于将设备直通给虚拟机，让虚拟机可以直接控制物理设备，从而获得接近于物理机的性能。</description></item><item><title>I/O 模型</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/I_O-%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/I_O-%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考：
Wiki, Asynchronous_I/O 编程中的 I_O
同步/异步：关注的是消息通信机制，被调用者在收到调用请求后，是否立即返回，还是得到最终结果后才返回,立即返回为异步，等待结果再返回为同步，异步不会影响调用者处理后续
同步和异步通常用来形容一次方法调用。
同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。
异步方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。而，异步方法通常会在另外一个线程中，“真实”地执行着。整个过程，不会阻碍调用者的工作。举个例子
你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下&amp;quot;，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。 而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。 阻塞/非阻塞：关注的是程序在等待调用结果（消息，返回值）时的状态.，调用者发起调用请求后，在收到响应结果之前是否会被挂起，被挂起为阻塞，不被挂起为非阻塞。举个例子
同步阻塞： 老张在厨房用普通水壶烧水，一直在厨房等着（阻塞），盯到水烧开（同步）； 异步阻塞： 老张在厨房用响水壶烧水，一直在厨房中等着（阻塞），直到水壶发出响声（异步），老张知道水烧开了； 同步非阻塞： 老张在厨房用普通水壶烧水，在烧水过程中，就到客厅去看电视（非阻塞），然后时不时去厨房看看水烧开了没（轮询检查同步结果）； 异步非阻塞： 老张在厨房用响水壶烧水，在烧水过程中，就到客厅去看电视（非阻塞），当水壶发出响声（异步），老张就知道水烧开了。 所谓同步异步，只是对于水壶而言。 普通水壶，同步；响水壶，异步。 虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。 同步只能让调用者去轮询自己（情况 2 中），造成老张效率的低下。 所谓阻塞非阻塞，仅仅对于老张而言。 立等的老张，阻塞；看电视的老张，非阻塞。 情况 1 和情况 3 中老张就是阻塞的，媳妇喊他都不知道。虽然 3 中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。</description></item><item><title>IDS/IPS</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/IDS_IPS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/IDS_IPS/</guid><description>概述 参考：
Wiki, Intrusion detection system Intrusion detection/prevention system(入侵监测系统 与 入侵防御系统，简称 IDS/IPS) 是一种设备或软件应用程序，用于监视网络或系统是否存在恶意活动或策略违规行为。
这套系统通常包含如下几部分
规则 # 一种人类可读的过滤规则 规则库 # 特定于某种识别场景的一组规则，识别某些特定的恶意流量 引擎 # 将规则翻译成流量过滤的语句以定位某个或某些流量 用 Snort 举例，Snort 本身可以表示 一种规则格式、一个识别规则的引擎、一个由 N 个规则组合而成的规则库；这些东西组合在一起，可以称之为一套系统。那么当流量来了之后（实时的流量 或者 .pcap 文件），Snort 可以读取流量，根据 Snort 规则库中的 Snort 规则，利用 Snort 识别引擎，对流量进行匹配后，识别出哪些流量是被规则命中的。
所谓引擎，应该是一种把自己的定义的人类可读的规则翻译成流量过滤语句的技术。
同理，其他的比如 Suricate、Yara、自研 的都是类似的道理，我们可以把这些系统中的规则通过某种方式进行转换，比如把人类可读的 Snort 规则转换成 Suricata 的规则后，由 Suricata 引擎再对流量识别。</description></item><item><title>IEEE</title><link>https://desistdaydream.github.io/docs/Standard/IT/IEEE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/IT/IEEE/</guid><description>概述 参考：
Wiki, Institute_of_Electrical_and_Electronics_Engineers Institute of Electrical and Electronics Engineers(电气和电子工程师协会，简称 IEEE) 是一个 501(c)(3) 电子工程、电气工程和其他相关学科的专业协会，其公司办事处位于纽约市，运营中心位于新泽西州皮斯卡塔韦。 IEEE 于 1963 年由美国电气工程师协会和无线电工程师协会合并而成
技术协会 IEEE 有多种 societies(协会)，每个协会都专注于某一知识领域。
IEEE Computer Society(计算机协会)</description></item><item><title>image</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/image/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/image/</guid><description>概述 参考：
image 命令用于管理容器镜像。
build - 使用 Dockerfile 构建一个镜像 history - Show the history of an image import - Import the contents from a tarball to create a filesystem image inspect - Display detailed information on one or more images load - Load an image from a tar archive or STDIN ls - 列出所有镜像 prune - 移除未使用的镜像 Syntax(语法) docker image prune [OPTIONS]
OPTIONS
-a, &amp;ndash;all # Remove all unused images, not just dangling ones -f, &amp;ndash;force # Do not prompt for confirmation EXAMPLE docker image prune -a # 清理所有没有使用的镜像</description></item><item><title>Information security utility</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Utility/Information-security-utility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Utility/Information-security-utility/</guid><description>概述 参考：
SQLMap # 非常强大且广为人知的开源自动化 SQL 注入漏洞检测与利用工具。支持检测和利用包括布尔盲注、时间盲注、报错注入、联合查询注入等常见的SQL注入类型，可根据目标情况灵活运用不同的注入手法来获取数据库中的数据或者执行相关操作。一旦发现存在SQL注入漏洞，它可以进一步获取数据库的诸多关键信息，例如数据库的类型、版本号、数据库中的表名、 列名以及具体的数据内容，帮助安全测试人员全面了解目标数据库的情况
https://github.com/shadow1ng/fscan # 一款内网综合扫描工具，方便一键自动化、全方位漏扫扫描。</description></item><item><title>Ingress Manifest</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/Ingress-Manifest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/Ingress-Manifest/</guid><description>概述 参考：
API 文档, 单页 官方文档，参考-Kubernetes API-服务资源-Ingress Manifest 中的顶层字段 apiVersion: networking/v1 kind: Ingress metadata(metadata) spec(spec) status(status) metadata name: STRING # Ingress 对象名称。必须名称空间唯一。 annotations: # Ingress 的控制器将会根据 annotations，以自定义其行为。这些注释下的 kev/value 对 可以通过 ingress 传递给 controller ，然后 controller 根据这些信息进行更详细的配置，比如 url rewrite、代理超时时间等等。 注意：不同的 controller 对 annotaions 中定义的内容有不同的处理。 nginx ingress controller 社区版的 annotaions 说明 nginx ingress controller 官方版的 annotaions 说明 如果是在公有云上，公有云的各种 LB，也会读取 annotations 中的内容，以便将自家的 LB 与 ingress 关联 spec defaultBackend(Object) ingressClassName(STRING) rules([]Object) # 是一个类似于 nginx 的 7 层反向代理的配置 Ingress 资源最重要的字段，主要的实现逻辑都在这里了</description></item><item><title>inode 已满解决方法</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/inode-%E5%B7%B2%E6%BB%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/inode-%E5%B7%B2%E6%BB%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</guid><description>概述 参考：
问题描述 在 Linux 系统的云服务器 ECS 实例内创建文件时，出现类似如下空间不足的提示。
No space left on device … 问题原因 导致该问题的可能原因如下所示：
磁盘分区空间使用率达到百分之百。 磁盘分区 inode 使用率达到百分之百。 存在僵尸文件。 挂载点覆盖。 解决方案 阿里云提醒您：
要解决该问题，请根据不同的问题原因，通过以下方式进行处理：
分区容量满 inode 容量满 修改 inode 数量 僵尸文件分析删除 挂载点覆盖 分区容量满的处理 登录服务器，使用df -h命令查看磁盘使用率，其中的Mounted on指挂载的目录。 进入根目录，执行 du -sh * 指令，逐级查看哪个目录占用磁盘空间较大，进入相应的目录，直到找到最精确的文件或目录。 最后，结合业务情况等判断对相关文件或目录进行删除，或者购买更大的数据盘分担处理。 inode 容量满的处理 通过如下操作，解决 inode 容量满的问题。
查询 inode 使用情况
Linux 的 inode 节点中，记录了文件的类型、大小、权限、所有者、文件连接的数目、创建时间与更新时间等重要的信息，还有一个比较重要的内容就是指向数据块的指针。一般情况不需要特殊配置，如果存放文件很多，则需要配置。有时磁盘空间有剩余但是不能存放文件，可能是由于 inode 耗尽所致。
执行df -i命令，可以查询 inode 的使用情况。 如果 inode 使用率达到或者接近 100%，可以通过以下两种方式进行处理： 清除 inode 占用高的文件或者目录。 修改 inode 数量。 清除 inode 占用高的文件或者目录</description></item><item><title>Internationalization</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Time-and-Language/Internationalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Time-and-Language/Internationalization/</guid><description>概述 参考：
Wiki, Internationalization_and_localization Internationalization(国际化，简称 i18n) 和 Localization(本地化，简称 L10n) 是使计算机软件适应不同语言、区域特性和目标语言环境的技术要求的方法。
操作系统中的 locale 功能和相关的环境设置是由底层的系统库和支持多语言的软件包共同控制和提供的。在 Linux 系统中，主要是通过 glibc（GNU C Library）这一核心库来实现对多语言和地区的支持。glibc 提供了对 i18n 和 L10n 的支持，包括对不同语言环境的文本处理、字符编码转换等功能。
Debian 系
由 libc-bin 和 systemd 管理 ~]# dpkg-query -S /usr/bin/locale libc-bin: /usr/bin/locale ~]# dpkg-query -S /usr/bin/localectl systemd: /usr/bin/localectl RedHat 系
由 glibc-common 和 systemd 管理 ~]# rpm -qf /usr/bin/locale glibc-common-2.28-36.oe1.x86_64 ~]# rpm -qf /usr/bin/localectl systemd-243-18.oe1.x86_64 此外，还有一些辅助工具和软件包负责生成和管理具体的locale数据，比如：
localedata: 这是包含特定于区域信息的数据文件，如日期和时间格式、数字和货币表示方式等，通常随glibc一起提供。 localedef: 一个用于从.po（gettext翻译项目文件）文件创建或更新locale定义的工具，也是glibc的一部分。 gettext: 这是一个广泛使用的国际化的库，帮助程序实现多语言支持。它允许程序使用翻译过的字符串，并且维护了一个翻译消息的数据库。 在系统层面，管理locale设置的还包括系统配置文件（如 /etc/default/locale或/etc/locale.conf）以及一些系统管理命令，如locale-gen用于生成指定的locale，update-locale用于更新系统的locale设置。
因此，locale功能不是由单一的包控制，而是涉及系统库、命令行工具、系统配置文件及一系列相互协作的组件共同作用的结果。
关联文件与配置 Debian 系</description></item><item><title>IP Header</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/IP-Header/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/IP-Header/</guid><description>概述 参考：
RFC 791，3.1.Internet Header Format IPv4 数据报被封装在链路层的 Frame 中
IPv4 数据报首部共 14 个字段，其中 13 个是必须的，第 14 个是可选的。前 13 个字段长度固定为 20 Bytes，即 160 bit；第 14 个字段长度在 0 ~ 40 Bytes 之间。
对照 WireShark 中展示的内容看，排除 [] 中的内容，每一行就是首部中的一个字段
Version(版本) # IP 协议的版本号。IPv4 其版本号为 4，因此在这个字段上的值为“6”。 Internet Header Length(首部长度，简称 IHL) # 由于 Options 字段的长度是可变的。所以 IPv4 的首部长度也是可变的。该字段的值在 5 ~ 15 之间(该字段只有 4 bits，1111 即为 15) 首部长度的计算方式如下：IHL * 32 bits。 若 IHL 的值为 5，也就是说 Options 字段为 0，那么 IPv4 首部长度就是 5 * 32 bits = 160 bits = 20 Bytes 就像上面的 IPv4 的 Datagram 结构图一样，每行都是 32 bit，不算 Options 字段和 Payload，那么刚好是 5 行。 Differentiated Services Field # 差异化的服务字段，基本没啥用。。。。o(╯□╰)o Differentiated Services Code Point # 最初定义为 Type Of Service(服务类型，简称 TOS)， Explicit Congestion Notification # 该字段定义在 RFC3168 中， Total Length # 定义了整个 IP 数据报的大小，最小为 20 字节(Payload 字段无内容)，最大为 65535 字节。 Identification# 主要用于唯一标识单个 IP 数据报的片段组。 一些实验工作建议将 ID 字段用于其他目的，例如添加数据包跟踪信息以帮助跟踪具有欺骗源地址的数据报，[31] 但 RFC 6864 现在禁止任何此类使用。 Flags # 用来控制或识别 IP 分片之后的每个片段，这 3 个 bit 分别表示不同的含义，若字段值为 0 表示未设置，值为 1 表示设置，类似 TCP 首部中 Flags 字段的用法。 第一个 # Reserved，保留字段，必须为 0 第二个 # Don&amp;rsquo;t Fragment(DF) 第三个 # More Fragment(MF) Fragment Offset(分片偏移) # IP 分片之后的偏移量 Time To Live(存活时间，简称 TTL) # 其实用 Hop Limit 的描述更准确，封包每经过一个路由器，就会将 TTL 字段的值减 1，减到 0 是，该包将会被丢弃。 Protocol# 封装 IP 数据报的上层协议，比如 6 表示 TCP、1 表示 ICMP 每种协议根据 RFC 1700 都分配了一个固定的编号，该 RFC 1700 最终被 RFC 3232 废弃，并将协议编号的维护工作，转到IANA 的在线数据库中 Header Checksum # 当数据包到达路由器时，路由器会计算标头的校验和，并将其与校验和字段进行比较。如果值不匹配，则路由器会丢弃该数据包。 Source Address(源地址) # 发送端 IP 地址。 Destination Address(目标地址) # 接收端 IP 地址。 Options(选项) # 可变长度，0-40 Bytes。 TTL Time To Live(存活时间，简称 TTL)。这个生存时间是由源主机设置（IP 头里有一个 TTL 域）初始值但不是存的具体时间，而是存储了一个 IP 数据报可以经过最大路由数，每经过一个处理它的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。</description></item><item><title>iperf 网络性能测量和调整工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/iperf-%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E6%B5%8B%E9%87%8F%E5%92%8C%E8%B0%83%E6%95%B4%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/iperf-%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E6%B5%8B%E9%87%8F%E5%92%8C%E8%B0%83%E6%95%B4%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官网 在 server 端监听某个端口，然后 client 用同样的 iperf 访问服务端，来进行性能测试
所以该工具需要在两台设备之间一同使用，其中一台作为服务端，另外一台作为客户端，两端互相通信，才可测试网络性能。而命令行的 OPTIONS 也是分为全局、服务端特定、客户端特定 这三类
Syntax(语法) iperf3 &amp;lt;-s | -c HOST&amp;gt; [OPTIONS]
通用选项
-p, &amp;ndash;port # 指定服务端监听的端口或者客户端要连接的端口 -f, &amp;ndash;format [kmgKMG] # 指定输出格式。可以是：Kbits, Mbits, KBytes, MBytes -i, &amp;ndash;interval # 指定每次带宽报告间隔的秒数。i.e.每隔几秒输出一次数据。默认每 1 秒报告一次 -F, &amp;ndash;file name # xmit/recv the specified file -A, &amp;ndash;affinity n/n,m # set CPU affinity -B, &amp;ndash;bind &amp;lt;host&amp;gt; # bind to a specific interface -V, &amp;ndash;verbose # more detailed output -J, &amp;ndash;json # output in JSON format &amp;ndash;logfile f # send output to a log file &amp;ndash;forceflush # force flushing output at every interval -d, &amp;ndash;debug # emit debugging output 服务端的特定选项</description></item><item><title>Job control</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/Job-control/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/Job-control/</guid><description>概述 参考：
Manual(手册)，Bash(1) - JOB_CONTROL Job control(作业控制) 是指有选择的停止/挂起进程的执行，并在稍后继续/恢复它们的执行能力。我们一般都是在 Shell 中使用此功能的，比如 Bash。
在前台执行的程序为前台 JOB，前台程序占用一个 shell，执行该程序后，shell 无法再进行别的操作
在后台执行的程序为后台 JOB，后台程序不占用 shell，可以在该 shell 下继续执行其余任务，不受 ctrl+c 的影响
常见操作：
ctrl+z # 在正在运行的 porcess 中使用这个组合键，可以让前台进程暂停 fg %JobNumber # 让后台的进程在前台工作 bg %JobNumber # 让前台的工作在后台工作 nohup COMMAND # 让命令触发的进程不随 shell 关闭而停止 COMMAND &amp;amp; # 让命令触发的进程直接在后台运行 jobs 命令 Syntax(语法) 查看 jobs
jobs [OPTIONS]
OPTIONS：
-l # 查看 jobs 的详细信息</description></item><item><title>Journaling File System</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/Journaling-File-System/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/Journaling-File-System/</guid><description>概述 参考：
Wiki, Journaling file system 背景 File System(文件系统) 要解决的一个关键问题是怎样防止掉电或系统崩溃造成数据损坏，在此类意外事件中，导致文件系统损坏的根本原因在于写文件不是原子操作，因为写文件涉及的不仅仅是用户数据，还涉及 metadata(元数据) 包括 Superblock、inode bitmap、inode、data block bitmap 等，所以写操作无法一步完成，如果其中任何一个步骤被打断，就会造成数据的不一致或损坏。
举一个简化的例子，我们对一个文件进行写操作，要涉及以下步骤：
从 data block bitmap 中分配一个数据块； 在 inode 中添加指向数据块的指针； 把用户数据写入数据块。 如果 步骤 2 完成了，3 未完成。结果是数据损坏，因为该文件认为数据块是自己的，但里面的数据其实是垃圾； 如果 步骤 2 完成了，1 未完成。结果是元数据不一致，因为该文件已经把数据块据为己有，然而文件系统却还认为该数据块未分配、随后又可能会把该数据块分配给别的文件、造成数据覆盖； 如果 步骤 1 完成了、2 未完成。结果就是文件系统分配了一个数据块，但是没有任何文件用到这个数据块，造成空间浪费； 如果 步骤 3 完成了，2 未完成。结果就是用户数据写入了硬盘数据块中，但白写了，因为文件不知道这个数据块是自己的。 Journaling File System 原理 ext3、ext4、xfs 等都是一种 Journaling File System(日志文件系统)
Journaling File System(日志文件系统) 就是为解决上述问题而诞生的。
它的原理是在进行写操作之前，把即将进行的各个步骤（称为 transaction）事先记录下来，保存在文件系统上单独开辟的一块空间上，这就是所谓的日志(journal)，也被称为 Write-ahead logging，日志保存成功之后才进行真正的写操作、把文件系统的元数据和用户数据写进硬盘（称为 checkpoint），这样万一写操作的过程中掉电，下次挂载文件系统之前把保存好的日志重新执行一遍就行了（术语叫做 replay），避免了前述的数据损坏场景。
有人问如果保存日志的过程中掉电怎么办？最初始的想法是把一条日志的数据一次性写入硬盘，相当于一个原子操作，然而这并不可行，因为硬盘通常以 512 字节为单位进行操作，日志数据一超过 512 字节就不可能一次性写入了。所以实际上是这么做的：给每一条日志设置一个结束符，只有在日志写入成功之后才写结束符，如果一条日志没有对应的结束符就会被视为无效日志，直接丢弃，这样就保证了日志里的数据是完整的。</description></item><item><title>jq</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/jq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/jq/</guid><description>概述 参考：
官方文档 jq 是轻量级且灵活的处理 JSON 数据的 Shell 命令行工具
这里是官方提供的 jq 命令在线测试工具，提供原始 JSON 内容，会自动根据 表达式 输出结果。
jq 用法详解 官方文档：https://stedolan.github.io/jq/manual/
jq 程序是一个过滤器，接收一个输入，并产生一个输出。
基础过滤 官方文档：https://stedolan.github.io/jq/manual/#Basicfilters
下面的 jq 用法，都是用下面这个 json 文件作为演示
{&amp;#34;favorite&amp;#34;:{&amp;#34;drink&amp;#34;:&amp;#34;water&amp;#34;,&amp;#34;food&amp;#34;:&amp;#34;sushi&amp;#34;,&amp;#34;game&amp;#34;:&amp;#34;WOW &amp;amp; PAL&amp;#34;},&amp;#34;sushiKinds&amp;#34;:[&amp;#34;sashimi&amp;#34;,{&amp;#34;name&amp;#34;:&amp;#34;hot&amp;#34;},{&amp;#34;name&amp;#34;:&amp;#34;handRoll&amp;#34;,&amp;#34;rice&amp;#34;:&amp;#34;more&amp;#34;},{&amp;#34;name&amp;#34;:null}],&amp;#34;arrayBrowser&amp;#34;:[{&amp;#34;name&amp;#34;:&amp;#34;360&amp;#34;,&amp;#34;url&amp;#34;:&amp;#34;http://www.so.com&amp;#34;},{&amp;#34;name&amp;#34;:&amp;#34;bing&amp;#34;,&amp;#34;url&amp;#34;:&amp;#34;http://www.bing.com&amp;#34;}]} 格式化后的内容如下，格式化内容仅作参考对照，因为 jq 命令本身就可以实现格式化的 json 的作用。
{ &amp;#34;favorite&amp;#34;: { &amp;#34;drink&amp;#34;: &amp;#34;water&amp;#34;, &amp;#34;food&amp;#34;: &amp;#34;sushi&amp;#34;, &amp;#34;game&amp;#34;: &amp;#34;WOW &amp;amp; PAL&amp;#34; }, &amp;#34;sushiKinds&amp;#34;: [ &amp;#34;sashimi&amp;#34;, { &amp;#34;name&amp;#34;: &amp;#34;hot&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;handRoll&amp;#34;, &amp;#34;rice&amp;#34;: &amp;#34;more&amp;#34; }, { &amp;#34;name&amp;#34;: null } ], &amp;#34;arrayBrowser&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;360&amp;#34;, &amp;#34;url&amp;#34;: &amp;#34;http://www.</description></item><item><title>K3S 备份与恢复</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</guid><description>概述 参考：
公众号-边缘计算k3s社区，容器化应用的救命稻草：深入探索 K3s 备份和恢复 使用嵌入式 etcd 数据存储进行备份和恢复 创建快照 默认情况下，K3s 会在 00:00 和 12:00 自动创建快照，并保留 5 个快照。当然，你也可以禁用自动快照或者通过 k3s etcd-snapshot save 来手动创建快照。
快照目录默认为 ${data-dir}/server/db/snapshots。data-dir 的默认值为 /var/lib/rancher/k3s，你可以通过设置 --data-dir 标志来更改。
从快照恢复集群 当 K3s 从备份中恢复时，旧的数据目录将被移动到 ${data-dir}/server/db/etcd-old/。然后 K3s 将尝试通过创建一个新的数据目录来恢复快照，最后使用具有一个 etcd 成员的新 K3s 集群启动 etcd。
在此示例中有 3 个 K3s Server 节点，分别是 S1、S2和 S3，快照位于 S1 上:
在 S1 上，使用 --cluster-reset 选项运行 K3s，同时指定 --cluster-reset-restore-path： ls /var/lib/rancher/k3s/server/db/snapshots/ on-demand-ip-172-31-3-36-1688025329 systemctl stop k3s k3s server \ --cluster-reset \ --cluster-reset-restore-path=/var/lib/rancher/k3s/server/db/snapshots/on-demand-ip-172-31-3-36-1688025329 在 S2 和 S3 上，停止 K3s。然后删除数据目录 /var/lib/rancher/k3s/server/db/： systemctl stop k3s rm -rf /var/lib/rancher/k3s/server/db/ 在 S1 上，再次启动 K3s： systemctl start k3s S1 启动成功后，在 S2 和 S3 上，再次启动 K3s 以加入恢复后的集群： systemctl start k3s S2 和 S3 虽然使用空的数据目录来启动 K3s 服务，但启动时会自动到 S1 去同步数据，从而完成 S2 和 S3 的恢复。</description></item><item><title>K3S 管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
官方文档，高级选项和配置 使用 etcdctl sudo etcdctl \ --cacert=/var/lib/rancher/k3s/server/tls/etcd/server-ca.crt \ --cert=/var/lib/rancher/k3s/server/tls/etcd/client.crt \ --key=/var/lib/rancher/k3s/server/tls/etcd/client.key \ --endpoint=A,B,C \ member list 更换 Master 节点 K3S 可以快速更换所有 Master 节点的系统，只需要剔除一个新增一个，逐一替换即可。就算没有 k3s server --cluster-init 这种命令的节点也是可以的。
其他推荐 关于旧版 iptables 建议关闭 firewalld</description></item><item><title>k8s CPU limit和throttling的迷思</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/k8s-CPU-limit%E5%92%8Cthrottling%E7%9A%84%E8%BF%B7%E6%80%9D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/k8s-CPU-limit%E5%92%8Cthrottling%E7%9A%84%E8%BF%B7%E6%80%9D/</guid><description>概述 参考：
原文链接： https://nanmu.me/zh-cn/posts/2021/myth-of-k8s-cpu-limit-and-throttle/ https://mp.weixin.qq.com/s/QYJycJCaxB42xdEo3qHHHA 你应当小心设定 k8s 中负载的 CPU limit，太小的值会给你的程序带来额外的、无意义的延迟，太大的值会带来过大的爆炸半径，削弱集群的整体稳定性。
request 和 limit k8s 的一大好处就是资源隔离，通过设定负载的 request 和 limit，我们可以方便地让不同程序共存于合适的节点上。
其中，request 是给调度看的，调度会确保节点上所有负载的 CPU request 合计与内存 request 合计分别都不大于节点本身能够提供的 CPU 和内存，limit 是给节点（kubelet）看的，节点会保证负载在节点上只使用这么多 CPU 和内存。例如，下面配置意味着单个负载会调度到一个剩余 CPU request 大于 0.1 核，剩余 request 内存大于 200MB 的节点，并且负载运行时的 CPU 使用率不能高于 0.4 核（超过将被限流），内存使用不多余 300MB（超过将被 OOM Kill 并重启）。
resources: requests: memory: 200Mi cpu: &amp;quot;0.1&amp;quot; limits: memory: 300Mi cpu: &amp;quot;0.4&amp;quot;
CPU 的利用率 CPU 和内存不一样，它是量子化的，只有“使用中”和“空闲”两个状态。
我和老婆聊了聊 CPU 和内存的不同，她帮我画了一张插图 图/我的妻子
当我们说内存的使用率是 60%时，我们是在说内存有 60%在空间上已被使用，还有 40%的空间可以放入负载。但是，当我们说 CPU 的某个核的使用率是 60%时，我们是在说采样时间段内，CPU 的这个核在时间上有 60%的时间在忙，40%的时间在睡大觉。</description></item><item><title>Kafka</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/</guid><description>概述 参考：
官网 Kafka 的 Consumer 在消费数据时，并不是把数据拿走，而是从队列里拿走一个副本。
可以配置队列保存数据的 最大时间、占用容量、etc. 。
每次执行 kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my_topic --from-beginning --property print.offset=true --max-messages 2 这类命令，都会创建一个临时的 Consumer，从头开始消费数据，输出的结果就是已消费的数据。
Kafka 原理详解 原文: https://mp.weixin.qq.com/s/Y0jYbDhs5ARbDbkrnA7Rjg
Kafka 是什么？ Kafka 是 Apache 旗下的一款分布式流媒体平台，Kafka 是一种高吞吐量、持久性、分布式的发布订阅的消息队列系统。它最初由 LinkedIn(领英)公司发布，使用 Scala 语言编写，与 2010 年 12 月份开源，成为 Apache 的顶级子项目。它主要用于处理消费者规模网站中的所有动作流数据。动作指(网页浏览、搜索和其它用户行动所产生的数据)。
消息系统分类 我们知道常见的消息系统有 Kafka、RabbitMQ、ActiveMQ 等等，但是这些消息系统中所使用的消息模式如下两种：
Peer-to-Peer (Queue) 简称 PTP 队列模式，也可以理解为点到点。例如单发邮件，我发送一封邮件给小徐，我发送过之后邮件会保存在服务器的云端，当小徐打开邮件客户端并且成功连接云端服务器后，可以自动接收邮件或者手动接收邮件到本地，当服务器云端的邮件被小徐消费过之后，云端就不再存储(这根据邮件服务器的配置方式而定)。
名词解释：
Producer=生产者
Queue=队列
Consumer=消费者
Peer-to-Peer 模式工作原理：
消息生产者 Producer1 生产消息到 Queue，然后 Consumer1 从 Queue 中取出并且消费消息。 消息被消费后，Queue 将不再存储消息，其它所有 Consumer 不可能消费到已经被其它 Consumer 消费过的消息。 Queue 支持存在多个 Producer，但是对一条消息而言，只会有一个 Consumer 可以消费，其它 Consumer 则不能再次消费。 但 Consumer 不存在时，消息则由 Queue 一直保存，直到有 Consumer 把它消费。 Publish/Subscribe（Topic） 简称发布/订阅模式。例如我微博有 30 万粉丝，我今天更新了一条微博，那么这 30 万粉丝都可以接收到我的微博更新，大家都可以消费我的消息。</description></item><item><title>Keypoint detection</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Keypoint-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Keypoint-detection/</guid><description>概述 参考：
https://blog.roboflow.com/what-is-keypoint-detection/ Keypoint detection(关键点监测) 可用来进行 Pose estimation 和 Facial recognition(面部识别)
Notes: 某些可以利用 Keypoint detection 实现的任务，并不止局限于这一种。还有可能有其他方式实现，比如面部识别不一定需要依赖关键点监测。</description></item><item><title>kube-apiserver 的设计与实现</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/API-Server/kube-apiserver-%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/API-Server/kube-apiserver-%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/</guid><description>概述 参考：
kube-apiserver 的设计与实现 · 田飞雨 公众号,API Server service 的实现 kube-apiserver 是 kubernetes 中与 etcd 直接交互的一个组件，其控制着 kubernetes 中核心资源的变化。它主要提供了以下几个功能：
提供 Kubernetes API，包括认证授权、数据校验以及集群状态变更等，供客户端及其他组件调用； 代理集群中的一些附加组件组件，如 Kubernetes UI、metrics-server、npd 等； 创建 kubernetes 服务，即提供 apiserver 的 Service，kubernetes Service； 资源在不同版本之间的转换； kube-apiserver 处理流程 kube-apiserver 主要通过对外提供 API 的方式与其他组件进行交互，可以调用 kube-apiserver 的接口 $ curl -k https://&amp;lt;masterIP&amp;gt;:6443或者通过其提供的 swagger-ui 获取到，其主要有以下三种 API：
core group：主要在 /api/v1 下； named groups：其 path 为 /apis/$NAME/$VERSION； 暴露系统状态的一些 API：如/metrics 、/healthz 等； API 的 URL 大致以 /apis/group/version/namespaces/my-ns/myresource 组成，其中 API 的结构大致如下图所示：
了解了 kube-apiserver 的 API 后，下面会介绍 kube-apiserver 如何处理一个 API 请求，一个请求完整的流程如下图所示：</description></item><item><title>kube-scheduler 实现调度器的程序</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/kube-scheduler-%E5%AE%9E%E7%8E%B0%E8%B0%83%E5%BA%A6%E5%99%A8%E7%9A%84%E7%A8%8B%E5%BA%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/kube-scheduler-%E5%AE%9E%E7%8E%B0%E8%B0%83%E5%BA%A6%E5%99%A8%E7%9A%84%E7%A8%8B%E5%BA%8F/</guid><description>概述 参考：
kube-scheduler 是实现 kuberntes Scheduler 的应用程序
kube-scheduler 启动后监听两个端口：
10251 端口为无需身份验证和授权即可不安全地为 HTTP 服务的端口。(1.18 版本后将要弃用) 10259 端口为需要身份验证和授权为 HTTPS 服务的端口。 kube-scheduler 高科用 与 [kube-controller-manager 高可用](/docs/10.云原生/2.3.Kubernetes%20 容器编排系统/4.Controller(控制器)/kube-controller-manager%20 实现控制器的程序.md 实现控制器的程序.md) 原理相同。
kube-scheduler 监控指标 详见：[kubernetes 监控](/docs/10.云原生/2.3.Kubernetes%20 容器编排系统/Kubernetes%20 管理/Kubernetes%20 监控/Kubernetes%20 系统组件指标.md 管理/Kubernetes 监控/Kubernetes 系统组件指标.md)
Kube-scheduler 参数详解 参考：
官方文档，参考-组件工具-kube-scheduler 默认的 manifest 示例 apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: component: kube-scheduler tier: control-plane name: kube-scheduler namespace: kube-system spec: containers: - command: - kube-scheduler - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf - --authorization-kubeconfig=/etc/kubernetes/scheduler.</description></item><item><title>kube-state-metrics</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/kube-state-metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/kube-state-metrics/</guid><description>概述 参考：
GitHub 项目，kubernetes/kube-stsate-metrics GitHub 文档，可暴露的所有指标列表 http://www.xuyasong.com/?p=1525 已经有了 cadvisor、Metric Server，几乎容器运行的所有指标都能拿到，但是下面这种情况却无能为力：
我调度了多少个 replicas？现在可用的有几个？ 多少个 Pod 是 running/stopped/terminated 状态？ Pod 重启了多少次？ 我有多少 job 在运行中 而这些则是 kube-state-metrics 提供的内容，它基于 client-go 开发，轮询 Kubernetes API，并将 Kubernetes 的结构化信息转换为 Metrics。
kube-state-metrics 提供的指标，按照阶段分为三种类别：
1.实验性质的：k8s api 中 alpha 阶段的或者 spec 的字段。 2.稳定版本的：k8s 中不向后兼容的主要版本的更新 3.被废弃的：已经不在维护的。 指标类别包括：
CertificateSigningRequest Metrics ConfigMap Metrics CronJob Metrics DaemonSet Metrics Deployment Metrics Endpoint Metrics Horizontal Pod Autoscaler Metrics Ingress Metrics Job Metrics Lease Metrics LimitRange Metrics MutatingWebhookConfiguration Metrics Namespace Metrics NetworkPolicy Metrics Node Metrics PersistentVolume Metrics PersistentVolumeClaim Metrics Pod Disruption Budget Metrics Pod Metrics ReplicaSet Metrics ReplicationController Metrics ResourceQuota Metrics Secret Metrics Service Metrics StatefulSet Metrics StorageClass Metrics ValidatingWebhookConfiguration Metrics VerticalPodAutoscaler Metrics VolumeAttachment Metrics 可以通过 prometheus 配置 scrape 的 target 为 kube-state-metrics ，将数据持久保存起来。</description></item><item><title>kube-vip</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/kube-vip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/kube-vip/</guid><description>概述 参考：
GitHub 项目，kube-vip/kube-vip 官网 官方文档，使用静态 Pod 部署 kube-vip kube-vip 是一个用于 Kubernetes 控制平面的 VIP 和 负载均衡器。他可以实现 Keepalived + HAProxy 的功能。
Kube-VIP 最初是为 Kubernetes 控制平面提供 HA 解决方案而创建的，随着时间的推移，它已经发展为将相同的功能合并到 Kubernetes 的 load-banlancers 类型的 Service 资源。
配置 Kube-VIP 通过命令行标志变更运行时行为
部署 作为静态 Pod 运行 生成 Manifests
export VIP=172.38.180.213 export INTERFACE=eth0 export KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r &amp;#34;.[0].name&amp;#34;) docker run --rm --net host docker.io/plndr/kube-vip:${KVVERSION} \ /kube-vip manifest pod \ --interface ${INTERFACE} \ --vip ${VIP} \ --controlplane \ --services \ --arp \ --leaderElection | tee /etc/kubernetes/manifests/kube-vip.</description></item><item><title>Kubeadm</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubeadm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubeadm/</guid><description>概述 参考：
kubeadm 源码在 Kubernetes 中，位置：kubernetes/kubernetes/cmd/kubeadm，本文以 1.19 版本为例
目录结构 $ tree -L 4 -d . ├── app │ ├── apis │ │ ├── kubeadm │ │ │ ├── fuzzer │ │ │ ├── scheme │ │ │ ├── v1beta1 │ │ │ ├── v1beta2 │ │ │ └── validation │ │ └── output │ │ ├── fuzzer │ │ ├── scheme │ │ └── v1alpha1 │ ├── cmd │ │ ├── alpha │ │ ├── options │ │ ├── phases │ │ │ ├── init │ │ │ ├── join │ │ │ ├── reset │ │ │ ├── upgrade │ │ │ │ └── node │ │ │ └── workflow │ │ ├── upgrade │ │ └── util │ ├── componentconfigs │ ├── constants │ ├── discovery │ │ ├── file │ │ ├── https │ │ └── token │ ├── features │ ├── images │ ├── phases │ │ ├── addons │ │ │ ├── dns │ │ │ └── proxy │ │ ├── bootstraptoken │ │ │ ├── clusterinfo │ │ │ └── node │ │ ├── certs │ │ │ └── renewal │ │ ├── controlplane │ │ ├── copycerts │ │ ├── etcd │ │ ├── kubeconfig │ │ ├── kubelet │ │ ├── markcontrolplane │ │ ├── patchnode │ │ ├── selfhosting │ │ ├── upgrade │ │ └── uploadconfig │ ├── preflight │ └── util │ ├── apiclient │ ├── audit │ ├── certs │ ├── config │ │ └── strict │ │ └── testdata │ ├── crypto │ ├── dryrun │ ├── etcd │ ├── image │ ├── initsystem │ ├── kubeconfig │ ├── kustomize │ ├── output │ ├── patches │ ├── pkiutil │ ├── pubkeypin │ ├── runtime │ └── staticpod └── test ├── cmd │ └── testdata │ └── init ├── kubeconfig └── resources kubeadm 是基于 cobra 框架的命令行工具，入口是 cmd/kubeadm/kubeadm.</description></item><item><title>Kubebuilder</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/Kubebuilder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/Kubebuilder/</guid><description>概述 参考：
Kubebuilder 代码示例详见 GitHub 上我的 kubernetesAPI 仓库
kubebuilder 命令行工具 用于构建 Kubernetes 扩展和工具的开发工具包。 提供用于创建新项目，API 和控制器的库和工具。 包括用于将工件打包到安装程序容器中的工具。
典型的项目生命周期：
初始化项目：
kubebuilder init &amp;ndash;domain example.com &amp;ndash;license apache2 &amp;ndash;owner &amp;ldquo;The Kubernetes authors&amp;rdquo; 创建一个或多个新资源 API 并将代码添加到其中：
kubebuilder create api &amp;ndash;group &amp;lt;group&amp;gt; &amp;ndash;version &amp;lt;version&amp;gt; &amp;ndash;kind &amp;lt;Kind&amp;gt; Create resource will prompt the user for if it should scaffold the Resource and / or Controller. To only scaffold a Controller for an existing Resource, select &amp;ldquo;n&amp;rdquo; for Resource. To only define the schema for a Resource without writing a Controller, select &amp;ldquo;n&amp;rdquo; for Controller.</description></item><item><title>kubernetes 环境开启 bridge-nf-call-iptables</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubernetes-%E7%8E%AF%E5%A2%83%E5%BC%80%E5%90%AF-bridge-nf-call-iptables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubernetes-%E7%8E%AF%E5%A2%83%E5%BC%80%E5%90%AF-bridge-nf-call-iptables/</guid><description>概述 参考：
原文,公众号,为什么 kubernetes 环境要求开启 bridge-nf-call-iptables ? 背景 Kubernetes 环境中，很多时候都要求节点内核参数开启 bridge-nf-call-iptables:
sysctl -w net.bridge.bridge-nf-call-iptables=1 参考官方文档 Network Plugin Requirements
如果不开启或中途因某些操作导致参数被关闭了，就可能造成一些奇奇怪怪的网络问题，排查起来非常麻烦。
为什么要开启呢？本文就来跟你详细掰扯下。
基于网桥的容器网络 Kubernetes 集群网络有很多种实现，有很大一部分都用到了 Linux 网桥:
每个 Pod 的网卡都是 veth 设备，veth pair 的另一端连上宿主机上的网桥。 由于网桥是虚拟的二层设备，同节点的 Pod 之间通信直接走二层转发，跨节点通信才会经过宿主机 eth0。 Service 同节点通信问题 不管是 iptables 还是 ipvs 转发模式，Kubernetes 中访问 Service 都会进行 DNAT，将原本访问 ClusterIP:Port 的数据包 DNAT 成 Service 的某个 Endpoint (PodIP:Port)，然后内核将连接信息插入 conntrack 表以记录连接，目的端回包的时候内核从 conntrack 表匹配连接并反向 NAT，这样原路返回形成一个完整的连接链路:
但是 Linux 网桥是一个虚拟的二层转发设备，而 iptables conntrack 是在三层上，所以如果直接访问同一网桥内的地址，就会直接走二层转发，不经过 conntrack:
Pod 访问 Service，目的 IP 是 Cluster IP，不是网桥内的地址，走三层转发，会被 DNAT 成 PodIP:Port。 如果 DNAT 后是转发到了同节点上的 Pod，目的 Pod 回包时发现目的 IP 在同一网桥上，就直接走二层转发了，没有调用 conntrack，导致回包时没有原路返回 (见下图)。 由于没有原路返回，客户端与服务端的通信就不在一个 &amp;ldquo;频道&amp;rdquo; 上，不认为处在同一个连接，也就无法正常通信。</description></item><item><title>Kubernetes 扩展</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Kubernetes-%E6%89%A9%E5%B1%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Kubernetes-%E6%89%A9%E5%B1%95/</guid><description>概述 参考：
官方文档，概念 - 扩展 Kubernetes - 扩展集群 概念： 任务：https://kubernetes.io/docs/tasks/extend-kubernetes/ 这里引用张磊大佬的一张图来开篇
Kubernetes 是高度可配置和可扩展的。因此，极少需要分发或提交补丁代码给 Kubernetes 项目。通过对 Kubernetes 的扩展，可以将中间狭窄的部分扩大。
本文档介绍自定义 Kubernetes 集群的方式。本文档的目标读者包括希望了解如何使 Kubernetes 集群满足其业务环境需求的 集群运维人员、 Kubernetes 项目的贡献者。 或潜在的平台开发人员 也可以从本文找到有用的信息，如对已存在扩展点和模式的介绍，以及它们的权衡和限制。
自定义方法可以大致分为两类
Configuration (配置) # 配置只涉及更改标志参数、本地配置文件或 API 资源； Extension (扩展) # 扩展涉及运行额外的程序或服务。 扩展的实现依赖于某些特殊配置，这些配置可能在某些 k8s 发行版中并不自带。需要自行修改程序参数来让集群支撑某些扩展方式。
配置 Kubernetes 集群 关于 配置文件 和 标志 的说明文档位于在线文档的&amp;quot;参考&amp;quot;部分，按照可执行文件组织：
kubelet kube-apiserver kube-controller-manager kube-scheduler. 在托管的 Kubernetes 服务或受控安装的 Kubernetes 版本中，标志和配置文件可能并不总是可以更改的。而且当它们可以进行更改时，它们通常只能由集群管理员进行更改。此外，标志和配置文件在未来的 Kubernetes 版本中可能会发生变化，并且更改设置后它们可能需要重新启动进程。出于这些原因，只有在没有其他选择的情况下才使用它们。
内置策略 API ，例如 ResourceQuota、 PodSecurityPolicy、 NetworkPolicy 和基于角色的权限控制 (RBAC)， 是内置的 Kubernetes API。API 通常与托管的 Kubernetes 服务和受控的 Kubernetes 安装一起使用。 它们是声明性的，并使用与其他 Kubernetes 资源（如 Pod ）相同的约定，所以新的集群配置可以重复使用， 并以与应用程序相同的方式进行管理。 而且，当它们变稳定后，也遵循和其他 Kubernetes API 一样的 支持政策。 出于这些原因，在合适的情况下它们优先于 配置文件 和 标志 被使用。</description></item><item><title>Kubernetes 系统组件指标</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/Kubernetes-%E7%B3%BB%E7%BB%9F%E7%BB%84%E4%BB%B6%E6%8C%87%E6%A0%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/Kubernetes-%E7%B3%BB%E7%BB%9F%E7%BB%84%E4%BB%B6%E6%8C%87%E6%A0%87/</guid><description>概述 参考：
官方文档 Kubernetes 系统组件以 Prometheus 格式暴露监控所需的指标。这种格式是结构化的纯文本，人类和机器都可以很方便得阅读。
Kubernetes 的下面几个系统组件默认都会在 /metrics 端点暴露指标信息：
kubelet kubelet 除了基本 /metrics 端点还会在 /metrics/cadvisor、/metrics/resource、/metrics/probes 这几个端点暴露指标 kube-apiserver kube-controller-manager kube-scheduler kube-proxy 想要采集这些组件的指标，通常需要 Prometheus 或类似的程序，配置抓取程序，以便定期收集，并将指标存储在时间序列数据库中。
访问 https 前准备，获取认证所需信息 与[访问 API Server 的 HTTPS](API%20Server.md Server.md) 的方式一样
方法一：使用 kubectl 的配置文件中的证书与私钥 想要访问 https 下的内容，首先需要准备证书与私钥或者 ca 与 token 等等。
首先获取 kubeclt 工具配置文件中的证书与私钥 cat /etc/kubernetes/admin.conf | grep client-certificate-data | awk &amp;lsquo;{print $2}&amp;rsquo; | base64 -d &amp;gt; /root/certs/admin.crt cat /etc/kubernetes/admin.conf | grep client-key-data | awk &amp;lsquo;{print $2}&amp;rsquo; | base64 -d &amp;gt; /root/certs/admin.</description></item><item><title>Label matchers</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Label-matchers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Label-matchers/</guid><description>概述 参考：
官方文档，告警 - 配置，标签匹配器 Label matchers(标签匹配器) 类似 K8S 中的 Label and Selector(标签和选择器)，是 Prometheus 中常见用以查找数据的功能，与 PromQL 的 XX选择器也有类似的效果。
在 Alertmanager 配置 中可以通过 Label matchers 过滤出想要处理的告警条目；在 Promethesu Server 的配置中也有类似（没有明确指出，比如 .remote_read.required_matchers）的逻辑，尽管有时候语法可能并不相同。</description></item><item><title>Label 与 Relabeling</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Label-%E4%B8%8E-Relabeling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Label-%E4%B8%8E-Relabeling/</guid><description>概述 参考：
Promtail 的 Label 与 Relabeling 功能与 Prometheus 中的 Relabeling(重新标记) 概念一样。
Promtail 具有一个嵌入式 Web 服务器，可以通过配置文件的 server 字段配置监听的端口，默认监听 80 端口
这个 Web 页面与 Prometheus 的页面基本一样，只不过更简单，只有 Service Dicovery 和 Targets 两个页面。
也确实只要两个页面就够了，在 Loki 套件中，Promtail 就是用来 发现目标、重新标记、采集日志、推送日志 的。
在服务发现页面里，也有 Discovered Labels 和 Target Labels 这两个
只不过 Journal 这个目标发现程序命名发现了很多标签，但是却显示不出来，这个比较奇怪</description></item><item><title>Library</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/Library/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/Library/</guid><description>概述 参考：
Wiki, Library(computing) 公众号 - 码农的荒岛求生，动态库和静态库有什么区别？ B 站，动态库和静态库到底有什么区别？ 公众号 - 码农的荒岛求生，动态链接库的实现原理是什么？ B 站，动态链接库的实现原理是什么？ Library(库) 是一个只读资源的集合(collection)，用来实现计算机程序。这个 collection 中通常是很多已经写好的可复用的代码，类似于代码中的 Function。相对代码文件中的 Function、Library 则更像是存在于代码文件外部的 Function，表现一种可执行代码的 Binary(二进制) 文件、纯文本代码文件，甚至随着发展，还可能包括图像。
e.g. 程序可以使用 Library 来间接进行 System Call，而不是直接在程序中编写系统调用的相关代码。
一个 Library 可以被多个独立的使用者（程序、其他 Library）使用以，modular(模块化) 的方式 code reuse(重用代码)。
Static lib 与 Dynamic lib Library 通常分为两大类
Static lib(静态库) # 编译程序时，将 Library 打包进最终的可执行文件 通常可以通过代码中使用 import、etc. 关键字在文件开头导入，各种语言和环境的 Library 形态不太一样。有的语言直接把代码源码放到本地，编译时引用；有的语言会把代码编译成 .a、.lib 文件，在编译时引用；etc. Dynamic lib(动态库) # 程序运行时，将 Library 加载到内存中 通常以文件的形式。Linux 中文件后缀为 .so，Windows 中文件后缀为 .dll。 Linker 参考:</description></item><item><title>link</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ip/link/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ip/link/</guid><description>概述 参考：
Manual(手册)，ip-link(8) 一个 link 代表一个 network device(网络设备)。link 对象及其相应的命令集，可以查看和操纵网络设备(增删改查等)。主要通过其自身的子命令来实现本身的功能。
网络设备配置
Syntax(语法) ip [OPTIONS] link [COMMAND]
COMMAND：
add|delete|set|show # 增|删|改|查 一个虚拟 link xstats # afstats # property # OPTIONS：
-4 # 指定使用的网络层协议是 IPV4 -r # 显示主机时，不使用 IP，而是使用主机的域名 add - 添加网络设备的虚拟链接 Notes: 真实物理网卡对应的网络设备无法通过 ip link add 命令添加
ip link add [link DEVICE] [ name ] NAME [ARGS] type TYPE [ ARGS ]
DEVICE # 要操作的物理设备 NAME # 要操作的设备的名称 ARGS # 这个参数可以设定设备的 IP 地址、网络地址、MTU 等 TYPE # 设备类型 bridge # 以太网网桥设备 bond # Bonding(绑定)设备 dummy # 虚拟网络接口 veth # Virtual ethernet interface(虚拟以太网接口)设备 vlan # 802.</description></item><item><title>Linux Foundation</title><link>https://desistdaydream.github.io/docs/Standard/Foundation/Linux-Foundation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Foundation/Linux-Foundation/</guid><description>概述 参考：
Wiki 官网 官网 Wiki Linux Foundation(Linux 基金会，简称 LF)，是一家非营利性技术贸易协会，致力于促进，保护和推进 Linux 和 协同开发，并支持“历史上最大的共享技术资源”[2]。它开始于 2000 年的开源码发展实验室（OSDL），并与自由标准组织（FSG）合并后从而成为现在的组织。Linux 基金会赞助 Linux 创始人 Linus Torvalds 和主管维护者 Greg Kroah-Hartman 的工作 并由领导 Linux 和开源公司的支持，包括思科，富士通，惠普[3]，IBM，英特尔，微软[4]，NEC，甲骨文，高通和三星[5]等知名的科技公司，以及来自全世界的开发商 。近年来，Linux 基金会通过活动，培训和认证以及开源项目扩大了服务范围。
IO Visor Project 官网：https://www.iovisor.org/</description></item><item><title>Linux 上抽象网络设备的原理及使用</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/Linux-%E4%B8%8A%E6%8A%BD%E8%B1%A1%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/Linux-%E4%B8%8A%E6%8A%BD%E8%B1%A1%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/</guid><description>概述 参考：
Linux 抽象网络设备简介 和磁盘设备类似，Linux 用户想要使用网络功能，不能通过直接操作硬件完成，而需要直接或间接的操作一个 Linux 为我们抽象出来的设备，既通用的 Linux 网络设备来完成。一个常见的情况是，系统里装有一个硬件网卡，Linux 会在系统里为其生成一个网络设备实例，如 eth0，用户需要对 eth0 发出命令以配置或使用它了。更多的硬件会带来更多的设备实例，虚拟的硬件也会带来更多的设备实例。随着网络技术，虚拟化技术的发展，更多的高级网络设备被加入了到了 Linux 中，使得情况变得更加复杂。在以下章节中，将一一分析在虚拟化技术中经常使用的几种 Linux 网络设备抽象类型：Bridge、802.1.q VLAN device、VETH、TAP，详细解释如何用它们配合 Linux 中的 Route table、IP table 简单的创建出本地虚拟网络。
相关网络设备工作原理 Bridge Bridge（桥）是 Linux 上用来做 TCP/IP 二层协议交换的设备，与现实世界中的交换机功能相似。Bridge 设备实例可以和 Linux 上其他网络设备实例连接，既 attach 一个从设备，类似于在现实世界中的交换机和一个用户终端之间连接一根网线。当有数据到达时，Bridge 会根据报文中的 MAC 信息进行广播、转发、丢弃处理。
图 1.Bridge 设备工作过程
如图所示，Bridge 的功能主要在内核里实现。当一个从设备被 attach 到 Bridge 上时，相当于现实世界里交换机的端口被插入了一根连有终端的网线。这时在内核程序里，netdev_rx_handler_register()被调用，一个用于接受数据的回调函数被注册。以后每当这个从设备收到数据时都会调用这个函数可以把数据转发到 Bridge 上。当 Bridge 接收到此数据时，br_handle_frame()被调用，进行一个和现实世界中的交换机类似的处理过程：判断包的类别（广播/单点），查找内部 MAC 端口映射表，定位目标端口号，将数据转发到目标端口或丢弃，自动更新内部 MAC 端口映射表以自我学习。
Bridge 和现实世界中的二层交换机有一个区别，图中左侧画出了这种情况：数据被直接发到 Bridge 上，而不是从一个端口接受。这种情况可以看做 Bridge 自己有一个 MAC 可以主动发送报文，或者说 Bridge 自带了一个隐藏端口和寄主 Linux 系统自动连接，Linux 上的程序可以直接从这个端口向 Bridge 上的其他端口发数据。所以当一个 Bridge 拥有一个网络设备时，如 bridge0 加入了 eth0 时，实际上 bridge0 拥有两个有效 MAC 地址，一个是 bridge0 的，一个是 eth0 的，他们之间可以通讯。由此带来一个有意思的事情是，Bridge 可以设置 IP 地址。通常来说 IP 地址是三层协议的内容，不应该出现在二层设备 Bridge 上。但是 Linux 里 Bridge 是通用网络设备抽象的一种，只要是网络设备就能够设定 IP 地址。当一个 bridge0 拥有 IP 后，Linux 便可以通过路由表或者 IP 表规则在三层定位 bridge0，此时相当于 Linux 拥有了另外一个隐藏的虚拟网卡和 Bridge 的隐藏端口相连，这个网卡就是名为 bridge0 的通用网络设备，IP 可以看成是这个网卡的。当有符合此 IP 的数据到达 bridge0 时，内核协议栈认为收到了一包目标为本机的数据，此时应用程序可以通过 Socket 接收到它。一个更好的对比例子是现实世界中的带路由的交换机设备，它也拥有一个隐藏的 MAC 地址，供设备中的三层协议处理程序和管理程序使用。设备里的三层协议处理程序，对应名为 bridge0 的通用网络设备的三层协议处理程序，即寄主 Linux 系统内核协议栈程序。设备里的管理程序，对应 bridge0 寄主 Linux 系统里的应用程序。</description></item><item><title>LLVM</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/LLVM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/LLVM/</guid><description>概述 参考：
GitHub 项目，llvm/llvm-project Wiki, LLVM LLVM 是一组 Compiler(编译器) 和 工具链技术，可以用于为任何编程语言开发前端（Notes: 不是 Web 开发中的前端），为任何指令集架构开发后端。LLVM 围绕一种与语言无关的中间表示（IR）设计，这种表示作为一种可移植的高级汇编语言，可以通过多次转换进行优化。
[!Tip] 然而，LLVM 项目逐渐演变为一个涵盖多个子项目的综合性项目，这与大多数当前开发者所理解的虚拟机关系不大。这使得该首字母缩略词变得“令人困惑”和“不合适”，因此自2011年以来，LLVM 官方不再是一个缩略词，而是一个适用于 LLVM 综合项目的品牌。该项目包括 LLVM intermediate representation(中间表示，简称 IR)、LLVM 调试器、LLVM 对 C++ 标准库的实现（完全支持 C++ 11 和C++ 14）等。LLVM 由 LLVM 基金会管理。编译工程师 Tanya Lattner 于 2014 年成为其主席。</description></item><item><title>Load Average 平均负载简述</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Load-Average-%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD%E7%AE%80%E8%BF%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Load-Average-%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD%E7%AE%80%E8%BF%B0/</guid><description>概述 参考：
https://blog.csdn.net/u011183653/article/details/19489603 https://blog.csdn.net/slvher/article/details/9199439 Load 与 Load Average LoadAverage = calc_load(TASK_RUNNING + TASK_UNINTERRUPTIBLE,n) Load 是此时此刻 CPU 正在处理的进程数。进程可运行状态时，它处在一个运行队列 run queue 中，与其他可运行进程争夺 CPU 时间。 系统的 load 是指正在运行 running 和准备好运行 runnable 以及 不可中断睡眠 的进程的总数。比如现在系统有 2 个正在运行的进程，3 个可运行进程，那么系统的 load 就是 5
Load Average 为在特定时间间隔内运行队列中(在 CPU 上运行或者等待运行多少进程)的平均进程数。如果一个进程满足以下条件则其就会位于运行队列中：
它没有在等待 I/O 操作的结果 它没有主动进入等待状态(也就是没有调用’wait’) 没有被停止(例如：等待终止) 在 Linux 中，进程分为三种状态，一种是阻塞的进程 blocked process，一种是可运行的进程 runnable process，另外就是正在运行的进程 running process。当进程阻塞时，进程会等待 I/O 设备的数据或者系统调用。
一、查看系统负荷
如果你的电脑很慢，你或许想查看一下，它的工作量是否太大了。
在 Linux 系统中，我们一般使用 uptime 命令查看（w 命令和 top 命令也行）。（另外，它们在苹果公司的 Mac 电脑上也适用。）</description></item><item><title>log 相关模块</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/log-%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/log-%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
org 官方文档，http - ngx_http_log_module org 官方文档，stream - ngx_stream_log_modeule access_log log_format 日志格式示例 { &amp;#34;args&amp;#34;: &amp;#34;$args&amp;#34;, &amp;#34;body_bytes_sent&amp;#34;: &amp;#34;$body_bytes_sent&amp;#34;, &amp;#34;bytes_sent&amp;#34;: &amp;#34;$bytes_sent&amp;#34;, &amp;#34;connection_requests&amp;#34;: &amp;#34;$connection_requests&amp;#34;, &amp;#34;geoip2_city&amp;#34;: &amp;#34;$geoip2_city&amp;#34;, &amp;#34;geoip2_city_country_name&amp;#34;: &amp;#34;$geoip2_city_country_name&amp;#34;, &amp;#34;geoip2_latitude&amp;#34;: &amp;#34;$geoip2_latitude&amp;#34;, &amp;#34;geoip2_longitude&amp;#34;: &amp;#34;$geoip2_longitude&amp;#34;, &amp;#34;geoip2_region_name&amp;#34;: &amp;#34;$geoip2_region_name&amp;#34;, &amp;#34;http_host&amp;#34;: &amp;#34;$http_host&amp;#34;, &amp;#34;http_user_agent&amp;#34;: &amp;#34;$http_user_agent&amp;#34;, &amp;#34;http_x_forwarded_for&amp;#34;: &amp;#34;$http_x_forwarded_for&amp;#34;, &amp;#34;remote_addr&amp;#34;: &amp;#34;$remote_addr&amp;#34;, &amp;#34;remote_port&amp;#34;: &amp;#34;$remote_port&amp;#34;, &amp;#34;request&amp;#34;: &amp;#34;$request&amp;#34;, &amp;#34;request_uri&amp;#34;: &amp;#34;$request_uri&amp;#34;, &amp;#34;request_time&amp;#34;: &amp;#34;$request_time&amp;#34;, &amp;#34;request_method&amp;#34;: &amp;#34;$request_method&amp;#34;, &amp;#34;scheme&amp;#34;: &amp;#34;$scheme&amp;#34;, &amp;#34;server_name&amp;#34;: &amp;#34;$server_name&amp;#34;, &amp;#34;server_protocol&amp;#34;: &amp;#34;$server_protocol&amp;#34;, &amp;#34;ssl_protocol&amp;#34;: &amp;#34;$ssl_protocol&amp;#34;, &amp;#34;ssl_cipher&amp;#34;: &amp;#34;$ssl_cipher&amp;#34;, &amp;#34;status&amp;#34;: &amp;#34;$status&amp;#34;, &amp;#34;time_iso8601&amp;#34;: &amp;#34;$time_iso8601&amp;#34;, &amp;#34;upstream&amp;#34;: &amp;#34;$upstream_addr&amp;#34;, &amp;#34;upstream_connect_time&amp;#34;: &amp;#34;$upstream_connect_time&amp;#34;, &amp;#34;upstream_response_time&amp;#34;: &amp;#34;$upstream_response_time&amp;#34; } log_format promtail_json &amp;#39;{&amp;#34;@timestamp&amp;#34;:&amp;#34;$time_iso8601&amp;#34;,&amp;#39; &amp;#39;&amp;#34;@version&amp;#34;:&amp;#34;Promtail json&amp;#34;,&amp;#39; &amp;#39;&amp;#34;server_addr&amp;#34;:&amp;#34;$server_addr&amp;#34;,&amp;#39; &amp;#39;&amp;#34;remote_addr&amp;#34;:&amp;#34;$remote_addr&amp;#34;,&amp;#39; &amp;#39;&amp;#34;host&amp;#34;:&amp;#34;$host&amp;#34;,&amp;#39; &amp;#39;&amp;#34;uri&amp;#34;:&amp;#34;$uri&amp;#34;,&amp;#39; &amp;#39;&amp;#34;body_bytes_sent&amp;#34;:$body_bytes_sent,&amp;#39; &amp;#39;&amp;#34;bytes_sent&amp;#34;:$body_bytes_sent,&amp;#39; &amp;#39;&amp;#34;request&amp;#34;:&amp;#34;$request&amp;#34;,&amp;#39; &amp;#39;&amp;#34;request_length&amp;#34;:$request_length,&amp;#39; &amp;#39;&amp;#34;request_time&amp;#34;:$request_time,&amp;#39; &amp;#39;&amp;#34;status&amp;#34;:&amp;#34;$status&amp;#34;,&amp;#39; &amp;#39;&amp;#34;http_referer&amp;#34;:&amp;#34;$http_referer&amp;#34;,&amp;#39; &amp;#39;&amp;#34;http_user_agent&amp;#34;:&amp;#34;$http_user_agent&amp;#34;&amp;#39; &amp;#39;}&amp;#39;;</description></item><item><title>Login info mgmt</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Login-info-mgmt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Login-info-mgmt/</guid><description>概述 参考：
查看登录日志
tail /var/log/secure procps 工具包中，有一些可以处理登录信息的工具，比如 pkill、w 等
last - 用来显示所有登录的信息 last 是 Util-linux Utilities
EXAMPLE
last reboot # 查看系统重新引导的时间。i.e.客户查看设备什么时候关机再开机过 lastb - 查看登录失败的用户信息 Notes: 这是一个指向 last 程序的软连接
lastb 程序在不同的发行版中，所属的 Package 不同。
lastb 工具会读取 /var/log/btmp 文件，并把文件内容中记录登录失败的信息列出来。b 是 bad 的含义，lastb 就是指现实坏的登录信息
~]# lastb root ssh:notty 172.19.42.203 Mon Jun 7 21:49 - 21:49 (00:00) root ssh:notty 172.19.42.203 Mon Jun 7 21:24 - 21:24 (00:00) root ssh:notty 172.19.42.203 Mon Jun 7 21:22 - 21:22 (00:00) .</description></item><item><title>LogQL 常见查询语句</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E7%AE%A1%E7%90%86/LogQL-%E5%B8%B8%E8%A7%81%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E7%AE%A1%E7%90%86/LogQL-%E5%B8%B8%E8%A7%81%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5/</guid><description>概述 参考：
官方文档，查询 - 查询示例 多重过滤
过滤应该首先使用标签匹配器，然后是行过滤器，最后使用标签过滤器：
{cluster=&amp;#34;ops-tools1&amp;#34;, namespace=&amp;#34;loki-dev&amp;#34;, job=&amp;#34;loki-dev/query-frontend&amp;#34;} |= &amp;#34;metrics.go&amp;#34; !=&amp;#34;out of order&amp;#34; | logfmt | duration &amp;gt; 30s or status_code!=&amp;#34;200&amp;#34; 多解析器
比如要提取以下格式日志行的方法和路径：
level=debug ts=2020-10-02T10:10:42.092268913Z caller=logging.go:66 traceID=a9d4d8a928d8db1 msg=&amp;#34;POST /api/prom/api/v1/query_range (200) 1.5s&amp;#34; 你可以像下面这样使用多个解析器：
{job=&amp;#34;loki-ops/query-frontend&amp;#34;} | logfmt | line_format &amp;#34;{{.msg}}&amp;#34; | regexp &amp;#34;(?P&amp;lt;method&amp;gt;\\w+) (?P&amp;lt;path&amp;gt;[\\w|/]+) \\((?P&amp;lt;status&amp;gt;\\d+?)\\) (?P&amp;lt;duration&amp;gt;.*)&amp;#34; Notes: 其实这种 regexp 语法在新版已经可以用 pattern 代替了
pattern `&amp;lt;method&amp;gt; &amp;lt;path&amp;gt; (&amp;lt;status&amp;gt;) &amp;lt;duration&amp;gt;` 首先通过 logfmt 解析器提取日志中的数据，然后使用 | line_format 重新将日志格式化为 POST /api/prom/api/v1/query_range (200) 1.5s，然后紧接着就是用 regexp 解析器通过正则表达式来匹配提前标签了。
格式化 下面的查询显示了如何重新格式化日志行，使其更容易阅读。</description></item><item><title>logs</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/logs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/logs/</guid><description>概述 参考：
logs 命令可以打印 pod 中的 container 的日志
kubectl logs [-f] [-p] (POD | TYPE/NAME) [-c CONTAINER] [options] 语法结构
kubectl logs &amp;lt;PodName&amp;gt; # 查看指定 pod 的日志 kubectl logs -f &amp;lt;PodName&amp;gt; # 类似 tail -f 的方式查看(tail -f 实时查看日志文件 tail -f 日志文件 log) kubectl logs &amp;lt;PodName&amp;gt; -c &amp;lt;container_name&amp;gt; # 查看指定 pod 中指定容器的日志 OPTIONS
-f # 实时查看日志文件，类似于 tailf -p,&amp;ndash;previous # 输出 pod 中曾经运行过，但目前已终止的容器的日志。(i.e 查看一个 container 重启之前的日志，用于排障) EXAMPLE
kubectl logs &amp;ndash;namespace=kube-system calico-node-krgz6 calico-node # 查看 calico-node-krgz6 这个 pod 的日志</description></item><item><title>Loki API</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-API/</guid><description>概述 参考：
官方文档，HTTP API 每个组件都会暴露一些基本的 API
GET /ready GET /metrics GET /config GET /services GET /loki/api/v1/status/buildinfo 除了这几个基本的 API 以外，每个组件都会暴露一些专用的 API，若是以 Monolithic 架构启动 Loki，则下面的所有 API 都会在这个进程暴露。
Querier API 与 Query Frontend API 查询器与查询前端暴露的 API 是我们最常用的 API，用来处理客户端发来的 LogQL。
GET /loki/api/v1/query GET /loki/api/v1/query_range Step vs Interval GET /loki/api/v1/labels GET /loki/api/v1/label/&amp;lt;name&amp;gt;/values GET /loki/api/v1/series GET /loki/api/v1/index/stats GET /loki/api/v1/tail Distributor API POST /flush POST /ingester/flush_shutdown Ingester API POST /flush POST /ingester/shutdown Ruler API 以 /loki/ 开头的 API 与 Prometheus API 兼容，结果格式可以互换使用</description></item><item><title>lrzsz</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/File-transfer/lrzsz/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/File-transfer/lrzsz/</guid><description>概述 参考：
GitHub 项目，UweOhse/lrzsz 官网 [!warning] 若想通过 ssh 使用 lrzsz 中的程序，必须要保证执行 ssh 命令的程序支持将 X/Y/Z Modem 协议封装到 SSH 中，比如 XShell、SecurityCRT、etc. 。如果是通过 PowerShell 使用 ssh 命令连接到服务器，是无法使用 lrzsz 的。
lrzsz 是一个用在 Unix-like OS 上的 File transfer 工具包，使用 X/Y/Z Modem 文件传输协议从本地直接上传/下载文件到操作系统中
lrzsz 中包含如下程序
r 开头的是 receive，让 lrzsz 所在系统从外部接受文件；s 开头的是 send，从 lrzsz 所在系统往外发送文件。都是相对 lrzsz 程序所在系统所说，以 lrzsz 程序为主语。
b 是 Ymodem、x 是 Xmodem、z 是 Zmodem
rb rx rz sb sx sz Syntax(语法) 参考:
Ubuntu 官网 Manual(手册)，rz(1) OPTIONS</description></item><item><title>lshw</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/lshw/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/lshw/</guid><description>概述 参考：
参考：
GitHub 项目，lyonel/lshw 官网 lshw 是一个提供机器硬件配置详细信息的小工具。
lshw 输出的内容详解见：https://ezix.org/project/wiki/HardwareLiSter#Howtointerpretlshwsoutput
Syntax(语法) https://ezix.org/project/wiki/HardwareLiSter#Usage
lshw [FORMAT] [OPTIONS]
FORMAT
-X # 启用 GUI（如果可用的话） -html # 以 HTML 格式输出 -xml # 以 XML 格式输出 -json # 以 JSON 格式输出 -short # 打印硬件路径。 H/W path Device Class Description ====================================================== system Standard PC (i440FX + PIIX, 1996) /0 bus Motherboard /0/0 memory 96KiB BIOS /0/400 processor AMD EPYC 7542 32-Core Processor /0/401 processor AMD EPYC 7542 32-Core Processor /0/1000 memory 8GiB System Memory /0/1000/0 memory 8GiB DIMM RAM /0/100 bridge 440FX - 82441FX PMC [Natoma] /0/100/1 bridge 82371SB PIIX3 ISA [Natoma/Triton II] /0/100/1.</description></item><item><title>lspci</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/lspci/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/lspci/</guid><description>概述 参考：
Manual(手册)，lspci(8) GitHub 项目，pciutils/pciutils 官网 列出所有 PCI 设备。在列出的设备信息中，包含了一些供应商的名称、分类名称、etc. 信息。这些信息统一从 pci.ids 文件 文件中获取。
CentOS 包：pciutils
Ubuntu 包：pciutils
其中还有 setpci 工具用来配置 PCI 设备。
TODO: lspci 是如何从 Linux 中拿到 PCI 设备列表的？
Syntax(语法) lspci [OPTIONS]
OPTIONS 基本显示模式
-mm # 以机器可读的形式转储 PCI 设备数据，以便于脚本解析。 显示内容详见 详细格式，通常与 -v 一起使用 -m # 与 -mm 一样，但是向后兼容。不要在新代码中使用 展示内容相关选项
-v # 显示 PCI 设备的详细信息。多次使用 -v 可以显示更多信息，最多支持 3 个 v。 -k # 显示用于处理 PCI 设备的内核驱动以及能够处理ta的内核模块。在正常输出模式下若使用 -v 选项时默认打开 -k。 -D # 始终显示 PCI 的 Domain 部分。 选择指定设备选项</description></item><item><title>Lua</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Lua/Lua/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Lua/Lua/</guid><description>概述 参考：
GitHub 项目，lua/lua 官网 Wiki, Lua 知乎，Lua 是怎样一门语言？ Lua 是一种强大、高效、轻量级、可嵌入的脚本语言。它支持过程式编程、面向对象编程、函数式编程、数据驱动编程和数据描述。
tips: “Lua”（发音为 LOO-ah）在葡萄牙语中的意思是“月亮”。因此，它既不是首字母缩略词也不是缩写词，而是一个名词。更具体地说，“Lua”是一个名字，是地球月球的名字，也是语言的名字。与大多数名称一样，它应该以小写字母开头，即“Lua”。请不要将其写为“LUA”，这样既难看又令人困惑，因为这样它就变成了一个缩写词，对不同的人有不同的含义。所以，请把“Lua”写对！
学习资料 菜鸟教程，Lua
安装完 rjpcomputing/luaforwindows 编译器后，可以在 安装目录/examples/quickluatour.lua 文件中看到非常全面的 Lua 使用示例，直接运行就可体验基本的 Lua 语法。
Hello World print(&amp;#34;Hello World!&amp;#34;) Lua可以在交互模式下输入代码直接查看效果，也可以将lua代码写入以.lua结尾的文件，然后使用lua FILE.lua命令查看代码效果，效果如下：
交互式：
~]# lua Lua 5.1.4 Copyright (C) 1994-2008 Lua.org, PUC-Rio &amp;gt; print(&amp;#34;hello world!&amp;#34;) hello world! 脚本式：
~]# cat hello_world.lua print(&amp;#34;hello world!&amp;#34;) ~]# lua hello_world.lua hello world! Lua 环境安装与使用 LuaJIT(Just-In-Time) 是 Lua 编程语言的跟踪即时编译器。
window 下你可以使用一个叫 &amp;ldquo;SciTE&amp;rdquo; 的 IDE环 境来执行 lua 程序，下载地址为：</description></item><item><title>Lua 规范与标准库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Lua/Lua-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Lua/Lua-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/</guid><description>概述 参考：
Lua 语言关键字 参考：
Lua的关键字有下面几个，这些关键字不能作为常量或者变量或其他用户自定义标识符
and break do else elseif end false for function if in local nil not or repeat return then true until while goto Lua 语言规范 参考：
一般来说，以下划线开头连接一串大写字母的名字（比如_VERSION）被保留用于Lua内部全局变量,效果如下：
~]# lua Lua 5.1.4 Copyright (C) 1994-2008 Lua.org, PUC-Rio &amp;gt; print(_VERSION) Lua 5.1 Lua 标准库 参考：
lua 参考手册，6 - 标准库 数据类型 number string table function 变量 lua的变量有三种类型：
全局变量。 局部变量。 表中的域。 默认情况下，lua定义的变量为全局变量。全局变量不需要声明，给一个变量赋值后即创建了这个变量，访问一个没有初始化的变量并不会报错，只不过得到的结果是nil,效果如下：
&amp;gt; print(b) nil &amp;gt; b=1 &amp;gt; print(b) 1 Note：如果想要删除一个变量，只需要将nil赋值给变量即可</description></item><item><title>Management</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Management/</guid><description>概述 参考：
官方文档 - PowerShell，模块 - Management 管理模块可以让我们在 PowerShell 中管理系统中的 进程、服务、Item 等。
Item 管理工具 Clear-Item Copy-Item Get-Item Invoke-Item Move-Item New-Item Remove-Item Rename-Item Set-Item Get-ChildItem # 获取指定位置的 Item 和 子Item。类似 ls 命令 New-Item https://learn.microsoft.com/zh-cn/powershell/module/microsoft.powershell.management/new-item
创建一个新的 Item 并设置它的值。可以创建的 Item 类型取决于当前所使用的 ProwerShell 提供程序。例如，在文件系统中，创建文件、目录、符号链接、等等；在注册表中，创建注册表条目
Syntax(语法) OPTIONS
-ItemType STRING # 指定新 Item 类型，可用的类型取决于 PowerShell 的提供程序 由于不同提供可用的类型非常多，笔记里就不写了，具体还是看 Net-Item 官方文档吧 EXAMPLE 创建符号链接(软连接)
创建 C:/Users/DesistDaydream/AppData/Roaming/yuzu 符号链接文件，指向 D:/Games/emulator/yuzu_data/user New-Item -ItemType SymbolicLink -Path &amp;quot;C:/Users/DesistDaydream/AppData/Roaming/yuzu&amp;quot; -Target &amp;quot;D:/Games/emulator/yuzu_data/user&amp;quot; Notes: 这种用法可以代替 mklink 命令 查看符号链接文件所指向的原始文件路径 (Get-Item ${PathToFile}).</description></item><item><title>Management API</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/Management-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/Management-API/</guid><description>概述 参考：
官方文档</description></item><item><title>Markdown</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/Markdown/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/Markdown/</guid><description>概述 参考：
官网 官方规范 Wiki, Markdown GitHub 项目，DavidAnson/markdownlint # 一种 MarkDown 的格式规范 Markdown 是一种轻量级的标记语言
Markdown 中的 LaTex 数学公式 参考：
Markdwon + LaTex 表达数学式子 简书，Markdown 数学公式语法 基础的 Markdown 语法 中无法满足数学公式的表达需求，此时可以借助 Latex 语法完成。在 Markdown 中由 $ 符号包围的部分编写的 Latex 语法，可以解析成数学公式。一共有两种格式
行内格式 # 使用 $。比如 $2^{10}=1024$ 的解析效果为：$2^{10}=1024$ 独行格式 # 使用 $$。比如 $$LaTex code$$ 的解析效果如下 $$LaTex code$$
速查 Markdown 中 Latex 基本符号速查表
显示字符 输入字符 显示字符 输入字符 显示字符 输入字符 # \# $ \$ % \% &amp;amp; \&amp;amp; ~ \~ _ \_ ^ \^ \\ \\ { \{ } \} ≤ \le ≥ \ge ≡ \equiv ≠ \ne 文本底线对齐的省略号 \ldots 文本中对齐的省略号 \cdots 圆括号 () 方括号 [] 竖线 `` 花括号 \{\} 双竖线 \ 长圆括号 \left( \right) 长方括号 \left[ \\right] 长花括号 \left\\{ \right\} 换行 \\ 空格 \space ← \leftarrow → \rightarrow 文字 \mbox{ } 字符相关 字符 插入 # $ % &amp;amp; ~ _ ^ \ { } 这些符号类字符需多加 \ 符号（类似于编程语言中的转义字符），其他可以直接插入。</description></item><item><title>Markup language</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/Markup-language/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/Markup-language/</guid><description>概述 参考：
Wiki, Markup_language Markup language(标记语言) 一种文本编码系统，由插入文本文档中的一组符号组成，用于控制其结构、格式或其各部分之间的关​​系。 标记通常用于控制文档的显示或丰富其内容以方便自动化处理。
标记语言是一组规则，用于管理文档中可以包含哪些标记信息以及如何将其与文档内容组合以方便人类和计算机程序使用。这一概念和术语源自纸质稿件的“标记”（即编辑的修订指示），传统上是用红笔或蓝色铅笔在作者的手稿上书写。</description></item><item><title>MCP</title><link>https://desistdaydream.github.io/docs/12.AI/MCP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/MCP/</guid><description>概述 参考：
GitHub 组织，modelcontextprotocol 官网 Model Context Protocol(模型上下文协议，简称 MCP) 是一种开放协议，能够实现 LLM 应用程序与外部数据源和工具之间的无缝集成。无论是在构建 AI 驱动的 IDE、增强聊天界面，还是创建自定义 AI 工作流，MCP 都提供了一种标准化的方式，将 LLM 连接到所需的上下文。
规范 参考：
规范 架构 https://modelcontextprotocol.io/specification/2025-03-26/architecture
MCP 的工程化实现本质也是一个类似 C/S 的架构，但是在其中多了 Model(模型) 的参与。一套完整的 MCP 系统通常包含如下几类组件：
Tips: 有些模型进行了 MCP 的训练，可以正常识别 MCP 的上下文内容，并且也可以返回 MCP 标准的上下文
Host(主持人) # 充当内容的容器和协调器。创建和管理多个 MCP Client 实例。协调 AI/LLM 集成和采样。管理跨客户端的上下文聚合。 类似 Web 中的 User Agent 概念。 MCP Client # 由 Host 创建并维护。与 MCP Server 建立 1:1 的连接关系。 MCP Server # 通过 MCP 原语公开 Resources, Tools, Prompts，提供后端程序的功能，用于与 MCP Client 通信。 类似各种可以提供 API 的 Web 应用程序。只不过使用了 MCP 协议包装了 API 或其他各种功能。 MCP Server 可以是多种形态，并不只局限于是监听了 TCP 的进程。甚至可以是一个本地文件系统上独立的 py 文件或二进制文件，只在使用时，由 MCP Client 直接使用以从标准输入和输出中进行交互。 Model # AI 模型。为问题提供 分析、总结 能力。 一套完整的 MCP 系统的运行过程通常如下所述：</description></item><item><title>Memory</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Memory/Memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Memory/Memory/</guid><description>概述 参考：
Wiki, Computer memory Random Access Memory(随机存取存储器，简称 RAM，也叫主存)，平时大家都叫 Memory(内存)。
RAM 是一种形式的计算机存储器可被读取和以任何顺序发生变化，通常用于存储工作数据和机器代码。甲随机存取存储器设备允许数据项被读出或写入在几乎相同的时间量，而不管存储器内数据的物理位置的。相反，对于其他直接访问数据存储介质，例如硬盘，CD-RW，DVD-RW和较旧的磁带和磁鼓存储器一样，由于机械限制（例如介质旋转速度和机械臂移动），读写数据项所需的时间根据其在记录介质上的物理位置而有很大不同。
RAM包含多路复用和多路分解电路，用于将数据线连接到寻址的存储器，以读取或写入条目。通常，同一地址访问的存储空间不止一位，而RAM设备通常具有多条数据线，并且被称为“ 8位”或“ 16位”等设备。
在当今的技术中，随机存取存储器采用具有MOS（金属氧化物半导体）存储单元的集成电路（IC）芯片的形式。RAM通常与易失性类型的内存（例如动态随机存取存储器（DRAM）模块）相关联，尽管已经开发了非易失性RAM，但如果断电，则会丢失存储的信息。存在其他类型的非易失性存储器，它们允许对读操作进行随机访问，但要么不允许写操作，要么对其具有其他种类的限制。其中包括大多数类型的ROM和一种闪存称为_NOR-Flash_。
易失性随机存取半导体存储器的两种主要类型是静态随机存取存储器（SRAM）和动态随机存取存储器（DRAM）。半导体RAM的商业用途可以追溯到1965年，当时IBM为他们的System / 360 Model 95计算机引入了SP95 SRAM芯片，而东芝则为其Toscal BC-1411电子计算器使用了DRAM存储单元，两者均基于双极晶体管。基于MOS晶体管的商用MOS存储器是在1960年代后期开发的，此后一直是所有商用半导体存储器的基础。1970年10月推出了第一款商用DRAM IC芯片Intel 1103。同步动态随机存取存储器（SDRAM）随后于1992年与三星KM48SL2000芯片一起首次亮相。
Error-Correcting Code memory Rank, 位宽, 颗粒 公众号 - 开发内功修炼，理解内存的Rank、位宽以及内存颗粒内部结构</description></item><item><title>Memory Info</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory-Info/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memory-Info/</guid><description>概述 参考：
/proc/meminfo 参考：
Manual(手册)，proc_meminfo(5) GitHub 项目，torvalds/linux - Documentation/filesystems/proc.rst#meminfo RedHat 官方给的解释 该文件报告有关系统上 Memory 使用情况的统计信息。 free 命令使用该文件来报告系统上的可用内存和已使用内存（物理内存和交换内存）以及内核使用的共享内存和缓冲区的数量。该文件是以 : 符号分割的 Key/Value pair(键/值对) 格式。可用参数及其详解如下：
MemTotal 总可用 Memory。即.物理 RAM 减去一些保留的 bits 和内核二进制代码所用的量
MemFree 空闲的 Memory。LowFree 与 HighFree 两个参数的值的和
MemAvailable 可用的 Memory。估算值，估计有多少内存可用于启动新的应用程序
Buffers 与 Cached 详见：《Memory 的缓存》
Active 最近使用过的 Memory。除非必要，否则通常不会回收。
Inactive 最近使用比较收的 Memory。这些内存会被优先回收。
Slab 内核数据结构缓存。dentry、inode_cache 等
SReclaimable Slab Reclaimable。Slab 的一部分，可以被 reclaimed(回收)。例如 dentry、inode 的缓存等等。
SUnreclaim Slab UnReclaim。Slab 的一部分，不可以被 reclaimed(回收)。即使内存有压力也无法回收
CommitLimit 提交限制。当前可以分配的内存上限。只有当 [/proc/sys/vm/overcommit_memory](net(网络相关参数).md Kernel/Kernel 参数/net(网络相关参数).md) 的参数值为 2 的时候，该限制才生效。这个上限是指当程序向系统申请内存时，如果申请的内存加上现在已经分配的内存，超过了 commitlimit 的值，则该申请将会失败。</description></item><item><title>Message Queue(消息队列)</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid><description>概述 参考：
场景一：日志采集系统，拿 Loki 举例，采集器(promtail)采集数据后，存储到后端日志存储器(Loki)上，当需要采集多个节点，并且当日志大量产生时， Loki 的处理很有可能会出现瓶颈而无法处理写入请求，这时候，我们就想要在 采集器 和 存储中间添加一个缓冲，来减慢后端存储的压力
而这就是 消息队列 的作用之一，采集器作为 MQ 的生产者，将日志数据传入队列，日志存储器作为 MQ 的消费者，从队列中逐步拿取日志数据并存储。有了这么一个缓冲，Loki 的压力将会得到很大缓和。
这时候可能还会有这种想法：我直接限制 采集器 的处理逻辑不好么，为什么还要中间再加一层东西，增加故障点。这是为了解耦，采集器的处理逻辑就是采集日志并上传，不要过多关注此行为之外的东西，这样一个产品才能快速迭代，更好的处理逻辑。
这种行为简称：消减波峰，保护后端(消费端)
场景二：现代的互联网应用大量地使用了消息队列（Messaging）。消息队列不仅被用于系统内部组件之间的通信，同时也被用于系统跟其它服务之间的交互。消息队列的使用可以增加系统的可扩展性、灵活性和用户体验。非基于消息队列的系统，其运行速度取决于系统中最慢的组件的速度（注：短板效应）。而基于消息队列可以将系统中各组件解除耦合，这样系统就不再受最慢组件的束缚，各组件可以异步运行从而得以更快的速度完成各自的工作。
总结：消息队列能够将业务逻辑解耦，调用方只需要下达命令而不用等待整个逻辑执行完毕。除此之外消息队列也可以抑制性能波峰的产生，在瞬时业务增长产生时保持性能曲线的平滑。
常见消息队列 RocketMQ
RabbitMQ
Kafka
ZeroMQ</description></item><item><title>Metric Queries</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/LogQL/Metric-Queries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/LogQL/Metric-Queries/</guid><description>概述 参考：
官方文档，查询 - 指标查询 LogQL 还可以通过 Functions(函数) 来对每个日志流进行计算以实现 Metric Queries(指标查询) 。就是将日志流中的日志计数，并根据技术进行一些查询，这种查询方式与 PromQL 的指标查询类似。
指标查询可用于计算诸如 错误消息率、最近 3 个小时内日志数量最多的 N 个日志源、etc. 的信息。
范围向量聚合 LogQL 与 Prometheus 具有相同的范围向量概念，不同之处在于所选的样本范围包括每个日志
常用函数主要是如下 4 个：
rate: 计算每秒的日志条目 count_over_time: 对指定范围内的每个日志流的条目进行计数 bytes_rate: 计算日志流每秒的字节数 bytes_over_time: 对指定范围内的每个日志流的使用的字节数 比如计算 nginx 的 qps：
rate({filename=&amp;#34;/var/log/nginx/access.log&amp;#34;}[5m])) 计算 kernel 过去 5 分钟发生 oom 的次数：
count_over_time({filename=&amp;#34;/var/log/message&amp;#34;} |~ &amp;#34;oom_kill_process&amp;#34; [5m])) 聚合运算符 与 PromQL 一样，LogQL 支持内置聚合运算符的一个子集，可用于聚合单个向量的元素，从而产生一个具有更少元素但具有集合值的新向量：
sum: Calculate sum over labels min: Select minimum over labels max: Select maximum over labels avg: Calculate the average over labels stddev: Calculate the population standard deviation over labels stdvar: Calculate the population standard variance over labels count: Count number of elements in the vector bottomk: Select smallest k elements by sample value topk: Select largest k elements by sample value sum：求和 min：最小值 max：最大值 avg：平均值 stddev：标准差 stdvar：标准方差 count：计数 bottomk：最小的 k 个元素 topk：最大的 k 个元素 聚合函数我们可以用如下表达式描述：</description></item><item><title>MIB</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/MIB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/MIB/</guid><description>概述 参考：
Wiki, Management_information_base MIB Wiki, Structure_of_Management_Information SMI https://www.techbuddies.io/2023/08/31/snmp-oids-explained-explore-what-they-are-and-how-to-correctly-use-them/ Management information base(管理信息库，简称 MIB) 是一种数据库，用于管理通信网络中的 entities(实体，也称为 Objects(对象))。MIB 使用 SMI 语法定义 Objects，其中包括 objects 的名称、OID、数据类型、描述(干什么用的)。MIB 也可以看作是 SNMP 的服务端与代理端的沟通桥梁，只有具有统一的格式，才能确定数据。
Structure of Managerment Intormation(管理信息结构,简称 SMI) 是 ASN.1 的子集，是一种技术语言，主要用在 SNMP(传统监控标准) 中，用于定义管理 MIB 中的 Objects。最新的版本是 1999 年的 SMIv2(RFC 2578)(文件内声明的名称为 SNMPv2-SMI)。
Object(对象) 可以是一个具体需要采集到的数据，比如 内存、CPU、磁盘、网络接口等等，也可以是一种抽象的集合，比如地区、硬件、系统、硬件、网络等等。上面说的所有事物，每一个都是一个 Object。所以，Object 可以包含另一个 Object，这也是人称常常将 MIB 称为树状的原因
Object Identifier(对象标识符，简称 OID) # 每一个 Object 都有一个 OID 数据存取格式：即每个 object 除了 OID 用作标示以外，还有数据内容需要遵循一定个格式规范 所谓的 MIB，其实主要是通过文件记录的内容。与其说是用文件记录，不如说 MIB 就是使用 ASN.1(标准的接口描述语言) 编写的代码。ASN.1 语言同样有类似 import、 function 这类的东西。只不过，记录 MIB 文件的语言，又与 ASN.</description></item><item><title>Microsoft Visual C++</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E4%BE%9D%E8%B5%96%E5%BA%93/Microsoft-Visual-C++/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E4%BE%9D%E8%B5%96%E5%BA%93/Microsoft-Visual-C++/</guid><description>概述 参考：
Microsoft Visual C++ Redistributable(简称 vsredist)，</description></item><item><title>MicroStack</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/OpenStack-%E8%A1%8D%E7%94%9F%E5%93%81/MicroStack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/OpenStack-%E8%A1%8D%E7%94%9F%E5%93%81/MicroStack/</guid><description>概述 参考：
官网 GitHub 项目，CanonicalLtd/microstack，代码已转移到 opendev.org https://opendev.org/x/microstack 这东西看来看去，感觉用的人不多呢，而且好像还不完善。
部署 https://ubuntu.com/openstack/install
~# microstack init --auto --control 2023-05-10 05:49:23,541 - microstack_init - INFO - Configuring clustering ... 2023-05-10 05:49:23,950 - microstack_init - INFO - Setting up as a control node. 2023-05-10 05:49:31,695 - microstack_init - INFO - Generating TLS Certificate and Key 2023-05-10 05:49:33,853 - microstack_init - INFO - Configuring networking ... 2023-05-10 05:49:49,792 - microstack_init - INFO - Opening horizon dashboard up to * 2023-05-10 05:49:52,339 - microstack_init - INFO - Waiting for RabbitMQ to start .</description></item><item><title>MMU</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Memory/MMU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Memory/MMU/</guid><description>概述 参考：
Wiki, Memory management unit CPU 芯片中的 Memory management unit(内存管理单元，简称 MMU)</description></item><item><title>Mobile app</title><link>https://desistdaydream.github.io/docs/Mobile-device/Mobile-app/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Mobile-device/Mobile-app/</guid><description>概述 参考：
Wiki, Mobile_app Mobile application(移动应用程序，简称 APP) 是设计用于在手机、平板电脑或手表等移动设备上运行的计算机程序或软件应用程序。移动应用程序通常与设计用于在台式计算机上运行的桌面应用程序以及在移动 Web 浏览器中运行而不是直接在移动设备上运行的 Web 应用程序形成对比。
电脑上的应用程序通常都称为 Application software。
好用的 APP 李跳跳 # 自定义屏幕点击。常用来跳过广告
GitHub 项目，gkd-kit/gkd # 自定义屏幕点击。常用来跳过广告
WeChat 参考：
微信开发者官方文档 微信浏览器：简单三步打开调试工具
微信开发者工具 参考：
官方文档 从 https://developers.weixin.qq.com/miniprogram/dev/devtools/download.html 下载
这本质就是一个类似 VSCode 的编辑器。
关联文件与配置 WeChat Files\Applet\ # 该目录是小程序所在文件夹。每个小程序文件都是一个独立的文件夹，以 wx 开头，像 wx64479c83c7630409 这样
想要找到对应的小程序，可以把所有 wx 开头的文件夹都删除，然后打开小程序，就会生成一个信息的 wx 开头的文件夹。 小程序 调试小程序 调试 微信小程序大体有两种办法，官方的和非官方的
使用微信官方的 微信开发者工具 一边写代码一边调试。
除了使用 微信开发者工具以外，在小程序中内嵌 web devtools 也可以实现类似浏览器调试的方法。可以在 PC 微信中调试 直接使用官方的 devtools - 必须要有小程序源码才可以
https://github.com/Tencent/vConsole # 一个轻量、可拓展、针对手机网页的前端开发者调试面板。现在 vConsole 是微信小程序的官方调试工具。 https://github.</description></item><item><title>Model</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Model/</guid><description>概述 参考：
Wiki, Machine_learning - Models Wiki, Hyperparameter 执行机器学习涉及创建 Model(模型)，这个模型狭义上指数学模型中的统计模型，是一种数学表示，用于描述和解决特定类型的问题。这些模型可以是各种各样的，包括传统的统计学模型，如线性回归和逻辑回归，也可以是基于神经网络的深度学习模型，如卷积神经网络和循环神经网络。
模型通常由 数学公式、超参数、参数 组成，可以根据给定的输入数据进行训练和调整，以使它们能够在未见过的数据上进行准确预测或分类。因此，AI 领域中的模型本质上是一种数学模型，通过使用数学方法来处理和分析数据，以解决各种问题，如分类、预测、图像处理、自然语言处理等。
数学公式 # 模型的结构通常用数学公式表示，e.g. 线性变换、激活函数、etc. 。e.g. 线性层的计算: $y = Wx + b$ ，其中 W 是权重矩阵，x 是输入向量，b 是偏置。 Hyperparameter(超参数) # 训练和模型架构设置中手动配置的参数，影响模型的性能和训练过程。常见的超参数包括：学习率、批量大小、网络层数和每层的神经元数量、激活函数类型、训练轮数、etc. 。而其他参数（例如节点权重）的值是通过训练得出的。 Parameters(参数) # 模型训练过程中学习到的一系列数值，e.g. 权重、etc. 。它们决定了输入数据如何影响模型的输出。 模型需要训练，训练后得到的模型文件是一系列的权值（权重值），通常是大量(上亿)个浮点数，如果进行了模型量化，也可以是整数。
创建模型 想要创建一个可用的模型，通常至少需要如下几步：
定义模型结构 # 选择模型类型等。比如 nn.Linear(10, 1) 定义了一个简单的全连接层。 TODO：定义损失函数和优化器 # 如交叉熵损失、均方误差，以及优化算法如 SGD、Adam。 激活函数 # 每个神经元应用的非线性函数，用于引入非线性，使模型能够学习复杂的模式。 损失函数 # 用于衡量模型输出与实际目标之间的差异。在训练过程中，模型会尝试最小化损失函数。 标注数据 # 标注数据以生成数据集用以训练模型 训练模型 # 利用数据集训练模型。通过给模型输入数据集和目标，让模型经过计算后调整自身参数（权重）。 保存模型 # 在训练完毕后保存模型，以便后续测试或部署。 暂时先用下面的代码尝试理解一下，随着后续深入学习逐步完善：
import torch from torch import nn # 一、定义模型结构 # Linear() 可以暂时理解为使用 Linear 模型，可以假设模型是 y = xA^T + b； # 10, 1 可以理解为 超参数。也可以简单理解为是在训练模型以检查返回值 fc 是否满足预期 fc = nn.</description></item><item><title>Module</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Rsyslog/Module/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Rsyslog/Module/</guid><description>概述 参考：
官方文档，模块 在配置模块时，可以会利用各种 Rsyslog objects(对象) 对模块进行更多配置，比如 input、action、etc. 这些对象。
objects 的概念是 Rsyslog 设计的 RainerScript 脚本语言中的。
module 对象 # 用于加载模块 input 对象 # 用于描述 Input 行为的主要手段，用于收集 rsyslog 处理的消息。 action 对象 # TODO TODO 在阅读各种模块文档时，通常能看到这种标题，这部分内容就是在说利用 input 对象对该模块进行配置。
比如我 module(load=&amp;quot;imuxsock&amp;quot;) 这样加载了 imuxsock 模块，然后可以这样 input(type=&amp;quot;imuxsock&amp;quot; Socket=&amp;quot;/root/tmp/log&amp;quot;) 利用 input 对象控制 imuxsock 模块的行为。Socket 参数是告诉 imuxsock 模块要在 /root/tmp/log 文件处监听 Unix Socket。
还有类似这样的标题: Action Parameters，这就是在说可以利用 action 对象对该模块进行配置。
Output 模块 https://www.rsyslog.com/doc/configuration/modules/idx_output.html
Input 模块 https://www.rsyslog.com/doc/configuration/modules/idx_input.html
Input 模块用于从各种来源收集消息。它们与消息生成器交互。它们通常是通过输入配置对象定义的。如果要配置具体的输入参数，通常是利用 input 对象实现的。
imuxsock https://www.</description></item><item><title>Module(模块)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Module%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Module%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
Linux 模块是 Loadable Kernel Module(全称为动态可加载内核模块，简称 LKM)，简称为模块。模块是具有独立功能的程序，它可以被单独编译，但不能独立运行。它在运行时被链接到内核作为内核的一部分在内核空间运行，这与运行在用户空间的进程是不同的。模块通常由一组函数和数据结构组成，用来实现一种文件系统、一个驱动程序或其他内核上层的功能。
总之，模块是一个伪内核（从某种意义上来说，内核也是一个模块）或其他内核模块提供使用功能的代码块。
模块的管理方式：使用 systemd 控制的 unit：systemd-modules-load.service
该 unit 启动后读取其中指定目录下的配置以加载模块
模块关联文件与配置 系统启动后，依次从上到下从以下目录读取模块名称以加载它们
/etc/modules-load.d/*.conf /run/modules-load.d/*.conf /usr/lib/modules-load.d/*.conf 系统启动后，依次从上到下从以下目录读取模块的额外参数并应用它们
/etc/modprobe.d/*.conf /run/modprobe.d/*.conf /usr/lib/modprobe.d/*.conf ~]# cat /etc/modules-load.d/br_netfilter.conf br_netfilter 该目录格式为每个模块一行 注意不要给模块名加任何后缀 /etc/sysconfig/modules/*.modules # 系统读取该目录下的脚本加载用户自定义的模块，该目录下的文件必须要以 .modules 为文件名结尾。该文件会被系统视为 shell 脚本，因此该文件应以解释器指令作为开头第一行。
/usr/lib/modules/$(uname -r)/kernel/ # 模块所在目录，不同类型的模块有不同目录
Note：不同版本内核的模块目录不同，所有安装的模块都在该目录下，如果需要把模块加载到内核中，则可以通过命令来加载该目录下的对应模块即可
arch # 与硬件平台有关的项目，例如 CPU 的等级等等 crypto # 核心所支持的加密的技术，例如 md5 或者 des 等等 drivers # 一些硬件的驱动程序，例如显卡、网卡、PCI 相关硬件等等 fs # 核心所支持的 filesystems，例如 vfat、reiserfs、nfs 等等 lib # 一些函数库 net # 与网络有关的各项协定数据，还有防火墙模块 sound # 与音效有关的各项模块 模块之间的依赖性</description></item><item><title>Multi-Stage Builds(多阶段构建)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/Multi-Stage-Builds%E5%A4%9A%E9%98%B6%E6%AE%B5%E6%9E%84%E5%BB%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/Multi-Stage-Builds%E5%A4%9A%E9%98%B6%E6%AE%B5%E6%9E%84%E5%BB%BA/</guid><description>概述 参考：
官方文档 https://docs.docker.com/build/building/multi-stage/ 两个奇技淫巧，将 Docker 镜像体积减小 99% https://mp.weixin.qq.com/s/6bgtD0Aer6-3u4u9jWBBhw
对于刚接触容器的人来说，他们很容易被自己构建的 Docker 镜像体积吓到，我只需要一个几 MB 的可执行文件而已，为何镜像的体积会达到 1 GB 以上？本文将会介绍几个奇技淫巧来帮助你精简镜像，同时又不牺牲开发人员和运维人员的操作便利性。本系列文章将分为三个部分：
第一部分着重介绍多阶段构建（multi-stage builds），因为这是镜像精简之路至关重要的一环。在这部分内容中，我会解释静态链接和动态链接的区别，它们对镜像带来的影响，以及如何避免那些不好的影响。中间会穿插一部分对 Alpine 镜像的介绍。
第二部分将会针对不同的语言来选择适当的精简策略，其中主要讨论 Go ，同时也涉及到了 Java ， Node ， Python ， Ruby 和 Rust 。这一部分也会详细介绍 Alpine 镜像的避坑指南。什么？你不知道 Alpine 镜像有哪些坑？我来告诉你。
第三部分将会探讨适用于大多数语言和框架的通用精简策略，例如使用常见的基础镜像、提取可执行文件和减小每一层的体积。同时还会介绍一些更加奇特或激进的工具，例如 Bazel ， Distroless ， DockerSlim 和 UPX ，虽然这些工具在某些特定场景下能带来奇效，但大多情况下会起到反作用。
本文介绍第一部分。
01 万恶之源 我敢打赌，每一个初次使用自己写好的代码构建 Docker 镜像的人都会被镜像的体积吓到，来看一个例子。
让我们搬出那个屡试不爽的 hello world C 程序：
/* hello.c */ int main () { puts(&amp;#34;Hello, world!&amp;#34;); return 0; } 并通过下面的 Dockerfile 构建镜像：</description></item><item><title>MySQL SQL</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-SQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-SQL/</guid><description>概述 参考：
MySQL 官方文档，SLQ 语句 SQL 语言被细分为几个语言元素，包括：
子句，它们是语句和查询的组成部分。（在某些情况下，这些是可选的。） 表达式，可以生成标量值或由数据的列和行组成的表 Predicates，指定可以评估为 SQL三值逻辑 (3VL)（真/假/未知）或布尔 真值的条件，用于限制语句和查询的效果，或更改程序流程。 查询，根据特定条件检索数据。这是 SQL 的一个重要元素。 语句，可能对模式和数据产生持久影响，或者可能控制事务、程序流、连接、会话或诊断。 SQL 语句还包括分号(&amp;quot;;&amp;quot;) 语句终止符。虽然不是每个平台都需要它，但它被定义为 SQL 语法的标准部分。 SQL 语句和查询中通常会忽略无关紧要的空格，从而更容易格式化 SQL 代码以提高可读性。 在 MySQL 中按照功能将各种语句进行了分类：
Data Definition Statements(数据定义语句) Data Manipulation Statements(数据操作语句) Transactional and Locking Statements(事务和锁语句) Replication Statements(复制语句) Prepared Statements(预处理语句) Compound Statement Syntax(符合语句) Database Administration Statements(数据库管理语句) Utility Statements(使用程序语句) 关键字 参考：
MySQL 官方文档，语言结构 - 关键字和保留字 函数与运算符 参考：
MySQL 官方文档，函数与运算符 内置函数 参考：
MySQL 官方文档，函数与运算符 - 内置函数和运算符参考 函数名 功能 启用版本 弃用版本 REPLACE() 替换掉指定字符串 REGEXP_REPLACE() 替换掉使用正则表达式匹配到的字符串 8.</description></item><item><title>MySQL 部署</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E9%83%A8%E7%BD%B2/</guid><description>概述 docker 启动 MySQL mkdir -p /opt/mysql/config mkdir -p /opt/mysql/data docker run -d --name mysql --restart always \ --network host \ -v /opt/mysql/data:/var/lib/mysql -v /opt/mysql/config:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=mysql \ mysql:8 对于 5.7+ 版本，推荐设置 SQL Mode，去掉默认的 ONLY_FULL_GROUP_BY。
tee /opt/mysql/config/mysql.cnf &amp;gt; /dev/null &amp;lt;&amp;lt;EOF [mysqld] sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION EOF 如果不去掉这个模式，当我们使用 group by 时，select 中选择的列如果不在 group by 中，将会报错：
ERROR 1055 (42000): Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column 'kalacloud.user_id' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by</description></item><item><title>Named Templates(命名模板)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Named-Templates%E5%91%BD%E5%90%8D%E6%A8%A1%E6%9D%BF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Named-Templates%E5%91%BD%E5%90%8D%E6%A8%A1%E6%9D%BF/</guid><description>概述 参考：
官方文档：https://helm.sh/docs/chart_template_guide/named_templates/ Named Templates(命名模板，有时称为 partial(部分) 或 subtemplate(子模板)) 是限定在一个文件内部的模板，并起一个名称。Named Templates 可以在一个文件中定义，并在其他地方使用它们。
我们有两种创建方法，以及几种不同的使用方法。
在 控制结构与变量 章节中，我们介绍了声明和管理模板三个动作：define，template，和 block。在本节中，我们将介绍这三个动作，并介绍一个 include 函数，与 template 类似功能。
在命名模板时要注意一个重要的细节：模板名称是全局的。如果声明两个具有相同名称的模板，则最后加载一个模板是起作用的模板。由于子 chart 中的模板与顶级模板一起编译，因此注意小心地使用特定 chart 的名称来命名模板。
通用的命名约定是为每个定义的模板添加 chart 名称：{{define &amp;ldquo;mychart.labels&amp;rdquo;}}。通过使用特定 chart 名称作为前缀，我们可以避免由于同名模板的两个不同 chart 而可能出现的任何冲突。
partials 和 _ 文件
到目前为止，我们已经使用了一个文件，一个文件包含一个模板。但 Helm 的模板语言允许创建指定的嵌入模板，可以通过名称访问。
在我们开始编写这些模板之前，有一些文件命名约定值得一提：
大多数文件 templates/ 被视为包含 Kubernetes manifests NOTES.txt 是一个例外 名称以下划线（_）开头的文件被假定为没有内部 manifest。这些文件不会渲染 Kubernetes 对象定义，而是在其他 chart 模板中随处可用以供调用。 这些文件用于存储 partials 和辅助程序。事实上，当我们第一次创建时 mychart，我们看到一个叫做文件 _helpers.tpl。该文件是模板 partials 的默认位置。
define 定义模板 &amp;amp;&amp;amp; template 引用模板 define 定义模板，语法如下：
{{ define &amp;#34;MY.</description></item><item><title>NAT 穿透是如何工作的：技术原理及企业级实践</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/NAT/NAT-%E7%A9%BF%E9%80%8F%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/NAT/NAT-%E7%A9%BF%E9%80%8F%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%9E%E8%B7%B5/</guid><description>译者序 本文翻译自 2020 年的一篇英文博客： How NAT traversal works 。
设想这样一个问题：在北京和上海各有一台 ==局域网的机器== （例如一台是家里的台式机，一 台是连接到星巴克 WiFi 的笔记本），二者都是私网 IP 地址，但可以访问公网， ==如何让这两台机器通信呢？==
既然二者都能访问公网，那最简单的方式当然是在公网上架设一个中继服务器： 两台机器分别连接到中继服务，后者完成双向转发。这种方式显然有很大的性能开销，而 且中继服务器很容易成为瓶颈。
有没有办法不用中继，让 ==两台机器直接通信== 呢？
如果有一定的网络和协议基础，就会明白这事儿是可能的。Tailscale 的这篇 ==史诗级长文== 由浅入深地展示了这种“可能”，如果完全实现本文所 介绍的技术，你将得到一个企业级的 NAT/防火墙穿透工具。 此外，如作者所说， ==去中心化软件== 领域中的许多有趣想法，简化之后其实都变成了 ==跨过公网（互联网）实现端到端直连== 这一问题，因此本文的意义并不仅限于 NAT 穿透本身。
由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。
以下是译文。
在前一篇文章 How Tailscale Works 中， 我们已经用较长篇幅介绍了 Tailscale 是如何工作的。但其中并没有详细描述我们是 ==如何穿透 NAT 设备，从而实现终端设备直连的== —— 不管这些终端之间 有什么设备（防火墙、NAT 等），以及有多少设备。本文试图补足这一内容。
1 引言 1.1 背景：IPv4 地址短缺，引入 NAT 全球 IPv4 地址早已不够用，因此人们发明了 NAT（网络地址转换）来缓解这个问题。
简单来说，大部分机器都使用 ==私有 IP 地址== ，如果它们需要访问公网服务，那么，
出向流量：需要经过一台 NAT 设备，它会对流量进行 SNAT，将私有 srcIP+Port 转 换成 NAT 设备的公网 IP+Port（这样应答包才能回来），然后再将包发出去； 应答流量（入向）：到达 NAT 设备后进行相反的转换，然后再转发给客户端。 整个过程对双方透明。</description></item><item><title>Net-SNMP 配置详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/Net-SNMP-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/Net-SNMP-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
snmpd.conf 文件 snmp.conf 文件 mibdirs +/usr/share/snmp/mibs/h3c # 添加 MIB 目录，以便 snmp 工具可以从这些目录中读取 MIB 文件。
mibs +HH3C-OID-MIB # 添加 snmp 工具可以 walk 等操作可以控制的 OID。
mibs +HH3C-SERVER-AGENT-MIB
mibs +HH3C-SERVER-TRAP-MIB</description></item><item><title>net-snmp-utils</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/net-snmp-utils/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/net-snmp-utils/</guid><description>概述 参考：
官方文档，手册 snmpwalk 与 snmpget snmpwalk 与 snmpget 使用 snmp 协议的 GETNEXT 请求，向 SNMP 代理发送查询请求，以便获取 SNMP 数据。
snmpget 获取指定 OID 的数据 snmpwalk 可以获取大量 OID 的数据 关联文件与配置 /etc/snmp/snmp.conf # snmpwalk 与 snmpget 运行时配置文件。若不存在则手动创建
/usr/local/share/snmp/mibs # MIB 文件的默认路径。这里现阶段包含 66 个 MIB 文件。
net-snmp-config --default-mibdirs 命令可以列出工具在使用中会读取 MIB 文件的默认路径，包括如下几个：
注意，CentOS 和 Ubuntu 的路径可能不相同。PS: 这种老程序是真滴坑 $HOME/.snmp/mibs /usr/share/snmp/mibs /usr/share/snmp/mibs/iana /usr/share/snmp/mibs/ietf 添加自定义 MIB 在 /etc/snmp/snmp.conf 文件中添加如下内容
mibdirs +/root/.snmp/mibs/h3c 在 /root/.snmp/mibs/h3c 目录下添加 MIB 文件后，snmpwalk 就可以获取到第三方 MIB 信息。</description></item><item><title>Netcat</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/Netcat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/Netcat/</guid><description>概述 参考：
Wike，Netcat Ncat Manual(手册) https://zhuanlan.zhihu.com/p/83959309 Netcat 是一个简单的实用程序通过 TCP 或 UDP 网络连接读取和写入数据。它旨在成为一个可靠的后端工具，可直接使用或轻松由其他程序和脚本驱动。同时，它还是一个功能丰富的网络调试和探索工具，因为它几乎可以创建您需要的任何类型的连接，包括端口绑定以接受传入连接。
由于 Netcat 的设计理念和功能，被人亲切的亲切得称为 网络工具中的瑞士军刀
最初的 Netcat 是由 hobbit 于 1995 年发布的，尽管它很受欢迎，但它并没有得到维护。有时甚至很难找到v1.10 源代码的副本。该工具的灵活性和实用性促使 Nmap 项目产生 Ncat)，这是一种支持 SSL、IPv6、SOCKS 和 http 代理、连接代理等的现代重新实现。除了 Nmap 项目重新了 Netcat，还有很多重写甚至扩展了 Netcat 的工具
Socat OpenBSD 的 Netcat Cryptcat Netcat6 pnetcat SBD 所谓的GNU Netcat 如需下载和更多信息， 访问 Netcat 主页。
Ncat 参考：
Nmap，ncat Ncat 是一个功能丰富的网络实用程序，它可以从命令行跨网络读取和写入数据。Ncat 由 Nmap 项目编写的，是对古老的 Netcat 的大大改进的重新实现。它同时使用 TCP 和 UDP 进行通信，并被设计为一种可靠的后端工具，可立即为其他应用程序和用户提供网络连接。Ncat 不仅适用于 IPv4 和 IPv6，还为用户提供了几乎无限的潜在用途。
在 Ncat 的众多功能中，包括将 Ncat 链接在一起、将 TCP 和 UDP 端口重定向到其他站点、SSL 支持以及通过 SOCKS4 或 HTTP（CONNECT 方法）代理（以及可选的代理身份验证）进行代理连接的能力。一些通用原则适用于大多数应用程序，从而使您能够立即向通常不支持它的软件添加网络支持。</description></item><item><title>netfilter</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/netfilter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/netfilter/</guid><description>概述 参考：
官方文档，内核子系统文档-Networking-Netfilter Conntrack Sysfs variables 用于配置 Netfilter 系统中的 Connection Tracking for netfilter</description></item><item><title>NetFlow</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/NetFlow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Network-analysis/NetFlow/</guid><description>概述 参考：
Wiki, NetFlow NetFlow 是 1996 年左右在 Cisco 路由器上引入的一项功能，它能够在 IP 网络流量进入或退出接口时收集该流量。通过分析 NetFlow 提供的数据，网络管理员可以确定流量的来源和目的地、服务类别以及拥塞原因等信息。
NetFlow 通常由三个部分组成
Flow exporter(流导出器) # 将数据包聚合成流，并将流记录导出到一个或多个流收集器。 Flow collector(流收集器) # 负责从流导出器接收的流数据的接收、存储和预处理。 Analysis application(分析程序) # 在入侵检测或流量分析的情况下分析接收到的流数据。 截至 2012 年，大多数防火墙和基于软件的 IP 路由器仍在使用类似于 NetFlow 交换的技术。例如 Linux 使用的 Netfilter 框架的 conntrack 功能。
NetFlow 与 DPI 下面回答来自 ChatGPT 3.5
NetFlow（网络流量流）和 DPI（深度数据包检测）是两种不同的网络监测和分析技术，它们在某些方面有联系，但主要关注的方面有所不同。
NetFlow:
NetFlow是一种网络流量分析技术，通常由Cisco开发和使用。 它通过在网络设备（如路由器和交换机）上捕获和记录网络流量的摘要信息来工作。这些信息包括源IP地址、目标IP地址、端口号、协议等。 NetFlow生成的报告提供了对流量模式、流量源和目标等的高层次摘要，适用于流量分析和网络性能监测。 DPI:
DPI是深度数据包检测的缩写，是一种更为深入地分析网络数据包内容的技术。 DPI不仅关注流量的源和目标，还深入解析数据包的内容，可以识别应用程序、协议、用户行为等。 DPI通常用于实时检测网络中的应用层协议，以便对网络流量进行更深入的分析，包括识别特定应用程序或服务，检测潜在的威胁和执行策略。 联系和区别：
联系： NetFlow和DPI都提供了对网络流量的分析能力，但关注的层次和信息的深度不同。 在一些情况下，可以将两者结合使用，通过NetFlow提供的摘要信息定位特定流量，然后使用DPI深入分析该流量的内容。 区别： NetFlow更专注于流量的高层次概要，而DPI更关注深入的数据包内容分析。 NetFlow通常用于流量监测、性能优化和容量规划，而DPI主要用于安全分析、应用层识别和用户行为分析。 分类 Wiki 中的分类: Computer network analysis，还分类下还包括 Network analyers，这里有 DPI</description></item><item><title>network</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-CLI/network/</guid><description>概述 参考：
network 命令用于管理容器的网络
connect - Connect a container to a network create - Create a network docker network create [OPTIONS] NETWORK
EXAMPLE
docker network create -d bridge &amp;ndash;subnet &amp;ldquo;172.26.0.0/16&amp;rdquo; &amp;ndash;gateway &amp;ldquo;172.26.0.1&amp;rdquo; mybr0 # 创建一个桥接的网络，网段是 172.26.0.0/16,网关是 172.26.0.1 disconnect - Disconnect a container from a network inspect - Display detailed information on one or more networks ls - List networks prune - 移除所有未使用的网络 rm - 移除一个或多个网络</description></item><item><title>Network Socket</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Network-Socket/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Network-Socket/</guid><description>概述 参考：
Wiki, Network Scoket Network Socket(网络套接字) 是网络域的 Socket
面向连接服务（TCP 协议）：是电话系统服务模式的抽象，即每一次完整的数据传输都要经过建立连接，使用连接，终止连接的过程。在数据传输过程中，各数据分组不携带目的地址，而使用连接号（connect ID）。本质上，连接是一个管道，收发数据不但顺序一致，而且内容相同。TCP 协议提供面向连接的虚电路。例如
文件传输 FTP 远程登录 SSH 数字语音 等 无连接服务（UDP 协议）：是邮政系统服务的抽象，每个分组都携带完整的目的地址，各分组在系统中独立传送。无连接服务不能保证分组的先后顺序，不进行分组出错的恢复与重传，不保证传输的可靠性。UDP 协议提供无连接的数据报服务。例如：
电子邮件 电子邮件中的挂号信 网络数据库查询 等 TCP/IP 的 Socket 提供下列三种类型套接字。
流式套接字（SOCK_STREAM）：TCP Socket 提供了一个面向连接、可靠的数据传输服务，数据无差错、无重复地发送，且按发送顺序接收。内设流量控制，避免数据流超限；数据被看作是字节流，无长度限制。文件传送协议（FTP）即使用流式套接字。 数据报式套接字（SOCK_DGRAM）：UDP Socket 提供了一个无连接服务（UDP）。数据包以独立包形式被发送，不提供无错保证数据可能丢失或重复，并且接收顺序混乱。网络文件系统（NFS）使用数据报式套接字。 原始式套接字（SOCK_RAW） ：裸 Socket 从应用层直接封装网络层报文，跳过传输层的协议.该接口允许对较低层协议，如 IP、ICMP 直接访问。常用于检验新的协议实现或访问现有服务中配置的新设备。 Socket Domain 套接字域，根据其所有使用的地址进行分类
AF_INET：Address Family，IPv4 AF_INET6：同上，IPv6 AF_UNIX：同一主机上不同进程之间通信时使用 每类套接字至少提供了两种 socket：流，数据报
TCP：传输控制协议，面向连接的协议，通信钱需要建立虚拟链路，结束后拆除链路
UDP，无连接的协议
流：可靠的传递，面向连接，无边界 数据报：不可靠的传递，有边界，无连接 Socket 通信流程</description></item><item><title>neutron</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/neutron/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/neutron/</guid><description>概述 参考：
Syntax(语法) neutron [OPTIONS] [SubCommand [OPTIONS]]
直接输入 neutron 可以进入 neutron 的 shell 模式，在 neutron 的 shell 中再执行相关命令
net-list # 列出网络信息
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.</description></item><item><title>Nginx 处理 HTTP 请求的流程</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E5%A4%84%E7%90%86-HTTP-%E8%AF%B7%E6%B1%82%E7%9A%84%E6%B5%81%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E5%A4%84%E7%90%86-HTTP-%E8%AF%B7%E6%B1%82%E7%9A%84%E6%B5%81%E7%A8%8B/</guid><description>概述 参考：
原文：Nginx 处理 HTTP 请求的 11 个阶段 博客园对该文章的排版更好 前面给大家讲了 Nginx 是如何处理 HTTP请求头部的，接下来就到了真正处理 HTTP 请求的阶段了。先看下面这张图，这张图是 Nginx 处理 HTTP 请求的示意图，虽然简单，但是却很好的说明了整个过程。
Read Request Headers：解析请求头。 Identify Configuration Block：识别由哪一个 location 进行处理，匹配 URL。 Apply Rate Limits：判断是否限速。例如可能这个请求并发的连接数太多超过了限制，或者 QPS 太高。 Perform Authentication：连接控制，验证请求。例如可能根据 Referrer 头部做一些防盗链的设置，或者验证用户的权限。 Generate Content：生成返回给用户的响应。为了生成这个响应，做反向代理的时候可能会和上游服务（Upstream Services）进行通信，然后这个过程中还可能会有些子请求或者重定向，那么还会走一下这个过程（Internal redirects and subrequests）。 Response Filters：过滤返回给用户的响应。比如压缩响应，或者对图片进行处理。 Log：记录日志。 以上这七个步骤从整体上介绍了一下处理流程，下面还会再说一下实际的处理过程。
Nginx 处理 HTTP 请求的 11 个阶段 下面介绍一下详细的 11 个阶段，每个阶段都可能对应着一个甚至多个 HTTP 模块，通过这样一个模块对比，我们也能够很好的理解这些模块具体是怎么样发挥作用的。
可以在 Nginx 源码 src/http/ngx_http_core_module.h 找到这 11 个阶段的定义
typedef enum { NGX_HTTP_POST_READ_PHASE = 0, NGX_HTTP_SERVER_REWRITE_PHASE, NGX_HTTP_FIND_CONFIG_PHASE, NGX_HTTP_REWRITE_PHASE, NGX_HTTP_POST_REWRITE_PHASE, NGX_HTTP_PREACCESS_PHASE, NGX_HTTP_ACCESS_PHASE, NGX_HTTP_POST_ACCESS_PHASE, NGX_HTTP_PRECONTENT_PHASE, NGX_HTTP_CONTENT_PHASE, NGX_HTTP_LOG_PHASE } ngx_http_phases; POST_READ：在 read 完请求的头部之后，在没有对头部做任何处理之前，想要获取到一些原始的值，就应该在这个阶段进行处理。这里面会涉及到一个 realip 模块。 SERVER_REWRITE：和下面的 REWRITE 阶段一样，都只有一个模块叫 rewrite 模块，一般没有第三方模块会处理这个阶段。 FIND_CONFIG：做 location 的匹配，暂时没有模块会用到。 REWRITE：对 URL 做一些处理。 POST_WRITE：处于 REWRITE 之后，也是暂时没有模块会在这个阶段出现。 接下来是确认用户访问权限的三个模块：</description></item><item><title>Nginx 衍生品</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E8%A1%8D%E7%94%9F%E5%93%81/Nginx-%E8%A1%8D%E7%94%9F%E5%93%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E8%A1%8D%E7%94%9F%E5%93%81/Nginx-%E8%A1%8D%E7%94%9F%E5%93%81/</guid><description>概述 OpenResty 参考：
GitHub 组织，OpenResty 官网 OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。
Nginx Unit 参考：
官网</description></item><item><title>Nginx 源码解析</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</guid><description>概述 参考：
GitHub 项目，nginx/nginx Nginx 的架构设计是高度模块化的，从 Nginx 的源码目录与 Nginx 模块化及其功能的划分是紧密结合的。
# tree -d . ├── auto ├── conf ├── contrib ├── docs ├── misc └── src ├── core ├── event │ └── modules ├── http │ ├── modules │ │ └── perl │ └── v2 ├── mail ├── misc ├── os │ ├── unix │ └── win32 └── stream 每个模块必须要具备 ngx_module_t 这个数据结构，比如 src/core/nginx.c 文件中，在 ngx_module_t 数据结构中，定义了 ngx_core_module 模块
ngx_module_t ngx_core_module = { // 定义模块名称为 ngx_core_module NGX_MODULE_V1, &amp;amp;ngx_core_module_ctx, /* module context */ // ngx_core_commands 是该模块的指令，这里一般会定义一个数组，数组中每个元素就是一个指令 ngx_core_commands, /* module directives */ // NGX_CORE_MODULE 是该模块的类型 NGX_CORE_MODULE, /* module type */ NULL, /* init master */ NULL, /* init module */ NULL, /* init process */ NULL, /* init thread */ NULL, /* exit thread */ NULL, /* exit process */ NULL, /* exit master */ NGX_MODULE_V1_PADDING }; 再看 src/http/ngx_http.</description></item><item><title>Nmap</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Utility/Nmap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Utility/Nmap/</guid><description>概述 参考：
官网 Manual(手册)，NMAP(1) Network Mapper(网络映射器，简称 Nmap) 是一个用于网络探索和安全审计的开源工具。旨在快速扫描大型网络。
Nmap 项目除了有自己的 nmap 工具外，还有很多实用程序，比如 Netcat、etc.
Syntax(语法) nmap [Scan Type&amp;hellip;] [OPTIONS] {TARGET}
Scan Type(扫描类型) # TARGET # 扫描目标 直接使用 nmap IP 即可开始一个简单的扫描任务
OPTIONS 参考：
https://nmap.org/book/man-briefoptions.html 规避防火墙/IDS 与 伪装 FIREWALL/IDS EVASION AND SPOOFING
TODO
-f; --mtu &amp;lt;val&amp;gt;: fragment packets (optionally w/given MTU) -D &amp;lt;decoy1,decoy2[,ME],...&amp;gt;: Cloak a scan with decoys -S &amp;lt;IP_Address&amp;gt;: Spoof source address -e &amp;lt;iface&amp;gt;: Use specified interface -g/--source-port &amp;lt;portnum&amp;gt;: Use given port number --proxies &amp;lt;url1,[url2],.</description></item><item><title>nova</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/nova/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/nova/</guid><description>概述 参考：
Syntax(语法) nova [OPTIONS] [SubCommand [OPTIONS]]
nova list [OPTIONS] # 列出SERVER相关信息
nova show # 显示指定SERVER的详细信息，非常详细
nova instacne-action-list # 列出指定SERVER的操作，创建、启动、停止、删除时间等，
注意：语法中的SERVER指的都是已经创建的虚拟服务器，SERVER可以用实例的NAME(实例名)或者UUID(实例的ID)来表示，SERVER的ID和NAME可以用过nova list命令查到
可以使用nova help SubCommand命令查看相关子命令的使用方法
nova list [OPTIONS] # 列出SERVER相关信息
OPTIONS
&amp;ndash;all-tenants # 显示所有租户的SERVER信息，可简写为&amp;ndash;all-t &amp;ndash;tenant [] # 显示指定租户的SERVER信息 EXAMPLE
nova list &amp;ndash;all-t # 显示所有正在运行的实例，可以查看实例以及ID和主机名 nova list &amp;ndash;all-t &amp;ndash;host cat /etc/uuid # 显示cat /etc/uuid命令输出的主机名的节点运行的实例信息 nova show # 显示指定SERVER的详细信息，非常详细
EXAMPLE
nova show ID # 以实例ID展示该实例的详细信息 nova show ID | grep host # 以实例ID查看所在节点的主机名 nova instacne-action-list # 列出指定SERVER的操作，创建、启动、停止、删除时间等，</description></item><item><title>nping</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/nping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/nping/</guid><description>概述 参考：
Nmap，nping 由 Nmap 项目组开发的类似 hping 的工具
每次的发包都称为一次 Probe(探测)
Syntax(语法) 参考：
Manual(手册)，nping nping [OPTIONS] {&amp;lt;targets&amp;gt;}
OPTIONS &amp;ndash;tcp # 使用 TCP 探针模式
TCP 探针模式选项 -g, &amp;ndash;source-port PORT_NUMBER # 设置源端口
&amp;ndash;flags FLAG_LIST # 设置 TCP 的 Flag, 多个 Flag 以逗号分隔
IPv4 选项 -S, &amp;ndash;source-ip # 设置源 IP 地址
Timing 和 Performance &amp;ndash;delay TIME # 前后两次发送探测行为的间隔. i.e. 每隔 TIME 探测一次
其他 -c, &amp;ndash;count N # 在发送 N 次后停止程序. 若 N 设为 0 则永不停止.</description></item><item><title>NPM</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/NPM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/NPM/</guid><description>概述 参考：
官网 官方文档，cli-使用 npm-配置 Node.js Package Manager(简称 NPM) 是 Node.js 自带的包管理工具，通常与 Node.js 一同安装，最初版本于 2010 年 1 月发行。NPM 本质是一个第三方模块，可以在 NodeJS 安装目录下的 lib/node_modules/npm/* 目录下找到 npm 的所有文件。
配置镜像源为淘宝的： npm config -g set registry=&amp;quot;https://registry.npmmirror.com&amp;quot;
npm 关联文件与配置 npm 从 命令行、环境变量、npmrc 文件 这些地方获取其配置信息：
命令行标志 环境变量 npmrc 文件 # npm 从以下几个地方依次读取 npmrc 文件 /PATH/TO/NPM/npmrc # npm 内置的配置文件。这内置的文件是不是不可见的？o(╯□╰)o ${PREFIX}/etc/npmrc # 全局配置文件，可以通过 --globalconfig 命令行选项或 ${NPM_CONFIG_GLOBALCONFIG} 环境变量改变其值 ~/.npmrc # 用户配置文件，可以通过 --userconfig 命令行选项或 ${NPM_CONFIG_USERCONFIG} 环境变量改变其值 /PATH/TO/MY/PROJECT/.npmrc # 每个项目自己的配置 ${PREFIX}/bin/ # npm 安装的各种依赖包中若包含命令行工具，则会在此目录创建软链接。该目录通常都会加入到 ${PATH} 变量中。</description></item><item><title>NTP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/NTP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/NTP/</guid><description>概述 参考：
Wiki, NTP Network Time Protocol(网络时间协议，简称 NTP) 是在数据网络潜伏时间可变的计算机系统之间通过分组交换进行时钟同步的一个网络Communication protocol，位于 OSI 模型的应用层。自 1985 年以来，NTP 是目前仍在使用的最古老的互联网协议之一。NTP 由特拉华大学的 David L. Mills 设计。
NTP 意图将所有参与计算机的协调世界时（UTC）时间同步到几毫秒的误差内。:3 它使用 Marzullo 算法的修改版来选择准确的时间服务器，其设计旨在减轻可变网络延迟造成的影响。NTP 通常可以在公共互联网保持几十毫秒的误差，并且在理想的局域网环境中可以实现超过 1 毫秒的精度。不对称路由和拥塞控制可能导致 100 毫秒（或更高）的错误。
该协议通常描述为一种主从式架构，但它也可以用在点对点网络中，对等体双方可将另一端认定为潜在的时间源。:20 发送和接收时间戳采用用户数据报协议（UDP）的端口 123 实现。这也可以使用广播或多播，其中的客户端在最初的往返校准交换后被动地监听时间更新。]NTP 提供一个即将到来闰秒调整的警告，但不会传输有关本地时区或夏时制的信息。
当前协议为版本 4（NTPv4），这是一个 RFC 5905 文档中的建议标准。它向下兼容指定于 RFC 1305 的版本 3。
NTP 的设计者 David L. Mills。
1979 年，网络时间同步技术在纽约的国家计算机会议上于运行在跨大西洋卫星网络的互联网服务上公开演示，这可能是该技术的首次公开演示。该技术后在 1981 年互联网工程笔记（IEN）173 中描述，并根据 RFC 778 文档开发为一个公开协议。该技术首先被部署在一个本地网络，作为 Hello 路由协议的一部分，并在 Fuzzball（一个用于网络原型的实验操作系统，已运行多年）中实现。
现在还有其他的相关网络工具。这包括 Daytime 和 Time 协议用以记录事件时间，以及互联网控制消息协议和 IP 时间戳选项（RFC 781）。更多完整的同步系统，虽然缺乏 NTP 的数据分析和时钟规律算法，包括 Unix 守护进程 timed 在内的软件其使用选举算法为所有客户端指定服务器。以及数字时间同步服务（Digital Time Synchronization Service，DTSS）使用类似构 NTP 阶层模型的服务器层次结构。</description></item><item><title>NUMA</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/NUMA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/NUMA/</guid><description>概述 参考：
Linux Kernel 文档，管理员指南 - 内存管理 - 概念 - Nodes Linux Kernel 文档，内存管理 - NUMA Linux Kernel 文档，管理员指南 - 内存管理 - NUMA 内存策略 Wiki, Non-uniform memory access Non-uniform memory access(非均匀内存访问，简称 NUMA) 是一种用于多处理结构的计算机的内存设计，其中内存访问时间取决于相对于处理器的内存位置。在 NUMA 下，处理器可以比非本地内存（另一个处理器的本地内存或处理器之间共享的内存）更快地访问自己的本地内存。 NUMA 的优势仅限于特定的工作负载，特别是在数据通常与某些任务或用户密切相关的服务器上。
Linux 将系统的硬件资源按照抽象的 Nodes(节点) 概念进行划分。Linux 将 Nodes 映射到硬件平台的物理 Cells(单元) 上，抽象出某些架构的一些细节。与物理单元一样，软件 Nodes 可能包含 0 个或多个 CPU、内存和/或 IO 总线。而且，与对更远程单元的访问相比，对“较近” Node 上的存储器的存储器访问通常会经历更快的访问时间和更高的有效带宽。</description></item><item><title>NumPy</title><link>https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/NumPy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/NumPy/</guid><description>概述 参考：
GitHub 项目，numpy/numpy 官网 Wiki, NumPy NumPy 是使用 Python 进行科学计算的基础包。
安装 pip install numpy</description></item><item><title>OAuth</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Access-Control/OAuth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Access-Control/OAuth/</guid><description>概述 参考：
RFC 6749, The OAuth 2.0 Authorization Framework Wiki, Oauth Open Authorization(简称 OAuth) 是一种用于 access delegation(访问授权) 的开放标准。通常作为互联网用户授权网站或应用程序访问其在其它网站上的信息的一种方式，而无需提供密码。亚马逊、谷歌、Meta Platforms、微软、推特、etc. 公司采用此机制，允许用户与第三方应用程序或网站共享其账户信息。
OAuth 的出现主要是解决这么一个问题：第三方应用程序，如何安全地获得用户授权，以访问该用户在另一个服务上的资源。
一个简单的场景是：我开发了一个照片打印程序（程序 A），用户想要打印自己存储在网盘中的照片，那么用户如何在不告诉 A 账号密码或者任何登录用 Token 等认证信息的情况下，让 A 访问到网盘中的照片呢？
程序 A 应该先找网盘要登录方式，提供给用户。网盘验证用户登录成功后，告诉 A 用户已登录并同意了 A 访问照片，同时提供一个 A 用的 Token。此时 A 可以使用这个 Token 来访问允许的内容。这中间，用户并不用把自己的认证信息提供给 A。
[!Note] 在上述场景中，为了避免将用户的敏感资源泄露给程序 A，这种程序一般都是本地部署，并不是通过互联网为多个用户提供服务的。比如 NAS，部署在本地，通过程序编写好的 OAuth 能力获取到权限，即可获取各种云盘中的资源
另外一个场景是非敏感信息的，比如 用户名、头像 之类的。这种就可以不用本地部署，而是第三方程序在互联网提供服务，比如各种网站在登陆时通过 Google 登录，本质也是使用了 Google 的 OAuth 能力获取 邮箱、头像 等非敏感信息。</description></item><item><title>object</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/object/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/object/</guid><description>概述 参考：
MDN，使用对象 object(对象) 是 Javascript 语言的核心概念。所有的数据类型都可以称之为 object。
JS 中的 object 可以简单理解为面向对象编程语言中的“对象”，只不过并不用 class 这种关键字进行声明（不过，在 ES6 标注后，可以使用 class 关键字声明一个 object）
JS 的 object 也是一系列 Property(属性) 的集合。属性包含一个名和一个值，若属性的值是一个函数，则该属性也称为 Method(方法)
var myObject = { // 其他属性... propertyOne: &amp;#34;Hello&amp;#34;, // 创建 myObject 对象的方法，方法名为 methodOne // 这个其实就类似于一个名为 methodOne 的函数，就像 `function methodOne(t)` methodOne: function (a) { // 实际的方法体代码 console.log(&amp;#34;调用了 myObject 对象的方法，参数为:&amp;#34; + a); }, methodTwo(a) { console.log(&amp;#34;调用了 myObject 对象的方法，参数为:&amp;#34;, a) } // 其他方法或属性... }; 注意：Javascript 还有一个 Object 类型的的数据也可以称为 object。。。挺绕的。。。0.</description></item><item><title>Object detection</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object-detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Object-detection/</guid><description>概述 参考：
Wiki, Object detection Ultralytics 文档，术语 - 对象监测 Google 学术 https://scholar.google.com/scholar?q=Object+detection&amp;hl=zh-CN&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart Object detection(对象检测) 是一种与计算机视觉和图像处理相关的计算机技术，用于检测数字图像和视频中特定类别（例如人类、建筑物或汽车）的语义对象的实例。
Image Classification(图像分类) # 确定图像中是否存在特定对象。
Bounding Box(边界框) # 用于突出显示图像中对象的位置的矩形。它由坐标 (x, y)、宽度和高度定义。
对象监测架构 One-Stage Detectors(单级检测器) 例如 YOLO、SSD：一步执行对象定位和分类，提供更快的推理速度，但有时会牺牲准确性。
Two-Stage Detectors(两阶段检测器) （例如 Faster R-CNN）：涉及区域提议阶段，然后进行对象分类，通常可以实现更高的准确度，但推理时间可能会更慢。</description></item><item><title>Obsidian</title><link>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/Obsidian/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/Obsidian/</guid><description>概述 参考：
官网 官方文档 开发者文档 Obsidian 也是基于 Chromium 的，使用 Ctrl + Shift + i 快捷键可以打开 DevTools
英文论坛
中文论坛
中文论坛与英文论坛的账户不共享
Obsidian 关联文件与配置 参考：
官方文档，Obsidian 如何存储数据 Obsidian 本身的运行时数据保存路径（我们假定设为 ${ObsidianData}）[^官方文档]
~/.config/Obsidian/ # Linux 系统 %APPDATA%/Obsidian/ # Windows 系统 ${REPO}/.obsidian/ # 特定于每个仓的配置的保存路径。在每个仓库的根目录下的 .obsidian/ 目录中。
workspaces.json # 工作区布局的配置文件。通常在每个仓库各自 .obsidian/ 目录下。 https://www.bilibili.com/video/BV1Dy4y1375P
Vault Obsidian 将本地仓库称为 vault，一个 vault 就是文件系统上的一个文件夹。这个 vault 中保存了所有记录的 文档、附件、插件、etc. 。
编辑与格式 https://help.obsidian.md/Editing+and+formatting/Basic+formatting+syntax
Obsidian 识别 Markdown 语法并渲染成文章。
Callouts https://help.obsidian.md/Editing+and+formatting/Callouts
Obsidian 扩展了 Markdown 的 Callouts(标注) 效果。</description></item><item><title>OCR</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OCR/</guid><description>概述 参考：
Wiki, Optical_character_recognition https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/models.md Optical character recognition(光学字符识别，简称 OCR) 是将图像以电子或机械方式转换为机器编码文本，无论是来自扫描文档、文档照片、场景照片、叠加在图像上的字母文字等。目前是文字识别的统称，已不限于文档或书本文字识别，更包括识别自然场景下的文字，又可以称为 Scene Text Recognition(场景文字识别，简称 STR)。
OCR 文字识别一般包括两个部分，文本检测和文本识别
文本检测首先利用检测算法检测到图像中的文本块 然后文本识别利用识别算法去识别文本块中的具体文字 Detection Model(检测模型) 文本检测就是要定位图像中的文字区域，然后通常以边界框的形式将单词或文本行标记出来。传统的文字检测算法多是通过手工提取特征的方式，特点是速度快，简单场景效果好，但是面对自然场景，效果会大打折扣。当前多是采用深度学习方法来做。
基于深度学习的文本检测算法可以大致分为以下几类：
基于目标检测的方法；一般是预测得到文本框后，通过NMS筛选得到最终文本框，多是四点文本框，对弯曲文本场景效果不理想。典型算法为EAST、Text Box等方法。 基于分割的方法；将文本行当成分割目标，然后通过分割结果构建外接文本框，可以处理弯曲文本，对于文本交叉场景问题效果不理想。典型算法为DB、PSENet等方法。 混合目标检测和分割的方法； Recognition Model(识别模型) OCR 识别算法的输入数据一般是文本行，背景信息不多，文字占据主要部分，识别算法目前可以分为两类算法：
基于 CTC 的方法；即识别算法的文字预测模块是基于 CTC 的，常用的算法组合为 CNN+RNN+CTC。目前也有一些算法尝试在网络中加入 transformer 模块等等。 基于 Attention 的方法；即识别算法的文字预测模块是基于 Attention 的，常用算法组合是 CNN+RNN+Attention 预处理 为了可以让程序快速检测到字符块后精准识别字符，有的时候还需要对图片进行预处理
比如图片是斜的，我们可以把图片正过来 若是图片有干扰，可以去掉干扰 等等&amp;hellip;&amp;hellip; 总结 用稍微简单一些的话说，检测模型用来检查一个图片中，哪些地方可以被识别模型识别；然后交给识别模型。若将图片直接交给识别模型，那么是无法获得任何结果的
用 PaddleOCR 的识别识别逻辑举例，至少需要用到两种模型：文本检测模型 和 文本识别模型。提供给 PaddleOCR 一张图后，首先先检测图片中包含的文字信息并定位为文本框，然后识别文本框中的文本。
Tips: 若想要识别倒转的文字，还可以通过 方向分类器 模型进行预处理。有的 OCR 程序还有很多其他的预处理操作，比如去斑、二值化、线条去除、布局分析 等等。
如下图：
用红框框起来的就是检测到的文本框，每个文本框都由 [[196.0, 10.0], [237.0, 10.</description></item><item><title>OCR</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/paddleocr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/paddleocr/</guid><description>概述 参考：
GitHub 项目，PaddlePaddle/PaddleOCR 使用说明 https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/whl.md</description></item><item><title>Open vSwitch</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/Open-vSwitch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/Open-vSwitch/</guid><description>概述 参考：
Wiki, Open_vSwitch Open vSwitch # 开放的虚拟交换机 特性：支持 802.1q，trunk，access；支持网卡绑定技术(NIC Bonding);支持 QoS 配置及策略；支持 GRE 通用路由封装；支持 VxLAN；等等
OVS 的组成部分：
ovs-vswitchd # 守护进程,实现数据报文交换功能，和 Linux 内核兼容模块一同实现了基于流的交换技术 ovsdb-server # ovs 的数据库，轻量级的数据库服务器，主要保存了 OVS 的配置信息，EXP 接口、交换、VLAN 等，ovs-vswitchd 的交换功能基于此库实现,相关数据信息保存在这个文件中：/etc/openvswitch/conf.db ovs-vsctl # 命令行工具，用于获取或更改 ovs-vswitchd 的配置信息，其修改操作会保存至 ovsdb-server 中 ovs-dpctl # ovs-appctl # ovsdbmonitor # ovs-controller # ovs-ofctl # ovs-pki # 一般情况下都是对于一台物理机上的几个 vSwithc 上的 VM 进行同行进行的配置，比如两个 VM 各连接一个 vSwitch，这时候可以对物理机使用 ip link add veth1.1 type veth peer name veth1.2 命令俩创建一对虚拟接口然后使用 ovs-vsctl add-port BRIDGE PORT 命令分别把这两个虚拟接口绑定在两个 vSwitch 上，实现俩个 vSwitch 之间互联并且能够通信。还有就是如图所示，由于 OVS 有 DB，各 NODE 之间的 OVS 数据都互相共享，那么可以直接把 VM 连接到 vSwitch 上，然后再连接到物理网络就可以互通了相当于只是几个交换机互联而已，如果进行隔离后，使得隔离的 VM 可以通信，那么使用 namespace 功能创建一个 vRouter，通过 vRouter 实现被隔离的网络间互相通信</description></item><item><title>OpenAPI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/OpenAPI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/OpenAPI/</guid><description>概述 参考：
官网 GitHub 社区，OAI Swagger OpenAPI Initiative(开放应用程序接口倡议，简称 OAI)。是由具有前瞻性的行业专家联合创建的，他们认识到标准化 API 描述方式的巨大价值。作为 Linux 基金会下的开放治理结构，OAI 致力于创建、发展 和 推广供所有人可用的中立的描述格式。
OAI 现阶段包含一个规范
OpenAPI Specification(简称 OAS) # 最初基于 SmartBear Software 捐赠的 Swagger 规范。 OAS 可以描述为一个文件，可以描述为一个规范的内容。人们常常在不同场景下，不加区分得统一用 OAS 来描述。比如 Swagger Codegen 项目中的描述中。 This is the Swagger Codegen project, which allows generation of API client libraries (SDK generation), server stubs and documentation automatically given an OpenAPI Spec.(这是 Swagger Codegen 项目，该项目允许在给定 OpenAPI 规范的情况下自动生成 API 客户端库（生成 SDK），服务器存根和文档。) 这里描述的指定的的 OpenAPI Spec 就是指 OAS，也就是说，而已根据 OAS 文件来生成代码。 OpenAPI Specification 参考:</description></item><item><title>OpenMetrics</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/OpenMetrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/OpenMetrics/</guid><description>概述 参考：
GitHub 项目，OpenObservability/OpenMetrics https://github.com/prometheus/OpenMetrics 官网 OpenMetrics 规范 OpenMetrics 是新时代的监控指标的标准，由 CNCF 主导，OpenMetrics 定义了大规模传输云原生指标的事实标准。
OpenMetricsSpec 用来定义监控指标的标准 [!Attention] 公众号 - InfoQ，OpenMetrics 归档并合并到 Prometheus
英文帖子: https://horovits.medium.com/openmetrics-is-archived-merged-into-prometheus-d555598d2d04 GitHub 项目，cncf/toc Issue 1364 已在 2024 年 8 月份将 OpenMetrics 项目归档合并到 Prometheus 中。
Data Model(数据模型) https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#data-model
平时我们口语交流，一般将随时间变化的数据称为 Metrics(指标)。这是监控数据的另一种叫法，与 OID 类似，可以代表一种监控数据、同时也是一种名词，比如我采集某个程序的监控数据，可以说采集这个程序的 Metrics。所以 Metrics 是一个抽象的叫法。
详见 Prometheus Data Model(数据模型)</description></item><item><title>OpenSSL 配置详解</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/OpenSSL/OpenSSL-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/OpenSSL/OpenSSL-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
Manual, 文件格式 Manual(手册), config(5) Manual(手册), x509v3_config(5) Manual(手册), openssl-req(1)-CONFIGURATION FILE FORMAT 部分 https://www.cnblogs.com/f-ck-need-u/p/6091027.html OpenSSL 配置文件为 OpenSSL 库及其二进制程序提供运行时参数。这是一个 INI 格式的配置文件。
配置文件一共有三类格式：
config # OpenSSL 通用配置格式 fips_config # OpenSSL FIPS 配置格式 x509v3_config # X.509 V3 证书扩展配置格式 配置文件格式 OpenSSL 配置文件的语法与 INI 类似，但与常见的 INI 配置并不太一样（Section 用于定义场景，而不是定义某种类型的配置），并且扩展了很多能力：
Section 本身的意义来源于 Openssl 命令行工具，各个 Section 是为各种场景服务的，甚至每个 Section 都可以有很多相同的 K/V 对。 通常可以配合 -extensions 选项以便让命令读取哪个 Section 的内容 特定的 Section 的名字是有意义的，比如 [req] Section 可以为 openssl req 命令提供参数，当执行 openssl req 命令时，会从默认配置文件的 [req] Section 获取配置参数，若没有，则再从 默认 Section 获取参数。 Section 中除了 key/value pair(键值对) 以外，还可以包括 Directives(指令) Section 中的 Key/Value Pair 可以进行变量定义，也可以引用变量。此时 Key 就是变量名，Value 就是变量的值。 引用方式有 $VAR 或 ${VAR} 两种，要想引用其他 Section 中的变量，则使用 $SectionName::VAR 或 ${SectionName::VAR} # 这是默认 Section HOME = /temp configdir = $ENV::HOME/config [ section_one ] # Quotes permit leading and trailing whitespace any = &amp;#34; any variable name &amp;#34; other = A string that can \ cover several lines \ by including \\ characters message = Hello World\n [ section_two ] greeting = $section_one::message 配置文件中的第一部分是一个 默认 Section。若要引用默认 Section 的变量，则使用 ENV 作为 Section 名 可以在 Section 中引用其他 Section。比如： # These must be in the default section config_diagnostics = 1 # 引用 openssl_init 部分的配置 openssl_conf = openssl_init [openssl_init] # 引用 oids 部分的配置 oid_section = oids # 以此类推 providers = providers alg_section = evp_properties ssl_conf = ssl_configuration engines = engines random = random [oids] .</description></item><item><title>openstackCLI</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/openstackCLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/openstackCLI/</guid><description>概述 参考：
常用命令 查看虚拟机的：server
查看网络的：
查看镜像的：
查看存储的：
openstack 命令基础 Openstack Command Line Client 官方介绍：https://docs.openstack.org/python-openstackclient/rocky/
OpenStackClient(又名 OSC)是openstack 的命令行客户端，这个客户端将 compute、identity、image、object、storage 和 blockStorage 这些的 APIs 一起放在一个具有统一命令结构的 shell 中。e.g.nova、neutron、glance 等命令，都会集中在 openstack 的子命令中。
语法格式：openstack [OPTIONS] Command [CommandArguments] 启动一个 shell 来执行 openstack 客户端中的 Command，或者直接使用 openstack+Command 来对 openstack 进行管理与控制
OPTIONS Command 所有 openstack 的可用的 Command 可以通过openstack command list 命令所列出的列表来查看。这些命令通过组来划分，每个命令组代表对一类服务的控制命令
openstack.cli command list [&amp;ndash;group &amp;lt;GroupKeyword&amp;gt;] # 按组列出 openstack 可以支持的所有 Command，可以在选项中指定要查看的具体组名，只查看该组的命令。GroupKeyword 可以使组名中的关键字，不用使用完整的组名
module list [&amp;ndash;all] # 显示 OSC 程序已经安装的 python 模块</description></item><item><title>opensuse的一次救援</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/opensuse%E7%9A%84%E4%B8%80%E6%AC%A1%E6%95%91%E6%8F%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/opensuse%E7%9A%84%E4%B8%80%E6%AC%A1%E6%95%91%E6%8F%B4/</guid><description>概述 参考：
昨晚吃完晚饭回到办公室，右边同事在控制台看着一个suse起不来一直启动的时候卡在suse的蜥蜴logo背景图那。见我来了叫我看下，他们已经尝试过恢复快照，但是还不行，应该是很久之前损坏的，只不过因为没重启没发现，我叫他重启下看看卡在哪，重启后进入内核后显示背景图那按下esc然后看卡在/sysroot挂载那。目测分区损坏了，经历了ubuntu的安装iso的rescue mode就是渣渣后，我还是信任centos的iso。
处理 先备份和准备工作 关闭虚机，后台拷贝下系统盘的卷先备份下。然后给虚机的IDE光驱挂载了个centos 7.5 DVD的iso，修改虚机启动顺序到ISO，进 Troubleshooting –&amp;gt; Rescue a CentOS Linux system
一般损坏的都不建议选1，因为挂载不上，所以是选3手动处理
Device or resource busy 1) Continue 2) Read-only mount 3) Skip to shell 4) Quit (Reboot) Please make a selection from the above: 3 最开始我lsblk和看了下硬盘的分区表，最后 vgchange -a y 激活lvm后 xfs_repair /dev/mapper/suse-lv_root 的时候提示该设备繁忙，遂查看了下
sh-4.2# lsof /dev/mapper/suse-lv_root sh-4.2# ps aux | less lsof和fuser都是返回空的，最后就 ps aux 一个个看，发现了个mount进程一直hung在那
sh-4.2# ps aux | grep moun[t] root 6126 0.0 0.</description></item><item><title>OpenWrt</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/OpenWrt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/OpenWrt/</guid><description>概述 参考：
GitHub 项目，openwrt/openwrt 官网 OpenWrt 项目是一个针对嵌入式设备的 Unix-like OS。与尝试创建单一、静态固件不同，OpenWrt 提供了一个完全可写的文件系统，并配备了软件包管理。这使您摆脱了供应商提供的应用程序选择和配置，并允许您通过使用软件包来定制设备，以适应任何应用程序。对于开发人员来说，OpenWrt 是构建应用程序的框架，无需在其周围构建完整固件；对于用户来说，这意味着完全定制的能力，可以以前所未想象的方式使用设备。
OpenWrt 的包管理器是 OPKG。
据说，爱快(ikuai) 是基于 OpenWrt 的二次封装系统。
ikuai 与 OpenWrt 大部分出现在软路由场景。
iStoreOS 是 koolshare 团队基于OpenWrt定制的软路由系统
OpenWrt 生态项目
luci # Lua 开发的配置接口。名称是 lua + uci 的组合。 uhttpd # HTTP 服务器。通常与 LuCI 组合使用 etc. 关联文件与配置 安装 与 安装操作系统 的逻辑类似，大体分如下几步
下载 Release 将 Release 制作到 U 盘中 在目标机器上插入 U 盘并写入 OpenWrt 系统 Release 官方 https://downloads.openwrt.org/
https://downloads.openwrt.org/releases/
简单的虚拟机测试与体验 使用 openwrt-24.10.1-x86-64-generic-ext4-combined-efi.img.gz Release 作为示例（带有 LuCI 的 Web 页面），下载并解压</description></item><item><title>Operator 模式</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Operator-%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Operator-%E6%A8%A1%E5%BC%8F/</guid><description>概述 参考：
官方文档，概念 - 扩展 K8S - Operator 模式 https://jimmysong.io/kubernetes-handbook/develop/operator.html Operator 是 Kubernetes API 的客户端，充当 Custom Resource 的控制器。作用与 controller-manager 类似。只不过是控制非 k8s 自带资源的控制器
Operator 是由 CoreOS 开发的，用来扩展 Kubernetes API 的特定的应用程序控制器，它用来创建、配置和管理复杂的有状态应用，如数据库、缓存和监控系统。Operator 基于 Kubernetes 的资源和控制器概念之上构建，但同时又包含了应用程序特定的领域知识。创建 Operator 的关键是 CRD（自定义资源）的设计。
背景 基于 Kubernetes 平台，我们可以轻松的搭建一些简单的无状态应用，比如对于一些常见的 web apps 或是移动端后台程序，开发者甚至不用十分了解 Kubernetes 就可以利用 Deployment，Service 这些基本单元模型构建出自己的应用拓扑并暴露相应的服务。由于无状态应用的特性支持其在任意时刻进行部署、迁移、升级等操作，Kubernetes 现有的 ReplicaSets、Deployment、Services 等资源对象已经足够支撑起无状态应用对于自动扩缩容、实例间负载均衡等基本需求。
在管理简单的有状态应用时，我们可以利用社区原生的 StatefulSet 和 PV 模型来构建基础的应用拓扑，帮助实现相应的持久化存储，按顺序部署、顺序扩容、顺序滚动更新等特性。
而随着 Kubernetes 的蓬勃发展，在数据分析，机器学习等领域相继出现了一些场景更为复杂的分布式应用系统，也给社区和相关应用的开发运维人员提出了新的挑战：
不同场景下的分布式系统中通常维护了一套自身的模型定义规范，如何在 Kubernetes 平台中表达或兼容出应用原先的模型定义？ 当应用系统发生扩缩容或升级时，如何保证当前已有实例服务的可用性？如何保证它们之间的可连通性？ 如何去重新配置或定义复杂的分布式应用？是否需要大量的专业模板定义和复杂的命令操作？是否可以向无状态应用那样用一条 kubectl 命令就完成应用的更新？ 如何备份和管理系统状态和应用数据？如何协调系统集群各成员间在不同生命周期的应用状态？ 而所有的这些正是 Operator 希望解决的问题，本文我们将首先了解到 Operator 是什么，之后逐步了解到 Operator 的生态建设，Operator 的关键组件及其基本的工作原理，下面让我们来一探究竟吧。</description></item><item><title>Operators</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/Operators/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/Operators/</guid><description>概述 参考：
官方文档，参考 - 语言规范 - 运算符 Arithmetic operators(算数运算符) https://go.dev/ref/spec#Arithmetic_operators
位运算 https://learnku.com/go/t/23460/bit-operation-of-go
位运算在 Go 语言中属于算数运算的一种。
Comparison operators(比较运算符) https://go.dev/ref/spec#Comparison_operators
Logical operators(逻辑运算符) https://go.dev/ref/spec#Logical_operators
Address operators https://go.dev/ref/spec#Address_operators
Receive operator https://go.dev/ref/spec#Receive_operator</description></item><item><title>os</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/os/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/os/</guid><description>概述 参考：
Go 标准库，os os 包提供了 Operating system 功能的接口，不受不同平台的影响。
这是一个简单的示例，打开一个文件并读取其中的一些内容
file, err := os.Open(&amp;#34;file.go&amp;#34;) // For read access. if err != nil { log.Fatal(err) }</description></item><item><title>OSI 模型</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/OSI-%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/OSI-%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考：
Wiki, OSI model OSI Open System Interconnection Model(开放式系统互联模型，简称 OSI 模型) 是一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于 ISO/IEC 7498-1。
OSI 模型背景 在制定计算机网络标准方面，起着重大作用的两大国际组织是：国际电信联盟电信标准化部门，与国际标准组织（ISO），虽然它们工作领域不同，但随着科学技术的发展，通信与信息处理之间的界限开始变得比较模糊，这也成了国际电信联盟电信标准化部门和 ISO 共同关心的领域。1984 年，ISO 发布了著名的 ISO/IEC 7498 标准，它定义了网络互联的 7 层框架，也就是开放式系统互联参考模型。
层次划分
根据建议 X.200，OSI 将计算机网络体系结构划分为以下七层，标有 1 ～ 7，第 1 层在底部。 现“OSI/RM”是英文“Open Systems Interconnection Reference Model”的缩写。
第 7 层 应用层
主条目：应用层
应用层（Application Layer）提供为应用软件而设的接口，以设置与另一应用软件之间的通信。例如: HTTP，HTTPS，FTP，TELNET，SSH，SMTP，POP3.HTML.等。
第 6 层 表达层
主条目：表达层
表达层（Presentation Layer）把数据转换为能与接收者的系统格式兼容并适合传输的格式。
第 5 层 会话层
主条目：会话层
会话层（Session Layer）负责在数据传输中设置和维护电脑网络中两台电脑之间的通信连接。
第 4 层 传输层
主条目：传输层
传输层（Transport Layer）把传输表头（TH）加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。例如:传输控制协议（TCP）等。</description></item><item><title>OverlayFS</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/OverlayFS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/OverlayFS/</guid><description>概述 参考：
公众号-MoeLove，聊聊 Docker 的存储驱动 Overlay2 大家好，我是张晋涛。
上周在我的交流群里有个小伙伴问到了 Overlay2 相关的问题，这篇就来介绍一下。(想进群的可以留言）
本节，我将为你介绍 Docker 现在推荐使用的存储驱动 Overlay2，在开始之前，你可以执行以下命令来查看 Docker 正在使用的存储驱动：
(MoeLove) ➜ ~ docker info --format '{{.Driver}}' overlay2
如果你看到的结果也是 overlay2 说明你的 Docker 已经在使用 overlay2 存储驱动了。我在个人工作站上用的是 btrfs，这是因为自从 Fedora 33 开始，btrfs 就成为了 Fedora 默认的文件系统。不过服务器上就都是 overlay2 了。
你也可能会看到其他不同的结果，可以在启动 docker daemon 的时候，通过 --storage-driver 参数进行指定，也可以在 /etc/docker/daemon.json 文件中通过 storage-driver 字段进行配置。
目前对于 Docker 最新版本而言，你有以下几种存储驱动可供选择：
overlay2 fuse-overlayfs btrfs zfs aufs overlay devicemapper vfs 但它们对于你使用的文件系统之类的都有不同的要求，且实现方式也不尽相同。我以本节的重点 overlay2 存储驱动为例，它需要你使用 Linux 4.x 以上版本的内核，或者是对于 RHEL/CentOS 等需要使用 3.10.0-514 以上的内核（旧版本中存在一些兼容性问题，我在之前的文章中有提到过）。</description></item><item><title>Packages AND Registries</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/Packages-AND-Registries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitLab/Packages-AND-Registries/</guid><description>概述 参考:
官方文档，部署并发布你的应用 - Packages 和 Registries 与 GitHub 不同，GitLab 有一个单独的存放 Assets 的地方，而不是放在 Release Assets 中，这个地方就是 Packages registry。
在 WebUI 点击左侧导航栏中 Deploy &amp;gt; Package Registry 标签可以查看项目中所有 Packages
GitLab 将多种实体或抽象概念抽象为 Packages
Package registry # 储存各种二进制文件 Container registry # 储存容器镜像 etc. 一个项目产生的交付物都可以称为 Packages。可以在项目左侧导航栏点击 Deploy &amp;gt; Package Registry 查看项目的 Packages。
Package registry GitLab 将如下的实体抽象为 Package:
Generic(通用) # 二进制文件 Helm # Helm 文件 etc. Generic package 参考:
官方文档，通用 Packages 使用 GitLab CI 推送通用的 Package</description></item><item><title>Packet Reassembly</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/Packet-Reassembly/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/Packet-Reassembly/</guid><description>概述 参考：
https://www.wireshark.org/docs/wsug_html_chunked/ChAdvReassemblySection.html Packet Reassembly(数据包重组)</description></item><item><title>PAM 模块详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
pam_faillock # 在指定的时间间隔内维护每个账户在尝试进行身份验证时的失败事件，并且在连续失败时锁定账户。
pam_limits
PAM 的各模块说明 全局参数
file=/PATH/TO/FILE # 用于指定统计次数存放的位置，默认保存在/var/log/tallylog 文件中； onerr # 当意外发生时，返加 PAM_SUCCESS 或 pam 错误代码，一般该项不进行配置； audit # 如果登录的用户不存在，则将访问信息写入系统日志； silent # 静默模式，不输出任何日志信息； no_log_info # 不打印日志信息通过 syslog 上面的五项全局参数，一般在使用中都不需要单独配置。 pam_nologin 这个模块可以限制一般用户是否能够登入主机之用。当 /etc/nologin 这个文件存在时，则所有一般使用者均无法再登入系统了！若 /etc/nologin 存在，则一般使用者在登入时， 在他们的终端机上会将该文件的内容显示出来！所以，正常的情况下，这个文件应该是不能存在系统中的。 但这个模块对 root 以及已经登入系统中的一般账号并没有影响。
pam_pwhistory - 记住最后的密码 参考：
Manual(手册)，pam_pwhistory(8) 该模块用于记住用户设置过的密码，以防止用户在修改密码时频繁交替得使用相同的密码
关联文件 /etc/security/opasswd # 用户设置过的历史密码将会以加密方式保存在该文件中。
模块参数 remember=INT # 用户设置过的 remember 个密码将会保存在 /etc/security/opasswd 文件中。默认值：10。值为 0 时，模块将会保持 opasswd 文件的现有内容不变 pam_pwquality - 密码质量检查 参考：
GitHub 项目，libpwquality/libpwquality Manual(手册)，pam_pwquality(8) pam_pwquality 模块属于 libpwquality 库，最初基于 pam_cracklib 模块，用以执行密码质量检查。仅提供 password 模块类型。</description></item><item><title>PAM 配置文件</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
Manual(手册)，pam.conf(5) 这是一个最基本的配置文件示例：
#%PAM-1.0 auth required pam_deny.so account required pam_deny.so password required pam_deny.so session required pam_deny.so Syntax(语法) PAM 配置文件由 Rules(规则) 列表组成，每条规则一行。规则是由空格分割的多个 Tokens 组成
不知道官方为什么把每个字段要称为 Token 。。。o(╯□╰)o
Service Type Control Module-Path Module-Arguments
Service # 需要调用 PAM 的应用程序的名称。比如 su、login、sshd 等等 注意：/etc/pam.conf 和 /etc/pam.d/* 配置文件有一点差别，在于 Service 字段。/etc/pam.d/ 目录下的所有配置文件，没有 Service 字段，取而代之的是文件名称，也就是说，Service 字段的值，就是 /etc/pam.d/ 目录下的文件名。 Type # 管理类型，这个类型就是 《Linux-PAM 管理组(认证功能的分组)》 的简写。即.本条规则中使用的模块要与哪个管理组关联。 可用的类型有 auth、account、password、session 若在类型前面加上 -，则表示即使模块不存在，也不会影响认证结果，也不会将事件记录到日志中。 Control # 规则执行完成后的行为。即调用 PAM API 完成后，会有返回值，根据返回值，决定如何进行后续认证。 Module-Path # 规则调用的 PAM 模块名称，模块默认在 /usr/lib64/security/ 目录(CentOS 系统)下。 不同系统中，模块所在的默认路径可能不一样。 若调用的 PAM 模块不在默认目录下，则该字段需要使用模块的绝对路径。 Module-Arguments # 规则调用的 PAM 模块的参数。每个参数以空格分隔。 Service Service 除了以应用程序命名，还可以使用自定义的名称，这些名称通常通过 include 这种 Control 行为引用该 Service。</description></item><item><title>pam_faillock</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/pam_faillock/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/pam_faillock/</guid><description>概述 参考：
Manual(手册)，pam_faillock(8) Ubuntu 22.04 TLS Manual Manual(手册)，faillock.conf(5) https://github.com/dev-sec/ansible-collection-hardening/issues/377 红帽官方文档，安全指南-账户锁 https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/security_guide/chap-hardening_your_system_with_tools_and_services#sect-Security_Guide-Workstation_Security-Account_Locking 提供 auth、account 管理类型的模块
pam_faillock 模块在指定的时间间隔内维护每个账户在尝试进行身份验证时的失败事件，并且在连续失败时锁定账户。
pam_faillock 与大部分模块有一点不同，不建议在 PAM 规则中配置参数，而是推荐使用默认的 /etc/security/faillock.conf 配置文件中配置参数
关联文件 /etc/security/faillock.conf # 运行时配置文件。除了在 /etc/pam.d/ 目录下的文件中配置模块的参数，还可以通过这个文件配置模块的参数。
/var/run/faillock/ # 记录用户身份验证失败的事件。目录中的文件名以用户名命名
模块参数 preauth | authfail | authsucc # 这 3 个参数必须根据该模块实例在 PAM 堆栈中的位置进行设置。
conf=&amp;lt;/PATH/TO/FILE&amp;gt; # 指定要使用的配置文件路径。
除了上面的参数外，模块的其他参数都可以在 /etc/security/faillock.conf 文件中进行配置
命令行工具 faillock faillock [OPTIONS]
管理登录失败锁定记录的工具
~]# faillock developer: When Type Source Valid 2021-10-21 21:42:50 RHOST 172.16.10.11 V root: When Type Source Valid 2021-10-21 21:42:41 RHOST 172.</description></item><item><title>pam_limits</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/pam_limits/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/PAM-%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/pam_limits/</guid><description>概述 参考：
Manual(手册)，pam_limits(8) Manula(手册)，limits.conf(5) 应用场景：我的 Linux 主机里面同时登入了十个人，这十个人不知怎么搞的， 同时开启了 100 个文件，每个文件的大小约 10M ，请问一下， 我的 Linux 主机的内存要有多大才够？ 10*100*10 = 10000M = 10G &amp;hellip; 老天爷，这样，系统不挂点才有鬼哩！为了要预防这个情况 的发生，所以我们是可以『限制用户的某些系统资源』的，包括可以开启的文件数量， 可以使用的 CPU 时间，可以使用的内存总量等等。除了这个模块有这个限制功能外，bash 还自带 ulimit 命令可以实现这个功能。
限制用户会话过程中对各种系统资源的使用情况，默认情况下该模块的配置文件是 /etc/security/limits.conf 该配置文件中的参数，可以通过 ulimit -a 命令查看 关联文件与配置 /etc/security/ #
/etc/security/limits.conf # 限制用户会话过程中对各种系统资源的使用情况的配置文件 配置文件语法 /etc/security/limit.conf 文件语法格式：
&amp;lt;DOMAIN&amp;gt; &amp;lt;TYPE&amp;gt; &amp;lt;ITEM&amp;gt; &amp;lt;VALUE&amp;gt; XXX XXXX XXXX XXXX 用户名/组名 限制类型 要限制的项目 具体值 DOMAIN # 设置需要被限制的用户名或组名，组名前面加@和用户名区别。也可使用通配符 * 来表示所有用户 Notes: Ubuntu 的 Manual-limits.conf(5) 中提到组和通配符限制不适用于 root 用户。要设置 root 用户的限制，此字段必须包含文字用户名 root。在 stackexchange 中的套路提到这是为了解决 bug 63230 TYPE # 在设定上，通常 soft 会比 hard 小，举例来说，soft 可设定为 80 而 hard 设定为 100，那么你可以使用到 90 (因为没有超过 100)，但介于 80~100 之间时，系统会有警告讯息通知你！ hard # 严格的设定，指设定的 value 必定不能超过设定的数值 soft # 警告的设定，指设定的 value 可以超过设定值，但是若超过则有警告讯息。 ITEM # 指定要限制的项目 core # 限制内核文件的大小 何谓 core 文件,当一个程序崩溃时，在进程当前工作目录的 core 文件中复制了该进程的存储图像。core 文件仅仅是一个内存映象（同时加上调试信息），主要是用来调试的。core 文件是个二进制文件，需要用相应的工具来分析程序崩溃时的内存映像，系统默认 core 文件的大小为 0，所以没有被创建。可以用 ulimit 命令查看和修改 core 文件的大小，例如：ulimit -c 1000 # 指定修改 core 文件的大小，1000 指定了 core 文件大小。也可以对 core 文件的大小不做限制，如： ulimit -c unlimited date # 最大数据大小 fsize # 最大文件大小 memlock # 最大锁定内存地址空间 nofile # 打开文件的最大数目，默认为 1024 对于需要做许多套接字连接并使它们处于打开状态的应用程序而言，最好通过使用 ulimit -n，或者通过设置 nofile 参数，为用户把文件描述符的数量设置得比默认值高一些 rss # 最大持久设置大小 stack # 最大栈大小 cpu # 以分钟为单位的最多 CPU 时间 nproc # 打开进程的最大数 as # 地址空间限制 maxlogins # 此用户允许登录的最大数目 VALUE # 指定 ITEM 中具体项目的值 NUM # 可以是具体的数值 unlimited # 表示无限制的 security 目录下文件的配置示例 /etc/security/limits.</description></item><item><title>pcap</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/pcap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/pcap/</guid><description>概述 参考：
Wiki, pcap(包捕获) 在计算机网络管理领域，Packet Capture(包捕获，简称 pcap) 是一个用于捕获网络流量的 API。很多数据包分析器都依赖于 pcap 来运行。所以，pcap 准确来说，应该称为 PCAP API
WinPcap # Microsoft OS 下最早的 pcap Npcap # Windows 新的 pcap libpcap # Unix-like OS 下的 pcap Notes: 虽然该名称是 packet capture 的缩写，但这并不是 API 的正确名称。类 Unix 系统在 libpcap 库中实现 pcap；对于 Windows，有一个名为 WinPcap 的 libpcap 端口不再受支持或开发，而对于 Windows 7 及更高版本，仍支持一个名为 Npcap 的端口。
很多实现 pcap 能力的语言若想开发 PCAP 能力必须依赖 libpcap（e.g. go 语言需要开启 CGO_ENABLED=1，且保证系统中安装了 pcap）
pcap 安装 Npcap https://npcap.com/#download
无注意事项，直接安装即可。
libpcap 参考:</description></item><item><title>PCI</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/PCI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/PCI/</guid><description>概述 参考：
Wiki, Peripheral_Component_Interconnect Peripheral Component Interconnect(外围组件互连，简称 PCI)
PCI-E 参考:
Wiki, PCI_Express Peripheral Component Interconnect Express(简称 PCI-E)
PCI 规范 参考:
pci设备身份识别码介绍说明 由 PCI-SIG 制定规范。一个 PCI 设备的通常由下面几个 ID 进行唯一识别
VID # Vendor ID。成为 PCI-SIG 会员的公司会获得 Vendor ID，可以从这里检索 Vendor ID 对应的公司名称（e.g. 0x8086 表示英特尔公司） DID # Device ID SID # Subsystem ID（有时候可以理解为 SDID） SVID # Subsystem-Vendor ID RID # Revision ID，也称 Rev ID，i.e. 版本号 CC # Class-Code 类型代码。 etc. TODO:
https://stackoverflow.com/questions/49050847/how-is-pci-segmentdomain-related-to-multiple-host-bridgesor-root-bridges https://pcisig.com/ https://pcisig.com/specifications https://pcisig.</description></item><item><title>PCI</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Hardware/PCI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Hardware/PCI/</guid><description>概述 参考:
GitHub 项目，torvalds/linux - 通过 sysfs 访问 PCI 设备资源 GitHub 项目，torvalds/linux - 如何编写 PCI 驱动 博客园，如何编写Linux PCI驱动程序 https://www.makelinux.net/ldd3/ - 12.1. The PCI Interface PCI device resources(PCI 设备资源) 由 Kernel 注册在 sysfs 的 /sys/devices/pci${DOMAIN:BUS}/ 目录。每个 PCI 设备资源在该目录下都有一个以 唯一标识符(有的时候也称为 PCI Address) 命名的目录，格式为: DOMAIN:BUS:SLOT.FUNC（e.g. 0000:17:00.0）
DOMAIN(域) # 表示 PCI 域编号。用于识别主机系统中的不同 PCI 主机桥。在较早期的系统中，只有一个域编号为 0。随着系统规模扩大，可能存在多个 PCI 域。 BUS(总线) # 表示 PCI 总线编号（16 进制）。一个 PCI 域中可能包含多条 PCI 总线，每条总线都有一个唯一编号。 SLOT(插槽) # 表示 PCI 插槽编号。每条 PCI 总线上可以连接多个 PCI 设备，每个设备对应一个插槽编号。 有的源码中也描述为 DEVICE。比如这里 FUNC(功能) # 表示 PCI 功能编号。一些 PCI 设备可能包含多个独立的功能，每个功能都有一个编号,用于区分和访问。对于单功能设备,该编号通常为 0。 有的源码中也描述为 FUNCTION 通常来说，目录可能是像这样的:</description></item><item><title>PCI-SIG</title><link>https://desistdaydream.github.io/docs/Standard/IT/PCI-SIG/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/IT/PCI-SIG/</guid><description>概述 参考：
Wiki, PCI-SIG Peripheral Component Interconnect Special Interest Group(外围组件互连特别兴趣小组，简称 PCI-SIG)</description></item><item><title>PIP</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python%E5%B7%A5%E5%85%B7/PIP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python%E5%B7%A5%E5%85%B7/PIP/</guid><description>概述 参考：
GitHub 项目，pypa/pip 官网 Package Installer for Python(Python 的包安装器，简称 PIP) 是 Python 的包管理程序。可以使用它来安装来自 Python 包索引和其他索引的包。从 Python 3.4 开始，它默认包含在 Python 二进制安装程序中。
pip 安装包逻辑 pip 默认从 PyPI 搜索包。
先下载到 /tmp/pip-unpack-随机数/包名-XXX.whl，然后默认情况下，将这些文件安装到 site-packages 目录。
有关 &amp;ndash;taget 选项的说明 当我们使用 --target TARGET_DIR 选项指定包的安装路径时，则会将随包带的可执行文件安装到 TARGET_DIR/bin/ 目录下，若两个具有可执行文件的包被同事安装到同一个 TARGET_DIR 中，则后安装的包的二进制文件将不会成功，并且有警告信息：
WARNING: Target directory /root/pythonpath/bin already exists. Specify --upgrade to force replacement. 假如现在想要安装 black 和 pipreqs 两个包，先安装 black，那么 pipreqs 可执行文件将不会安装成功，除非使用 &amp;ndash;upgrade 选项，此时，bin/ 目录下的 black 可执行文件将被删除，并替换为 pipreqs 可执行文件。
综上所述：&amp;ndash;target 选项不适合指定为 PYTHONPATH，而是为每个包指定一个独立的目录，并且每个目录下的 bin 目录都要添加到 $PATH 才可以，这是一个很鸡肋的选项。</description></item><item><title>Pipeline</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Pipeline/Pipeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Pipeline/Pipeline/</guid><description>概述 参考：
官方文档 公众号，Promtail Pipeline 日志处理配置 Pipeline 用来处理 tail 到的每一行日志的内容、标签、时间戳。Pipeline 的行为在配置文件的 .scrape_config.pipeline_stages 字段定义。是 Promtail 处理日志必不可少的一个环节。
Pipeline 由一组 stages(阶段) 组成，Loki 将 Stages 分为 4 大类型：
Parsing stages(解析阶段)# 解析每行日志，并从中提取数据。提取的数据可供后面几个阶段使用 Transform stages(转换阶段) # (可省略)转换解析阶段提取到的数据 Actions stages(行动阶段)# (可省略)处理转换阶段转换后的数据。行动包括以下几种 为每行日志添加标签或修改现有标签 更改每行日志的时间戳 改变日志行内容 根据提取到的数据创建 metrics(指标) Filtering stages(过滤阶段) # (可省略)根据指定的条件，保留或删除日志行。 注意：过滤阶段的类型中，有一个名为 match 的过滤阶段。match 是一个通用的阶段，不受阶段顺序影响，在处理日志行之前，match 阶段可以使用 LogQL，来过滤要使用某些阶段进行处理的日志行。 各阶段类型 Parsing stages(解析阶段) 类型： cri # 使用标准的 CRI 日志格式来解析每行日志，并提取数据 docker # 使用标准的 docker 日志文件格式来解析每行日志，并提取数据(Pipeline 的默认行为，该阶段包括 json、labels、timestamp、output 四个阶段) regex # 使用正则表达式从每行日志提取数据 json # 使用 JSON 格式解析每行日志，并提取数据 replace # 使用正则表达式替换数据 Transform stages(转换阶段) 类型： multiline # 多行阶段将多行日志进行合并，然后再将其传递到 pipeline 的下一个阶段。 pack # Packs a log line in a JSON object allowing extracted values and labels to be placed inside the log line.</description></item><item><title>Plugin 配置</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Plugin-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/Plugin-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
GitHub 项目文档，containerd/docs/PLUGINS.md 本篇笔记的记录格式 Containerd 在 TOML 配置文件中，通过 TOML 表的方式来描述一个插件及其具有的功能，效果如下：
[plugins.&amp;quot;PLUGIN&amp;quot;] PLUGIN = TYPE.ID TYPE = io.containerd.NAME.VERSION 所以，一个完整描述插件功能的的 TOML 表应该是这样的：
[plugins.&amp;quot;io.containerd.NAME.VERSION.NAME&amp;quot;.NAME....] 这篇笔记在记录时，则省略前面的通用字符串(plugins.&amp;quot;io.containerd.)，只以最后的关键字来描述，以获得更好的阅读效果。
比如下文中标题一的 [grpc.v1.cri] 下的标题二的 [registry] 下的标题三的 [mirrors]下的 docker.io 镜像仓库的镜像配置，反应到配置文件中，就是这样的：
[plugins] [plugins.&amp;#34;io.containerd.grpc.v1.cri&amp;#34;] [plugins.&amp;#34;io.containerd.grpc.v1.cri&amp;#34;.registry] [plugins.&amp;#34;io.containerd.grpc.v1.cri&amp;#34;.registry.mirrors] [plugins.&amp;#34;io.containerd.grpc.v1.cri&amp;#34;.registry.mirrors.&amp;#34;docker.io&amp;#34;] endpoint = [&amp;#34;https://ac1rmo5p.mirror.aliyuncs.com&amp;#34;] 带 [] 的都是一个一个的表，表只是用来进行分组，表中的每一个 键值对 才是真实的配置。
[gc.v1.scheduler] - 调度器插件 [grpc.v1.cri] - CRI 插件 参考：
GitHub 项目文档，containerd/docs/cri GitHub 项目文档，containerd/docs/cri/config.md-CRI 插件配置指南 注意：
CRI 插件是当 Containerd 作为 CRI 时所使用的配置，所以 ctr、nerdctl 工具在执行某些命令时，有可能不会调用这些配置，就比如其中的 registry 配置，就算配置了，ctr pull 和 nerdctl pull 命令也无法享受到效果。但是使用 crictl 命令是没问题的。 sanbox_image(STRING) # 启动 Pod 时要使用的 Infra 容器。默认值：k8s.</description></item><item><title>Plugins</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/Plugins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/Plugins/</guid><description>概述 参考：
关联文件与配置 在每个项目的根目录下有这么一个目录： ${Project}/.vscode/，所有适用于本项目的插件配置通常都会保存在该目录中。
Debug 插件 参考：
官方文档，用户指南 - Debugging https://www.barretlee.com/blog/2019/03/18/debugging-in-vscode-tutorial/ Debug 插件的默认配置文件名为 launch.json
launch.json https://code.visualstudio.com/docs/editor/debugging#_launchjson-attributes
cwd # 运行程序的工作路径
program # 启动调试器时要运行的可执行文件或文件
args # 运行程序的参数
简单示例 { // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &amp;#34;version&amp;#34;: &amp;#34;0.2.0&amp;#34;, &amp;#34;configurations&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Launch Package&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;go&amp;#34;, &amp;#34;request&amp;#34;: &amp;#34;launch&amp;#34;, &amp;#34;mode&amp;#34;: &amp;#34;auto&amp;#34;, &amp;#34;cwd&amp;#34;: &amp;#34;${workspaceRoot}&amp;#34;, &amp;#34;program&amp;#34;: &amp;#34;cmd/statistics/main.go&amp;#34;, &amp;#34;args&amp;#34;: [&amp;#34;-s&amp;#34;, &amp;#34;dp&amp;#34;] } ] } SFTP 插件 https://github.com/liximomo/vscode-sftp#connection-hopping
新的 SFTP 插件，上面的已不更新。 https://github.com/Natizyskunk/vscode-sftp { &amp;#34;name&amp;#34;: &amp;#34;ansible&amp;#34;, &amp;#34;host&amp;#34;: &amp;#34;172.</description></item><item><title>Plugins</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Plugins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Plugins/</guid><description>概述 参考：
Plugins(插件)
Clickhouse 参考：
GitHub 项目，grafana/clickhouse-datasource https://grafana.com/grafana/plugins/grafana-clickhouse-datasource/ ClickHouse 插件
Macros https://github.com/grafana/clickhouse-datasource?tab=readme-ov-file#macros
Grafana 的 ClickHouse 插件会改变一些 Grafana 中某些变量、函数的用法；还有一些新增加的 Macros 功能可以使用
$__timeFilter(COLUMN_NAME) #
Macro Description 渲染结果示例 $__dateFilter(ColumnName) Replaced by a conditional that filters the data (using the provided column) based on the date range of the panel date &amp;gt;= toDate('2022-10-21') AND date &amp;lt;= toDate('2022-10-23') $__timeFilter(ColumnName) 利用 toDateTime() 函数转换 Grafana 面板时间范围选择器选择时间范围的值 time &amp;gt;= toDateTime(1415792726) AND time &amp;lt;= toDateTime(1447328726) etc.</description></item><item><title>Pod Manifest</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/Pod-Manifest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/Pod-Manifest/</guid><description>概述 参考：
API 文档，单页 官方文档，参考 - Kubernetes API - 工作负载资源 - Pod GitHub 项目，kubernetes/api - 1.31 - core/v1/types.go Pod 是可以在主机上运行的容器的集合。此资源由客户端创建并调度到主机上。
Manifest 中的顶层字段 apiVersion: v1 kind: Pod metadata(metadata) spec(spec) status(status) metadata metadata 字段用来描述一个 Pod 的元数据信息。该字段内容详见通用定义的 ObjectMeta
annotations(STRING) # Pod 注释，不同于 label，仅用于为资源提供元数据 labels(map[STRING]STRING) # Pod 的标签，通过“键值对”的方式定义，可以添加多个标签 KEY: VAL # 比如该键值可以是 run: httpd，标签名是 run，run 的值是 httpd，key 与 val 使用字母，数字，_，-，.这几个字符且以字母或数字开头；val 可以为空。 name(STRING) # Pod 对象名称。必须名称空间唯一。 ownerReferences([]Object) # 该对象所依赖的对象列表，一般由控制器自动生成。也可以手动指定。 spec spec 字段用来描述一个 Pod 应该具有的属性。Pod 中的 spec 字段大体分为如下几类</description></item><item><title>Pod 是如何出现的</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Pod-%E6%98%AF%E5%A6%82%E4%BD%95%E5%87%BA%E7%8E%B0%E7%9A%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Pod-%E6%98%AF%E5%A6%82%E4%BD%95%E5%87%BA%E7%8E%B0%E7%9A%84/</guid><description>概述 参考：
公众号 - 程序员白日梦，一文讲明白-K8S各核心架构组件 https://www.cnblogs.com/ZhuChangwu/p/16441181.html Pod 出现流程中的 Watch 机制的应用 通过 kubectl 命名发起请求。 apiserver 通过对应的 kubeconfig 进行认证，认证通过后将 yaml 中的 pod 信息存到 etcd。 Controller-Manager 通过 apiserver 的 Watch 接口发现了pod信息的更新，执行该资源所依赖的拓扑结构整合，整合后将对应的信息交给 apiserver，apiserver 写到 etcd。 Scheduler 同样通过 apiserver 的 watch 接口更新到 pod 可以被调度，通过算法给 pod 分配节点，并将 pod 和对应节点绑定的信息交给 apiserver，apiserver 写到 etcd。 kubelet 从 apiserver 获取需要创建的 pod 信息，调用 CNI 接口给 pod 创建 pod 网络，调用 CRI 接口去启动容器，调用 CSI 进行存储卷的挂载。 网络，容器，存储创建完成后 pod 创建完成，等业务进程启动后，pod 运行成功。 输入 kubectl run 时会发生什么? 参考:</description></item><item><title>Pose estimation</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose-estimation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Pose-estimation/</guid><description>概述 参考：
Wiki, Pose Wiki, 3D pose estimation 通过 Object detection 检测到对象后，利用 Pose estimation(姿态估计) 确定对象的位置和方向，通常是在三维空间中。姿态通常以变换矩阵的形式在内部存储。术语 pose(姿态) 在很大程度上与 transform(变换) 同义，但 transform 常常包含 缩放，而姿态通常不包含。</description></item><item><title>PostgreSQL SQL</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/PostgreSQL/PostgreSQL-SQL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/PostgreSQL/PostgreSQL-SQL/</guid><description>概述 参考：
官方文档，SQL 语言 TODO: 整理特定于 PostgreSQL 的 SQL
# 创建新表 CREATE TABLE user_tbl(name VARCHAR(20), signup_date DATE); # 插入数据 INSERT INTO user_tbl(name, signup_date) VALUES(&amp;#39;张三&amp;#39;, &amp;#39;2013-12-22&amp;#39;); # 从表中查询数据 SELECT * FROM user_tbl; # 更新数据 UPDATE user_tbl set name = &amp;#39;李四&amp;#39; WHERE name = &amp;#39;张三&amp;#39;; # 删除记录 DELETE FROM user_tbl WHERE name = &amp;#39;李四&amp;#39; ; # 添加栏位 ALTER TABLE user_tbl ADD email VARCHAR(40); # 更新结构 ALTER TABLE user_tbl ALTER COLUMN signup_date SET NOT NULL; # 更名栏位 ALTER TABLE user_tbl RENAME COLUMN signup_date TO signup; # 删除栏位 ALTER TABLE user_tbl DROP COLUMN email; # 表格更名 ALTER TABLE user_tbl RENAME TO backup_tbl; # 删除表格 DROP TABLE IF EXISTS backup_tbl; 函数 与 运算符 参考：</description></item><item><title>PostMan</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/API-%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7/PostMan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/API-%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7/PostMan/</guid><description>概述 参考：
官网 Postman Collection SDK https://www.postmanlabs.com/postman-collection/
pm 是核心对象</description></item><item><title>PotPlayer</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/PotPlayer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/PotPlayer/</guid><description>概述 参考：
官网 Wiki, PotPlayer</description></item><item><title>PowerShell 变量</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/PowerShell/PowerShell-%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/PowerShell/PowerShell-%E5%8F%98%E9%87%8F/</guid><description>概述 参考：
官方文档 - PowerShell，关于-关于变量 官方文档 - PowerShell，关于-关于自动变量 官方文档 - PowerShell，关于-关于首选项变量 官方文档 - PowerShell，脚本-基本概念-环境变量 PowerShell 变量名称不区分大小写，可以包含空格和特殊字符。但是官方推荐尽量避免使用空格和特殊字符，使用起来很麻烦，详见包含特殊字符的变量名称
PowerShell 中的环境变量与局部变量在声明方式和引用方式上有明显不同，这与 Bash 变量 不太一样。举一个非常简单的例子：
PS C:\Users\DesistDaydream&amp;gt; $test_var=&amp;#34;这是一个普通变量&amp;#34; PS C:\Users\DesistDaydream&amp;gt; $test_var 这是一个普通变量 PS C:\Users\DesistDaydream&amp;gt; $env:test_var PS C:\Users\DesistDaydream&amp;gt; $env:test_env_var=&amp;#34;这是一个环境变量&amp;#34; PS C:\Users\DesistDaydream&amp;gt; $test_env_var PS C:\Users\DesistDaydream&amp;gt; $env:test_env_var 这是一个环境变量 局部变量 PowerShell 中有几种不同类型的变量：
User-created variables(用户创建的变量) # 用户创建的变量由用户创建和维护。 默认情况下，仅在 PowerShell 窗口打开时，在 PowerShell 命令行中创建的变量才存在。 关闭 PowerShell 窗口时，将删除变量。 若要保存变量，请将其添加到 PowerShell 配置文件。 还可以在具有全局、脚本或本地范围的脚本中创建变量。 Automatic variables(自动变量) # 自动变量存储 PowerShell 的状态。 这些变量由 PowerShell 创建，PowerShell 会根据需要更改其值，以保持其准确性。 用户无法更改这些变量的值。 例如，变量 $PSHOME 存储 PowerShell 安装目录的路径。 Preference variables(首选项变量) # 首选项变量存储 PowerShell 的用户首选项。 这些变量由 PowerShell 创建，并使用默认值填充。 用户可以更改这些变量的值。 例如，变量 $MaximumHistoryCount 确定会话历史记录中的最大条目数。 自动变量 描述存储 PowerShell 的状态信息的变量。 这些变量由 PowerShell 创建和维护。</description></item><item><title>Printer</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Peripheral/Printer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Peripheral/Printer/</guid><description>概述 参考：
Wiki, Printer Printer(打印机)
3D 打印机 深圳拓竹科技有限公司
https://bambulab.cn/ 模型站点 https://www.thingiverse.com/</description></item><item><title>proc</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/proc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/proc/</guid><description>概述 参考：
Manual(手册)，proc(5) GitHub 项目，torvalds/linux - Documentation/filesystems/proc.rst https://www.kernel.org/doc/html/latest/filesystems/proc.html process information pseudo-filesystem(进程信息伪文件系统，简称 proc)， 提供了内核数据结构的接口。一般挂载到 /proc 目录。一般情况是由操作系统自动挂载的，也可以通过mount -t proc proc /proc命令手动挂载。proc 文件系统中的大多数文件都是只读的，但是有些文件是可写的，用于改变内核参数。
proc 文件系统不用于存储。其主要目的是为硬件，内存，运行的进程和其他系统组件提供基于文件的接口。通过查看相应的 /proc 文件，可以检索许多系统组件上的实时信息。/proc 中的某些文件也可以（由用户和应用程序）操纵以配置内核。
/proc/PID/ - 每个进程自己的独立信息 每个进程在 /proc 下有一个名为自己进程号的目录，该目录记载了该进程相关的 proc 信息。
这些目录的详细用处详见 Process info
/proc/cmdline - 引导系统时，传递给内核的参数 通常通过引导管理器（如 lilo（8）或 grub（8））完成。
/proc/cpuinfo - CPU 信息 如 cpu 的类型、制造商、 型号和性能等。
/proc/devices - 当前运行的核心配置的设备驱动的列表 /proc/dma - 显示当前使用的 dma 通道 /proc/filesystems - 内核可以支持的文件系统列表 /proc/interrupts - 系统中断统计信息 详见：Interrupts(中断)
这用于记录每个 IO 设备每个 CPU 的中断数。从 Linux 2.</description></item><item><title>Process info</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Process-info/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Process-info/</guid><description>概述 参考：
Linux 中有多种途径可以获取进程信息
/proc/PID/ 目录 etc. /proc/PID/ 参考：
https://github.com/torvalds/linux/blob/v5.19/Documentation/filesystems/proc.rst#11-process-specific-subdirectories [!Tip] 这下面的文件或目录的用途和信息，都有对应的 Manual，Manual 的名字是 proc_pid_XXX 的形式。e.g. stat 文件的 Manual 是 proc_pid_stat(5)
每个进程在 /proc/ 目录下有一个名为自己进程号的目录，该目录记载了该进程相关的 proc 信息。
./cgroup - 进程所属的控制组信息 详见 Cgroup
./cmdline - 该进程的完整命令 除非进程是僵尸和内核态进程。在后一种情况下，这个文件中什么也没有：也就是说，对这个文件的读取将返回 0 个字符。命令行参数在这个文件中以一组字符串的形式出现，用空字节(&amp;rsquo;\0&amp;rsquo;)隔开，在最后一个字符串之后还有一个空字节。 把这个文件看作是进程希望你看到的命令行。 ./exe - 具有该 PID 的实际运行的程序的绝对路径。是一个符号链接 ./fd/ - 其中包含 PID 进程打开的每个文件的一个条目 该条目由其文件描述符命名，并且是指向实际文件的符号链接。 因此，0 是标准输入，1 是标准输出，2 是标准错误，依此类推。详解见：File Descriptor(文件描述符) ./fdinfo/ - 其中包含 PID 进程打开的每个文件的一个条目，该条目由其文件描述符命名 该目录中的文件仅由进程所有者读取。 可以读取每个文件的内容以获得有关相应文件描述符的信息。 内容取决于相应文件描述符所引用的文件类型。详解见：File Descriptor(文件描述符)
./maps - 进程的内存映射信息 ~]# cat /proc/1751/maps 00400000-00401000 r-xp 00000000 fd:01 100897359 /opt/java/jdk1.</description></item><item><title>Prometheus-adapter</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/Prometheus-adapter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/Prometheus-adapter/</guid><description>概述 参考:
GitHub 项目，kubernetes-sigs/prometheus-adapter 该项目从 DirectXMan12/k8s-prometheus-adapter 移动到 kubernetes-sigs/prometheus-adapter 主要特性： 一、adapter 在成功注册 API 之后，可以通过 Prometheus 实现 custom.metrics.k8s.io API 和 metrics.k8s.io API 的功能 adaper 可以替换掉 metrics server 来实现其功能。adapter 要想实现 kubectl top node/pod 命令的功能，则需要 adapter 通过查询 Prometheus 来获取数据完成，这需要 prometheus 提前获取某些数据来支撑 adapter 得查询，而查询语句则是根据 adapter 的配置文件中 resourceRules 配置环境中的规则来指定。
其中 kubectl top node 如果查询语句查询结果为空，则在执行命令查询时会报错：error: metrics not available yet 其中 kubectl top pod 如果查询语句查询结果为空，则在执行命令查询时会报错：No resources found 二、adapter 可以根据 prometheus 提供的核心 metrics 数据(比如 CPU 使用率等)或者自定义 metrics 数据，来自动实现[HPA](4.Controller(控制器).md 容器编排系统/4.Controller(控制器).md)功能。</description></item><item><title>Promise</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Promise/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Promise/</guid><description>概述 参考：
B 站 up-思学堂，5 分钟彻底学会使用 Promise，你真的懂 Promise 吗？ https://www.runoob.com/w3cnote/javascript-promise-object.html Promise 是一个对象，它代表了一个异步操作的最终完成或者失败。
一个 Promise 必然处于以下几种状态之一：
pending(待定) # 初始状态，既没有被兑现，也没有被拒绝。 fulfilled(已兑现) # 意味着操作成功完成。 rejected(已拒绝) # 意味着操作失败。 Promise 的链式调用 Promise.prototype.then()、Promise.prototype.catch() 和 Promise.prototype.finally() 方法用于将进一步的操作与已敲定的 Promise 相关联。由于这些方法返回 Promise，因此它们可以被链式调用。
.then() 方法最多接受两个参数；第一个参数是 Promise 兑现时的回调函数，第二个参数是 Promise 拒绝时的回调函数。每个 .then() 返回一个新生成的 Promise 对象，这个对象可被用于链式调用，例如：
const myPromise = new Promise((resolve, reject) =&amp;gt; { setTimeout(() =&amp;gt; { resolve(&amp;#34;foo&amp;#34;); }, 300); }); myPromise .then(handleFulfilledA, handleRejectedA) .then(handleFulfilledB, handleRejectedB) .then(handleFulfilledC, handleRejectedC); 方法 Promise.resolve() 方法
Promise.reject() 方法</description></item><item><title>PromQL Functions</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/PromQL-Functions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/PromQL-Functions/</guid><description>概述 参考：
官方文档，Prometheus - 查询 - 函数 fuckcloudnative.io 公众号 - k8s 技术圈，PromQL 查询之 rate 函数的使用 Prometheus Extrapolation 原理解析，delta、increase 函数的解析 Prometheus 提供了其它大量的内置函数，可以对时序数据进行丰富的处理。在代码 promql/functions.go 中可以看到当前所有可用的 PromQL 函数。
函数的语法 某些函数有默认的参数，例如：year(v=vector(time()) instant-vector)。这是一个标准的函数结构 函数名(形参 形参的类型)
instant-vector # 表示参数类型，该类型表示一个瞬时向量表达式 range-vector 表示一个范围向量表达式 v # 表示这是 year 函数中，instant-vector 类型的形参 vector(time()) # 表示参数 v 的默认值。 比如 absent(up) 这个表达式中，up 就是传递给参数 v 的值，是一个瞬时向量表达式。absent 表示该函数的功能。
Prometheus 内置函数 absent() - 判断表达式是否可以获取到序列 absent(v instant-vector) 返回值有两种
空向量 # 如果传递给它的向量参数具有样本数据，返回空向量，就是不返回任何时间序列的意思。 1 # 如果传递的向量参数没有样本数据，则返回不带度量指标名称且带有标签的时间序列，且样本值为 1。 效果如下：
absent() 函数特别适用于告警，用于判断单条时间序列（给定 Name 与 Label 组合成的 Metrics）是否存在。</description></item><item><title>PromQL Operators(运算符)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/PromQL-Operators%E8%BF%90%E7%AE%97%E7%AC%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/PromQL-Operators%E8%BF%90%E7%AE%97%E7%AC%A6/</guid><description>概述 参考：
官方文档，Prometheus-查询-运算符 Binary Operators(二元运算符) PromQL 支持基本的 逻辑 和 算术 运算符。 对于两个即时向量之间的运算，可以修改匹配行为。
使用 PromQL 除了能够方便的按照查询和过滤时间序列以外，PromQL 还支持丰富的运算符，用户可以使用这些运算符对进一步的对事件序列进行二次加工。这些运算符包括：数学运算符，逻辑运算符，布尔运算符等等。
详见《Binary Operators(二元运算符)》章节
Vector Matching(向量匹配) 向量与向量之间进行运算操作时会基于默认的匹配规则：
右边向量表达式获取到的时间序列与左边向量表达式获取到的时间序列的标签进行一一匹配，完全匹配到的两个时间序列进行运算，没有匹配到的直接丢弃 说白话就是，两条时间序列要想进行二元运算，他们的标签必须完全相同才可以。
这时就产生问题了，如果我想让两条标签不同的序列进行二元运行，怎么办呢？这时候就需要使用 Vector Matching(向量匹配) 来扩展二元运算的功能。通过 Vector Matching，我们可以根据标签的匹配规则，选择出来符合要求的时间序列进行二元运算。
在 PromQL 中有多种典型的匹配模式：一对一(one-to-one)、多对一(many-to-one)、一对多(one-to-many)。
向量匹配常用于生成新的时间序列
一对一匹配 一对一匹配模式会从操作符两边表达式获取的瞬时向量依次比较并找到唯一匹配(标签完全一致)的样本值，然后进行二元运算。
Syntax(语法) &amp;lt;VectorExpr1&amp;gt; &amp;lt;BinaryOperators&amp;gt; ignoring(LabelList) &amp;lt;VectorExpr2&amp;gt; &amp;lt;VectorExpr1&amp;gt; &amp;lt;BinaryOperators&amp;gt; on(LabelList) &amp;lt;VectorExpr2&amp;gt; on 与 ignoring 关键字会将其左右两侧表达式中标签进行匹配，根据其指定的 LabelList 来匹配标签，匹配到的序列将会执行二元运算
ignoreing(LabelList) # 匹配不包含 LabelList 的序列。 on(LabelList) # 匹配包含 LabelList 的序列。 例如当存在样本：
method_code:http_errors:rate5m{method=&amp;#34;get&amp;#34;, code=&amp;#34;500&amp;#34;} 24 method_code:http_errors:rate5m{method=&amp;#34;get&amp;#34;, code=&amp;#34;404&amp;#34;} 30 method_code:http_errors:rate5m{method=&amp;#34;put&amp;#34;, code=&amp;#34;501&amp;#34;} 3 method_code:http_errors:rate5m{method=&amp;#34;post&amp;#34;, code=&amp;#34;500&amp;#34;} 6 method_code:http_errors:rate5m{method=&amp;#34;post&amp;#34;, code=&amp;#34;404&amp;#34;} 21 method:http_requests:rate5m{method=&amp;#34;get&amp;#34;} 600 method:http_requests:rate5m{method=&amp;#34;del&amp;#34;} 34 method:http_requests:rate5m{method=&amp;#34;post&amp;#34;} 120 使用 PromQL 表达式：</description></item><item><title>Promtail 配置</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Promtail-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Promtail-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
Loki 官方文档，发送数据 - Promtail - 配置 GitHub 官方文档 promtail.yaml 配置文件详解 Promtail 在 YAML 文件（通常称为 config.yaml）中进行配置，该文件包含 Promtail 运行时信息，抓取到的日志存储位置，以及抓取日志的行为
顶级字段
global(global) # 影响所有目标的全局设置。 server(server) # 配置 promtail 程序运行时行为。如指定监听的ip、port等信息。 clients(clients) # 配置 Promtail 如何连接到 Loki 的多个实例，并向每个实例发送日志。 Note：如果其中一台远程Loki服务器无法响应或发生任何可重试的错误，这将影响将日志发送到任何其他已配置的远程Loki服务器。 发送是在单个线程上完成的！ 如果要发送到多个远程Loki实例，通常建议并行运行多个Promtail客户端。 positions(positions) # positions 文件用于记录 Promtail 发现的目标。该字段用于定义如何保存 postitions.yaml 文件。 Promtail 发现的目标就是指日志文件。 scrape_configs(scrape_configs) # 配置 Promtail 如何发现日志文件，以及如何从这些日志文件抓取日志。 limits_config(limits_config) # 为 Promtail 配置全局的限制功能 target_config(target_config) # Configures how tailed targets will be watched. options(options_config) # Configures additional promtail configurations tracing(tracing_config) # Configures tracing support server clients positions positions 文件用于记录 Promtail 发现的目标。该字段用于定义如何保存 postitions.</description></item><item><title>promtool</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/promtool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/promtool/</guid><description>概述 参考：
官方文档，命令行工具 - promtool https://blog.51cto.com/u_13236892/5968043 promtool 是 Prometheus 一个命令行工具，用以管理、检查 Promethus，包括 规则配置、etc. 。
[!Warning] 截至 2024-07-24 还不够完善，有些功能无法添加认证能力，对以添加认证的 Prom 无能为力。
Syntax(语法) Command Description check 检查资源的有效性。比如配置文件是否正确、etc. query 运行 PromQL 获取查询结果 debug 获取 Debug 信息 push Push to a Prometheus server. test 单元测试 tsdb Run tsdb commands. promql PromQL 格式化与编辑器 [!Notes] 截至 2024-08-01，&amp;ndash;http.config.file 选项的格式在 https://github.com/prometheus/common/blob/v0.55.0/config/http_config.go#L299 ，由 LoadHTTPConfigFile() 函数解析 HTTPClientConfig 结构体。与 prometheus 的 &amp;ndash;web.config.file 配置格式并不一致
格式像这样：
basic_auth: username: myusername password: mypassword query instant # 即时向量查询 range # 范围向量查询 range 范围向量查询。默认返回 302 个样本，当前时间为结束时间，当前时间的前 5 分钟是开始时间，每秒 1 个样本。</description></item><item><title>Provisioning</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-Configuration/Provisioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-Configuration/Provisioning/</guid><description>概述 参考：
官方文档，管理 - Provisioning Grafana 在一开始，只能通过 Web 页面(也就是 API)来配置 DataSources(数据源) 和 Dashboard(仪表盘)。这样做有一个缺点，就是无法提前加载数据源和仪表盘。
比如现在有这么一种场景：我想新搭建一个 Grafana，并且包含一些数据源和仪表盘，正常情况是启动服务后，在 Web 页面导入和创建。
此时就会有个问题：如果数据源和仪表盘有几十个，逐一导入和创建势必会消耗大量人力，也无法实现自动话。
所以：有没有一种办法，可以在启动 Grafana 之前，就能直接加载这些数据呢？
Grafana 从 v5.0 版本中，决定通过一个 Provisioning(配置供应系统) 来解决上述问题。这个系统可以通过一系列的配置文件，让 Grafana 启动时加载他们，可以瞬间让启动好的 Grafana 就具有一定数量的数据源和仪表盘。这种行为使得 GitOps 更自然。这种思路除了可以用在数据源和仪表盘上以外，还可以扩展，比如提前配好用户信息、告警信息等等。
Grafana 的 Provisioning(配置供应系统) 可以提供如下能力，每种能力使用一个目录
Notes: 可以通过 grafana.ini 的 .paths.provisioning 字段修改 ${ProvisioningDir} 的值，默认值: /etc/grafana/provisioning/
能力 目录 用途 Data sources(数据源) ${ProvisioningDir}/dashboards/ 预配置 Grafana 数据源 Plugins(插件) ${ProvisioningDir}/plugins/ 预配置 Plugins Dashboards(仪表盘) ${ProvisioningDir}/dashboards/ 预配置 Dashboard Alerting(警报) ${ProvisioningDir}/alerting/ 预配置 Grafana Alerting [!Tip] 通常默认情况下，从目录中读取所有 .</description></item><item><title>ProxmoxVE</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/ProxmoxVE/ProxmoxVE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/ProxmoxVE/ProxmoxVE/</guid><description>概述 参考：
官网 Proxmox Virtual Environment(Proxmox 虚拟环境) 是一个基于QEMU/KVM 和 LXC 的开源服务器虚拟化管理解决方案。您可以使用易于使用的集成 Web 界面或 CLI 来管理虚拟机、容器、高可用集群、存储和网络。 Proxmox VE 代码已获得 GNU Affero 通用公共许可证版本 3 的许可。该项目由 Proxmox Server Solutions GmbH 开发和维护。</description></item><item><title>Proxy</title><link>https://desistdaydream.github.io/docs/Web/Proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Proxy/</guid><description>概述 参考：
Wiki, Proxy_server 在计算机网络中，Proxy server(代理服务器) 是一种服务器应用程序，充当资源请求的客户端和提供该资源的服务器之间的中介。
Proxy(代理) 有很多种理解，还可以表示一种服务、一个概念。
Proxy 服务在整个 IT 圈子中非常常见，隧道、VPN 等等都可以看做是代理的一种。
Forward/Reverse proxy Forward proxy(正向代理) 与 Reverse proxy(反向代理)。
正向代理 反向代理 代理对象 客户端 服务端 隐藏对象 客户端 IP 服务端 IP 主要用途 突破限制、匿名访问 负载均衡、安全防护、加速 典型工具 Clash, Squid, Shadowsocks Nginx, HAProxy, Cloudflare [!Note] 在 Web 中还有一个 User-Agent 的概念，Agent 可以看作是一种代理，只不过代理形式与 Proxy 有点不太一样，Agent 更强调作为用户的代理人执行操作。虽然都是代替真实人类发起网络请求，Agent 更靠近人类。
比如我可以这么描述：DesistDaydream 通过 Chrome 这个 Agent，利用 Clash 这个 Forward proxy 访问 Google 网站，Google 网站使用 Nginx 这个 Reverse proxy 返回其站点的资源给我的 Agent 后，由 Agent 展现给我。</description></item><item><title>psql 命令</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/PostgreSQL/psql-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/PostgreSQL/psql-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方文档 psql 是 PostgreSQL 的交互式终端，可以看作是 PostgreSQL 的 REPL。
psql 中可以执行有多种类型的命令
Meta-Commands SQL Syntax(语法) psql [OPTION] [DBNAME [USERNAME]]
OPTIONS
连接数据库相关选项 -U, &amp;ndash;username USERNAME # 使用指定的用户连接数据库。默认值: 当前 Shell 环境的用户。 -h, &amp;ndash;host HOSTNAME # 指定 PostgreSQL 服务端所在的 HOSTNAME，可以是 IP 或 Domain。如果该以 \ 开头，则将其用作 Unix 域套接字的目录。 -p, &amp;ndash;port PORT # 指定 PostgreSQL 服务端监听的 TCP 端口或本地 Unix 域套接字文件扩展名。默认为 PGPORT 环境变量的值，默认值: 5432。 SQL 执行相关 -t, &amp;ndash;tuples-only # 关闭列名和结果行计数页脚等的打印。这相当于 \t 或 \pset tuples_only Meta-Commands \h：查看SQL命令的解释，比如 \h select。 \?</description></item><item><title>Puppeteer</title><link>https://desistdaydream.github.io/docs/Web/Browser-automation/Puppeteer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser-automation/Puppeteer/</guid><description>概述 参考：
GitHub 项目，puppeteer/puppeteer 官网 中文文档？ 10分钟快速上手爬虫之Puppeteer Puppeteer 是一个 Node.js 库，它提供了一个高级 API 来通过 DevTools 协议控制 Chrome/Chromium。 Puppeteer 默认以无头模式运行，但可以配置为在完整（“有头”）Chrome/Chromium 中运行。
注意：Puppeteer 并不是一个 WebDriver 的实现。
Puppetter 安装 pnpm install puppetter
安装 Puppetter 时，会在 ${HOME}/.cache/puppeteer/ 目录下安装 Chrome 程序。
注意：若是 pnpm 安装，则需要删除原始的文件，只取消项目下的链接后执行 pnpm install puppetter 并不会在没有 Chrome 程序时执行下载逻辑。
用法 元素 https://www.cnblogs.com/totoro-cat/p/11310832.html
定位元素返回 ElementHandle 实例，然后使用 ElementHandle 下的方法处理元素</description></item><item><title>Python 爬虫工具</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Python-%E7%88%AC%E8%99%AB%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/Python-%E7%88%AC%E8%99%AB%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
2022 Python Web 爬虫武器库盘点 curl_cffi: 支持原生模拟浏览器 TLS/JA3 指纹的 Python 库
HTTP 请求 Requests Requests 是从 Python 2 就开始流行的 HTTP 请求库，至今已有十一年历史。当初 Python 内置的 http 库过于底层，用起来非常麻烦，Requests 的出现像救世主一样，slogan 就是“http for humans”，标版自己简单好用人性化。Requests 也确实对得起自己的 solgan，至少提供了以下便捷功能：
对常用的 HTTP 请求方法进行封装，可以非常方便的设置 url 参数，表单参数。 可以自动探测响应内容，自动对响应进行解码和解压缩。 自动维护长连接和连接池。 多文件上传。 自动处理分块响应。 会话和 cookie 持久化。 支持 HTTP/HTTPS 代理。 特别是会话维持、 cookie 持久化、设置代理，是写爬虫必须的。有段时间，知乎上 Python 话题非常火，Python 话题下最火的子话题就是 “Python 爬虫”，而 “Python 爬虫”最火的子话题就是 Requests。
但随着 Python 3.6、3.7、3.8、3.9、3.10 的发布，Python 社区对协程、Type Hint 的支持越来越成熟，同时有部分网站开始使用 HTTP/2 协议，Requests 对这些都不支持。从 2011 年开始，Requests 就显得不那么现代了。</description></item><item><title>Python 网络编程</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Python-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Python-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</guid><description>概述 参考：
Web 框架 Flask 框架与 Django 框架比较老
FastAPI 框架与 Tornado 框架相对较新
Flask 参考:
GitHub 项目，pallets/flask Django 参考:
GitHub 项目，django/django FastAPI https://github.com/fastapi/fastapi
Tornado https://github.com/tornadoweb/tornado
Flask 与 Django 来源于： ChatGPT
Flask 和 Django 都是 Python 语言中常见的 web 框架，用于开发 web 应用程序。以下是 Flask 和 Django 的比较：
Flask Flask 是一个轻量级的 web 框架，它可以快速构建 web 应用程序 Flask 的代码风格非常灵活，可以以各种方式编写代码 它没有内置的数据库抽象层、表单验证和身份验证 Flask 可以更好地用于小型和中型的 web 应用程序 Django Django 是一个全功能的 web 框架，用于快速开发 web 应用程序 Django 提供许多构建 web 应用程序所需的功能，如内置的 ORM（对象关系映射器）、表单验证、身份验证等 它适用于大型 web 应用程序，可以更好地用于复杂的项目 如何选择 Flask 还是 Django？ 以下是一些考虑因素，可以帮助您决定使用 Flask 还是 Django：</description></item><item><title>Python 虚拟环境</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Python-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/Python-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/</guid><description>概述 参考：
官方文档，Python 教程 - 虚拟环境和包 Python 没有 go.mod 与 go.sum 这种文件来管理第三方依赖模块的版本。假如现在只有一个 3.10 版本的 Python，那么所有项目的依赖模块都会被安装到 site-packages 目录中，且 site-packages 目录中保存只能保存唯一一个版本的依赖。若项目 A 需要 模块 C 的 1.0 版本，项目 B 需要 模块 C 的 2.0 的版本，这时候就会产生冲突，若同时运行这两个项目，将有其中一个无法正常运行。因为只要安装 C 1.0，当前环境的 C 2.0 就会被覆盖。
为了解决上述第三方模块的多版本管理问题，Python 想了一个类似 JS 的 node_modules 方案。。称为 virtual environment(虚拟环境，简称 venv)。就相当于为每个项目建立一个独立的 Python 环境。。。。
但是。。。另一个可怕的问题就是。。。。如果多个项目依赖相同版本的模块。。那么。。就要安装很多遍。。。。。唉。。。。。。
TODO: 如何解决这个问题？
想要使用 Python 虚拟环境，需要先安装一个名为 venv 的内置模块（这个模块是在 CPyhon 的源码中的，在 sys 库或用pip命令里看不到），但是有的发行版并没有随着 Python 一起安装，比如 Ubuntu，需要手动安装 apt install python3.10-venv
创建虚拟环境 假设我们现在有一个项目，放在单独的目录中，project-venv-demo，想要让这个项目有独立的依赖环境，那就执行如下命令即可
# 创建一个虚拟环境目录 ~]# python3 -m venv /root/tmp/project-venv-demo ~]# ls /root/tmp project-venv-demo # 激活虚拟环境 # source /root/tmp/project-venv-demo/bin/activate (project-venv-demo) ~]# 此时的 Shell 中的提示符前面出现了 (project-venv-demo)，这就说明当前已在 Python 的虚拟环境那种了。此时的虚拟环境中将是已安装的特定 Python 版本</description></item><item><title>PyTorch</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PyTorch/</guid><description>概述 参考：
GitHub 项目，pytorch/pytorch 官网 PyTorch 是一个使用 Torch 构建的 Python 包，提供两个高级特性：
带有强大 GPU 加速的张量计算（类似于 NumPy） 基于计算图的自动微分系统构建的深度神经网络 安装 PyTorch 参考：
官方文档，开始 安装 PyTorch 分为使用 GPU 和 CPU 两种，比如：
CPU pip3 install torch torchvision torchaudio GPU pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 GPU 版的 PyTorch 依赖 CUDA
Note: 如果我们想要使用 GPU 但是却安装的 CPU 版的 PyTorch，将会报错：Torch not compiled with CUDA enabled。说白了就是下载的 PyTorch 不是在 CUDA 环境下编译的，无法处理 CUDA 的请求。
[!Tip] 若安装速度太慢，可以在 pip install 命令中看到 Downloading 的 URL，手动下载，比如 https://download.</description></item><item><title>qemu-img</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/qemu-img/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/qemu-img/</guid><description>概述 参考：
官方文档，工具 - QEMU 磁盘镜像工具 管理 VM image(虚拟机的镜像) 文件。qemu-img 工具可以创建、转换和修改 image 文件。所有 QEMU 支持的格式都可以处理
注意：不要使用 qemu-img 修改正在运行的虚拟机或者任何其他进程正在使用的 image 文件。
Syntax(语法) qemu-img [Standard OPTIONS] COMMAND [COMMAND OPTIONS]
Standard OPTIONS -U, &amp;ndash;force-share # -f(STRING) # 指定第一个镜像文件的格式。默认值: raw -F(STRING) # 指定第二个镜像文件的格式。默认值: raw COMMAND check [-q] [-f fmt] [&amp;ndash;output=ofmt] [-r [leaks | all]] [-T src_cache] filename create [-q] [-f fmt] [-o options] filename [size] commit [-q] [-f fmt] [-t cache] filename compare [-f fmt] [-F fmt] [-T src_cache] [-p] [-q] [-s] filename1 filename2 convert [-c] [-p] [-q] [-n] [-f fmt] [-t cache] [-T src_cache] [-O output_fmt] [-o options] [-s snapshot_name] [-S sparse_size] filename [filename2 [&amp;hellip;]] output_filename info [-f fmt] [&amp;ndash;output=ofmt] [&amp;ndash;backing-chain] filename map [-f fmt] [&amp;ndash;output=ofmt] filename snapshot [-q] [-l | -a snapshot | -c snapshot | -d snapshot] filename rebase [-q] [-f fmt] [-t cache] [-T src_cache] [-p] [-u] -b backing_file [-F backing_fmt] filename resize [-q] filename [+ | -]size amend [-q] [-f fmt] [-t cache] -o options filename check - 检查 VM 镜像文件 qemu-img check [-q] [-f fmt] [&amp;ndash;output=ofmt] [-r [leaks | all]] [-T src_cache] filename</description></item><item><title>qemu-system</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/qemu-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/KVM_QEMU-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/qemu-system/</guid><description>概述 参考：
官方 Manual(手册)，qemu-system-x86_64 官方文档，系统模拟-调用（这个其实也是 man 手册） qemu-system 的名称在不同的 CPU 架构上有不同的名称：
amd64 架构 qemu-system-x64_64 arm64 架构 qemu-system-aarch64 qemu-system-arm 注意：在 CentOS 系统中，该二进制文件的名字是 qemu-kvm，是一个在 /usr/local/bin/qemu-kvm 这个位置并指向 /usr/libexec/qemu-kvm 的软链接
Syntax(语法) qemu-system-x86_64 [OPTIONS] [DISK_IMAGE]
DISK_IMAGE 是 IDE 硬盘 0 的原始硬盘映像。有些目标不需要磁盘映像。
Standard OPTIONS(标准选项) https://www.qemu.org/docs/master/system/invocation.html#hxtool-0
-name #
-m # 指定内存大小，单位是 M
-cpu MDOEL # 设定要模拟的 CPU 类型
-smp [,cores=核心数][,threads=线程数][,sockets=有几个 CPU 插槽][,maxcpus=指定正在使用的 CPU 数] # 设定 vCPU 数量
-M # 指定要模拟的主机类型,可以使用 qemu-system-x86_64 -M ? 命令查看所支持的所有可模拟的主机类型
-boot [order=DRIVES][,once=DRIVES][,menu=on|off] # 定义启动设备的引导次序</description></item><item><title>Querying API</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/Querying-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/Querying-API/</guid><description>概述 参考：
官方文档，Prometheus - 查询-HTTP API OpenAPI Querying API 可以查询 Prometheus 的 运行时配置、时间序列数据、运行时状态 等等。官方称之为 HTTP API
在 HTTP API 中使用 PromQL Prometheus 当前稳定的 HTTP API 可以通过 /api/v1 访问。
API 响应格式 Prometheus API 使用了 JSON 格式的响应内容。 当 API 调用成功后将会返回 2xx 的 HTTP 状态码。
反之，当 API 调用失败时可能返回以下几种不同的 HTTP 状态码：
404 Bad Request # 当参数错误或者缺失时。 422 Unprocessable Entity # 当表达式无法执行时。 503 Service Unavailiable # 当请求超时或者被中断时。 这类 API 有一个统一的返回体
{ // 本次请求的结果 &amp;#34;status&amp;#34;: &amp;#34;success&amp;#34; | &amp;#34;error&amp;#34;, // 本次请求所返回的具体数据，就是一个PromQL的查询结果 &amp;#34;data&amp;#34;: &amp;lt;data&amp;gt;, // 当 status 值为 error 时，会显示这两个字段。data 字段仍然会保留一些附加数据。 &amp;#34;errorType&amp;#34;: &amp;#34;&amp;lt;string&amp;gt;&amp;#34;, &amp;#34;error&amp;#34;: &amp;#34;&amp;lt;string&amp;gt;&amp;#34;, // 当执行http请求出现warnings时，会显示这个字段。data 字段中仍然会有数据 &amp;#34;warnings&amp;#34;: [&amp;#34;&amp;lt;string&amp;gt;&amp;#34;] } status 与 data 字段是默认包含的。当 status 值不是 success 时，会出现其他字段。</description></item><item><title>QUIC</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/UDP/QUIC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/UDP/QUIC/</guid><description>概述 参考：
RFC 9000 - QUIC: A UDP-Based Multiplexed and Secure Transport Wiki, QUIC 尽管其名称最初被提议为“Quick UDP Internet Connections”的缩写，但在 IETF 中使用的 QUIC 一词并不是缩写词；它只是协议的名称。QUIC 提高了当前使用传输控制协议 (TCP) 的面向连接的 Web 应用程序的性能。它通过使用 UDP 在两个端点之间建立大量多路复用连接来实现这一点，并且旨在为许多应用程序在传输层淘汰 TCP，从而为该协议赢得了偶尔的绰号“TCP/2”
如何用 UDP 实现可靠传输？ 参考：
原文：支付宝二面：如何用 UDP 实现可靠传输？ 自 2015 年以来，QUIC 协议开始在 IETF 进行标准化并被国内外各大厂商相继落地。鉴于 QUIC 具备“0RTT 建联”、“支持连接迁移”等诸多优势，并将成为下一代互联网协议：HTTP3.0 的底层传输协议，蚂蚁集团支付宝客户端团队与接入网关团队于 2018 年下半年开始在移动支付、海外加速等场景落地 QUIC。
本文是综述篇，介绍QUIC 在蚂蚁的整体落地情况。
之所以是综述，是因为 QUIC 协议过于复杂，如果对标已有的协议，QUIC 近似等于 HTTP + TLS +TCP，无法详细的毕其功于一役，因此我们通过综述的方式将落地的重点呈现给读者，主要介绍如下几个部分：
QUIC背景：简单全面的介绍下 QUIC 相关的背景知识 方案选型设计：详细介绍蚂蚁的落地方案如何另辟蹊径、优雅的支撑 QUIC 的诸多特性，包括连接迁移等 落地场景：介绍 QUIC 在蚂蚁的两个落地场景，包括：支付宝客户端链路以及海外加速链路 几项关键技术：介绍落地 QUIC 过程中核心需要解决的问题，以及我们使用的方案，包括：“支持连接迁移”、“提升 0RTT 比例&amp;quot;， &amp;ldquo;支持 UDP 无损升级”以及“客户端智能选路” 等 几项关键的技术专利 本文也是 QUIC 协议介绍的第一篇，后续我们会把更多的落地细节、体验优化手段、性能优化手段、安全与高可用、QUIC 新技术等呈现给大家。</description></item><item><title>Rack</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Rack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Rack/</guid><description>概述 参考：
https://en.wikipedia.org/wiki/19-inch_rack https://en.wikipedia.org/wiki/Rack_unit 机柜单元，所以 1U 就是 1 unit，指 1单元 Rack(机柜)
A full-height rack cabinet 全高机架柜</description></item><item><title>Rancher</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher/</guid><description>概述 参考：
官方文档：https://rancher.com/ Rancher 是为使用容器的公司打造的容器管理平台。Rancher 简化了使用 Kubernetes 的流程，开发者可以随处运行 Kubernetes（Run Kubernetes Everywhere），满足 IT 需求规范，赋能 DevOps 团队。
Rancher 在现阶段可以看作是一个解决方案，是一套产品的统称，这套产品包括如下几个：
K3S # 用于运行高可用 Rancher 的底层平台。是一个轻量的 kubernetes，一个 k3s 二进制文件即可包含所有 kubernetes 的主要组件。 Rancher Server # Rancher 管理程序，常部署于 k3s 之上，用来管理其下游 k8s 集群。 RKE # Rancher 创建的 kubernetes 集群。是一个可以通过名为 rke 的二进制文件以及一个 yaml 文件，即可启动 kubernetes 集群的引擎。RKE 与 kubernetes 的关系，类似于 docker 与 containerd 的关系。 Rancher Server 介绍 Rancher Server 由认证代理(Authentication Proxy)、Rancher API Server、集群控制器(Cluster Controller)、数据存储(比如 etcd、mysql 等)和集群代理(Cluster Agent) 组成。除了 Cluster Agent 以外，其他组件都部署在 Rancher Server 中。(这些组件都集中在一起，一般可以通过 docker 直接启动一个 Rancher Server。)</description></item><item><title>Rancher 部署与清理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</guid><description>概述 参考：
常见问题：https://www.bookstack.cn/read/rancher-2.4.4-zh/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98.md 快速部署体验 docker run -d --name=rancher-server --restart=unless-stopped \ -p 60080:80 -p 60443:443 \ -v /opt/rancher:/var/lib/rancher \ --privileged \ rancher/rancher:v2.5.3 如果想让 rancher 可以验证外部 https 的自建 CA 证书，需要在启动前将证书导入 rancher-server 中，效果如下：
参考链接： https://rancher.com/docs/rancher/v2.x/en/installation/resources/chart-options/#additional-trusted-cas
https://rancher.com/docs/rancher/v2.x/en/installation/other-installation-methods/single-node-docker/advanced/#custom-ca-certificate
docker run -d --name=rancher-server --restart=unless-stopped \ -p 60080:80 -p 60443:443 \ -v /opt/rancher:/var/lib/rancher \ -v /host/certs:/container/certs \ -e SSL_CERT_DIR=&amp;#34;/container/certs&amp;#34; \ --privileged \ rancher/rancher:latest 在宿主机的 /host/certs 目录中存放要导入的证书，比如可以把 harbor 的证书与私钥放入该目录中，这样 rancher 就可以添加 https 的 harbor 仓库了
还可以传递 CATTLE_SYSTEM_DEFAULT_REGISTRY 环境变量，让 rancher 内部使用私有镜像地址。比如</description></item><item><title>Rancher 配置</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/Rancher-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
Rancher Server URL 的修改
当 Rancher Server URL 变更后(比如从 40443 变到 60443)，则还需要连带修改以下几部分
Rancher Web 页面最上面的标签，进入系统设置，修改server-url。
k8s 集群中，修改 cattle-system 名称空间中，名为cattle-credentials-XXX的 secret 资源中的 .data.url 字段的值，这个值是用 base64 编码的。
echo -n &amp;ldquo;https://X.X.X.X:60443&amp;rdquo; | bas64 ，通过该命令获取编码后的 url，然后填入 .data.url 字段中
k8s 集群中，修改 cattle-cluster-agent-XX 和 cattle-node-agent-XX 这些 pod 的 env 参数，将其中的 CATTLE_SERVER 的值改为想要的 URL。
cattle-node-agent 在 2.5.0 版本之后没有了，就不用改了。
导入集群的 yaml 文件位置
打开 https://RancherIP/v3/cluster/集群ID/clusterregistrationtokens 页面
在 data 字段下，可以看到获取 yaml 文件的 URL，可能会有多组，一般以时间最新的那组为准。</description></item><item><title>RBAC</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Access-Control/RBAC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Access-Control/RBAC/</guid><description>概述 参考：
Wiki, RBAC 基于角色的权限访问控制（Role-Based Access Control）作为传统访问控制（自主访问，强制访问）的有前景的代替受到广泛的关注。在 RBAC 中，权限与角色相关联，用户通过成为适当角色的成员而得到这些角色的权限。这就极大地简化了权限的管理。在一个组织中，角色是为了完成各种工作而创造，用户则依据它的责任和资格来被指派相应的角色，用户可以很容易地从一个角色被指派到另一个角色。角色可依新的需求和系统的合并而赋予新的权限，而权限也可根据需要而从某角色中回收。角色与角色的关系可以建立起来以囊括更广泛的客观情况。
RBAC 支持三个著名的安全原则：最小权限原则，责任分离原则和数据抽象原则。
最小权限原则之所以被 RBAC 所支持，是因为 RBAC 可以将其角色配置成其完成任务所需要的最小的权限集。 责任分离原则可以通过调用相互独立互斥的角色来共同完成敏感的任务而体现，比如要求一个计帐员和财务管理员共参与同一过帐。 数据抽象可以通过权限的抽象来体现，如财务操作用借款、存款等抽象权限，而不用操作系统提供的典型的读、写、执行权限。然而这些原则必须通过 RBAC 各部件的详细配置才能得以体现。 RBAC 有许多部件(BUCU)，这使得 RBAC 的管理多面化。尤其是，我们要分割这些问题来讨论：用户与角色的指派；角色与权限的指派；为定义角色的继承进行的角色与角色的指派。这些活动都要求把用户和权限联系起来。然而在很多情况下它们最好由不同的管理员或管理角色来做。对角色指派权限是典型的应用管理者的职责。银行应用中，把借款、存款操作权限指派给出纳角色，把批准贷款操作权限指派给经理角色。而将具体人员指派给相应的出纳角色和管理者角色是人事管理的范畴。角色与角色的指派包含用户与角色的指派、角色与权限的指派的一些特点。更一般来说，角色与角色的关系体现了更广泛的策略。
基本概念 RBAC 认为权限授权实际上是 Who、What、How 的问题。在 RBAC 模型中，who、what、how 构成了访问权限三元组,也就是“Who 对 What(Which)进行 How 的操作”。
Who：权限的拥用者或主体（如 Principal、User、Group、Role、Actor 等等）。
What：权限针对的对象或资源（Resource、Class）。
How：具体的权限（Privilege,正向授权与负向授权）。
Operator：操作。表明对 What 的 How 操作。也就是 Privilege+Resource
Role：角色，一定数量的权限的集合。权限分配的单位与载体,目的是隔离 User 与 Privilege 的逻辑关系.
Group：用户组，权限分配的单位与载体。权限不考虑分配给特定的用户而给组。组可以包括组(以实现权限的继承)，也可以包含用户，组内用户继承组的权限。User 与 Group 是多对多的关系。Group 可以层次化，以满足不同层级权限控制的要求。
RBAC 的关注点在于 Role 和 User, Permission（允许/权限）的关系。称为 User assignment(UA)和 Permission assignment(PA).关系的左右两边都是 Many-to-Many 关系。就是 user 可以有多个 role，role 可以包括多个 user。</description></item><item><title>RBAC 授权</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authorization%E6%8E%88%E6%9D%83/RBAC-%E6%8E%88%E6%9D%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authorization%E6%8E%88%E6%9D%83/RBAC-%E6%8E%88%E6%9D%83/</guid><description>概述 参考：
官方文档，参考 - API 访问控制 - 使用 RBAC 授权 RBAC 概念 基于 Role(角色) 的访问控制(RBAC) 是一种根据各个用户的角色来控制对 Kubernetes 内资源的访问权限的方法。
在 Kubernetes 的 RBAC 机制中有如下标准化术语：
Role(角色)# 是一组规则的集合，这些规则定义了对 Kubernetes 集群(即 APIserver)的操作权限 权限包括：get、list、watch、create、update、patch、delete Subject(主体)# 即把 Role 的规则作用于 Subject 上。Subject 就是本文开头讲的 Accounts Subject 类型(kind)包括：User、Group、ServiceAccount 其中 User 就是 认证里的 User Account。User 的名字可以是字符串，也可以是邮件风格的名称，或者以字符串形式表达的数字 ID。 Group 的概念是什么还不知道，也没找到参考文档。不过有一个可能应该是这样描述的： Group 与 User 有关系，在创建 User 的证书时，在 subjct 中，O 的值就是表示 Kubernetes RBAC 机制中 Group 的概念。这么看，其实这个 User 与 Group 的概念与 Linux 中用户与组的概念一样。 ServiceAccount 详见 Service Account RoleBinding：定义了 Role 与 Subject 的绑定关系 rules# 规则，i.</description></item><item><title>rc 配置文件</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/npmrc-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/npmrc-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
pnpm 官方文档，配置 - .npmrc 这里面的笔记都以 pnpm 为主。
“rc” 是 “run commands” 的缩写。它的起源可以追溯到 Unix 的祖父母 CTSS。早期的 Unix 使用 “rc” 作为操作系统启动脚本的名称，作为对 CTSS runcom 的致敬。在一些项目中，以 “rc” 结尾的文件通常是配置文件，如 “.eslintrc”、“.npmrc” 等。这些文件包含了程序的运行时配置，如资源配置、运行控制等。
Node 模块设定 store-dir # 指定存储模块的路径。</description></item><item><title>Rclone mount</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rclone/Rclone-mount/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rclone/Rclone-mount/</guid><description>概述 参考：
官方文档，命令-rclone mount Rclone 的 mount 功能使用 FUSE 将 Remote 作为文件系统挂载到操作系统中。
使用 VFS https://rclone.org/commands/rclone_mount/#vfs-virtual-file-system
rclone mount 命令使用文件系统的 VFS，这将 rclone 使用 Remote 调整为看起来更像磁盘文件系统的东西。
VFS 缓存机制 rclone mount 可以使用两种 VFS 的缓存机制
目录缓存 文件缓存 文件缓存
为 &amp;ndash;vfs-cache-mode 选项指定了除 off 以外的值，即表示开启文件缓存。开启文件缓存后，默认是 write-back 策略，对文件的所有写入操作都是针对本地的缓存文件，只有关闭缓存文件后等待 5s(该值可由 &amp;ndash;vfs-write-back 选项指定)后才会将缓存文件回写到 Remote 以更新原文件。如果 rclone 因为意外情况退出导致文件未上传，那么必须要使用相同选项启动 rclone，才会在开始运行时回写这些文件。
用人话说：开启文件缓存后，修改的文件是都是本地缓存文件，需要等一会，才会缓存文件同步给源文件。
rclone 提供了 4 中缓存模式，模式越高，兼容性越好，但磁盘占用越多。
off # 关闭文件缓存。最低的模式，兼容性最差。本地不做任何缓存，所有文件直接从云端获取并写入，网速特别好时（复制粘贴大文件时建议至少100M管以上速度）使用。 minimal # 最小模式。与 off 类似，一般只有新创建的文件才会缓存。 writes # 写模式。打开后有修改的文件都会缓存。如果回写失败，将以指数增加的间隔重试，最多 1 分钟。 full # 完全模式，兼容性最好。缓存全部文件。 在此模式下，缓存中的文件将是 sparse files(稀疏文件)，并且 rclone 将跟踪已下载的文件的哪些位。 notes: 对于在 Windows 和 Linux 中的 rclone mount，上述缓存模式的说明不太一样，比如关闭缓存的情况下，linux 用 vim 是无法编辑文件的，但是 windows 中用编辑器是可以编辑的，并且修改内容瞬间会同步到源文件。</description></item><item><title>Rclone 配置</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rclone/Rclone-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rclone/Rclone-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
官方文档，用法 官方文档，全局命令行标志 Rclone 的配置有点混乱，不过大体分为两部分，Backend(与后端相关) 和 Non Backend(与后端无关) 两种配置。
Non Backend # 通常是指 Rclone 自身的运行时方式。比如使用 sync、copy 等命令时设置并发数、等等。 这部分配置无法通过 rclone.conf 文件设置。 Backend # 针对各种 Remote 所使用的 Backend 的配置。 这两类配置，可以使用一种或多种方式进行配置，可用的配置方式有：
命令行标志 环境变量 配置文件 Backend 无关配置 Rclone 可以通过如下几种方式配置，优先级从上至下由高到低：
命令行标志 环境变量 rclone 命令的每个选项都可以通过环境变量设置其默认值。选项与环境变量的对应关系规则如下：
去掉长选项名称开头的 -- 选项名称中的 - 改为 _ 字母改为大写 前面加上 RCLONE_ 前缀 比如：
&amp;ndash;stats 对应 RCLONE_STATS &amp;ndash;drive-use-trash 对应 RCLONE_DRIVE_USE_TRASH 其中 &amp;ndash;verbose 的对应关系比较特殊，-v 对应 RCLONE_VERBOSE=1；-vv 对应 RCLONE_VERBOSE=2
Backend 相关配置 Backend 配置本质上就是配置 Remote，Rclone 通过如下几种方式配置 Backend，优先级从上至下由高到低</description></item><item><title>Redhat 包管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Redhat-%E5%8C%85%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Redhat-%E5%8C%85%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
rpm 工具 参考：
Manual(手册)，rpm(8) Syntax(语法) rpm -i [OPTIONS] PACKAGE # 安装软件包
OPTIONS
-v # 显示安装过程 -h # 显示安装进度 EXAMPLE
rpm -ivh X.rpm # 安装 X.rpm 软件包 rpm -Uvh X.rpm # 升级 X.rpm 软件包 rpm -q [OPTIONS] PACKAGE # 查询软件包
OPTIONS
-a # 列出所有已经安装在系统上的所有软件包的完整名称 -i &amp;lt;PACKAGE&amp;gt; # 列出 PACKAGE 这个包的详细信息，安装时间，版本，开发商，描述等等 -l &amp;lt;PACKAGE&amp;gt; # 列出 PACKAGE 这个包的所有文件与目录所在完整文件名(list) -R &amp;lt;PACKAGE&amp;gt; # 列出 PACKAGE 这个包所依赖的文件 -f &amp;lt;FILE&amp;gt; # 列出该 FILE 属于哪个 PACKAGE 中的文件 EXAMPLE</description></item><item><title>Redis</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis/</guid><description>概述 参考：
GitHub 项目，redis/redis GitHub 项目，valkey-io/valkey # Linux Foundation 基于 7.2.4 版本分叉的项目，保持原有 License 官网 [!Warning] 3 月 30 日 Redis 发布博客改变 License，后续 Linux 基金会基于 7.2.4 版本分叉，保持原有 License。开源版本改名称为 Redis OSS（open source）
Redis 是一个开源的、网络化的、内存中的、具有持久化的键值数据存储。(是否持久化根据配置决定)
Redis 是一个内存数据库, 所有数据默认都存在于内存当中,可以配置“定时以追加或者快照”的方式储存到硬盘中. 由于 redis 是一个内存数据库, 所以读取写入的速度是非常快的, 所以经常被用来做数据, 页面等的缓存。
Redis 的组件 redis-server # 服务端 redis-cli # Redis CLI，一个命令行客户端 redis-benchmark # 压测工具 redis-check-dump &amp;amp;&amp;amp; redis-check-aof # 检测工具 Redis 的数据类型 Redis 数据类型
Redis 部署 Docker 启动 Redis docker run -d --name redis \ --network=host \ redis:5.</description></item><item><title>Redis 数据类型</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>概述 参考：
官方文档，数据类型 https://redis.io/docs/latest/develop/data-types/ string(字符串)，hash(哈希)，list(列表)，set(集合) 及 zset(sorted set：有序集合)。
后面增加了：
Bit arrays (或者说 simply bitmaps)
在 2.8.9 版本添加了 HyperLogLog 结构
一般情况下，每种类型的数据都有与之相关的 Redis CLI 中的子命令对应进行处理</description></item><item><title>Regular Expression(正则表达式)</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Regular-Expression%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Regular-Expression%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</guid><description>概述 参考：
Wiki, Regular Expression 正则表达式在线测试 https://r2coding.com/#/README?id=%e6%ad%a3%e5%88%99%e8%a1%a8%e8%be%be%e5%bc%8f GitHub 项目，PCRE2Project/pcre2 PCRE 官网 PCRE Man page GitHub 项目，google/re2 RE2 是一种快速、安全、线程友好的替代方案，可替代 PCRE、Perl 和 Python 中使用的回溯正则表达式引擎。它是一个 C++ 库 记于 2023 年 2 月10 日：有了 ChatGPT，这正则表达式。。。我想。。。应该再也不用背了。。。。
Regular Expression(正则表达式，简称 RegEX 或 RegEXP) 是用于定义 Search Pattern(搜索模式) 的一系列字符串。这种 Pattern(模式) 通常被字符串搜索算法用于 find(查找) 字符串、或 find and replace(查找并替换) 字符串、或者验证输入内容。RegEX 是一种在 Theoretical Computer Science(理论计算机科学) 和 Formal Language(形式语言) 理论中发展起来的技术。
还有一个学名 Perl Compatible Regular Expressions(Perl 兼容的正则表达式，简称 PCRE)，这用来表示 Perl 语言兼容的正则表达式。
用白话说，所谓的 正则表达式，就是用来通过一种称为 Pattern(模式) 的方式，筛选出长篇内容里的部分内容。其实就是一堆字符组合在一起形成一种行为，这个行为就是匹配字符行为。也可以勉强算编程语言的一种吧~
所以，这个世界在很多时候，把正则表达式这个概念，用 RegEX、RegEXP、Pattern 这几种单词表示。</description></item><item><title>Retrieval</title><link>https://desistdaydream.github.io/docs/12.AI/Retrieval/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Retrieval/</guid><description>概述 参考：
RAG 参考：
Wiki, Retrieval-augmented generation B 站，AI知识库RAG技术原理，三大痛点与进阶方案【不用编程】 Retrieval-augmented generation(检索增强生成，简称 RAG) 是一种使 12.AI 模型能够检索信息的技术。它修改了与 LLM 的交互，使模型能够参考指定的一组文档来响应用户的查询，并使用这些信息来补充其预先存在训练数据中的信息。
用户把资料添加进知识库的时候，程序会先把它们拆分成很多个文本块，然后使用嵌入模型对这些文本块进行向量化（向量化指的是把切拆分后的文本），变成一个超长的数字序列。然后程序把向量以及对应的文本保存在向量数据库里面。
接下来用户开始提问，不过这个提问并非直接送达到大模型那里，而是把其本身也经过向量化处理，先变成一个1024维的向量。然后把用户的提问与向量数据库进行相似度匹配，这个匹配过程是基于向量的纯数学运算，最后知识库选出匹配度最高的几个原文片段，再加上用户的问题发给大模型，大模型进行最后的归纳总结
存在问题：
切片很粗暴 检索不精准 # 搜索知识库时，只能找到切片，无法将搜索内容与全文进行上下文管理，只有部分切片。最后会 AI 拿到的内容是不足的，导致结果不精准。 没有大局观 重排序模型，可以把向量数据库初步检索出来的数据，使用专用的重排序模型进行更深入的语义分析。然后再按照问题的相关性进行重新的排序，把相关性最大的一些数据排到前面并且交付给大模型。这是一种先粗后细的两步检索策略，可以进一步提高检索精度
使用超长上下文，避免切片太碎，但是。。。。资源消耗非常非常高。。。。</description></item><item><title>RKE</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/RKE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/RKE/</guid><description>概述 参考：
官方文档： https://rancher.com/docs/rke/latest/en/ https://rancher2.docs.rancher.cn/docs/rke/_index/ Rancher Kubernetes Engine(RKE)，是经过 CNCF 认证的 Kubernetes 发行版，完全在 Docker 容器内运行。它适用于裸机和虚拟机。RKE 解决了安装复杂性的问题，这是 Kubernetes 社区中的常见问题。借助 RKE，Kubernetes 的安装和操作既简单又自动化，并且完全独立于所运行的操作系统和平台。只要服务器可以运行受支持的 Docker 版本，就可以使用 RKE 部署和运行 Kubernetes。
使用 rke 工具，仅需通过一个 yaml 的配置文件以及 docker 环境，即可启动一个功能完全的 kubernetes 集群。其中所有系统组件(包括 kubelet)都是以容器的方式运行的。通过 Rancher 创建的 kubernetes 集群，就是 RKE 集群。
RKE 集群与原生 K8S 集群的区别 RKE 与 sealos 实现高可用的方式类似。不同点是 RKE 集群的 node 节点是通过 ngxin 来连接 API Server。
RKE 集群部署 参考：RKE 部署与清理
下载 rke 二进制文件。(在 github 上下载 rke 命令行工具) 创建集群配置文件。 RKE 默认使用名为 cluster.</description></item><item><title>RPA</title><link>https://desistdaydream.github.io/docs/12.AI/Automation/RPA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Automation/RPA/</guid><description>概述 参考：
Wiki, Robotic_process_automation Robotic process automation(机器人的流程自动化，简称 RPA) 是一种基于 软件机器人 或 人工智能 的流程自动化形式，这是一种实现自动化的设计思想、概念，并不是特指某个具体的实物。
在传统的工作流程自动化工具中，软件开发人员会生成一系列操作来自动执行任务，并使用内部 API 或专用脚本语言连接到后端系统。相比之下，RPA 系统通过观察用户在应用程序的图形用户界面 (GUI) 中执行该任务来开发操作列表，然后通过直接在 GUI 中重复这些任务来执行自动化。这可以降低在可能不具有用于此目的的 API 的产品中使用自动化的障碍。
RPA 工具与 GUI 测试工具在技术上有很强的相似性。这些工具还可以自动执行与 GUI 的交互，并且通常通过重复用户执行的一组演示操作来实现。 RPA 工具与此类系统的不同之处在于，它们允许在多个应用程序内和之间处理数据，例如，接收包含发票的电子邮件，提取数据，然后将其输入簿记系统。
实现工具 UiPath # 国外很有名
UiBot # 按键精灵那波人搞的
影刀 # 国产 UiPath
Power Automate # 微软出的
Tag UI # https://github.com/aisingapore/TagUI 不维护了
PyAutoGUI # Python 第三方库，基于 opencv、 等工具实现的自动化工具，可以识别图像并调用鼠标和键盘操作这些识别到的图像。
其他 RPA 中国官网 居然没有 HTTPS？</description></item><item><title>Rsync</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rsync/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Rsync/</guid><description>概述 参考：
GitHub 项目，WayneD/rsync 官网 rsync+inotify 数据实时同步介绍与 K8s 实战应用 rsync（remote sync） 远程同步，rsync 是 linux 系统下的数据镜像备份工具。使用快速增量备份工具 Remote Sync 可以远程同步，支持本地复制，或者与其他 SSH、rsync 主机同步。已支持跨平台，可以在 Windows 与 Linux 间进行数据同步。rsync 监听端口：873，rsync 运行模式：C/S。</description></item><item><title>RsysLog 配置</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Rsyslog/RsysLog-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Rsyslog/RsysLog-%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
Manual(手册), rsyslog.conf(5) 本笔记中的 Facility 概念见 日志系统 中 Facility(设施) 的介绍 Rsyslog 已经发展了几十年。因此有多种不同格式进行配置
basic # 以前称为 sysklogd 格式。这种格式最适合在单独一行上表达基本配置，源于原始的 syslog.conf 格式。最常见的用例是匹配设施/严重性并将匹配消息写入日志文件。 advanced # 以前称为 RainerScript 格式。这种格式首先在 rsyslog v6 中提供，对于需要多行的重要用例来说是最好、最精确的格式。此格式专为高级用例而设计，例如转发到可能部分离线的远程主机。 obsolete legacy # 过失的遗留格式。在编写新配置时不应该使用。 RainerScript https://www.rsyslog.com/doc/rainerscript/index.html
RainerScript 是一种专门设计的脚本语言，非常适合处理网络事件和配置事件处理器。它是 rsyslog 使用的主要配置语言。请注意，RainerScript 可能不会缩写为 rscript，因为那是别人的商标。
自 rsyslog 3.12.0 起提供了一些有限的 RainerScript 支持（用于表达式支持）。在 v5 中，支持“if .. then”语句。自 rsyslog v6 以来，第一个完整的实现可用。
Data Types Expressions Functions Control Structures Objects MODULES 模块配置 参考：
https://www.rsyslog.com/doc/configuration/modules/index.html 配置文件新老版本有两种格式，下面这两种写法，都可以表示让 Rsyslog 加载 imuxsock 模块
$ModLoad imuxsock # 老版本语法 module(load=&amp;ldquo;imuxsock&amp;rdquo;) # 新版本语法 更多模块配置详情见 Module</description></item><item><title>RTSP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/RTSP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/RTSP/</guid><description>概述 参考：
Wiki, Real_Time_Streaming_Protocol Real Time Streaming Protocol(实时流协议，简称 RTSP) 是一种网络应用协议，专为娱乐和通信系统的使用，以控制流媒体服务器。</description></item><item><title>Runtime</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Runtime/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Runtime/</guid><description>概述 参考：
原文链接：白话 Kubernetes Runtime 回想最开始接触 k8s 的时候, 经常搞不懂 CRI 和 OCI 的联系和区别, 也不知道为啥要垫那么多的 “shim”(尤其是 containerd-shim 和 dockershim 这两个完全没啥关联的东西还恰好都叫 shim). 所以嘛, 这篇就写一写 k8s 的 runtime 部分, 争取一篇文章把下面这张 Landscape 里的核心项目给白话明白。
(以上理由其实都是为了说服自己写写水文也是可以的…)
典型的 Runtime 架构 我们从最常见的 runtime 方案 Docker 说起, 现在 Kubelet 和 Docker 的集成还是挺啰嗦的:
当 Kubelet 想要创建一个容器时, 有这么几步:
Kubelet 通过 CRI 接口(gRPC) 调用 dockershim, 请求创建一个容器. CRI 即容器运行时接口(Container Runtime Interface), 这一步中, Kubelet 可以视作一个简单的 CRI Client, 而 dockershim 就是接收请求的 Server. 目前 dockershim 的代码其实是内嵌在 Kubelet 中的, 所以接收调用的凑巧就是 Kubelet 进程; dockershim 收到请求后, 转化成 Docker Daemon 能听懂的请求, 发到 Docker Daemon 上请求创建一个容器; Docker Daemon 早在 1.</description></item><item><title>Scheduler</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Scheduler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Scheduler/</guid><description>概述 参考：
调度系统设计精要</description></item><item><title>Scheduler(调度器)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/Scheduler%E8%B0%83%E5%BA%A6%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/Scheduler%E8%B0%83%E5%BA%A6%E5%99%A8/</guid><description>概述 参考：
官方文档，概念 - 调度与驱逐 公众号 - 云原生社区动态，6 张图带你深入了解 kube-scheduler Scheduler(调度器) 负责决定 Pod 与 Node 的匹配关系，并将 Pod 调度到匹配到的 Node 上，以便 Kubelet 可以运行这些 Pod。Scheduler 在调度时会充分考虑 Cluster 的拓扑结构，当前各个节点的负载，以及应用对高可用、性能、数据亲和性的需求。
Scheduler 通过 Kubernetes 的 watch 机制来发现集群中新创建且尚未被调度到 Node 的 Pod。Scheduler 会将发现的每一个未调度的 Pod 调度到一个合适的 Node 上去运行。
调度器的实现 kube-scheduler 是实现 Kubernetes 调度器功能的程序。
Scheduler 调度策略 参考：
官方文档，参考 - 调度 - 调度策略 Scheduler 调度的时候，通过以下步骤来完成调度
Predicate(预选) # 排除那些不满足 Pod 运行环境的 Node Priorities(优选) # 通过算法，剩余可运行 Pod 的 Node 进行计算后排序，选择结果最高的 Node Select(选定) # 若优选后有多个 Node 得分相同，则随机挑选，将选择的结果告诉 APIServer 用哪个 Node 部署 Pod 调度倾向性：亲合性 Affinity，反亲合性 AntiAffinity，污点 Taints，容忍度 Tolerations</description></item><item><title>Secure Shell Protocol</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Secure-Shell-Protocol/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Secure-Shell-Protocol/</guid><description>概述 参考：
Wiki, Secure_Shell_Protocol https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys-on-centos-8 Secure Shell Protocol(安全外壳协议，简称 SSH) 是一种加密的Communication protocol，可在不安全的网络中为网络服务提供安全的传输环境。SSH 通过在网络中创建安全隧道来实现 SSH 客户端与服务器之间的连接。虽然任何网络服务都可以通过 SSH 实现安全传输，SSH 最常见的用途是远程登录系统，人们通常利用 SSH 来传输命令行界面和远程执行命令。使用频率最高的场合类 Unix 系统，但是 Windows 操作系统也能有限度地使用 SSH。2015 年，微软宣布将在未来的操作系统中提供原生 SSH 协议支持，Windows 10 1809 版本已提供可手动安装的 OpenSSH 工具
SSH 的实现 OpenSSH
Go 语言的 SSH 实现
https://github.com/search?q=sshd+language%3AGo&amp;ref=opensearch&amp;type=repositories GitHub 项目，jpillora/sshd-lite 对应博客 https://blog.gopheracademy.com/go-and-ssh/ https://github.com/nwtgck/handy-sshd https://github.com/Matir/sshdog 其他 https://github.com/shazow/ssh-chat</description></item><item><title>Security</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Security/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Security/</guid><description>概述 参考：
官方文档 - PowerShell，模块 - Security Get-ExecutionPolicy 获取当前会话的执行策略。
Restricted 执行策略不允许任何脚本运行。 AllSigned 和 RemoteSigned 执行策略可防止 Windows PowerShell 运行没有数字签名的脚本。 默认使用 Restricted 策略，此时当我们执行脚本时将会失败，并报错：
无法加载文件 XXXXX，因为在此系统上禁止运行脚本。有关详细信息，请参阅 https:/go.microsof t.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。 Syntax(语法) EXAMPLE Set-ExecutionPolicy 为 Windows 计算机设置 PowerShell 执行策略
Syntax(语法) Get-Command
EXAMPLE 设置策略为 RemoteSigned
Set-ExecutionPolicy RemoteSigned</description></item><item><title>select</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/SQL/%E6%9F%A5%E8%AF%A2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/SQL/%E6%9F%A5%E8%AF%A2/</guid><description>概述 参考：
Wiki, SQL 语法 - 查询 SQL 中最常见的操作（查询）使用声明性 SELECT 语句。
FROM 子句，指示要从中检索数据的表。 FROM 子句可以包含可选的 JOIN 子句来指定连接表的规则。 WHERE 子句包含一个比较谓词，它限制查询返回的行。 WHERE 子句从结果集中消除比较谓词不计算为 True 的所有行。 GROUP BY 子句将具有公共值的行投影到较小的行集中。[需要澄清] GROUP BY 通常与 SQL 聚合函数结合使用，或用于从结果集中消除重复行。 WHERE 子句在 GROUP BY 子句之前应用。 HAVING 子句包含一个谓词，用于过滤 GROUP BY 子句产生的行。由于聚合函数作用于 GROUP BY 子句的结果，因此可以在 HAVING 子句谓词中使用聚合函数。 ORDER BY 子句标识使用哪个列对结果数据进行排序，以及按哪个方向对它们进行排序（升序或降序）。如果没有 ORDER BY 子句，则 SQL 查询返回的行的顺序是不确定的。 DISTINCT 关键字消除重复数据。 FETCH FIRST 子句指定要返回的行数。有些 SQL 数据库有非标准的替代方案，例如 LIMIT、TOP 或 ROWNUM。常见 LIMIT OFFSET 子句指定开始返回数据之前要跳过的行数。 虽然 SELECT 位于语句最前面，它在逻辑处理中，基本上是最后一个被执行的部分。下面列出查询子句在逻辑上处理顺序：</description></item><item><title>Selenium</title><link>https://desistdaydream.github.io/docs/Web/Browser-automation/Selenium/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser-automation/Selenium/</guid><description>概述 参考：
GitHub 项目，SeleniumHQ/selenium 官网 https://selenium-python.readthedocs.io/ 特定于 Python 的文档，官方文档很多示例都不全。 https://segmentfault.com/q/1010000043032537 这里表示文档不全 Selenium 使浏览器自动化，用于自动化 Web 应用程序。Selenium 通过 WebDriver 控制浏览器。
Selenium 使用浏览器的方式 Selenium 通过如下几种方式使用浏览器
打开新的浏览器 使用当前运行的浏览器 通过 Chrome 的 debug 端口连接 使用指定的缓存 [!Tip] Selenium 通过 chromedriver.exe 拉起的浏览器不包含任何数据（登录状态、cookie、etc.）
所以如果想要使用当前浏览器（比如避免反复登录），必须通过其他方式（e.g. Chrome 的 Debug 端口、etc.）
其他 Selenium 启动的 Chrome 的参数
C:\Program Files\Google\Chrome\Application\chrome.exe&amp;#34; --allow-pre-commit-input --disable-background-networking --disable-backgrounding-occluded-windows --disable-client-side-phishing-detection --disable-default-apps --disable-hang-monitor --disable-popup-blocking --disable-prompt-on-repost --disable-sync --enable-automation --enable-logging --log-level=0 --no-first-run --no-service-autorun --password-store=basic --remote-debugging-port=0 --test-type=webdriver --use-mock-keychain --user-data-dir=&amp;#34;C:\Users\DESIST~1\AppData\Local\Temp\scoped_dir11888_46574381&amp;#34; --flag-switches-begin --flag-switches-end data: 正常启动浏览器的参数</description></item><item><title>Sentinel 命令</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/Sentinel-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/Sentinel-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方文档 https://redis.io/docs/latest/operate/oss_and_stack/management/sentinel/#sentinel-api 博客园大佬 基本命令 PING - 健康检查 sentinel masters - 显示被监控的所有 master 以及它们的状态 sentinel master &amp;lt;MASTER&amp;gt; - 显示指定 MASTER 的信息和状态 sentinel slaves &amp;lt;MASTER&amp;gt; - 显示指定 MASTER 的所有 slave 以及它们的状态 sentinel get-master-addr-by-name &amp;lt;MASTER&amp;gt; - 返回指定 MASTER 的 ip 和端口 如果正在进行 failover 或者 failover 已经完成，将会显示被提升为 master 的 slave 的 ip 和端口。
sentinel reset &amp;lt;pattern&amp;gt; - 重置名字匹配该正则表达式的所有的 master 的状态信息 清楚其之前的状态信息，以及 slaves 信息。
sentinel failover &amp;lt;MASTER&amp;gt; - 强制 sentinel 为指定的 MASTER 执行 failover 执行该操作的 Sentinel 节点并不需要得到其他 Sentinel 的同意。但是 failover 后会将最新的配置发送给其他 sentinel。</description></item><item><title>server 组</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/server-%E7%BB%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/server-%E7%BB%84/</guid><description>概述 参考：
https://redis.io/docs/latest/commands/?group=server BGREWRITEAOF - # Asynchronously rewrite the append-only file
BGSAVE -
summary: Asynchronously save the dataset to disk
since: 1.0.0
CLIENT GETNAME -
summary: Get the current connection name
since: 2.6.9
CLIENT ID -
summary: Returns the client ID for the current connection
since: 5.0.0
CLIENT KILL [ip:port] [ID client-id] [TYPE normal|master|slave|pubsub] [ADDR ip:port] [SKIPME yes/no]
summary: Kill the connection of a client
since: 2.4.0
CLIENT LIST -</description></item><item><title>Service Account</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authentication%E8%AE%A4%E8%AF%81/Service-Account/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authentication%E8%AE%A4%E8%AF%81/Service-Account/</guid><description>概述 参考：
官方文档，任务 - 配置 Pod 和 容器 - 为 Pods 配置服务账户 官方文档，参考 - API 访问控制 - 管理服务账户 详解 Service Account 之前，需要了解这么一个 k8s 的运行逻辑：每个 Pod 在创建成功后，都会声明并使用一个 ServiceAccount 作为自己与集群通信的认证，默认使用 Pod 所在 Namepace 的名为 default 的 ServiceAccount
上面这个默认的 default 具有很高的权限，如果想对该 default 进行安全保护，可以修改绑定到 default 的 role(i.e. RBAC 授权) 的权限
每个 ServiceAccount 对象在被创建出来之后，都会自动生成一个对应的 Secrets 对象，认证信息即在该 Secret 中。
# 与 ServiceAccount 关联的 secret 会以 SAName-token-STRING 的方式命名。 # 效果如下，在monitoring 名称空间中每个 sa 都有一个 secret 对应。(SA 是 ServiceAccount 的简称) [root@master ~]# kubectl get serviceaccount -n monitoring NAME SECRETS AGE alertmanager-main 1 2m18s default 1 13d .</description></item><item><title>Service Manifests</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/Service-Manifests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/Service-Manifests/</guid><description>概述 参考：
API 文档单页 官方文档，参考-Kubernetes API-服务资源-Service 官方文档，参考-Kubernetes API-服务资源-Endpoint Service Manifests 详解 Manifest 中的顶层字段 apiVersion: v1 # API 版本，基础字段必须要有 kind: Service # 指明要创建的资源类型为 Service，基础字段必须要有 metadata(metadata) spec(spec) status(status) metadata metadata 字段描述该 Service 资源的元数据，其中 name 是必须要写明的元数据项。该字段内容详见通用定义的 ObjectMeta
name: STRING # 指定该资源的名字
spec spec 字段描述该 Service 的规格(specification)
clusterIP: STRING # 手动给该 Service 分配 IP，该 IP 在服务创建后无法手动修改，可以设置为 None，变成无头 service，这时候请求不由 service 处理，直接通过 service 名称转发到后端的 Pod
ports([]OBJECT)
- protocol: TCP # 将 service 的端口映射到 pod 的端口，使用 TCP 协议 nodePort: NUM # 指明 Service 通过 k8s 集群中的那个端口对外提供服务，默认随机从 30000-32767 中随机分配(注：该字段只有 type 为 NodePort 的时候才有作用) port: NUM # 指明该 service 所使用的端口 targetPort: XXX # 指明后端 Pod 的端口</description></item><item><title>ServiceDiscovery</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/ServiceDiscovery/ServiceDiscovery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/ServiceDiscovery/ServiceDiscovery/</guid><description>概述 参考：
Service Discovery(服务发现)
Nacos 参考：
官网 官方文档 部署文档 发现、配置和管理微服务
Consul 参考：
GitHub 项目，hashicorp/consul 注册
curl --location --request PUT &amp;#39;http://10.10.4.90:8500/v1/agent/service/register&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;id&amp;#34;: &amp;#34;10.10.11.16&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;node-exporter&amp;#34;, &amp;#34;address&amp;#34;: &amp;#34;10.10.11.16&amp;#34;, &amp;#34;port&amp;#34;: 9100, &amp;#34;tags&amp;#34;: [ &amp;#34;linux&amp;#34; ], &amp;#34;Meta&amp;#34;: { &amp;#34;custom_house_name&amp;#34;: &amp;#34;天津机房&amp;#34;, &amp;#34;business_type&amp;#34;: &amp;#34;迎检&amp;#34; } }&amp;#39; 利用服务的 Meta 在 Prometheus 进行 consul_sd 时添加 Lable</description></item><item><title>services</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/services/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Compose/services/</guid><description>概述 参考：
官方文档，参考 - Compose 文件参考 - Services 顶级元素 build 指定为构建镜像上下文路径：
例如 webapp 服务，指定为从上下文路径 ./dir/Dockerfile 所构建的镜像：
version: &amp;#34;3&amp;#34; services: webapp: build: ./dir 或者，作为具有在上下文指定的路径的对象，以及可选的 Dockerfile 和 args：
version: &amp;#34;3&amp;#34; services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 labels: - &amp;#34;com.example.description=Accounting webapp&amp;#34; - &amp;#34;com.example.department=Finance&amp;#34; - &amp;#34;com.example.label-with-empty-value&amp;#34; target: prod context：上下文路径。 dockerfile：指定构建镜像的 Dockerfile 文件名。 args：添加构建参数，这是只能在构建过程中访问的环境变量。 labels：设置构建镜像的标签。 target：多层构建，可以指定构建哪一层。 cap_add 与 cap_drop 添加或删除容器拥有的宿主机的内核功能。等价于 docker run 命令中的的 &amp;ndash;cap-add 标志
cap_add: - ALL # 开启全部权限 cap_drop: - SYS_PTRACE # 关闭 ptrace权限 cgroup_parent 为容器指定父 cgroup 组，意味着将继承该组的资源限制</description></item><item><title>SFTP Subsystem</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/SFTP-Subsystem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/SFTP-Subsystem/</guid><description>概述 参考：
Manual, sftp-server https://serverfault.com/questions/660160/difference-between-openssh-internal-sftp-and-sftp-server OpenSSH 的 SFTP 子系统早期由独立的二进制程序 sftp-server 实现（默认路径 /usr/libexec/openssh/sftp-server），后面内嵌到 sshd 中，通过 internal-sftp 参数开启 SFTP 子系统。
OpenSSH 的 SFTP 子系统可以实现 SFTP 能力。
要启用 SFTP 子系统，在 sshd_config 配置文件中使用 Subsystem sftp XXX 指令，XXX 用来指示是用外部二进制程序实现 SFTP 还是内嵌的 sftp 逻辑实现 SFTP。
下面两个指令都可以启动 SFTP 子系统（sftp-server 在新版已经内嵌到 sshd 程序中，更推荐使用 Subsystem sftp internal-sftp）
Subsystem sftp /usr/libexec/openssh/sftp-server Subsystem sftp internal-sftp sftp-server sftp-server 程序的命令参数同样可以在 sshd_config 配置文件中指定，比如：
Subsystem sftp internal-sftp -f LOCAL5 -l INFO OPTIONS -f LOG_FACILITY # 指定记录日志时使用的 Facility 代码。默认值: AUTH。可用的值有: DAEMON, USER, AUTH, LOCAL0, LOCAL1, LOCAL2, LOCAL3, LOCAL4, LOCAL5, LOCAL6, LOCAL7</description></item><item><title>Signal(信号)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Signal%E4%BF%A1%E5%8F%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Signal%E4%BF%A1%E5%8F%B7/</guid><description>概述 参考：
Wiki, Signal Signal(信号) 是 Inter Process Communication 的一种受限形式。信号是发送到进程或同一进程内的特定线程的异步通知，目的是将发生的事件通知给它。发送信号后，操作系统会中断目标进程的正常执行流程以传递信号。在任何非原子指令中，执行都可以中断。如果该进程先前已注册了信号处理程序，则将执行该例程。否则，将执行默认信号处理程序。
信号类似于中断，区别在于中断由处理器介导并由内核处理，而信号由内核介导（可能通过系统调用）并由进程处理。内核可能会将中断作为信号传递给引起中断的进程（典型示例为 SIGSEGV，SIGBUS，SIGILL 和 SIGFPE）。
信号类型
Linux 系统共定义了 64 种信号，分为两大类：可靠信号与不可靠信号，前 32 种信号为不可靠信号，后 32 种为可靠信号。
1.1 概念
不可靠信号： 也称为非实时信号，不支持排队，信号可能会丢失, 比如发送多次相同的信号, 进程只能收到一次. 信号值取值区间为 1~31； 可靠信号： 也称为实时信号，支持排队, 信号不会丢失, 发多少次, 就可以收到多少次. 信号值取值区间为 32~64 1.2 信号表
在终端，可通过 kill -l 查看所有的 signal 信号
使用时，这些信号开头的 3 个大写字符(SIG)可以省略
~]# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX 取值 名称 解释 默认动作 1 SIGHUP 挂起 2 SIGINT 中断 3 SIGQUIT 退出 4 SIGILL 非法指令 5 SIGTRAP 断点或陷阱指令 6 SIGABRT abort 发出的信号 7 SIGBUS 非法内存访问 8 SIGFPE 浮点异常 9 SIGKILL kill 信号 不能被忽略、处理和阻塞 10 SIGUSR1 用户信号 1 程序自定义的信号，常用这种信号来处理日志或加载配置文件。比如 docker 用这种信号来生成日志 11 SIGSEGV 无效内存访问 12 SIGUSR2 用户信号 2 13 SIGPIPE 管道破损，没有读端的管道写数据 14 SIGALRM alarm 发出的信号 15 SIGTERM 终止信号 16 SIGSTKFLT 栈溢出 17 SIGCHLD 子进程退出 默认忽略 18 SIGCONT 进程继续 19 SIGSTOP 进程停止 不能被忽略、处理和阻塞 20 SIGTSTP 进程停止 21 SIGTTIN 进程停止，后台进程从终端读数据时 22 SIGTTOU 进程停止，后台进程想终端写数据时 23 SIGURG I/O 有紧急数据到达当前进程 默认忽略 24 SIGXCPU 进程的 CPU 时间片到期 25 SIGXFSZ 文件大小的超出上限 26 SIGVTALRM 虚拟时钟超时 27 SIGPROF profile 时钟超时 28 SIGWINCH 窗口大小改变 默认忽略 29 SIGIO I/O 相关 30 SIGPWR 关机 默认忽略 31 SIGSYS 系统调用异常 对于 signal 信号，绝大部分的默认处理都是终止进程或停止进程，或 dump 内核映像转储。 上述的 31 的信号为非实时信号，其他的信号 32-64 都是实时信号。</description></item><item><title>Slack</title><link>https://desistdaydream.github.io/docs/Utils/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1/Slack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1/Slack/</guid><description>概述 参考：
官网 Wiki, Slack(software) Slack 是一个即时通信程序
Slack 提供了许多 IRC 风格的功能，包括 按主题组织的持久聊天室（频道）、私人群组和直接消息传递。
工作空间 Workspace(工作空间) 是 Slack 中核心且特殊的概念。Slack 的账号都是针对 Workspace 的，Slack 本身并没有一个账号。
这和我们平时用的聊天软件的使用逻辑有很大区别，Slack 并不是一个账号可以加入所有群组的。
频道 Channel(频道) 是 Slack 的组成基础，每个 Workspace 的多人聊天都是在频道中进行的。频道一般都是以 # 开头的。
一个新的 Workspace 中有一个默认的 Channel，这里包含了所有进入 Workspace 的成员。
Channel 分两类
公开 私密 应用 参考：
官方文档，Slack 中的应用指南 App(应用) 是 Slack 的扩展。也是 Slack 的重要组成，通过为 Workspace 添加应用，可以实现更多能力。</description></item><item><title>SNMP 采集第三方 MIB 文件定义的设备信息</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/SNMP-%E9%87%87%E9%9B%86%E7%AC%AC%E4%B8%89%E6%96%B9-MIB-%E6%96%87%E4%BB%B6%E5%AE%9A%E4%B9%89%E7%9A%84%E8%AE%BE%E5%A4%87%E4%BF%A1%E6%81%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/SNMP-%E9%87%87%E9%9B%86%E7%AC%AC%E4%B8%89%E6%96%B9-MIB-%E6%96%87%E4%BB%B6%E5%AE%9A%E4%B9%89%E7%9A%84%E8%AE%BE%E5%A4%87%E4%BF%A1%E6%81%AF/</guid><description>概述 参考：
https://lvii.github.io/server/2013-07-05-net-snmp-get-info-from-third-custumed-mib-file/ 厂里机房搞来 PDU 机柜电源插座，这个 bootbox 可以采集一些机柜温度，以及各个插座的电流功率啥的。
要用 SNMP 协议来获取这些信息，因为是第三方设备，要根据厂商的 MIB 文件中定义的 OID 来解析相关字段。
下面开始介绍怎么折腾：
把 MIB 放到系统 mibdirs 路径 让 net-snmp 工具自动加载 MIB 文件 用 snmptranslate 解析 MIB 文件中的 OID 用 snmpwalk 或 snmpget 采集对应 OID 字段信息 准备一下 snmp 相关的命令行工具，要在 CentOS 装上下面几个软件包：
rpm command net-snmp snmpd 服务 net-snmp-libs 系统常用的 MIBS 文件库 net-snmp-utils 提供 snmpget / snmpwalk / snmptranslate 等采集工具 net-snmp-devel 提供 net-snmp-config 命令行工具 修改 MIB 文件路径 参考 net-snmp 文档: 「Where should I put my MIB files?</description></item><item><title>SNMP(传统监控标准)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/SNMP%E4%BC%A0%E7%BB%9F%E7%9B%91%E6%8E%A7%E6%A0%87%E5%87%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/SNMP%E4%BC%A0%E7%BB%9F%E7%9B%91%E6%8E%A7%E6%A0%87%E5%87%86/</guid><description>概述 参考：
RFC 1157，A Simple Network Management Protocol (SNMP) RFC 1156，Management Information Base for Network Management of TCP/IP-based internets Wiki, SNMP Simple Network Management Protocol(简单网络管理协议，简称 SNMP)。想实现该协议，通常需要由两部分完成(监控端和被监控端)，是在两端的两个进程之间进行通信，该进程都需要占用一个 socket
监控端：通常称为 NMS 端，管理端 被监控端：通常称为 Agent 端，NMS 要去收集被监控端的数据的时候，可能收集到的是一些很敏感的数据(CPU 使用率，带宽占用率等，这些一般是不公开的)，所以需要在被监控节点上部署一个专门的程序，这个程序能在本地取得一定的管理权限，然后接受监控端发送的数据收集指令，代为在被监控节点本地完成数据收集，所以被称为 Agent 端，代理端 SNMP 的工作模式，使用 udp 协议发送报文
监控端主动发送请求到被监控端的 agent 去收集数据 被监控节点主动向监控端报告自己所采集的数据 当监控端发现被监控端发生异常时，可以发送一些控制指令，将被监控端修改一些参数 实现 SNMP 的组件 Management Information Base(管理信息库，简称 MIB) # 用来定义所有监控端的 objects，其中包括 objects 的名称、OID、数据类型、描述(干什么用的)。MIB 也可以看作是 SNMP 的服务端与代理端的沟通桥梁，只有具有统一的格式，才能确定数据。 Object(对象) # 这个对象可以是一个具体需要采集到的数据，比如 内存、CPU、磁盘、网络接口等等，也可以是一种抽象的集合，比如地区、硬件、系统、硬件、网络等等。上面说的所有事物，每一个都是一个 Object。所以，Object 可以包含另一个 Object，这也是人称常常将 MIB 称为树状的原因 Object Identifier(对象标识符，简称 OID) # 每一个 Object 都有一个 OID 数据存取格式：即每个 object 除了 OID 用作标示以外，还有数据内容需要遵循一定个格式规范 Structure of Managerment Intormation(管理信息结构,简称 SMI) # 是 ASN.</description></item><item><title>Snort</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Snort/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Snort/</guid><description>概述 参考：
GitHub 项目，snort3/snort3 官网 Wiki, Snort_(software) Snort 是世界上最重要的开源 Intrusion Prevention System(入侵防御系统，IPS)。 Snort IPS 使用一系列规则来帮助定义恶意网络活动，并使用这些规则来查找与其匹配的数据包并为用户生成警报。
Snort 也可以内联部署来阻止这些数据包。 Snort 有三个主要用途：作为数据包嗅探器（如 tcpdump）、作为数据包记录器 — 这对于网络流量调试很有用，或者可以用作成熟的网络入侵防御系统。 Snort 可以下载并配置用于个人和商业用途。
Snort 规则 参考：
官方文档，规则 Snort 规则主要由两部分组成
Rule header # 定义了流量的基础规则，协议、源/目 的 IP 和 PORT，最基本就是这 5-tuple。 Rule body # 类似于 7 层策略。定义了与指定规则关联的数据包的内容应该如何匹配。用 () 包裹起来。 Rule body 中包括很多可用的 OPTIONS，详见 https://docs.snort.org/rules/options/ ，比如 msg、flow、etc. 都是 OPTIONS。 以下是具有 Rule header 和 Rule body 定义的完整形式的 Snort 3 规则的示例：
alert tcp $EXTERNAL_NET 80 -&amp;gt; $HOME_NET any ( msg:&amp;#34;Attack attempt!</description></item><item><title>Snort Rule body</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Snort-Rule-body/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Snort-Rule-body/</guid><description>概述 参考：
官方文档，Rule Options Snort Rule body 由很多的 Options 组成，Options 是 Snort 规则的核心和灵魂，这些 Options 决定了被 Snort 规则影响的数据包是否应该通过并发往目的地，或是还是应该应该就此停止。
其中最关键的就是 Payload Detection(载荷监测) 选项，Payload 检测是对 Payload 进行匹配的核心规则，只要满足了匹配规则，就可以对匹配到的数据包进行一系列操作。
每个 Options 都有一个 name(名称)，关键字后面跟 :，冒号后面时 Options 的具体内容（也可以成为 Options 的条件），最后每个 Options 都要以 ; 结尾。有的选项带有 arguments(参数)，可以在 ; 之间用 , 分割 Options 和 Option arguments。
比如: content:&amp;quot; pizza&amp;quot;, within 6;
content 是 Option 的名称，表示这是一个名为 content 的选项。 &amp;quot;pizza&amp;quot; 是 Option 的内容 , within 6 是 Option 的参数 Rule Options 总共分为 4 类:</description></item><item><title>Socat</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Socat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Socat/</guid><description>概述 参考：
官网：http://www.dest-unreach.org/socat/ 官方文档：http://www.dest-unreach.org/socat/doc/socat.html Socat 是一个多功能的网络工具，名字来由是” Socket CAT”，可以看作是 Netcat 的 N 倍加强版。
Socat 是一个两个独立数据通道之间的双向数据传输的继电器。这些数据通道包含文件、管道、设备（终端或调制解调器等）、socket（Unix，IP4，IP6 - raw，UDP，TCP）、SSL、SOCKS4 客户端或代理 CONNECT。
Socat 支持广播和多播、抽象 Unix sockets、Linux tun/tap、GNU readline 和 PTY。它提供了分叉、记录和进程间通信的不同模式。多个选项可用于调整 socat 和其渠道，Socat 可以作为 TCP 中继（一次性或守护进程），作为一个守护进程基于 socksifier，作为一个 shell Unix 套接字接口，作为 IP6 的继电器，或面向 TCP 的程序重定向到一个串行线。
socat 的主要特点就是在两个数据流之间建立通道；且支持众多协议和链接方式：ip, tcp, udp, ipv6, pipe,exec,system,open,proxy,openssl,socket 等。
工作原理
socat 的运行有 4 个阶段:
初始化 解析命令行以及初始化日志系统。 打开连接 先打开第一个连接，再打开第二个连接。这个单步执行的。 如果第一个连接失败，则会直接退出。 数据转发 谁有数据就转发到另外一个连接上, read/write 互换。 关闭 其中一个连接掉开，执行处理另外一个连接。 地址类型 参数由 2 部分组成，第一个连接和第二个连接，最简单的用法就是 socat - - 其效果就是输入什么，回显什么其用法主要在于地址如何描述, 下面介绍几个常用的。 TCP TCP:&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt; 目标机器 IP 对应端口 portTCP-LISTEN:&amp;lt;port&amp;gt; 本机监听端口。</description></item><item><title>Socket</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Socket/Socket/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Socket/Socket/</guid><description>概述 参考：
Manual, socket(2) Manual, socket(7) GitHub 项目，torvalds/linux - include/linux/socket.h Wiki 搜索, Socket Socket(套接字) 是两个实体间进行数据通信的 Endpoint(端点)。是计算机领域中数据通信的一种约定，或者说是一种方法。通过 Socket 这种方法，计算机内的进程可以互相交互数据，不同计算机之间也可以互相交互数据。
Socket(套接字) 原意是 “插座”，所以 Socket 就像插座的作用一样，只要把插头插上，就能让设备获得电力。同理，只要两个程序通过 Socket 互相套接，也就是说两个程序都插在同一个 Socket 上，那么这两个程序就能交互数据。
在软件上，Socket 负责套接计算机中的数据(可以想象成套接管，套接管即为套管，是用来把两个管连接起来的东西，套接字就是把计算机中的字(即最小数据)连接起来，且只把头部连接起来，套管也是，只把两根很长的管的头端套起来接上)
在系统层面，Socket 可以连接系统中的两个进程，进程与进程本身是互相独立的，如果需要传递消息，那么就需要两个进程各自打开一个接口(API)，Socket 把两个进程的 API 套住使之连接起来，即可实现进程间的通信。该 Socket 是抽象的，虚拟的，只是通过编程函数来实现进程的 API 功能，如果进程没有 API，那么就无法通过 Socket 与其余进程通信。 当然，一个进程也可以监听一个名为 .scok 的文件，这个文件就像 API 一样，其他程序想与该进程交互，只要指定该 .sock 文件，然后对这个 .sock 文件进行读写即可。 在网络层面，Socket 负责把不在同一主机上的进程(比如主机 A 的进程 C 和主机 B 的进程 D)连接起来，而两个不同主机上的进程如何被套接起来呢，套接至少需要提供一个头端来让套接管(字)包裹住才行。这时候(协议，IP，端口,例如：ftp://192.168.0.1:22)共同组成了网络上的进程标示，该进程逻辑上的头端即为紫色部分的端口号，不同主机的两个进程可以通过套接字把端口号套起来连接，来使两个网络上不同主机的进程进行通信，该同能同样是在程序编程的时候用函数写好的，程序启动为进程的时候，则该接口会被拿出来监听。 想要在 Linux 中使用 Socket，可以直接利用 socket 系统调用 int socket(int domain, int type, int protocol); 创建一个 Socket。</description></item><item><title>ss</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ss/</guid><description>概述 参考：
Manual(手册)，ss(8) ss 用于转储 socket 统计信息。 它允许显示类似于 netstat 工具的信息。 它可以显示比其他工具更多的 TCP 和状态信息
Syntax(语法) ss [OPTIONS] [FILTER]
OPTIONS 如果不使用任何选项，则 ss 命令将显示已建立连接的打开的非监听套接字（例如 TCP / UNIX / UDP）的列表。
~]# ss Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port ...... u_str ESTAB 0 0 * 22170 * 22171 u_str ESTAB 0 0 /run/systemd/journal/stdout 23554 * 23347 u_str ESTAB 0 0 /var/lib/sss/pipes/private/sbus-dp_implicit_files.850 22246 * 22240 tcp ESTAB 0 0 172.19.42.248:ssh 172.19.42.203:63482 -A QUERY, &amp;ndash;query=QUERY, &amp;ndash;socket=QUERY # 要转储的套接字表的列表，用逗号分隔。可以理解以下标识符：all，inet，tcp，udp，raw，unix，packet，netlink，unix_dgram，unix_stream，unix_seqpacket，packet_raw，packet_dgram，dccp，sctp，vsock_stream，vsock_dgram，xdp 列表中的任何项目都可以选择添加前缀带有感叹号!</description></item><item><title>SSDP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/SSDP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/SSDP/</guid><description>概述 参考：
-Wiki, Simple_Service_Discovery_Protocol
Simple Service Discovery Protocol(简单服务发现协议，简称 SSDP) 是一种基于 TCP_IP
SSDP 使用 239.255.255.250 组播地址
SSDP 是 UPnP 技术的基础。</description></item><item><title>ssh</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/ssh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/ssh/</guid><description>概述 参考：
Manual(手册), ssh(1) Manual(手册), ssh_config(5) Syntax(语法) ssh [OPTIONS] [User@] HostIP [COMMAND]
OPTIONS -C # 请求压缩所有数据(包括 stdin、stdout、stderr、X11 转发的数据、TCP 和 UNIX-domain 连接) -i &amp;lt;/PATH/FILE&amp;gt; # 使用指定的私钥文件来进行登录认证 -J &amp;lt;DEST[,DEST2,&amp;hellip;]&amp;gt; # 首先与 DEST 建立 ssh 连接，并通过 DEST 跳转到最终目标主机。如果需要多次跳转。可以指定多个 DEST 并以逗号分割。 DEST 格式为：[USER@]HOST[:PORT] -o &amp;lt;KEY=VALUE&amp;gt; # 以命令行的方式配置本应该在 OpenSSH 配置 - ssh_config 文件中的内容。KEY 是 ssh_config 配置文件中的关键字。 -p &amp;lt;PORT&amp;gt; # 指定 HostIP 所在远程服务器监听的端口 -T # 不要分配一个伪终端 -W # 请求将客户端上的标准输入和输出通过安全通道转发到端口上的主机。 表示 -N，-T，ExitOnForwardFailure 和 ClearAllForwardings，尽管可以在配置文件中或使用 -o 命令行选项覆盖它们。 -X # 启用 X11 转发 -Y # 启用受信任的 X11 转发。 受信任的 X11 转发不受 X11 SECURITY 扩展控件的约束。 隧道选项 -w LOCAL_TUN[:REMOTE_TUN] # 在客户端与服务端建立互相连接的 tun 设备.</description></item><item><title>SSL/TLS Pinning</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/SSL_TLS-Pinning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/SSL_TLS-Pinning/</guid><description>概述 参考：
Wiki, HTTP_Public_Key_Pinning OWASP，Certificate and Public Key Pinning 知乎，证书锁定SSL Pinning简介及用途 SSL/TLS Pinning 也可以称为 Public Key Pinning、Certificate Pinning。顾名思义，将服务器提供的 SSL/TLS 证书内置到移动端开发的 APP 客户端中，当客户端发起请求时，通过比对内置的证书和服务器端证书的内容，以确定这个连接的合法性。
在公共网络中通知我们使用安全的 SSL/TLS 通信协议来进行通信，并且使用数字证书来提供加密和认证，在《HTTPS入门, 图解SSL从回车到握手》过程中我们知道握手环节仍然面临（MIM中间人）攻击的可能性，因为CA证书签发机构也存在被黑客入侵的可能性，同时移动设备也面临内置证书被篡改的风险。
SSL/TLS Pinning 原理 证书锁定（SSL/TLS Pinning）提供了两种锁定方式： Certificate Pinning 和 Public Key Pinning，文头和概述描述的实际上是 Certificate Pinning（证书锁定）。
HTTP Public Key Pinning(简称 HPKP) 在 RFC 7469 中标准化。扩展了 Certificate Pinning，Certificate Pinning 对 Web 浏览器和应用程序中的知名网站或服务的公钥哈希进行硬编码。
证书锁定 我们需要将APP代码内置仅接受指定域名的证书，而不接受操作系统或浏览器内置的CA根证书对应的任何证书，通过这种授权方式，保障了APP与服务端通信的唯一性和安全性，因此我们移动端APP与服务端（例如API网关）之间的通信是可以保证绝对安全。但是CA签发证书都存在有效期问题，所以缺点是在证书续期后需要将证书重新内置到APP中。
公钥锁定 公钥锁定则是提取证书中的公钥并内置到移动端APP中，通过与服务器对比公钥值来验证连接的合法性，我们在制作证书密钥时，公钥在证书的续期前后都可以保持不变（即密钥对不变），所以可以避免证书有效期问题。
证书锁定指纹(Hash) 获取移动端所需证书 如果采用证书锁定方式，则获取证书的摘要hash，以 infinisign.com 为例
## 在线读取服务器端.cer格式证书 openssl s_client -connect infinisign.com:443 -showcerts &amp;lt; /dev/null | openssl x509 -outform DER &amp;gt; infinisign.</description></item><item><title>Standard commands</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/OpenSSL/Standard-commands/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/OpenSSL/Standard-commands/</guid><description>概述 参考：
其他标准命令 openssl passwd - 对指定的字符串生成 hash 过的密码 openssl password [OPTIONS] [STRING]
MD5 算法加密后的格式为：$算法简称$SALT$XXXXXX，算法简称为 1 或者 apr1，SALT 为指定的盐的字符串，XXXX 为生成的加密的字符串
OPTIONS
-crypt # standard Unix password algorithm (default) -1 # -1 基于 MD5 的密码算法（注意：不指定 salt 的话，会使用随机的 slat） -salt # 在生成加密的密码中加盐(salt)。（为什么叫盐详见https://zh.wikipedia.org/wiki/%E7%9B%90_(%E5%AF%86%E7%A0%81%E5%AD%A6)这是密码学的一个概念）,加盐与不加盐得出的结果是不一样的 EXAMPLE
openssl passwd -1 123456 结果为：$1$ONQ8XSuX$Cv0wy2WbbbwOt/YkXuAlU/ openssl passwd -1 -salt 123 123456 结果为：$1$123$7mft0jKnzzvAdU4t0unTG1 openssl rand - 生成伪随机数字节 EXAMPLE
openssl rand -hex 6 # 生成随机数 RSA 标准命令 openssl genrsa - 生成 RSA 密钥 Syntax(语法) openssl genrsa [ OPTIONS ] [ ARGUMENTS ]</description></item><item><title>Statefulset Manifest</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/Statefulset-Manifest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/Statefulset-Manifest/</guid><description>概述 参考：
API 文档单页 官方文档，参考-KubernetesAPI-工作负载资源-StatefulSet Manifest 中的顶层字段 apiVersion: apps/v1 kind: StatefulSet metadata(metadata) spec(spec) # 指明该 StatefulSet 的规格 status(status) metadata Statefulset 对象的元数据，该字段内容详见通用定义的 [ObjectMeta](/docs/10.云原生/2.3.Kubernetes%20 容器编排系统/1.API、Resource(资源)、Object(对象)/API%20 参考/Common%20Definitions(通用定义).md Definitions(通用定义).md)
spec spec 用来描述一个 Statefulset 应该具有的属性。也就是用来定义 Statefulset 的行为规范。一共分为如下几类
描述 Statefulset 类型的控制器的行为 描述 Statefulset 控制器所关联的 Pod 的属性。 控制器行为 podManagementPolicy(STRING) # Pod 管理策略。默认值：OrderedReady 此配置只影响扩、缩 Pod 的行为，更新 Pod 不受此配置控制。可用的值有以下两个：
OrderedReady # 按照 Pod 的次序依次创建每个 Pod 并等待 Ready 之后才创建后面的 Pod Parallel # 并行创建或删除 Pod（不等待前面的 Pod Ready 就开始创建所有的 Pod） replicas(INT) # 该控制器运行的 Pod 数量，默认值：1。 selector(Object) # 必须的。Pod 的选择器，根据标签匹配要控制的 Pod。必须与 template.</description></item><item><title>Statistics</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Statistics/Statistics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Statistics/Statistics/</guid><description>概述 参考：
Statistics(统计学)
方差、标准差、标准误、离差 理顺这个逻辑，方差、标准差、标准误、离差的关系，就清楚了
检测和处理异常值 参考:
https://cloud.tencent.com/developer/article/2015850 本文是关于检测和处理数据集中的异常值，主要包含以下四部分内容：
什么是异常值？ 为什么检测异常值很重要？ 如何检测异常值？ 如何处理异常值？ 什么是异常值？ 异常值是与其他观察结果显着不同的数据点。如下图所示，橙色数据点与一般分布相去甚远。我们将此点称为异常值。
为什么检测异常值很重要？ 在数据科学项目、统计分析、机器学习应用中检测异常值非常重要：
异常值会导致分布偏斜。 异常值会严重影响数据集的均值和标准差。这些可能会在统计上给出错误的结果。 可能导致偏差或影响估计。 大多数机器学习算法在存在异常值的情况下都不能很好地工作。 异常值在欺诈检测等异常检测中非常有用，其中欺诈交易与正常交易非常不同。 特别是在线性问题中，异常值更能显示出它们的影响。例如下面的例子；左边的图片中当 x 变量的值增加时，y 变量的值减小。但是由于异常值，观察到随着变量 x 的值增加，变量 y 的值也增加。异常值扭曲了我们的分析结果。
在上面的示例中，如果从数据集中移除异常值，可以获得更准确、不会被误导的测试结果。
如何检测异常值？ 可以通过许多不同的方式检测异常值。下面总结了一些常用的方法：
领域的知识 标准差法 Z-Score法 箱线图（四分位距 - IQR）法 领域的知识
借助行业知识，可以了解数据集中的哪个观察结果可能是异常值。例如; 假设一名房地产经纪人，平均房屋租金为 700 美元。如果房屋租金为 5000 美元，就可以说这是一个异常值。
标准差法
在统计学中，标准偏差是衡量一组值的变化量或离散度的量度。低标准差表示这些值趋向于接近集合的平均值，而高标准差表示这些值分布在更宽的范围内。
正态分布如下图所示。在正态分布中，数据应该在一个小范围的值内，高值和低值的异常值较少。
如图上图所示，
68.27% 的值在平均值的 +1、-1 标准差范围内， 95.45% 的值在平均值的 +2、-2 标准差范围内， 99.73 % 的值在平均值的 +3、-3 标准差范围内。 在正态分布中，预计我们的数据应该远离平均值 -3、+3 个标准差。因此，有了这些信息，可以指定下限和上限；
Lower Limit = Mean - 3 * Standart Deviation Upper Limit = Mean + 3 * Standart Deviation Z-Score法</description></item><item><title>Status</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/Status/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/Status/</guid><description>概述 参考：
官方文档，参考-KubernetesAPI-通用定义-Status</description></item><item><title>Storage Pool 命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Storage-Pool-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Storage-Pool-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方 Manual(手册)，STORAGE POOL COMMANDS pool-create pool-info pool-list pool-destroy pool-dumpxml</description></item><item><title>Stream cipher</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cipher/Stream-cipher/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/Cipher/Stream-cipher/</guid><description>概述 参考：
Wiki, Stream_cipher 知乎，TRIVIUM:密码学 Stream Cipher</description></item><item><title>string 组</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/string-%E7%BB%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-CLI/string-%E7%BB%84/</guid><description>概述 参考：
https://redis.io/docs/latest/commands/?group=string APPEND - 附加一个 value 到指定的 key since: 2.0.0
Syntax(语法) APPEND key value
BITCOUNT key [start end]
summary: Count set bits in a string
since: 2.6.0
BITFIELD key [GET type offset] [SET type offset value] [INCRBY type offset increment] [OVERFLOW WRAP|SAT|FAIL]
summary: Perform arbitrary bitfield integer operations on strings
since: 3.2.0
BITOP operation destkey key [key &amp;hellip;]
summary: Perform bitwise operations between strings
since: 2.6.0
BITPOS key bit [start] [end]</description></item><item><title>su 与 sudo</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/su-%E4%B8%8E-sudo/su-%E4%B8%8E-sudo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/su-%E4%B8%8E-sudo/su-%E4%B8%8E-sudo/</guid><description>概述 参考：
su 参考：
Manual(手册), su(1) 总结 使用 su 命令切换用户身份然后执行命令虽然简单，但是，也有一些致命的缺点：
普通用户必须知道 root 密码才可以切换到 root，这样 root 密码就泄漏了。 使用 su 命令切换身份，无法对切换后的身份做精细的控制，拿到超级权限的人可以为所欲为。甚至可以改掉 root 密码，让真正的管理员无法再拥有 root 权限。 这时候，就可以使用 sudo 工具
su 配置 /etc/pam.d/su #
/etc/pam.d/su-l #
/etc/default/su #
/etc/login.defs #
sudo 参考：
Manual(手册), sudo(8) Manual(手册), sudoers(5) 如何改变 sudo 日志文件 sudo(substitute user [或 superuser] do) 程序可以让当前用户使用其他的用户的权限来执行指定的命令
通过 sudo 命令，我们可以把某些 root 权限(e.g.只有 root 用户才能执行的命令)分类有针对性授权给指定的普通用户，并且普通用户不需要知道 root 密码就可以使用得到的授权来管理。效果如下所示(配置好 sudo 之后，普通用户 desistdaydream 也可以通过在命令前加 sudo 来执行 root 才能执行的命令) sudo 通过各种插件实现功能。默认插件为 sudoers，用来确定用户的 sudo 权限，sudoers 的策略，通过 /etc/sudoers 文件进行配置，或者在 LDAP 中进行配置。</description></item><item><title>SUID,SGID,SBIT 特殊权限</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/SUIDSGIDSBIT-%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Access-Control%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/SUIDSGIDSBIT-%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90/</guid><description>概述 参考：
理解 Linux 特殊权限 SUID,SGID,SBIT setuid 和 setgid 分别是 set uid ID upon execution 和 set group ID upon execution 的缩写。我们一般会再次把它们缩写为 suid 和 sgid。它们是控制文件访问的权限标志(flag)，它们分别允许用户以可执行文件的 owner 或 owner group 的权限运行可执行文件。
说明：本文的演示环境为 Ubuntu 16.04。
SUID 在 Linux 中，所有账号的密码记录在 /etc/shadow 这个文件中，并且只有 root 可以读写入这个文件：
如果另一个普通账号 tester 需要修改自己的密码，就要访问 /etc/shadow 这个文件。但是明明只有 root 才能访问 /etc/shadow 这个文件，这究竟是如何做到的呢？事实上，tester 用户是可以修改 /etc/shadow 这个文件内的密码的，就是通过 SUID 的功能。让我们看看 passwd 程序文件的权限信息：
上图红框中的权限信息有些奇怪，owner 的信息为 rws 而不是 rwx。当 s 出现在文件拥有者的 x 权限上时，就被称为 SETUID BITS 或 SETUID ，其特点如下：</description></item><item><title>Surveillance</title><link>https://desistdaydream.github.io/docs/Utils/Surveillance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/Surveillance/</guid><description>概述 参考：
Wiki, Video surveillance 常见的监控摄像头（不是那种简单的接电脑用的通用摄像头）自身内部也是一个小型操作系统，具有 认证、网络、等等 相关能力。有的甚至可以提供 Web 服务，通过远程登录到摄像头的 Web，可以查看、更改摄像头相关配置。
常见网络摄像机(摄像头)的端口及RTSP地址
网络视频录像机 参考：
Wiki, Network_video_recorder Network video recorder(网络视频录像机，简称 NVR) 是一种专用计算机系统，其中包含软件程序，可将数字格式的视频记录到磁盘驱动器、USB 闪存驱动器、SD 存储卡或其他大容量存储设备上。 NVR 不包含专用的视频捕获硬件。然而，该软件通常在专用设备上运行，通常带有嵌入式操作系统。
网络录像机与数字录像机 (DVR) 不同，因为它们的输入来自网络，而不是直接连接到视频采集卡或调谐器。 DVR 上的视频在 DVR 处进行编码和处理，而 NVR 上的视频在摄像机处进行编码和处理，然后流式传输到 NVR 进行存储或远程查看。可以在 NVR 上进行附加处理，例如进一步压缩或用元数据标记。
常见架构 常见的架构是摄像头、录像机、交换机
摄像头 监控的基本单元 录像机 是一个1u的设备，有小型系统，可以通过显示器直接连接或web页面访问 交换机 通常是傻瓜型的没有vlan配置之类的，把摄像头、录像机、路由器都连上，录像机和摄像机都可以通过dhcp获得ip 海康威视 参考：
Wiki, Hikvision 4008005998
海康威视 和 萤石 其实是同一个品牌，萤石 是海康旗下的子品牌；萤石主要做的是消费者市场，也就是家用摄像头，而海康威视则主要都是卖专业的安防摄像头。
在萤石云app中也可以查看绑定的摄像头的画面
NVR NVR 可以接显示器，通过鼠标操纵 NVR 系统。可以展示已添加通道的内容。比如显示摄像头的实时画面。
在 NVR 中将可添加的设备抽象为“通道”，添加通道即可添加摄像头。正常情况下，录像机可以扫描到当前网络中的所有摄像头，直接点击添加即可，但是添加后需要手动设置摄像头的密码。
工具 参考：
官方文档，hitools 设备网络搜索 # 基于 SSDP 搜索局域网内所在网段的在线设备。同时支持查看设备信息、激活设备、修改设备的网络参数、重置设备密码等功能 向 239.</description></item><item><title>Syscalls 列表</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/System-Call/Syscalls-%E5%88%97%E8%A1%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/System-Call/Syscalls-%E5%88%97%E8%A1%A8/</guid><description>概述 参考：
Manual(手册)，syscall(2)- System call 列表 一、进程控制 a.创建进程 b.终止进程 c.载入、执行 d.获取/设置过程属性 e.等待时间、等待事件、信号事件 f.分配和释放内存 二、文件管理 a.创建文件、删除文件 open(&amp;ldquo;abc&amp;rdquo;, O_WRONLY|O_CREAT|O_NOCTTY|O_NONBLOCK, 0666)
创建文件，主要是使用了 O_CREAT 参数
unlink() # 删除文件
b.打开文件、关闭文件 open()、openat()、creat() - 打开并可能创建一个文件 https://man7.org/linux/man-pages/man2/openat.2.html
int open(const char *pathname, int flags); int open(const char *pathname, int flags, mode_t mode); int creat(const char *pathname, mode_t mode); int openat(int dirfd, const char *pathname, int flags); int openat(int dirfd, const char *pathname, int flags, mode_t mode); int openat2(int dirfd, const char *pathname, const struct open_how *how, size_t size); c.</description></item><item><title>sysfs</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/sysfs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/sysfs/</guid><description>概述 参考：
Manual(手册)，sysfs(5) 在 Man 中最后的 See Also 中提到了下面几个文档 https://github.com/torvalds/linux/blob/master/Documentation/filesystems/sysfs.rst Documentation/ABI Documentation/*/sysfs.txt 基于此，可以通过在 Linux 仓库的 go to file 搜索框中，输入 Documentation/sysfs 这种关键字，找到很多与 sysfs 相关的文件。TODO: 如何利用 path 关键字使用统配或正则在 github 全局搜索文件？ Kernel 文档，管理员指南 - 关于如何访问 sysfs 中信息的规则 Kernel 文档，管理员指南 - Linux ABI 描述 Wiki, Sysfs 用于导出 kernel objects(内核对象，简称 kobject) 的文件系统。对于在系统中注册的每个 kobject，都会在 sysfs 中为其创建一个目录。该目录被创建为 kobject 父目录的子目录，向用户空间表达内部对象层次结构。 sysfs 中的顶级目录代表对象层次结构的共同祖先；即对象所属的子系统。
Sys File System(sys 文件系统，简称 sysfs) 是一个 pseudo-filesystem(伪文件系统)，提供内核数据结构的接口(更准确地说，sysfs 中的文件和目录提供了内核内部定义的 kobject 结构的视图)。sysfs 下的文件提供关于设备、内核模块、文件系统和其他内核组件的信息。sysfs 一般挂载到 /sys 目录。通常情况下，系统会自动挂载它，但也可以使用 mount -t sysfs sysfs /sys 命令手动挂载</description></item><item><title>System 模块</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/System-%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/System-%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
2.9 官方文档，用户指南 - 使用模块 - System 模块 aix_devices – Manages AIX devices aix_filesystem – Configure LVM and NFS file systems for AIX aix_inittab – Manages the inittab on AIX aix_lvg – Manage LVM volume groups on AIX aix_lvol – Configure AIX LVM logical volumes alternatives – Manages alternative programs for common commands at – Schedule the execution of a command or script file via the at command authorized_key – Adds or removes an SSH authorized key awall – Manage awall policies beadm – Manage ZFS boot environments on FreeBSD/Solaris/illumos systems capabilities – Manage Linux capabilities cron – Manage cron.</description></item><item><title>systemd.exec 类指令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/systemd.exec-%E7%B1%BB%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/systemd.exec-%E7%B1%BB%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
Manual(手册)，systemd.exec(5) systemd.exec 类的指令是 Unit File 指令中特殊部分的指令中的通用指令 的一种，可以配置进程执行时的环境，主要用于 service、socket、mount、swap 部分。
systemd.exec 包含很多很多指令，我们可以将其分为如下几大类：
PATHS # 路径相关指令 USER/GROUP IDENTITY # 用户/组标识相关指令 CAPABILITIES SECURITY MANDATORY ACCESS CONTROL PROCESS PROPERTIES SCHEDULING SANDBOXING SYSTEM CALL FILTERING ENVIRONMENT # 环境变量相关指令 LOGGING AND STANDARD INPUT/OUTPUT CREDENTIALS SYSTEM V COMPATIBILITY 比如 环境变量、运行程序的用户和组、运行路径 等等
Paths https://man7.org/linux/man-pages/man5/systemd.exec.5.html#PATHS
Paths(路径) 相关的指令可用于更改文件系统的服务视图。请注意，路径必须是绝对路径，并且不得包含 .. 路径组件。
WorkingDirectory=&amp;lt;STRING&amp;gt; # 采用相对于由 RootDirectory 指令 或特殊值 ~ 指定的服务根目录的目录路径。
User/Group Identity https://man7.org/linux/man-pages/man5/systemd.exec.5.html#USER/GROUP_IDENTITY
User=&amp;lt;STRING&amp;gt; # 指定运行该 Unit 使用的用户。 CAPABILITIES(能力)相关指令 https://man7.org/linux/man-pages/man5/systemd.exec.5.html#CAPABILITIES</description></item><item><title>Table 面板</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Table-%E9%9D%A2%E6%9D%BF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Table-%E9%9D%A2%E6%9D%BF/</guid><description>概述 参考：
Table 面板需要配合 Table 格式
当从 Prometheus 获取了一条 Serie 的数据后，使用 Table 对数据进行格式化，那么就会形成上图所示的样子。这条 serie 的所有标签、时间、值 都会被 Grafana 转换为 [Field(字段)](/docs/6.可观测性/Grafana/Panel(面板)%20 与%20Dashboard(仪表盘)/Panel(面板)%20 配置详解.md 配置详解.md)。
Panel - 面板配置 Field - 字段相关配置 Overrides - 字段替换配置</description></item><item><title>Tailscale ACL</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale-ACL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale-ACL/</guid><description>概述 参考：
官方文档，使用 ACL 管理权限 官方文档，参考 - Tailnet 策略文件语法 Tailscale 博客，RBAC 的初衷 ACL 的配置示例 groups https://tailscale.com/kb/1337/policy-syntax#groups
hosts https://tailscale.com/kb/1337/policy-syntax#hosts
acls https://tailscale.com/kb/1337/policy-syntax#acls
dst dst 字段设置一个访问目标的列表，该列表是一组适用于某 acl 规则的访问目标。
列表中的每个元素格式为 HOST:PORTS。i.e. 1 个 host，1 个或多个 ports。
HOST 可以是一以下任意类型
Type Example Description Any * Includes any destination (no restrictions). User shreya@example.com Includes any device currently signed in as the provided user. Group group:&amp;lt;group-name&amp;gt; Includes all users in the provided group. Tailscale IP address 100.101.102.103 Includes only the device that owns the provided Tailscale IP address.</description></item><item><title>tailscale CLI</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/tailscale-CLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/tailscale-CLI/</guid><description>概述 参考：
官方文档，参考 - CLI Syntax(语法) tailscale COMMAND
netcheck # 打印本地网络状况分析。主要是显示当前可用的 DERP 以及本机到各个 DERP 的连接延迟 等信息。 ping &amp;lt;HOST&amp;gt; # 通过 Tailscale ping 指定主机，看看本机是如何路由到目标的（是直通还是经过了 DERP） set # 改变指定的配置。 login/logout login 登录到 Tailscale 协调服务器
logout 从Tailscale 协调服务器登出，并使节点的密钥过期
up/down 连接/断开 与 Tailscaled 的链接。断开后，Tailscale 协调服务器（e.g. Headscale）将不会连接到该节点。
set &amp;ndash;accept-routes # 是否接受其他节点公开的路由信息。默认值: false
Tips: 对应 /var/lib/tailscale/tailscaled.state 文件中 .profile-XXX 字段中的 .RouteAll 字段 &amp;ndash;advertise-routes # 向整个 Tailscale 网络公开本机的路由。也就是说告诉其他节点访问哪些 IP 要经过本机。默认值: 空，值是以 , 分割的 CIDR 格式的子网
switch 显示或切换到不同的 Tailscale 账户。</description></item><item><title>Tailscale DERP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale-DERP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale-DERP/</guid><description>概述 参考：
公众号，自建 DERP 中继服务器，从此 Tailscale 畅通无阻 官方文档，自定义 DERP 服务器 上篇文章介绍了如何使用 Headscale 替代 Tailscale 官方的控制服务器，并接入各个平台的客户端。本文将会介绍如何让 Tailscale 使用自定义的 DERP Servers。可能很多人都不知道 DERP 是个啥玩意儿，没关系，我先从 中继服务器 开始讲起。
STUN 是什么 Tailscale 的终极目标是让两台处于网络上的任何位置的机器建立点对点连接（直连），但现实世界是复杂的，大部份情况下机器都位于 NAT 和防火墙后面，这时候就需要通过打洞来实现直连，也就是 NAT 穿透。
NAT 按照 NAT 映射行为和有状态防火墙行为可以分为多种类型，但对于 NAT 穿透来说根本不需要关心这么多类型，只需要看 NAT 或者有状态防火墙是否会严格检查目标 Endpoint，根据这个因素，可以将 NAT 分为 Easy NAT 和 Hard NAT。
Easy NAT 及其变种称为 “Endpoint-Independent Mapping” (EIM，终点无关的映射) 这里的 Endpoint 指的是目标 Endpoint，也就是说，有状态防火墙只要看到有客户端自己发起的出向包，就会允许相应的入向包进入，不管这个入向包是谁发进来的都可以。 hard NAT 以及变种称为 “Endpoint-Dependent Mapping”（EDM，终点相关的映射） 这种 NAT 会针对每个目标 Endpoint 来生成一条相应的映射关系。在这样的设备上，如果客户端向某个目标 Endpoint 发起了出向包，假设客户端的公网 IP 是 2.</description></item><item><title>Tampermonkey</title><link>https://desistdaydream.github.io/docs/Web/Browser/Extensions/Tampermonkey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Browser/Extensions/Tampermonkey/</guid><description>概述 参考：
官网 GitHub 项目，Tampermonkey/tampermonkey 社区
https://bbs.tampermonkey.net.cn/ 其他类 Tampermonkey https://github.com/scriptscat/scriptcat</description></item><item><title>TCP Analysis</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/TCP-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/TCP-Analysis/</guid><description>概述 参考：
官方文档，TCP Analysis 公众号 - 小林 coding，一文搞定 Wireshark 网络数据包分析（Notes: 一文搞不定） https://help.aliyun.com/document_detail/112990.html(Wireshark 常见提示) 使用 Wireshark 分析 TCP。
通过 WireShark 理解三次握手和四次挥手 通过 WireShark 分析网络包，并理解 TCP 三次握手和四次挥手的工作原理。
本次例子，我们将要访问的 http://192.168.3.200 服务端。在终端用 tcpdump 命令抓取数据包：
# 客户端执行 tcpdump 命令抓包 tcpdump -i any tcp and host 192.168.3.200 and port 80 -w http.pcap 接着，在终端二执行下面的 curl 命令 curl http://192.168.3.200
最后，回到终端一，按下 Ctrl+C 停止 tcpdump，并把得到的 http.pcap 取出到电脑。
使用 Wireshark 打开 http.pcap 后，你就可以在 Wireshark 中，看到如下的界面：
我们都知道 HTTP 是基于 TCP 协议进行传输的，那么：
最开始的 3 个包就是 TCP 三次握手建立连接的包 中间是 HTTP 请求和响应的包 而最后的 3 个包则是 TCP 断开连接的挥手包 Wireshark 可以用时序图的方式显示数据包交互的过程，从菜单栏中，点击 统计 (Statistics) -&amp;gt; 流量图 (Flow Graph)，然后，在弹出的界面中的 「流量类型」选择 「TCP Flows」，你可以更清晰的看到，整个过程中 TCP 流的执行过程：</description></item><item><title>TCP Header</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/TCP-Header/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/TCP-Header/</guid><description>概述 参考：
RFC 9293，3.1.Header Format TCP 段被封装在 IP 数据报中
首部长度：一般为 20 字节，选项最多 40 字节，限制 60 字节。下图中的位，即代表 bit，也就是说，首部一共 160 bit，即 20 Byte。
对照在 WireShark 中展示的内容看，排除 [] 中的内容，WireShark 中展示的一个 SYN TCP 段的内容，每一行就是包头中的一个内容
Source Port(源端口号) # Destination Port(目的端口号) # 每个 TCP 报文段都包含源和目的的端口号，这两个端口号用于寻找发送端与接收端的应用进程。这两个值加上 IP 首部中的源和目的的 IP 地址，组成 TCP 四元组，用于确定唯一一个 TCP 连接。 Sequence Number(序号，简称 SeqNum) # TCP 报文段的唯一标识符，该标识符具有先后顺序。如果不为每一个包编号，则没法确认哪个包先来哪个包后来。 SeqNum 用来解决网络包乱序的问题。 Initial Sequence Number(初始序号，简称 ISN) # TCP 交互的两端，有一个初始的 SeqNum，就是 A 发送给 B 或者 B 发送给 A 的第一个 TCP 段，这第一个 TCP 段的 SeqNum 就是 ISN。 注意：TCP 为应用层提供全双工服务，这意味着数据能在两个方向上独立进行传输。因此，一个 TCP 连接的两端都会有自己独立的 SeqNum。所以首次建立连接时客户端和服务端都会生成一个 ISN。ISN 是一个随机生成的数。 SeqNum 最大值为 232-1，到达最大值后，回到 0 开始。 Acknowledgment Number(确认序号，简称 AckNum) # 下一次期望收到数据中报文段的 SeqNum。发出去的包应该有确认，要不然怎么知道对方有没有收到呢？如果没有收到就应该重新发送，直到送达。 AckNum 用来解决丢包的问题。 AckNum 可以用来确认上次发送的数据大小。 假如 172.</description></item><item><title>TCP 异常处理</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</guid><description>概述 参考：
有些 TCP 异常处理的详解在 WireShark 目录下的 TCP Analysis 笔记中
万字长文 | 23 个问题 TCP 疑难杂症全解析 原文: https://juejin.cn/post/6869734247465402382
https://mp.weixin.qq.com/s/cyeeXx7fLZ_ngB-QnMM_TQ 每个时代，都不会亏待会学习的人。
在进入今天主题之前我先抛几个问题，这篇文章一共提出 23 个问题。
TCP 握手一定是三次？TCP 挥手一定是四次？
为什么要有快速重传，超时重传不够用？为什么要有 SACK，为什么要有 D-SACK？
都知道有滑动窗口，那由于接收方的太忙了滑动窗口降为了 0 怎么办？发送方就永远等着了？
Silly Window 又是什么？
为什么有滑动窗口流控还需要拥塞控制？
快速重传一定要依赖三次重复 ACK ？
这篇文章我想由浅到深地过一遍 TCP，不是生硬的搬出各个知识点，从问题入手，然后从发展、演进的角度来看 TCP。
起初我在学计算机网络的时候就有非常非常多的疑问，脑子里简直充满了十万个为什么，而网络又非常的复杂，发展了这么多年东西真的太多了，今天我就大致的浅显地说一说我对 TCP 这些要点的理解。
好了，废话不多说，开始上正菜。
TCP 是用来解决什么问题？ TCP 即 Transmission Control Protocol，可以看到是一个传输控制协议，重点就在这个控制。
控制什么？
控制可靠、按序地传输以及端与端之间的流量控制。够了么？还不够，它需要更加智能，因此还需要加个拥塞控制，需要为整体网络的情况考虑。
这就是出行你我他，安全靠大家。
为什么要 TCP，IP 层实现控制不行么？ 我们知道网络是分层实现的，网络协议的设计就是为了通信，从链路层到 IP 层其实就已经可以完成通信了。
你看链路层不可或缺毕竟咱们电脑都是通过链路相互连接的，然后 IP 充当了地址的功能，所以通过 IP 咱们找到了对方就可以进行通信了。
那加个 TCP 层干啥？IP 层实现控制不就完事了嘛？</description></item><item><title>TCP 重置</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP-%E9%87%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP-%E9%87%8D%E7%BD%AE/</guid><description>概述 参考：
公众号-小林coding，原来墙，是这么把我 TCP 连接干掉的！ 大家好，我是小林。
再过几天就春节了，应该很多小伙伴都已经放假了，或者是在回家的路上。
就不聊太硬核的技术了，今天聊一个比较轻松的问题：如何关闭一个 TCP 连接？
可能大家第一反应是「杀掉进程」不就行了吗？
是的，这个是最粗暴的方式，杀掉客户端进程和服务端进程影响的范围会有所不同：
在客户端杀掉进程的话，就会发送 FIN 报文，来断开这个客户端进程与服务端建立的所有 TCP 连接，这种方式影响范围只有这个客户端进程所建立的连接，而其他客户端或进程不会受影响。 而在服务端杀掉进程影响就大了，此时所有的 TCP 连接都会被关闭，服务端无法继续提供访问服务。 所以，关闭进程的方式并不可取，最好的方式要精细到关闭某一条 TCP 连接。
有的小伙伴可能会说，伪造一个四元组相同的 RST 报文不就行了？
这个思路很好，「伪造 RST 报文来关闭 TCP 连接」的方式其实有个专业术语叫：TCP 重置攻击。
我们的墙，在过滤网站的时候，其实就是这么干的。当然，墙除了 TCP 重置连接的方式外，还有很多方式来过滤网站，比如域名劫持、IP封锁、HTTPS 证书过滤等等。
这次我们只重点关注 TCP 重置技术。
TCP 重置技术 伪造 RST 报文说来简单，但是不要忘了还有个「序列号」的问题，你伪造的 RST 报文的序列号一定能被对方接受吗？
如果 RST 报文的序列号不是对方期望收到的序列号，那么这个 RST 报文则会被对方丢弃，就达不到重置 TCP 连接的效果了。
举个例子，下面这个场景，客户端发送了一个长度为 100 的 TCP 数据报文，服务端收到后响应了 ACK 报文，表示收到了这个 TCP 数据报文。服务端响应的这个 ACK 报文中的确认号（ack = x + 100）就是表明服务端下一次期望收到的序列号是 x + 100。</description></item><item><title>Tempo</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Traces/Tempo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Traces/Tempo/</guid><description>概述 参考：
原文链接：https://cloud.tencent.com/developr/article/1759966 Tempo是 Grafana Labs 在ObservabilityCON 2020大会上新开源的一个用于做分布式式追踪的后端服务。它和 Cortex、Loki 一样，Tempo 也是一个兼备高扩展和低成本效应的系统。
之前小白有提到 Grafana Labs 的云原生 Observability 宇宙只剩下 trace 部分，那么今天就拿 Loki 的分布式追踪来体验下这 Observability 的最后一环吧。正式开始前，先看下小白精心准备的 Tempo 体验视频吧。
关于 Tempo Tempo 本质上来说还是一个存储系统，它兼容一些开源的 trace 协议（包含 Jaeger、Zipkin 和 OpenCensus 等），将他们存在廉价的 S3 存储中，并利用 TraceID 与其他监控系统（比如 Loki、Prometheus）进行协同工作。
可以看到 Tempo 的架构仍然分为distributor、ingester、querier、tempo-query、compactor这几个架构，熟悉 Loki 和 Cortex 的朋友可能光看名字就知道他们大概是做什么的。不熟悉的同学也没关系，下面简单说下各模块的作用：
distributor 监听多个端口，分别接受来自 Jaeger、Zipkin 和 OpenCensus 协议的数据，按照 TraceID 进行哈希并映射到哈希环上，并交由 ingester 进行存储处理。当前 distributor 支持的 trace 协议如下：
Protocol Port OpenTelemetry 55680 Jaeger - Thrift Compact 6831 Jaeger - Thrift Binary 6832 Jaeger - Thrift HTTP 14268 Jaeger - GRPC 14250 Zipkin 9411 ingester 具体负责 trace 数据的块存储（memcache、GCS、S3）、缓存（Memcache）和索引的处理</description></item><item><title>Time</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Time/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Time/</guid><description>概述 参考：
Wiki, ISO 8601 Wiki-cn，各地日期和时间表示法 https://baike.baidu.com/item/ISO%208601/3910715?fr=aladdin 中国计量科学研究院，SI 基本单位 1983 年，国际计量大会讨论决定，把 1 米的定义修改为光在 1/299792458 秒内走过的距离
1967 年，国际计量大会定义：1 秒是铯 133 原子基态的两个超精细能量间跃迁对应辐射的 9192631770 个周期的持续时间。
Timestamps 参考：
RFC 3339，Date and Time on the Internet: Timestamps Wiki, Timestamp Momentjs，时间格式 Timestamps(时间戳) 是识别特定事件发生时间的字符序列或编码信息，通常给出 date(日期) 和 time(时间)，有时精确到一秒的一小部分。然而，时间戳不必基于某种绝对的时间概念。它们可以具有任何纪元，可以相对于任何任意时间，例如系统的开机时间，或相对于过去的某个任意时间。
日期
日期格式为 YYYY-MM-DD，其中 YYYY 为年，MM 为月 (01–12)，DD 为月份日期 (01–31)。例如，2022 年 1 月 1 日显示为 2022-01-01。如果仅显示月和日，则格式为 MM-DD。例如，6 月 11 日显示为 06-11。
时间
时间格式为 HH:mm:ss，其中 HH 为小时 (00–24)，mm 为分钟 (00–60)，ss 为秒 (00–60)。如果仅显示小时和分钟，则格式为 hh:mm，例如 23:59。</description></item><item><title>Time series 面板</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Time-series-%E9%9D%A2%E6%9D%BF/Time-series-%E9%9D%A2%E6%9D%BF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Time-series-%E9%9D%A2%E6%9D%BF/Time-series-%E9%9D%A2%E6%9D%BF/</guid><description>概述 参考：
这是一个初始的 Time series 面板，有两条查询语句，更改了序列的名称。
sum(node_memory_MemTotal_bytes) (sum(node_memory_MemTotal_bytes{} - node_memory_MemAvailable_bytes{}) / sum(node_memory_MemTotal_bytes{}))*100 Time series 是一个二维的，具有 x/y Axes(轴) 的面板。x 轴(横轴) 以时间分布、y 轴(纵轴) 以样本值分布
下面的文章将只介绍 Time series 面板的独有配置，有很多共有配置详见 Panel
Panel - 面板配置 Tooltip(工具提示) 当鼠标移动到面板上是显示的提示，效果如下
Legend - 用于配置面板内的 Legend Legend
Graph styles(图表样式) 设置值的显示样式(柱状、线条、圆点三种) 其他的配置选项，都是在开启某个样式后，才会显示对应样式专用的选项。 Min step 设置时间长一点，Bars 与 Points 样式才可以看出来效果。否则都挤到一坨去了~
Style # 指定图表样式
Bars # 柱状图样式。当 X 轴的模式变为 Series、Historgram 时，自动开启 Lines # 线条样式。 Line width # 线条宽度。 Fill opacity# 填充不透明。默认 0。 Points # 圆点样式。 Point size# 每个圆点的大小 Alert thresholds # 在面板上显示报警阈值和区域</description></item><item><title>TLB</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Memory/TLB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Memory/TLB/</guid><description>概述 参考：
Wiki, Translation lookaside buffer translation lookaside buffer(转换后被缓冲区，简称 TLB) 用于减少访问用户内存位置所需的时间，是 MMU 的一部分
TLB 是一种 Cache 功能，CPU 在寻址时，若是从 TLB 没有查到虚拟内存地址与物理内存地址的对应关系，称为 未命中，此时会去查找常规的页表。</description></item><item><title>tmpfs</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/tmpfs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%89%B9%E6%AE%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/tmpfs/</guid><description>概述 参考：
GitHub 项目，torvalds/linux - Documentation/filesystems/tmpfs.rst Kernel 文档，文件系统 - tmpfs Tmpfs 是一个将所有文件保存在虚拟内存中的文件系统。tmpfs 中的所有内容都是 temporary(临时) 的，因为不会在硬盘上创建任何文件。如果卸载 tmpfs 实例，其中存储的所有内容都会丢失。
tmpfs 将所有内容放入内核内部缓存中，并增长和收缩以容纳其包含的文件，并且如果为 tmpfs 挂载启用了 swap，则能够将不需要的页面交换到交换空间。 tmpfs 还支持 THP。
tmpfs 有 3 个用于调整大小的挂载选项
size # 为此 tmpfs 分配的 Bytes 。默认值: 物理内存的一半 nr_blocks # 与 size 相同，但是以 PAGE_SIZE 为单位。 nr_inodes # 为此 tmpfs 分配的最大 inodes 数。默认值: 物理内存 pages 的一半</description></item><item><title>TODO</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/TODO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/TODO/</guid><description>概述 参考：
https://github.com/drunkdream/turbo-tunnel
https://github.com/turbo-tunnel/docs https://github.com/turbo-tunnel/telnet-go # 这是一个用go实现的telnet程序，你可以把它当作一个普通的 telnet 客户端来用（访问中文 telnet 服务端可能会有乱码）。当然，它的真正用途并不在此，而是用于当 SSH 服务端不支持端口转发时建立一个 TCP 隧道。实现原理是通过将 socket 双向通信转换为对stdin和stdout的读写，而stderr则用于日志或错误信息的输出。</description></item><item><title>TOML</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/TOML/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/TOML/</guid><description>概述 参考：
GitHub 项目，toml-lang/toml 官方文档 Wiki, TOML 知乎 格式对比 Tom&amp;rsquo;s Obvious, Minimal Language(简称 TOML) 是一种配置语言，旨在称为一种最小的配置文件结构，并且易于阅读、具有显而易见的语义。
TOML 规范 TOML 大小写敏感 TOML 必须是有效的 UTF-8 编码的 Unicode 文档 空白表示 Tab(0x09) 或 空格(0x20) 换行表示 LF(0x0a) 或 CRLF(0x0D 0x0A) TOML 特点 TOML 的原子单位也是 Key/Value pair(键值对)。多个 Key/Value pair 组成一个 Table(表)。
所以，一个 TOML 格式的配置文件，本质上是 Table(表) 的集合。
TOML 放弃了括号或缩进的底层原理，而是以 . 符号来表示层级关系(实现类似缩进的效果)
TOML 基本示例 # This is a TOML document. title = &amp;#34;TOML Example&amp;#34; [owner] name = &amp;#34;Tom Preston-Werner&amp;#34; dob = 1979-05-27T07:32:00-08:00 # First class dates [database] server = &amp;#34;192.</description></item><item><title>Torch</title><link>https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/Torch/</guid><description>概述 参考：
GitHub 项目，torch/torch7 官网 Wiki, Torch(机器学习) Torch 是一个开源的机器学习库，一个科学计算框架，也是一种基于 Lua 的脚本语言。它为用 C 实现的深度学习算法提供 LuaJIT 接口。它是在 EPFL 的 IDIAP 创建的。 Torch 开发于 2017 年转移到 PyTorch，这是 Python 库的一个端口。
Torch 自称为神经网络界的 Numpy，因为他能将 Torch 产生的 Tensor(张量) 放在 GPU 中加速运算 (前提是你有合适的 GPU)，就像 Numpy 会把 array 放在 CPU 中加速运算。所以神经网络的话, 当然是用 Torch 的 tensor 形式数据最好。就像 Tensorflow 当中的 Tensor 一样。
安装 略，一般都安装 PyTorch</description></item><item><title>Transformers</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Transformers/</guid><description>概述 参考：
GitHub 项目，huggingface/transformers Wiki, Transformer_(machine_learning_model) Hugging Face 创始人亲述：一个 GitHub 史上增长最快的 AI 项目 官方文档 Transformer 架构由 Google 在 2017 年发表的论文 《Attention is All You Need》首次提出，它使用 Self-Attention(自注意力) 机制取代了之前在 NLP 任务中常用的 RNN(循环神经网络)，使其成为预训练语言模型阶段的代表架构。
Transformer 是 Hugging Face 开源的是一种深度学习模型，它采用自注意力机制，对输入数据的每一部分的重要性进行差异加权。它主要用于 自然语言处理(NLP) 和 计算机视觉(CV) 领域。
Transformers 提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。它的宗旨是让最先进的 NLP 技术人人易用。
Transformers 提供了便于快速下载和使用的 API，让你可以把预训练模型用在给定文本、在你的数据集上微调然后通过 model hub 与社区共享。同时，每个定义的 Python 模块均完全独立，方便修改和快速研究实验。
Transformers 支持三个最热门的深度学习库： Jax, PyTorch 以及 TensorFlow — 并与之无缝整合。你可以直接使用一个框架训练你的模型然后用另一个加载和推理。
安装 Transformers 安装 Transformers 本质就是安装 Transformers 的模型，并且还需要一些可以调用模型的代码(通常都是 Python 包)。</description></item><item><title>TSConfig</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/TSConfig/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/TSConfig/</guid><description>概述 参考：
官方文档，项目配置-tsconfig.json 是什么 官方文档，TSConfig 参考 TSConfig 通常是名为 tsconfig.json 或 jsconfig.json 的文件，当目录中出现了 tsconfig.json 文件，则说明该目录是 TypeScript 项目的根目录。tsconfig.json 文件指定了编译项目所需的根目录下的文件以及编译选项。
简单示例 可以运行 ES6 语法（导入包时用的 import 关键字）逻辑的 TS 代码的配置
{ &amp;#34;compilerOptions&amp;#34;: { // &amp;#34;target&amp;#34;: &amp;#34;es2016&amp;#34;, &amp;#34;module&amp;#34;: &amp;#34;ES6&amp;#34;, &amp;#34;esModuleInterop&amp;#34;: true, } } 注意，若环境中有 package.json 文件，需要搭配该文件中的 &amp;quot;type&amp;quot;: &amp;quot;module&amp;quot; 配置，才可以正常使用 ES6 语法。
compilerOptions baseUrl paths 配置路径别名。
若使用 Vite 打包代码，则需要在 vite.config.ts 文件中也同步配置 resolve.alias：
export default defineConfig({ resolve: { alias: { // 让我们在导入时使用可以使用 @ 符号作为 src 目录的别名，而不是相对路径，比如： // import App from &amp;#39;@/App.</description></item><item><title>TSDB Admin APIs</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/TSDB-Admin-APIs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-API/TSDB-Admin-APIs/</guid><description>概述 参考：
官方文档</description></item><item><title>TUN and TAP</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/TUN-and-TAP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/TUN-and-TAP/</guid><description>概述 参考：
网络虚拟化技术（二）: TUN/TAP MACVLAN MACVTAP Wiki, TUN/TAP TUN/TAP 类型的设备会利用 /dev/net/tun 文件, 基于 tun.ko 模块实现(TODO).
TUN 设备 TUN 设备是一种虚拟网络设备，通过此设备，程序可以方便地模拟网络行为。TUN 模拟的是一个三层设备,也就是说,通过它可以处理来自网络层的数据，更通俗一点的说，通过它，我们可以处理 IP 数据包。
先来看看物理设备是如何工作的：
上图中的 eth0 表示我们主机已有的真实的网卡接口 (interface)。
网卡接口 eth0 所代表的真实网卡通过网线(wire)和外部网络相连，该物理网卡收到的数据包会经由接口 eth0 传递给内核的网络协议栈(Network Stack)。然后协议栈对这些数据包进行进一步的处理。
对于一些错误的数据包,协议栈可以选择丢弃；对于不属于本机的数据包，协议栈可以选择转发；而对于确实是传递给本机的数据包,而且该数据包确实被上层的应用所需要，协议栈会通过 Socket API 告知上层正在等待的应用程序。
下面看看 TUN 的工作方式：
我们知道，普通的网卡是通过网线来收发数据包的话，而 TUN 设备比较特殊，它通过一个文件收发数据包。
如上图所示，tunX 和上面的 eth0 在逻辑上面是等价的， tunX 也代表了一个网络接口,虽然这个接口是系统通过软件所模拟出来的.
网卡接口 tunX 所代表的虚拟网卡通过文件 /dev/tunX 与我们的应用程序(App) 相连，应用程序每次使用 write 之类的系统调用将数据写入该文件，这些数据会以网络层数据包的形式，通过该虚拟网卡，经由网络接口 tunX 传递给网络协议栈，同时该应用程序也可以通过 read 之类的系统调用，经由文件 /dev/tunX 读取到协议栈向 tunX 传递的所有数据包。
此外，协议栈可以像操纵普通网卡一样来操纵 tunX 所代表的虚拟网卡。比如说，给 tunX 设定 IP 地址，设置路由，总之，在协议栈看来，tunX 所代表的网卡和其他普通的网卡区别不大，当然，硬要说区别，那还是有的,那就是 tunX 设备不存在 MAC 地址，这个很好理解，tunX 只模拟到了网络层，要 MAC 地址没有任何意义。当然，如果是 tapX 的话，在协议栈的眼中，tapX 和真是网卡没有任何区别。</description></item><item><title>UltraISO</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ISO%E6%96%87%E4%BB%B6%E4%B8%8E%E5%8F%AF%E5%90%AF%E5%8A%A8U%E7%9B%98%E5%88%B6%E4%BD%9C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ISO%E6%96%87%E4%BB%B6%E4%B8%8E%E5%8F%AF%E5%90%AF%E5%8A%A8U%E7%9B%98%E5%88%B6%E4%BD%9C%E5%B7%A5%E5%85%B7/</guid><description>Rufus 参考：
官网 UltraISO 参考：
官网 UltraISO 是一个运行在Microsoft Windows平台上的用来创建、修改和转换ISO文件的软件。
官方似乎没有 Portable(便携版)~~ o(╯□╰)o
将 ISO 文件写到 U 盘 插入 U 盘 打开 iso 文件。 “写入硬盘映像” 在”硬盘驱动器“栏选择想要写入数据的 U 盘，点击“写入“</description></item><item><title>Unix Domain Socket</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Socket/Unix-Domain-Socket/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/Socket/Unix-Domain-Socket/</guid><description>概述 参考：
Manual, unix(7) Wiki, Unix domain Socket Unix Domain Socket 是 IPC 的一种实现方式。Socket 原本是为了网络通信设计的，但后来在 Socket 的框架上发展出一种 IPC 机制，就是 Unix Domain Socket。虽然 Netork Socket 也可用于同一台主机的进程间通信(通过 loopback 地址 127.0.0.1)，但是 Unix Domain Socket 用于 IPC 更有效率，因为不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等，只是将应用层数据从一个进程拷贝到另一个进程。这是因为 IPC 机制本质上是可靠的通讯，而网络协议是为不可靠通讯设计的。
Unix Domain Socket 是全双工的，API 接口语义丰富，相比其它 IPC 机制有明显的优越性，目前已成为使用最广泛的 IPC 机制，比如 X Window 服务器和 GUI 程序之间就是通过 UNIX domain socket 通讯的。
Unix domain socket 是 POSIX 标准中的一个组件，所以不要被名字迷惑，linux 系统也是支持它的。</description></item><item><title>URL 与 URI</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/URL-%E4%B8%8E-URI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/URL-%E4%B8%8E-URI/</guid><description>概述 参考：
Wiki, URI Wiki, IRI Wiki, URL Wiki, CleanURL-slug Wiki, URL encoding RFC 3986, Uniform Resource Identifier(URI): Generic Syntax RFC 1738, Uniform Resource Locators (URL) https://www.ruanyifeng.com/blog/2010/02/url_encoding.html 既然 HTTP 的本质是是在两点之间传输超文本，那么这个超文本又该如何表示呢？我们应该如何正确得找到这个超文本呢？所以，人们将超文本描述为 Resource(资源)，互联网上如此之多得资源，就需要一个唯一标识符来标识每一个资源。URI 就是这么一个用来标识资源的规范。
Uniform Resource Identifier(统一资源标识符，简称 URI) 是 Web 技术使用的唯一标识符。URI 可以用于标识任何东西，包括现实世界中的对象，例如人和地方，概念或信息资源，例如网页和书籍。某些 URI 提供了一种在网络上(在 Internet 上或在另一个专用网络上，例如在计算机文件系统或 Intranet 上)定位和检索信息资源的方法，它们是 Uniform Resource Locator(统一资源定位符，简称 URL)。而其他 URI 仅提供一个唯一名称，而没有找到或检索该资源的信息，这类 URI 被称为 Uniform Resource Name(统一资源名称，简称 URN)。
尽管 URI 仍然是常用术语，但定义 URI 的规范已经被 Internationalized Resource Identifiers(国际化资源标识符，简称 IRI) 的规范所取代。IRI 扩展了 URI 的定义，以便 IRI 可以处理诸如 Kanji(汉字) 之类的字符集，而不是仅限于 ASCII。</description></item><item><title>User Account(KubeConfig)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authentication%E8%AE%A4%E8%AF%81/User-AccountKubeConfig/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authentication%E8%AE%A4%E8%AF%81/User-AccountKubeConfig/</guid><description>概述 参考：
官方文档，概念 - 配置 - 使用 kubeconfig 文件访问集群 官方文档，任务 - 访问集群中的应用程序 - 配置多集群访问 User Account(用户账户，简称 UA) 使用 KubeConfig 文件进行认证。KubeConfig 是一个允许各个客户端与集群通信时所用到的认证配置文件，由于与 kubernetes 交互的途径只有通过 API Server 这一条途径，所以就相当于 API Server 的各客户端(kubelet、scheduler、controller-manager、kube-proxy 等)与其进行通信时使用的认证、配置文件。
KubeConfig 是对 UserAccount 的扩展，KubeConfig 会创建 UserAccount 并关联到指定的集群上
使用 KubeConfig 的原因：可以不用进行双向证书交换，节省交互开销。仅用于对安全性不那么高的情况，否则依然使用双向认证，比如 etcd 与 apiserver 的交互
首先，Kubeconfig 可以是任意文件名的文件，Kubeconfig 只是一个概念，并以文本文件的形式展示出来。 在开启了 TLS 的集群中，每当与集群交互的时候少不了的是身份认证，使用证书和 token(令牌)两种认证方式是最简单也最通用的认证方式。 以 kubectl 为例，kubectl 只是个 go 编写的可执行程序，只要为 kubectl 配置合适的 KubeConfig，就可以在集群中的任意节点使用。kubectl 默认会从 ~/.kube 目录下查找文件名为 config 的文件，也可以使用 &amp;ndash;kubeconfig 命令行标志时指明具体的 KubeConfig 文件。(注意：下文中的用户指的是 kubernetes 中的用户，与 linux 的用户不同)</description></item><item><title>Utilities</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Utilities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Utilities/</guid><description>概述 参考：
https://github.com/HotBoy-java/PotatoTool # 这款工具是一款功能强大的网络安全综合工具，旨在为安全从业者、红蓝对抗人员和网络安全爱好者提供全面的网络安全解决方案。它集成了多种实用功能，包括解密、分析、扫描、溯源等，为用户提供了便捷的操作界面和丰富的功能选择。</description></item><item><title>Utility</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Utility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/PowerShell-%E5%86%85%E7%BD%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Utility/</guid><description>概述 参考：
官方文档 - PowerShell，模块 - Utility Select-String https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/select-string?view=powershell-7.4
Select-String cmdlet 使用正则表达式匹配来搜索输入字符串和文件中的文本模式。Select-String 可以实现类似于 Unix-like OS 中的 grep 命令或 Windows 中的 findstr.exe 的效果。</description></item><item><title>Utility</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Utility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Utility/</guid><description>概述 参考：
MGit # 在 Android 上使用 git 管理代码仓库
https://f-droid.org/packages/com.manichord.mgit/</description></item><item><title>Utility</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/Utility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/Utility/</guid><description>概述 参考：
https://github.com/L-codes/Neo-reGeorg
TCP Ping 工具。用来实现类似 ping 的效果来测试 4 层端口连接状态
https://github.com/cloverstd/tcping</description></item><item><title>Variable</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Variable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Variable/</guid><description>概述 参考：
官方文档，仪表盘 - 变量 可以人为添加如下几类变量
Query # 变量值从数据源查询中获取 Custom # 手动定义一个变量的值 Text box # 定义一个文本框变量，用户可以在其中输入任意字符串作为变量的值 Constant # 定义一个隐藏常量变量，对于要共享的仪表板中的指标前缀很有用。TODO: 没看懂有啥用 全局内置变量 https://grafana.com/docs/grafana/latest/dashboards/variables/add-template-variables/#global-variables
时间相关 $__from 与 $__to https://grafana.com/docs/grafana/latest/dashboards/variables/add-template-variables/#__from-and-__to
Grafana 有两个内置时间范围变量：$__from 和 $__to。这两个变量的来源是 Grafana 的时间选择器，下图中的 From 与 To 选择的时间就是这两个变量的值。假如当前时间是 2024 年 11 月 24 日 0 点 0 分 0 秒，选择了 Last 6 hours 这个时间范围，则 ${__from} 的值为 1732356000000（i.e. 2024-11-23 18:00:00）；${__to} 的值为 1732377600000（i.e. 2024-11-24 00:00:00）。
可以通过如下语法控制显示出来的时间格式：
Syntax Example result Description ${__from} 1594671549254 默认格式。毫秒级 Unix 时间戳 ${__from:date} 2020-07-13T20:19:09.</description></item><item><title>VFIO</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/VFIO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/VFIO/</guid><description>概述 参考：
Linux 内核文档，驱动 API - VFIO Virtual Function I/O(简称 VFIO) 驱动程序是一个与 IOMMU 设备无关的框架，用于在受 IOMMU 保护的安全环境中公开对用户空间的直接设备访问。换句话说，这允许安全非特权用户空间驱动程序。
人话：可以让用户空间的进程直接控制物理硬件设备，而不用经过内核。比如 DPDK 可以通过 vfio 模块，让使用 DPDK 的程序掠过内核直接控制网卡，进而避免了流量过大导致的内核软中断过高的问题。</description></item><item><title>Vim 问题处理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/Vim/Vim-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/Vim/Vim-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</guid><description>概述 参考：
Vim 黄色阴影处理 经常会出现字符上会出现黄色的阴影部分，虽然不会影响到自己的编辑，但是看着就是不习惯，解决这个问题的方式：
在 vim 编辑器中执行 :nohlsearch 即可 如果希望以后都不在出现这个情况，可以在 /etc/vim/vimrc 文件中添加 set nohlsearch，使之永久生效 Vim中复制粘贴缩进错乱问题的解决方案 不知道大家是否会有这种困扰，例如在 Android Studio 有一段缩进优美的代码实现，例如：
public void sayHello() { String msg = &amp;#34;Hello Vim Paste Mode&amp;#34;; System.out.println(msg); } 当你把这段缩进优美的代码直接 ctrl+c，ctrl+v 到 Vim 的时候，就会出现如下恶心的情况：
可以看到，这种直接粘贴的方式会导致代码丢失和缩进错乱等情况。
解决方案 vim 进入 paste 模式，命令如下：
:set paste 进入 paste 模式之后，再按 i 进入插入模式，进行复制、粘贴就很正常了。
命令模式下，输入下面的命令以解除 paste 模式。
:set nopaste paste 模式主要帮我们做了如下事情：
textwidth 设置为 0 wrapmargin 设置为 0 set noai set nosi softtabstop 设置为 0 revins 重置 ruler 重置 showmatch 重置 formatoptions 使用空值</description></item><item><title>virt-install</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/virt-install/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/virt-install/</guid><description>概述 参考：
GitHub 项目，virt-manager/virt-manager 中的 Manual(手册) Manual(手册)，virt-install(1)（另一个网站的 Manual） virt-install 是一个命令行工具，用于通过 Libvirt 管理程序管理库创建新的 KVM、Xen 或 Linux 容器。请参阅本文档末尾的示例部分以快速入门。
virt-manager 在图形化界面创建的虚拟机本质上就是调用的 virt-install 命令在系统中执行的。virt-manager 创建的虚拟机生成的 xml 文件可以推导出 virt-install 创建同样虚拟机所需要使用到的参数。
virt-install 命令中很多参数都可以在 XML 文件中找到对应的配置。比如 --memory 的全部可配置参数可以在 https://libvirt.org/formatdomain.html#memory-allocation 这里找到。
Syntax(语法) virt-install &amp;ndash;name NAME &amp;ndash;memory MB STORAGE INSTALL [OPTIONS]
许多参数都有子选项，要查看与该参数相关联的子选项的完整列表使用例子中类似的命令，例如：virt-install &amp;ndash;disk=?
随着版本的更新，很多选项都会被更好的选项而替代，那些被弃用的选项可能不会在笔记中出现，具体详见官方文档。
有几个参数是在使用 libvirt 工具安装虚拟机时必须指定的：
&amp;ndash;name is required &amp;ndash;memory amount in MiB is required &amp;ndash;disk storage must be specified (override with &amp;ndash;disk none) 安装方式 &amp;ndash;location URL, &amp;ndash;cdrom CD/ISO, &amp;ndash;pxe, &amp;ndash;import, &amp;ndash;boot hd|cdrom|&amp;hellip; 注意： 在创建虚拟机时，我们一般都会指定一下虚拟机的系统类型，以便优化 virtio 等性能相关功能。所有 virt-manager 支持的虚拟机列表可以通过 virt-install --osinfo list 命令列出。</description></item><item><title>vm(内存相关参数)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/vm%E5%86%85%E5%AD%98%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/vm%E5%86%85%E5%AD%98%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</guid><description>概述 参考：
Linux Kernel 文档，管理员指南 - /proc/sys 文档 - /proc/sys/vm 文档 /proc/sys/vm/ 目录下的文件可用于调整 Linux Kernel 中有关 Virtual Memory(虚拟内存) 子系统的操作。
vm.drop_caches = NUM 写入该文件可以清理内存中的缓存。详见 Memory 的缓存 章节中“缓存清理”部分
vm.swappiness = 10 这个内核参数可以用来调整系统使用 swap 的时机。默认值：60
设为 60 即表示：当内存中空闲空间低于 60%的时候，就会开始使用 swap 空间(也就是说系统使用了 40%的内存之后，就开始使用 swap)
vm.max_map_count = 262144 一个进程可以拥有的 VMA(虚拟内存区域) 的数量。默认值：65530
常用于运行 Elasticsearch 服务的设备上。
vm.overcommit_memory = 1 配置是否允许[内存 overcommit](Memroy%20 的%20Over%20Commit%20 与%20OOM.md 管理/Memroy 的 Over Commit 与 OOM.md)，有 0、1、2 三种模式。默认值：0
0 # heuristic overcommit(试探式允许 overcommit)。 当应用进程尝试申请内存时，内核会做一个检测。内核将检查是否有足够的可用内存可以分配。如果有足够的可用内存，内存申请允许；否则，内存申请失败。 1 # always overcommit,never check(总是允许 overcommit) 对于内存的申请请求，内核不会做任何检测，并直接分配内存。 2 # never overcommit,always check(永不允许 overcommit) 说是永不允许 overcommit，其实只是通过其他参数来控制 overcommit(过量使用) 的大小。可以分配的总内存将会受到 /proc/meminfo 中的 CommitLimit 这个参数限制。 CommitLimit = (total_RAM - total_huge_TLB) * overcommit_ratio / 100 + total_swap totaol_RAM # 系统内存总量(就是物理内存) total_huge_TLB # 为 huge pages 保留的内存量，一般没有保留，都是 0 overcommit_ratio # /proc/sys/vm/overcommit_ratio 内核参数的值。 total_swap # swap 空间的总量 比如我现在有一个 16G 内存的服务器，swap 空间为 16，overcommit_ratio 参数设为 50，那么 CommitLimit 的计算结果为 24G。 此时，如果 /proc/meminfo 中的 Commited_AS 参数 值为 23G，当一个程序申请超过 1G 内存时，则会失败。 所以从根本上讲，模式 2 下，可以分配的内存总量，受 overcommit_ration 这个内核参数控制。所谓的永远不会 overcommit，则是指 overcommit_ration 参数的值小于 100。 注意：从 Linux 内核 3.</description></item><item><title>Vmess</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Vmess/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Vmess/</guid><description>概述 参考：
https://www.chengxiaobai.com/essays/v2ray-trojan-xray.html
Vmess 协议是 V2Ray 项目的主流加密协议
Xray 参考：
原文: https://qoant.com/2021/04/vps-with-xray/ V2Fly 与 V2Ray
V2Fly 是 V2Ray 的延伸，因为 V2Ray 仓库的作者失踪，所以建立了 V2Fly，本质上两者没区别。
Xray 介绍 由于 Debian 包维护人员发现 XTLS库 的 LICENSE 不是 BSD 许可，提了一个 issue 希望作者 @rprx 能修改 LISENCE 许可方便打包，详见 https://github.com/XTLS/Go/issues/9。由这个 issue 引发了广泛讨论，rprx 认为目前许可不是问题，也有不少人认为协议是立场的体现，各执一词。
最终 V2ray(V2fly社区) 维护团队经过投票确认 XTLS 不符合 V2ray 的 MIT 协议，并在 V2ray-core 4.33.0版本移除了 XTLS。rprx 和其拥护者行动起来，很快就创建了 Project X 项目和其核心 Xray（Xray取名来自XTLS和V2ray的结合），并以 XTLS 为核心协议陆续发布了 Xray-core 的多个版本，于是 Xray 诞生了。
XTLS 和 Xray 离不开作者 @rprx 的辛勤付出，因此也简要介绍一下 @rprx：</description></item><item><title>vsftpd</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/vsftpd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/vsftpd/</guid><description>概述 参考：
https://security.appspot.com/vsftpd.html Wiki, Vsftpd vsftpd 是实现 FTP 协议的程序
vsftp 关联文件与配置 /etc/vsftpd.conf # vsftpd 程序的配置文件
/etc/ftpusers # 此文件包含 禁止 FTP 登录的用户名，通常有&amp;quot;root&amp;quot;，&amp;ldquo;uucp&amp;rdquo;，&amp;ldquo;news&amp;rdquo; 之类，因为这些用户权限太高，登录 FTP 误操作危险性大。
User NAME User NAME User NAME &amp;hellip;&amp;hellip;. User NAME 配置文件 keywords 说明
最小基本配置
write_enable=YES # 对 ftp 服务器是否有写的权限 local_enable=YES # 是否允许本地用户登录(本地用户即 ftp 服务器自身的用户) anonymous_enable=NO # 是否允许匿名登录 扩展配置
chroot_local_user=YES # 是否启动本地用户 chroot 规则，chroot 改变登录 ftp 的本地用户根的目录位置 allow_writeable_chroot=YES # 允许在限定目录有写权限 chroot_list_enable=YES # 是否启动不受 chroot 规则的用户名单 chroot_list_file=/etc/vsftpd.chroot_list # 定义不受限制的用户名单在哪个文件中 pam_service_name=vsftpd 改为 pam_service_name=ftp # 如果始终登录时候提示密码错误，则修改此项 vsftp 可以使用 Chroot 功能。比如：下面第一个图是不启动 Chroot 规则的情况，第二张图是启用 Chroot 规则的情况，可以看到当使用 Chroot 时，/srv/ftp/ 目录对于 ftp 程序来说是作为 / 存在的。由于这个原因，所以启动 Chroot 的时候，ftp 工具无法访问所设定的 / 目录以外的其他目录</description></item><item><title>Vue 第三方库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</guid><description>概述 参考：
GitHub 项目，vuejs/awesome-vue # 一些常用的第三方库 Element Plus 参考：
GitHub 项目，element-plus/element-plus 官网 Element Plus 是一个基于 Vue3 的 UI 框架。它是 Element UI 基于 Vue3 的重构版本。
nmxiaowei/avue # 基于现有的 element-ui 库进行的二次封装，简化一些繁琐的操作
Ant Design Vue 参考：
GitHub 项目，vueComponent/ant-design-vue 官网 一个基于Ant Design和Vue的企业级UI组件。
其他 vue3-easy-data-table # 数据表组件
x-extends/vxe-table # vue 表格解决方案
mirari/v-viewer # vue 的图片查看器组件，支持旋转、缩放、缩放等
小组件 yanmiao99/vue3-go-crud-project</description></item><item><title>Vue 指令</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
官方文档，基础-模板语法-指令 官方文档-API，内置指令 Directives(指令) 是带有 v- 前缀的特殊 Attribute。Vue 提供了许多内置指令，包括 Template 组件中学习的 v-bind 和 v-html。 如果把 Vue 当做一种新的编程语言，那指令，就是 Vue 语言的部分 Keyword(关键字)</description></item><item><title>Vulnerable</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Vulnerable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Security-software/Vulnerable/</guid><description>概述 参考：
Vulnerable 在中文环境那种可以称为 靶场、靶站、etc. ，用来描述在安全测试过程中充当被攻击或者主动检测的目标。
英文中好像没有一个明确的词儿可以和 靶场、靶站 相对应，这个词是从 Vulhub 项目中找到的。
Vulhub 参考：
GitHub 项目，vulhub/vulhub</description></item><item><title>W3C</title><link>https://desistdaydream.github.io/docs/Standard/Internet/W3C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Internet/W3C/</guid><description>概述 参考：
GitHub 组织，W3C https://w3c.github.io/ 官网 Wiki, World_Wide_Web_Consortium World Wide Web Consortium(万维网联盟，简称 W3C) 是一个开发开放标准以确保 Web 长期发展的国际社区。该联盟成立于 1994 年，由蒂姆·伯纳斯-李 (Tim Berners-Lee) 领导，由成员组织组成，这些成员组织拥有全职员工，共同致力于万维网标准的开发。截至 2023 年 3 月 5 日，W3C 拥有 462 名成员。W3C 还从事教育和外展活动、开发软件并充当讨论 Web 的开放论坛。
W3C 标准 https://www.w3.org/standards/
W3C 标准和草案搜索页: https://www.w3.org/TR/</description></item><item><title>WAL</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/WAL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/WAL/</guid><description>概述 参考：
Wiki, Write-ahead logging 在计算机科学中，Write-ahead logging(预写日志记录，简称 WAL) 是一系列用于在数据库系统中提供原子性和持久性（ACID 属性中的两个）的技术。
在使用 WAL 的系统中，所有的修改都先被写入到日志中，然后再被应用到系统状态中。通常包含 redo 和 undo 两部分信息。为什么需要使用 WAL，然后包含 redo 和 undo 信息呢？举个例子，如果一个系统直接将变更应用到系统状态中，那么在机器断电重启之后系统需要知道操作是成功了，还是只有部分成功或者是失败了（为了恢复状态）。如果使用了 WAL，那么在重启之后系统可以通过比较日志和系统状态来决定是继续完成操作还是撤销操作。
redo log 称为重做日志，每当有操作时，在数据变更之前将操作写入 redo log，这样当发生断电之类的情况时系统可以在重启后继续操作。undo log 称为撤销日志，当一些变更执行到一半无法完成时，可以根据撤销日志恢复到变更之间的状态。
现代文件系统通常至少对文件系统元数据使用 WAL 的变体；这就是所谓的 Journaling File System。</description></item><item><title>Watch and Informer</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Watch-and-Informer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Watch-and-Informer/</guid><description>概述 参考：
官方文档，参考 - API 概述 - Kubernetes API 概念, 高效监测变化 K8s list-watch 机制和 Informer 模块 Reflector
在 Kubernetes 中，有5个主要的组件，分别是 master 节点上的 kube-api-server、kube-controller-manager 和 kube-scheduler，node 节点上的 kubelet 和kube-proxy 。这其中 kube-apiserver 是对外和对内提供资源的声明式 API 的组件，其它4个组件都需要和它交互。为了保证消息的实时性，有两种方式：
客户端组件 (kubelet, scheduler, controller-manager 等) 轮询 apiserver apiserver 通知客户端 为了降低 kube-apiserver 的压力，有一个非常关键的机制就是 list-watch。list-watch 本质上也是 client 端监听 k8s 资源变化并作出相应处理的生产者消费者框架
list-watach 机制需要满足以下需求：
实时性 (即数据变化时，相关组件越快感知越好) 保证消息的顺序性 (即消息要按发生先后顺序送达目的组件。很难想象在Pod创建消息前收到该Pod删除消息时组件应该怎么处理) 保证消息不丢失或者有可靠的重新获取机制 (比如 kubelet 和 kube-apiserver 间网络闪断，需要保证网络恢复后kubelet可以收到网络闪断期间产生的消息) list-watch 机制 list-watch 由两部分组成，分别是 list 和 watch。list 非常好理解，就是调用资源的 list API 罗列资源 ，基于 HTTP 短链接实现，watch 则是调用资源的 watch API 监听资源变更事件，基于 HTTP 长链接实现</description></item><item><title>Web SSH</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Web-SSH/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Web-SSH/</guid><description>概述 参考：
公众号-云原生运维圈，Gin+Xterm.js实现WebSSH远程Kubernetes Pod 一
Xterm.js简介
xterm.js （https://xtermjs.org/）是一个开源的 JavaScript 库，它模拟了一个终端接口，可以在网页中嵌入一个完全功能的终端。这个库非常灵活，并且具有很多定制选项和插件系统。
下面是一些使用 xterm.js 的基本步骤：
首先，需要在项目中安装 xterm.js。你可以直接从 npm 安装： npm install xterm
然后在 HTML 中创建一个容器来承载终端 &amp;lt;div id=&amp;quot;terminal&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; 在你的 JavaScript 文件中，导入 Terminal 类并创建一个新的实例 `import { Terminal } from &amp;lsquo;xterm&amp;rsquo;;
const term = new Terminal();
把这个终端附加到 HTML 元素上 term.open(document.getElementById('terminal')); 现在你就可以向终端写入数据了 `term.write(&amp;lsquo;Hello, World!&amp;rsquo;);
如果你想读取用户在终端中的输入，可以监听 onData 事件 `term.onData(data =&amp;gt; { console.log(data); });
以上只是最基础的使用方法。xterm.js 提供了许多其他功能，如主题定制、附加插件（例如 FitAddon 可以自动调整终端大小，WebLinksAddon 可以捕获 URL 并将其变为可点击链接）、设置光标样式、更改字体大小等等。你可以访问 xterm.js 的 GitHub （https://github.com/xtermjs/xterm.js）仓库 或者 文档 来获取更详细的信息。</description></item><item><title>WebDAV</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/WebDAV/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/WebDAV/</guid><description>概述 参考：
RFC 4918, HTTP Extensions for Web Distributed Authoring and Versioning (WebDAV) Wiki, WebDAV https://www.zhihu.com/question/30719209 Web Distributed Authoring and Versioning(Web 分布式创作和版本控制，简称 WebDAV) 是 HTTP 的一组扩展，它允许 User-Agent(用户代理) 通过提供并发控制和命名空间操作的设施，直接在 HTTP Web 服务器 中协作创作内容，从而允许 Web 被视为一种 可写的、协作的 媒体，而不仅仅是一种只读媒体。WebDAV 定义在 RFC 4918 中
当我们使用符合 WebDAV 标准的程序部署了服务端之后，通过客户端，就可以使用 HTTP 协议访问服务端
应用示例 通过 WebDAV，可以将互联网上的网盘提供商，将自身的网盘，挂载到操作系统上，作为一个盘符
HTTP 协议定义了几种请求: GET, POST,PUT 等用来下载文件上传数据。WebDAV 在标准的 HTTP 协议上扩展了特有的请求方式: PROPFIND, MOVE, COPY 等。 然后用这些请求，操作 web 服务器上的磁盘(像不像一个网盘！！！)
注意: 在 Nginx 等代理后面的 WebDAV 无法执行那些扩展的请求方式，比如 MOVE 等，实际情况是重命名时将会报错 Dir.</description></item><item><title>WebServer</title><link>https://desistdaydream.github.io/docs/Web/WebServer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/WebServer/</guid><description>概述 参考：
MDN，Web server Wiki, Web server Web server(Web 服务器) 是用以响应静态资源的程序，可以提供 Web 服务。
在最基本的层面上，每当浏览器需要托管在 Web server 上的文件时，浏览器都会通过 HTTP 请求该文件。当请求到达正确的 Web server 时，HTTP 服务器接受该请求，找到所请求的文档，并将其发送回浏览器（同样通过 HTTP）。 （如果服务器找不到所请求的文档，则会返回 404 响应。）
实现 Web server 的软/硬件
Tomcat Nginx Tomcat 参考：
官网 Wiki, Apache Tomcat Apache Tomcat（简称“Tomcat”）是 Jakarta Servlet、Jakarta Expression Language 和 WebSocket 技术的免费开源实现。使用 Java 开发的 HTTP Web server 环境，Java 代码也可以在其中运行。因此，它是一个 Java Web 应用程序服务器，尽管不是完整的 JEE 应用程序服务器。</description></item><item><title>Webservice And REST</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Webservice-And-REST/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Webservice-And-REST/</guid><description>概述 参考：
阮一峰，RESTful API 设计指南 思否，REST架构的思考 Server Side(服务端) Server Side(服务端) 的 WebAPI 是由一个或多个公开暴露的 Endpoints(端点) 组成的编程接口
Endpoints(端点) Endpoints(端点，简称 ep) 是与服务端 WebAPI 交互的重要方面，因为 Endpoints 指定了客户端可以访问的资源位置。通常，是通过 URI 进行访问，HTTP 请求发送到这个 URI 上，从而期望从这个 URI 上得到响应。
Web services expose one or more endpoints to which messages can be sent. A web service endpoint is an entity, processor, or resource that can be referenced and to which web services messages can be addressed. Endpoint references convey the information needed to address a web service endpoint.</description></item><item><title>wget</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/wget/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/wget/</guid><description>概述 参考：
Syntax(语法) OPTIONS
-O NAME # 下载后重命名为指定的 NAME EXAMPLE
wget -q -O - http://www.baidu.com/ # 不下载，将 URL 为http://www.baidu.com/的内容输出到标准输出上</description></item><item><title>WHATWG</title><link>https://desistdaydream.github.io/docs/Standard/Internet/WHATWG/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Internet/WHATWG/</guid><description>概述 参考：
GitHub 组织，WHATWG 官网 Wiki, WHATWG Web Hypertext Application Technology Working Group(Web超文本应用技术工作组，简称 WHATWG) 是一个负责维护与开发 Web 标准的社区，他们的工作成果包括 DOM、Fetch API，和 HTML。一些来自 Apple、Mozilla，和 Opera 的员工在 2004 年建立了 WHATWG。</description></item><item><title>whereis which 查询工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/whereis-which-%E6%9F%A5%E8%AF%A2%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/whereis-which-%E6%9F%A5%E8%AF%A2%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
which - 查看可执行文件的位置 ~]# which ls /usr/bin/ls whereis - 查看文件的位置， 如 whereis ls ~]# whereis ls ls: /usr/bin/ls /usr/share/man/man1/ls.1.gz</description></item><item><title>Windows Management Instrumentation</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-Management-Instrumentation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-Management-Instrumentation/</guid><description>概述 参考：
官方文档 Wiki, Windows_Management_Instrumentation Windows Management Instrumentation(简称 WMI) 使用 CIM(通用信息模型) 行业标准来表示系统、应用程序、网络、设备和其他受管理的组件。
https://www.syscom.com.tw/ePaper_Content_EPArticledetail.aspx?id=76&amp;EPID=159&amp;j=4&amp;HeaderName=%E7%A0%94%E7%99%BC%E6%96%B0%E8%A6%96%E7%95%8C
在 PowerShell 中使用 WMI https://learn.microsoft.com/zh-cn/powershell/scripting/learn/ps101/07-working-with-wmi
Windows PowerShell 早期 WMI cmdlet 已弃用，在 PowerShell 6+ 中不可用，请改用 CIM cmdlet。
PowerShell 中存在多个本机 WMI cmdlet，且无需安装任何其他软件或模块。 Get-Command 可用于确定 Windows PowerShell 中存在哪些 WMI cmdlet。 以下结果来自运行 5.1 版 PowerShell 的 Windows 10 实验环境计算机。 结果因运行的 PowerShell 版本而异。
Get-Command -Noun WMI* CommandType Name Version Source ----------- ---- ------- ------ Cmdlet Get-WmiObject 3.1.0.0 Microsof... Cmdlet Invoke-WmiMethod 3.1.0.0 Microsof... Cmdlet Register-WmiEvent 3.</description></item><item><title>Windows MGMT</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-MGMT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-MGMT/</guid><description>概述 参考：
休眠
这么多年了，为啥Windows笔记本们连个休眠都做不好？【差评君】</description></item><item><title>Windows 共享</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E5%85%B1%E4%BA%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E5%85%B1%E4%BA%AB/</guid><description>概述 参考：
保证机器在“专用网络”，打开共享</description></item><item><title>Windows 设置与优化</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Windows-%E8%AE%BE%E7%BD%AE%E4%B8%8E%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Windows-%E8%AE%BE%E7%BD%AE%E4%B8%8E%E4%BC%98%E5%8C%96/</guid><description>概述 参考：
语言栏 设置快捷键：设置 - 时间和语言 - 输入 - 高级键盘设置 - 输入语言热键</description></item><item><title>Windows 系统实用工具</title><link>https://desistdaydream.github.io/docs/Utils/Windows-%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/Windows-%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/Windows-%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/Windows-%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
公众号-差评，我从三百条留言中，筛选出了差友们推荐的好用软件 图拉丁吧工具箱 # 需要的东西基本全了，没啥可说的。
https://www.tbtool.cn/ NirSoft 网站提供了一系列独特的小型且有用的免费软件，全部由 Nir Sofer 开发。
PowerToys
https://github.com/microsoft/PowerToys 非常强大的 windows 系统工具 DevToys
https://github.com/DevToys-app/DevToys Windows 桌面版开发者工具，时间戳转换、json 格式化、etc. 卸载工具 Revo Uninstaller #
https://www.revouninstaller.com/ https://www.bilibili.com/video/BV13x4y1G7Qc 30天过后请按照我的教程走一遍就好了哈 Geek Uninstaller #
https://geekuninstaller.com/ 卸载完成后扫描系统和注册表，手动选择要删除的项目 磁盘空间管理工具 SpaceSniffer
http://www.uderzo.it/main_products/space_sniffer Dism++
https://github.com/Chuyu-Team/Dism-Multi-language 还可以控制系统软件、系统服务，不过好像很久不更新了，最后一次 release 还是 2021 年。。。( ╯□╰ ) AppReadWriteCounter
https://www.nirsoft.net/utils/app_read_write_counter.html 监控每个程序对磁盘读/写的工具，NirSoft 开发的 自启动管理 Autoruns
https://learn.microsoft.com/en-us/sysinternals/downloads/autoruns 内存管理 MemReduct
https://github.com/henrypp/memreduct 轻量级实时内存管理应用程序，用于监视和清理计算机上的系统内存。 搜索 Everything
官网 被吹爆的最强搜索工具Everything，你可能根本不会用！ 适用于 Windows 的全局搜索工具，非常小巧好用！！！ 甚至可以批量对文件重命名 监控工具 TrafficMonitor # https://github.com/zhongyang219/TrafficMonitor
截图 Snipaste # https://www.</description></item><item><title>WindowsShell 变量</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/WindowsShell-%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/WindowsShell-%E5%8F%98%E9%87%8F/</guid><description>概述 参考：
https://sysin.org/blog/windows-env/ https://ss64.com/nt/syntax-variables.html 赋值方式与引用方式详见各自 Shell 章节
在 CMD 中： 引用方式：
在 CMD 和资源管理器中：%VAR% TODO: Windows 中的变量好像不区分大小写？
常用环境变量 COMPUTERNAME # 主机名
USERNAME # 用户名
USERPROFILE # 用户家目录。默认值：C:/Users/${USERNAME}/
TMP # 临时目录。默认值：
系统级 C:/WINDOWS/TEMP 用户级 %USERPROFILE%/AppData/Local/Temp APPDATA # 应用程序的数据保存路径。默认值：%USERPROFILE%/AppData/Roaming/
这个目录下的数据通常可以随着网络连接同步到其他电脑。比如用户的配置、插件等等。当然，很多时候，应用程序也会将这些可以在网络同步的数据保存到 文档、家目录 等等地方中。 LOCALAPPDATA # 应用程序的本地数据保存路径。默认值：%USERPROFILE%/AppData/Local/
ProgramData # 指定程序数据文件夹的路径。与 Program Files 文件夹不同，应用程序可以使用此文件夹为标准用户存储数据，因为它不需要提升的权限。默认值：C:/ProgramData
ProgramFiles # 默认值：C:/Program Files
注意：
Windows 中没有指向 “文档”、“视频” 等等目录的变量，可以在 PowerShell 中使用 [environment]::getfolderpath(&amp;quot;mydocuments&amp;quot;) 获取。 参考: https://stackoverflow.com/questions/3492920/is-there-a-system-defined-environment-variable-for-documents-directory</description></item><item><title>Windows包管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Windows%E5%8C%85%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Windows%E5%8C%85%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
官方文档 %LOCALAPPDATA%/Packages/ # 通过应用商店安装的程序会保存在这里？待确认
AppX 参考：
官方文档 Get-AppxPackage
Remove-AppxPackage
MSIX 参考：
官方文档 WinGet 参考：
官方文档-Windows，包管理器 winget 是一个 Windows Package Manager(Windows 包管理器)，由命令行工具 (WinGet) 和一组用于在 Windows 设备上安装应用程序的服务组成。
安装 winget Syntax(语法) https://learn.microsoft.com/en-us/windows/package-manager/winget/#commands
EXAMPLE 卸载 Windows 小组件
winget uninstall &amp;#34;windows web experience pack&amp;#34;</description></item><item><title>Wireguard 流量伪装</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/Wireguard-%E6%B5%81%E9%87%8F%E4%BC%AA%E8%A3%85/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/Wireguard-%E6%B5%81%E9%87%8F%E4%BC%AA%E8%A3%85/</guid><description>概述 参考：
WireGuard 在国内网络环境下会遇到一个致命的问题：UDP 封锁/限速。虽然通过 WireGuard 可以在隧道内传输任何基于 IP 的协议（TCP、UDP、ICMP、SCTP、IPIP、GRE 等），但 WireGuard 隧道本身是通过 UDP 协议进行通信的，而国内运营商根本没有能力和精力根据 TCP 和 UDP 的不同去深度定制不同的 QoS 策略，几乎全部采取一刀切的手段：对 UDP 进行限速甚至封锁。
虽然运营商对 UDP 不友好，但却无力深度检测 TCP 连接的真实性。既然对 TCP 连接睁一只眼闭一只眼，那我将 UDP 连接伪装成 TCP 连接不就蒙混过关了。目前支持将 UDP 流量伪装成 TCP 流量的主流工具是 udp2raw，另一款比它更强大的新工具：Phantun。
udp2raw 参考：
GitHub 项目，wangyu-/udp2raw 使用原始套接字将 UDP 流量转换为加密的 UDP/FakeTCP/ICMP 流量的隧道，帮助您绕过 UDP 防火墙（或不稳定的 UDP 环境）
部署 这里我使用 docker 部署的，实体进程和相关文档见 udp2raw 运行
Linux server 端 :
# 监听86的tcp端口，把86端口收到的伪装成tcp的udp报文转发到 127.0.0.1:16000 上 docker run \ -d --name udp2raw \ --restart always \ --net host \ --cap-add NET_RAW \ --cap-add NET_ADMIN \ -v /run/xtables.</description></item><item><title>WPS</title><link>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/WPS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/PKM/WPS/</guid><description>概述 参考 垃圾软件
安装时修改路径后提示没有权限，然后点继续就直接安装到 C 盘了，点取消才能安装到其他路径。
关联文件与配置 C:/ProgramData/kingsoft/ # 安装程序运行时下载的文件保存路径 C:/rogram Files (x86)/Kingsoft/ # 不知道干啥用的 C:/Users/DesistDaydream/AppData/Local/kingsoft/ # 不知道干啥用的 C:/Users/DesistDaydream/AppData/Roaming/kingsoft/ # 不知道干啥用的 %我的文档%/KingsoftData/ # 暂时不知道win中“我的文档”的变量是什么。 %我的文档%/WPS Cloud Files/ ./${ACCOUNT_ID}/cachedata/${RANDOM_NUM}/ # 金山文档通过 wps 方式打开后，会将文件缓存到该目录。每个文件占一个目录。</description></item><item><title>WSGI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/WSGI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/WSGI/</guid><description>概述 参考：
Wiki, Web Server Gateway Interface Web Server Gateway Interface(Web 服务器网关接口，简称 WSGI) 是一种简单的 Web 服务器调用约定，用于将请求转发到用 Python 编程语言编写的 Web 应用程序或框架。 WSGI 的当前版本（版本 1.0.1）在 Python 增强提案 (PEP) 3333 中指定。</description></item><item><title>XDG</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/freedesktop/XDG/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/freedesktop/XDG/</guid><description>概述 参考：
freedesktop 规范 freedesktop.org 制定互操作性规范，但我们不是官方标准机构。项目不需要实施所有这些规范，也不需要认证。
这些规范许多都在 X Desktop Group(简称 XDG) 的旗帜下。（Cross-Desktop Group 代表跨桌面组）
其中一些规范正在（非常）活跃地使用，并且有大量感兴趣的开发人员。其中许多被认为是稳定的，不需要进一步开发，并且可能没有积极的发展。其中一些未被使用或广泛实施。
常见变量 https://specifications.freedesktop.org/basedir-spec/latest/ar01s03.html
XDG_CACHE_HOME 定义了应该存储用户特定的非必要数据文件的基本目录。如果 $XDG_CACHE_HOME 未设置或为空，则应使用等于 $HOME/.cache 的默认值。这是一个 Linux 和 Unix 操作系统环境变量，Windows 系统中并没有这个环境变量。</description></item><item><title>XFS</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/XFS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/XFS/</guid><description>概述 参考：
Wiki, XFS XFS 是由 Silicon Graphics 于 1993 年创建的高性能 64 位 Journaling File System(日志文件系统)。
可以通过 xfs_info 命令行工具看到信息
~]# xfs_info /dev/mapper/vg1-root meta-data=/dev/mapper/vg1-root isize=512 agcount=4, agsize=32735744 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1 data = bsize=4096 blocks=130942976, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0, ftype=1 log =internal log bsize=4096 blocks=63937, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0</description></item><item><title>XML</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/XML/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80/XML/</guid><description>概述 参考：
MDN，XML Wiki, XML W3C 官网，XML 标准 Extensible Markup Language(可扩展标记语言，简称 XML) 是一种用于存储、传输和重建任意数据的标记语言和文件格式，常用来作为配置文件使用。它定义了一组规则，用于以人类可读和机器可读的格式对文档进行编码。万维网联盟 1998 年的 XML 1.0 规范和其他几个相关规范——它们都是免费的开放标准——定义了 XML。
XML 语言由 DOM 严格序列化，XML 只是一种没有预定义 tags(标签) 的 HTML（人话: XML 中的 &amp;lt;dev&amp;gt;、&amp;lt;p&amp;gt;、等等 标签没有特殊含义）。所有 tag 都像关键字一样，
XML 标准 XML 使用了与 HTML 相似的术语
Element(元素) Tag(标签) Attribute(属性) 整个 XML 是由一个元素的集合体，由根元素开头。通过缩进控制层级，每个层级都表示是上层元素的子元素。
XPath 参考：
MDN，XPath Wiki, XPath 菜鸟教程，XPath XML Path Language(XML 路径语言，简称 XPath) 是一种表达语言，它使用非 XML 语法来提供一种灵活地定位（指向）XML 文档的不同部分的方法。它也可以用于检查文档中某个定位节点是否与某个模式（pattern）匹配。它由万维网联盟 (W3C) 于 1999 年定义，可用于根据 XML 文档的内容计算值（例如字符串、数字或布尔值）。支持 XML 的应用程序（例如 Web 浏览器）和许多编程语言都支持 XPath。</description></item><item><title>YAML</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/YAML/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/YAML/</guid><description>概述 参考：
官方文档，规范 v1.2.2 Wiki, YAML 编程免不了要写配置文件，怎么写配置也是一门学问。
YAML 是专门用来写配置文件的语言，非常简洁和强大，远比 JSON 格式方便
YAML Ain&amp;rsquo;t Markup Language(简称 YAML) 是一种数据序列化语言。设计目标就是方便人类读写，并且可以在日常工作中与现代编程语言很好的配合。它实质上是一种通用的数据串行化格式。
YAML 与 JSON 的关系 JSON 和 YAML 都旨在成为人类可读的数据交换格式。但是，JSON 和 YAML 具有不同的优先级。 JSON 的首要设计目标是简单性和通用性。因此，JSON 的生成和解析非常简单，但代价是人类可读性降低。它还使用最低公分母信息模型，以确保所有现代编程环境都可以轻松处理任何 JSON 数据。
相反，YAML 的首要设计目标是人类可读性并支持序列化任意本机数据结构。因此，YAML 允许可读性极强的文件，但生成和解析起来更复杂。此外，YAML 的业务范围超越了最低公分母数据类型，因此在不同的编程环境之间进行转换时，需要进行更复杂的处理。
因此，YAML 可以看作是 JSON 的自然超集，可以提高人类可读性和更完整的信息模型。实际上也是这种情况；每个 JSON 文件也是一个有效的 YAML 文件，JSON 与 YAML 格式可以轻松得互相转换
并且，YAML 格式也可以转换为别的格式
YAML 基本语法规则 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 Data Structures(数据结构) YAML 由多个 Node(节点) 组成，每个 Node 都可以是三种 Native Data Structures(原生数据结构) 其中之一：</description></item><item><title>YOLO</title><link>https://desistdaydream.github.io/docs/12.AI/AI-Projects/Yolo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/AI-Projects/Yolo/</guid><description>概述 参考：
GitHub 组织，ultralytics GitHub 项目，ultralytics/ultralytics GitHub 项目，ultralytics/assets Ultralytics 的模型、数据集、etc. 资产 ultralytics 官网 YOLO 的歷史進程！YOLO 大補帖！ https://www.bilibili.com/video/BV1sCtHewEw7 v8 与 v10 的选择，为什么不要用 v10 而是用 v8，为什么 v10 的检测效果不好 YOLO(You Only Look Once）是一种流行的物体检测和图像分割模型，由华盛顿大学的约瑟夫-雷德蒙（Joseph Redmon）和阿里-法哈迪（Ali Farhadi）开发。YOLO 于 2015 年推出，因其高速度和高精确度而迅速受到欢迎。
2015 年 Joseph Redmon 提出的 YOLO 橫空出世，从诞生的那一刻起就标榜「高精度」、「高效率」、「高实用性」，為 One-Stage 方法在物体侦测演算法里拉开序幕。
YOLOv1 (2016) Joseph Redmon You Only Look Once: Unified, Real-Time Object Detection YOLOv2 (2017) Joseph Redmon YOLO9000: Better, Faster, Stronger YOLOv3 (2018) Joseph Redmon YOLOv3: An Incremental Improvement 突发 然而，2020 年 约瑟夫·雷德蒙 突然投下一枚重磅炸弹，他受够 YOLO 不断被运用在军事应用以及个人隐私，宣布停止电脑视觉相关的研究。 YOLOv4 (2020) Alexey Bochkovskiy YOLOv4: Optimal Speed and Accuracy of Object Detection YOLOv5 进一步提高了模型的性能，并增加了超参数优化、集成实验跟踪和自动导出为常用导出格式等新功能。 YOLOv6 (2022) 由美团开源，目前已用于该公司的许多自主配送机器人。 YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications YOLOv7 增加了额外的任务，如 COCO 关键点数据集的姿势估计 YOLOv6 v3.</description></item><item><title>ZooKeeper</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/ZooKeeper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/ZooKeeper/</guid><description>概述 参考：
GitHub 项目，apache/zookeeper 官网 https://github.com/Snailclimb/JavaGuide?tab=readme-ov-file https://javaguide.cn/distributed-system/distributed-process-coordination/zookeeper/zookeeper-intro.html https://javaguide.cn/distributed-system/distributed-process-coordination/zookeeper/zookeeper-plus.html 该文已加入开源文档：JavaGuide（一份涵盖大部分 Java 程序员所需要掌握的核心知识）。地址:https://github.com/Snailclimb/JavaGuide.
1. 前言 相信大家对 ZooKeeper 应该不算陌生。但是你真的了解 ZooKeeper 到底有啥用不？如果别人/面试官让你给他讲讲对于 ZooKeeper 的认识，你能回答到什么地步呢？
拿我自己来说吧！我本人曾经使用 Dubbo 来做分布式项目的时候，使用了 ZooKeeper 作为注册中心。为了保证分布式系统能够同步访问某个资源，我还使用 ZooKeeper 做过分布式锁。另外，我在学习 Kafka 的时候，知道 Kafka 很多功能的实现依赖了 ZooKeeper。
前几天，总结项目经验的时候，我突然问自己 ZooKeeper 到底是个什么东西？想了半天，脑海中只是简单的能浮现出几句话：
ZooKeeper 可以被用作注册中心、分布式锁； ZooKeeper 是 Hadoop 生态系统的一员； 构建 ZooKeeper 集群的时候，使用的服务器最好是奇数台。 由此可见，我对于 ZooKeeper 的理解仅仅是停留在了表面。
所以，通过本文，希望带大家稍微详细的了解一下 ZooKeeper 。如果没有学过 ZooKeeper ，那么本文将会是你进入 ZooKeeper 大门的垫脚砖。如果你已经接触过 ZooKeeper ，那么本文将带你回顾一下 ZooKeeper 的一些基础概念。
另外，本文不光会涉及到 ZooKeeper 的一些概念，后面的文章会介绍到 ZooKeeper 常见命令的使用以及使用 Apache Curator 作为 ZooKeeper 的客户端。
如果文章有任何需要改善和完善的地方，欢迎在评论区指出，共同进步！
2. ZooKeeper 介绍 2.</description></item><item><title>变量</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E6%9D%BF/%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E6%9D%BF/%E5%8F%98%E9%87%8F/</guid><description>概述 参考：
官方文档，变量 Hugo 的模板具有上下文感知能力，让我们在创建网站视图时，可以使用大量的变量。
比如获取当前页面的类型、种类、创建时间、修改时间，我们在配置文件中的很多定义也会被 Hugo 感知到并使用在模板中。
Hugo 的变量用法与 Go 模板变量的用法相同。
Site 变量 Page 变量 Shortcode 变量 Taxonomy 变量 File 变量 Menu 变量 Git 变量 Sitemap 变量</description></item><item><title>变量管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/%E5%8F%98%E9%87%8F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/%E5%8F%98%E9%87%8F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>export 设置或显示环境变量(export 的效力仅作用于该次登陆操作)。
Syntax(语法) export [OPTIONS] [VarName[=VALUE] &amp;hellip;]
用户创建的变量仅可用于当前 Shell，子 Shell 默认读取不到父 Shell 定义的变量。为了把变量传递给子 Shell，需要使用 export 命令。这样输出的变量，对于子 Shell 来说就是环境变量。
OPTIONS
-f # 代表[NAME]中为函数名称 -n # 删除指定的变量。变量实际上并未删除，只是不会输出到后续指令的执行环境中 -p # 列出所有的 shell 赋予程序的环境变量。 EXAMPLE export VarName=&amp;ldquo;Value&amp;rdquo;
export VarName
declare 参考:
Manual(手册)，bash(1)-Shell 内置命令 - declare 声明 shell 变量。declare 为 shell 命令，在第一种语法中可用来声明变量并设置变量的属性，在第二种语法中可用来显示 shell 函数。若不加上任何参数，则会显示全部的 shell 变量与函数(与执行 set 指令的效果相同)。
Syntax(语法) declare [+/-][OPTIONS] VarName
OPTIONS
- # 给变量添加类型属性 + # 取消变量的类型属性 变量类型选项 -a # 将变量声明为数组型 -A # 将变量声明为关联数组类型（i.</description></item><item><title>不通过数学解释 LLMs 是如何工作的</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%8D%E9%80%9A%E8%BF%87%E6%95%B0%E5%AD%A6%E8%A7%A3%E9%87%8A-LLMs-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%8D%E9%80%9A%E8%BF%87%E6%95%B0%E5%AD%A6%E8%A7%A3%E9%87%8A-LLMs-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/</guid><description>概述 参考：
https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math 中文翻译：公众号 - 云原生实验室，大模型到底有没有智能？一篇文章给你讲明明白白 生成式人工智能 (GenAI) 和大语言模型 (LLM1)，这两个词汇想必已在大家的耳边萦绕多时。它们如惊涛骇浪般席卷了整个科技界，登上了各大新闻头条。ChatGPT，这个神奇的对话助手，也许已成为你形影不离的良师益友。
然而，在这场方兴未艾的 GenAI 革命背后，有一个谜题久久萦绕在人们心头：这些模型的智能究竟从何而来？本文将为您揭开谜底，解析生成式文本模型的奥秘。我们将抛开晦涩艰深的数学，用通俗易懂的语言，带您走进这个神奇的算法世界。让我们撕下 “魔法” 的面纱，看清其中的计算机科学本质。
LLM 的真面目 首先，我们要破除一个常见的误区。许多人误以为，这些模型是真的能够与人对话，回答人们的各种问题。然而，它们真正的能力远没有想象的那么复杂——它们所做的，不过是根据输入的文本，预测下一个词语 (更准确地说，是下一个 token)。
Token，这个看似简单的概念，却是揭开 LLM 神秘面纱的钥匙。让我们由此出发，步步深入，一探究竟。
Token，这些文本的积木、语言的原子，正是 LLM 理解世界的基石。对我们而言，token 不过是单词、标点、空格的化身，但在 LLM 的眼中，它们是精简而高效的信息编码。有时，一个 token 可能代表一串字符，长短不一；有时，它可能是孤零零的一个标点符号。
LLM 的词汇表，就是这些 token 的集合，啥都有，样样全。这其中的奥秘，要追溯到 BPE 算法。BPE 算法是如何炼制出这些 tokens 的？这个问题，值得我们细细探究。但在此之前，只需记住：GPT-2 模型，这个自然语言处理界的明星，它的词汇表中有 50,257 个 token。
在 LLM 的世界里，每个 token 都有一个独一无二的数字身份证。而 Tokenizer，就是文本和 token 之间的 “翻译官”，将人类的语言转化为 LLM 能理解的编码，也将 LLM 的思维解码为人类的文字。如果你熟悉 Python，不妨亲自与 token 打个照面。只需安装 OpenAI 的 tiktoken 包：
pip install tiktoken `
然后在 Python 中尝试以下操作：</description></item><item><title>部署 KVM/QEMU 虚拟化环境</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E9%83%A8%E7%BD%B2-KVM_QEMU-%E8%99%9A%E6%8B%9F%E5%8C%96%E7%8E%AF%E5%A2%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E9%83%A8%E7%BD%B2-KVM_QEMU-%E8%99%9A%E6%8B%9F%E5%8C%96%E7%8E%AF%E5%A2%83/</guid><description>概述 参考：
RedHat 官方文档，9-配置和管理虚拟化-开启虚拟化 Ubuntu 官方文档，虚拟化介绍 前期准备 查看 CPU 是否支持 KVM，筛选出来相关信息才可以正常使用 KVM
egrep &amp;ldquo;(svm|vmx)&amp;rdquo; /proc/cpuinfo 安装虚拟化组件 CentOS yum group install -y &amp;lsquo;Virtualization Host&amp;rsquo; # 安装虚拟化组 若安装完成后，模块未装载，则手动装载 KVM 模块 modprobe kvm modprobe kvm-intel 验证系统是否已经准备好成为虚拟化主机 virt-host-validate 启动 libvirt 服务 systemctl enable libvirtd &amp;ndash;now 创建连接使用命令 ln -sv /usr/libexec/qemu-kvm /usr/bin/ 安装 X 服务端程序 yum install -y xorg-x11-xauth xorg-x11-server-utils 安装图形管理工具 yum install virt-manager -y 安装 qemu 以模拟 I/O 设备 yum install qemu-system-x86 qemu-img -y 安装 virt 安装命令 yum install virt-install -y 安装虚拟机文件系统的管理工具 yum install libguestfs-tools -y Ubuntu 检查环境</description></item><item><title>常见问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid><description>概述 参考：
Unable to complete install: &amp;lsquo;VM &amp;lsquo;XXXX&amp;rsquo; didn&amp;rsquo;t show up after expected time.&amp;rsquo; 使用 virt-manager 安装 VM 时，惦记 Bejin Install 后报错。
TODO: 咋解决？？
guest has not initialized the display 无法连接虚拟机显示器
video 设备选为 Node 后，连接虚拟机提示 This VM has no graphic display device
使用 qemu-system 运行不会有这个问题，使用 virt-install 运行时会出现这个问题
TODO: 咋解决？？
Requested operation is not valid: cannot undefine domain with nvram 用 virsh 删除虚拟机时报错
解决方案：添加 &amp;ndash;nvram 或者删除配置文件中的这行 &amp;lt;nvram&amp;gt;/var/lib/libvirt/qemu/nvram/debian6.0_VARS.fd&amp;lt;/nvram&amp;gt;
TODO: 咋解决？？</description></item><item><title>持久化存储流程</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/</guid><description>概述 参考：
公众号，一文读懂 K8s 持久化存储流程 K8S 持久化存储基础 在进行 K8s 存储流程讲解之前，先回顾一下 K8s 中持久化存储的基础概念。
1. 名词解释 in-tree： 代码逻辑在 K8s 官方仓库中； out-of-tree： 代码逻辑在 K8s 官方仓库之外，实现与 K8s 代码的解耦； PV： PersistentVolume，集群级别的资源，由 集群管理员 or External Provisioner 创建。PV 的生命周期独立于使用 PV 的 Pod，PV 的 .Spec 中保存了存储设备的详细信息； PVC： PersistentVolumeClaim，命名空间（namespace）级别的资源，由 用户 or StatefulSet 控制器（根据VolumeClaimTemplate） 创建。PVC 类似于 Pod，Pod 消耗 Node 资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存），而 PVC 可以请求特定存储卷的大小及访问模式（Access Mode）； StorageClass： StorageClass 是集群级别的资源，由集群管理员创建。SC 为管理员提供了一种动态提供存储卷的“类”模板，SC 中的 .Spec 中详细定义了存储卷 PV 的不同服务质量级别、备份策略等等； CSI： Container Storage Interface，目的是定义行业标准的“容器存储接口”，使存储供应商（SP）基于 CSI 标准开发的插件可以在不同容器编排（CO）系统中工作，CO 系统包括 Kubernetes、Mesos、Swarm 等。 2.</description></item><item><title>从PTTYPE="dos"到TYPE="LVM2_member"的救援</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E4%BB%8EPTTYPEdos%E5%88%B0TYPELVM2_member%E7%9A%84%E6%95%91%E6%8F%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E4%BB%8EPTTYPEdos%E5%88%B0TYPELVM2_member%E7%9A%84%E6%95%91%E6%8F%B4/</guid><description>概述 参考：
同事叫我救援一台云主机，虽说是虚拟机，但是类比到硬件服务器还是一样的操作，这里记录下给后来者查阅
故障信息 控制台进去看到 centos7 的背景虚化的数字 7 + 转圈，重启下看下完整的错误，重启选了内核然后进到图形界面的时候按下 ecs 取消，观察终端
[ OK ] Started Show Plymouth Boot Screen. [ OK ] Reached target Paths. [ OK ] Reached target Basic System. [ 124.522110] dracut-initqueue[240]: Warning: dracut-initqueue timeout - starting timeout scripts [ 125.034736] dracut-initqueue[240]: Warning: dracut-initqueue timeout - starting timeout scripts [ 125.542788] dracut-initqueue[240]: Warning: dracut-initqueue timeout - starting timeout scripts [ 126.522110] dracut-initqueue[240]: Warning: dracut-initqueue timeout - starting timeout scripts [ 127.</description></item><item><title>错误处理</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Control-structure/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</guid><description>概述 参考：
Defer 延缓。
关键字defer允许我们推迟到函数返回之前（或任意位置执行 return 语句之后）一刻才执行某个语句或函数（为什么要在返回之后才执行这些语句?因为return语句同样可以包含一些操作，而不是单纯地返回某个值）。
Panic 直译为恐慌，在计算机中表示产生严重错误
当发生像数组越界或类型断言失败这样的严重错误时，会触发panic: runtime error运行时恐慌伴随着程序的崩溃输出一个runtime.Error接口类型的值。这个错误值有个RuntimeError()方法用于区别普通错误。
在多层嵌套的函数调用中调用panic，可以马上终止当前函数的执行，所有的defer语句都会保证执行并把控制权交还给接收到panic的函数调用者。这样向上冒泡直到最顶层，并执行(每层的)defer，在栈顶处程序崩溃，并在命令行中用传给panic的值报告错误情况：这个终止过程就是panicking。
Recover 恢复。这个Recover内建函数被用于从panic或错误场景中恢复：让程序可以从panicking重新获得控制权，停止终止过程进而恢复正常执行。recover只能在defer关键字的函数中使用，用于取得panic调用中传递过来的错误值，如果是正常执行，调用recover会返回nil，且没有其他效果
有一个简单的 parse 包（示例 13.4）用来把输入的字符串解析为整数切片；这个包有自己特殊的 ParseError。当没有东西需要转换或者转换成整数失败时，这个包会 panic（在函数 fields2numbers 中）。但是可导出的 Parse 函数会从 panic 中 recover 并用所有这些信息返回一个错误给调用者。为了演示这个过程，在 panic_recover.go 中 调用了 parse 包（示例 13.4）；不可解析的字符串会导致错误并被打印出来。</description></item><item><title>定时同步 GitHub 的代码仓库到 Gitee</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/%E5%AE%9A%E6%97%B6%E5%90%8C%E6%AD%A5-GitHub-%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E5%88%B0-Gitee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/%E5%AE%9A%E6%97%B6%E5%90%8C%E6%AD%A5-GitHub-%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E5%88%B0-Gitee/</guid><description>概述 参考：
利用 GitHub Action 同步 该功能已经有很多实现了，这篇文章以 https://github.com/Yikun/hub-mirror-action 项目为例。这个项目的基本逻辑是这样的：
通过 GitHub Actions 构建一个 Docker 容器，在 Docker 容器中，引入 Gitee 的私钥，这样可以在容器中使用 git 命令向 Gitee push 代码而不用输入密码了 容器启动后，在容器内 pull github 上的代码，并 push 到 gitee 上。 首先先来一个最基本的 Action 的 workflow 文件示例
name: Gitee repos mirror periodic job on: # 取消 push 的注释后，向本仓库推送代码即可开始 Gitee 同步 # push: schedule: # 每天北京时间9点跑 - cron: &amp;#34;0 1 * * *&amp;#34; jobs: build: runs-on: ubuntu-latest steps: - name: Cache phpdragon src repos # 使用 github 官方提供的 action 来引用发行版的主要版本 uses: actions/cache@v1 with: path: /home/runner/work/phpdragon/phpdragon-cache key: ${{ runner.</description></item><item><title>多宿主机集中管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%A4%9A%E5%AE%BF%E4%B8%BB%E6%9C%BA%E9%9B%86%E4%B8%AD%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%A4%9A%E5%AE%BF%E4%B8%BB%E6%9C%BA%E9%9B%86%E4%B8%AD%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
除了 OpenStack 以外，市面上没有多少可以批量管理 KVM 主机的项目 o(╯□╰)o 唯一能搜到的只有一个 WebVirtCloud ~~~~
为什么要用 Python 写前端呢。。。裂开了。。。。o(╯□╰)o
WebVirtCloud 参考：
GitHub 项目，retspen/webvirtmgr(已于 2018 年停止更新，被 webvirtcloud 代替) GitHub 项目，retspen/webvirtcloud WebVirtCloud 是一个由 Python 的 Web 框架 Django 编写的前后端一体项目。
WebVirtCloud 有多个组件
Nginx 监听 80 端口，入口，用来响应 /static/ 下的各种静态资源 Webvirtcloud 监听 8000 端口，处理 IP:PORT/ 路径的访问请求，展示出的进程名为 gunicorn Gunicorn(Green Unicorn) 是一个 UNIX 下符合 WSGI 规范的 HTTP 服务器(说简单点就是一个类似 Nginx 程序)。 WSGI 指定了“web 服务器”和“Python web 应用/ web 框架”之间的标准接口，以提高 web 应用在一系列 web 服务器间的移植性。 Novnc 监听 6080 端口，处理 IP:PORT/novncd/ 路径的访问请求，展示出的进程名为 novncd WebVirtCloud 在容器中通过老式的 runsvdir 运行，runsvdir 会读取 -P 选项指定的目录，可以看到，runsv 程序后的参数，就是 /etc/service/ 目录下的目录名</description></item><item><title>反向解析原理</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/%E5%8F%8D%E5%90%91%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/%E5%8F%8D%E5%90%91%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/</guid><description>概述 参考：
我们都知道DNS解析是把域名解析到IP，你知道怎么把IP解析到域名吗？知道反向解析的工作原理吗？
上一篇博客DNS解析原理讲解了域名到IP的解析流程，本篇着重讲解一下从IP到域名的解析流程。
首先，简单聊一下反向解析的使用场景，当前使用最多的是用于邮箱服务器IP配置反向解析指向邮箱域名。比如一个邮箱服务器，每天会收到来自互联网IP发送大量邮件，并不是每封邮件都要接收的，否则邮箱会被垃圾邮件刷爆的。所以邮箱服务器通常都有自己的反垃圾邮件规则。比如收到某个IP服务器发过来的邮件，首先会判断此IP是否在反垃圾邮件联盟的黑名单里，如果IP在黑名单就直接拒收邮件了。然后会判断邮箱域名信誉度是否良好，是否在黑名单。怎么获取邮箱域名呢，就是通过检测IP的反向解析来获取邮箱域名。所以说，对于自己搭建邮箱服务器，IP设置反向解析指向域名是重要的一步。
那IP的解析流程是怎样的呢？
要知道这个答案首先要知道IP在全球是怎么管理分配的。ICANN负责全球IP地址的编号分配，将部分商用IP分配给RIR(Regional Internet Registry，地区性 Internet 注册机构)来负责管理。全球一共有5个RIR：
ARIN 主要负责北美地区业务
RIPE 主要负责欧洲地区业务
LACNIC 主要负责拉丁美洲美洲业务
AfriNIC 负责非洲地区业务
APNIC 负责亚太地区业务
RIR 再授权给国家级注册机构负责管理各国家内的 IP 管理，比如 APNIC 下面的 CNNIC，JPNIC 等。CNNIC 再把 IP 授权给不同服务商，比如华为云，其他运营商等等。
对于一个域名，例如www.huawei.com，我们知道是com顶级域，那假如一个IP 117.78.61.19，是怎么判断是哪个顶级域呢？
反向解析也有一个顶级域是in-addr.arpa，对于IP 117.78.61.19实际对应的反向域名是19.61.78.117.in-addr.arpa，反向顶级域把117.in-addr.arpa这个A类授权给APNIC来管理，APNIC把78.117.in-addr.arpa这个B类授权给CNNIC来管理，CNNIC把下面的部分C类地址给华为云；
通过dig命令加 -x参数可以查看反向解析流程，大致类似于域名的解析流程。
知道了域名，IP的解析流程，对于我们定位解析不生效判断就更好理解了。可以查看是到哪一步中断，具体再去分析。希望以上分享对你有一定帮助</description></item><item><title>访问控制</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</guid><description>概述 参考：
官方文档，安装 - 配置安全性 - 配置身份验证 Grafana 以 Organizations(组织) 为最大分类
组织可以包含 Teams，Teams 又可以包含 Users。
当我们正常登录或者匿名访问时，首先进到组织中，不同的组织，可以看到的面板、数据源等等配置都是不一样的。</description></item><item><title>告警模板详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/%E5%91%8A%E8%AD%A6%E6%A8%A1%E6%9D%BF%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Alertmanager/%E5%91%8A%E8%AD%A6%E6%A8%A1%E6%9D%BF%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，通知模板参考</description></item><item><title>更多包管理工具</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/%E6%9B%B4%E5%A4%9A%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/%E6%9B%B4%E5%A4%9A%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
Yarn 参考：
官网 管理 Yarn 的首选方式是通过 Corepack，这是从 16.10 开始随所有 Node.js 版本一起提供的新二进制文件。它充当我们和 Yarn 之间的中介，让我们在多个项目中使用不同的包管理器版本，而无需再签入 Yarn 二进制文件。
Node.js &amp;gt;=16.10 Corepack 默认包含在所有 Node.js 安装中，但目前是可选的。要启用它，请运行以下命令： corepack enable
Node.js &amp;lt;16.10 在 16.10 之前的版本中，Node.js 不包含 Corepack；为了解决这个问题，运行： npm i -g corepack
配置镜像源以加速下载各种依赖包
yarn config set registry https://registry.npmmirror.com -g 配置 $PATH 以便可以直接执行通过 yarn 安装的各种工具
export PATH=$PATH:~/.config/yarn/global/node_modules/.bin Yarn 关联文件与配置 ~/.yarnrc # 配置文件
~/.config/yarn/* #
yarn Syntax(语法)</description></item><item><title>故障处理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>概述 参考：
查看崩溃信息 https://its401.com/article/CRJ297486/120602345
1.打开控制面板
2.再进入安全和维护
3.点击维护查看可靠性历史记录
4.点击关键信息随便个事件进去可以看见因为啥文件导致卡死的。
我是因为 wps 的某个文件，把 wps 卸了就好了。 5.如果还没解决的话，可以试试利用 Dism 修复系统
管理员打开 cmd 命令行。
直接输入这两条就好了
DISM /Online /Cleanup-image /ScanHealth //这一条指令用来扫描全部系统文件，并扫描计算机中映像文件与官方系统不一致的情况。 DISM /Online /Cleanup-image /RestoreHealth //计算机必须联网，这种命令的好处在于可以在修复时，系统未损坏部分可以继续运行
图标变成白色 删除图标缓存文件 %LOCALAPPDATA\IconCache.db，然后重启 “资源管理器”</description></item><item><title>故障处理案例</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description>概述 参考：
公众号，0.2 秒复制了 100G 的文件？ 主要描述了文件系统与磁盘空间管理问题，导致一个文件占据了跳跃性的空间，让文件变成虚假的无限大。
Welcome to emergency 系统可以启动，直接进入 emergency 模式，输入密码后按 Ctrl+D 可以进入系统，多半是挂载问题，除了检查 /etc/fstab 的挂载外，还需要看如下几个目录有没有关于文件系统的模块参数：
/etc/modprobe.d/*.conf /run/modprobe.d/*.conf /usr/lib/modprobe.d/*.conf 找到被删除但是还被占用的文件 日常运维过程中，我们经常需要处理磁盘空间问题，当接到告警后，第一时间会去找那些大文件，一般比如 Centos，可能大文件就是 /var/log/messages。但有的时候，会出现怎么也查不到大文件的情况，通过 du 查找的时候，统计出来的大小，跟 df 显示的占用空间对应不上。如果通过 df -i 查看 inode 没有满的话，那么极有可能，是有大文件被直接 rm 了，但是仍然有进程打开了这个文件。
这种情况，由于进程没有退出，因此文件占用的空间并不会释放；直到进程退出，磁盘空间才会真正释放。
如何找到是哪个进程打开了该文件 Linux 上，由于进程仍然存活，因此可以通过查看所有进程打开的 fd，如果该文件已经被删除，则查看时，会显示(deleted)。
示例如下：
$ sudo find /proc/*/fd -ls | grep &amp;#39;(deleted)&amp;#39; 388609 0 lrwx------ 1 zerotier-one zerotier-one 64 Aug 21 00:19 /proc/29400/fd/4 -&amp;gt; /tmp/ibpX85Vd\ (deleted) 388610 0 lrwx------ 1 zerotier-one zerotier-one 64 Aug 21 00:19 /proc/29400/fd/5 -&amp;gt; /tmp/ibCwAgAj\ (deleted) 388611 0 lrwx------ 1 zerotier-one zerotier-one 64 Aug 21 00:19 /proc/29400/fd/6 -&amp;gt; /tmp/ibRZ5rep\ (deleted) 388612 0 lrwx------ 1 zerotier-one zerotier-one 64 Aug 21 00:19 /proc/29400/fd/7 -&amp;gt; /tmp/ibBuNEzA\ (deleted) 388616 0 lrwx------ 1 zerotier-one zerotier-one 64 Aug 21 00:19 /proc/29400/fd/11 -&amp;gt; /tmp/ibG68kpG\ (deleted) 如何避免这种情况</description></item><item><title>故障处理案例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description>概述 参考：
OpenAI 新部署的遥测服务在大规模集群中产生了大量 API 调用导致控制平面过载，让 CoreDNS 服务不可用导致集群内部交互出现问题 https://status.openai.com/incidents/ctrsv3lwd797
公众号 -k8s技术圈，OpenAI 严重生产故障复盘，这次真的是 Kubernetes 的锅～ 案例列表 公众号 - 云原生实验室，JVM 内存与 K8s 容器内存不一致引发的 OOMKilled 总结
公众号 - 云原生运维，从崩溃到防御：一个 emptyDir 引发的「蝴蝶效应」
nfs 相关 K8S 中与 NFS 相关的故障通常为 Node 没有安装 nfs 客户端。还有不太常见的版本问题（在 storageclass 中添加 mountOptions 字段指定 nfs 版本即可）。
张馆长，k8s 使用 nfs 下 pod 无法创建的解决思路
kube-proxy 无法绑定 NodePort 端口 故障现象 参考：
其他有相同现象的人： 馆长 ieevee kube-proxy 日志报错：
root@desistdaydream:~# kubectl logs -n kube-system kube-proxy-4thfl | more E0507 06:05:09.</description></item><item><title>关系数据</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/</guid><description>概述 参考：
Relational Data(关系数据)
MySQL MySQL
PostgreSQL PostgreSQL
SQLite SQLite
Clickhouse ClickHouse</description></item><item><title>观测容器</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E8%A7%82%E6%B5%8B%E5%AE%B9%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E8%A7%82%E6%B5%8B%E5%AE%B9%E5%99%A8/</guid><description>概述 参考：
容器的 Observability 如何实现？
Docker 为什么不内置 cAdvisor？docker stats 命令为什么不设计个接口直接吐出来 OpenMetrics 格式的数据？
cAdvisor 参考：
GitHub 项目，google/cadvisor Prometheus 官方文档，指南 - 使用 cAdvisor 监控 Docker 容器指标 http://www.xuyasong.com/?p=1483 Container Advisor(容器顾问，简称 cAdvisor) 为容器用户提供了对其运行中容器的资源使用情况和性能特征的深入理解。它是一个持续运行的守护进程，负责收集、汇总、处理并导出有关运行容器的信息。具体而言，它会记录每个容器的资源隔离参数、历史资源使用情况、完整历史资源使用直方图以及网络统计信息。这些数据会按容器和整机维度分别导出。
cAdvisor 被集成在 Kubelet 中
暴露的指标 cadvisor_version_info 具有常数“1”值的度量，由内核版本、操作系统版本、docker 版本、cadvisor 版本和 cadvisor 修订版标记。 container_cpu_cfs_periods_total 已用强制周期间隔数。 container_cpu_cfs_throttled_periods_total 节流周期间隔数。 container_cpu_cfs_throttled_seconds_total 容器被限制的总持续时间。 container_cpu_load_average_10s 过去 10 秒内容器 cpu 负载平均值的值。 container_cpu_system_seconds_total 以秒为单位消耗的累积系统 CPU 时间。 container_cpu_usage_seconds_total 以秒为单位消耗的累积 CPU 时间。 container_cpu_user_seconds_total 以秒为单位消耗的累积用户 cpu 时间。 container_file_descriptors 容器的打开文件描述符数。 container_fs_inodes_free 可用索引节点数 container_fs_inodes_total inode 数 container_fs_io_current 当前正在进行的 I/O 数 container_fs_io_time_seconds_total 花费在 I/O 上的累计秒数 container_fs_io_time_weighted_seconds_total 累积加权 I/O 时间（以秒为单位） container_fs_limit_bytes 此文件系统上的容器可以消耗的字节数。 container_fs_read_seconds_total 阅读花费的累计秒数 container_fs_reads_bytes_total 读取的累积字节数 container_fs_reads_merged_total 合并读取的累积计数 container_fs_reads_total 已完成读取的累计计数 container_fs_sector_reads_total 已完成扇区读取的累积计数 container_fs_sector_writes_total 已完成扇区写入的累积计数 container_fs_usage_bytes 此文件系统上的容器消耗的字节数。 container_fs_write_seconds_total 写入花费的累计秒数 container_fs_writes_bytes_total 写入字节的累积计数 container_fs_writes_merged_total 合并写入的累积计数 container_fs_writes_total 已完成写入的累积计数 container_last_seen 上次导出器看到容器的时间 container_memory_cache 页缓存内存的字节数。 container_memory_failcnt 内存使用次数达到限制 container_memory_failures_total 内存分配失败的累积计数。 container_memory_mapped_file 内存映射文件的大小（以字节为单位）。 container_memory_max_usage_bytes 以字节为单位记录的最大内存使用量 container_memory_rss RSS 的大小（以字节为单位）。 container_memory_swap 容器交换使用量（以字节为单位）。 container_memory_usage_bytes 当前内存使用量（以字节为单位），包括所有内存，无论何时访问 container_memory_working_set_bytes 当前工作集（以字节为单位）。 container_network_receive_bytes_total 接收字节的累计计数 container_network_receive_errors_total 接收时遇到的错误累积计数 container_network_receive_packets_dropped_total 接收时丢弃的数据包的累积计数 container_network_receive_packets_total 接收的数据包的累积计数 container_network_transmit_bytes_total 传输的累积字节数 container_network_transmit_errors_total 传输时遇到的错误累积计数 container_network_transmit_packets_dropped_total 传输时丢弃的数据包的累积计数 container_network_transmit_packets_total 传输的数据包的累积计数 container_processes 在容器内运行的进程数。 container_scrape_error 1 如果在获取容器指标时出错，则为 0 否则 container_sockets 容器打开的套接字数。 container_spec_cpu_period 容器的 CPU 周期。 container_spec_cpu_quota 容器的 CPU 配额。 container_spec_cpu_shares 容器的 CPU 份额。 container_spec_memory_limit_bytes 容器的内存限制。 container_spec_memory_reservation_limit_bytes 容器的内存预留限制。 container_spec_memory_swap_limit_bytes 容器的内存交换限制。 container_start_time_seconds 自 Unix 纪元以来容器的启动时间（以秒为单位）。 container_tasks_state 处于给定状态的任务数 container_threads 容器内运行的线程数 container_threads_max 容器内允许的最大线程数，如果值为零则无穷大 container_ulimits_soft 容器根进程的软 ulimit 值。如果 -1 则无限制，优先级和好除外 Grafana 面板 https://grafana.</description></item><item><title>函数</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E6%9D%BF/%E5%87%BD%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E6%A8%A1%E6%9D%BF/%E5%87%BD%E6%95%B0/</guid><description>概述 参考：
官方文档，函数 与 Hugo 的变量一样，我们还可以在模板中使用函数功能，用法与 Go 模板中的函数一样，只不过 Hugo 基于这些基本的 Go 模板函数还增加了额外的功能。</description></item><item><title>好用的 Action</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/%E5%A5%BD%E7%94%A8%E7%9A%84-Action/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/%E5%A5%BD%E7%94%A8%E7%9A%84-Action/</guid><description>概述 参考：
GitHub Marketplace，Action docker/build-push-action https://github.com/docker/build-push-action
使用 Buildx 构建和推送 Docker 映像的 GitHub Action
name: Build and push Docker image uses: docker/build-push-action@v2 with: - **context: .** # 构建上下文 - **file: simulate_mysql_exporter/e37_exporter/Dockerfile** # 指定要使用的 Dockerfile 路径，`默认值：{context字段的值}/Dockerfile` - **push: true** # 构建完成后，是否推送镜像 - **tags: ghcr.io/desistdaydream/e37-exporter:v0.2.0** # 指定要构建的镜像名称 action-gh-release https://github.com/softprops/action-gh-release
用于创建 Realease 的 GitHub Action
Notes: action-gh-release 需要上传文件，所以需要将仓库的 Actions 配置 中的 Workflow 权限设置为读写</description></item><item><title>环境变量</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</guid><description>概述 参考：
Wiki, Environment_variable Environment variable(环境变量) 是一种特殊的Variable（本质也是变量，只不过是一个抽象的概念，将特定用途的变量抽象为环境变量）。环境变量可以影响计算机上运行中的进程的行为方式。环境变量是进程运行所在环境的一部分。例如，正在运行的进程可以查询 TEMP 环境变量的值，以发现一个合适的位置来存储临时文件；或者查询 HOME 变量以查找由运行进程的用户拥有的目录结构。
环境变量于 1979 年与 Unix 7 版本一起引入，因此从那时起包括在所有Unix-like OS中（包括 Linux、macOS）。从 1982 年的 PC DOS 2.0 开始，所有后续的 Microsoft OS也都将环境变量作为一项功能包含在其中。
尽管各种操作系统中对于环境变量在使用时的语法、标准各有不同，但所有系统都统一将环境变量作为操作系统的基本功能之一。</description></item><item><title>汇编语言</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E4%BD%8E%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E4%BD%8E%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/</guid><description>概述 参考：
汇编语言入门教程 - 阮一峰的网络日志 学习编程其实就是学高级语言，即那些为人类设计的计算机语言。
但是，计算机不理解高级语言，必须通过编译器转成二进制代码，才能运行。学会高级语言，并不等于理解计算机实际的运行步骤。
计算机真正能够理解的是低级语言，它专门用来控制硬件。汇编语言就是低级语言，直接描述 / 控制 CPU 的运行。如果你想了解 CPU 到底干了些什么，以及代码的运行步骤，就一定要学习汇编语言。
汇编语言不容易学习，就连简明扼要的介绍都很难找到。下面我尝试写一篇最好懂的汇编语言教程，解释 CPU 如何执行代码。
一、汇编语言是什么？ 我们知道，CPU 只负责计算，本身不具备智能。你输入一条指令（instruction），它就运行一次，然后停下来，等待下一条指令。
这些指令都是二进制的，称为操作码（opcode），比如加法指令就是00000011。编译器的作用，就是将高级语言写好的程序，翻译成一条条操作码。
对于人类来说，二进制程序是不可读的，根本看不出来机器干了什么。为了解决可读性的问题，以及偶尔的编辑需求，就诞生了汇编语言。
汇编语言是二进制指令的文本形式，与指令是一一对应的关系。比如，加法指令00000011写成汇编语言就是 ADD。只要还原成二进制，汇编语言就可以被 CPU 直接执行，所以它是最底层的低级语言。
二、来历 最早的时候，编写程序就是手写二进制指令，然后通过各种开关输入计算机，比如要做加法了，就按一下加法开关。后来，发明了纸带打孔机，通过在纸带上打孔，将二进制指令自动输入计算机。
为了解决二进制指令的可读性问题，工程师将那些指令写成了八进制。二进制转八进制是轻而易举的，但是八进制的可读性也不行。很自然地，最后还是用文字表达，加法指令写成 ADD。内存地址也不再直接引用，而是用标签表示。
这样的话，就多出一个步骤，要把这些文字指令翻译成二进制，这个步骤就称为 assembling，完成这个步骤的程序就叫做 assembler。它处理的文本，自然就叫做 aseembly code。标准化以后，称为 assembly language，缩写为 asm，中文译为汇编语言。
每一种 CPU 的机器指令都是不一样的，因此对应的汇编语言也不一样。本文介绍的是目前最常见的 x86 汇编语言，即 Intel 公司的 CPU 使用的那一种。
三、寄存器 学习汇编语言，首先必须了解两个知识点：寄存器和内存模型。
先来看寄存器。CPU 本身只负责运算，不负责储存数据。数据一般都储存在内存之中，CPU 要用的时候就去内存读写数据。但是，CPU 的运算速度远高于内存的读写速度，为了避免被拖慢，CPU 都自带一级缓存和二级缓存。基本上，CPU 缓存可以看作是读写速度较快的内存。
但是，CPU 缓存还是不够快，另外数据在缓存里面的地址是不固定的，CPU 每次读写都要寻址也会拖慢速度。因此，除了缓存之外，CPU 还自带了寄存器（register），用来储存最常用的数据。也就是说，那些最频繁读写的数据（比如循环变量），都会放在寄存器里面，CPU 优先读写寄存器，再由寄存器跟内存交换数据。
寄存器不依靠地址区分数据，而依靠名称。每一个寄存器都有自己的名称，我们告诉 CPU 去具体的哪一个寄存器拿数据，这样的速度是最快的。有人比喻寄存器是 CPU 的零级缓存。
四、寄存器的种类 早期的 x86 CPU 只有 8 个寄存器，而且每个都有不同的用途。现在的寄存器已经有 100 多个了，都变成通用寄存器，不特别指定用途了，但是早期寄存器的名字都被保存了下来。</description></item><item><title>基于 DNS 的 Kubernetes 服务发现的规范</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/%E5%9F%BA%E4%BA%8E-DNS-%E7%9A%84-Kubernetes-%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E7%9A%84%E8%A7%84%E8%8C%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/%E5%9F%BA%E4%BA%8E-DNS-%E7%9A%84-Kubernetes-%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E7%9A%84%E8%A7%84%E8%8C%83/</guid><description>概述 概述 参考：
官方文档 任何基于 DNS 的以实现 Kubernetes 服务发现的实现工具，必须提供本规范描述的 Resource Record
DNS Records 类型包含以下几种：A/AAAA、SRV、PTR、CHAME。不同的 k8s 资源，其可用的 Record Type 也不相同。
Resource Records 规范
在下面的描述中，有几个占位符，表示如下含义：
&amp;lt;service&amp;gt; # service 对象的名字
&amp;lt;ns&amp;gt; # namesapce 的名字
&amp;lt;zone&amp;gt; # 集群域名(默认为 cluster.local)。
集群域名可以通过 kubelet 的配置文件 clusterDomain 字段定义。 &amp;lt;ttl&amp;gt; # 一条 Record 的标准 DNS 存活时间
ClusterIP 类型 Service 的 RR 格式 参考：官方文档
现在假定一个 Service 对象名为 &amp;lt;service&amp;gt;，在名为 &amp;lt;ns&amp;gt; 名称空间，该 Service 对象的 CLUSTER-IP 为 &amp;lt;cluster-ip&amp;gt;。则 DNS 实现程序必须具有下列几种类型的 Records(记录)。
A/AAAA Record 如果 &amp;lt;service&amp;gt; 对象具有 &amp;lt;cluster-ip&amp;gt; 且为 IPv4 地址。</description></item><item><title>即时通信</title><link>https://desistdaydream.github.io/docs/Utils/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1/</guid><description>概述 参考：
Wiki, Instant_messaging Instant messaging(即时通信，简称 IM) 是一种在线聊天技术，可以使文本通过网络进行实时传输。大多数 IM 程序使用推送技术并添加其他功能，比如 表情符号、文件传输、聊天机器人、IP 语音、视频聊天、etc. 功能。
常见 IM 程序
Slack Discord WeChat(微信) Dingtalk(钉钉) 飞书 Telegram etc. Chatbot 参考：
Wiki, Chatbot https://github.com/zhayujie/chatgpt-on-wechat # Python 实现的。基于大模型搭建的聊天机器人，同时支持 微信公众号、企业微信应用、飞书、钉钉 等接入（这些接入目标抽象为 Channel），可选择GPT3.5/GPT-4o/GPT-o1/ DeepSeek/Claude/文心一言/讯飞星火/通义千问/ Gemini/GLM-4/Claude/Kimi/LinkAI（这些是 AI 模型）。能处理文本、语音和图片，访问操作系统和互联网，支持基于自有知识库进行定制企业智能客服。
https://github.com/hanfangyuan4396/dify-on-wechat # Python 实现的。基于 chatgpt-on-wechat，相当于其下游分支。为 channel 和 model 添加了对接目标。channel 的 wechat bot 可以对接 Gewechat；model 可以对接 Dify。 加入了 Ollama 支持，个人不更新项目 https://github.com/kaina404/chatgpt-on-wechat/tree/feature/ollama_support https://github.com/Joycc/chatgpt-on-wechat/tree/master 微信的 Chatbot 可以使用多种方式实现：
模拟 ipad 模拟 web # 截至 2025-03-22 被查的厉害，而且容易失败，失败几次就会被官方警告 模拟 Windows 桌面端 Wechaty 参考：</description></item><item><title>计算机厂家信息</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%82%E5%AE%B6%E4%BF%A1%E6%81%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%82%E5%AE%B6%E4%BF%A1%E6%81%AF/</guid><description>Dell 信息查询：https://www.dell.com/support/home/zh-cn
报修热线：
华三 信息查询：https://es.h3c.com/entitlement/
报修热线：
可以通过微信小程序建单 浪潮 信息查询：https://www.inspur.com/eportal/ui?pageId=2317460
报修热线：4008600011
其他 七彩虹 举办比赛，开奖时第一和第二名是没参加过比赛
https://www.bilibili.com/video/BV17EyKYcEeY/ https://www.bilibili.com/video/BV1wVmKYLE77</description></item><item><title>加密解密的最佳实践</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%8A%A0%E5%AF%86%E8%A7%A3%E5%AF%86%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%8A%A0%E5%AF%86%E8%A7%A3%E5%AF%86%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
数据加密、请求参数加密、data 加密。
简单示例 公开密钥加密 与 对称密钥加密的常见流程，以 RSA 和 AES 举例：
向 A 发起请求（比如登录时），A 返回自身的 RSA 公钥，将公钥保存在本地 向 A 发起请求，随机生成 X 位（e.g. 16 位、32 位）长度的字符串，用于对称加密的 AES 密钥，需要携带如下信息 使用 A 的 公钥 加密 密钥 的结果可以放在请求头中 使用 密钥 加密要发送的数据放在请求体中 A 收到请求后 使用 RSA 私钥 解密请求头，以获取 密钥 使用 密钥 解密请求体中的数据 处理数据 使用 密钥 加密响应数据放在响应体中。</description></item><item><title>进程、线程、线程池</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0/</guid><description>概述 参考：
公众号-码农的荒岛求生，看完这篇文章还不懂高并发中的线程与线程池你来打我 一切要从 CPU 说起 你可能会有疑问，讲多线程为什么要从 CPU 说起呢？原因很简单，在这里没有那些时髦的概念，你可以更加清晰的看清问题的本质。
CPU 并不知道线程、进程之类的概念。
CPU 只知道两件事:
从内存中取出指令 执行指令，然后回到 1 你看，在这里 CPU 确实是不知道什么进程、线程之类的概念。
接下来的问题就是 CPU 从哪里取出指令呢？答案是来自一个被称为 Program Counter(简称 PC) 的寄存器，也就是我们熟知的程序计数器，在这里大家不要把寄存器想的太神秘，你可以简单的把寄存器理解为内存，只不过存取速度更快而已。
PC 寄存器中存放的是什么呢？这里存放的是指令在内存中的地址，什么指令呢？是 CPU 将要执行的下一条指令。
那么是谁来设置 PC 寄存器中的指令地址呢？
原来 PC 寄存器中的地址默认是自动加 1 的，这当然是有道理的，因为大部分情况下 CPU 都是一条接一条顺序执行，当遇到 if、else 时，这种顺序执行就被打破了，CPU 在执行这类指令时会根据计算结果来动态改变 PC 寄存器中的值，这样 CPU 就可以正确的跳转到需要执行的指令了。
聪明的你一定会问，那么 PC 中的初始值是怎么被设置的呢？
在回答这个问题之前我们需要知道 CPU 执行的指令来自哪里？是来自内存，废话，内存中的指令是从磁盘中保存的可执行程序加载过来的，磁盘中可执行程序是编译器生成的，编译器又是从哪里生成的机器指令呢？答案就是我们定义的函数。
注意是函数，函数被编译后才会形成 CPU 执行的指令，那么很自然的，我们该如何让 CPU 执行一个函数呢？显然我们只需要找到函数被编译后形成的第一条指令就可以了，第一条指令就是函数入口。
现在你应该知道了吧，我们想要 CPU 执行一个函数，那么只需要把该函数对应的第一条机器指令的地址写入 PC 寄存器就可以了，这样我们写的函数就开始被 CPU 执行起来啦。
你可能会有疑问，这和线程有什么关系呢？
从 CPU 到操作系统 上一小节中我们明白了 CPU 的工作原理，我们想让 CPU 执行某个函数，那么只需要把函数对应的第一条机器执行装入 PC 寄存器就可以了，这样即使没有操作系统我们也可以让 CPU 执行程序，虽然可行但这是一个非常繁琐的过程，我们需要：</description></item><item><title>进程与CPU核心的绑定</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E8%BF%9B%E7%A8%8B%E4%B8%8ECPU%E6%A0%B8%E5%BF%83%E7%9A%84%E7%BB%91%E5%AE%9A/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E8%BF%9B%E7%A8%8B%E4%B8%8ECPU%E6%A0%B8%E5%BF%83%E7%9A%84%E7%BB%91%E5%AE%9A/</guid><description>概述 参考:
Linux 有问必答：如何知道进程运行在哪个 CPU 内核上？ https://www.xmodulo.com/cpu-core-process-is-running.html 问题：我有个 Linux 进程运行在多核处理器系统上。怎样才能找出哪个 CPU 内核正在运行该进程？
当你在 多核 NUMA 处理器上运行需要较高性能的 HPC（高性能计算）程序或非常消耗网络资源的程序时，CPU/memory 的亲和力是限度其发挥最大性能的重要因素之一。在同一 NUMA 节点上调度最相关的进程可以减少缓慢的远程内存访问。像英特尔 Sandy Bridge 处理器，该处理器有一个集成的 PCIe 控制器，你可以在同一 NUMA 节点上调度网络 I/O 负载（如网卡）来突破 PCI 到 CPU 亲和力限制。
作为性能优化和故障排除的一部分，你可能想知道特定的进程被调度到哪个 CPU 内核（或 NUMA 节点）上运行。
这里有几种方法可以找出哪个 CPU 内核被调度来运行给定的 Linux 进程或线程。
方法一 如果一个进程使用 taskset 命令明确的被固定（pinned）到 CPU 的特定内核上，你可以使用 taskset 命令找出被固定的 CPU 内核：
$ taskset -c -p
例如, 如果你对 PID 5357 这个进程有兴趣:
$ taskset -c -p 5357
pid 5357&amp;rsquo;s current affinity list: 5</description></item><item><title>可观测性之数据模型</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Observability/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E4%B9%8B%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Observability/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E4%B9%8B%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考
原文：公众号-k8s 技术圈，聊聊可观测性之数据模型 在 201x 年，随着容器技术的出现，容器的部署方式逐渐被各大互联网公司采用，相比物理机/虚拟机，容器的好处是环境隔离、轻量、快速。
但是管理容器是一件复杂的事情，后来出现了 Kubernetes，成为了事实上的容器管理标准，目前各大公司都在使用 Kubernetes。
因为容器和 Kubernetes 降低了服务（应用）的部署和升级成本，所以催生了「微服务」的概念，服务从「单体复杂服务」向「多个简单服务」演变，在之前，需要着重考虑服务内的架构设计，单个服务对外提供尽可能多的能力，而在微服务中，会直接把单个服务拆分成多个服务，服务之间用 API 调用。
这里也可以看到，在微服务中，架构设计的重要性降低，API 设计的重要性提高。
另外，拆分出微服务后，编程的难度事实上降低了，对编程人员的要求也降低了。
这说明一个事实，随着基础设施的不断发展，会有越来越多的「编程能力」沉淀成基础设施，使编程的难度不断降低：软件开发不断向简单的方式发展。
但是，随着微服务的发展，服务变得太多了，管理负责度又上升了，比如怎么去解决服务发现的问题、怎么控制流量、服务之间怎么做隔离，服务状态怎么观测等等。这时候又出现了「服务治理」的概念，关于服务治理，有一个新的词：Service Mesh，现在事实标准是 Istio。
概述 可观测性是为了应对微服务的复杂场景下发明出来的一个词，本质上是为了衡量系统运行的状态，可观测性是服务治理的一个维度，和功能性、可测试性、可运维性一样。
一般常说可观测性包含三个度量角度：Metric、Logging、Tracing，其实还有一个：Profiling。
Metric：指标，对系统中某一类信息的聚合统计，比如 QPS、延迟、错误率等。 Logging：日志，对系统所做行为的一种记录，它是离散的，没有相关性，为了区分这种记录的重要程度，会分级别（DEBUG、INFO、WARN、ERROR、FATAL）。 Tracing：调用链，它反映的是请求经过某个组件的运行情况，经过组件的数据叫做 Span，Span 可以体现经过组件的状态、一些关键属性和事件、上下文信息。Span 之间通过 Trace ID 关联。 Profiling：一般叫做 Continuous Profiling，持续分析，它反映的是程序内部的运行状态，比如栈调用、执行时间等。可以把 Profiling 可视化成火焰图方面分析问题。 一般来说，基于这些度量处理故障的流程是：Metric → Tracing → Logging → Profiling
根据 Metric 配置的告警策略发现问题，基于 Tracing 查看是哪个组件出问题，基于 Logging 查看组件的日志，Profiling 分析组件具体的故障或性能问题。
数据模型 在 Tracing 领域，之前有两个项目，一个是 OpenTracing，它是一个规范，Jaeger 就是基于 OpenTracing 的开源实现，另一个是 OpenCensus，它是 Google 开源的度量工具。这两个项目功能高度重合，在 CNCF 主导下合并成了 OpenTelemetry，而 OpenTracing 和 OpenCensus 也不再维护。</description></item><item><title>控制字符</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6/</guid><description>概述 参考：
Wiki, Control character 在计算机和电信领域，Control character(控制字符) 或 Non-printing character(非打印字符，简称 NPC) 是字符的编码（或称为 字符集）中非书面字符、符号的代码点。
这些控制字符包括：回车符（Carriage-Return）、换行符（Line-Feed）、退格符（Backspace）、逃离符（转义符 Escape-Character）、制表符（Tab）、响铃符（Bell）、等等。这些控制字符本身通常不会显示在终端屏幕上。键盘上的 ESC、Enter、Backspace、等等 按键在按下后，都会向终端发送对应的控制字符。
在 ASCII 表 中有 33 个控制字符，比如 0 - 32 号字符，都属于控制字符。在 ECMA-48 标准中又增加了 32 个
ACSII 中的 33 个控制字符通常称为 C0 控制字符。后来还添加了 ASCII 中的 128-159 作为控制字符，称为 C1 控制字符。</description></item><item><title>灵魂拷问，上 Kubernetes 有什么业务价值？</title><link>https://desistdaydream.github.io/blog/copy/%E4%BA%91%E5%8E%9F%E7%94%9F/%E7%81%B5%E9%AD%82%E6%8B%B7%E9%97%AE%E4%B8%8A-Kubernetes-%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%9A%E5%8A%A1%E4%BB%B7%E5%80%BC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E4%BA%91%E5%8E%9F%E7%94%9F/%E7%81%B5%E9%AD%82%E6%8B%B7%E9%97%AE%E4%B8%8A-Kubernetes-%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%9A%E5%8A%A1%E4%BB%B7%E5%80%BC/</guid><description>原文链接
本文整理自 2020 年 7 月 22 日《基于 Kubernetes 与 OAM 构建统一、标准化的应用管理平台》主题线上网络研讨会。文章共分为上下两篇，本文为上篇，主要和大家介绍上Kubernetes有什么业务价值，以及什么是“以应用为中心”的 Kubernetes。下篇将跟大家具体分享如何构建“以应用为中心”的 Kubernetes。
关注公众号，回复“0722”即可下载 PPT
非常感谢大家来到 CNCF 的直播，我是张磊，阿里云的高级技术专家，Kubernetes 项目资深维护者。同时也是 CNCF 应用交付领域 co-chair。我今天给大家带来的分享主题是《基于 Kubernetes 与 OAM 构建统一、标准化的应用管理平台》。在封面上有个钉钉群组二维码。大家可以通过这个二维码进入线上交流群。
上 Kubernetes 有什么业务价值？
今天要演讲的主题是跟应用管理或者说是云原生应用交付是相关的。首先我们想要先回答这么一个问题：为什么我们要基于 Kubernetes 去构建一个应用管理平台？
上图是一个本质的问题，我们在落地 K8s 经常遇到的一个问题。尤其是我们的业务方会问到这么一个问题，我们上 Kubernetes 有什么业务价值？这时候作为我们 K8s 工程师往往是很难回答的。原因在哪里呢？实际上这跟 K8s 的定位是相关的。K8s 这个项目呢，如果去做一个分析的话，我们会发现 K8s 不是一个 PaaS 或者应用管理的平台。实际上它是一个标准化的能力接入层。什么是能力接入层呢？大家可以看一下下图。
实际上通过 Kubernetes 对用户暴露出来的是一组声明式 API，这些声明式 API 无论是 Pod 还是 Service 都是对底层基础设施的一个抽象。比如 Pod 是对一组容器的抽象，而 Deployment 是对一组 pod 的抽象。而 Service 作为 Pod 的访问入口，实际上是对集群基础设施：网络、网关、iptables 的一个抽象。Node 是对宿主机的抽象。Kubernetes 还提供了我们叫做 CRD（也就是 Custom Resource）的自定义对象。让你自己能够自定义底层基础设施的一个抽象。</description></item><item><title>流量监控与处理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%B5%81%E9%87%8F%E7%9B%91%E6%8E%A7%E4%B8%8E%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%B5%81%E9%87%8F%E7%9B%91%E6%8E%A7%E4%B8%8E%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
iftop iftop 是一个类似 top 的命令，只不过是监控系统网络中数据传输情况的，使用该命令默认打开如下的界面
界面上面显示的是类似刻度尺的刻度范围，为显示流量图形的长条作标尺用的。
中间的 &amp;lt;= 和 =&amp;gt; 这两个左右箭头，表示的是流量的方向。
TX：发送流量 RX：接收流量 TOTAL：总流量 Cumm：运行 iftop 到目前时间的总流量 peak：流量峰值 rates：分别表示过去 2s 10s 40s 的平均流量 OPTIONS：
其中有一些选项，可以用在打开 iftop 程序之后，这些选项使用 黄色背景 来表示在 iftop 程序中使用的字母
-F # 显示特定网段的进出流量，如# iftop -F 10.10.1.0/24 或# iftop -F 10.10.1.0/255.255.255.0 -i &amp;lt;DEV&amp;gt; # 指定要监测的网卡 -n # 不进行主机名的查找，e.g.显示 ip 而不显示主机名 -N # 显示端口号时，直接显示端口号，而不显示使用端口的进程名。 -P # 在展示界面显示每个连接的端口。也就是说显示当前连接的流量是哪个进程的。 EXAMPLE
iftop -P Nethogs - 网络流量监控工具 nethogs 可以根据进程来查看网络带宽利用率。nethogs 类似于网络版的 top 命令，如果有突发的网络流量增大，可以使用 nethogs 去定位是哪一个 PID 造成的。</description></item><item><title>密钥/证书的编码</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E5%AF%86%E9%92%A5_%E8%AF%81%E4%B9%A6%E7%9A%84%E7%BC%96%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E5%AF%86%E9%92%A5_%E8%AF%81%E4%B9%A6%E7%9A%84%E7%BC%96%E7%A0%81/</guid><description>概述 参考：
当我们生成密钥后，是不易于保存的，比如我在 go 代码，使用 RSA 算法生成了这么一个密钥：
私钥中包含里 公钥、n、d、组件，公钥中包含 n、e。可以发现，这种数据是不便于保存与共享的。所以，一般情况是使用一种 Encoding(编码) 规则，对密钥进行处理后以生成某种格式的文件，以便保存。当需要使用密钥时，使用对应规则的来 Decoding(解码) 该文件以获得密钥，然后再开始使用。而现阶段最常用的文件就是，就是 PEM 文件格式。
除了可以对密钥编码，还可以对证书进行编码，证书由于其复杂的格式，也不利于传输。
如果用 openssl 命令查看私钥，则是下面这种格式
root@desistdaydream:~/projects/DesistDaydream/GoLearning# openssl rsa -text -noout -in cryptography/private.pem RSA Private-Key: (2048 bit, 2 primes) modulus: 00:d0:94:1c:6e:25:54:61:1d:34:23:1f:25:f7:a5: ...... publicExponent: 65537 (0x10001) privateExponent: 00:bb:fe:52:e5:9f:f5:be:96:30:d0:db:19:40:6d: ...... prime1: 00:f3:06:5f:c4:e6:27:d2:1d:ba:d1:35:40:34:b1: ...... prime2: 00:db:b6:ee:09:28:3c:53:f5:70:e7:9a:11:8b:55: ...... exponent1: 3b:17:1e:ac:22:86:26:29:c2:65:e1:fb:c5:94:3e: ...... exponent2: 00:a4:a5:5d:95:61:20:6c:2e:36:30:68:45:13:6b: ...... coefficient: 00:e3:ed:7a:4a:2d:4c:ec:e0:0d:77:e8:4e:df:9b: ...... PEM 文件格式 参考：
Wiki, PEM Privacy-Enhanced Mail(增强隐私的邮件，简称 PEM) 是一种文件的格式(虽然曾经不止代表文件格式)。这种格式的文件用于存储 加密的密钥、证书 等数据。
PEM 起源于 1993 年 IETF 定义“隐私增强邮件”的一组标准，尽管这个标准未得到广泛采用，并已被 PGP 和 S/MIME 取代，但其中定义的各种文本编码格式却变得非常流行。所以，PEM 这种文件编码格式最终由 IETF 在 RFC7468 中正式定义。</description></item><item><title>命令行工具</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/Hugo/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，命令-hugo hugo 是 Hugo 的命令行工具。
在网站的根目录下使用 hugo 命令，可以为网站构建静态文件，并保存到 publish/ 目录中。
Sytnax(语法) hugo [COMMAND] [FLAGS]
FLAGS
-D, &amp;ndash;buildDrafts # 包含标记为 draft 的内容 hugo server Syntax(语法) hugo server [FLAGS]
FLAGS
&amp;ndash;bind STRING # 监听地址。默认值: 127.0.0.1 -p, &amp;ndash;port INT # 监听端口。默认值: 1313 -w, &amp;ndash;watch # 监听文件的改变，文件改变时重新应用，以便结果可以实时显示。默认值: true &amp;ndash;cacheDir STRING # filesystem path to cache directory。默认值: $TMPDIR/hugo_cache/</description></item><item><title>内存逃逸</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/</guid><description>概述 参考：
腾讯云，简单聊聊内存逃逸 51CTO，Go 语言中的逃逸分析作用 前置知识： Heap and Stack，必须要了解编程中，哪些情况会使用到 Stack，哪些情况会使用到 Heap。
Go 语言的内存逃逸通常都是指从变量所在的内存地址(i.e. 指针)从 Stack 变为 Heap，此时指针的值将会发生改变。下面是一个最直观的示例：
in1 := []int{1, 2, 3} in2 := []string{&amp;#34;4&amp;#34;, &amp;#34;5&amp;#34;} for i, v1 := range in1 { fmt.Printf(&amp;#34;循环 %v\n&amp;#34;, i+1) // 外层循环并不会发生逃逸现象 // fmt.Printf(&amp;#34;v1-Dec: %v\n&amp;#34;, &amp;amp;v1) for _, v2 := range in2 { println(&amp;#34;v1-Hex: &amp;#34;, &amp;amp;v1, &amp;#34;v2-Hex: &amp;#34;, &amp;amp;v2) // TODO: fmt 有逃逸问题？ https://juejin.cn/post/6955453411969990670, append 好像也有类似的内存逃逸现象 // 正常情况下，v2 的指针应该也是一样的，但是用了 fmt 之后，指针的值在外层循环的下一次迭代中产生了变化 fmt.Printf(&amp;#34;v1-Dec: %v, v2-Dec: %v\n&amp;#34;, &amp;amp;v1, &amp;amp;v2) } } 输出结果：</description></item><item><title>排序</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E6%8E%92%E5%BA%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E6%8E%92%E5%BA%8F/</guid><description>概述 参考：
各种排序方法演示： https://www.bilibili.com/video/BV1Tk4y1v7SJ Selection Sort(选择排序)
Insertion Sort(插入排序)
Quick Sort(LR prts)(快速排序)
Merge Sort(归并排序)
Heap Sort(堆排序)
Radlx Sort(MSD 基数排序)
std::sort()
std::stable_sort()
Shell Sort(希尔排序)
Bubble Sort(冒泡排序)
Gnome Sort()
Bitnoic Sort
Bogo Sort</description></item><item><title>配置文件管理</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
golang 常用库：配置文件解析库/管理工具-viper 使用 Viper golang 常用库：gorilla/mux-http 路由库使用 golang 常用库：配置文件解析库/管理工具-viper 使用 golang 常用库：操作数据库的 orm 框架-gorm 基本使用 golang 常用库：字段参数验证库-validator 使用 一、viper 简介 viper 配置管理解析库，是由大神 Steve Francia 开发，他在 google 领导着 golang 的产品开发，他也是 gohugo.io 的创始人之一，命令行解析库 cobra 开发者。总之，他在 golang 领域是专家，很牛的一个人。
他的 github 地址：https://github.com/spf13
viper 是一个配置管理的解决方案，它能够从 json，toml，ini，yaml，hcl，env 等多种格式文件中，读取配置内容，它还能从一些远程配置中心读取配置文件，如 consul，etcd 等；它还能够监听文件的内容变化。
二、viper 功能介绍 读取 json，toml，ini，yaml，hcl，env 等格式的文件内容 读取远程配置文件，如 consul，etcd 等和监控配置文件变化 读取命令行 flag 的值 从 buffer 中读取值 配置文件又可以分为不同的环境，比如 dev，test，prod 等。
viper 可以帮助你专注配置文件管理。
viper 读取配置文件的优先顺序，从高到低，如下：
显式设置的 Set 函数 命令行参数 环境变量 配置文件 远程 k-v 存储系统，如 consul，etcd 等 默认值 Viper 配置 key 是不区分大小写的。</description></item><item><title>七层代理配置</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/%E4%B8%83%E5%B1%82%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/%E4%B8%83%E5%B1%82%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
公众号，Nginx 代理 WebSocket 方法 这个配置里的 172.19.42.217 是 kubernetes 集群的入口，一般在 80 和 443 上都起一个 ingress controler，这样，多种域名都代理到同一个 kubernetes 集群，然后由 ingress 再将流量进行路由分配。
user nginx; worker_processes 4; error_log /dev/stdout warn; pid /var/run/nginx.pid; events { worker_connections 102400; } http { default_type application/octet-stream; access_log /dev/stdout main; keepalive_timeout 120; log_format main &amp;#39;$remote_addr - $remote_user [$time_local] &amp;#34;$request&amp;#34; &amp;#39; &amp;#39;$status $body_bytes_sent &amp;#34;$http_referer&amp;#34; &amp;#39; &amp;#39;&amp;#34;$http_user_agent&amp;#34; &amp;#34;$http_x_forwarded_for&amp;#34;&amp;#39; &amp;#39;$upstream_addr &amp;#39; &amp;#39;ups_resp_time: $upstream_response_time &amp;#39; &amp;#39;request_time: $request_time&amp;#39;; sendfile on; server_names_hash_bucket_size 256; server { listen 80; server_name grafana.</description></item><item><title>其他</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E5%85%B6%E4%BB%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Windows-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E5%85%B6%E4%BB%96/</guid><description>概述 MSConfig Microsoft System Configuration(系统配置，简称 msconfig) 程序可以配置 Windows 的引导方式和启动方式、管理服务、自启动程序、打开一些实用的工具。
自 Windows 10 版本 21H1 以及 Windows Server 21H1 半年频道版本起，WMIC 实用程序已弃用。该实用程序已被 Windows PowerShell for WMI 取代（请参阅第 7 章 — 使用 WMI）。此弃用仅适用于 WMI 命令行 (WMIC) 实用程序； Windows Management Instrumentation (WMI) 本身不受影响。另请参阅我们不再开发的 Windows 10 功能。
链接文件管理 mklink 参考：
官方文档 可以使用 PowerShell 内置管理工具中的 Management 模块下的 New-Item -ItemType SymbolicLink 命令代替 mklink 命令
Syntax(语法) mklink [[/d] | [/h] | [/j]] &amp;lt;link&amp;gt; &amp;lt;target&amp;gt;
为 target 创建一个名为 link 的链接文件。即 link 是要创建的新文件</description></item><item><title>其他</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/%E5%85%B6%E4%BB%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/%E5%85%B6%E4%BB%96/</guid><description>概述 参考：
Telnet 参考：
RFC 854 - TELNET PROTOCOL SPECIFICATION RFC 855 - TELNET OPTION SPECIFICATIONS RFC 857 - TELNET ECHO OPTION RFC 858 - TELNET SUPPRESS GO AHEAD OPTION RFC 1091 - Telnet Terminal-Type Option RFC 1143 - The Q Method of Implementing TELNET Option Negotiation Wiki, Telnet Python Telnet 库
https://docs.python.org/3/library/telnetlib.html 已弃用，将在 3.13 删除
Go Telnet 库
https://github.com/ebarkie/telnet 可以实现 Telnet 服务端
https://github.com/reiver/go-telnet
https://blog.csdn.net/wangkai_123456/article/details/70167943
Telnet 仅仅是基于 TCP 的类似 Echo 逻辑，建立 TCP 连接后，Telnet 服务端需要与客户端协商一些内容，</description></item><item><title>启动项</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E5%90%AF%E5%8A%A8%E9%A1%B9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E5%90%AF%E5%8A%A8%E9%A1%B9/</guid><description>概述 我们可以通过多种方式，让 Windows 启动后自动执行一些命令
Windows 服务 任务计划程序 使用自启动目录 TODO: 待总结 任务管理器中的启动应用 参考：
任务管理器启动项中出现 Program 解决办法 任务管理器中的启动应用信息保存在 注册表 的如下几个位置
HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\Run HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Run Autoruns 程序 参考：
官网 Autoruns 是微软官方推出的自启动程序管理器。
只需运行 Autoruns，它就会向您显示当前配置的自动启动应用程序以及可用于自动启动配置的注册表和文件系统位置的完整列表。 Autoruns 显示的自动启动位置包括登录条目、Explorer 加载项、Internet Explorer 加载项（包括浏览器帮助程序对象 (BHO)、Appinit DLL、映像劫持、启动执行映像、Winlogon 通知 DLL、Windows 服务和 Winsock 分层服务提供程序、媒体）编解码器等等。切换选项卡以查看不同类别的自动启动。
最佳实践 开机后运行 Powershell 脚本 编写 Powershell 脚本，X.ps1，并将 X.ps1 的快捷方式放到 `%appdata%\Microsoft\Windows\Start Menu\Programs\Startup\ 目录下
设置 .ps1 后缀的默认应用为 Powershell(比如 pwsh、powershell 等)</description></item><item><title>弃用</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/%E5%BC%83%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Storage%E5%AD%98%E5%82%A8/%E5%BC%83%E7%94%A8/</guid><description>概述 参考：
BoltDB-Shipper 运行细节 Ingester 组件用于将 Index 与 Chunks 数据写入存储；Querier 组件用于从存储中读取 Index 和 Chunks 以处理 LogQL 查询请求。
写入数据 在深入了解细节之前，需要知道 Ingester 如何管理存储中的 Index 数据。
读取数据 Queriers lazily loads BoltDB files from shared object store to configured cache_location. When a querier receives a read request, the query range from the request is resolved to period numbers and all the files for those period numbers are downloaded to cache_location, if not already. Once we have downloaded files for a period we keep looking for updates in shared object store and download them every 5 Minutes by default.</description></item><item><title>前端管理</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%89%8D%E7%AB%AF%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%89%8D%E7%AB%AF%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
Go 语言也可以处理前端页面，比如使用 DOM、等等。
暂时没发现可以使用 BOM 的方式，毕竟没法在浏览器内嵌入 Go 代码，但是却可以在本地处理 HTML 页面(使用 DOM)。
goquery 参考：
GitHub 项目，PuerkitoBio/goquery goquery 为 Go 语言带来了类似于 jQuery 的语法和一组特性。它基于 Go 的 net/html 包和 CSS 选择器库 cascadia。由于 net/html 解析器返回节点，而不是功能齐全的 DOM 树，jQuery 的状态操作函数（如 height()、css()、detach()）已被取消。
说白了，这是一个操作 DOM 树的库。</description></item><item><title>青龙</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Job/%E9%9D%92%E9%BE%99/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Job/%E9%9D%92%E9%BE%99/</guid><description>概述 参考：
GitHub 项目，whyour/qinglong CSDN-青龙-白虎 一个支持 Python、JavaScript、Shell、TypeScript 代码编写的 Job 管理平台。
青龙没有文档吗？青龙的 API 在哪？这玩意咋什么文档都没有。。。。。o(╯□╰)o。。。。只能直接看 API 的源码吗？这里有人整了个 OpenAPI 格式的
青龙部署 https://github.com/zhangguanzhang/docker-compose/tree/master/qinglong
version: &amp;#34;3&amp;#34; services: qinglong: image: whyour/qinglong:latest container_name: qinglong restart: unless-stopped tty: true ports: - 5700:5700 - 5701:5701 environment: - ENABLE_HANGUP=true - ENABLE_WEB_PANEL=true volumes: - ./qinglong/config:/ql/config - ./qinglong/log:/ql/log - ./qinglong/db:/ql/db - ./qinglong/repo:/ql/repo - ./qinglong/raw:/ql/raw - ./qinglong/scripts:/ql/scripts - ./qinglong/jbot:/ql/jbot - ./qinglong/ninja:/ql/ninja docker-compose up -d docker exec -it qinglong bash apk add ca-certificates cd /ql (可选) pnpm config set registry https://registry.</description></item><item><title>任务计划程序与服务</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Microsoft-Management-Console/%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E7%A8%8B%E5%BA%8F%E4%B8%8E%E6%9C%8D%E5%8A%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/Microsoft-Management-Console/%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E7%A8%8B%E5%BA%8F%E4%B8%8E%E6%9C%8D%E5%8A%A1/</guid><description>概述 参考：</description></item><item><title>容器非root启动</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E9%9D%9Eroot%E5%90%AF%E5%8A%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E9%9D%9Eroot%E5%90%AF%E5%8A%A8/</guid><description>概述 参考：
官方文档，Rootless 模式 容器非 root 启动改造的经验 参考：
zhangguanzhang，容器非 root 启动改造的经验 最近业务容器的非 root 启动改造实战案例经验，后续有新的也更新进来
改造 前提须知 这里列举些基础知识
使用 root 不安全的举例 虽然 linux 有 user namespace 隔离技术，但是 docker 不支持类似 podman 那样的给每个容器设置范围性的 uidmap 映射（当然 k8s 现在也不支持），并且容器默认配置下的权限虽然去掉了一些。但是容器内还是能对挂载进去的进行修改的，比如帖子 rm -rf * 前一定一定要看清当前目录 老哥的操作：
docker run --rm -v /mnt/sda1:/mnt/sda1 -it alpine cp /mnt/sda1/somefile.tar.gz . tar xzvf somefile.tar.gz cd somefile-v1.0 ls # 看了看内容觉得不是自己想要的，回上一级目录准备删掉： cd .. rm -rf * 嗯，alpine 默认的 workdir 是 / ，所以删除 rm -rf /*。当然还有其他不安全的，所以在业务角度上，我们需要给容器内进程设置在非 root 下最小的运行权限。</description></item><item><title>容器中使用 GPU</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E4%B8%AD%E4%BD%BF%E7%94%A8-GPU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E4%B8%AD%E4%BD%BF%E7%94%A8-GPU/</guid><description>概述 参考：
Nvidia 参考：
Nvidia 官方文档，容器工具包 - 安装指南 安装 Container Toolkit(容器工具包，简称 ctk)
Notes: 若不安装 ctk，启动容器指定 GPU 时将会报错: docker: Error response from daemon: could not select device driver &amp;quot;&amp;quot; with capabilities: [[gpu]]. 3
Ubuntu
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \ &amp;amp;&amp;amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \ sed &amp;#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&amp;#39; | \ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list apt update apt install -y nvidia-container-toolkit 最佳实践 Docker 19.03，增加了对&amp;ndash;gpus 选项的支持，我们在 docker 里面想读取 nvidia 显卡再也不需要额外的安装 nvidia-docker 了，下面开始实战 安装 nvidia-container-runtime： 查看官网（https://nvidia.</description></item><item><title>如何构建以应用为中心的Kubernetes</title><link>https://desistdaydream.github.io/blog/copy/%E4%BA%91%E5%8E%9F%E7%94%9F/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E4%BB%A5%E5%BA%94%E7%94%A8%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84Kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E4%BA%91%E5%8E%9F%E7%94%9F/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E4%BB%A5%E5%BA%94%E7%94%A8%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84Kubernetes/</guid><description>原文链接
本文整理自 2020 年 7 月 22 日《基于 Kubernetes 与 OAM 构建统一、标准化的应用管理平台》主题线上网络研讨会。
关注公众号，回复“0722”即可下载 PPT
文章共分为上下两篇。上篇文章《灵魂拷问，上 Kubernetes 有什么业务价值？》，主要和大家介绍了上 Kubernetes 有什么业务价值，以及什么是“以应用为中心”的 Kubernetes。本文为下篇，将跟大家具体分享如何构建“以应用为中心”的 Kubernetes。
如何构建“以应用为中心”的 Kubernetes？
构建这么一个以用户为中心的 Kubernetes，需要做几个层级的事情。
1. 应用层驱动 首先来看最核心的部分，上图中蓝色部分，也就是 Kubernetes。可以在 Kubernetes 之上定义一组 CRD 和 Controller。可以在 CRD 来做用户这一侧的 API，比如说 pipeline 就是一个 API，应用也是一个 API。像运维侧的扩容策略这些都是可以通过 CRD 的方式安装起来。
2. 应用层抽象 所以我们的需要解决第一个问题是应用抽象。如果在 Kubernetes 去做应用层抽象，就等同于定义 CRD 和 Controller，所以 Controller 可以叫做应用层的抽象。本身可以是社区里的，比如 Tekton，istio 这些，可以作为你的应用驱动层。这是第一个问题，解决的是抽象的问题。不是特别难。
3. 插件能力管理 很多功能不是 K8s 提供的，内置的 Controller 还是有限的，大部分能力来自于社区或者是自己开发的 Controller。这时我的集群里面就会安装好多好多插件。如果要构建以应用为中心的 Kubernetes，那我必须能够管理起来这些能力，否则整个集群就会脱管了。用户想要这么一个能力，我需要告诉他有或者是没有。需要暴露出一个 API 来告诉他，集群是否有他需要的能力。假设需要 istio 的流量切分，需要有个接口告诉用户这个能力存不存在。不能指望用户去 get 一下 crd 合不合适，检查 Controller 是否运行。这不叫以应用为中心的 K8s，这叫裸 K8s。</description></item><item><title>设计模式</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid><description>概述 参考：
Wiki, Design pattern 菜鸟教程，设计模式 mohuishou，Go 设计模式24-总结 掘金，设计模式 Design pattern(设计模式) 代表了最佳的实践。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。
1995 年，艾瑞克·伽马（ErichGamma）、理査德·海尔姆（Richard Helm）、拉尔夫·约翰森（Ralph Johnson）、约翰·威利斯迪斯（John Vlissides）等 4 位作者合作出版了《设计模式：可复用面向对象软件的基础》（Design Patterns: Elements of Reusable Object-Oriented Software）一书，这是设计模式领域里程碑的事件，导致了软件设计模式的突破。这 4 位作者在软件开发领域里也以他们的“四人组”（Gang of Four，GoF）匿名著称。
有关软件设计模式的定义很多，有些从模式的特点来说明，有些从模式的作用来说明。本教程给出的定义是大多数学者公认的，从以下两个方面来说明。
1. 软件设计模式的概念 软件设计模式（Software Design Pattern），又称设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。它描述了在软件设计过程中的一些不断重复发生的问题，以及该问题的解决方案。也就是说，它是解决特定问题的一系列套路，是前辈们的代码设计经验的总结，具有一定的普遍性，可以反复使用。其目的是为了提高代码的可重用性、代码的可读性和代码的可靠性。
2. 学习设计模式的意义 设计模式的本质是面向对象设计原则的实际运用，是对类的封装性、继承性和多态性以及类的关联关系和组合关系的充分理解。正确使用设计模式具有以下优点：
可以提高程序员的思维能力、编程能力和设计能力。 使程序设计更加标准化、代码编制更加工程化，使软件开发效率大大提高，从而缩短软件的开发周期。 使设计的代码可重用性高、可读性强、可靠性高、灵活性好、可维护性强。 当然，软件设计模式只是一个引导。在具体的软件开发中，必须根据设计的应用系统的特点和要求来恰当选择。对于简单的程序开发，可能写一个简单的算法要比引入某种设计模式更加容易。但对大项目的开发或者框架设计，用设计模式来组织代码显然更好。
装饰模式 Decorator(装饰器)
策略模式 用来解决过多 if else 逻辑的模式
// 假如现在有如下条件 if FirstCondition { // 条件一 } else if SecondCondition { // 条件二 } 策略指：当满足 XX 条件，执行 YY 行为。
也就是说，可以将上面的 if else 中的 Condition(条件) 转为 Strategy(策略，i.</description></item><item><title>深度学习</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid><description>概述 参考：
Wiki, Deep_learning Deep learning(深度学习) 是机器学习方法家族的一部分，它基于具有表示学习的人工神经网络。学习可以是监督的、半监督的或无监督的。
深度神经网络、深度信念网络、深度强化学习、递归神经网络、卷积神经网络和 Transformer 等深度学习架构已应用于计算机视觉、语音识别、自然语言处理、机器翻译、生物信息学、药物设计等领域、医学图像分析、气候科学、材料检验和棋盘游戏程序，它们在这些方面产生的结果可与人类专家的表现相媲美，在某些情况下甚至超过人类专家的表现
深度学习框架 TensorFlow # 基于 NumPy 构建，谷歌开发
PyTorch # 基于 Torch 构建，Facebook 开发
Paddle，百度飞桨
DeepSpeed 参考：
GitHub 项目，microsoft/DeepSpeed DeepSpeed Chat 一键式RLHF训练，让你的类 ChatGPT 千亿大模型提速省钱15倍</description></item><item><title>视频的编码与解码</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E8%A7%86%E9%A2%91%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E8%A7%86%E9%A2%91%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</guid><description>概述 参考：
Wiki, Advanced Video Coding Wiki, High Efficiency Video Coding Wiki, AV1 视频编码其实就是 图像编码 与 音频编码 的结合体。
毕竟视频就是一幅幅图像叠加在一起而已，只不过在每时每刻又要附加上声音。
编码技术
AVC 也称 H.264、MPEG-4 part10 HEVC 也称 H.265、MPEG-H part 2 AV1 视频 编码 与 压缩 B 站，差评君-这么多视频编码，为什么不能统一成一种呢？
可能有小伙伴不太清楚编码器是干嘛的，差评君先花点时间给大家解释下： （ 很快的啊，不用担心内容劝退。。懂的小伙伴可以直接往下划 ）
我们平常在爱奇艺、 B 站看的视频，它们原本的体量十分巨大。
有多大呢，我们就拿 1080p 分辨率的视频举例吧，一秒钟视频流大概有 149 MB 那么大（ 1920 x 1080 x 8bit x 三个 RGB 通道 x 24 帧 / 8 ）。
相当于说我们的网速至少需要达到 149 MB/s，才能够保证看 1080p 视频不卡。
提醒一下，149 MB/s 约合 1194 Mbps，比千兆宽带（ 1000 Mbps ）还快一点。</description></item><item><title>数据库对比</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94/</guid><description>概述 参考：
GreptimeDB vs. ClickHouse vs. ElasticSearch 日志引擎性能对比报告 原文: https://mp.weixin.qq.com/s/eITHYdw8Qoa0xYozqJZuOw
GreptimeDB 在 v0.9 版本引入了日志存储和检索功能，使得用户可以使用同样数据模型和查询语言（SQL）来统一处理指标、日志（和事件）。
本报告将初步给出 v0.9 首次引入的日志存储和检索的单机性能，包括写入和查询性能、资源占用和压缩率等。在可观测性领域中，常用的日志系统包括经典的 ELK 组合（ElasticSearch）以及在国内广泛使用的 ClickHouse。我们选择这两个系统进行横向对比，以供参考。GreptimeDB 面向云原生环境设计，因此我们也测试了基于 S3 对象存储的读写性能。
测试场景 测试数据和流程 我们选用 nginx access log 作为写入数据，一行数据的样例如下：
129.37.245.88 - meln1ks [01/Aug/2024:14:22:47 +0800] &amp;#34;PATCH /observability/metrics/production HTTP/1.0&amp;#34; 501 33085 我们使用 vector[1] 这个开源可观测数据 pipeline 来生成并写入上面的数据。整体测试的流程如图：
数据写入后，我们分别使用 SQL（GreptimeDB 和 ClickHouse）和 ElasticSearch HTTP 协议进行查询测试。
写入方式 写入方式我们也做了区分：
切分模式：将每行日志，切分出多个字段，比如上面这行日志，可以切分出 http_version、ip、method、path、status 等字段。我们同样使用 vector 进行日志的解析和切分； 全文模式：将该条日志，除了时间戳以外，完整存储为一个 message 的文本字段，并启用全文索引。 我们也将比较两种模式带来的差异。
软硬件说明 硬件环境 机器规格 操作系统 aws c5d.2xlarge, 8 CPU 16 Gib memory ubuntu 24.</description></item><item><title>数据类型</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>概述 参考：
Numbers(数字型) # 格式化标识符 %d
Integers(整数型) # 简写为 int Floating Point Numbers(浮点数型) complex 复数共两种复数，complex64 和 complex128，分别对应 float32 和 float64 两种浮点数精度。内置的 complex 函数用于构建复数，内建的 real 和 imag 函数分别返回复数的实部和虚部 Strings(字符型) # 格式化标识符 %s
Booleans(布尔型)
注意：很多时候，Booleans 类型的值可以用数字表示
1 表示 true(真) 0 表示 false(假) Associative Arrays(关联数组) # 就是 抽象数据类型 中描述的，很多时候称为 map(映射)、dictionary(字典)、etc.</description></item><item><title>数据应用</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/</guid><description>概述 参考：
艺恩
官网: https://www.endata.com.cn/index.html 艺恩娱数（数据展示大盘）: https://ys.endata.cn/DataMarket/Index 票房、艺人 七麦数据
官网: https://www.qimai.cn/ 榜单: https://www.qimai.cn/rank</description></item><item><title>数组</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%95%B0%E7%BB%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%95%B0%E7%BB%84/</guid><description>概述 参考：
Array(数组) 也是一种变量，数组中可以存放多个值，每个值都称为该数组的元素。Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小（与 PHP 类似）。
与大部分编程语言类似，数组元素的下标由 0 开始。
Shell 数组用 () 小括号来表示，元素用空白符分割
定义数组的方式：ArrayName=(Value1 ... ValueN)
数组的赋值 #!/bin/bash my_array=(A B &amp;#34;C&amp;#34; D) # 我们也可以使用下标来定义数组: array_name[0]=value0 array_name[1]=value1 array_name[2]=value2 数组的引用 通过数组的下标来获取数组的值，数组中的第一位下标是 0，第二位下标是 2&amp;hellip;&amp;hellip;以此类推
引用数组元素值的一般格式是：${array_name[index]} # index 是下标的数字
实例
#!/bin/bash my_array=(A B &amp;#34;C&amp;#34; D) echo &amp;#34;第一个元素为: ${my_array[0]}&amp;#34; echo &amp;#34;第二个元素为: ${my_array[1]}&amp;#34; echo &amp;#34;第三个元素为: ${my_array[2]}&amp;#34; echo &amp;#34;第四个元素为: ${my_array[3]}&amp;#34; 执行脚本，输出结果如下所示： $ chmod +x test.sh $ ./test.sh 第一个元素为: A 第二个元素为: B 第三个元素为: C 第四个元素为: D 引用数组中指定的元素 参考 变量与系统环境配置详解 中变量的高级技巧一节，可以通过 ${ } 来截取数组中的元素</description></item><item><title>四层代理配置</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</guid><description>概述 参考：
4 层代理配置 user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; include /usr/share/nginx/modules/*.conf; events { worker_connections 10240; } stream { include stream.d/*.conf; upstream grafana { server 172.38.40.216:30000; server 172.38.40.217:30000; } upstream prometheus { server 172.38.40.216:30001 weight=8 max_fails=2 fail_timeout=30s; server 172.38.40.217:30001 weight=8 max_fails=2 fail_timeout=30s; } server { listen 30000; proxy_pass grafana; proxy_connect_timeout 10s; } server { listen 30001; proxy_pass prometheus; proxy_connect_timeout 2s; } } http { }</description></item><item><title>锁</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E9%94%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E9%94%81/</guid><description>概述 参考：
公众号-小林coding，面试官：你说说互斥锁、自旋锁、读写锁、悲观锁、乐观锁的应用场景 互斥锁、自旋锁、读写锁、悲观锁、乐观锁的应用场景 前言 生活中用到的锁，用途都比较简单粗暴，上锁基本是为了防止外人进来、电动车被偷等等。
但生活中也不是没有 BUG 的，比如加锁的电动车在「广西 - 窃·格瓦拉」面前，锁就是形同虚设，只要他愿意，他就可以轻轻松松地把你电动车给「顺走」，不然打工怎么会是他这辈子不可能的事情呢？牛逼之人，必有牛逼之处。
那在编程世界里，「锁」更是五花八门，多种多样，每种锁的加锁开销以及应用场景也可能会不同。
如何用好锁，也是程序员的基本素养之一了。
高并发的场景下，如果选对了合适的锁，则会大大提高系统的性能，否则性能会降低。
所以，知道各种锁的开销，以及应用场景是很有必要的。
接下来，就谈一谈常见的这几种锁：
正文 多线程访问共享资源的时候，避免不了资源竞争而导致数据错乱的问题，所以我们通常为了解决这一问题，都会在访问共享资源之前加锁。
最常用的就是互斥锁，当然还有很多种不同的锁，比如自旋锁、读写锁、乐观锁等，不同种类的锁自然适用于不同的场景。
如果选择了错误的锁，那么在一些高并发的场景下，可能会降低系统的性能，这样用户体验就会非常差了。
所以，为了选择合适的锁，我们不仅需要清楚知道加锁的成本开销有多大，还需要分析业务场景中访问的共享资源的方式，再来还要考虑并发访问共享资源时的冲突概率。
对症下药，才能减少锁对高并发性能的影响。
那接下来，针对不同的应用场景，谈一谈「互斥锁、自旋锁、读写锁、乐观锁、悲观锁」的选择和使用。
互斥锁与自旋锁：谁更轻松自如？ 最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。
加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。
当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：
互斥锁加锁失败后，线程会释放 CPU ，给其他线程； 自旋锁加锁失败后，线程会忙等待，直到它拿到锁； 互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。
对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图：
所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。
那这个开销成本是什么呢？会有两次线程上下文切换的成本：
当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行； 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。 线程的上下文切换的是什么？当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。
上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。
所以，如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。
自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。
一般加锁的过程，包含两个步骤：
第一步，查看锁的状态，如果锁是空闲的，则执行第二步； 第二步，将锁设置为当前线程持有； CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。</description></item><item><title>特殊符号</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7/</guid><description>概述 参考：
Bash 中特殊符号的说明 这些特殊符号的作用，一般是在对 Linux 和 shell 有一定了解的基础上，才能明白其作用。
' ' 和 &amp;quot; &amp;quot;(单引号 和 双引号) 首先，单引号和双引号，都是为了解决中间有空格的问题。
因为空格在 Shell 中时作为一个很典型的分隔符，比如 string1=this is astring，这样执行就会报错。为了避免这个问题，因此就产生了单引号和双引号。
单引号引用的内容，所见即所得。即将单引号内的内容原样输出，或者描述为单引号里面看到的是什么就会输出什么。单引号是全引用，被单引号括起的内容不管是常量还是变量都不会发生替换。
~]# var=dablelv ~]# echo &amp;#39;$var&amp;#39; $var 双引号引用的内容，所见非所得。如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容。双引号是部分引用，被双引号括起的内容常量还是常量，变量则会发生替换，替换成变量内容。
~]# var=dablelv ~]# echo &amp;#34;$var&amp;#34; dablelv 无引号不使用引号定义字符串时，字符串不能包含空白字符（如 Space 或 Tab），需要该加引号，一般连续的字符串，数字，路径等可以不加引号。如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容。
~]# str3=test String -bash: String: 未找到命令 ~]# echo $str3 ~]# 可见，字符串中包含有空格时不实用引号括起来，将无法正常输出。
$() 和 `` 用于命令替换 在 bash shell 中，$( ) 与`` (反引号) 都是用来做命令替换用(command substitution)的。
例如：version=$(uname -r) 和 version=uname -r 都可以使 version 得到内核的版本号</description></item><item><title>提供程序</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/PowerShell/%E6%8F%90%E4%BE%9B%E7%A8%8B%E5%BA%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/WindowsShell/PowerShell/%E6%8F%90%E4%BE%9B%E7%A8%8B%E5%BA%8F/</guid><description>概述 参考：
官方文档，关于 - 关于 Providers PowerShell Providers(提供程序) 是 .NET 程序
内置提供程序 PowerShell 包含一组内置提供程序，可提供对不同类型对象的访问。
Alias provider Drive - Alias: Object types - System.Management.Automation.AliasInfo Certificate provider Drive - Cert: Object types - Microsoft.PowerShell.Commands.X509StoreLocation, System.Security.Cryptography.X509Certificates.X509Certificate2 Environment provider Drive - Env: Object types - System.Collections.DictionaryEntry FileSystem provider Drive - C: and other depending on hardware Object types - System.IO.FileInfo, System.IO.DirectoryInfo Function provider Drive - Function: Object types - System.Management.Automation.FunctionInfo Registry provider Drive - HKLM:, HKCU: Object types - Microsoft.</description></item><item><title>提问的艺术</title><link>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/%E6%8F%90%E9%97%AE%E7%9A%84%E8%89%BA%E6%9C%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/%E5%AD%A6%E4%B9%A0/%E6%8F%90%E9%97%AE%E7%9A%84%E8%89%BA%E6%9C%AF/</guid><description>概述 参考：
https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way https://github.com/alist-org/alist/discussions/227 提问的智慧 How To Ask Questions The Smart Way
Copyright © 2001,2006,2014 Eric S. Raymond, Rick Moen
本指南英文版版权为 Eric S. Raymond, Rick Moen 所有。
原文网址：http://www.catb.org/~esr/faqs/smart-questions.html
Copyleft 2001 by D.H.Grand(nOBODY/Ginux), 2010 by Gasolin, 2015 by Ryan Wu
本中文指南是基于原文 3.10 版以及 2010 年由 Gasolin 所翻译版本的最新翻译；
协助指出翻译问题，请发 issue，或直接发 pull request 给我。
本文另有繁體中文版。
原文版本历史 声明 许多项目在他们网站的帮助文档中链接了本指南。这很好，这正是我们想要的用途。但如果你是该项目管理员并试图创建指向本指南的超链接，请在超链接附近的显著位置注明：
本指南不提供此项目的实际支持服务！
我们已经深刻领教到缺少上述声明所带来的痛苦：我们将不停地被那些认为发布这本指南就意味着有责任解决世上所有技术问题的傻瓜苦苦纠缠。
如果你因寻求某些帮助而阅读本指南，并在离开时还觉得可以从本文作者这里得到直接帮助，那你就是我们之前说的那些傻瓜之一。别问我们问题，我们只会忽略你。我们在这本指南中想教你如何从那些真正懂得你所遇到的软件或硬件问题的人处取得协助，而 99% 的情况下那不会是我们。除非你确定本指南的作者之一刚好是你所遇到的问题领域的专家，否则请不要打扰我们，这样大家都会开心一点。
简介 在黑客的世界里，你所提技术问题的解答的好坏, 很大程度上取决于你提问的方式与此问题的难度。本指南将教你如何正确地提问以获得你满意的答案。
现在开源（Open Source）软件已经相当盛行，您通常可以从其他更有经验的用户那里获得与黑客一样好的答案，这是件好事；和黑客相比，用户们往往对那些新手常遇到的问题更宽容一些。尽管如此，以我们在此推荐的方式对待这些有经验的用户通常也是从他们那里获得有用答案的最有效方式。
首先你应该明白，黑客们喜爱有挑战性的问题，或者能激发他们思维的好问题。如果我们并非如此，那我们也不会成为你想询问的对象。如果你给了我们一个值得反复咀嚼玩味的好问题，我们自会对你感激不尽。好问题是激励，是厚礼。好问题可以提高我们的理解力，而且通常会暴露我们以前从没意识到或者思考过的问题。对黑客而言，“好问题！”是诚挚的大力称赞。
尽管如此，黑客们有着蔑视或傲慢面对简单问题的坏名声，这有时让我们看起来对新手、无知者似乎较有敌意，但其实不是那样的。
我们不讳言我们对那些不愿思考、或者在发问前不做他们该做的事的人的蔑视。那些人是时间杀手 —— 他们只想索取，从不付出，消耗我们可用在更有趣的问题或更值得回答的人身上的时间。我们称这样的人为 失败者（loser） （由于历史原因，我们有时把它拼作 lusers）。</description></item><item><title>同源同宿</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E5%90%8C%E6%BA%90%E5%90%8C%E5%AE%BF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E5%90%8C%E6%BA%90%E5%90%8C%E5%AE%BF/</guid><description>概述 参考：
同源同宿，找不到对应的英文。与 Load balancing 中的 Session persistence(会话保持) 的技术类似。</description></item><item><title>图像处理模块</title><link>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/OpenCV/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
官方文档，模块 - 图像处理 图像处理模块下还有很多分类
Image Filtering(图像过滤) Geometric Image Transformations(几何图像变换) Miscellaneous Image Transformations(各种图像转换) Drawing Functions(绘图功能) Color Space Conversions(色彩空间转换) ColorMaps in OpenCV(OpenCV 中的颜色图) Planar Subdivision(平面细分) Histograms(直方图) Structural Analysis and Shape Descriptors(结构分析和形状描述符) Motion Analysis and Object Tracking(运动分析和对象跟踪) Feature Detection(特征检测) Object Detection(物体检测) Image Segmentation(图像分割) C API Hardware Acceleration Layer(硬件加速层) Object Detection(对象检测) 参考：
官方文档，主模块 - 对象监测 官方文档，模块 - 图像处理 - 对象检测 官方文档，教程 - 图像处理 - 模板匹配 OpenCV 实现 Object detection(对象检测) 的能力，是通过模板匹配技术查找与模板图像（补丁）匹配（相似）的图像区域。
Source image(源图像) (I) # 我们期望在其中找到与模板图像匹配的图像。一般就是大图、或者说背景图。 Template image(模板图像)（T） # 将与源图像进行比较的补丁图像。一般是较小的图片。 我们的目标是在源图像中检测到与模板图像的最佳匹配区域。比如这样：</description></item><item><title>图像的编码与解码</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%9B%BE%E5%83%8F%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%9B%BE%E5%83%8F%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</guid><description>概述 参考：
Wiki-Pixel(像素) Wiki-Image resolution(分辨率) Wiki-Raster graphics(光栅图像) 图像的编码 和 字符的编码 其实本质上都是使用二进制来进行 编/解码。
图像 想要了解图像的编码/解码，首先要明确一下图片的组成
这个图，如果放到编辑器中，然后无限放大，会看到这种效果：
从这里可以看到，一张图片，其实就是很多很多的小方块组成的，每个小方块，都称之为 Pixel(像素)。
Piexl(像素) Picture Element(图像元素，简称 Pel)，也就是常常听说的 Piexl(像素)。在数字成像中，像素是光栅图像中最小的可寻址元素，或者是全点可寻址 显示设备中的最小可寻址元素；因此，它是屏幕上所显示图片的最小可控元素。
每个像素都是原始图像的样本；通常，更多的样本会提供对原件的更准确的表示。每个像素的强度是可变的。在彩色成像系统中，颜色通常由三个或四个分量强度来表示，例如红色，绿色和蓝色，或青色，品红色，黄色和黑色。
在一些语境中(如描述相机传感器)，_像素 指的是多组分表示的单个标量元素（称为_感光点_在相机传感器上下文中，虽然传感器个体_有时使用），[3]而在其它上下文中它可以指的是空间位置的一组分量强度。
一般情况下，电脑中的颜色都是使用三原色混合而成，比如：
可以看到，每个颜色都有一个数字表示，而 RGB 就是三原色，不用强度的三原色，就会组成不同强度的新颜色。
Image Resolution(图像分辨率) Image Resolution(图像分辨率) 指图像可以存在的细节，分辨率仅适用于 光栅图像。一般是指单位英寸中所包含的像素个数。 用白话说，分辨率就是判断一张图片清晰度的重要标志，而上文提到的 像素，就是分辨率的一部分。通常，分辨率可以通过如下几种方式来判断
像素数 空间分辨率 光谱分辨率 时间分辨率 辐射分辨率 大部分时候，其实主要就是以像素的数量来决定一张图像的分辨率，比如：
而 像素密度 与 像素总数，又是判断分辨率所具有像素数的两个重要指标
像素密度 # 单位长度内的像素数量除以单位长度，单位为 PPI（Pixels Per Inch）。像素密度越高，说明像素越密集，5PPI 表示每英寸有 5 个像素，500PPI 表示每英寸有 500 个像素，PPI 的数值高，图片和视频的清晰度就更高。 像素总数 # 图片、影像的单独一帧图所含像素的数量，单位为像素，计算方式为长边的像素个数乘以短边的像素个数。 宽度为 2048 像素，高度为 1536 像素的图像总计 2048×1536 = 3,145,728 像素或 3.</description></item><item><title>网络丢包问题处理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E4%B8%A2%E5%8C%85%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E4%B8%A2%E5%8C%85%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</guid><description>概述 参考：
公众号-马哥Linux运维，如何高效定位网络丢包问题？ 引言
本期分享一个比较常见的网络问题&amp;ndash;丢包。例如我们去ping一个网站，如果能ping通，且网站返回信息全面，则说明与网站服务器的通信是畅通的，如果ping不通，或者网站返回的信息不全等，则很可能是数据被丢包了，类似情况想必大家都不陌生。针对网络丢包，本人提供一些常见的丢包故障定位方法，希望能够帮助大家对网络丢包有更多的认识，遇到丢包莫要慌，且跟着一起来涨姿(知)势(识)···
什么是丢包
数据在Internet上是以数据包为单位传输的，单位为字节，数据在网络上传输，受网络设备，网络质量等原因的影响，使得接收到的数据少于发送出去的数据，造成丢包。
数据包接收、发送原理
发送数据包：
1.应用程序的数据包，在TCP层增加TCP报文头，形成可传输的数据包。 2.在IP层增加IP报头，形成IP报文。 3.经过数据网卡驱动程序将IP包再添加14字节的MAC头，构成frame（暂⽆CRC），frame（暂⽆CRC）中含有发送端和接收端的MAC地址。 4.驱动程序将frame（暂⽆CRC）拷贝到网卡的缓冲区，由网卡处理。 5.⽹卡为frame（暂⽆CRC）添加头部同步信息和CRC校验，将其封装为可以发送的packet，然后再发送到网线上，这样说就完成了一个IP报文的发送了，所有连接到这个网线上的网卡都可以看到该packet。
接收数据包：
1.⽹卡收到⽹线上的packet，⾸先检查packet的CRC校验，保证完整性，然后将packet头去掉，得到frame。（⽹卡会检查MAC包内的⽬的MAC地址是否和本⽹卡的MAC地址⼀样，不⼀样则会丢弃。） 2.⽹卡将frame拷贝到预分配的ring buffer缓冲。 3.⽹卡驱动程序通知内核处理，经过TCP/IP协议栈层层解码处理。 4.应⽤程序从socket buffer 中读取数据。
核心思路
了解了收发包的原理，可以了解到丢包原因主要会涉及⽹卡设备、⽹卡驱动、内核协议栈三⼤类。以下我们将遵循“从下到上分层分析（各层可能性出现的丢包场景），然后查看关键信息，最终得出分析结果”的原则展开介绍。
目录&amp;ndash;网络丢包情形概览
&amp;gt; 硬件网卡丢包
&amp;gt; 网卡驱动丢包
&amp;gt; 以太网链路层丢包
&amp;gt; 网络IP层丢包
&amp;gt; 传输层UDP/TCP丢包
&amp;gt; 应用层socket丢包
针对以上6种情形，分别作出如下详述~
硬件网卡丢包
Ring Buffer溢出
如图所示，物理介质上的数据帧到达后首先由NIC（网络适配器）读取，写入设备内部缓冲区Ring Buffer中，再由中断处理程序触发Softirq从中消费，Ring Buffer的大小因网卡设备而异。当网络数据包到达（生产）的速率快于内核处理（消费）的速率时，Ring Buffer很快会被填满，新来的数据包将被丢弃；
查看：
通过ethtool或/proc/net/dev可以查看因Ring Buffer满而丢弃的包统计，在统计项中以fifo标识：
$ ethtool -S eth0|grep rx_fifo rx_fifo_errors: 0 $ cat /proc/net/dev Inter-|Receive | Transmitface |bytes packets errs drop fifo frame compressed multicast|bytes packets errs drop fifo colls carrier compressed eth0: 17253386680731 42839525880 0 0 0 0 0 244182022 14879545018057 41657801805 0 0 0 0 0 0</description></item><item><title>网络链路追踪工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%BD%91%E7%BB%9C%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%BD%91%E7%BB%9C%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
trace 路由追踪 参考：
Linux 中有两个工具可以用来追踪路由，tracepath 与 traceroute。tracepath 工具包含在 iputils 包中，安装完系统可以直接使用。traceroute 是单独的一个包，需要手动安装。
默认使用 UDP 来进行追踪。
下面是 tracepath 工具输出的信息
~]# tracepath qq.com -n 1?: [LOCALHOST] pmtu 1500 1: no reply 2: 10.20.1.1 1.205ms ..... 6: 111.33.170.185 3.582ms 7: 117.131.130.137 6.999ms 8: 221.183.13.45 6.017ms asymm 9 9: 221.183.38.61 7.326ms asymm 8 第一列为 TTL 的值。TTL(Time To Live)存活时间，指一个数据包到达目的地时，可传递的最长距离(Hop)。每当数据包经过一个路由器时，其存活次数就会减一，当存货次数为 0 时，路由器会丢弃该数据包。TTL 的设计目的时为了防止数据包因为不正确的路由表等原因造成的无限循环而无法送达目的地。
第二列为每个 hop (i.e.每跳)的信息(就是路由吓一跳的地址)。注意，如果当前 hop 的设备禁止 icmp 报文，那么该 hop 无法显示地址。
剩下的信息为当前 hop 路径点的信息。这些信息包含如下内容</description></item><item><title>网络性能优化</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>概述 参考：
一台 Linux 服务器最多能支撑多少个 TCP 连接？ 原文链接: https://mp.weixin.qq.com/s/BwddYkVLSYlkKFNeA-NUVg
困惑很多人的并发问题 在网络开发中，我发现有很多同学对一个基础问题始终是没有彻底搞明白。那就是一台服务器最大究竟能支持多少个网络连接？我想我有必要单独发一篇文章来好好说一下这个问题。
很多同学看到这个问题的第一反应是 65535。原因是：“听说端口号最多有 65535 个，那长连接就最多保持 65535 个了”。是这样的吗？还有的人说：“应该受 TCP 连接里四元组的空间大小限制，算起来是 200 多万亿个！”
如果你对这个问题也是理解的不够彻底，那么今天讲个故事讲给你听！
一次关于服务器端并发的聊天 &amp;ldquo;TCP 连接四元组是源 IP 地址、源端口、目的 IP 地址和目的端口。任意一个元素发生了改变，那么就代表的是一条完全不同的连接了。拿我的 Nginx 举例，它的端口是固定使用 80。另外我的 IP 也是固定的，这样目的 IP 地址、目的端口都是固定的。剩下源 IP 地址、源端口是可变的。所以理论上我的 Nginx 上最多可以建立 2 的 32 次方（ip 数）×2 的 16 次方（port 数）个连接。这是两百多万亿的一个大数字！！&amp;rdquo;
&amp;ldquo;进程每打开一个文件（linux 下一切皆文件，包括 socket），都会消耗一定的内存资源。如果有不怀好心的人启动一个进程来无限的创建和打开新的文件，会让服务器崩溃。所以 linux 系统出于安全角度的考虑，在多个位置都限制了可打开的文件描述符的数量，包括系统级、用户级、进程级。这三个限制的含义和修改方式如下：&amp;rdquo;
系统级：当前系统可打开的最大数量，通过 fs.file-max 参数可修改 用户级：指定用户可打开的最大数量，修改/etc/security/limits.conf 进程级：单个进程可打开的最大数量，通过 fs.nr_open 参数可修改 &amp;ldquo;我的接收缓存区大小是可以配置的，通过 sysctl 命令就可以查看。&amp;rdquo;
$ sysctl -a | grep rmem net.</description></item><item><title>文件系统管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考
mkfs 与 mke2fs 用于在磁盘设备上创建 LInux 文件系统，也就是将分区格式化。
dumpe2fs 与 xfs_info 是相似的工具，分别对应 ext 和 xfs 文件系统的信息查看
mkfs 参考：
Manual(手册)，mkfs(8) 纯 mkfs 已弃用，使用 mkfs.TYPE 来创建指定类型的文件系统而不用 -t 选项了。事实上，mkfs 只是 Linux 下各种 Filesystem Builder(文件系统构建器) 的前端，仅通过 mkfs.TYPE 来调用各种特定于各种文件系统的构建器程序
比如 mkfs.ext4 就相当于调用了 EXT4 文件系统的构建器，即 mke2fs 命令。mkfs 默认调用的是 ext2 的构建器。
mke2fs 参考：
Manual(手册)，mke2fs(8) Manual(手册)，mke2fs.conf(5) mke2fs 由 mkfs.ext2、mkfs.ext3、mkfs.ext4 调用。
关联文件与配置 /etc/mke2fs.conf # 控制 mke2fs 命令创建 EXT 文件系统时使用的默认参数。这些默认参数值会被命令行参数指定的值覆盖。
简单示例：
有全局默认值，以及为不同文件系统类型设定的默认值。
[defaults] base_features = sparse_super,filetype,resize_inode,dir_index blocksize = 4096 inode_size = 256 inode_ratio = 16384 [fs_types] ext3 = { features = has_journal } ext4 = { features = extents,flex_bg inode_size = 256 } small = { blocksize = 1024 inode_ratio = 4096 } floppy = { features = ^resize_inode blocksize = 1024 inode_size = 128 } Syntax(语法) mke2fs [OPTIONS]</description></item><item><title>问题实例</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Net-SNMP/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</guid><description>概述 参考：
No Such Object available on this agent at this OID 或 No more variables left in this MIB View (It is past the end of the MIB tree) 本地测试：snmpwalk -v 2c -cpublic localhost 1.3.6.1.2.1.25.3.3.1.1
远程测试：snmpwalk -v 2c -c public 192.168.1.172 1.3.6.1.2.1.25.3.3.1.1
如果本地测试 ok，远程测试出现如下报错：
No Such Object available on this agent at this OID 或 No more variables left in this MIB View (It is past the end of the MIB tree)</description></item><item><title>系统启动流程</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</guid><description>概述 参考：
公众号 - 马哥 Linux 运维，Linux 系统开机加电后发生了什么？ 公众号 - 码农的荒岛求生，操作系统是如何启动起来的？ 公众号 - 码农的荒岛求生，操作系统是怎么一步步启动起来的？ 操作系统被称为 The first programme(第一个程序)，原因很简单，只有当操作系统启动起来后才能运行我们编写的程序，那么操作系统是怎样启动起来的呢？实际上这个过程就像发射火箭一样有趣
操作系统也是普通程序 首先我们必须意识到这样两点：
CPU 执行的是机器指令，编译器将程序翻译后成了机器指令 操作系统本身也是一个程序，这个程序被编译后也会生成一大堆机器指令 现在我们知道了，操作系统本身其实也是一大堆机器指令，既然是机器指令那么它必须得存放在什么地方。
存放在哪里呢？
想想我们编写的程序，编译后生成的是可执行文件，也就是说是以“文件”的形式存放的，并且存放在硬盘上，而操作系统也没什么不同，编译后生成的机器指令同样是以文件的形式存放的，存放在哪里呢？可以存放在任何能存储数据的介质，像 CD、磁盘之类都可以。
我们编写的程序在启动时被加载器——也就是 loader，加载到内存，加载器也是一个程序，这是一个加载其它程序的程序；这么说可能有点拗口，但计算机系统中有大量类似的程序，编译器是一个翻译程序的程序、操作系统是一个运行其它程序的程序、链接器是一个链接程序的程序、解释器是一个执行脚本程序的程序等等。
鸡生蛋蛋生鸡的问题
回到我们的主题，我们写的代码是 loader 加载到内存后运行的，那么操作系统这个程序是也同样的道理，必须得有个什么东西也要把操作系统加载到内存中运行才可以，这个东西不叫 loader，而是叫 boot loader，其本身也是一个程序，它的任务就是加载一个更大的程序，就像这里的操作系统。
此时这里会出现一个鸡生蛋蛋生鸡的，既然我们的程序是被加载器 loader(操作系统的一部分)加载到内存中，而操作系统又是被 boot loader 这个加载程序加载到内存中的，那么又是什么加载器把 boot loader 这个加载程序加载到内存中呢？而又又是什么加载器把上一句中的什么加载器加载内存中呢？而又又又是什么。。？
你会发现这个一个没有出口的无穷递归啊有没有，总得有个什么把前一个程序加载到内存，就好比今天的前一天是昨天、昨天的前一天是前天、前天的前一天是大前天，如果一直这样思考下去那么时间到底在哪里开始的呢？时间到底有没有开始(参考时间简史或相对论)？
时间有没有开始这个问题我不清楚，但操作系统启动的这个问题我知道。
上述关于加载器以及加载加载器等问题全部指向了内存，让我们好好想一想内存有什么特殊性？
内存断电后是无法保存数据 程序员都知道内存只有在加电的情况下才可以保存数据(关于内存的实现原理你可以参考这篇《你管这破玩意叫 CPU？》)，那么很显然，当断电后内存中的内容就丢失了，那么又很显然的，当你在按下计算机开关通电时，内存中的内容是未被初始化的，也就是说内存中的内容是无效的，此时的内存里还是一片荒芜，这里没有任何东西可供 CPU 来执行，这就好比大爆炸之前的宇宙。
但我们的计算机总是能启动起来，CPU 必须得执行“一段什么程序”把第一个 boot loader 加载到内存中，由于此时内存中还什么都没有，那么这段程序一定被保存在了其它地方。
保存在了哪里呢？
没错，这段程序就被保存在了 BIOS 的非易失性存储 ROM 或者 flash 存储中了，这里的代码在即使断电后也会保存下来，加电后 CPU 开始执行这里代码，把 boot loader 加载到内存中，现在你应该明白第一个 boot loader 是怎样被加载到内存的了吧。</description></item><item><title>系统证书管理</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/%E7%B3%BB%E7%BB%9F%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/%E7%B3%BB%E7%BB%9F%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
SSL 证书缓存清理 Windows certutil -delstore my &amp;quot;${CertificateName}&amp;quot;
Linux update-ca-certificates --fresh</description></item><item><title>小米</title><link>https://desistdaydream.github.io/docs/Mobile-device/%E5%B0%8F%E7%B1%B3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Mobile-device/%E5%B0%8F%E7%B1%B3/</guid><description>概述 参考：
官网 官网-全球 小米妙想 https://hyperos.mi.com/continuity
https://www.bilibili.com/video/BV1pw41157ai
2022 年 8 月 11 日，Miui+ 更名 小米妙享 PC 版。
小米电脑管家？
Miui+ 在 Miui+ 文件管理中双击想要在电脑中打开的文件将会被保存到 ${HOME}\AppData\Roaming\MI\MiScreenShare\Edit 路径下。</description></item><item><title>小型机器</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%B0%8F%E5%9E%8B%E6%9C%BA%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%B0%8F%E5%9E%8B%E6%9C%BA%E5%99%A8/</guid><description>概述 参考：
PC 基准测试网站 小型机器常用来作为桌面终端、工控机、软路由、等等 使用。
CPU 对比网站
【零基础】软路由保姆级入门教程 一篇看懂软路由
下图截至 2021-09-22</description></item><item><title>性能优化</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>概述 参考：
《性能之巅：洞悉系统、企业与云计算》
《BPF之巅 洞悉Linux系统和应用性能》
性能优化的一点感触 原文链接：https://mp.weixin.qq.com/s/OXvQCPK1ZyM7yyfFzyFYBA
最近参与了几个项目的性能优化，总体来说各个项目都有所提升，能够满足用户使用需求，但是这个过程耗费了大量的人力、物力资源成本，主要原因有以下几点:
系统本身没有任何参数指标，这一点其实是大多数系统存在的问题，打个比方我作为乙方给甲方做了一个软件，交付完成后供甲方使用，这个系统的 TPS 是多少？硬件配置/用户矩阵是什么？系统可靠性 4 个 9 还是 2 个 9？你可能会说，我们的客户要求根本没有这么严格，能用就行，实则不然，如果说一年没问题，一年后客户的用户数量增长了一倍，忽然发现系统卡顿，几乎不能使用，客户找你算账，这该怎么办？谁的原因造成的&amp;hellip;.. 你说我们给自己公司做的产品，不要求这些东西，满足当前用户即可，那我现在问你，你的系统用户承载量是什么？当你真的出现用户数量激增，你该如何应对？ 框架标准化，如果一个企业中多个项目使用的框架五花八门，真正出现性能问题的时候，只能大家齐上阵，见招拆招，忙的不亦乐乎，其实收效甚微。 翻译需求，很多功能逻辑说不通，但又没法改，为什么？客户要求如此、产品经理设计如此，产品经理也已经不在了，原型设计文档找不到了，当然这种项目都是比较老的项目，很多公司都会存在此类问题。 灰度发布系统，深夜一群人呆在一起发布一个系统，一起处理 bug 真的是团队团结的表现吗?回家陪陪老婆孩子，好好休息，第二天的工作效率不是更高吗？ 如果现在让我做一个系统，我应该如何设计？趁着周六有时间就这四个问题简单聊聊，希望能够对大家的工作有所启发。
系统参数 你打开的汽车使用说明书，它会告诉你它在什么温度下可以正常工作、最高时速是多少、承客量多大&amp;hellip;&amp;hellip;如果出现问题，仪表盘会给出什么样提示，你应该如何规避这些故障。软件系统也一样，你的安装部署手册里要告诉别人你的系统需要多大内存、多少硬盘、什么规格的 CPU 来支撑多少用户量。设计文档的非功能性指标应该包含系统每秒处理事务数量（TPS）或查询数量是多少、安全性指标等级甚至支持用户数量；你的管理端界面或者监控系统应该告诉运维人员 CPU 占用量、内存占用量、硬盘使用情况、带宽使用；阈值告警参数，触发阈值产生告警，研发人员如何查看日志排除故障。 说的简单，这些指标从哪里得到呢？没有特别好的办法，只能通过压力测试、稳定性测试、安全性测试甚至平时的故障模拟中得到。 确实这些度量指标非常昂贵，甚至要超过你系统本身的成本，即便如此，你要去做，因为你不去量化一个系统，你就无法管理一个系统，可以想象一下你每天都是在闭着眼睛开车，你永远不知道您离灾难有多近。所以你要说服你的老板，抵挡住节省金钱的诱惑，认真对待系统指标数据。 当然完全做出这些东西到底有多复杂？我作为过来人认为并不复杂，而且能减轻不少后期工作量，想想一个系统不会所有的接口都对性能有要求，所以你只要评估出存在性能瓶颈的接口加以性能测试即可；另外性能测试脚本开发完成后都是复用的状态，所以不会产生太大工作量，而且又保证了每次上线之前都可以自动化验证部分接口，这不比人肉点点点香的多吗？ 另外像一些系统层面的参数指标，比如 Http 调用成功/失败情况、CPU、内存占用情况、告警等，可以搭建一套监控工具，比如 Prometheus 等。完成此类指标的获取。 如果说我的系统总共就几个人用、或者这种付出和收益完全成反比，那当我没说。
框架标准化 框架，通俗来说也就是我们产品/项目架构，就架构本身而言，一定先有设计目标，架构要去干什么样的事情，去完成一个购物网站还是一个管理平台，存在很大区别；根据设计目标，应该定义出设计原则，这也就是平时经常见到的控制反转、里氏替换、最小依赖、单一职责等原则，加上清晰的边界和实现价值（架构做什么，不做什么）；最后通过使用 Gof 总结出来 23 种设计模式加上算法就形成了一套框架。在这个框架的基础上就可以开发我们的应用。你可能会反驳我们项目五花八门，经常变动，一般架构很难满足，甚至架构需要经常改动，大概率是框架抽象定义的不够好，你看看你平时用到的 tomcat 框架、spring 框架，你感知到它的存在了吗？反而像早期 IBM 做的 weblogic、jboss 什么都做的重量级框架，已被抛弃，所以解耦和抽象再怎么强调都不为过。 定义好框架只是第一步，下面就是使用了，就目前国内情况而言，开源项目越来越火爆，所以基本上从网上找找，七拼八凑就行成了一套自己的框架，这本身而言也没有错误，极大降低企业框架定义的成本，但是一个框架通常只能解决某一类的问题，所以前期就需要架构人员进行反复编写代码进行测试和使用，得到这个框架自身的数据，而不是看见别人用的很好，别人多少数据量都可以轻易支撑起来，别人的使用场景很可能跟你不一样，要不然为啥市面充斥着五花八门的框架，大多数原因都不能从根本上解决自己的痛点问题。 接着架构人员要参与到编码中，发现问题及时更正和修改，引导开发人员如何划分模块，关键时刻做出示例，进而形成自己的开发规范，而不仅仅是站在一个指导者的角色，口头告诉程序员该如何使用，满足不了性能指标或者业务一团糟的时候开始考虑拆分，然后拆成几个微服务也是乱上加乱，根本不能从本质上解决问题。 总结来说，做架构首先要考虑的是自己的需求、目的及边界、原则、实现价值，最后才考虑技术实现和工具组件，而不是首先撸出一套框架生搬硬套，最后说程序员不会使用，代码写的太垃圾。
翻译需求 通常来说，一般是提出需求，架构人员进行架构设计，产品经理画出原型设计，开发人员开始设计、开发、提交测试交付。最后一个阶段看似已经定型，按照需求完成任务即可。但是人都会犯错，作为开发/测试人员不能对照原型、设计文档翻译需求，出现问题后，自豪的说，就是这样设计的，我也没办法，你找产品去。但是你有没有考虑过，即使产品人员改了改需求，最后你不还是照做，受伤的还是自己。所以我们在做任何一个功能的时候都要搞清楚问题的本质，事情的初衷。 你可能会反驳说，我的产品比较强势，他做的东西面向的是用户，开发人员是无法理解的，照着做就行了。但我觉着这些并不是理由，如果一个产品说用户要求的，你可以站在一个用户的角度去理解，如果是从数据角度，让他把数据拿出来，如果讲不明白，你完全可以拒绝，否则你做出来的东西肯定是四不像。所谓铁打的营盘，流水的兵，换了几波人之后完全无法理解这种逻辑，产品如何迭代。你要说你的产品功能过于复杂，大多数是产品设计就存在一定问题，你看看你常用的应用，那个不是简单易用。 为什么要对开发人员强调需求呢？因为你的需求做的不严谨，存在漏洞，都会给后期的性能、再次开发埋下祸根，而且这种问题，越往后解决成本越高。
灰度发布 相信大家面试的时候经常会听到面试官问这个问题, 如何保证一个系统高可用？如何做到不停机发布系统？答案也很简单，负载均衡，当然负载均衡也有很多种，有基于域名重定向、DNS、IP、数据链路层的负载均衡，你可以根据你服务自身情况，选择一种适合自己的。当然你会反驳我说，我的系统就一个副本，不要求高可用，那我会说，你敢白天上线吗？如果不敢，请乖乖做灰度发布（金丝雀、A/B、蓝绿等等）。 这并不是凭空增加大家的工作量，不知道大家认不认这样一个事实，软件发布通常遵循墨菲定律，往往不好的，一般情况下不会出现的问题，甚至没有想到的，都会在线上出现。要么人家都说运维人员都相信玄学，其实倒不是因为玄学，是因为存在未知。线上的用户、历史数据量往往最多的，也是最全面的，所以线上更容易复现一些问题。通过灰度发布部署多套，开发/测试人员完全可以在工作时间、站在用户的角度测试完成后上线发布。否则直接回退，即实现了测试，也没有影响用户使用。 灰度发布说简单也简单，最简单的你在你的 nginx 写几句 lua 脚本，便可以把包含特定标识的用户路由到特定服务。
总结 看完本文后，感觉会有点诧异，说的不是性能优化吗？不应该讲讲连接池配置多大、缓存如何使用、系统优化、硬件配置、甚至代码如何编写的一些技巧吗？怎么扯了一堆没用的。从某种程度上来说，软件的性能优化成本往往跟前期的软件设计成本反比，前期在设计上花费的时间越多，往往后期优化成本就越低。没有任何组织能够一开始就做一个高性能的软件系统，大多数都是随着用户和数据的增多演化而来。前期的性能指标、系统架构、甚至功能需求编写都能够为后期软件性能优化带来帮助。</description></item><item><title>虚拟化调试和优化指南</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E8%B0%83%E8%AF%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E8%99%9A%E6%8B%9F%E5%8C%96%E8%B0%83%E8%AF%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/</guid><description>概述 参考：
红帽官方文档，7 - 虚拟化调整和优化指南 新链接: https://docs.redhat.com/zh_hans/documentation/red_hat_enterprise_linux/7/html-single/virtualization_tuning_and_optimization_guide/index 网卡软中断过高问题 原文连接: https://mp.weixin.qq.com/s/X3wsJ13V-ou7j8qccd30AA
游戏网关高峰期时出网络丢包,CPU0 软中断%sys 高达 90%。
这意思就是说多个 CPU 中，只有 1 个来处理软中断信号
使用 ethtool -l eth0 查看网卡队列数，若网卡不支持多多列，将会报错: netlink error: Operation not supported
配置网卡多队列 参考:
https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html-single/virtualization_tuning_and_optimization_guide/index#sect-Virtualization_Tuning_Optimization_Guide-Networking-Multi-queue_virtio-net https://docs.redhat.com/zh_hans/documentation/red_hat_enterprise_linux/7/html/virtualization_tuning_and_optimization_guide/sect-virtualization_tuning_optimization_guide-networking-multi-queue_virtio-net 要使用多队列 virtio-net，请在 VM 的 XML 配置中添加以下内容（主要是添加 queues='N'，其中 N 的值从 1 到 256，因为内核支持多队列 tap 设备）支持 256 个队列：
&amp;lt;interface type=&amp;#39;network&amp;#39;&amp;gt; &amp;lt;source network=&amp;#39;default&amp;#39;/&amp;gt; &amp;lt;model type=&amp;#39;virtio&amp;#39;/&amp;gt; &amp;lt;driver name=&amp;#39;vhost&amp;#39; queues=&amp;#39;N&amp;#39;/&amp;gt; &amp;lt;/interface&amp;gt; 当在 VM 中运行带有 N virtio-net 队列的虚拟机时，使用以下命令（ M 的值从 1 到 N）启用多队列支持 ：</description></item><item><title>虚拟网络设备(Bridge,VLAN)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87BridgeVLAN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87BridgeVLAN/</guid><description>概述 参考：
云计算底层技术-虚拟网络设备(Bridge,VLAN) Posted on September 24, 2017 by opengers in openstack
原文链接：openstack 底层技术-各种虚拟网络设备一(Bridge,VLAN)
IBM 网站上有一篇高质量文章。本文会参考文章部分内容，本系列介绍 OpenStack 使用的这些网络设备包括 Bridge，VLAN，tun/tap, veth，vxlan/gre。本篇先介绍 Bridge 和 VLAN 相关，其它在下一篇中介绍
OpenStack 一般分为计算，存储，网络三部分。考虑构建一个灵活的可扩展的云网络环境，而物理网络架构一般是固定和难于扩展的，因此虚拟网络将更有优势。Linux 平台上实现了各种不同功能的虚拟网络设备，包括Bridge,Vlan,tun/tap,veth pair,vxlan/gre，...，这些虚拟设备就像一个个积木块一样，被 OpenStack 组合用于构建虚拟网络。 还有火热的 Docker，docker 容器的隔离技术实现脱胎于 Linux 平台上的namspace,以及更早的chroot。
文中会牵涉虚拟机，所以文中出现的”主机”一词明确表示一台物理机，”接口”指挂载到网桥上的网络设备，环境如下：
CentOS Linux release 7.3.1611 (Core) Linux controller 3.10.0-514.16.1.el7.x86_64 #1 SMP Wed Apr 12 15:04:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux OpenStack社区版 Newton Linux Bridge
内核模块bridge
[root@controller ~]# modinfo bridge filename: /lib/modules/3.10.0-514.16.1.el7.x86_64/kernel/net/bridge/bridge.ko Bridge 是 Linux 上工作在内核协议栈二层的虚拟交换机，虽然是软件实现的，但它与普通的二层物理交换机功能一样。可以添加若干个网络设备(em1,eth0,tap,.</description></item><item><title>虚拟网络设备(tun tap,veth)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87tun-tapveth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization/Network-Virtualization/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87tun-tapveth/</guid><description>概述 参考：
[openstack 底层技术-各种虚拟网络设备一(Bridge,VLAN)](https://opengers.github.io/openstack/openstack-base-virtual-network-devices-bridge-and-vlan/ openstack 底层技术-各种虚拟网络设备二(tun/tap,veth) 第一篇文章介绍了 Bridge 和 VLAN，本文继续介绍 tun/tap，veth 等虚拟设备，除了 tun，其它设备都能在 openstack 中找到应用，这些各种各样的虚拟网络设备使网络虚拟化成为了可能
tun/tap tap 设备作为虚拟机网卡 openvpn 中使用的 tun 设备 veth 设备 veth 设备在 openstack 中的应用 tun/tap 我们知道 KVM 虚拟化中单个虚拟机是主机上的一个普通 qemu-kvm 进程，虚拟机当然也需要网卡，最常见的虚拟网卡就是使用主机上的 tap 设备。那从主机的角度看，这个qemu-kvm进程是如何使用 tap 设备呢，下面先介绍下 tun/tap 设备概念，然后分别用一个实例来解释 tun/tap 的具体用途 tun/tap 是操作系统内核中的虚拟网络设备，他们为用户层程序提供数据的接收与传输。实现 tun/tap 设备的内核模块为 tun，其模块介绍为 Universal TUN/TAP device driver，该模块提供了一个设备接口 /dev/net/tun 供用户层程序读写，用户层程序通过读写 /dev/net/tun 来向主机内核协议栈注入数据或接收来自主机内核协议栈的数据，可以把 tun/tap 看成数据管道，它一端连接主机协议栈，另一端连接用户程序
~]# modinfo tun filename: /lib/modules/3.10.0-514.16.1.el7.x86_64/kernel/drivers/net/tun.ko alias: devname:net/tun ... description: Universal TUN/TAP device driver .</description></item><item><title>一致性哈希算法 consistent hashing</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/Consistent-hashing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/Consistent-hashing/</guid><description>概述 参考：
Wiki, Consistent hashing 朱双印 blog，白话解析：一致性哈希算法 consistent hashing 在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景，了解了这个应用场景之后，再来理解一致性哈希算法，就容易多了，也更能体现出一致性哈希算法的优点，那么，我们先来描述一下这个经典的分布式缓存的应用场景。
场景描述 假设，我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为 0 号、1 号、2 号，现在，有 3 万张图片需要缓存，我们希望这些图片被均匀的缓存到这 3 台服务器上，以便它们能够分摊缓存的压力。也就是说，我们希望每台服务器能够缓存 1 万张左右的图片，那么，我们应该怎样做呢？如果我们没有任何规律的将 3 万张图片平均的缓存在 3 台服务器上，可以满足我们的要求吗？可以！但是如果这样做，当我们需要访问某个缓存项时，则需要遍历 3 台缓存服务器，从 3 万个缓存项中找到我们需要访问的缓存，遍历的过程效率太低，时间太长，当我们找到需要访问的缓存项时，时长可能是不能被接收的，也就失去了缓存的意义，缓存的目的就是 提高速度，改善用户体验，减轻后端服务器压力，如果每次访问一个缓存项都需要遍历所有缓存服务器的所有缓存项，想想就觉得很累，那么，我们该怎么办呢？原始的做法是对缓存项的键进行哈希，将 hash 后的结果对缓存服务器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上，这样说可能不太容易理解，我们举例说明，仍然以刚才描述的场景为例，假设我们使用图片名称作为访问图片的 key，假设图片名称是不重复的，那么，我们可以使用如下公式，计算出图片应该存放在哪台服务器上。
hash（图片名称）% N
因为图片的名称是不重复的，所以，当我们对同一个图片名称做相同的哈希计算时，得出的结果应该是不变的，如果我们有 3 台服务器，使用哈希后的结果对 3 求余，那么余数一定是 0、1 或者 2，没错，正好与我们之前的服务器编号相同，如果求余的结果为 0， 我们就把当前图片名称对应的图片缓存在 0 号服务器上，如果余数为 1，就把当前图片名对应的图片缓存在 1 号服务器上，如果余数为 2，同理，那么，当我们访问任意一个图片的时候，只要再次对图片名称进行上述运算，即可得出对应的图片应该存放在哪一台缓存服务器上，我们只要在这一台服务器上查找图片即可，如果图片在对应的服务器上不存在，则证明对应的图片没有被缓存，也不用再去遍历其他缓存服务器了，通过这样的方法，即可将 3 万张图片随机的分布到 3 台缓存服务器上了，而且下次访问某张图片时，直接能够判断出该图片应该存在于哪台缓存服务器上，这样就能满足我们的需求了，我们暂时称上述算法为 HASH 算法或者取模算法，取模算法的过程可以用下图表示。
但是，使用上述 HASH 算法进行缓存时，会出现一些缺陷，试想一下，如果 3 台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？没错，很简单，多增加两台缓存服务器不就行了，假设，我们增加了一台缓存服务器，那么缓存服务器的数量就由 3 台变成了 4 台，此时，如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在的服务器编号必定与原来 3 台服务器时所在的服务器编号不同，因为除数由 3 变为了 4，被除数不变的情况下，余数肯定不同，这种情况带来的结果就是当服务器数量变动时，所有缓存的位置都要发生改变，换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据，同理，假设 3 台缓存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从 3 台变为 2 台，如果想要访问一张图片，这张图片的缓存位置必定会发生改变，以前缓存的图片也会失去缓存的作用与意义，由于大量缓存在同一时间失效，造成了 缓存雪崩，此时前端缓存已经无法起到承担部分压力的作用，后端服务器将会承受巨大的压力，整个系统很有可能被压垮，所以，我们应该想办法不让这种情况发生，但是由于上述 HASH 算法本身的缘故，使用取模法进行缓存时，这种情况是无法避免的，为了解决这些问题，一致性哈希算法诞生了。</description></item><item><title>音频处理</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/</guid><description>概述 参考：
USB # 声卡输入
AUX IN # (Auxiliary)是指音频输入。线路输入
SUB OUT # 低音输出
DC IN # 电源输入
音箱品牌 HECATE G2000
常见问题 麦克风增强 麦克风声音小？三句话教你麦克风无法增强怎么办
Equalizer APO
https://sourceforge.net/projects/equalizerapo/ https://sourceforge.net/projects/peace-equalizer-apo-extension/</description></item><item><title>应用示例</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/</guid><description>概述 参考：
Manual(手册)，systemd.unit(5) - EXAMPLE 开机建立远程隧道 [Unit] Description=Remote SSH [Service] ExecStart=/bin/ssh -N -R 20001:localhost:22 root@10.253.26.241 Restart=on-failure RestartSec=10 [Install] WantedBy=network.target 让 Service 使用环境变量 [Unit] Description=UnitDemo [Service] EnvironmentFile=/etc/default/demo ExecStart=/usr/local/bin/unit-demo.sh [Install] WantedBy=multi-user.target ~]# cat /etc/default/demo DEMO=DesistDaydream ~]# cat /usr/local/bin/unit-demo.sh #!/bin/bash # while : do echo $DEMO sleep 5 done 启动 Service 后，可以看到如下输出
Aug 01 14:14:45 centos7-2009 systemd[1]: Started Foo. Aug 01 14:14:45 centos7-2009 unit-demo.sh[8901]: DesistDaydream Aug 01 14:14:50 centos7-2009 unit-demo.sh[8901]: DesistDaydream Aug 01 14:14:55 centos7-2009 unit-demo.</description></item><item><title>云原生</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/</guid><description>概述 参考：
B 站-马哥，云原生底层逻辑和学习方向 公众号-刘超的通俗云计算，不是技术也能看懂云原生 Cloud Native(云原生)
我们来看看这些大牛们都如何定义云原生的：
2010 年，WSO2 技术总监 PaulFremantle 首次提出 Cloud Native，他一直想用一个词表达一个架构，这种架构能够描述应用程序和中间件能够在云环境中有良好的运行状态。云原生有以下特性 分布式、弹性、多租户，子服务，按需计量和计费，增量部署和测试。2013 年，Netflix 云架构师，Adrian Cockcroft 介绍了 Netflix 在 AWS 上基于 Cloud Native 的成功应用，Netflix 在 AWS 上有上万个实例。 2015 年，来自 Pivotal 的 Matt Stine，他的电子书《迁移到云原生应用架构》，他认为单体架构在向云原生架构的演进过程中，需要流程、文化、技术共同变革，该书把 Cloud Native 描述为一组最佳实践，具体包含如下内容：十二因子，微服务，敏捷基础设施，基于 API 的协作，反脆弱性。 2017 年，Matt Stine 在接受媒体采访时又改了口风，将云原生架构归纳为模块化、可观察、可部署、可测试、可替换、可处理 6 特质；而 Pivotal 最新官网对云原生概括为 4 个要点：DevOps+持续交付+微服务+容器。 2015 年云原生计算基金会（CNCF）成立，最初把云原生定义为包括：容器化封装+自动化管理+面向微服务。 CNCF 于 2018 年通过了对云原生重新定义的提案，V1.0 的定义如下： 云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。 微服务与无服务 Knative 参考：
GitHub 组织，knative 官网</description></item><item><title>运维工具</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7/</guid><description>概述 常见运维工具介绍：
OS provisioning：PXE，Cobbler(repository,distritution,profile)
PXE:dhcp,tftp,http,ftp
dnsmasq:dhcp,dns
OS Config:系统配置
puppet,salstack,func Task Excute:任务执行
fabric,func,saltstack Deployment:部署
fabric 自动化运维工具介绍 Cobbler Cobbler
Ansible Ansible
SaltStack https://github.com/saltstack/salt
puppet https://www.puppet.com/
https://github.com/puppetlabs/puppet
其他 Go 语言实现的
基于 SSH 的 https://github.com/skx/deployr https://github.com/melbahja/goph 带有 Client 的 运维平台 https://github.com/openspug/spug # 开源运维平台：面向中小型企业设计的轻量级无Agent的自动化运维平台，整合了主机管理、主机批量执行、主机在线终端、文件在线上传下载、应用发布部署、在线任务计划、配置中心、监控、报警等一系列功能。
https://github.com/veops/cmdb
https://github.com/TencentBlueKing/bk-cmdb # 蓝鲸智云配置平台(BlueKing CMDB)</description></item><item><title>站点管理</title><link>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/%E7%AB%99%E7%82%B9%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/%E7%AB%99%E7%82%B9%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
搜索引擎收录个人网站 Google 使用 Google Search Console 添加资源，使用网址前缀的方式，在其中输入想要自己博客的网址，比如 https://demo.xyz
此时 Google 提供了一些验证方式，用以验证该网站是我所有。我们使用默认的 HTML 文件 的方式，下载文件到我们网站的 / 目录下
我们需要保证 Google 访问我们的站点时，可以通过访问到该静态资源，即 https://demo.xyz/google7f9c064908d7820d.html，这个文件的内容非常简单：
google-site-verification: google7f9c064908d7820d.html 只要 Google 可以正常访问到该资源，那么就通过了 Google 的验证，在设置中可以看到如下内容：
对于 Hugo 来说，可以将这个 HTML 页面放到 static 目录下</description></item><item><title>正则</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%AD%A3%E5%88%99/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%AD%A3%E5%88%99/</guid><description>概述 参考：
原文链接 Go 遵循 Regular Expression(正则表达式) 语法
手机号码正则匹配
String PHONE_NUMBER_REG = &amp;#34;^(13[0-9]|14[579]|15[0-3,5-9]|16[6]|17[0135678]|18[0-9]|19[89])\\d{8}$&amp;#34;; /** * JS 使用 */ &amp;#34;18016381232&amp;#34;.match(/^(13[0-9]|14[579]|15[0-3,5-9]|16[6]|17[0135678]|18[0-9]|19[89])\d{8}$/) 元字符 代码 说明 . 匹配除换行符以外的任意字符 \w 匹配字母或数字或下划线或汉字 \s 匹配任意的空白符 \d 匹配数字 \b 匹配单词的开始或结束 ^ 匹配字符串的开始 $ 匹配字符串的结束 字符转义 如果你想查找元字符本身的话，比如你查找.,或者*,就出现了问题：你没办法指定它们，因为它们会被解释成别的意思。这时你就得使用\来取消这些字符的特殊意义。因此，你应该使用.和*。当然，要查找 \ 本身，你也得用 \\
例如：deerchao\.net 匹配 deerchao.net，C:\\Windows 匹配 C:\Windows
重复 你已经看过了前面的*,+,{2},{5,12}这几个匹配重复的方式了。下面是正则表达式中所有的限定符(指定数量的代码，例如*,{5,12}等)：
代码/语法 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {n} 重复 n 次 {n,} 重复 n 次或更多次 {n,m} 重复 n 到 m 次 下面是一些使用重复的例子：</description></item><item><title>证书 与 PKI</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/%E8%AF%81%E4%B9%A6-%E4%B8%8E-PKI/</guid><description>概述 参考：
Wiki, Public Key Certificate Wiki, PKI Wiki, CSR Wiki, CA Wiki, Root Certificate RFC,5280 公众号,云原生生态圈-白话文说 CA 原理 Arthurchiao 博客,[译] 写给工程师：关于证书（certificate）和公钥基础设施（PKI）的一切（SmallStep, 2018） 公众号-云原生实验室，搬运了上面的文章 Certificate 与 PKI 的目标很简单：Bind names to Public Keys(将名字关联到公钥)。这是关于 Certificate 与 PKI 的最高抽象，其他都是属于实现细节
Certificate Certificate(证书) 在密码学中，是指 公开密钥加密 中完善其签名缺点的 Public Key Certificate(公钥证书)。在公开密钥加密的介绍中，我们看到了公钥加密的特点，并且也发现了缺点，公钥容易被劫持。那么为了解决这个问题，就需要一个东西可以验证公钥的真实性。公钥证书也就由此而来。
Public Key Certificate(公钥证书，简称 PKC) 也称为 Digital Certifacte(数字证书) 或 Identity Certificate(身份证书)，是一种用于证明公钥的所有权的电子文档。
假设有这么一种场景：公钥加密系统使我们能知道和谁在通信，但这个事情的前提是：我们必须要有对方的公钥
那么，如果我们不知道对方的公钥，那么该怎么办呢？这时候 Certificate 就出现了。
首先，我需要从对方手里拿到公钥和其拥有者的信息 那么我如何相信我拿到的信息是真实有效的呢？~可以请一个双方都信任的权威机构，对我拿到的信息做出证明 而这个权威机构用来证明信息有效的东西，就是 Certificate 公钥证书通常应该包含如下内容：
密钥的信息 有关其所有者的身份信息，称为 Subject(主体) 验证证书内容的实体的数字签名，这个实体称为 Issuer(发行人) 权威机构对证书的签名，签名的大概意思就是：Public key XXX 关联到了 name XXX，这就对应了文章开头的那句话：Certificate 与 PKI 的目标很简单：Bind names to Public Keys(将名字关联到公钥) 对证书的签名的实体称为 Certificate Authority(简称 CA)，也可以称为 Issuer(签发者)。 被签名的实体称为 Subject(主体)。 举个例子，如果某个 Issuer 为 Bob 签发了一张证书，其中的内容就可以解读如下：</description></item><item><title>中国行政区划及代码</title><link>https://desistdaydream.github.io/docs/Standard/%E4%B8%AD%E5%9B%BD%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E5%8F%8A%E4%BB%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/%E4%B8%AD%E5%9B%BD%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E5%8F%8A%E4%BB%A3%E7%A0%81/</guid><description>概述 参考：
GB/T 2260-2007 中华人民共和国行政区划代码 国家统计局，统计用区划代码和城乡划分代码 国家统计局，统计用区划代码和城乡划分代码编制规则 GitHub 项目，modood/Administrative-divisions-of-China</description></item><item><title>中间人攻击与HTTPS抓包</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB%E4%B8%8EHTTPS%E6%8A%93%E5%8C%85/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB%E4%B8%8EHTTPS%E6%8A%93%E5%8C%85/</guid><description>概述 参考：
公众号-小林 coding，字节一面：HTTPS 一定安全可靠吗？ HTTPS 一定安全可靠吗？
这个问题的场景是这样的：客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手。
具体过程如下：
客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手； 在客户端与中间人进行 TLS 握手过程中，中间人会发送自己的公钥证书给客户端，客户端验证证书的真伪，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。 在中间人与服务端进行 TLS 握手过程中，服务端会发送从 CA 机构签发的公钥证书给中间人，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。 后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。 从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。
那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够 “偷看” 浏览器与服务端之间的 HTTPS 请求和响应的数据。
但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。
中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。
如果用户执意点击「继续浏览此网站」，相当于用户接受了中间人伪造的证书，那么后续整个 HTTPS 通信都能被中间人监听了。
所以，这其实并不能说 HTTPS 不够安全，毕竟浏览器都已经提示证书有问题了，如果用户坚决要访问，那不能怪 HTTPS ，得怪自己手贱。
客户端是如何验证证书的？ 接下来，详细说一下实际中数字证书签发和验证流程。
如下图图所示，为数字证书签发和验证流程：
当服务端向 CA 机构申请证书的时候，CA 签发证书的过程，如上图左边部分：</description></item><item><title>重大变化</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/</guid><description>概述 参考：
GitHub，kubernetes/kubernetes-CHANGELOG 该文档记录 Kubernetes 历史上的重大事件，以及比较重要的版本更新信息。
Kubernetes 不再在 kubelet 中维护 docker-shim 代码
版本更新 1.9 我从该版本开始接触
1.14 1.16 1.16 更新日志
1.19 1.19 更新日志
1.20 Kubernetes 不再在 kubelet 中维护 docker-shim 代码
1.22 https://mp.weixin.qq.com/s/TQoyU3S2q4Q-yCK0zGHo9g https://mp.weixin.qq.com/s/PTPTmR6Dprqsyd6E-hBvlw https://kubernetes.io/blog/2021/07/14/upcoming-changes-in-kubernetes-1-22/ 1.23 https://mp.weixin.qq.com/s/SiFhhDHHjHNbg8QPX4fOBw 1.24 公众号 - CNCF，Kubernetes 1.24：观星者 Dockershim 从 kubelet 中删除
1.25 公众号 - MoeLove，K8S 生态周报| K8s v1.25 将 GlusterFS 卷插件废弃 公众号 - 进击云原生，Kubernetes 1.25 中的重大更改和删除 公众号 - CNCF，Kubernetes 1.25版本中的删除和主要变化 1.26 公众号 - CNCF，Kubernetes v1.26：振奋人心 1.29 公众号 - CNCF，Kubernetes v1.</description></item><item><title>重大变化</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/</guid><description>概述 参考：
曾领导六大开源项目，Go 语言负责人从 Google 离职 原文：https://mp.weixin.qq.com/s/PbTs1_W1r7bnABVIAtTjCw
Steve Francia 于 6 年前加入 Google，是 Go 语言的产品负责人，今天他在个人社交平台宣布将离开 Google。
6 年后，我将离开 Google。我为 Go 团队在过去六年里所取得的成就感到非常自豪，我也从未像现在这样对 Go 的未来充满期待。
你可能不熟悉 Steve Francia 这个名字，但你一定会对他的履历刮目相看。Steve Francia 在开源领域拥有超过 25 年的工作经验，领导了六大开源项目（Go、Docker、Hugo、MongoDB、Drupal、Cobra；其中他更是 Hugo、Cobra、Viper 和 spf13-vim 的作者），他还帮助 Google 定义了开源战略，也是 Github 上最受欢迎的前 50 名工程师。
Steve Francia 在 6 年前加入了 Go 团队，目标是将 Go 从一种小众的语言变成一种主流的、企业级的语言。现在回过头来看，Steve Francia 已经完成，甚至可以说是超额完成了这个目标。
在这段时间里，Go 团队交付了 VS Code Go 和 Gopls、大大改善了 Go 的开发体验、改进了 Go 的文档，以及改进了开发者安装 Go 的方式。Go 语言也从主要由 Googlers 编写，发展到如今主要由社区贡献者编写。
Go 的用户数量在这段时期也增长了 10 倍，Go 用户的使用频率也从偶尔使用增加到每天都使用。如今超过 75% 的 CNCF 项目都是用 Go 编写的。</description></item><item><title>主要组件</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Opensatck-%E4%BB%8B%E7%BB%8D/%E4%B8%BB%E8%A6%81%E7%BB%84%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Opensatck-%E4%BB%8B%E7%BB%8D/%E4%B8%BB%E8%A6%81%E7%BB%84%E4%BB%B6/</guid><description>概述 参考：
Keystone # 为 OpenStack 的各种服务提供认证和权限管理服务。简单的说，OpenStack 上的每一个操作都必须通过 Keystone 的审核。核心服务 Compute(计算) Nova：计算服务， 管理计算资源，VM 的生命周期，包括但不限于启动、调度、按需创建 VMs。核心的服务 Network(网络) Neutron：为 OpenStack 提供网络连接服务，负责创建和管理 L2、L3 网络，为 VM 提供虚拟网络和物理网络连接。核心服务 Storage(存储) Cinder # 块存储服务。一般用作 VM 数据盘。Cinder 功能创建的每个块存储设备(提供的每一个 Volume)在 VM 看来就是一块虚拟硬盘，一般用作数据盘，如果把这个 VM 摧毁了，这个 volume 和里边的数据依然还在，还可以把它接到其他 VM 上继续使用里边的数据。cinder 创建的 volume 必须被接到虚拟机上才能工作。核心服务 Swift # 对象存储服务。一般存放 image，分布式存储服务，过于重量级，VM 可以通过 RESTful API 存放对象数据。可选的方案。Glance 可以将镜像存放在 Swift 中；Cinder 也可以将 Volume 备份到 Swift 中。当成百上千台实例同时基于同一个模板启动的时候，每个节点都要下载该模板，那么磁盘 IO、网络 IO 成为瓶颈，这时候 swift 就可以实现分布式存储方式，把一个镜像模板文件分成一块一块分别存放在分布式存储集群中。注意：images 可以不存储在 swift 提供的分布式存储上而直接存在各 node 的本地 Glance # 镜像服务，存储和检索磁盘镜像的元数据，如果 VM 没那么多，可以不使用 swift 存储镜像，直接存放在各个节点的本地，这时候当用户请求调用 images 的时候，可以通过 glance 查询所需镜像的元数据，然后回应该请求让其去所在位置调用所需 image；Nova 创建 VM 时将使用 Glance 提供。核心服务 Ceilometer # 提供 OpenStack 监控和计量服务，为报警、统计或计费提供数据。 Horizon # 为 OpenStack 用户提供一个 Web 的自服务 Portal，即 web 的操作面。 Heat # 用于多组件联动 Trove # 提供 DBaas 服务 Sahara # ：用于在 Openstack 中实现 Hadoop 的管理</description></item><item><title>注册表</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E6%B3%A8%E5%86%8C%E8%A1%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/%E6%B3%A8%E5%86%8C%E8%A1%A8/</guid><description>概述 参考：
公众号-差评，所有电脑管家都叫你清理的注册表，竟然能偷偷控制你的电脑！ 注册表前身 其实，注册表也不是一开始就存在于 Windows 上。
在 Windows 95 之前，微软通过一种叫 “ 配置文件 ” 的东西，来实现如今注册表的作用。
这里面存储的，就是一些软件的基本信息。比如说配置一些文件的打开路径在哪里，或者是软件要用哪些字体来读取。
通常通过 ini 格式的文件，配置文件会趁着咱们安装各种软件的时候，把自己丢在系统的各种文件夹里。想修改一些配置的时候，咱们可以直接去这个软件的安装目录里找 ini 文件就行。
看上去挺方便，不过这 ini 文件最大的问题吧，就是太容易修改了，甚至可以简单到直接用记事本给打开。
到时候手一抖改几个字，可能一个软件就打不开了。
比如把一个 5 行的行间距手一抖改成复数，软件当场就寻思我哪见过这个？不当场宕机就不错了。万一改的还是系统配置文件，电脑指不定也得抽两抽。
而且，当年大家用的还都是机械硬盘。。。考虑到 ini 文件分散在系统的各种犄角旮旯，读取起来太麻烦，打开也嫌慢，更不方便维护。
微软后来就一寻思，干脆把这些乱的到处都是的 ini 文件功能给整合了起来。
通过一个统一的，系统级别的分层数据库来起到过去 “ 配置文件 ” 做的事情。这个库里面装的呢，就是咱们电脑里哪些花里胡哨，乱七八糟的配置。
举个例子，我们鼠标右键的每次点击，到底会弹出来哪些菜单选项，以及具体要弹的多长。都得让注册表来告诉它才行。
而且吧，比起过去各自为战，互相之间看不对眼的配置文件。注册表还能起到一个**系统级别的调度功能，**可以把这些软件之间的信息共享给其它软件，。
当有新的软件安装的时候，也会优先把自己能干什么，自己需要什么的消息给写入注册表里。
就像咱们现在能用 WPS 软件来打开 word 文档，中间还得靠注册表这个 “传话筒” 来沟通才行。想让系统能弄清楚，我们得把 “ wps 可以打开 word ” 文档这件事情，写到注册表里。
借助当时更为先进的数据库结构，注册表还能够实现**多用户配置和多线程读写等功能。**别看咱们现在嫌弃注册表长的丑，要知道当年，这可是少有的图形可视化界面。
注册表小解 按 win + R，在对话框里输入 regedit 来打开注册表编辑器。
HKEY_CLASSES_ROOT # 包含有关已注册应用程序的信息 ， 包括驱动 ， 文件拓展名等等 。 HKEY_CURRENT_USER # 存储特定于当前登录用户的设置 ， 包括环境变量 ， 个人桌面的设置等等 。 HKEY_LOCAL_MACHINE # 存储特定于本地计算机的设置 ， 由系统内核维护在内存中 ， 以便映射所有其他子键 。 这些信息可以其它用户使用 。 HKEY_USERS # 和上面的第二个项目相对 ， 包含与机器上主动加载的每个用户配置文件的 HKEY_CURRENT_USER 键对应的子键 HKEY_CURRENT_CONFIG # 该主键保存了计算机当前硬件的配置信息 ， 这些配置可以根据当前所连接的网络类型或硬件驱动软件安装的改变而改变 。 备份注册表 文件 - 导出</description></item><item><title>字段选择器</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/%E5%AD%97%E6%AE%B5%E9%80%89%E6%8B%A9%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/%E5%AD%97%E6%AE%B5%E9%80%89%E6%8B%A9%E5%99%A8/</guid><description>概述 参考：
官方文档，概念-概述-使用对象-字段选择器 Field selectors(字段选择器) 允许你根据一个或多个资源字段的值 筛选 Kubernetes 的 Object(对象)。 下面是一些使用字段选择器查询的例子：
metadata.name=my-service metadata.namespace!=default status.phase=Pending 下面这个 kubectl 命令将筛选出 status.phase 字段值为 Running 的所有 Pod：
kubectl get pods --field-selector status.phase=Running 说明：
字段选择器本质上是资源“过滤器（Filters）”。默认情况下，字段选择器/过滤器是未被应用的， 这意味着指定类型的所有资源都会被筛选出来。 这使得 kubectl get pods 和 kubectl get pods --field-selector &amp;quot;&amp;quot; 这两个 kubectl 查询是等价的。
支持的字段 不同的 Kubernetes 资源类型支持不同的字段选择器。 所有资源类型都支持 metadata.name 和 metadata.namespace 字段。 使用不被支持的字段选择器会产生错误。例如：
kubectl get ingress --field-selector foo.bar=baz Error from server (BadRequest): Unable to find &amp;#34;ingresses&amp;#34; that match label selector &amp;#34;&amp;#34;, field selector &amp;#34;foo.</description></item><item><title>字符的编码与解码</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</guid><description>概述 参考：
Wiki, Character encoding 阮一峰博客 公众号 - k8s 技术圈，计算机字符编码的前世今生 B 站 - 幼麟实验室，Golang 合辑-P1 string(这个 P 讲的就是字符的编码与解码) 我们知道计算机只认识二进制数据，其他格式的数据都需要转换成二进制才能被计算机处理，也就是说我们在计算机上看到的文本、视频、可执行程序等格式的文件，最终都会转换成二进制数据交给计算机处理
计算机中最小的数据单位是 bit，也叫二进制位(简称：位)，每一个 bit 都有 0 和 1 两种状态，最早的计算机在设计时采用了 8 个 bit 作为一个 Byte(字节)，所以一个字节能表示的最大整数就是二进制的 11111111 等于十进制的 255，一共 256 个数字(即.0~255)，想要表示更大的整数就必须要用多个字节，例如两个字节可以表示最大的整数就是二进制的 1111111111111111，共 16 位，等于十进制的 65535。
更多的字节，就可以表示更大的数值范围，比如 32 位，最大可以表示为 4,294,967,295，我们平时说的 32 位电脑、64 位电脑，也是同一个意思，所以就说 32 位电脑，没法传输 4 G 以上的文件，就是因为其最大可以表示的数字就是 4,294,967,295，更大的文件，已经无法识别了。整数可以这么表示，那么字符怎么办呢？一堆二进制的 0 和 1，任何计算都无法算出字母 A 吧？~o(╯□╰)o
聪明的人类啊。。。如果无法通过计算得到，那么就中转一下，人为规定就好了~比如：
字符 十进制编号 二进制编号 A 65 0100 0001 B 66 &amp;hellip;&amp;hellip; a 97 &amp;hellip;&amp;hellip; 要存储字符时，就存储这个数值；要读取字符时，按照映射关系，找到这个字符；就像这样，收录许多字符，然后给它们一一编号，得到一个字符与编号的对照表，这就是 Character sets(字符集)，经过这么多年的发展，大家对这个术语有很多种叫法：Character encoding(字符编码)、Character map(字符映射)、Code page(代码页) 都可以表示同一个概念。</description></item><item><title>自建CA并签署证书</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/%E8%87%AA%E5%BB%BACA%E5%B9%B6%E7%AD%BE%E7%BD%B2%E8%AF%81%E4%B9%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crypto-mgmt/%E8%87%AA%E5%BB%BACA%E5%B9%B6%E7%AD%BE%E7%BD%B2%E8%AF%81%E4%B9%A6/</guid><description>概述 参考：
主要依赖 genrsa, req, x509 这三个子命令
0. 设定变量 # CA 相关信息 export CA_KEY=&amp;#34;ca.key&amp;#34; export CA_CRT=&amp;#34;ca.crt&amp;#34; export CA_COMMON_NAME=&amp;#34;DesistDaydream-CA&amp;#34; # 需要签发的证书的相关信息 export SSL_COMMON_NAME=&amp;#34;desistdaydream.it&amp;#34; export SSL_KEY=${SSL_COMMON_NAME}.key export SSL_CSR=${SSL_COMMON_NAME}.csr export SSL_CRT=${SSL_COMMON_NAME}.crt 1. 创建根 CA 私钥 首先，创建一个强 RSA 私钥用于你的根 CA：
openssl genrsa -out ${CA_KEY} 4096 2. 创建根 CA 证书 使用生成的私钥创建自签名的根 CA 证书：
openssl req -x509 -new -nodes -key ${CA_KEY} -sha256 -days 3650 -out ${CA_CRT} \ -subj &amp;#34;/C=CN/CN=${CA_COMMON_NAME}&amp;#34; 在提示时需填写各项信息，其中最重要的是 Common Name (CN)，可以设为 &amp;ldquo;DesistDaydream-CA&amp;rdquo; 或类似名称。
3. 创建域名私钥 为你的通配符域名创建一个私钥：</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
让服务器成为路由器 这里假设想作为路由器的服务器的 IP 为 172.38.180.211
一、首先需要保证路由器具有 IP 转发能力，开启 IP 转发
echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward 二、保证路由器在收到局域网内其他设备的数据包时，将收到的 IP SNAT 为本机 IP。这有两种方法
方法一：手动 SNAT
export LOCAL_IP=&amp;#34;172.38.180.211&amp;#34; export LAN_CIDR=&amp;#34;172.38.180.0/24&amp;#34; iptables -t nat -A POSTROUTING -s ${LAN_CIDR} ! -d ${LAN_CIDR} -j SNAT --to-source ${LOCAL_IP} 如果 LOCAL_IP 直接就是公网 IP 的话，也就是这台服务器本身就有公网 IP 的话，那就更完美了。
方法二：自动 SNAT
iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 这条命令表示将 eth0 接口的出站流量进行伪装，i.e. 使用 eth0 接口的 IP 地址作为源地址。这样，内网的主机就可以通过本服务器访问外网了。
三、将内网服务器的网关设为这台服务器即可
我可以 ping 别人，别人不能 ping 我 iptables -A INPUT -p icmp &amp;ndash;icmp-type 8 -s 0/0 -j DROP # 默认 INPUT 链的策略为 ACCEPT 的时候用 iptables -A INPUT -p icmp &amp;ndash;icmp-type 0 -s 0/0 -j ACCEPT # 默认 INPUT 链的策略为 DROP 的时候用 iptables -A OUTPUT -p icmp &amp;ndash;icmp-type 0 -s LOCALIP -j DROP # 默认 OUTPUT 链的策略为 ACCEPT 的时候用，注意把 Localip 改为本机 IP iptables -A OUTPUT -p icmp &amp;ndash;icmp-type 8 -s LOCALIP -j ACCEPT # 默认 OUTPUT 链的策略为 DROP 的时候用，注意把 Localip 改为本机 IP 其他 屏蔽 HTTP 服务 Flood×××，有时会有用户在某个服务，例如 HTTP 80 上发起大量连接请求，此时我们可以启用如下规则：</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 基本新硬盘操作 创建 GPT 格式的分区表 parted /dev/vdb mktable gpt 为 /dev/vdb 创建一个主分区，大小是该磁盘的 0% 到 100%，设置名称为 data1 parted /dev/vdb mkpart data1 0% 100% 注意：尽量使用 % 来标识磁盘分区大小，否则会提示磁盘分区未对齐。若是显示命令无法显示百分比，则通过 unit 子命令将单位转换为 % 为 /dev/vdb1 创建 xfs 文件系统 mkfs.xfs /dev/vdb1 挂载文件系统 mount /dev/vdb1 /mnt/test 为新磁盘创建 LVM # 创建 GPT 格式的分区表 parted /dev/vdb mktable gpt # 为/dev/vdb分一个主分区，大小是该磁盘的0%到100% parted /dev/vdb mkpart lvm 0% 100% # 创建 PV pvcreate /dev/vdb1 # 创建 VG vgcreate vg-data /dev/vdb1 # 创建 LV lvcreate -l 100%FREE -n lv0 vg-data # 为 /dev/mapper/vg--data-lv0 创建 xfs 文件系统 mkfs.</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 这里的最佳实践，主要是使用 Libvirt 工具集对虚拟机的全生命周期进行管理。比如创建、修改、删除虚拟机。
最常用的工具是 virt-install、virsh 命令
通过 libvirt 远程管理虚拟机 通过 TCP 连接 参考：
StackOverflow，could-not-add-the-parameter-listen-to-open-tcp-socket libvirtd 官方手册 systemctl stop libvirtd.service
在 /etc/libvirt/libvirtd.conf 文件中添加 auth_tcp=&amp;quot;none&amp;quot;
让 libvirtd 监听本地 TCP 端口
systemctl enable libvirtd-tcp.socket --now systemctl start libvirtd.service
最后使用 virsh -c qemu+tcp://192.168.1.66/system 即可连接到远程 libvirtd
通过 SSH 连接 virsh -c qemu+ssh://root@192.168.1.166/system 配置URI别名 为了简化管理员的工作，可以在 libvirt 客户端配置文件中设置 URI 别名。对于 root 用户，配置文件为 /etc/libvirt/libvirt.conf；对于任何非特权用户，配置文件为 $XDG_CONFIG_HOME/libvirt/libvirt.conf。在此文件中，可以使用以下语法来设置别名
uri_aliases = [ &amp;#34;hail=qemu+ssh://root@hail.cloud.example.com/system&amp;#34;, &amp;#34;sleet=qemu+ssh://root@sleet.cloud.example.com/system&amp;#34;, ] URI 别名应该是由字符 a-Z、0-9、_、- 组成的字符串。 = 后面可以是任何 libvirt URI 字符串，包括任意 URI 参数。 URI 别名将应用于任何打开 libvirt 连接的应用程序，除非它已显式地将 VIR_CONNECT_NO_ALIASES 参数传递给 virConnectOpenAuth。如果传入的 URI 包含允许的别名字符集之外的字符，则不会尝试别名查找。</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/12.AI/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
AI是如何作画和修复老电影的？10分钟还你一个4K的青春。【AI原理解析系列】
为什么需要 AI ？跟传统搜索有什么区别？
比如想要搜索如下问题：
玩 XXX 游戏的时候，在游戏中正常，但是切出游戏使用其他程序时 CPU 使用率直接到 100%，再切回游戏又正常了 如果是传统搜索引擎，需要我们自己有一定基础，然后提炼其中的关键字，再从搜索结果中，逐步筛选想要的结果，但是用 AI 的话，直接把问题抛给 AI，AI 来处理，并对搜索到的结果进行总结
提示语 参考：
GitHub 项目，f/awesome-chatgpt-prompts GitHub 项目，PlexPt/awesome-chatgpt-prompts-zh 公众号-云原生小白，你应该知道的ChatGPT提示语 ChatGPT 对话中提示语可以极大影响对话质量。定义明确的提示语可以帮助确保我们的对话保持在正确的方向上。并涵盖用户感兴趣的上下文信息，从而带来较好的用户体验。
那么，什么是好的 ChatGPT 提示语，以及我们如何制作有效的提示语？有几个关键原则需要记住。
明确性。清晰简洁的提示将有助于确保 ChatGPT 理解当前的对话主题。避免使用过于复杂或模棱两可的语言。 重点。一个明确的提示语应该有明确的目的和重点，避免使用过于宽泛或开放式的提示，这可能会导致对话不连贯或方向失控。 相关性。确保你的提示语与当前对话相关。避免引入不相关的话题或切入点分散ChatGPT 的焦点 遵循这些原则，我们就可以制作有效的 ChatGPT 提示语。并以此推动产生一个富有吸引力和质量上层的对话体验。
案例分析 为了更好的理解 ChatGPT 提示语，我们来看看一些非常成功的案例
英语翻译和改进者 下面我让你来充当翻译家，你的目标是把任何语言翻译成中文，请翻译时不要带翻译腔，而是要翻译得自然、流畅和地道，使用优美和高雅的表达方式。请翻译下面这句话：“how are you ?”
担任面试官 我想让你充当面试官。我将是候选人，你将向我提出该职位的面试问题。我希望你只以面试官的身份回答。不要一下子写出所有的问题。我希望你只对我进行面试。问我问题，并等待我的回答。不要写解释。像面试官那样一个一个地问我问题，并等待我的回答。我的第一句话是 &amp;ldquo;你好面试官&amp;rdquo;
在这个例子中，ChatGPT 被当做面试官，它需要先提出问题并等待用户回答。这个提示是非常具体的和有针对性的概述让 ChatGPT 进行人物角色扮演，和对对话场景的模拟。
旅游指南 我想让你充当一个旅游向导。我将给你写下我的位置，你将为我的位置附近的一个地方提供旅游建议。在某些情况下，我也会告诉你我要访问的地方的类型。你也会向我推荐与我的第一个地点相近的类似类型的地方。我的第一 个建议请求是&amp;quot;我在成都，我只想看大熊猫&amp;quot;
在这个例子中，ChatGPT 被用作旅游指南，根据具体地点和地方类型提供参观建议。该提示语也是具有有针对性的，清楚地概述了对当前对话的期望。
作为专业DBA 贡献者：墨娘
我要你扮演一个专业DBA。我将提供给你数据表结构以及我的需求，你的目标是告知我性能最优的可执行的SQL语句，并尽可能的向我解释这段SQL语句，如果有更好的优化建议也可以提出来。
我的数据表结构为:
CREATE TABLE user ( id int NOT NULL AUTO_INCREMENT, name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT &amp;rsquo;&amp;rsquo; COMMENT &amp;lsquo;名字&amp;rsquo;, PRIMARY KEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT=&amp;lsquo;用户表&amp;rsquo;;</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
妙用SSH端口转发 例一：转发 windows 服务器的远程桌面 在本地电脑上打开 PowerShell，输入如下命令（参数需要自己修改，参见上一节的解释）：
ssh -L 10080:&amp;lt;内网Windows服务器IP&amp;gt;:3389 user@123.123.123.123 -p 6001 上面这条命令使用帐号 user 登录了 123.123.123.123 的 6001 端口对应的服务器(192.168.0.123)，并在该服务器上建立一个 ssh 转发，将本地计算机(127.0.0.1，localhost)的10080端口映射到了 &amp;lt;内网Windows服务器IP&amp;gt; 的 3389 端口。 回车后，提示输入密码，输入账号 user 在192.168.0.123服务器密码。 登录后不要关闭 Powershell 窗口，否则转发会中断。
之后便可以用本地地址访问 windows 服务器的远程桌面。
为了节约带宽并提高流畅度，可以把桌面背景改成纯色，可以把颜色深度调低，还可以把显示配置里的分辨率调小，一般使用 1600*900 分辨率。 PS：如果是高分屏觉得此分辨率看不清楚可以使用远程桌面自带的缩放功能。在标题栏上点右键即可。
同理，如果局域网的个人电脑也开启了远程桌面功能，也可以用这种办法访问。 RDP 协议优化是是很好的，这种办法 1 Mbps 的带宽就可以获得比较流畅的体验
例二：转发目标服务器的 web 服务 tensorboard 和 jupyter notebook 使用的是 http 协议，可以通过端口转发来访问。
打开 Powershell，输入如下命令
ssh -L 28186:localhost:28888 user@123.123.123.123 -p 6001 上面这条命令使用帐号 user 登录了 123.123.123.123 的 6001 端口对应的服务器(192.</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E7%AE%A1%E7%90%86/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E7%AE%A1%E7%90%86/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
标签设计最佳实践: https://grafana.com/docs/loki/latest/get-started/labels/bp-labels/
公众号 - 云原生小白，Loki中的标签简明指南（译）
https://grafana.com/blog/2020/08/27/the-concise-guide-to-labels-in-loki/ 最近很多同学的 Loki 在上线过程中经常遇见丢日志的情况，一查 Loki 日志的发现是日志流的时序问题导致的。这也从侧方面反映出大家对 Loki 的日志流和标签之间的关系还是明确清楚。几个月前，偶然看见博客上原作者对 Loki 标签有过简明指南，深感有责任翻译给大家，用于理解这部分概念。由于原文写于 Loki1.x 时代，译文对于部分于差异的部分进行了相关删减，如小伙伴们要阅读原文，点击文末【阅读原文】即可
作为 Loki 的用户或操作员，我们的目标应该是使用尽可能少的标签来存储你的日志。
这意味着，更少的标签带来更小的索引，从而导致更好的性能 再重复一遍 更少的标签=更好的性能
这可能听起来有悖直觉。大部分数据库的管理经验告诉我们，如果你想让查询更加快速，我们通常通过需要建立更多的索引。但是，Loki 是以完全相反的方式构建和优化的。我们围绕 Loki 的设计初衷是为了保持运营成本和复杂性低，这是通过保持一个非常小的索引和利用硬件能力和并行化运算来实现的。
因此，作为 Loki 的用户或操作者，我们在添加标签之前一定要三思而行。
我举个例子：
ts=2020-08-25T16:55:42.986960888Z caller=spanlogger.go:53 org_id=29 traceID=2612c3ff044b7d02 method=Store.lookupIdsByMetricNameMatcher level=debug matcher=&amp;#34;pod=&amp;#34;loki-canary-25f2k/&amp;#34;&amp;#34; queries=16 我们应该通过 TraceID 查询所有日志？
你可能会想，&amp;ldquo;我应该提取 traceID 作为标签&amp;rdquo;，然后我可以这样查询。
{cluster=&amp;#34;ops-cluster-1&amp;#34;,namespace=&amp;#34;loki-dev&amp;#34;, traceID=”2612c3ff044b7d02”} 千万不要这样做! 我们要避免将日志中的内容提取成标签！如果你想在你的日志中找到高基的数据，可以使用下面这样的过滤表达式。
{cluster=&amp;#34;OPS-cluster-1&amp;#34;,namespace=&amp;#34;loki-dev&amp;#34;} |= &amp;#34;traceID=2612c3ff044b7d02&amp;#34; 但是如果标签是一个较低的基数怎么办？如果把日志级别提取到标签中，而我们的日志级别只有五个值，怎么办？
{cluster=&amp;#34;OPS-cluster-1&amp;#34;,namespace=&amp;#34;loki-dev&amp;#34;, level=&amp;#34;debug&amp;#34;} 在这里要小心！记住标签对索引和存储有多重的, 增加一个标签，那么对Loki的索引和存储有倍增的效应。一开始是我们是一个日志流，现在变成了多达五个流（按照日志级别）。然后我们考虑是否添加另一个标签？但是不幸的是，即使它只有几个值，事情也会很快失控。
相反，我们应该按照过滤表达式如下编写 LogQL 语法：
{cluster=&amp;#34;OPS-cluster-1&amp;#34;,namespace=&amp;#34;loki-dev&amp;#34;} |= &amp;#34;level=debug&amp;#34; |= &amp;#34;status=200&amp;#34; |= &amp;#34;path=/api/v1/query&amp;#34; 是否可以将日志内容提取为标签？</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
Vermouth 博客，高可用 Prometheus 问题集锦 几点原则 监控是基础设施，目的是为了解决问题，不要只朝着大而全去做，尤其是不必要的指标采集，浪费人力和存储资源（To B 商业产品例外）。 需要处理的告警才发出来，发出来的告警必须得到处理。 简单的架构就是最好的架构，业务系统都挂了，监控也不能挂。Google Sre 里面也说避免使用 Magic 系统，例如机器学习报警阈值、自动修复之类。这一点见仁见智吧，感觉很多公司都在搞智能 AI 运维。 不要把随机值放在 Label 中 这里强烈建议不要把随机值，或者变化较快的值放在 label 里，如 timestamp，request_args，thread_id 等等，这是因为只要 label 的值一变，就会产生另外一个 Series，而 Prometheus 或者类 Prometheus 的监控系统，都会把近期出现的 Series 信息缓存在内存中，如果短期内出现大量 Series，可能导致系统 OOM。（俗称：高基数问题） 注意：如果想记录一些经常变动的 Label 集合，应该使用日志系统，而不是监控系统 Prometheus 的局限 Prometheus 是基于 Metric 的监控，不适用于日志（Logs）、事件 (Event)、调用链 (Tracing)。 Prometheus 默认是 Pull 模型，合理规划你的网络，尽量不要转发。 对于集群化和水平扩展，官方和社区都没有银弹，需要合理选择 Federate、Cortex、Thanos 等方案。 监控系统一般情况下可用性大于一致性，容忍部分副本数据丢失，保证查询请求成功。这个后面说 Thanos 去重的时候会提到。 Prometheus 不一定保证数据准确，这里的不准确一是指 rate、histogram_quantile 等函数会做统计和推断，产生一些反直觉的结果，这个后面会详细展开。二来查询范围过长要做降采样，势必会造成数据精度丢失，不过这是时序数据的特点，也是不同于日志系统的地方。 Prometheus 容量规划 容量规划除了上边说的内存，还有磁盘存储规划，这和你的 Prometheus 的架构方案有关。
如果是单机 Prometheus，计算本地磁盘使用量。 如果是 Remote-Write，和已有的 Tsdb 共用即可。 如果是 Thanos 方案，本地磁盘可以忽略（2H)，计算对象存储的大小就行。 Prometheus 每 2 小时将已缓冲在内存中的数据压缩到磁盘上的块中。包括 Chunks、Indexes、Tombstones、Metadata，这些占用了一部分存储空间。一般情况下，Prometheus 中存储的每一个样本大概占用 1-2 字节大小（1.</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Crawler/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 项目示例 https://github.com/lixi5338619/lxSpider 爬虫案例合集
https://github.com/onepureman/spider_draft 各种网站的登陆破解，仅供交流学习
https://github.com/Zero-S1/awesome-python-login-model python模拟登陆一些大型网站，还有一些简单的爬虫
https://github.com/rip-tyang/trend-archive # 来自不同网站的存档热/趋势主题/视频/等。Bilibili 的热门
裁判文书网 检索到想要的文书后如何批量下载？
参考: https://www.bilibili.com/video/BV1zg411a7cN （2023年12月2日10:08:12 已失效）
button=document.getElementsByClassName(&amp;#34;a_xzBox&amp;#34;) for (let i = 0; i&amp;lt;=5; i++){setTimeout(() =&amp;gt;button[i].click(),1000 *i)}</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Playbook/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
使用 Inventory 变量 一、指定多个 inventory，并使用 &amp;ndash;limit 限定主机
ansible-playbook -i inventory/fj-server.yaml -i inventory/fj-client.yaml deploy-monitoring.yaml --limit FJ-BS101-JMR-Monitor 模板使用方式（直接使用 groups, hostvars 这两个变量）
{% for target in groups[&amp;#39;intf&amp;#39;] %} {{ hostvars[target][&amp;#39;ansible_host&amp;#39;] }} {% endfor %} 二、使用 include_vars 加载
deploy-test.yaml
- hosts: fj-server gather_facts: no pre_tasks: - name: &amp;#34;加载 client inventory&amp;#34; ansible.builtin.include_vars: file: inventory/fj-client.yaml # 读取该文件，将其中内容作为变量使用 name: client_inventory # 这些变量的父级字段名称 roles: - test tasts/main.yaml
- name: &amp;#34;检查变量&amp;#34; ansible.builtin.debug: msg: &amp;#34;{{ item[&amp;#39;ansible_host&amp;#39;] }}&amp;#34; with_items: # 要使用 valuse() 函数 - &amp;#34;{{ client_inventory[&amp;#39;intf&amp;#39;].</description></item><item><title>Best practices</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/Best-practices/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/WireShark/Best-practices/</guid><description>概述 参考：
从 pcap 文件中还原出原始文件 一个文件本身是一堆 Bytes 的组合，而 pcap 中每个 tcp 之类的包的 payload 包含的就是文件传输时文件的所有 Bytes，只不过被拆分到多个包中
首先使用 _ws.col.info contains &amp;quot;TCP segment of a reassembled PDU&amp;quot; 过滤出来所有被分片的包（这些通常都是包含文件的包）
选中其中一个包，按 ctrl + alt + shift + t 快捷键，追踪该包所述的 TCP 流
一个文件本质上就是红框中的内容（只不过这里把 Bytes 以 ASCII 表示，所以人类不可读）
在窗口下方选择该会话其中一个方向，并选择原始数据后，点击另存为，就保存下来文件了。假如命名为 response_file.hex
此时我们需要做的就是想办法把该文件开头/结尾不需要的部分去掉 (●ˇ∀ˇ●)
使用 Visual Studio Code 安装一个十六进制编辑器的插件，并用打开 response_file.hex 会看到如下内容。
我们需要把 HTTP 的 Header 删掉，根据 WireShark 的 TCP 流看，HTTP Header 后面跟着两个换行（从 ASCII 表 查时 0D 0A），所以也就是截止到 50 4B 之前的所有内容都要删掉</description></item><item><title>dell硬件监控OMSA</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/dell%E7%A1%AC%E4%BB%B6%E7%9B%91%E6%8E%A7OMSA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/dell%E7%A1%AC%E4%BB%B6%E7%9B%91%E6%8E%A7OMSA/</guid><description>OMSA（全称 Openmanage Server Administrator),是戴尔公司自主研发的 IT 系统管理解决方案 http://linux.dell.com/
OMSA 的安装 自动安装 https://linux.dell.com/repo/hardware/dsu/
配置存储库 curl -O https://linux.dell.com/repo/hardware/dsu/bootstrap.cgi bash bootstrap.cgi yum install srvadmin-all.x86_64 Note：
srvadmin-base # 代理程序，可以生成 snmp 信息 srvadmin-server-cli # 命令行客户端，可以通过命令行查看硬件信息 srvadmin-storage-cli # 存储资源的命令行客户端，不安装这个则无法获取 raid 和硬盘的数据 下面是使用 yum 安装 OMSA 的 repo 文件
~]# cat /etc/yum.repos.d/DELL-OMSA.repo [dell-system-update_independent] name=dell-system-update_independent baseurl=https://linux.dell.com/repo/hardware/dsu/os_independent/ gpgcheck=1 gpgkey=https://linux.dell.com/repo/hardware/dsu/public.key https://linux.dell.com/repo/hardware/dsu/public_gpg3.key enabled=1 exclude=dell-system-update*.i386 [dell-system-update_dependent] name=dell-system-update_dependent mirrorlist=https://linux.dell.com/repo/hardware/dsu/mirrors.cgi?osname=el$releasever&amp;amp;basearch=$basearch&amp;amp;native=1 gpgcheck=1 gpgkey=https://linux.dell.com/repo/hardware/dsu/public.key https://linux.dell.com/repo/hardware/dsu/public_gpg3.key enabled=1 参考文章：http://www.madown.com/2017/05/23/81/
手动安装 https://www.dell.com/support/home/去该网站输入主机号查询，然后根据关键字搜索 OMSA 并下载
解压已下载的安装包 mkdir dell-omsa tar -zxvf OM-SrvAdmin-Dell-Web-LX-9.3.0-3465_A00.tar -C dell-omsa # 安装 rpm 包 cd dell-omsa/linux/RPMS/supportRPMS/srvadmin/RHEL7/x86_64 yum localinstall *.</description></item><item><title>Headscale</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Headscale/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Headscale/</guid><description>概述 参考：
GitHub 项目，juanfont/headscale 公众号 - 云原声实验室，Tailscal 开源版本让你的 WireGuard 直接起飞 馆长博客，headscale 搭建和应用场景 Tailscale 的控制服务器是不开源的，而且对免费用户有诸多限制，这是人家的摇钱树，可以理解。好在目前有一款开源的实现叫 Headscale，这也是唯一的一款，希望能发展壮大。
Headscale 由欧洲航天局的 Juan Font 使用 Go 语言开发，在 BSD 许可下发布，实现了 Tailscale 控制服务器的所有主要功能，可以部署在企业内部，没有任何设备数量的限制，且所有的网络流量都由自己控制。
目前 Headscale 还没有可视化界面，期待后续更新吧。
Headscale 部署 理论上来说只要你的 Headscale 服务可以暴露到公网出口就行，但最好不要有 NAT，所以推荐将 Headscale 部署在有公网 IP 的云主机上。
安装程序与应用配置 准备一些环境变量
export HeadscaleVersion=&amp;#34;0.22.3&amp;#34; export HeadscaleArch=&amp;#34;amd64&amp;#34; # 各个 Tailscale 节点与 Headscale 通信的 IP export HeadscaleAddr=&amp;#34;https://X.X.X.X:YYY&amp;#34; 准备 Headscale 相关文件及目录。从 GitHub 仓库的 Release 页面下载最新版的二进制文件。
wget --output-document=/usr/local/bin/headscale \ https://github.com/juanfont/headscale/releases/download/v${HeadscaleVersion}/headscale_${HeadscaleVersion}_linux_${HeadscaleArch} chmod +x /usr/local/bin/headscale 创建相关目录及文件
mkdir -p /etc/headscale mkdir -p /var/lib/headscale touch /var/lib/headscale/db.</description></item><item><title>Kubernetes 开源社区指南</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E6%8C%87%E5%8D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E6%8C%87%E5%8D%97/</guid><description>概述 参考：
如何玩转 Kubernetes 开源社区？这篇文章一定要看！
近日，「DaoCloud 道客」成功进入 Kubernetes 开源榜单累计贡献度全球前十，亚洲前三。基于在 Kuberntes 开源社区的长期深耕细作，「DaoCloud 道客」积累了一些心得，特写此文章，旨在帮助对开源贡献感兴趣的同学快速⼊⻔，并为之后的进阶之路提供⼀些参考和指导意义。
这⼀章节，你将了解整个 Kubernetes 社区是如何治理的：
1.1. 分布式协作 与公司内部集中式的项⽬开发模式不同，⼏乎所有的开源社区都是⼀个分布式、松散的组织，为此 ，Kubernetes 建⽴了⼀套完备的社区治理制度。协作上，社区⼤多数的讨论和交流主要围绕 issue 和 PR 展开。由于 Kubernetes ⽣态⼗分繁荣，因此所有对 Kubernetes 的修改都⼗分谨慎，每个提交的 PR 都需要通过两个以上成员的 Review 以及经过⼏千个单元测试、集成测试、端到端测试以及扩展性测试，所有这些举措共同保证了项⽬的稳定。
1.2. Committees 委员会由多人组成，主要负责制定组织的行为规范和章程，处理一些敏感的话题。常见的委员会包括行为准则委员会，安全委员会，指导委员会。
1.3. SIG SIG 的全称是 Special Interest Group，即特别兴趣⼩组，它们是 Kubernetes 社区中关注特定模块的永久组织，Kubernetes 作为⼀个拥有⼏⼗万⾏源代码的项⽬，单⼀的⼩组是⽆法了解其实现的全貌的。Kubernetes ⽬前包含 20 多个 SIG，它们分别负责了 Kubernetes 项⽬中的不同模块，这是我们参与 Kubernetes 社区时关注最多的⼩组。作为刚刚参与社区的开发者，可以选择从某个 SIG 入手，逐步了解社区的⼯作流程。
1.4. KEP KEP 的全称是 Kubernetes Enhancement Proposal，因为 Kubernetes ⽬前已经是⽐较成熟的项⽬了，所有的变更都会影响下游的使⽤者，因此，对于功能和 API 的修改都需要先在 kubernetes/enhancements 仓库对应 SIG 的⽬录下提交提案才能实施，所有的提案都必须经过讨论、通过社区 SIG Leader 的批准。</description></item><item><title>WSL</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/WSL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/WSL/</guid><description>概述 参考：
GitHub 项目，microsoft/WSL 官方文档，windows-wsl 安装 WSL 现在默认使用 WSL2，也推荐安装和使用 WSL2。
打开 “启用或关闭Windows功能”，开启 “适用于 Linux 的 Windows 子系统” 和 “虚拟机平台”。
之后在 Microsoft Store 中使用 Windows Susystem for Linux 关键字搜索并安装 WSL 的最新版。
若不开启“虚拟机平台” 或 安装最新版 WSL，在安装后启动时，将可能会出现下图错误
安装 Linux 发行版 在 PowerShell 执行指令
安装 Ubuntu 发行版的 WSL
wsl --install -d Ubuntu 常见问题 若安装后 linux 无法启动，报错：WslRegisterDistribution failed with error: 0x800701bc
（可选）设置 wsl 版本
wsl --set-default-version 2 忘记密码时，可以在 PowerShell 中使用 wsl 命令直接以 root 用户登录 wsl</description></item><item><title>WSL 配置详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/WSL-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/WSL-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，WSL 配置 wsl.conf 和 .wslconfig 是 INI 格式的配置文件，两者互相配合以定义 WSL 虚拟机的运行方式
wsl.conf 是在每个 WSL 中的 Linux 发行版内部的配置。通常是指 本地配置（tips: 本地配置就是指在 WSL 系统中，也就是 Linux 系统中的配置） .wslconfig 是在 Windows 中为所有 WSL发行版配置。通常是指 全局配置 wsl.conf boot systemd(BOOLEAN) # 是否启用 systemd
.wslconfig .wslconfig 包含两个部分: wsl2 和 experimental
[wsl2] https://learn.microsoft.com/en-us/windows/wsl/wsl-config#main-wsl-settings
networkingMode(STRING) # 如果该值是 mirrored，则这将打开镜像网络模式。默认值: NAT
mirrored 会让虚拟机镜像本地网络。WSL2 和 Windows 主机的网络互通而且 IP 地址相同了，还支持 IPv6 了，并且从外部（比如局域网）可以同时访问 WSL2 和 Windows 的网络。这波升级彻底带回以前 WSL1 那时候的无缝网络体验了，并且 Windows 防火墙也能过滤 WSL 里的包了，再也不需要什么桥接网卡、端口转发之类的操作了。 dnsTunneling(BOOLEAN) # 更改 DNS 请求从 WSL 代理到 Windows 的方式。默认值: false</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Glossary/</guid><description>概述 参考：
官方文档，参考 - 术语 Declarative Application Management https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/declarative-application-management.md
Declarative Application Management(声明式应用管理) 是一种部署和管理应用程序的方式。
kubeconfig https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/
kubeconfig 是用于保存集群访问信息的文件，这是引用配置文件的通用方法，并不表示一定会有一个名为 kubeconfig 的文件。
kubeconfig 文件用来组织有关集群、用户、明哼空间的信息和身份验证机制。kubectl 命令行工具使用 kubeconfig 文件来与 Kubernetes 集群进行交互。Kuberntes 集群的某些主要组件，也会使用 kubeconfig 文件进行交互，比如使用 kubeadm 工具部署的 kubernetes 集群，在每个节点的 /etc/kubernetes 目录下，就会有以 .conf 文件结尾的 kubeconfig 文件，以供 kubelet、scheduler、controller-manager 等组件使用。
Manifest https://kubernetes.io/docs/reference/glossary/?fundamental=true#term-manifest
JSON 或 YAML 格式的 Kubernetes API 对象的规范。
manifest 指定了应用该 manifest 时，Kubernetes 将维护的对象的所需状态。每个配置文件可以包含多个清单</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/12.AI/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Glossary/</guid><description>概述 参考：
B 站，一口气通关大模型的 100 个关键词 Synmbolism(符号主义)
Connectionism(联结主义)
Model(模型) # 函数
Weight(权重) # 函数里的参数
Large Model(大模型) # 参数量特别大的模型
Robustness(鲁棒性) # 模型不因输入的一点点小的变化，导致结果产生很大的波动
fitting(拟合)/overfitting(过拟合) 与 泛化性 # 下图红线拟合得较好；蓝线过拟合。过拟合之后，该模型无法处理非训练样本外的其他数据了。神经网络层数多到某个限度之后，将会过拟合
B 站，【漫士】为什么刷题想得越多，考得反而越差？ https://www.bilibili.com/video/BV1RqXRYDEe2?t=15.0 过拟合 是指 “分析结果与特定数据集过于接近或完全一致，因此可能无法拟合其他数据或可靠地预测未来的观测值”，所以过拟合了就缺少泛化性。
Training(训练) # 调整模型参数的过程
Pre-training(预训练) # “事先训练” 好一个基础模型的方式
Fine-tuning(微调) # 基于预训练的模型“继续训练”，让模型学会具体的任务的方式
Inference(推理) # 参数调整好后，根据函数的输入计算输出结果这个过程
Emergence(涌现) # 量变引起质变，而突然出现的以前没有的能力的现象
Generative Pre-trained Transformer(生成式预训练变换器，简称 GPT)
训练过程 权重 Closed-source Model 闭源模型 × × Open-weight Model 开放权重模型 × √ Open-source Model 开源模型 √ √ Generative AI(生成式 AI) #</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/Web/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Glossary/</guid><description>概述 参考：
Window Window(窗口) # 打开浏览器就相当于打开了一个窗口，这个窗口是用户可以在显示器上直接看到的，可以最小化、最大化、移动、关闭。这是 Windows 系统常用的术语。
User-Agent https://en.wikipedia.org/wiki/User_agent
User-Agent(用户代理) # 在我们发送一个请求时，User-Agent 是可以表示用户的代理方（proxy）。大多数情况下，这个用户代理都是一个浏览器，不过它也可能是任何东西，比如一个爬取网页来充实、维护搜索引擎索引的机器 Crawler(爬虫)（其实就是代码写的具有发起 HTTP 请求的程序，毕竟浏览器也是代码写的）。说白了，任何可以发起 HTTP 请求的都可以称为 User-Agent。</description></item><item><title>WSA</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/WSA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows-%E7%AE%A1%E7%90%86/WSA/</guid><description>概述 参考：
GitHub 项目，microsoft/WSA 官方文档，windows-android-wsa [!Warning] 微软将在 2025 年 3 月 5 日停止支持 WSA。Learn more.
Windows Subsystem for Android with Amazon Appsotre
WSA 管理器若没有打开任何应用、文件管理等功能，过一会会自动关闭 WSA，此时 adb 工具也连接不上，要想保持连接，至少要开着一个 WSA 系统中的功能。
关联文件与配置 %LOCALAPPDATA%/Packages/MicrosoftCorporationII.WindowsSubsystemForAndroid_8wekyb3d8bbwe/ # 安装目录？数据保存目录？
在浏览器或资源管理器的导航栏中输入 wsa://com.android.settings 即可打开像手机设置一样的 WSA 安卓设置。
安装 WSA 参考：
秋风于渭水，win11 安卓子系统（WSA）ROOT安装面具（Magisk）与谷歌框架（Google Apps） bitxeno&amp;rsquo;s notes，通过 WSA 抓取 android 的 https 网络请求包 吾爱破解，[Android Tools] WSA with Magisk Root安装配置教程(2023.5) Notes: 截至 2024.1.13，微软官方还未向中国地区推送 WSA，在商店搜索不到，就算通过网页上的商店连接打开电脑上的 Microsoft Store，一会提示所在地去不可用，所以需要先修改系统中的 国际或地区
“系统设置”→“时间和语言”→“语言和区域”→“区域”→“国家或地区”，选择「美国」
Notes: 如果系统中的 Microsoft Store 搜不到 WSA，可以通过下面的网页链接打开 Microsoft Store 对应的页面进行安装</description></item><item><title>硬核致敬Linux ！30岁生日快乐！</title><link>https://desistdaydream.github.io/blog/copy/cE4x63tYxoqrDinifeWqeg/</link><pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/cE4x63tYxoqrDinifeWqeg/</guid><description>原文链接：https://mp.weixin.qq.com/s/cE4x63tYxoqrDinifeWqeg
1991年8月25日，21岁的Linus Torvalds（以下简称Linus）做了一个免费的操作系统“Linux”，并在这一天向外界公布这个由“业余爱好”主导的个人项目；如今，全球超级计算机500强和超过70%的智能手机都在运行Linux，因此，8月25日也被许多Linux的爱好者视为Linux真正的诞生日期。
你好 30 年前，Linus Torvalds 首次发布 Linux 内核时还是赫尔辛基大学的一名 21 岁学生。他的声明是这样开始的，“我正在做一个（免费的）操作系统（只是一个爱好，不会很大和专业&amp;hellip;&amp;hellip;）”。三十年后，排名前 500 的超级计算机都在运行 Linux，所有智能手机的 70% 以上都是如此。Linux 显然既庞大又专业。
三十年来，Linus Torvalds 领导了 Linux 内核开发，激励了无数其他开发人员和开源项目。2005 年，Linus 还创建了 Git来帮助管理内核开发过程，此后它成为最受欢迎的版本控制系统，受到无数开源和专有项目的信赖。
Linux历史 OS史前历史
Linux的历史
Linux系统 Linux系统软件架构
Linux系统由硬件、kernel、系统调用、shell、c库、应用程序组成，架构层次分明，Linux内的各种层功能独立，程序在用户空间和内核空间之间的分离，能支持更多应用。
| 用户模态 | 用户应用 | 例如：Bash，LibreOffice，GIMP，Blender，0 A.D.，Mozilla Firefox等 | | 低层系统构件 | 系统守护进程：
systemd，runit，logind，networkd，PulseAudio等 | 窗口系统：
X11，Wayland，SurfaceFlinger(Android) | 其他库：
GTK+, Qt, EFL, SDL, SFML, FLTK, GNUstep等 | 图形：
Mesa，AMD Catalyst等 | | C标准库 | open()，exec()，sbrk()，socket()，fopen()，calloc()，&amp;hellip; (直到2000个子例程)
glibc目标为POSIX/SUS兼容，musl和uClibc目标为嵌入式系统，bionic为Android而写等 | | 内核模态 | Linux内核 | stat, splice, dup, read, open, ioctl, write, mmap, close, exit等（大约380个系统调用）</description></item><item><title>ext 文件系统机制原理剖析</title><link>https://desistdaydream.github.io/blog/copy/ext_filesystem/</link><pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/ext_filesystem/</guid><description>原文链接：https://www.junmajinlong.com/linux/ext_filesystem/
回到 Linux 基础系列文章大纲
回到 Shell 系列文章大纲
将磁盘进行分区，分区是将磁盘按柱面进行物理上的划分。划分好分区后还要进行格式化，然后再挂载才能使用 (不考虑其他方法)。格式化分区的过程其实就是创建文件系统。
文件系统的类型有很多种，如 CentOS 5 和 CentOS 6 上默认使用的 ext2/ext3/ext4，CentOS 7 上默认使用的 xfs，windows 上的 NTFS，光盘类的文件系统 ISO9660，MAC 上的混合文件系统 HFS，网络文件系统 NFS，Oracle 研发的 btrfs，还有老式的 FAT/FAT32 等。
本文将非常全面且详细地介绍 ext 家族的文件系统，中间还非常详细地介绍了 inode、软链接、硬链接、数据存储方式以及操作文件的理论，基本上看完本文，对文件系统的宏观理解将再无疑惑。ext 家族的文件系统有 ext2/ext3/ext4，ext3 是有日志的 ext2 改进版，ext4 对相比 ext3 做了非常多的改进。虽然 xfs/btrfs 等文件系统有所不同，但它们只是在实现方式上不太同，再加上属于自己的特性而已。
block 的出现 硬盘最底层的读写 IO 一次是一个扇区 512 字节，如果要读写大量文件，以扇区为单位肯定很慢很消耗性能，所以硬盘使用了一个称作逻辑块的概念。逻辑块是逻辑的，由磁盘驱动器负责维护和操作，它并非是像扇区一样物理划分的。一个逻辑块的大小可能包含一个或多个扇区，每个逻辑块都有唯一的地址，称为 LBA。有了逻辑块之后，磁盘控制器对数据的操作就以逻辑块为单位，一次读写一个逻辑块，磁盘控制器知道如何将逻辑块翻译成对应的扇区并读写数据。
到了 Linux 操作系统层次，通过文件系统提供了一个也称为块的读写单元，文件系统数据块的大小一般为 1024bytes (1K) 或 2048bytes (2K) 或 4096bytes (4K)。文件系统数据块也是逻辑概念，是文件系统层次维护的，而磁盘上的逻辑数据块是由磁盘控制器维护的，文件系统的 IO 管理器知道如何将它的数据块翻译成磁盘维护的数据块地址 LBA。对于使用文件系统的 IO 操作来说，比如读写文件，这些 IO 的基本单元是文件系统上的数据块，一次读写一个文件系统数据块。比如需要读一个或多个块时，文件系统的 IO 管理器首先计算这些文件系统块对应在哪些磁盘数据块，也就是计算出 LBA，然后通知磁盘控制器要读取哪些块的数据，硬盘控制器将这些块翻译成扇区地址，然后从扇区中读取数据，再通过硬盘控制器将这些扇区数据重组写入到内存中去。</description></item><item><title>Tailscale: How it works</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale-How-it-works/</link><pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/Tailscale/Tailscale-How-it-works/</guid><description>Blog 博客 | 三月 20, 2020
How Tailscale works Tailscale 工作原理 People often ask us for an overview of how Tailscale works. We’ve been putting off answering that, because we kept changing it! But now things have started to settle down.
人们经常要求我们概述 Tailscale 的工作原理。我们一直推迟回答这个问题，因为我们的架构在不断演进！但现在系统已逐渐趋于稳定。
Let’s go through the entire Tailscale system from bottom to top, the same way we built it (but skipping some zigzags we took along the way). With this information, you should be able to build your own Tailscale replacement… except you don’t have to, since our node software is open source and we have a flexible free plan.</description></item><item><title/><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/%E6%9C%AA%E5%91%BD%E5%90%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/%E6%9C%AA%E5%91%BD%E5%90%8D/</guid><description/></item><item><title/><link>https://desistdaydream.github.io/docs/Standard/Internet/RFC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Internet/RFC/</guid><description>概述 参考：
Wiki, RFC RFC 存储库搜索 RFC Editor 存储库搜索 Request for Comments(征求意见，简称 RFC) 是互联网协会（ISOC）及其相关机构的出版物，最突出的互联网工程工作组（IETF），互联网的主要技术开发和标准制定机构。
RFC 文档阅读方法 参考：
知乎 Obsoleted by: NUM # 是当前文档的下一版。可以描述为：当前文档被 NUM 淘汰。也就是说：对于 NUM 文档来说，当前文档已过时。 Updated by: NUM # 是当前文档的早期版本。可以描述为：当前文档被 NUM 更新。也就是说：对于 NUM 文档来说，当前文档是已更新的。 Obsoletes: NUM # 对于当前版本，NUM 是过时的 Updates: NUM # 对于当前版本，NUM 是最新的 如何阅读 RFC 来源： How to read RFC?
无论好坏，请求注释文档（RFC）包含了我们在 Internet 上遇到的许多协议。这些 RFC 文档被开发人员视为圣经，他们会试着去发现隐藏的含义，即使无法理解也无关紧要。虽然这通常会导致挫败感 - 但更重要的是 - RFC 其中的操作性和安全性思考。 然而，根据我对 HTTP 和其他一些事情的经验和收获，我们通过对 RFC 如何构建和发布的一些了解，可以更容易理解正在查看的 RFC 内容。</description></item><item><title>【BPF网络篇系列-2】容器网络延时之 ipvs 定时器篇 | 深入浅出 eBPF</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF%E7%BD%91%E7%BB%9C%E7%AF%87%E7%B3%BB%E5%88%97-2%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%BB%B6%E6%97%B6%E4%B9%8B-ipvs-%E5%AE%9A%E6%97%B6%E5%99%A8%E7%AF%87-_-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-eBPF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF%E7%BD%91%E7%BB%9C%E7%AF%87%E7%B3%BB%E5%88%97-2%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%BB%B6%E6%97%B6%E4%B9%8B-ipvs-%E5%AE%9A%E6%97%B6%E5%99%A8%E7%AF%87-_-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-eBPF/</guid><description>1. 前言 趣头条的容器化已经开展了一年有余，累计完成了近 1000 个服务的容器化工作，微服务集群的规模也达到了千台以上的规模。随着容器化服务数量和集群规模的不断增大，除了常规的 API Server 参数优化、Scheduler 优化等常规优化外，近期我们还碰到了 kubernetes 底层负载均衡 ipvs 模块导致的网络抖动问题，在此把整个问题的分析、排查和解决的思路进行总结，希望能为有类似问题场景解决提供一种思路。
涉及到的 k8s 集群和机器操作系统版本如下：
k8s 阿里云 ACK 14.8 版本，网络模型为 CNI 插件 terway 中的 terway-eniip 模式； 操作系统为 CentOS 7.7.1908，内核版本为 3.10.0-1062.9.1.el7.x86_64； 2. 网络抖动问题 在容器集群中新部署的服务 A，在测试初期发现通过服务注册发现访问下游服务 B（在同一个容器集群） 调用延时 999 线偶发抖动，测试 QPS 比较小，从业务监控上看起来比较明显，最大的延时可以达到 200 ms。
图 2-1 服务调用延时
服务间的访问通过 gRPC 接口访问，节点发现基于 consul 的服务注册发现。通过在服务 A 容器内的抓包分析和排查，经过了以下分析和排查：
服务 B 部分异常注册节点，排除异常节点后抖动情况依然存在； HTTP 接口延时测试， 抖动情况没有改善； 服务 A 在 VM（ECS）上部署测试，抖动情况没有改善； 经过上述的对比测试，我们逐步把范围缩小至服务 B 所在的主机上的底层网络抖动。
经过多次 ping 包测试，我们寻找到了某台主机 A 与 主机 B 两者之间的 ping 延时抖动与服务调用延时抖动规律比较一致，由于 ping 包 的分析比 gRPC 的分析更加简单直接，因此我们将目标转移至底层网络的 ping 包测试的轨道上。</description></item><item><title>/etc/kubernetes 目录误删恢复</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/etc_kubernetes-%E7%9B%AE%E5%BD%95%E8%AF%AF%E5%88%A0%E6%81%A2%E5%A4%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/etc_kubernetes-%E7%9B%AE%E5%BD%95%E8%AF%AF%E5%88%A0%E6%81%A2%E5%A4%8D/</guid><description>故障现象 参考：阳明公众号原文
Kubernetes 是一个很牛很牛的平台，Kubernetes 的架构可以让你轻松应对各种故障，今天我们将来破坏我们的集群、删除证书，然后再想办法恢复我们的集群，进行这些危险的操作而不会对已经运行的服务造成宕机。
如果你真的想要执行接下来的操作，还是建议别在生产环境去折腾，虽然理论上不会造成服务宕机，但是如果出现了问题，可千万别骂我~~~
我们知道 Kubernetes 的控制平面是由几个组件组成的：
etcd：作为整个集群的数据库使用
kube-apiserver：集群的 API 服务
kube-controller-manager：整个集群资源的控制操作
kube-scheduler：核心调度器
kubelet：是运行在节点上用来真正管理容器的组件
这些组件都由一套针对客户端和服务端的 TLS 证书保护，用于组件之间的认证和授权，大部分情况下它们并不是直接存储在 Kubernetes 的数据库中的，而是以普通文件的形式存在。
# tree /etc/kubernetes/pki/ /etc/kubernetes/pki/ ├── apiserver.crt ├── apiserver-etcd-client.crt ├── apiserver-etcd-client.key ├── apiserver.key ├── apiserver-kubelet-client.crt ├── apiserver-kubelet-client.key ├── ca.crt ├── ca.key ├── CTNCA.pem ├── etcd │ ├── ca.crt │ ├── ca.key │ ├── healthcheck-client.crt │ ├── healthcheck-client.key │ ├── peer.crt │ ├── peer.key │ ├── server.crt │ └── server.key ├── front-proxy-ca.</description></item><item><title>1.Namespaces</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/1.Namespaces/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/1.Namespaces/</guid><description>概述 参考：
Wiki, Linux_namespaces 思否，Linux Namespace 和 Cgroup 骏马金龙博客，Linux namespace 公众号，YP 小站-Namespace 机制详解 公众号，开发内功修炼-Linux 网络名称空间 公众号，MoeLove-彻底搞懂容器技术的基石：namespace https://mp.weixin.qq.com/s/o5nZZzOTNXOFjv2aaIZ6OA(下) Linux Namespaces(Linux 名称空间) 是 Linux 内核的一个特性，Namespaces 可以对内核资源进行划分，使得一组进程看到一组资源，而另一组进程看到一组不同的资源。
这里的资源包括 进程 ID、主机名、用户 ID、网络 等等。
如果把 Linux 操作系统比作一个大房子，那名称空间指的就是这个房子中的一个个房间，住在每个房间里的人都自以为独享了整个房子的资源，但其实大家仅仅只是在共享的基础之上互相隔离，共享指的是共享全局的资源，而隔离指的是局部上彼此保持隔离，因而名称空间的本质就是指：一种在空间上隔离的概念，当下盛行的许多容器虚拟化技术（典型代表如 LXC、Docker）就是基于 Linux 名称空间的概念而来的。
很早以前的 Unix 有一个叫 Chroot 的系统调用（通过修改根目录把用户 jail(监狱) 到一个特定目录下），Chroot 提供了一种简单的隔离模式(隔离目录)：Chroot 内部的文件系统无法访问外部的内容。Linux Namespace 就是基于 Chroot 的概念扩展而来，提供了对系统下更多资源的隔离机制。
操作系统通过虚拟内存技术，使得每个用户进程都认为自己拥有所有的物理内存，这是操作系统对内存的虚拟化。操作系统通过分时调度系统，每个进程都能被【公平地】调度执行，即每个进程都能获取到 CPU，使得每个进程都认为自己在进程活动期间拥有所有的 CPU 时间，这是操作系统对 CPU 的虚拟化。
从这两种虚拟化方式可推知，当使用某种虚拟化技术去管理进程时，进程会认为自己拥有某种物理资源的全部。
虚拟内存和分时系统均是对物理资源进行虚拟化，其实操作系统中还有很多非物理资源，比如用户权限系统资源、网络协议栈资源、文件系统挂载路径资源等。通过 Linux 的 namespace 功能，可以对这些非物理全局资源进行虚拟化。
Linux namespace 是在当前运行的系统环境中创建(隔离)另一个进程的运行环境出来，并在此运行环境中将一些必要的系统全局资源进行【虚拟化】。进程可以运行在指定的 namespace 中，因此，namespace 中的每个进程都认为自己拥有所有这些虚拟化的全局资源。
背景 Linux Namespaces 的灵感来自 Plan 9 from Bell Labs 中大量使用的名称空间功能。Plan 9 from Bell Labs 是贝尔实验室弄出来的分布式操作系统。</description></item><item><title>10.1.bootstrap 认证配置步骤介绍</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/10.1.bootstrap-%E8%AE%A4%E8%AF%81%E9%85%8D%E7%BD%AE%E6%AD%A5%E9%AA%A4%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/10.1.bootstrap-%E8%AE%A4%E8%AF%81%E9%85%8D%E7%BD%AE%E6%AD%A5%E9%AA%A4%E4%BB%8B%E7%BB%8D/</guid><description>kubelet 授权 kube-apiserver 的一些操作 exec run logs 等
RBAC 只需创建一次就可以
kubectl create clusterrolebinding kube-apiserver:kubelet-apis --clusterrole=system:kubelet-api-admin --user kubernetes
创建 bootstrap kubeconfig 文件
注意: token 生效时间为 1day , 超过时间未创建自动失效，需要重新创建 token
kubeadm token create --description kubelet-bootstrap-token --groups system:bootstrappers:kubernetes-clientgroup --kubeconfig ~/.kube/config
查看生成的 token
kubeadm token list --kubeconfig ~/.kube/config TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS ** 2kcmsb.hyl5s4g0l1mkff9z** **23h** 2018-11-16T11:08:00+08:00 authentication,signing kubelet-bootstrap-token system:bootstrappers:kubernetes-clientgroup 配置集群参数，生成 kubernetes-clientgroup-bootstrap.kubeconfig
kubectl config set-cluster kubernetes \ --certificate-authority=/etc/kubernetes/ssl/ca.pem \ --embed-certs=true \ --server=https://192.168.1.7:6443 \ #master节点ip --kubeconfig=kubernetes-clientgroup-bootstrap.</description></item><item><title>10.1.CPU 执行程序的秘密，藏在了这 15 张图里</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.1.CPU-%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%A7%98%E5%AF%86%E8%97%8F%E5%9C%A8%E4%BA%86%E8%BF%99-15-%E5%BC%A0%E5%9B%BE%E9%87%8C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.1.CPU-%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%A7%98%E5%AF%86%E8%97%8F%E5%9C%A8%E4%BA%86%E8%BF%99-15-%E5%BC%A0%E5%9B%BE%E9%87%8C/</guid><description>CPU 执行程序的秘密，藏在了这 15 张图里
前言
代码写了那么多，你知道 a = 1 + 2 这条代码是怎么被 CPU 执行的吗？
软件用了那么多，你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运行在 64 位的电脑上吗？64 位的操作系统可以运行在 32 位的电脑上吗？如果不行，原因是什么？
CPU 看了那么多，我们都知道 CPU 通常分为 32 位和 64 位，你知道 64 位相比 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能一定比 32 位 CPU 高很多吗？
不知道也不用慌张，接下来就循序渐进的、一层一层的攻破这些问题。
图灵机的工作方式 要想知道程序执行的原理，我们可以先从「图灵机」说起，图灵的基本思想是用机器来模拟人们用纸笔进行数学运算的过程，而且还定义了计算机由哪些部分组成，程序又是如何执行的。
图灵机长什么样子呢？你从下图可以看到图灵机的实际样子：
图来源自：http://www.kristergustafsson.me/turing-machine/
图灵机的基本组成如下：
有一条「纸带」，纸带由一个个连续的格子组成，每个格子可以写入字符，纸带就好比内存，而纸带上的格子的字符就好比内存中的数据或程序；
有一个「读写头」，读写头可以读取纸带上任意格子的字符，也可以把字符写入到纸带的格子；
读写头上有一些部件，比如存储单元、控制单元以及运算单元：
1、存储单元用于存放数据；
2、控制单元用于识别字符是数据还是指令，以及控制程序的流程等；
3、运算单元用于执行运算指令；
知道了图灵机的组成后，我们以简单数学运算的 1 + 2 作为例子，来看看它是怎么执行这行代码的。
首先，用读写头把 「1、2、+」这 3 个字符分别写入到纸带上的 3 个格子，然后读写头先停在 1 字符对应的格子上；</description></item><item><title>10.2.深入理解 Cilium 的 eBPF 收发包路径</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/10.2.%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Cilium-%E7%9A%84-eBPF-%E6%94%B6%E5%8F%91%E5%8C%85%E8%B7%AF%E5%BE%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/10.2.%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Cilium-%E7%9A%84-eBPF-%E6%94%B6%E5%8F%91%E5%8C%85%E8%B7%AF%E5%BE%84/</guid><description>深入理解 Cilium 的 eBPF 收发包路径 本文翻译自 2019 年 DigitalOcean 的工程师 Nate Sweet 在 KubeCon 的一篇分享: Understanding (and Troubleshooting) the eBPF Datapath in Cilium[1] 。
由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。
以下是译文。
为什么要关注 eBPF？ 网络成为瓶颈
大家已经知道网络成为瓶颈，但我是从下面这个角度考虑的：近些年业界使用网络的方式 ，使其成为瓶颈（it is the bottleneck in a way that is actually pretty recent） 。
网络一直都是 I/O 密集型的，但直到最近，这件事情才变得尤其重要。
分布式任务（workloads）业界一直都在用，但直到近些年，这种模型才成为主流。虽然何时成为主流众说纷纭，但我认为最早不会早于 90 年代晚期。
公有云的崛起，我认为可能是网络成为瓶颈的最主要原因。
这种情况下，用于管理依赖和解决瓶颈的工具都已经过时了。
但像 eBPF 这样的技术使得网络调优和整流（tune and shape this traffic）变得简单很多。eBPF 提供的许多能力是其他工具无法提供的，或者即使提供了，其代价也要比 eBPF 大 的多。
eBPF 无处不在
eBPF 正在变得无处不在，我们可能会争论这到底是一件好事还是坏事（eBPF 也确实带了一 些安全问题），但当前无法忽视的事实是：Linux 内核的网络开发者们正在将 eBPF 应用 于各种地方（putting it everywhere）。其结果是，eBPF 与内核的默认收发包路径（ datapath）耦合得越来越紧（more and more tightly coupled with the default datapath）。</description></item><item><title>10.2.知道硬盘很慢，但没想到比 CPU Cache 慢 10000000 倍</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.2.%E7%9F%A5%E9%81%93%E7%A1%AC%E7%9B%98%E5%BE%88%E6%85%A2%E4%BD%86%E6%B2%A1%E6%83%B3%E5%88%B0%E6%AF%94-CPU-Cache-%E6%85%A2-10000000-%E5%80%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.2.%E7%9F%A5%E9%81%93%E7%A1%AC%E7%9B%98%E5%BE%88%E6%85%A2%E4%BD%86%E6%B2%A1%E6%83%B3%E5%88%B0%E6%AF%94-CPU-Cache-%E6%85%A2-10000000-%E5%80%8D/</guid><description>天啦噜！知道硬盘很慢，但没想到比 CPU Cache 慢 10000000 倍 https://mp.weixin.qq.com/s/-E5jcp7tfkXjsSu2vzdeAw
前言
大家如果想自己组装电脑的话，肯定需要购买一个 CPU，但是存储器方面的设备，分类比较多，那我们肯定不能只买一种存储器，比如你除了要买内存，还要买硬盘，而针对硬盘我们还可以选择是固态硬盘还是机械硬盘。
相信大家都知道内存和硬盘都属于计算机的存储设备，断电后内存的数据是会丢失的，而硬盘则不会，因为硬盘是持久化存储设备，同时也是一个 I/O 设备。
但其实 CPU 内部也有存储数据的组件，这个应该比较少人注意到，比如寄存器、CPU L1/L2/L3 Cache 也都是属于存储设备，只不过它们能存储的数据非常小，但是它们因为靠近 CPU 核心，所以访问速度都非常快，快过硬盘好几个数量级别。
问题来了，那机械硬盘、固态硬盘、内存这三个存储器，到底和 CPU L1 Cache 相比速度差多少倍呢？
在回答这个问题之前，我们先来看看「存储器的层次结构」，好让我们对存储器设备有一个整体的认识。
存储器的层次结构 我们想象中一个场景，大学期末准备考试了，你前去图书馆临时抱佛脚。那么，在看书的时候，我们的大脑会思考问题，也会记忆知识点，另外我们通常也会把常用的书放在自己的桌子上，当我们要找一本不常用的书，则会去图书馆的书架找。
就是这么一个小小的场景，已经把计算机的存储结构基本都涵盖了。
我们可以把 CPU 比喻成我们的大脑，大脑正在思考的东西，就好比 CPU 中的寄存器，处理速度是最快的，但是能存储的数据也是最少的，毕竟我们也不能一下同时思考太多的事情，除非你练过。
我们大脑中的记忆，就好比 CPU Cache，中文称为 CPU 高速缓存，处理速度相比寄存器慢了一点，但是能存储的数据也稍微多了一些。
CPU Cache 通常会分为 L1、L2、L3 三层，其中 L1 Cache 通常分成「数据缓存」和「指令缓存」，L1 是距离 CPU 最近的，因此它比 L2、L3 的读写速度都快、存储空间都小。我们大脑中短期记忆，就好比 L1 Cache，而长期记忆就好比 L2/L3 Cache。
寄存器和 CPU Cache 都是在 CPU 内部，跟 CPU 挨着很近，因此它们的读写速度都相当的快，但是能存储的数据很少，毕竟 CPU 就这么丁点大。
知道 CPU 内部的存储器的层次分布，我们放眼看看 CPU 外部的存储器。</description></item><item><title>10.3.如何写出让 CPU 跑得更快的代码？</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.3.%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E8%AE%A9-CPU-%E8%B7%91%E5%BE%97%E6%9B%B4%E5%BF%AB%E7%9A%84%E4%BB%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.3.%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E8%AE%A9-CPU-%E8%B7%91%E5%BE%97%E6%9B%B4%E5%BF%AB%E7%9A%84%E4%BB%A3%E7%A0%81/</guid><description>面试官：如何写出让 CPU 跑得更快的代码？
前言
代码都是由 CPU 跑起来的，我们代码写的好与坏就决定了 CPU 的执行效率，特别是在编写计算密集型的程序，更要注重 CPU 的执行效率，否则将会大大影响系统性能。
CPU 内部嵌入了 CPU Cache（高速缓存），它的存储容量很小，但是离 CPU 核心很近，所以缓存的读写速度是极快的，那么如果 CPU 运算时，直接从 CPU Cache 读取数据，而不是从内存的话，运算速度就会很快。
但是，大多数人不知道 CPU Cache 的运行机制，以至于不知道如何才能够写出能够配合 CPU Cache 工作机制的代码，一旦你掌握了它，你写代码的时候，就有新的优化思路了。
那么，接下来我们就来看看，CPU Cache 到底是什么样的，是如何工作的呢，又该写出让 CPU 执行更快的代码呢？
CPU Cache 有多快？ 你可能会好奇为什么有了内存，还需要 CPU Cache？根据摩尔定律，CPU 的访问速度每 18 个月就会翻倍，相当于每年增长 60% 左右，内存的速度当然也会不断增长，但是增长的速度远小于 CPU，平均每年只增长 7% 左右。于是，CPU 与内存的访问性能的差距不断拉大。
到现在，一次内存访问所需时间是 200300 多个时钟周期，这意味着 CPU 和内存的访问速度已经相差 200300 多倍了。
为了弥补 CPU 与内存两者之间的性能差异，就在 CPU 内部引入了 CPU Cache，也称高速缓存。
CPU Cache 通常分为大小不等的三级缓存，分别是 L1 Cache、L2 Cache 和 L3 Cache。</description></item><item><title>10.4.CPU 缓存一致性</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.4.CPU-%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/10.4.CPU-%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/</guid><description>概述 参考：
公众号,小林 coding-10 张图打开 CPU 缓存一致性的大门 公众号,小林 coding-用动图的方式，理解 CPU 缓存一致性协议！ 在线体验 MESI 协议状态转换 CPU Cache 的数据写入 随着时间的推移，CPU 和内存的访问性能相差越来越大，于是就在 CPU 内部嵌入了 CPU Cache（高速缓存），CPU Cache 离 CPU 核心相当近，因此它的访问速度是很快的，于是它充当了 CPU 与内存之间的缓存角色。
CPU Cache 通常分为三级缓存：L1 Cache、L2 Cache、L3 Cache，级别越低的离 CPU 核心越近，访问速度也快，但是存储容量相对就会越小。其中，在多核心的 CPU 里，每个核心都有各自的 L1/L2 Cache，而 L3 Cache 是所有核心共享使用的。
我们先简单了解下 CPU Cache 的结构，CPU Cache 是由很多个 Cache Line 组成的，CPU Line 是 CPU 从内存读取数据的基本单位，而 CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成，你可以在下图清晰的看到：
我们当然期望 CPU 读取数据的时候，都是尽可能地从 CPU Cache 中读取，而不是每一次都要从内存中获取数据。所以，身为程序员，我们要尽可能写出缓存命中率高的代码，这样就有效提高程序的性能，具体的做法，你可以参考我上一篇文章「如何写出让 CPU 跑得更快的代码？」</description></item><item><title>2.CGroup</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/2.CGroup/2.CGroup/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/2.CGroup/2.CGroup/</guid><description>概述 参考：
Wiki, Cgroups Manual(手册),cgroup(7) Linux Kernel 官方文档,Linux 内核用户和管理员指南-Control Group V1 Linux Kernel 官方文档,Linux 内核用户和管理员指南-Control Group V2 红帽文档： https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/system_design_guide/using-control-groups-through-a-virtual-file-system_setting-limits-for-applications https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/resource_management_guide/index 思否，Linux Namespace 和 Cgroup https://fuckcloudnative.io/posts/understanding-cgroups-part-1-basics/ Control Groups(控制组，简称 CGroups) 是一个 Linux 内核特性，用于限制、隔离一组进程集合的资源使用，资源包括 CPU、内存、磁盘 IO、网络 等。CGroups 由 Google 的两位工程师开发，自 2008 年 1 月发布的 Linux 2.6.24 版本的内核中提供此能力。到目前为止，CGroups 分 v1 和 v2 两个版本，v1 实现较早，功能比较多，但是由于它里面的功能都是零零散散的实现的，所以规划的不是很好，导致了一些使用和维护上的不便，v2 的出现就是为了解决 v1 中这方面的问题，在最新的 4.5 内核中，cgroup v2 声称已经可以用于生产环境了，但它所支持的功能还很有限，随着 v2 一起引入内核的还有 cgroup namespace。v1 和 v2 可以混合使用，但是这样会更复杂，所以一般没人会这样用。
在 Linux 里，一直以来就有对进程进行分组的概念和需求，比如 session group， progress group 等，后来随着人们对这方面的需求越来越多，比如需要追踪一组进程的内存和 IO 使用情况等，于是出现了 cgroup，用来统一将进程进行分组，并在分组的基础上对进程进行监控和资源控制管理等。</description></item><item><title>Agent 与 Proxy</title><link>https://desistdaydream.github.io/docs/Standard/Agent-%E4%B8%8E-Proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Agent-%E4%B8%8E-Proxy/</guid><description>今天，在阅读 Jolokia 文档的时候，看到其支持两种架构模式： Agent Mode 与 Proxy Mode。从字面上理解，agent 与 proxy 都有代理的意思，那么它们在内涵上到底有什么不同的，值得思考。
Agent Mode
Proxy Mode
从上面两张图可以看出，Proxy 与 Agent 所处的位置和目的有所不同，Agent 处在被代理对象的内部，而 Proxy 与被代理对象之间处于一种相对独立的状态。
举个例子，Proxy 类似于会计事务所，而 Agent 类似于公司里做会计工作的员工，它们都是处理企业的财务问题，但是角色不同。
Agent 代理 通常指与用户接口的客户端程序
Proxy 代理 接收用户请求并将请求发给服务器,然后接收服务器回应并返回给用户 实际上 Proxy 的功能就是代替用户访问服务器,用户被隐藏.
The Etymology of &amp;ldquo;Agent&amp;rdquo; and &amp;ldquo;Proxy&amp;rdquo; in Computer Networking Discourse 原文: https://cyber.harvard.edu/archived_content/people/reagle/etymology-agency-proxy-19981217.html
September 18, 1998. _Joseph Reagle _ Revised: January 15, 1999 .
Given that the topic of this paper addresses both computer and legal agency, we believe an examination of the usage of the terms &amp;ldquo;agent&amp;rdquo; and &amp;ldquo;proxy&amp;rdquo; within each field is instructive.</description></item><item><title>Annotations 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Annotations-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Annotations-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，用户指南-Annotations 与 ConfigMap 实现配置 Nginx Ingress Controller 运行时行为类似，只不过，Annotations 的方式，是通过设置 Ingress 资源的 .metadata.annotations 字段下的内容实现的。
.metadata.annotations 字段下的内容也是由无数的 Key/Value Pairs(键/值对) 组成。绝大部分 Key 都会对应一个 Nginx 的 Directives(指令)
Nginx controoler 程序默认读取 Ingress 对象中 metadata.annotations 字段下前缀为 nginx.ingress.kubernetes.io 的字段，作为运行程序时的配置信息。
注意：
所有 Key 都是以 nginx.ingress.kubernetes.io 作为前缀，比如配置认证相关，那么 Key 就是 nginx.ingress.kubernetes.io/auth-realm 可以为 nginx-ingress-controller 程序添加 --annotations-prefix 命令行标志以改变前缀 Key 详解 Authentication - 认证相关配置 https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#authentication
可以为 Nginx 所代理的后端配置一些简单的认证，比如 用户名/密码
nginx.ingress.kubernetes.io/auth-realm(STRING) #
nginx.ingress.kubernetes.io/auth-secret(STRING) #
nginx.ingress.kubernetes.io/auth-type(STRING) #
Backend Protocol - 后端协议配置 https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#backend-protocol
使用后端协议注释可以指示 NGINX 应如何与后端服务通信。</description></item><item><title>Ansible UI</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E6%89%A9%E5%B1%95/Ansible-UI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E6%89%A9%E5%B1%95/Ansible-UI/</guid><description>概述 参考：
Github 项目，ansible/awx</description></item><item><title>Ansible Variables</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Variables/Ansible-Variables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Variables/Ansible-Variables/</guid><description>group_vars 概述 参考：
官方文档，传统目录 - 使用变量 官方文档，传统目录 - 使用变量 - 变量优先级 虽然通过自动化可以使事情更简单、更可重复，但是并非所有系统都完全相同。在某些情况下，观察到一个系统的行为或状态可能会影响到配置其他系统的方式。比如，我们可能需要找出一个系统的 IP 地址，并将这个 IP 地址作为另一个系统中配置的值。
基于上述目的，Ansible 可以通过 Variables(变量) 来管理各个系统之间的差异。
Ansible 的变量就跟编程语言中的变量概念一样，同样可以定义、引用。我们使用标准的 YAML 语法创建变量，包括列表和字典；可以这么说，YAML 中每个字段的 key 就是变量名，value 就是变量的值。我们可以在 Playbooks、Inventory、甚至命令行中定义与引用变量。我们还可以在 Playbooks 运行期间，将任务的返回值注册为变量，以创建一个新的变量。
创建变量后，我们可以在 模块的参数、模板、控制结构 中使用这些变量。在 GitHub 中有一个 Ansible 示例的目录，可以看到很多 Ansible 使用变量的例子
下面的示例就是在命令行中使用 debug 模块，查看了一下 inventory_hostname 这个默认变量的值
~]$ ansible -i ../inventory/ all -m debug -a &amp;#39;msg={{inventory_hostname}}&amp;#39; hw-cloud-xngy-jump-server-linux-2 | SUCCESS =&amp;gt; { &amp;#34;msg&amp;#34;: &amp;#34;hw-cloud-xngy-jump-server-linux-2&amp;#34; } 变量的优先级 变量可以是自带的，就是由人们自行定义的，可以在多个地方定义变量，(e.g.在某些文件里定义变量、通过命令行传递变量等等。由于 ansible 所要处理的的文件有很多，不同类型的文件下定义的变量的优先级也不同)
下面的优先级列表由低到高，最下面的变量优先级最高
command line values (eg “-u user”) role defaults # 定义在 ${ROLE}/defaults/main.</description></item><item><title>ansible.builtin(内置模块)</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
官方文档，参考 - 所有模块和插件的索引 - 所有模块的索引 - ansible.builtin ansible.builtin.add_host – Add a host (and alternatively a group) to the ansible-playbook in-memory inventory ansible.builtin.apt – Manages apt-packages ansible.builtin.apt_key – Add or remove an apt key ansible.builtin.apt_repository – Add and remove APT repositories ansible.builtin.assemble – Assemble configuration files from fragments ansible.builtin.assert – Asserts given expressions are true ansible.builtin.async_status – Obtain status of asynchronous task ansible.builtin.blockinfile – Insert/update/remove a text block surrounded by marker lines ansible.</description></item><item><title>ansible.posix(POSIX 标准模块)</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.posixPOSIX-%E6%A0%87%E5%87%86%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.posixPOSIX-%E6%A0%87%E5%87%86%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
官方文档，参考 - 所有模块和插件的索引 - 所有模块的索引-ansible.posix posix 模块是关于符合 POSIX 标准的操作系统相关的模块
ansible.posix.acl – Set and retrieve file ACL information. ansible.posix.at – Schedule the execution of a command or script file via the at command ansible.posix.authorized_key – Adds or removes an SSH authorized key ansible.posix.firewalld – Manage arbitrary ports/services with firewalld ansible.posix.firewalld_info – Gather information about firewalld ansible.posix.mount – Control active and configured mount points ansible.posix.patch – Apply patch files using the GNU patch tool ansible.</description></item><item><title>ansible通过跳板机与目标主机通信</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E7%AE%A1%E7%90%86/ansible%E9%80%9A%E8%BF%87%E8%B7%B3%E6%9D%BF%E6%9C%BA%E4%B8%8E%E7%9B%AE%E6%A0%87%E4%B8%BB%E6%9C%BA%E9%80%9A%E4%BF%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-%E7%AE%A1%E7%90%86/ansible%E9%80%9A%E8%BF%87%E8%B7%B3%E6%9D%BF%E6%9C%BA%E4%B8%8E%E7%9B%AE%E6%A0%87%E4%B8%BB%E6%9C%BA%E9%80%9A%E4%BF%A1/</guid><description>在公司开发中，为了安全起见，生产环境跟开发环境是相互隔离开来的。也就是说在开发环境网络中无法直接 ssh 登录到生产环境的机器， 如果需要登录生产环境的机器，通常会需要借助跳板机，先登录到跳板机，然后通过跳板机登录到生产环境。
那么，使用 Ansible 时，如何配置，可以直接穿过跳板机呢？
大致的过程如下面的图示：
+-------------+ +----------+ +--------------+ | 开发环境机器A | &amp;lt;---&amp;gt; | 跳板机B | &amp;lt;--&amp;gt; | 生产环境机器B | +-------------+ +----------+ +--------------+ 我们可以通过 ssh 命令的 ProxyCommand 选项来解决以上问题。
通过 ProxyCommand 选项，机器 A 能够灵活使用任意代理机制与机器 C 上的 SSH Server 端口建立连接，接着机器 A 上的 SSH Client 再与该连接进行数据交互，从而机器 A 上的 SSH Client 与机器 C 上的 SSH Server 之间建立了与一般直接 SSH 连接不太一样的间接 SSH 连接。
不过由于间接 SSH 连接的透明性，逻辑上可认为机器 A 上的 SSH Client 与机器 C 上的 SSH Server 建立了直接 SSH 连接。</description></item><item><title>ApacheBench</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/ApacheBench/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/ApacheBench/</guid><description>概述 Apache HTTP服务器基准测试工具
ApacheBench 介绍 ApacheBench，简称 ab。ab 是用于对 Apache 超文本传输协议（HTTP）服务器进行基准测试的工具。它旨在使您对当前的 Apache 安装方式有一个印象。这尤其向您显示 Apache 安装每秒能够处理多少个请求。
ApacheBench 的安装与使用 ab 工具包含在 httpd-tools 软件包中，直接安装 httpd-tools 即可
ApacheBench 测试结果参数解析</description></item><item><title>API</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/API/</guid><description>概述 Ceph RESTful API 参考：
官方文档，Ceph 管理器守护进程-Ceph RESTful API GitHub，ceph/ceph/src/pybind/mgr/dashboard/openapi.yaml(该 API 的 openapi 文件) 在 Dashboard 模块中，提供了一组用于管理集群的 RESTful 风格的 API 接口。这组 API 默认位于 https://localhost:8443/api 路径下
在 /docs 端点下，可以查看 OpenAPI 格式的信息
在 /dpcs/api.json 端点可以获取 openapi 格式的 API 信息。
/api/auth /api/auth 接口获取 Token
curl -X POST &amp;#34;https://example.com:8443/api/auth&amp;#34; \ -H &amp;#34;Accept: application/vnd.ceph.api.v1.0+json&amp;#34; \ -H &amp;#34;Content-Type: application/json&amp;#34; \ -d &amp;#39;{&amp;#34;username&amp;#34;: &amp;lt;username&amp;gt;, &amp;#34;password&amp;#34;: &amp;lt;password&amp;gt;}&amp;#39; 获取 Token 后，其他接口，都可以使用该 Token 进行认证，比如：
curl -H &amp;#34;Authorization: Bearer $TOKEN&amp;#34; ...... /api/auth/check /api/auth/check 接口可以检查 Token。通常还可以作为对 API 的健康检查接口。</description></item><item><title>API Aggregation(聚合) Layer</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/API-Aggregation%E8%81%9A%E5%90%88-Layer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/API-Aggregation%E8%81%9A%E5%90%88-Layer/</guid><description>概述 参考；
官方文档参考： https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/ api aggregation 称为 api 聚合。用于扩展 kubernetes 的 API 。如下所示。其中 v1beta1.metrics.k8s.io 是通过 prometheus-adapter 添加的新 API
[root@master-1 ~]# kubectl get apiservices.apiregistration.k8s.io NAME SERVICE AVAILABLE AGE v1. Local True 163d ......... v1beta1.metrics.k8s.io monitoring/prometheus-adapter True 120m v1beta1.networking.k8s.io Local True 163d ...... 聚合出来的 API 会关联到一个指定的 service 上，所有对该 API 发起的请求，都会交由该 service 并转发到其后端的 pod 进行处理。
下面是一个扩展 API 的样例，其中指定了该 API 所关联的 service
apiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: name: v1beta1.metrics.k8s.io spec: group: metrics.k8s.io groupPriorityMinimum: 100 insecureSkipTLSVerify: true service: name: prometheus-adapter namespace: monitoring version: v1beta1 versionPriority: 100 API Aggregation 的核心功能是动态注册、发现汇总、安全代理。</description></item><item><title>API Server 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-Server/API-Server-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-Server/API-Server-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，参考 - 组件工具 - kube-apiserver API Server 现阶段只能通过命令行标志才可以改变运行时行为。暂无配置文件可用。
kube-apiserver 命令行标志详解 &amp;ndash;allow-privileged &amp;lt;BOOL&amp;gt; # 是否允许有特权的容器。默认值：false。
&amp;ndash;basic-auth-file &amp;lt;FILE&amp;gt; # 配置 API Server 的基础认证。
该标志已于 1.19 版本彻底弃用。详见 PR #89069 &amp;ndash;insecure-port &amp;lt;NUM&amp;gt; # 开启不安全的端口。默认值：0，即不开启不安全的端口
&amp;ndash;insecure-bind-address &amp;lt;IP&amp;gt; # 不安全端口的监听地址。默认值：127.0.0.1。
&amp;ndash;runtime-config &amp;lt;OBJECT&amp;gt; # 启用或禁用内置的 APIs。
OBJECT 是 key=value 的键值对格式。key 为 API 组名称，value 为 true 或 false。
比如
要关闭 batch/v1 组，则设置 --runtime-config=batch/v1=false 要开启 batch/v2alpha1 组，则设置 --runtime-config=batch/v2alpha1 &amp;ndash;secure-port &amp;lt;NUM&amp;gt; # API Server 监听的安全端口。默认值：6443。不能以 0 关闭。
&amp;ndash;service-node-port-range &amp;lt;PortRange&amp;gt; # 指定 NodePort 类型的 service 资源可以使用的端口范围。</description></item><item><title>API 扩展</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/API-%E6%89%A9%E5%B1%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/API-%E6%89%A9%E5%B1%95/</guid><description>概述 参考：
官方文档，概念 - 扩展 Kubernetes - 扩展 Kubernetes API Resource(资源) 是 Kubernetes API 中的一个 endpoint(端点)， 其中存储的是某个类别的 API 对象 的一个集合。 例如内置的 pods 资源包含一组 Pod 对象。(这里面“点”的意思是这么一种语境。我说的几点记住了吗？知识点。等等)
而扩展 Kubernetes API 实际上就是添加 Custom Resource(自定义的资源)。
Custom Resource 自定义资源 什么是自定义资源呢？
如 API 与 Resource 中介绍的，Kubernetes 自身的一切都抽象为 Resource(资源)。顾名思义，Custom Resource(自定义资源) 就是非 Kubernetes 核心的资源。如果要类比的话，那么 Custom Resource 与 Kubernetes 的关系，类似于 Linux 中，Module(模块) 与 Kernel(内核) 的关系。其实，再准确的说法应该是下文将要提到的 Operator，Operator 与 Kubernetes 的关系，类似于 Linux 中，Module(模块) 与 Kernel(内核) 的关系。现在很多 Kubernetes 核心功能现在都用自定义资源来实现，这使得 Kubernetes 更加模块化。
自定义资源可以像普通资源(比如.pod)一样被创建和销毁。一旦某个自定义资源被安装，就可以使用 kubectl 来创建和访问其中的对象，就像为 pods 这种内置资源所做的一样。</description></item><item><title>Architecture(架构)</title><link>https://desistdaydream.github.io/docs/Standard/Architecture%E6%9E%B6%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Architecture%E6%9E%B6%E6%9E%84/</guid><description>概述 参考：
Wiki, Computer Architecture 各行各业微服务技术架构图分享 包含：智慧仓储#docker#部署图、通用微服务架构图、物联网终端微服务架构图、平台微服务技术架构、基于#SpringCloud#的微服务架构图、基于 SpringCloud 的微服务电商系统架构图、#k8s#云原生架构图、#云计算#总体架构和技术架构。
微服务不是架构演变的终极目标。最近比较流行的方向还有 Serverless、FaaS 等方向。另一方面也有人再重新关注单体系统的开发，我们认为技术架构应该是服务业务的，根据不同的业务类型选择正确的技术栈是每个架构师应该具备的能力。</description></item><item><title>Argo CD</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/ArgoCD/Argo-CD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/ArgoCD/Argo-CD/</guid><description>概述 参考：
GitHub 项目，argoproj/argo-cd Argo CD 保姆级入门教程 在上一篇『👉GitOps 介绍[1]』中，我介绍了什么是 GitOps，包括 GitOps 的原则和优势，以及 GitOps 与 DevOps 的区别。本文将介绍用于实施 GitOps 的工具 Argo CD。
Argo CD 是以 Kubernetes 作为基础设施，遵循声明式 GitOps 理念的持续交付（continuous delivery, CD）工具，支持多种配置管理工具，包括 ksonnet/jsonnet、kustomize 和 Helm 等。它的配置和使用非常简单，并且自带一个简单易用的可视化界面。
按照官方定义，Argo CD 被实现为一个 Kubernetes 控制器，它会持续监控正在运行的应用，并将当前的实际状态与 Git 仓库中声明的期望状态进行比较，如果实际状态不符合期望状态，就会更新应用的实际状态以匹配期望状态。
在正式开始解读和使用 Argo CD 之前，我们需要先搞清楚为什么需要 Argo CD？它能给我们带来什么价值？
传统 CD 工作流 从上篇文章『👉GitOps 介绍[2]』可以知道，目前大多数 CI/CD 工具都使用基于 Push 的部署模式，例如 Jenkins、CircleCI 等。这种模式一般都会在 CI 流水线运行完成后执行一个命令（比如 kubectl）将应用部署到目标环境中。
这种 CD 模式的缺陷很明显：
需要安装配置额外工具（比如 kubectl）； 需要 Kubernetes 对其进行授权； 需要云平台授权； 无法感知部署状态。也就无法感知期望状态与实际状态的偏差，需要借助额外的方案来保障一致性。 下面以 Argo CD 为例，来看看遵循声明式 GitOps 理念的 CD 工具是怎么实现的。</description></item><item><title>ASCII 表</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/ASCII-%E8%A1%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E5%AD%97%E7%AC%A6%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/ASCII-%E8%A1%A8/</guid><description>概述 参考：
Wiki, ASCII 原文链接：https://www.middlewareinventory.com/ascii-table/
Character Binary Value Decimal Value Octal Value Hex Value 符号 用途 二进制表示 十进制表示 八进制表示 十六进制表示 NUL null 0 0 0 00 SOH start of heading 1 1 1 01 STX start of text 10 2 2 02 ETX end of text 11 3 3 03 EOT end of transmission 100 4 4 04 ENQ enquiry 101 5 5 05 ACK acknowledge 110 6 6 06 BEL bell 111 7 7 07 BS backspace 1000 8 10 08 TAB horizontal tab 1001 9 11 09 LF line feed(换行) 1010 10 12 0A VT vertical tab 1011 11 13 0B FF form feed 1100 12 14 0C CR carriage return(回车) 1101 13 15 0D SO shift out 1110 14 16 0E SI shift in 1111 15 17 0F DLE data link escape 10000 16 20 10 DC1 device control 1 10001 17 21 11 DC2 device control 2 10010 18 22 12 DC3 device control 3 10011 19 23 13 DC4 device control 4 10100 20 24 14 NAK negative acknowledge 10101 21 25 15 SYN synchronous idle 10110 22 26 16 ETB end of trans.</description></item><item><title>ASN.1</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/ASN.1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/ASN.1/</guid><description>概述 参考：
ITU 官网, ITU-T-ASN.1 项目 Wiki, ASN.1 Wiki, X.690-DER_encoding http://www.txrzx.com/i4477.html http://threelambda.com/2020/11/08/asn-1/ https://lapo.it/asn1js 《抽象语法记法 asn.1 原理与应用》 Abstract Syntax Notation One (ASN.1) 是一种标准的 interface description language(接口描述语言)，用于定义以跨平台方式序列化和反序列化的数据结构。 它广泛用于电信和计算机网络，尤其是在密码学中。
Abstract Syntax Notation One(抽象语法表示法，简称 ASN.1) 是一个形式化的标准，用于定义抽象数据类型的规范。它广泛用于计算机网络中，用于描述 telecommunications protocols(电信协议) 传输数据时所使用的 formal notation(正式表示法)。
通信设备需要相互传输数据，但是设备可能是由不同厂家生产的，其硬件体系结构、程序语言的语法定义和程序功能实现一般是不相同的。例如，在一台设备中，整形数据类型是 16 位表示，而在另一台则可能用 32 位表示。这些差异导致了同一数据对象在不同的设备上被表示为不同的符号串。为了解决以上问题，ISO 组织推出了 ASN.1。ASN.1 通过定义若干简单类型和复合类型，使得各个设备对其间交换消息的数据类型有了一致的认识。系统的消息发送方采用编码规则（BER、PER）将 ASN.1 描述的消息编码成二进制字节流；消息接受方对收到的字节流进行解码，再转化为符合其自身语法的消息格式。这样，经过 ASN.1 处理的消息独立于应用环境，就不会因为系统终端的区别而产生歧义。基于 H.323 协议的视频会议系统的信令消息就是采用 ASN.1 来表示的。
80 年代初，当时的国际电报电话咨询委员会（CCITT）将应用于 E-mail MHS 协议的基本记法和解码格式进行了标准化，形成了 X.409 方案，这是 ASN.1 的前身。该标准后来被 ISO 组织采用并将其分为抽象语法记法和传输语法，形成了 ISO/IEC 8824 和 ISO/IEC 8825 两个系列标准，且版本在不断更新之中（目前是 2015 年版本）。CCITT 于 1989 年相应地发布了 X.</description></item><item><title>Authentication(认证)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Authentication%E8%AE%A4%E8%AF%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Authentication%E8%AE%A4%E8%AF%81/</guid><description>概述 参考：
官方文档，运行方式 - 认证 Loki 不附带任何包含的身份验证层。运营商应在您的服务之前运行身份验证反向代理，例如使用基本身份验证或 OAuth2 代理的 NGINX。
请注意，在多租户模式下使用 Loki 时，Loki 要求将 HTTP 标头 X-Scope-OrgID设置为标识租户的字符串。填充此值的责任应由身份验证反向代理处理。阅读多租户文档以了解更多信息。
有关身份验证 Promtail 的信息，请参阅文档以了解如何配置 Promtail。</description></item><item><title>awk</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk/</guid><description>概述 参考：
官网 官方文档 awk 以字段为单位进行处理
其实就是把一行的数据分割,然后对每个字段进行处理,包含 cut 等命令)，支持变量，条件判断，循环，数组等编程基本语言
Syntax(语法) awk [OPTIONS] &amp;lsquo;COMMAND&amp;rsquo; FILE
awk [OPTIONS] &amp;lsquo;PATTERN1{ACTION1} PATTERN2{ACTION2}&amp;hellip;.&amp;rsquo; FILE
OPTIONS
-f FILE # 指定要使用的 awk 代码文件。 -F [“[分隔符]”] # 指定分隔符，默认分隔符为一个或多个的“空格键”或者“tab 键”，也可以具体指定一个或多个 e.g.当使用-F “ [/:]”的时候即是空格、/、:这三个符号出现任意一个都算作一个分隔符 AWK 语言 awk 其实本质上可以看作编程语言，只不过这个语言只是用来处理文本的而已。在使用命令时，可以使用 -f 选项指定要使用的代码文件。
awk 语言的基本结构 awk 代码由 PATTERN {ACTION} 组成，PATTERN 是可省略的。
PATTERN 用来进行匹配的模式，匹配到的内容将会执行 ACTION 中定义的操作 /搜索模式/ 判断模式 BEGIN 执行 ACTION 前的准备工作，比如给 awk 中的自带变量赋值,在 print 前在屏幕输出点内容 END 执行 ACTION 后的收尾工作 ACTION 用来执行具体的动作 print $NUM &amp;ldquo;输出内容&amp;rdquo; $NUM&amp;hellip;&amp;hellip; # 在屏幕输出哪几个字段以及哪些内容，内容可以是各种分隔符 一个最简单的 awk 代码如下：</description></item><item><title>Base64 编码</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/Base64-%E7%BC%96%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/Base64-%E7%BC%96%E7%A0%81/</guid><description>概述 参考：
Wiki, Base64 Base64 是一组 二进制 到 文本 的编码方案，它是基于 64 个可打印的字符来表示二进制的数据的一种方法。二进制的数据中的每一个位数的内容，都可以通过字符来表示。
对于所有二进制到文本编码方案而言，Base64 都被设计为在只能可靠地支持文本内容的通道上以二进制格式存储数据。Base64 在万维网上特别流行，它的用途包括将图像文件或其他二进制资产嵌入文本资产（例如HTML和CSS文件）中的功能。
Base64 还广泛用于发送电子邮件附件。这是必需的，因为 SMTP（原始格式）仅设计为传输 7 位 ASCII 字符。这种编码会产生 33–36％ 的开销（编码本身的开销为 33％；插入的换行符最多可导致 3％ 的开销）。</description></item><item><title>Bash 变量</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%8F%98%E9%87%8F/</guid><description>概述 参考：
Manual(手册)，bash(1) - 形参 - Shell 变量 Bash 可以从逻辑上分为如下几种变量
局部变量 # 不以被子进程继承的变量。通常在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。 环境变量 # 可以被子进程继承的变量。通常继承自操作系统的环境变量。所有的程序，包括 Shell 启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候 Shell 脚本也可以定义环境变量。 局部变量与环境变量的区别主要在于是否可以被子进程继承
~]# TestVar=&amp;#34;This is Normal Var&amp;#34; ~]# export TestEnvVar=&amp;#34;This is Enviroment Var&amp;#34; ~]# bash # 在这里进入了一个新的 Bash 程序，不通过 export 声明的非环境变量 ~]# echo $TestVar ~]# echo $TestEnvVar This is Enviroment Var 这个示例中可以看到，当我们启动一个新 Bash 时，不使用 export 声明的变量，将不会被子 Bash 继承。这就是环境变量与普通变量的基本区别。
局部变量 没什么特殊的说明
环境变量 根据变量的定义位置，环境变量分为多个作用域：
系统范围 用户范围 进程范围 声明变量与取消变量 对于 Shell 编程语言来说，一个变量其实不声明也是可以的，默认任意字符串组合成的变量的值都为空，比如
~]# env | grep randomVar ~]# echo $randomVar ~]# echo $?</description></item><item><title>Bash 操作历史记录</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E6%93%8D%E4%BD%9C%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BD%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E6%93%8D%E4%BD%9C%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BD%95/</guid><description>history 工具 参考：
Manual(手册),history https://blog.csdn.net/m0_38020436/article/details/78730631 https://blog.csdn.net/sz_bdqn/article/details/46527021 history 工具可以通过如下几个 Bash 的环境变量来配置运行方式
HISTTIMEFORMAT # 历史记录的格式 HISTSIZE # 历史记录可以保留的最大命令数 HISTFILESIZE # 历史记录可以保留的最大行数 HISTCONTROL # 应用示例 export HISTTIMEFORMAT=&amp;quot;%Y-%m-%d:%H-%M-%S:whoami: &amp;quot; 持久化 cat &amp;gt; /etc/profile.d/custom_ops.sh &amp;lt;&amp;lt;END export HISTTIMEFORMAT=&amp;#34;%Y-%m-%d %H:%M:%S `whoami` &amp;#34; END 谁动了我的主机? 之活用 History 命令 参考：
http://lab.xmirror.cn/2017/05/26/sdlwdzj/ Linux 系统下可通过 history 命令查看用户所有的历史操作记录，在安全应急响应中起着非常重要的作用，但在未进行附加配置情况下，history 命令只能查看用户历史操作记录，并不能区分用户以及操作时间，不便于审计分析。
当然，一些不好的操作习惯也可能通过命令历史泄露敏感信息。
下面我们来介绍如何让 history 日志记录更细化，更便于我们审计分析。
1、命令历史记录中加时间 默认情况下如下图所示，没有命令执行时间，不利于审计分析。
通过设置 export HISTTIMEFORMAT=&amp;rsquo;%F %T &amp;lsquo;，让历史记录中带上命令执行时间。
注意”%T”和后面的”’”之间有空格，不然查看历史记录的时候，时间和命令之间没有分割。
要一劳永逸，这个配置可以写在/etc/profile 中，当然如果要对指定用户做配置，这个配置可以写在/home/$USER/.bash_profile 中。
本文将以/etc/profile 为例进行演示。
要使配置立即生效请执行 source /etc/profile，我们再查看 history 记录，可以看到记录中带上了命令执行时间。
如果想要实现更细化的记录，比如登陆过系统的用户、IP 地址、操作命令以及操作时间一一对应，可以通过在/etc/profile 里面加入以下代码实现</description></item><item><title>Bash 快捷键</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%BF%AB%E6%8D%B7%E9%94%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%BF%AB%E6%8D%B7%E9%94%AE/</guid><description>概述 快速编辑命令高效率输入
并非大型软件或者 IDE 才有快捷键,shell 也有,如果能够熟练使用快捷键,做起事情来且不事半功倍。
网上流传的快捷键在 xshell 下可能和菜单的快捷键 alt 啥的冲突
我只说下 xshell 下和用的最多的
光标部分总的来说就是移动,最常用的就四个:
移动到行首和行尾部
ctrl + a 行首
ctrl + e 行末
然后单词移动,xshell 下 alt 不起作用,esc+b/f 可以前后
但是 ctrl+左/右也可以,所以建议单词之间移动使用:
ctrl + ← 光标移动到前一个单词开头
ctrl + → 光标移动到后一个单词结尾
配合下面的 ctrl+w 或者 esc+d 来删除前后单词
删除部分
ctrl + u 删除当前光标左边所有内容
ctrl + k 删除当前光标右边所有内容
ctrl + w 删除当前光标到左边最近的一个空格(通常用来删除一个单词)
esc + d 删除当前光标到右边最近的一个空格(通常用来删除一个单词)
ctrl + y 粘贴上面删除的部分
编辑部分
esc + t 互换相邻的两个单词</description></item><item><title>Bash 命令行参数处理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/</guid><description>概述 参考：
https://www.cnblogs.com/klb561/p/9211222.html https://blog.csdn.net/qq_22203741/article/details/77671379 shell 代码命令行选项与修传入参数处理 在编写 shell 程序时经常需要处理命令行参数，本文描述在 bash 下的命令行处理方式。
选项与参数：
如下命令行：
./test.sh -f config.conf -v &amp;ndash;prefix=/home
-f 为选项，它需要一个参数，即 config.conf -v 也是一个选项，但它不需要参数。 &amp;ndash;prefix 我们称之为一个长选项，即选项本身多于一个字符，它也需要一个参数，用等号连接，当然等号不是必须的，/home 可以直接写在&amp;ndash;prefix 后面，即&amp;ndash;prefix/home,更多的限制后面具体会讲到。 在 bash 中，可以用以下三种方式来处理命令行参数，每种方式都有自己的应用场景。
通过位置变量手工处理参数 # 参考变量与环境变量 文章中的位置变量 getopts # 简单工具 getopt # 复杂工具 依次讨论这三种处理方式。
通过位置变量手工处理参数 在手工处理方式中，首先要知道几个变量，还是以上面的命令行为例：
代码如下:
$0 ： ./test.sh,即命令本身，相当于 c/c++中的 argv[0] $1 ： -f,第一个参数. $2 ： config.conf $3, $4 &amp;hellip; ：类推。 $# 参数的个数，不包括命令本身，上例中 $# 为 4. $@ # 参数本身的列表，也不包括命令本身，如上例为 -f config.conf -v &amp;ndash;prefix=/home $* # 和 $@ 相同，但 &amp;quot;$*&amp;quot; 和 &amp;quot;$@&amp;quot;(加引号)并不同，&amp;quot;$*&amp;quot; 将所有的参数解释成一个字符串，而 &amp;quot;$@&amp;quot; 是一个参数数组。 例子：</description></item><item><title>BCC 工具集</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/BCC-%E5%B7%A5%E5%85%B7%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/BCC-%E5%B7%A5%E5%85%B7%E9%9B%86/</guid><description>概述 参考：
官网 GitHub 项目, iovisor/bcc BPF Compiler Collection(BPF 编译器合集，简称 BCC) 是用于创建有效的内核跟踪和操作程序的工具包。BCC 是 Linux 基金会旗下的 IO Visor 项目组做出来的基于 eBPF 的产品。BBC 主要用来为 Linux 提供 Dynamic Tracing(动态追踪) 功能的实现。
BCC 安装 通过 Linux 包管理器安装 Ubuntu 标准的 Ubuntu Universe 仓库 与 iovisor 的 PPA 仓库中都可以用来安装 BCC 工具，但是包的名称不同。Ubuntu 安装完的程序，其名称会在最后加上 -bpfcc。
使用 Ubuntu 仓库安装 sudo apt-get install bpfcc-tools linux-headers-$(uname -r) 使用 iovisor 仓库安装 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD echo &amp;#34;deb https://repo.iovisor.org/apt/$(lsb_release -cs) $(lsb_release -cs) main&amp;#34; | sudo tee /etc/apt/sources.</description></item><item><title>Binary Operators(二元运算符)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/Binary-Operators%E4%BA%8C%E5%85%83%E8%BF%90%E7%AE%97%E7%AC%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/PromQL/Binary-Operators%E4%BA%8C%E5%85%83%E8%BF%90%E7%AE%97%E7%AC%A6/</guid><description>概述 参考：
官方文档，查询 - 运算符 PromQL 支持基本的 逻辑 和 算术 运算符。 对于两个即时向量之间的运算，可以修改匹配行为。
使用 PromQL 除了能够方便的按照查询和过滤时间序列以外，PromQL 还支持丰富的运算符，用户可以使用这些运算符对进一步的对事件序列进行二次加工。这些运算符包括：数学运算符，逻辑运算符，布尔运算符等等。
官方文档中，将时间序列中的标签称为 element(元素)
Arithmetic(算术) 二元运算符 PromQL 支持以下算术二元运算符：
(加法) (减法) (乘法) / (除法) % (求余) ^ (幂运算) 算术二元运算符可以实现如下三种类型的运算：
Between two scalars(标量与标量) Between an instant vector and a scalar(即时向量与标量) Between two instant vectors(即时向量与即时向量) Between two scalars(标量与标量) 就是普通的数学运算，类似于 1+1、2*3 等等，直接获取一个标量结果
Between an instant vector and a scalar(即时向量与标量) 当瞬时向量与标量之间进行数学运算时，数学运算符会依次作用域瞬时向量中的每一个样本值，从而得到一组新的时间序列。
与 标量之间 的二元运算一样，只不过将即时向量表达式获取到的所有时间序列的值与标量进行运算，效果如下：
经过运算后：
Between two instant vectors(即时向量与即时向量) 如果是即时向量与即时向量之间进行数学运算时，过程会相对复杂一点。 例如，如果我们想根据 node_disk_bytes_written 和 node_disk_bytes_read 获取主机磁盘 IO 的总量，可以使用如下表达式：</description></item><item><title>BIND</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/BIND/BIND/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/BIND/BIND/</guid><description>概述 参考：
ISC-BIND9 官方网站 Wiki, BIND Bekerley Internat Name Domain(伯克利互联网名字域，简称 BIND) 是实现 DNS 服务的应用程序。该程序最著名的组件被称为 named，主要用来实现两个最主要的 DNS 功能：NameServer(名称服务器) 与 Resolver(解析器)。
该软件最初是在 1980 年代初在加州大学伯克利分校 (UCB) 设计的。该名称起源于 Berkeley Internet Name Domain 的首字母缩写词，反映了该应用程序在 UCB 中的使用。最新版本是 BIND 9，于 2000 年首次发布，仍然由 Internet Systems Consortium (ISC) 积极维护，每年发布数次新版本。
BIND9 已进化为一个非常灵活，全功能的 DNS 系统。无论您的应用程序是什么，绑定 9 可能具有所需的功能。作为第一个，最旧，最常见的解决方案，还有更多网络工程师已经熟悉绑定 9，而不是与任何其他系统。
BIND 部署 dns 服务，包名 bind，程序名 named
基础程序包：bind 提供服务，bing-libs 提供库文件，bind-utils 提供测试程序
rndc:remote name domain controller,默认与 bind 安装在同一主机，且只能通过 127.0.1 来连接 named 进程，提供辅助性的管理功能，使用 tcp 的 953 端口</description></item><item><title>Blackbox Exporter</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Blackbox-Exporter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Blackbox-Exporter/</guid><description>概述 参考：
GitHub 项目，prometheus/blackbox_exporter 官方文档 公众号 - 云原生小白，Prometheus Operator中探针的使用 我们可以使用如下几种协议来对目标进行探测
http tcp dns icmp 使用方法 curl &amp;#39;http://10.244.1.26:19115/probe?module=http_2xx&amp;amp;target=www.baidu.com&amp;#39; Prometheus 使用 Blackbox Exporter 的配置示例 与一般 Exporter 配置不同， Blackbox Exporter 的配置方式与 SNMP Exporter 更像，每一个待探测的目标将会作为 Blackbox Exporter 程序的参数。可以通过 Relabel 机制，设置目标的 instance 标签。
scrape_configs: - job_name: &amp;#34;blackbox-http-get&amp;#34; metrics_path: /probe params: module: [http_2xx] # Look for a HTTP 200 response. static_configs: - targets: - http://prometheus.io # Target to probe with http. - https://prometheus.io # Target to probe with https.</description></item><item><title>Bond 与 Team</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bond-%E4%B8%8E-Team/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/Bond-%E4%B8%8E-Team/</guid><description>概述 参考：
Wiki, Link Aggregation Wiki, MII Linux 内核文档,Linux 网络文档-Linux 以太网 Bonding 驱动入门指南(这里可以看到所有 Bonding 参数) Linux 基金会 Wiki,网络-bonding 红帽官方的 bond 说明文档：https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/networking_guide/ch-configure_network_bonding https://www.ibm.com/docs/en/linux-on-systems?topic=recommendations-link-monitoring Link Aggregation(链路聚合) 技术就是将多条物理链路聚合成一条带宽更高的逻辑链路，该逻辑链路的带宽等于被聚合在一起的多条物理链路的带宽之和。聚合在一起的物理链路的条数可以根据业务的带宽需求来配置。因此链路聚合具有成本低，配置灵活的优点，此外，链路聚合还具有链路冗余备份的功能，聚合在一起的链路彼此动态备份，提高了网络的稳定性。早期链路聚合技术的实现没有统一的标准，各厂商都有自己私有的解决方案，功能不完全相同，也互不兼容。因此，IEEE 专门制定了链路聚合的标准，目前链路聚合技术的正式标准为 IEEE Standard 802.3ad，而 Link Aggregation Control Protocol(链路汇聚控制协议,LACP) 是该标准的主要内容之一，是一种实现链路动态聚合的协议。
Link Aggregation Control Protocol Link Aggregation Control Protocol(链路汇聚控制协议，简称 LACP) 在 IEEE 以太网标准中，提供了一种方法，可以将多个物理链路捆绑在一起以形成单个逻辑链路。LACP 允许网络设备通过将 LACP 数据包发送到 Peer(对等方) 以 negotiate(协商) 链路状态，并实现自动捆绑。
Peer(对等方) 指的是与本网络设备直连的可以实现 LACP 的对端网络设备 LACP 数据包通常称为 Link Aggregation Control Protocol Data Unit(链路汇聚控制协议数据单元，简称 LACPDU)
Bond，网卡绑定 Bond 类型的网络设备是通过把多个网络设备绑定为一个逻辑网络设备，实现本地网络设备的冗余、带宽扩容和负载均衡。在应用部署中是一种常用的技术。
Linux 中使用 bonding 模块实现 bonding 驱动程序。</description></item><item><title>Boot Configuration</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Boot-Configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Boot-Configuration/</guid><description>概述 参考：
Linux Kernel 官网文档，Linux 内核用户和管理员指南-内核引导配置 Boot Configuration(引导配置) 扩展了当前内核命令行，在引导内核时，可以提供额外的运行时配置。该文件默认在 /boot/config-$(uname -r)，每个内核版本都有一个对应的文件。
该文件有几千行，每一行都是一个以 = 分割的键值对，用来在系统启动内核前的引导阶段，为内核配置运行时行为
Linux Namespace 配置 CONFIG_CHECKPOINT_RESTORE=y CONFIG_NAMESPACES=y # 是否启用 Linux Namespace CONFIG_UTS_NS=y # 是否启用 UTS NS CONFIG_IPC_NS=y # 是否启用 IPC NS CONFIG_USER_NS=y CONFIG_PID_NS=y CONFIG_NET_NS=y # # 是否启用 NET NS CONFIG_UIDGID_STRICT_TYPE_CHECKS=y CONFIG_SCHED_AUTOGROUP=y CONFIG_MM_OWNER=y</description></item><item><title>BPF 相关文章</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/</guid><description>[译] 利用 eBPF 支撑大规模 K8S Service
为容器时代设计的高级 eBPF 内核特性（FOSDEM, 2021）</description></item><item><title>BPF 在网络领域的实现</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E5%9C%A8%E7%BD%91%E7%BB%9C%E9%A2%86%E5%9F%9F%E7%9A%84%E5%AE%9E%E7%8E%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/BPF-%E5%9C%A8%E7%BD%91%E7%BB%9C%E9%A2%86%E5%9F%9F%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid><description>概述 参考：
arthurchiao.art 的文章 [译] 为容器时代设计的高级 eBPF 内核特性（FOSDEM, 2021) eBPF 架构 eBPF 能够让你在内核中创建新的 DataPath。eBPF 就是内核本身的代码，想象空间无限，并且热加载到内核；换句话说，一旦加载到内核，内核的行为就变了。在 eBPF 之前，改变内核行为这件事情，只能通过修改内核再重新编译，或者开发内 核模块才能实现。
由于上述原因，真正的 eBPF，应该是基于 eBPF 实现的数据路径，由于 eBPF 可以修改内核，所以可以在内核创建新的类似 Netfilter 的 Hook 点，以便跳过复杂的 Netfilter。甚至可以直接在网卡驱动中运行 eBPF 代码，而无需将数据包送到复杂的协议栈进行处理。</description></item><item><title>bpftrace 工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/bpftrace-%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/bpftrace-%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
GitHub 项目，iovisor/bpftrace bpftrace 是用于 Linux 增强型 eBPF 的高级跟踪语言，可在最近的 Linux 内核 (4.x) 中使用。 bpftrace 使用 LLVM 作为后端，将脚本编译为 BPF 字节码，并利用 BCC 与 Linux BPF 系统交互，以及现有的 Linux 跟踪功能：内核动态跟踪（kprobes）、用户级动态跟踪（uprobes）、和跟踪点。 bpftrace 语言的灵感来自 awk 和 C，以及 DTrace 和 SystemTap 等前身跟踪器。 bpftrace 是由 Alastair Robertson 创建的。、
简单示例
# Files opened by process bpftrace -e &amp;#39;tracepoint:syscalls:sys_enter_open { printf(&amp;#34;%s %s\n&amp;#34;, comm, str(args-&amp;gt;filename)); }&amp;#39; # Syscall count by program bpftrace -e &amp;#39;tracepoint:raw_syscalls:sys_enter { @[comm] = count(); }&amp;#39; # Read bytes by process: bpftrace -e &amp;#39;tracepoint:syscalls:sys_exit_read /args-&amp;gt;ret/ { @[comm] = sum(args-&amp;gt;ret); }&amp;#39; # Read size distribution by process: bpftrace -e &amp;#39;tracepoint:syscalls:sys_exit_read { @[comm] = hist(args-&amp;gt;ret); }&amp;#39; # Show per-second syscall rates: bpftrace -e &amp;#39;tracepoint:raw_syscalls:sys_enter { @ = count(); } interval:s:1 { print(@); clear(@); }&amp;#39; # Trace disk size by process bpftrace -e &amp;#39;tracepoint:block:block_rq_issue { printf(&amp;#34;%d %s %d\n&amp;#34;, pid, comm, args-&amp;gt;bytes); }&amp;#39; # Count page faults by process bpftrace -e &amp;#39;software:faults:1 { @[comm] = count(); }&amp;#39; # Count LLC cache misses by process name and PID (uses PMCs): bpftrace -e &amp;#39;hardware:cache-misses:1000000 { @[comm, pid] = count(); }&amp;#39; # Profile user-level stacks at 99 Hertz, for PID 189: bpftrace -e &amp;#39;profile:hz:99 /pid == 189/ { @[ustack] = count(); }&amp;#39; # Files opened, for processes in the root cgroup-v2 bpftrace -e &amp;#39;tracepoint:syscalls:sys_enter_openat /cgroup == cgroupid(&amp;#34;/sys/fs/cgroup/unified/mycg&amp;#34;)/ { printf(&amp;#34;%s\n&amp;#34;, str(args-&amp;gt;filename)); }&amp;#39;</description></item><item><title>BuildKit 构建工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/BuildKit-%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/BuildKit-%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
GitHub 项目，moby/buildkit 官方文档 知乎，官方下一代Docker镜像构建神器 &amp;ndash; BuildKit BuildKit 是 Docker 上游社区(Moby)推出的下一代镜像构建神器，可以更加快速，有效，安全地构建容器镜像。Docker v18.06 已经集成了该组件。BuildKit 可用于多种导出格式（例如 OCI 或 Docker）以及前端支持（Dockerfile），并提供高效缓存和运行并行构建操作等功能。BuildKit 仅需要容器运行时就能执行，当前受支持的运行时包括 Containerd 和 Runc。
构建步骤优化 Docker 提供的原始构建最令人沮丧的问题之一是 Dockerfile 指令执行构建步骤的顺序性。在引入多阶段构建之后，可以将构建步骤分组为单独的逻辑构建任务在同一个 Dockerfile 中。
有时，这些构建阶段是彼此完全独立的，这意味着它们可以并行执行-或根本不需要执行。遗憾的是，传统的 Docker 镜像构建无法满足这种灵活性。这意味着构建时间通常会比绝对必要的时间更长。
相比之下，BuildKit 会创建一个构建步骤之间的依赖关系图，并使用该图来确定可以忽略构建的哪些元素;可以并行执行的元素;需要顺序执行的元素。这可以更有效地执行构建，这对开发人员来说很有价值，因为他们可以迭代其应用程序的镜像构建。
高效灵活的缓存 虽然在旧版 Docker 镜像构建中缓存构建步骤非常有用，但效率却不如预期。作为对构建后端的重写，BuildKit 在此方面进行了改进，并提供了更快，更准确的缓存机制。使用为构建生成的依赖关系图，并且基于指令定义和构建步骤内容。
BuildKit 提供的另一个巨大好处是以构建缓存导入和导出的形式出现，正如 Kaniko 和 Makisu 允许将构建缓存推送到远程注册表一样，BuildKit 也是如此，但是 BuildKit 使您可以灵活地将缓存嵌入到内部注册表中。镜像（内联）并将它们放在一起（虽然不是每个注册表都支持），或者将它们分开导入。也可以将缓存导出到本地目录以供以后使用。
当从头开始建立构建环境而没有任何先前的构建历史时，导入构建缓存的能力就发挥了自己的作用：导入“预热”缓存，对于临时 CI/CD 环境特别有用。
工件 当使用旧版 Docker 镜像构建器构建镜像时，将生成的镜像添加到 Docker 守护进程管理的本地镜像的缓存中。需要单独的docker push将该镜像上载到远程容器镜像注册表。新的工件构建工具通过允许您在构建调用时指定镜像推送来增强体验，BuildKit 也不例外，它还允许以几种不同格式输出镜像；本地目录中的文件，本地 tarball，一个本地 OCI 镜像 tarball，一个 Docker 镜像 tarball，一个存储在本地缓存中的 Docker 镜像以及一个推送到注册表的 Docker 镜像，有很多格式！</description></item><item><title>C10K 与 C100K 问题</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/C10K-%E4%B8%8E-C100K-%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/C10K-%E4%B8%8E-C100K-%E9%97%AE%E9%A2%98/</guid><description>你好，我是倪朋飞。
前面内容，我们学习了 Linux 网络的基础原理以及性能观测方法。简单回顾一下，Linux 网络基于 TCP/IP 模型，构建了其网络协议栈，把繁杂的网络功能划分为应用层、传输层、网络层、网络接口层等四个不同的层次，既解决了网络环境中设备异构的问题，也解耦了网络协议的复杂性。
基于 TCP/IP 模型，我们还梳理了 Linux 网络收发流程和相应的性能指标。在应用程序通过套接字接口发送或者接收网络包时，这些网络包都要经过协议栈的逐层处理。我们通常用带宽、吞吐、延迟、PPS 等来衡量网络性能。
今天，我们主要来回顾下经典的 C10K 和 C1000K 问题，以更好理解 Linux 网络的工作原理，并进一步分析，如何做到单机支持 C10M。
注意，C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接 1 万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接 100 万）的问题。
C10K C10K 问题最早由 Dan Kegel 在 1999 年提出。那时的服务器还只是 32 位系统，运行着 Linux 2.2 版本（后来又升级到了 2.4 和 2.6，而 2.6 才支持 x86_64），只配置了很少的内存（2GB）和千兆网卡。
怎么在这样的系统中支持并发 1 万的请求呢？
从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以。所以，物理资源是足够的，接下来自然是软件的问题，特别是网络的 I/O 模型问题。</description></item><item><title>Calico</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Calico/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Calico/</guid><description>Calico 基本概念 基于以 BGP 协议构建网络，主要由三个部分组成
第一部分：Calico 的 CNI 插件。这是 Calico 与 Kubernetes 对接的部分
第二部分：Felix，一个 DaemonSet。负责在 Host 上插入路由规则(即：写入 Linux 内核的 FIB(转发信息库 Forwarding information base)，以及维护 Calico 所需的网络设备等工作
第三部分：BIRD，BGP Client。专门负责在集群内分发路由规则信息
Calico 利用 Linux 内核原生的路由和 iptables 防火墙功能。进出各个容器，虚拟机和主机的所有流量都会在路由到目标之前遍历这些内核规则。
calicoctl：允许您从简单的命令行界面实现高级策略和网络。 orchestrator plugins：提供与各种流行协调器的紧密集成和同步。 key/value store：保存 Calico 的策略和网络配置状态。比如 etcd calico/node：在每个主机上运行，从 key/value store 中读取相关的策略和网络配置信息，并在 Linux 内核中实现它。 Dikastes/Envoy：可选的 Kubernetes sidecar，通过相互 TLS 身份验证保护工作负载到工作负载的通信，并实施应用层策略。 Calico BGP 工作原理 实际上，Calico 项目提供的网络解决方案，与 Flannel 的 host-gw 模式，几乎是完全一样的。也就是说，Calico 也会在每台宿主机上，添加一个格式如下所示的路由规则：
&amp;lt; 目的容器 IP 地址段 &amp;gt; via &amp;lt; 网关的 IP 地址 &amp;gt; dev eth0 其中，网关的 IP 地址，正是目的容器所在宿主机的 IP 地址。</description></item><item><title>CDN</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/CDN/CDN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/CDN/CDN/</guid><description>概述 http://3ms.huawei.com/km/groups/1002549/home?l=zh-cn#category=5402776 学习材料
Content Delivery Network(内容分发网络，简称 CDN)
内容的定义：内容就是资源，人们浏览的网页，下载的数据，观看的视频等等都属于内容范畴
CDN 产生的原因以及 CDN 的基本概念
非签约模式：即不通过与内容提供方签约的方式来获取资源镜像
DNS 引流 流量镜像 签约模式：即与内容提供方签约后，获取对方的资源景象
通过 CNAME，域名的别名方式来重定向用户请求 模式 非签约模式 签约模式 文件类型 大文件(视频类，下载类) 小文件(网页类) 大文件(视频类，下载类) 小文件(网页类) 调度模式 流量镜像 本地 DNS DNS 引流，转发 全局 DNS+本地 HTTP 全局 DNS CDN 流程
Cache 结构
用户请求资源的缓存状态信息表：
TCP_HIT：内网用户请求的资源是 HCS 已缓存资源，内网用户获取的资源来自于 HCS 中的已缓存资源。 TCP_MISS：内网用户请求的资源不是 HCS 已缓存资源，内网用户获取的资源来自于外网 Web 服务器。 TCP_CNC_MISS：内网用户请求的头部规定不缓存这个资源，HCS 不缓存这个资源，内网用户获取的资源来自于外网 Web 服务器。 TCP_SNC_MISS：外网 Web 服务器返回的头部规定不缓存这个资源，HCS 不缓存这个资源，内网用户获取的资源来自于外网 Web 服务器。 TCP_REFRESH(刷新)_HIT：内网用户请求的资源命中了 HCS 已缓存资源，但 HCS 需要检查这个资源是否已更新，外网 Web 服务器通知 HCS 这个资源未修改，HCS 将这个资源发送给内网用户。 TCP_REFRESH_MISS_METADATA：外网 Web 服务器返回一个对应请求资源的 304 报文，表示这个资源已临时被移走。 TCP_REFRESH_MISS：内网用户请求的资源命中了 HCS 已缓存资源，但 HCS 需要检查这个资源是否已更新，外网 Web 服务器通知 HCS 这个资源已经过期，HCS 重新从 Web 服务器获取这个资源后再发送给内网用户。 TCP_PARTIAL(部分)_HIT：客户端分段请求文件的时候，命中请求资源。 TCP_PARTIAL_MISS：客户端分段请求文件的时候，未命中请求资源。 TCP_REFRESH_UKN_MISS：内网用户请求的资源命中了 HCS 已缓存资源，但 HCS 需要检查这个资源是否已更新，但未能判断出是否更新，代理访问。 TCP_REFRESH_NC_MISS：内网用户请求的资源命中了 HCS 已缓存资源，但 HCS 需要检查这个资源是否已更新，，外网 Web 服务器通知 HCS 这个资源未修改，但未从本地吐出，代理访问。 PCDN 参考：</description></item><item><title>Ceph 部署</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档，Cephadm 以 pacific 版本为例 安装 cephadm 在所有节点安装 cephadm，这是一个 python 程序，当通过第一个节点让其他节点加入集群时，会调用待加入节点中的 cephadm 程序。
curl --silent --remote-name --location https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm chmod +x cephadm ./cephadm add-repo --release pacific ./cephadm install cephadm install ceph-common 引导第一个节点 cephadm bootstrap --mon-ip 192.168.1.201 配置 ceph CLI cephadm install ceph-common 其他 # 开启遥测，发送数据给官方 ceph telemetry on 添加其他节点 # 添加认证信息 ssh-copy-id -f -i /etc/ceph/ceph.pub root@192.168.1.202 ssh-copy-id -f -i /etc/ceph/ceph.pub root@192.168.1.203 # 添加节点 ceph orch host add hw-cloud-xngy-ecs-test-0002 192.168.1.202 ceph orch host add hw-cloud-xngy-ecs-test-0003 192.</description></item><item><title>Ceph 故障排查笔记</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E7%AC%94%E8%AE%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E7%AC%94%E8%AE%B0/</guid><description>参考：公众号,云原声实验室-Ceph 故障排查笔记 | 万字经验总结
Ceph OSD 异常无法正常启动 当某个 OSD 无法正常启动时：
$ ceph -s cluster: id: b313ec26-5aa0-4db2-9fb5-a38b207471ee health: HEALTH_WARN Degraded data redundancy: 177597/532791 objects degraded (33.333%), 212 pgs degraded, 212 pgs undersized application not enabled on 3 pool(s) mon master003 is low on available space 1/3 mons down, quorum master002,master003 services: mon: 3 daemons, quorum master002,master003, out of quorum: master001 mgr: master003(active), standbys: master002 mds: kubernetes-1/1/1 up {0=master002=up:active}, 1 up:standby osd: 2 osds: 2 up, 2 in data: pools: 5 pools, 212 pgs objects: 177.</description></item><item><title>Ceph 命令行工具</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/Ceph/Ceph-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，Ceph 存储集群-手册页 官方文档，Ceph 对象网关-radosgw-admin 手册页 ceph # Ceph 管理工具 一个 Python 实现的脚本工具，用于手动部署和似乎 Ceph 集群。通过很多的子命令，允许部署 ceph-mon、ceph-osd、PG、ceph-mds 等，并可以对集群整体进行维护和管理。
orch Orchestrator(编排器，简称 orch)
Syntax(语法) COMMAND
host # 对集群中的节点进行管理 add &amp;lt;HOSTNAME&amp;gt; [ADDR] [LABELs&amp;hellip;] [&amp;ndash;maintenance] # 向集群中添加一个节点 label add &amp;lt;HOSTNAME&amp;gt; &amp;lt;LABEL&amp;gt; # 为节点添加一个标签 ls # 列出 Orch 已知的服务 rm &amp;lt;ServiceName&amp;gt;# 移除一个服务 EXAMPLE
radosgw-admin # RADOS 网关的用户管理工具 radosgw-admin 是一个 RADOS 网关用户的管理工具。可以增删改查用户。该工具通过非常多的子命令进行管理，并且每个子命令可用的选项也各不相同，Ceph 官方对这个工具的提示做的非常不好，子命令需要带的选项并不提示，只能自己尝试~~~
user Syntax(语法) radosgw-admin user COMMAND [OPTIONS]
COMMAND
user create &amp;ndash;display-name=&amp;lt;STRING&amp;gt; &amp;ndash;uid=&amp;lt;STRING&amp;gt; # 创建一个新用户 user info [&amp;ndash;uid=&amp;lt;STRING&amp;gt; | &amp;ndash;access-key=&amp;lt;STRING&amp;gt;] # 显示一个用户的信息，包括其子用户和密钥。通过 uid 或 ak 指定要显示的用户。 user list # 列出所有用户 user modify &amp;ndash;uid=&amp;lt;STRING&amp;gt; # 修改指定的用户 OPTIONS</description></item><item><title>CGroup FS</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/2.CGroup/CGroup-FS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/2.CGroup/CGroup-FS/</guid><description>概述 参考：
/sys/fs/cgroup/* CGroupV1 CGroupV1 根目录下的每个目录的名称都是一个子系统的名称，每个子系统都有其自己独立的资源控制配置文件。
~]# ls -l /sys/fs/cgroup/ total 0 dr-xr-xr-x 5 root root 0 Jan 26 21:46 blkio lrwxrwxrwx 1 root root 11 Jan 26 21:46 cpu -&amp;gt; cpu,cpuacct lrwxrwxrwx 1 root root 11 Jan 26 21:46 cpuacct -&amp;gt; cpu,cpuacct dr-xr-xr-x 5 root root 0 Jan 26 21:46 cpu,cpuacct dr-xr-xr-x 3 root root 0 Jan 26 21:46 cpuset dr-xr-xr-x 5 root root 0 Jan 26 21:46 devices dr-xr-xr-x 4 root root 0 Jan 26 21:46 freezer dr-xr-xr-x 3 root root 0 Jan 26 21:46 hugetlb dr-xr-xr-x 5 root root 0 Jan 26 21:46 memory lrwxrwxrwx 1 root root 16 Jan 26 21:46 net_cls -&amp;gt; net_cls,net_prio dr-xr-xr-x 3 root root 0 Jan 26 21:46 net_cls,net_prio lrwxrwxrwx 1 root root 16 Jan 26 21:46 net_prio -&amp;gt; net_cls,net_prio dr-xr-xr-x 3 root root 0 Jan 26 21:46 perf_event dr-xr-xr-x 5 root root 0 Jan 26 21:46 pids dr-xr-xr-x 2 root root 0 Jan 26 21:46 rdma dr-xr-xr-x 5 root root 0 Jan 26 21:46 systemd dr-xr-xr-x 5 root root 0 Jan 26 21:46 unified .</description></item><item><title>Chart Hooks</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Charts/Chart-Hooks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Charts/Chart-Hooks/</guid><description>Chart Hooks 概述 参考：官方文档
Helm 提供了一种** Hook(钩子) **机制可以在一个 release 的生命周期内进行干预，比如：
安装任何资源之前，提前先安装 ConfigMap 或者 Secret
在安装一个新的 Chart 执行，执行一个 Job 以备份数据库，然后在升级后执行第二个 Job 以还原数据。
在删除一个 Release 之前，运行一个 Job，以便在删除服务之前优雅得停止服务。
等等等
说白了：就是让我们在操作 Chart 中的资源时，可以运行一个 Job 或某些资源(比如删除 operator 之前，运行一个 job 先删除所有 CRD 资源)。有点类似与就类似 crds 目录 的作用一样，但并不完全一样。
Hooks 种类 pre-install # 在渲染模板之后、创建资源之前，执行安装
post-install # 在 Chart 中所有资源创建之后(并不用等待 running)，执行安装
pre-delete # 在从 Kubernetes 删除任何资源之前，执行安装
post-delete # 删除所有 releases 资源后，执行安装
pre-upgrade # 在渲染模板之后，在任何资源更新之前，执行安装
post-upgrade # 在所有资源都升级后，执行安装
pre-rollback # Executes on a rollback request after templates are rendered, but before any resources are rolled back</description></item><item><title>Charts</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Charts/Charts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Charts/Charts/</guid><description>概述 参考：
官方文档，主题-charts Helm 管理的安装包称为 Charts(图表)。就好比 Cento 的安装包是 rpm、Windows 的安装包是 exe、Ubuntu 的安装包是 deb。
Charts 是描述 Kubernete 资源的一组 manifests 集合，被有规则得放在特定的目录树中。这些 Charts 可以打包成 archives。
Chart 也有海图的概念，就好像 Helm 代表舵柄一样，当人们手握 Helm 在大海中航行时，可以查看 Charts，来观察地图，以便决定我们如何航行。
Chart File Structure(图表文件结构) 官方文档：https://helm.sh/docs/topics/charts/
一个 Chart 保存在一个目录中，目录名就是 Chart 的名称(没有版本信息)。比如 myapp 这个 chart 就放在 ./mapp/ 这个目录中
在这个目录中，一般由以下内容组成：
带有 OPTIONAL 表示不是必须的，可选的内容就算不存在，该 chart 也可正常使用
Chart.yaml # 用来做 Chart 的初始化的文件，记录该 Chart 的名称、版本、维护者等元数据信息 LICENSE # (OPTIONAL)一个 chart 许可证的纯文本文件。 README.md # (OPTIONAL)一个易于阅读的自述文件。 values.yaml # 用于给 templates 目录下的各个 manifests 模板设定默认值。values.</description></item><item><title>Chrony</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Time-and-Language/Chrony/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Time-and-Language/Chrony/</guid><description>概述 参考：
GitLab，chrony/chrony 官网 官方文档 Chrony 是 NTP(网络时间协议) 的通用实现。它可以将系统时钟与 NTP 服务器，参考时钟（例如 GPS 接收器）以及使用手表和键盘进行的手动输入进行同步。它还可以充当 NTPv4（RFC 5905）服务器并与之对等，以向网络中的其他计算机提供时间服务。
yum install chrony 即可安装该工具
Chrony 配置 /etc/chrony.conf # chronyd 守护进程运行的配置文件。该文件官方说明：https://chrony.tuxfamily.org/doc/3.4/chrony.conf.html
基础配合文件示例 # 指定 NTP 服务器。使用指定的 NTP 服务来同步本地时间。可以使用本机 ip，表示与本机同步时间。 server 172.40.0.3 iburst # Record the rate at which the system clock gains/losses time. driftfile /var/lib/chrony/drift # Allow the system clock to be stepped in the first three updates # if its offset is larger than 1 second.</description></item><item><title>CIDR</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/CIDR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/CIDR/</guid><description>概述 参考：
Wiki, CIDR Classless Inter-Domain Routing(无类别域间路由，简称 CIDR) 是一个用于给用户分配IP 地址以及在互联网上有效地路由 IP数据包的对 IP 地址进行归类的方法。
Notes: CIDR 可以看作是网段的一种表示方法。是一种表示 IP Blocks(网络地址块) 或 SubNet(子网) 的方法
在域名系统出现之后的第一个十年里，基于分类网络进行地址分配和路由 IP 数据包的设计就已明显显得可扩充性不足（参见 RFC 1517）。为了解决这个问题，互联网工程工作小组在 1993 年发布了一新系列的标准 RFC 1518 和 RFC 1519 以定义新的分配 IP 地址块和路由IPv4数据包的方法。
一个 IP 地址包含两部分：标识网络的前缀和紧接着的在这个网络内的主机地址。在之前的分类网络中，IP 地址的分配把 IP 地址的 32 位按每 8 位为一段分开。这使得前缀必须为 8，16 或者 24 位。因此，可分配的最小的地址块有 256（24 位前缀，8 位主机地址，28=256）个地址，而这对大多数企业来说太少了。大一点的地址块包含 65536（16 位前缀，16 位主机，216=65536）个地址，而这对大公司来说都太多了。这导致不能充分使用 IP 地址和在路由上的不便，因为大量的需要单独路由的小型网络（C 类网络）因在地域上分得很开而很难进行聚合路由，于是给路由设备增加了很多负担。
无类别域间路由是基于 Variable-length Subnet Masking(可变长子网掩码，简称 VLSM) 来进行任意长度的前缀的分配。在 RFC 950（1985）中有关于可变长子网掩码的说明。CIDR 包括：
指定任意长度的前缀的可变长子网掩码技术。遵从 CIDR 规则的地址有一个后缀说明前缀的位数，例如：192.</description></item><item><title>client-go连接K8s集群进行pod的增删改查</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/client-go%E8%BF%9E%E6%8E%A5K8s%E9%9B%86%E7%BE%A4%E8%BF%9B%E8%A1%8Cpod%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/client-go%E8%BF%9E%E6%8E%A5K8s%E9%9B%86%E7%BE%A4%E8%BF%9B%E8%A1%8Cpod%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/</guid><description>背景 最近在看client-go源码最基础的部分，client-go的四类客户端，RestClient、ClientSet、DynamicClient、DiscoveryClient。其中RestClient是最基础的客户端，它对Http进行了封装，支持JSON和protobuf格式数据。其它三类客户端都是通过在RestClient基础上再次封装而得来。不过我对ClientSet和DynamicClient傻傻分不清，虽然很多资料上说它两最大区别是，ClientSet能够使用预先生成的Api和ApiServer进行通信；而DynamicClient更加强大，不仅仅能够调用预先生成的Api，还能够对一些CRD资源通过结构化嵌套类型跟ApiServer进行通信。意思大致明白前者能够调用Kubernetes本地资源类型，后者还可以调用一些自定资源，那么他们究竟是如何跟ApiServer进行交互、Pod的增删改查呢？本文通过分析ClientSet代码和client-go客户端调用Kubernetes集群的方式来演示下整个交互过程。
准备工作 已经安装Kubernetes集群和配置本地IDE环境
根据kubernetes集群版本选择clone client-go到本地：https://github.com/kubernetes/client-go/tree/release-14.0。 导入到IDE。 运行 examples/create-update-delete-deployment/main.go 正常情况下会提示如下错误： panic: CreateFile C:\Users\shj\.kube\config: The system cannot find the path spe cified. 错误信息提示很清楚，没有找到本地文件夹下的config文件，处理方式也很简单，只需要把你Kubernetes集群中$HOME/.kube/config复制到本地即可；仔细阅读代码可以发现，也可以通过自行配置客户端连接信息（生产环境慎用）。
4、运行 main 函数即可进行 Pod 增删改查操作。
client-go 连接 ApiServer 进行 Pod 的增删改查 获取APIserver连接地址、认证配置等信息 var kubeconfig *string //获取当前用户home文件夹，并获取kubeconfig配置 if home := homedir.HomeDir(); home != &amp;#34;&amp;#34; { kubeconfig = flag.String(&amp;#34;kubeconfig&amp;#34;, filepath.Join(home, &amp;#34;.kube&amp;#34;, &amp;#34;config&amp;#34;), &amp;#34;(optional) absolute path to the kubeconfig file&amp;#34;) } else {//如果没有获取到，则需要自行配置kubeconfig kubeconfig = flag.String(&amp;#34;kubeconfig&amp;#34;, &amp;#34;&amp;#34;, &amp;#34;absolute path to the kubeconfig file&amp;#34;) } //把用户传递的命令行参数，解析为响应变量的值 flag.</description></item><item><title>Clonezilla</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Clonezilla/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Clonezilla/</guid><description>概述 参考：
官网 知乎，使用再生龙CloneZilla进行Linux系统的镜像完全封装和还原 其他实践： https://blog.csdn.net/zhaoxinfan/article/details/126474777 https://blog.csdn.net/zhangjia453/article/details/115353982 Clonezilla 是类似于 True Image 或 Norton Ghost 的分区和磁盘映像/克隆程序。它可以帮助您进行系统部署、裸机备份和恢复。可以使用三种类型的 Clonezilla：
Clonezilla live # Clonezilla live 允许您使用 CD/DVD 或 USB 闪存驱动器启动和运行 clonezilla（仅限单播） Clonezilla lite server # Clonezilla 精简版服务器允许您使用 Clonezilla live 进行大规模克隆（支持单播、广播、多播、比特流） Clonezilla SE # Clonezilla SE 包含在 DRBL 中，因此必须首先设置 DRBL 服务器才能使用 Clonezilla 进行大规模克隆（支持单播、广播和组播） Clonezilla live 适用于单机备份和恢复。虽然 Clonezilla 精简版服务器或 SE 用于大规模部署，但它可以同时克隆多台（40 多台！）计算机。Clonezilla 仅保存和恢复硬盘中使用过的块。这提高了克隆效率。对于 42 节点集群中的一些高端硬件，报告了以 8 GB/分钟的速率恢复的多播。
CloneZilla 可以将 Linux 完整移植到另一台机器中，保证数据，分区，挂载，启动项。。所有的一切完全一致
注意：进行还原的机器需要与进行镜像封装的机器关键硬件配置一致，否则可能产生显卡驱动无法使用等问题
Clonezilla Live 本身就是一个小型的 Liunx 发行版，这就像是 Linux 版的 WinPE 一样。除了图形页面可供操作外，还可以通过命令行，执行诸如 ssh 之类的命令。这也就意味着，Clonezilla 可以读写远程存储设备中，封装好的 Linux 镜像可以直接写入到 NFS、S3 中，还原 Linux 时，也可以从这些远程存储设备中读取镜像。</description></item><item><title>Cobbler 部署</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/Cobbler-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/Cobbler-%E9%83%A8%E7%BD%B2/</guid><description>概述 基础环境准备 检测 selinux 是否关闭(必须关闭)
setenforce 0 sed -i &amp;#39;s/SELINUX=enforcing/SELINUX=disabled/&amp;#39; /etc/selinux/config 检测防火墙是否关闭(必须关闭)
systemctl disable firewalld &amp;amp;&amp;amp; systemctl stop firewalld 注意：
虚拟机网卡采用桥接模式，不使用 NAT 模式，我们会搭建 DHCP 服务器，在同一局域网多个 DHCP 服务会有冲突，所以最好把路由器的 DHCP 服务关闭 安装 Cobbler 以及相关功能配件 yum install cobbler cobbler-web pykickstart httpd dhcp tftp-server fence-agents -y
cobbler # cobbler 程序包 cobbler-web # cobbler 的 web 服务包 pykickstart # cobbler 检查 kickstart 语法错误 httpd # Apache web 服务 dhcp # dhcp 服务 tftp-server # tftp 服务 systemctl enable cobblerd httpd tftp rsyncd dhcpd &amp;amp;&amp;amp; systemctl start cobblerd httpd tftp rsyncd dhcpd</description></item><item><title>cobbler 命令说明</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/cobbler-%E5%91%BD%E4%BB%A4%E8%AF%B4%E6%98%8E/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/cobbler-%E5%91%BD%E4%BB%A4%E8%AF%B4%E6%98%8E/</guid><description>distro cobbler distro report &amp;ndash;name=CentOS7-1810 # 查看安装镜像文件信息 import cobbler import [OPTIONS]
OPTIONS
&amp;ndash;path # 指定制作部署系统时的镜像所用到的光盘镜像的路径 &amp;ndash;name # 为安装源定义一个名字，指定部署系统所用的镜像名 &amp;ndash;arch # 指定安装源是 32 位、64 位、ia64, 目前支持的选项有: x86│x86_64│ia64 EXAMPLE
cobbler import &amp;ndash;path=/mnt/ &amp;ndash;name=CentOS7-1810 &amp;ndash;arch=x86_64 profile cobbler profile report &amp;ndash;name=CentOS7-x86_64 # 查看指定的 profile 设置 system cobbler system list # 列出 ksvalidator FILE 用于测试指定 FILE 的 kickstart 语法是否正确</description></item><item><title>Cobra</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/CLI/Cobra/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/CLI/Cobra/</guid><description>概述 参考：
GitHub 项目，spf13/cobra 官网 https://zhangguanzhang.github.io/2019/06/02/cobra/ Cobra 是一个 Go 语言的库，其提供简单的接口来创建强大现代的 CLI 接口，类似于 git 或者 go 工具。同时，它也是一个应用，用来生成个人应用框架，从而开发以 Cobra 为基础的应用。热门的 docker 和 k8s 源码中都使用了 Cobra
Cobra 结构由三部分组成：
Command(命令) # Args(参数) # Flag(标志) # type Command struct { Use string // The one-line usage message. Short string // The short description shown in the &amp;#39;help&amp;#39; output. Long string // The long message shown in the &amp;#39;help&amp;lt;this-command&amp;gt;&amp;#39; output. Run func(cmd *Command, args []string) // Run runs the command.</description></item><item><title>Cockpit</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Cockpit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Cockpit/</guid><description>概述 参考：
官网：https://cockpit-project.org/ cockpit 是一个基于 web 的 Linxu 服务器管理工具。可以通过 web 端管理服务器上的虚拟机、容器、服务、网络、存储等等。还可以提供一个 web 版的控制台。
Cockpit 关联文件与配置 /etc/cockpit/
./ws-certs.d/ # https 证书保存目录。cockpit 第一次启动时，会在该目录生成 https 所需的 证书与私钥</description></item><item><title>config 子命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/config-%E5%AD%90%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/config-%E5%AD%90%E5%91%BD%E4%BB%A4/</guid><description>概述 config 子命令用于控制 User Account(KubeConfig) 的 KubeConfig 文件
Syntax(语法) **kubectl config SUBCOMMAND [options]
SUBCOMMAND 包括：
current-context # 显示当前上下文 Displays the current-context delete-cluster # Delete the specified cluster from the kubeconfig delete-context # 从 kubeconfig 文件中删除指定的上下文 get-clusters # 显示在 kubeconfig 中已经定义的 cluster 信息。Display clusters defined in the kubeconfig get-contexts # 显示在 kubeconfig 中的上下文列表。每行的信息表示包括以*表示当前使用的 context，context 名称，cluster 与 authinfo(认证信息即用户名)，名称空间 rename-context# Renames a context from the kubeconfig file. set # 在 KubeConfig 文件中设置一个单独的值。Sets an individual value in a kubeconfig file set-cluster # 在 kubeconfig 中设定集群条目。 set-context# 在 kubeconfig 中设定上下文条目。Sets a context entry in kubeconfig set-credentials # 在 kubeconfig 中设定用户凭证。 unset# 取消在 KubeConfig 文件中设置的一个单独的值。Unsets an individual value in a kubeconfig file use-context# 在 kubeconfig 中设定当前上下文(即使用哪个用户操作客户端)。 view# 显示已经合并的 KubeConfig 文件或一个指定的 KubeConfig 文件。Display merged kubeconfig settings or a specified kubeconfig file。 OPTIONS &amp;ndash;kubeconfig=/PATH/FILE # 指明要操作的 KubeConfig 文件 SubCommand(子命令) set-cluster # 在 kubeconfig 文件中设置一个集群条目。Sets a cluster entry in kubeconfig kubectl config set-cluster NAME [&amp;ndash;server=server] [&amp;ndash;certificate-authority=PATH/TO/CERTIFICATE/AUTHORITY] [&amp;ndash;insecure-skip-tls-verify=true] [OPTIONS] #</description></item><item><title>ConfigMap 与 Secret</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Volume/ConfigMap-%E4%B8%8E-Secret/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Volume/ConfigMap-%E4%B8%8E-Secret/</guid><description>概述 参考：
官方文档，概念-存储-卷-configMap 官方文档，任务-配置 Pods 和容器-使用 ConfigMap 配置 Pod ConfigMap 与 Secret 这两种资源是 Kubernetes 的配置管理中心，是一种特殊类型的 Volume。用来提供给从 k8s 集群外部到 pod 内部的应用，注入各种信息(配置文件、变量等)的功能。
这种类型的 Volume 不是为了存放 Container 中的数据，也不是用来进行 Container 与 Host 之间的数据交换。而是用来为 Container 提供预先定义好的数据。从 Container 的角度看，这些 Volume 里的信息就仿佛是被 Kubernetes &amp;ldquo;投射&amp;quot;进容器当中一样。
为什么需要 ConfigMap？ 几乎所有的应用开发中，都会涉及到配置文件的变更，比如说在 web 的程序中，需要连接数据库，缓存甚至是队列等等。而我们的一个应用程序从写第一行代码开始，要经历开发环境、测试环境、预发布环境直到最终的线上环境。而每一个环境都要定义其独立的各种配置。如果我们不能很好的管理这些配置文件，运维工作将顿时变的无比的繁琐。为此业内的一些大公司专门开发了自己的一套配置管理中心，如 360 的 Qcon，百度的 disconf 等。很多应用程序的配置需要通过配置文件，命令行参数和环境变量的组合配置来完成（“十二要素应用”等均要求去配置）。这些配置应该从 image 内容中解耦，以此来保持容器化应用程序的可移植性。
Kubernetes 也提供了自己的一套方案，即 ConfigMap。kubernetes 通过 ConfigMap 来实现对容器中应用的配置管理，configmap 是 kubernetes 中的一个资源，可以通过 yaml 来进行配置。每个运行 Pod 的环境都可以有自己的一套 configmap，只需要当 Pod 运行在此环境的时候，自动加载对应的 configmap 即可实现 Pod 中 container 的配置变更。secret 是加密的 configmap。</description></item><item><title>Connection 配置详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/Connection-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/Connection-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
Manual(手册),nm-settings-nmcli(5) # 这个 man 手册中，可以看到每个 Setting 中都有哪些 Property 以及这些 Property 的作用。 Manual(手册),nm-settings-dbus(5) # 这里有 Property 的默认值 Manual(手册),nm-settings-keyfile(5) Manual(手册),nm-settings-ifcfg-rh(5) 在 GNOME 开发者中心官网中，也可以查到 Manual Connection 配置文件默认由 keyfile 插件管理，是类似 INI 格式的。同时配置文件还会保存在 D-Bus 中。
在 D-Bus 中，NetworkManager 将 INI 中的 Sections(部分) 称为 Settings(设置)，Setting 多个是 Properties(属性) 的集合。所以，很多文档，都将 Connection 表示为一组特定的、封装好的、独立的 Settings(集合)。Connection 由一个或多个 Settings 组成。
# 我启动了一个 连接 ~]# nmcli con up bridge-slave-bond0 Connection successfully activated (master waiting for slaves) (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/16) # 从 D-Bus 的路径中可以看到这些信息 ~]# busctl get-property org.</description></item><item><title>Connnection Tracking(连接跟踪)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Connnection-Tracking%E8%BF%9E%E6%8E%A5%E8%B7%9F%E8%B8%AA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Connnection-Tracking%E8%BF%9E%E6%8E%A5%E8%B7%9F%E8%B8%AA/</guid><description>概述 参考：
arthurchiao，连接跟踪：原理、应用及 Linux 内核实现 Connection Tracking(连接跟踪系统，简称 ConnTrack、CT)，用于跟踪并且记录连接状态。CT 是 Linux 网络流量控制的基础
例如，上图是一台 IP 地址为 10.1.1.2 的 Linux 机器，我们能看到这台机器上有三条 连接：
机器访问外部 HTTP 服务的连接（目的端口 80） 外部访问机器内 FTP 服务的连接（目的端口 21） 机器访问外部 DNS 服务的连接（目的端口 53） 连接跟踪所做的事情就是发现并跟踪这些连接的状态，具体包括：
从数据包中提取元组（tuple）信息，辨别数据流（flow）和对应的连接（connection） 为所有连接维护一个状态数据库（conntrack table），例如连接的创建时间、发送 包数、发送字节数等等 回收过期的连接（GC） 为更上层的功能（例如 NAT）提供服务 需要注意的是，连接跟踪中所说的“连接”，概念和 TCP/IP 协议中“面向连接”（ connection oriented）的“连接”并不完全相同，简单来说：
TCP/IP 协议中，连接是一个四层（Layer 4）的概念。 TCP 是有连接的，或称面向连接的（connection oriented），发送出去的包都要求对端应答（ACK），并且有重传机制 UDP 是无连接的，发送的包无需对端应答，也没有重传机制 CT 中，一个元组（tuple）定义的一条数据流（flow ）就表示一条连接（connection）。 后面会看到 UDP 甚至是 ICMP 这种三层协议在 CT 中也都是有连接记录的 但不是所有协议都会被连接跟踪 本文中用到“连接”一词时，大部分情况下指的都是后者，即“连接跟踪”中的“连接”。
原理 要跟踪一台机器的所有连接状态，就需要：
拦截（或称过滤）流经这台机器的每一个数据包，并进行分析。 根据这些信息建立起这台机器上的连接信息数据库（conntrack table）。 根据拦截到的包信息，不断更新数据库 例如</description></item><item><title>Containerd Image</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-Image/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-Image/</guid><description>概述 参考：
https://blog.frognew.com/tags/containerd.html 重学容器 09: Containerd 是如何存储容器镜像和数据的 这是一个 /var/lib/containerd 目录的最基本组成：
~]# tree -L 1 . ├── io.containerd.content.v1.content ├── io.containerd.metadata.v1.bolt ├── io.containerd.runtime.v2.task ├── io.containerd.snapshotter.v1.overlayfs ├── ...... 等 └── tmpmounts 初始情况，Containerd 会加载部分插件，对应了 content、snapshot、metadata、runtime 等等插件。通过 ctr plugin ls 命令可以发现，目录名称与插件名称是一致的。
这是一个只有一个 lchdzh/k8s-debug:v1 镜像的 /var/lib/containerd 目录：
~]# tree /var/lib/containerd -L 5 . ├── io.containerd.content.v1.content │ ├── blobs │ │ └── sha256 │ │ ├── 02daccf1684b499e99c258348d492c5f0ea086174d2f0d430791d4f902ae4f71 │ │ ├── 188c0c94c7c576fff0792aca7ec73d67a2f7f4cb3a6e53a84559337260b36964 │ │ ├── 5f9b9d9c910519d9a4b1e06f031672e14acf9bcc288ed7e3ed3842916ed4394d │ │ ├── c690d4fd64d6622c3721a1db686c2e4cfb559dd1d9f9ff825584a8f56ec02c7f │ │ ├── df727e3daae2c57da7071b4056d328d4bbb9d6a913e469d8f07b58e35a5cff96 │ │ └── ee24b921ba004624b350e7f140e68c6a7d8297bb815b4ca526979a7e66cec15a │ └── ingest ├── io.</description></item><item><title>Containerd 问题汇总</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Containerd-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Containerd-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</guid><description>与老版本不兼容问题 使用 nerdctl 通过 containerd 运行容器时报错：
FATA[0000] failed to create shim: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/default/210729ebc4386d8e89132a3dea24fa0d67643587af119247837a0f1009d82fa7/log.json: no such file or directory): runc did not terminate successfully: exit status 127: unknown 本质是 runc 问题
~]# runc -v runc: symbol lookup error: runc: undefined symbol: seccomp_api_get ~]# ldd /usr/bin/runc linux-vdso.so.1 (0x00007fffbfbee000) libpthread.so.0 =&amp;gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fd802a37000) libseccomp.so.2 =&amp;gt; /lib/x86_64-linux-gnu/libseccomp.so.2 (0x00007fd802a15000) libc.so.6 =&amp;gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fd802823000) /lib64/ld-linux-x86-64.so.2 (0x00007fd8036f9000) https://github.</description></item><item><title>Context Switch(上下文切换)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Context-Switch%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Context-Switch%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/</guid><description>概述 参考：
极客时间，Linux 性能优化实战-03 基础篇：经常说的 CPU 上下文切换是什么意思 LinuxPerformance 博客，进程切换：自愿与强制 Wiki, Context Swtich 简书，进程/线程上下问切换会用掉你多少 CPU 我们都知道，Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。
而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）。
CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文
知道了什么是 CPU 上下文，我想你也很容易理解 CPU 上下文切换。CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。
而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。
我猜肯定会有人说，CPU 上下文切换无非就是更新了 CPU 寄存器的值嘛，但这些寄存器，本身就是为了快速运行任务而设计的，为什么会影响系统的 CPU 性能呢？
在回答这个问题前，不知道你有没有想过，操作系统管理的这些“任务”到底是什么呢？也许你会说，任务就是进程，或者说任务就是线程。是的，进程和线程正是最常见的任务。但是除此之外，还有没有其他的任务呢？
不要忘了，硬件通过触发信号，会导致中断处理程序的调用，也是一种常见的任务。
所以，根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景:
进程上下文切换 线程上下文切换 中断上下文切换 进程上下文切换 Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。
内核空间（Ring 0）具有最高权限，可以直接访问所有资源； 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。 换个角度看，也就是说，进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。</description></item><item><title>Contexts 与 Variables</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Contexts-%E4%B8%8E-Variables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Contexts-%E4%B8%8E-Variables/</guid><description>概述 参考：
官方文档，学习 GitHub Actions-上下文 官方文档，学习 GitHub Actions-环境变量 GitHub Actions 中可以通过 Contexts(上下文) 与 Environment Variables(环境变量) 来暴露工作流的信息或引用工作流的信息。就像下面的示例一样：
这是一个环境变量的示例：
GitHub Action 中的环境变量本质上是 Shell 中的变量，引用方式也是一样的。
name: Greeting on variable day on: workflow_dispatch env: DAY_OF_WEEK: Monday jobs: greeting_job: runs-on: ubuntu-latest env: Greeting: Hello steps: - name: &amp;#34;Say Hello Mona it&amp;#39;s Monday&amp;#34; run: echo &amp;#34;$Greeting $First_Name. Today is $DAY_OF_WEEK!&amp;#34; env: First_Name: Mona 这是一个上下文的示例：
name: Greeting on variable day on: workflow_dispatch env: DAY_OF_WEEK: Monday jobs: greeting_job: runs-on: ubuntu-latest env: Greeting: Hello steps: - name: &amp;#34;Say Hello Mona it&amp;#39;s Monday&amp;#34; run: echo &amp;#34;${{ env.</description></item><item><title>CoreDNS</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/CoreDNS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/CoreDNS/</guid><description>概述 参考：
官网 官方手册 CoreDNS 所有插件详解 k8s 中的 CoreDNS 的配置示例 CoreDNS 是一个用 Go 编写的 DNS 服务器，目标是要称为云原生环境下的 DNS 服务器和服务发现解决方案。
CoreDNS 与 BIND 这类 DNS 服务器不同，CoreDNS 非常灵活，几乎所有功能都由插件来实现
插件可以独立或者一起运行，以便执行一个 **DNS Function(DNS 功能)。**可以说 CoreDNS 是由插件驱动的
那么什么是“ DNS 功能”？ 出于 CoreDNS 的目标，我们将其定义为实现 CoreDNS Plugin API 的软件。 实现的功能可能会大相径庭。 有些插件本身并不会创建响应，例如指标或缓存，但会添加功能。 然后有一些插件确实会产生响应。 这些也可以做任何事情：有一些与 Kubernetes 通信以提供服务发现的插件，有一些从文件或数据库中读取数据的插件。
So what’s a “DNS function”? For the purpose of CoreDNS, we define it as a piece of software that implements the CoreDNS Plugin API.</description></item><item><title>CoreDNS 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/CoreDNS-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/CoreDNS/CoreDNS-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方配置文档 CoreDNS 的配置文件为 Corefile。
Corefile 源于 Caddy 框架的的配置文件 Caddyfile。Corefile 将会定义如下 CoreDNS 的行为：
CoreDNS 的运行逻辑很像 Nginx，会抽象出 server 的概念并运行。可以同时定义多个 Server 以实现不同功能，每个 Server 主要定义下面几种行为： Server 以什么协议监听在哪个端口 Server 负责哪个 zone 的权威 DNS 解析 Server 将会加载哪些插件 一个典型的最基础的 Corefile 格式如下所示：
ZONE[:PORT] { [PLUGIN]... } ZONE# 定义 Server 的 zone。默认值： . PORT# 定义 Server 监听的端口。默认值：53。即 -dns.port 标志的值。 PLUGIN# 定义 Server 要加载的插件。这是可选的，但是如果不加载任何插件，那么 coredns 将为所有查询返回 SERVFAIL 。 并且，不同的 Plugins 还可以定义不同的参数以改变其运行行为。 比如：
. {} 上述配置文件表达的是：server 负责根域 . 的解析，监听在 53 端口，并且不使用任何插件。</description></item><item><title>CoreDNS 应用实例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/CoreDNS-%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/CoreDNS-%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B/</guid><description>原文链接：https://mp.weixin.qq.com/s/uzGhAHVqjmgH8QA8eIsS4w
自从 Kubernetes1.11 之后，CoreDNS 作为集群内默认的域名解析服务，你是否对它还仅仅还停留在对 Kubernetes 的 Service 解析呢？事实上光 DNS 在 K8S 内就有很多有意思的操作，今天我们不妨来看看 CoreDNS 的各种高阶玩法。
1. 自定义 hosts 解析 默认情况下，Kubernetes 集群内的容器要解析外部域名时，CoreDNS 会将请求转发给/etc/resolv.conf文件里指定的上游 DNS 服务器。这个是由这个配置决定的。
forward . /etc/resolv.conf 有的时候，我们如果需要在集群内全局劫持某个域名时，我们通常可以利用hosts插件来帮忙。hosts插件会每隔 5s 将需解析的信息重新加载到 coredns 当中，当你有任何变化时直接更新它的配置区块即可。常见的 host 有两种方法配置，分别如下：
定义 host .:53 { hosts { 1.1.1.1 test.cloudxiaobai.com 2.2.2.2 test2.cloudxiaobai.com fallthrough } } 加载 hosts 文件 直接从/etc/hosts加载host信息 . { hosts { fallthrough } } #又或者,从当前目录的test.hosts文件中加载host信息 . { hosts test.hosts { fallthrough } } 当被需要解析的域名不在 hosts 当中时，需要用fallthrough继续将请求转发给其它插件继续处理</description></item><item><title>Coroutine(协程)</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Coroutine%E5%8D%8F%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Coroutine%E5%8D%8F%E7%A8%8B/</guid><description>概述 参考：
Wiki, Coroutine 协程，被我玩会了！ Coroutine(协程) 是计算机程序组件，通过允许暂停和恢复执行来概括非抢占式多任务处理的子程序。协程非常适合实现熟悉的程序组件，例如协作任务、异常、事件循环、迭代器、无限列表和管道。
协程，被我玩会了 前言
大家好，我的朋友们！
干了这么年后端，写过C/C++、Python、Go，每次说到协程的时候，脑海里就只能浮现一些关键字yeild、async、go等等。
但是对于协程这个知识点，我理解的一直比较模糊，于是决定搞清楚。
全文阅读预计耗时10分钟，少刷几个小视频的时间，多学点知识，想想就很划算噻！
协程概念的诞生 先抛一个粗浅的结论：协程从广义来说是一种设计理念，我们常说的只是具体的实现。
理解好思想，技术点就很简单了，关于协程道与术的区别：
上古神器COBOL 协程概念的出现比线程更早，甚至可以追溯到20世纪50年代，提协程就必须要说到一门生命力极强的最早的高级编程语言COBOL。
最开始我以为COBOL这门语言早就消失在历史长河中，但是我错了。
COBOL语言，是一种面向过程的高级程序设计语言，主要用于数据处理，是国际上应用最广泛的一种高级语言。COBOL是英文Common Business-Oriented Language的缩写，原意是面向商业的通用语言。
截止到今年在全球范围内大约有1w台大型机中有3.8w+遗留系统中约2000亿行代码是由COBOL写的，占比高达65%，同时在美国很多政府和企业机构都是基于COBOL打造的，影响力巨大。
时间拉回1958年，美国计算机科学家梅尔文·康威(Melvin Conway)就开始钻研基于磁带存储的COBOL的编译器优化问题，这在当时是个非常热门的话题，不少青年才俊都扑进去了，包括图灵奖得主唐纳德·尔文·克努斯教授(Donald Ervin Knuth)也写了一个优化后的编译器。
看看这两位的简介，我沉默了：
梅尔文·康威(Melvin Conway)也是一位超级大佬，著名的康威定律提出者。
唐纳德·尔文·克努斯是算法和程序设计技术的先驱者，1974年的图灵奖得主，计算机排版系统TeX和字型设计系统METAFONT的发明者，他因这些成就和大量创造性的影响深远的著作而誉满全球，《计算机程序设计的艺术》被《美国科学家》杂志列为20世纪最重要的12本物理科学类专著之一。
那究竟是什么问题让这群天才们投入这么大的精力呢？快来看看！
COBOL编译器的技术难题 我们都是知道高级编程语言需要借助编译器来生成二进制可执行文件，编译器的基本步骤包括：读取字符流、词法分析、语法分析、语义分析、代码生成器、代码优化器等。
这种管道式的流程，上一步的输出作为下一步的输入，将中间结果存储在内存即可，这在现代计算机上毫无压力，但是受限于软硬件水平，在几十年前的COBOL语言却是很难的。
在1958年的时候，当时的存储还不发达，磁带作为存储器是1951年在计算机中得到应用的，所以那个时代的COBOL很依赖于磁带。
其实，我在网上找了很多资料去看当时的编译器有什么问题，只找到了一条：编译器无法做到读一次磁带就可以完成整个编译过程，也就是所谓的one-pass编译器还没有产生。
当时的COBOL程序被写在一个磁带上，而磁带不支持随机读写，只能顺序读，而当时的内存又不可能把整个磁带的内容都装进去，所以一次读取没编译完就要再从头读。
于是，我脑补了COBOL编译器和磁带之间可能的两种multi-pass形式的交互情况：
可能情况一 对于COBOL的编译器来说，要完成词法分析、语法分析就要从磁带上读取程序的源代码，在之前的编译器中词法分析和语法分析是相互独立的，这就意味着： 词法分析时需要将磁带从头到尾过一遍 语法分析时需要将磁带从头到尾过一遍 可能情况二 听过磁带的朋友们一定知道磁带的两个基本操作：倒带和快进。 在完成编译器的词法分析和语法分析两件事情时，需要磁带反复的倒带和快进去寻找两类分析所需的部分，类似于磁盘的寻道，磁头需要反复移动横跳，并且当时的磁带不一定支持随机读写。
从一些资料可以看到，COBOL当时编译器各个环节相互独立的，这种软硬件的综合限制导致无法实现one-pass编译。
协同式解决方案 在梅尔文·康威的编译器设计中将词法分析和语法分析合作运行，而不再像其他编译器那样相互独立，两个模块交织运行，编译器的控制流在词法分析和语法分析之间来回切换：
当词法分析模块基于词素产生足够多的词法单元Token时就控制流转给语法分析 当语法分析模块处理完所有的词法单元Token时将控制流转给词法分析模块 词法分析和语法分析各自维护自身的运行状态，并且具备主动让出和恢复的能力 可以看到这个方案的核心思想在于：
梅尔文·康威构建的这种协同工作机制，需要参与者让出（yield）控制流时，记住自身状态，以便在控制流返回时能从上次让出的位置恢复（resume）执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。
这种协作式的任务流和计算机中断非常像，在当时条件的限制下，由梅尔文·康威提出的这种让出/恢复模式的协作程序被认为是最早的协程概念，并且基于这种思想可以打造新的COBOL编译器。
在1963年，梅尔文·康威也发表了一篇论文来说明自己的这种思想，虽然半个多世纪过去了，有幸我还是找到了这篇论文：
https://melconway.com/Home/pdf/compiler.pdf
说实话这paper真是有点难，时间过于久远，很难有共鸣，最后我放弃了，要不然我或许能搞明白之前编译器的具体问题了。
怀才不遇的协程 虽然协程概念出现的时间比线程还要早，但是协程一直都没有正是登上舞台，真是有点怀才不遇的赶脚。
我们上学的时候，老师就讲过一些软件设计思想，其中主流语言崇尚自顶向下top-down的编程思想:
对要完成的任务进行分解，先对最高层次中的问题进行定义、设计、编程和测试，而将其中未解决的问题作为一个子任务放到下一层次中去解决。
这样逐层、逐个地进行定义、设计、编程和测试，直到所有层次上的问题均由实用程序来解决，就能设计出具有层次结构的程序。
C语言就是典型的top-down思想的代表，在main函数作为入口，各个模块依次形成层次化的调用关系，同时各个模块还有下级的子模块，同样有层次调用关系。
但是协程这种相互协作调度的思想和top-down是不合的，在协程中各个模块之间存在很大的耦合关系，并不符合高内聚低耦合的编程思想，相比之下top-down使程序结构清晰、层次调度明确，代码可读性和维护性都很不错。
与线程相比，协作式任务系统让调用者自己来决定什么时候让出，比操作系统的抢占式调度所需要的时间代价要小很多，后者为了能恢复现场会在切换线程时保存相当多的状态，并且会非常频繁地进行切换，资源消耗更大。
综合来说，协程完全是用户态的行为，由程序员自己决定什么时候让出控制权，保存现场和切换恢复使用的资源也非常少，同时对提高处理器效率来说也是完全符合的。
那么不禁要问：协程看着不错，为啥没成为主流呢？
协程的思想和当时的主流不符合 抢占式的线程可以解决大部分的问题，让使用者感受的痛点不足 换句话说：协程能干的线程干得也不错，线程干的不好的地方，使用者暂时也不太需要，所以协程就这样怀才不遇了。</description></item><item><title>CORS跨域(一)：深入理解跨域请求概念及其根因</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%AE%A1%E7%90%86/CORS%E8%B7%A8%E5%9F%9F%E4%B8%80%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%85%B6%E6%A0%B9%E5%9B%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%AE%A1%E7%90%86/CORS%E8%B7%A8%E5%9F%9F%E4%B8%80%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%85%B6%E6%A0%B9%E5%9B%A0/</guid><description>原文链接：https://mp.weixin.qq.com/s/dynx7wrSINYFKZgGPcD3zQ
❝Talk is cheap. Show me the money.&amp;gt; ❞
前言 你好，我是YourBatman。 做 Web 开发的小伙伴对“跨域”定并不陌生，像狗皮膏药一样粘着几乎每位同学，对它可谓既爱又恨。跨域请求之于创业、小型公司来讲是个头疼的问题，因为这类企业还未沉淀出一套行之有效的、统一的解决方案。 让人担忧的是，据我了解不少程序员同学（不乏有高级开发）碰到跨域问题大都一头雾水：然后很自然的 用谷歌去百度一下搜索答案，但相关文章可能参差不齐、鱼龙混杂。短则半天长则一天（包含改代码、部署等流程）此问题才得以解决，一个“小小跨域”问题成功偷走你的宝贵时间。 既然跨域是个如此常见（特别是当下前后端分离的开发模式），因此深入理解 CORS 变得就异常的重要了（反倒前端工程师不用太了解），因此早在 2019 年我刚开始写博客那会就有过较为详细的系列文章：现在把它搬到公众号形成技术专栏，并且加点料，让它更深、更全面、更系统的帮助到你，希望可以助你从此不再怕 Cors 跨域资源共享问题。
本文提纲 版本约定 JDK：8 Servlet：4.x 正文 文章遵循一贯的风格，本文将采用概念 + 代码示例的方式，层层递进的进行展开叙述。那么上菜，先来个示例预览，模拟一下跨域请求，后面的一些的概念示例将以此作为抓手。
模拟跨域请求 要模拟跨域请求的根本是需要两个源：让请求的来源和目标源不一样。这里我就使用 IDEA 作为静态 Web 服务器（63342），Tomcat 作为后端动态 Servlet 服务器（8080）。
❝&amp;gt; 说明：服务器都在本机，端口不一样即可 ❞
前端代码 index.html
&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;quot;en&amp;quot;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;quot;UTF-8&amp;quot;&amp;gt; &amp;lt;title&amp;gt;CORS跨域请求&amp;lt;/title&amp;gt; &amp;lt;!--导入Jquery--&amp;gt; &amp;lt;script src=&amp;quot;https://cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;button id=&amp;quot;btn&amp;quot;&amp;gt;跨域从服务端获取内容&amp;lt;/button&amp;gt; &amp;lt;div id=&amp;quot;content&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; $(&amp;quot;#btn&amp;quot;).click(function () { // 跨域请求 $.get(&amp;quot;http://localhost:8080/cors&amp;quot;, function (result) { $(&amp;quot;#content&amp;quot;).</description></item><item><title>CPU 空闲时在干嘛？</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/CPU-%E7%A9%BA%E9%97%B2%E6%97%B6%E5%9C%A8%E5%B9%B2%E5%98%9B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/CPU-%E7%A9%BA%E9%97%B2%E6%97%B6%E5%9C%A8%E5%B9%B2%E5%98%9B/</guid><description>概述 参考：
公众号-码农的荒岛求生，CPU 空闲时在干嘛？
人空闲时会发呆会无聊，计算机呢？
假设你正在用计算机浏览网页，当网页加载完成后你开始阅读，此时你没有移动鼠标，没有敲击键盘，也没有网络通信，那么你的计算机此时在干嘛？
有的同学可能会觉得这个问题很简单，但实际上，这个问题涉及从硬件到软件、从 CPU 到操作系统等一系列环节，理解了这个问题你就能明白操作系统是如何工作的了。
你的计算机 CPU 使用率是多少？ 如果此时你正在计算机旁，并且安装有 Windows 或者 Linux ，你可以立刻看到自己的计算机 CPU 使用率是多少。
这是博主的一台安装有 Win10 的笔记本：
可以看到大部分情况下 CPU 利用率很低，也就在 8% 左右，而且开启了 283 个进程，这么多进程基本上无所事事，都在等待某个特定事件来唤醒自己，就好比你写了一个打印用户输入的程序，如果用户一直不按键盘，那么你的进程就处于这种状态。
有的同学可能会想也就你的比较空闲吧，实际上大部分个人计算机 CPU 使用率都差不多这样(排除掉看电影、玩游戏等场景)，如果你的使用率总是很高，风扇一直在嗡嗡的转，那么不是软件 bug 就有可能是病毒。。。
那么有的同学可能会问，剩下的 CPU 时间都去哪里了？
剩下的 CPU 时间去哪里了？ 这个问题也很简单，还是以 Win10 为例，打开任务管理器，找到 “详细信息” 这一栏，你会发现有一个 “系统空闲进程”，其 CPU 使用率达到了 99%，正是这个进程消耗了几乎所有的 CPU 时间。
那么为什么存在这样一个进程呢？以及这个进程什么时候开始运行呢？
这就要从操作系统说起了。
程序、进程与操作系统 当你用最喜欢的代码编辑器编写代码时，这时的代码不过就是磁盘上的普通文件，此时的程序和操作系统没有半毛钱关系，操作系统也不认知这种文本文件。
程序员写完代码后开始编译，这时编译器将普通的文本文件翻译成二进制可执行文件，此时的程序依然是保存在磁盘上的文件，和普通没有本质区别。
但此时不一样的是，该文件是可执行文件，也就是说操作系统开始 “懂得” 这种文件，所谓 “懂得” 是指操作系统可以识别、解析、加载，因此必定有某种类似协议的规范，这样编译器按照这种协议生成可执行文件，操作系统就能加载了。
在 Linux 下可执行文件格式为 ELF ，在 Windows 下是 EXE 。</description></item><item><title>CPU 是如何读写内存的？</title><link>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/CPU-%E6%98%AF%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99%E5%86%85%E5%AD%98%E7%9A%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/CPU-%E6%98%AF%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99%E5%86%85%E5%AD%98%E7%9A%84/</guid><description>https://mp.weixin.qq.com/s/S3Cn6KsDGKqxxP58y2m67Q
如果你觉得这是一个非常简单的问题，那么你真应该好好读读本文，我敢保证这个问题绝没有你想象的那么简单。注意，一定要完本文，否则可能会得出错误的结论。闲话少说，让我们来看看 CPU 在读写内存时底层究竟发生了什么。 谁来告诉 CPU 读写内存 我们第一个要搞清楚的问题是：谁来告诉 CPU 去读写内存？答案很明显，是程序员，更具体的是编译器。CPU 只是按照指令按部就班的执行，机器指令从哪里来的呢？是编译器生成的，程序员通过高级语言编写程序，编译器将其翻译为机器指令，机器指令来告诉 CPU 去读写内存。在精简指令集架构下会有特定的机器指令，Load/Store 指令来读写内存，以 x86 为代表的复杂指令集架构下没有特定的访存指令。精简指令集下，一条机器指令操作的数据必须来存放在寄存器中，不能直接操作内存数据，因此 RISC 下，数据必须先从内存搬运到寄存器，这就是为什么 RISC 下会有特定的 Load/Store 访存指令，明白了吧。而 x86 下无此限制，一条机器指令操作的数据可以来自于寄存器也可以来自内存，因此这样一条机器指令在执行过程中会首先从内存中读取数据。关于复杂指令集以及精简指令集你可以参考这两篇文章《CPU 进化论：复杂指令集》与《不懂精简指令集还敢说自己是程序员？》
两种内存读写 现在我们知道了，是特定的机器指令告诉 CPU 要去访问内存。不过，值得注意的是，不管是 RISC 下特定的 Load/Store 指令还是 x86 下包含在一条指令内部的访存操作，这里读写的都是内存中的数据，除此之外还要意识到，CPU 除了从内存中读写数据外，还要从内存中读取下一条要执行的机器指令。毕竟，我们的计算设备都遵从冯诺依曼架构：程序和数据一视同仁，都可以存放在内存中。现在，我们清楚了 CPU 读写内存其实是由两个因素来驱动的：
程序执行过程中需要读写来自内存中的数据
CPU 需要访问内存读取下一条要执行的机器指令
然后 CPU 根据机器指令中包含的内存地址或者 PC 寄存器中下一条机器指令的地址访问内存。这不就完了吗？有了内存地址，CPU 利用硬件通路直接读内存就好了，你可能也是这样的想的。真的是这样吗？别着急，我们接着往下看，这两节只是开胃菜，正餐才刚刚开始。
急性子吃货 VS 慢性子厨师 假设你是一个整天无所事事的吃货，整天无所事事，唯一的爱好就是找一家餐厅吃吃喝喝，由于你是职业吃货，因此吃起来非常职业，1 分钟就能吃完一道菜，但这里的厨师就没有那么职业了，炒一道菜速度非常慢，大概需要 1 小时 40 分钟才能炒出一道菜，速度比你慢了 100 倍，如果你是这个吃货，大概率会疯掉的。而 CPU 恰好就是这样一个吃货，内存就是这样一个慢吞吞的厨师，而且随着时间的推移这两者的速度差异正在越来越大：在这种速度差异下，CPU 执行一条涉及内存读写指令时需要等**“很长一段时间“数据才能”缓缓的“从内存读取到 CPU 中，在这种情况你还认为 CPU 应该直接读写内存吗**？
无处不在的 28 定律 28 定律我想就不用多介绍了吧，在《不懂精简指令集还敢说自己是程序员集中起来然后呢？放到哪里呢？当然是放到一种比内存速度更快的存储介质上，这种介质就是我们熟悉的 SRAM，普通内存一般是 DRAM，这种读写速度更快的介质充当 CPU 和内存之间的 Cache，这就是所谓的缓存。</description></item><item><title>CPU 性能优化</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>系统性能调优之绑定 cpu 原文链接：https://mp.weixin.qq.com/s/jiQz01hg8DiA1zucqjMZkQ
支持超线程的numa架构 物理硬件视角，
将多个CPU封装在一起，这个封装被称为插槽Socket； Core是socket上独立的硬件单元； 通过intel的超线程HT技术进一步提升CPU的处理能力，OS看到的逻辑上的核Processor的数量。 每个硬件线程都可以按逻辑cpu寻址，因此这个处理器看上去有八块cpu。
对于操作系统的视角：
CPU(s)：8 NUMA node0 CPU(s)：0，4 NUMA node1 CPU(s)：1，5 NUMA node2 CPU(s)：2，6 NUMA node3 CPU(s)：3，7 操作系统视角.png
L1缓分成两种，一种是指令缓存，一种是数据缓存。L2缓存和L3缓存不分指令和数据。L1和L2缓存在第一个CPU核中，L3则是所有CPU核心共享的内存。L1、L2、L3的越离CPU近就越小，速度也越快，越离CPU远，速度也越慢。再往后面就是内存，内存的后面就是硬盘。我们来看一些他们的速度：
L1 的存取速度：4 个CPU时钟周期 L2 的存取速度：11 个CPU时钟周期 L3 的存取速度：39 个CPU时钟周期 RAM内存的存取速度 ：107 个CPU时钟周期 如果 CPU 所要操作的数据在缓存中，则直接读取，这称为缓存命中。命中缓存会带来很大的性能提升，因此，我们的代码优化目标是提升 CPU 缓存的命中率。
在主流的服务器上，一个 CPU 处理器会有 10 到 20 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 CPU 处理器（也称为多 CPU Socket），每个处理器有自己的物理核（包括 L1、L2 缓存），L3 缓存，以及连接的内存，同时，不同处理器间通过总线连接。通过lscpu来看：
root@ubuntu:~# lscpu Architecture: x86_64 CPU(s): 32 Thread(s) per core: 1 Core(s) per socket: 8 Socket(s): 4 L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 20480K NUMA node0 CPU(s): 0-7 NUMA node1 CPU(s): 8-15 NUMA node2 CPU(s): 16-23 NUMA node3 CPU(s): 24-31 你可能注意到，三级缓存要比一、二级缓存大许多倍，这是因为当下的 CPU 都是多核心的，每个核心都有自己的一、二级缓存，但三级缓存却是一颗 CPU 上所有核心共享的。</description></item><item><title>CPU与GPU到底有什么区别？</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/CPU%E4%B8%8EGPU%E5%88%B0%E5%BA%95%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/CPU%E4%B8%8EGPU%E5%88%B0%E5%BA%95%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</guid><description>原文链接：公众号-码农的荒岛求生，CPU 与 GPU 到底有什么区别？
大家好，我是小风哥，今天简单聊聊 CPU 与 GPU。
CPU 的故事我们聊得比较多了，之前也发布过很多关于 CPU 的文章，因此这里重点聊聊 GPU。
教授 vs 小学生
你可以简单的将 CPU 理解为学识渊博的教授，什么都精通，而 GPU 则是一堆小学生，只会简单的算数运算，可即使教授再神通广大，也不能一秒钟内计算出 500 次加减法，因此对简单重复的计算来说单单一个教授敌不过数量众多的小学生，在进行简单的算数运算这件事上，500 个小学生(并发)可以轻而易举打败教授。
因此我们可以看到，CPU 和 GPU 的最大不同在于架构，CPU 适用于广泛的应用场景(学识渊博)，可以执行任意程序，而 GPU 则专为多任务而生，并发能力强，具体来讲就是多核，一般的 CPU 有 2 核、4 核、8 核等，而 GPU 则可能会有成百上千核：
可以看到，CPU 内部 cache 以及控制部分占据了很大一部分片上面积，因此计算单元占比很少，再来看看 GPU，GPU 只有很简单的控制单元，剩下的大部分都被计算单元占据，因此 CPU 的核数有限，而 GPU 则轻松堆出上千核：
只不过 CPU 中每个核的能力好比教授，而 GPU 的每个核的能力好比一个小学生。
你可能会想，为什么 GPU 需要这么奇怪的架构呢？
为什么 GPU 需要这么多核心？
想一想计算机上的一张图是怎么表示的？无非就是屏幕上的一个个像素：
我们需要为每个像素进行计算，而且是相同的运算，就好比刚才例子中的小学生计算计加法一样，注意，对于屏幕来说一般会有上百万个像素，如果我们要串行的为每一个像素进行运算效率就太低了，因此我们可以让 GPU 中的每一个核心去为相应的像素进行计算，由于 GPU 中有很多核心，因此并行计算可以大幅提高速度。
现在你应该明白为什么 GPU 要这样工作了吧。
除了 GPU 的核心数比较多之外，GPU 的工作方式也比较奇怪。</description></item><item><title>CRI 对比</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/CRI-%E5%AF%B9%E6%AF%94/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/CRI-%E5%AF%B9%E6%AF%94/</guid><description>原文：阳明公众号
下面是我已经测试的几个 CRI，并进行一些基准测试来对他们进行了简单的对比，希望对你有所帮助：
dockershim containerd crio 对于 cri-o，已经测试了 2 个后端：runc 和 crun，以测试对 cgroupsv2 的影响。
测试环境 我这里的测试环境是一个 1.19.4 版本的 kubernetes 集群，使用 ansible 进行创建（https://gitlab.com/incubateur-pe）。集群运行在 kvm 上，配置如下：
master：Centos/7, 2vcpus/2G 内存。 crio-crun 节点：Fedora-32, 2vcpus/4G 内存。 其他节点：Centos/7, 2vcpus/4G 内存. 底层是 i7-9700K ，64G 的内存和一个 mp510 nvme 硬盘。
创建集群 这里我直接使用 molecule 创建一个集群，并配置了它在每个 worker 节点上使用不同的 cri，对应的 ansible 源码位于：https://gitlab.com/incubateur-pe/kubernetes-bare-metal/-/tree/dev/molecule/criBench
使用上面的脚本，执行 molecule converge 命令后，大概 10 分钟左右，我们就可以得到一个如下所示的 kubernetes 集群。
接下来我们就可以进行一些简单的基准测试了。
测试 1. bucketbench 测试 Bucketbench (https://github.com/estesp/bucketbench) 是一个可以对容器引擎执行一系列操作的测试工具，它非常适合于了解之前每个节点的性能。
这里我们的测试参数很简单：
3 个线程 15 次循环 run/stop/delete 操作 对应的结果如下所示（ms 为单位）：</description></item><item><title>crictl 命令行工具</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/crictl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/crictl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
项目地址 使用 crictl 对 kubernetes 进行调试 crictl 用于为 kubelet CRI 进行调试的 命令行工具
cri-tools 旨在为 Kubelet CRI 提供一系列调试和验证工具，其中包括：
crictl: kubelet 的 CRI 命令行工具 critest:kubelet CRI 的验证测试套件 用白话说就是：kubelet 如果要与 CRI 对接，那么如何检测对接成功呢，就是使用 crictl 工具来测试。还可以对已经与 kubelet 建立连接的 CRI 执行相关操作，比如启停容器等。
Note：要想使用 crictl 命令行工具，必须要先进行配置，指定好要操作的 CRI 的 endpoint，才可以正常使用
crictl 配置 /etc/crictl.yaml # crictl 命令行工具运行时配置文件
基本配置文件示例 runtime-endpoint: unix:///run/containerd/containerd.sock image-endpoint: unix:///run/containerd/containerd.sock timeout: 10 debug: true crictl 命令行工具 crictl [Global OPTIONS] COMMAND [COMMAND OPETIONS] [ARGUMENTS&amp;hellip;] COMMMAND
attach Attach to a running container create Create a new container exec Run a command in a running container version Display runtime version information images List images inspect Display the status of one or more containers inspecti Return the status of one or more images inspectp Display the status of one or more pods logs Fetch the logs of a container port-forward Forward local port to a pod ps List containers pull Pull an image from a registry runp Run a new pod rm Remove one or more containers rmi Remove one or more images rmp Remove one or more pods pods List pods start Start one or more created containers info # 显示与 crictl 对接的 CRI 信息 stop Stop one or more running containers stopp Stop one or more running pods update Update one or more running containers config Get and set crictl options stats List container(s) resource usage statistics completion Output bash shell completion code help, h Shows a list of commands or help for one command OPTIONS</description></item><item><title>ctr</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/ctr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/ctr/</guid><description>概述 参考：
官方文档 Syntax(语法) ctr [GLOBAL OPTIONS] COMMAND [OPTIONS] [ARGs&amp;hellip;]
GLOBAL OPTIONS:
COMMANDS:
plugins, plugin provides information about containerd plugins version print the client and server versions containers, c, container manage containers content manage content events, event display containerd events images, image, i manage images leases manage leases namespaces, namespace, ns manage namespaces pprof provide golang pprof outputs for containerd run run a container snapshots, snapshot # manage snapshots tasks, t, task # manage tasks install # install a new package oci # OCI tools shim # interact with a shim directly tasks # 任务管理 create 的命令创建了容器后，并没有处于运行状态，只是一个静态的容器。一个 container 对象只是包含了运行一个容器所需的资源及配置的数据结构，这意味着 namespaces、rootfs 和容器的配置都已经初始化成功了，只是用户进程(这里是 nginx)还没有启动。然而一个容器真正的运行起来是由 task 对象实现的，task 代表任务的意思，可以为容器设置网卡，还可以配置工具来对容器进行监控等。</description></item><item><title>Custom Resource Definitions(CRD)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Custom-Resource-DefinitionsCRD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Custom-Resource-DefinitionsCRD/</guid><description>概述 参考：
官方文档，概念 - 扩展 Kubernetes - 扩展 API - 自定义资源，CRD Custom Resource Definitions 自定义资源定义，简称 CRD。是一个 Kubernetes 的 API 对象。其前身是 Kubernetes1.6 版本中一个叫做 ThirdPartyResource(第三方资源，简称 TPR) 的内建对象，可以用它来创建自定义资源，但该对象在 kubernetes1.7 中版本已被 CRD（CustomResourceDefinition）取代。CRD 的目的是让 Kubernetes API 能够认识新对象(就是 yaml 中的 kind)。所以通过 CRD 创建的对象可以跟 kubernetes 中内建对象一样使用 kubectl 操作，就像 kubectl 操作 pod 一样，如果我定义了一个名为 lch 的 crd ，那么我可以使用 kubectl get lch 命令来操作 lch 这个资源
注意：单纯设置了 CRD，并没有什么用，只有跟自定义控制器(controller)结合起来，才能将资源对象中的声明式 API 翻译成用户所期望的状态。自定义控制器可以用来管理任何资源类型，但是一般是跟 CRD 结合使用。自定义控制器称为 Operator。
为什么这么说呢？
比如，在一个 pod 的 yaml 文件里每一个字段就是对该资源的定义，name 字段定义了该资源名字，image 字段定义了 pod 这个资源的 container 所使用的镜像等等。但是，既然有字段可以定义一个 k8s 资源，那么谁又来决定这个字段就是其所描述的功能呢？~答案当然是 kubernetes 主程序(也就是 kube-controller)。</description></item><item><title>Data Type(数据类型)</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/TypeScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-Type%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/TypeScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Data-Type%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>概述 参考：
官方文档，常见类型</description></item><item><title>dd 生成指定大小的文件</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/dd-%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E5%A4%A7%E5%B0%8F%E7%9A%84%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/dd-%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E5%A4%A7%E5%B0%8F%E7%9A%84%E6%96%87%E4%BB%B6/</guid><description>概述 Syntax(语法) 参考:
https://blog.csdn.net/menogen/article/details/38059671 dd [OPTIONS[=FLAGS]]
OPTIONS
bs=BYTES # 每次读取和写入的字节数 cbs=BYTES # convert BYTES bytes at a time conv=CONVS # convert the file as per the comma separated symbol list count=N # 读取的 block 数，block 的大小由 ibs 指定（只针对输入参数） ibs=BYTES # read up to BYTES bytes at a time (default: 512) if=FILE # 指定输入文件。默认从标准输入读取。 /dev/zero 是 Linux 的一个伪文件，它可以产生连续不断的 null 流（二进制的 0） iflag(FLAGS) # 使用 FLAGS 来控制输入(读取数据)时的行为特征。多个 FLAG 以 , 分隔 obs=BYTES # write BYTES bytes at a time (default: 512) of=FILE # 指定输出文件。默认输出到标准输出。 oflag=FLAGS # 使用 iflag 来控制输出(写入数据)时的行为特征。多个 FLAG 以 , 分隔 seek=N # skip N obs-sized blocks at start of output skip=N # skip N ibs-sized blocks at start of input status=LEVEL # The LEVEL of information to print to stderr; &amp;rsquo;none&amp;rsquo; suppresses everything but error messages, &amp;rsquo;noxfer&amp;rsquo; suppresses the final transfer statistics, &amp;lsquo;progress&amp;rsquo; shows periodic transfer statistics FLAGS append # 追加模式(仅对输出有意义；隐含了 conv=notrunc) direct # 使用直接 I/O 存取模式，即跳过缓存，不操作内存，而是直接操作磁盘 directory # 除非是目录，否则 directory 失败 dsync # 使用同步 I/O 存取模式 sync # 与上者类似，但同时也对元数据生效 fullblock # 为输入积累完整块(仅 iflag) nonblock # 使用无阻塞 I/O 存取模式 noatime # 不更新存取时间 nocache # 丢弃缓存数据 noctty # 不根据文件指派控制终端 nofollow # 不跟随链接文件 EXAMPLE 测试当前磁盘 写入文件 的速度 dd if=/dev/zero of=testdd bs=1M count=1000 测试当前磁盘 纯写入文件 的速度，即不使用缓存 dd if=/dev/zero of=testdd bs=1M count=1024 oflag=sync,direct,nonblock 测试当前磁盘 纯读取文件 的速度，即不使用缓存 dd if=testdd of=/dev/null bs=1M count=1024 iflag=sync,direct,nonblock 测试 sdb 磁盘 的 写入速度。注意：要使用一块空盘，否则数据没了 dd if=/dev/urandom of=/dev/sdb1 bs=1M count=1024 测试 sdb 磁盘 的读取速度 dd if=/dev/sdb1 of=/dev/null bs=1M count=1024</description></item><item><title>DDNS</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DDNS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DDNS/</guid><description>概述 参考：
Wiki, DDNS Dynamic Domain Name System(动态域名系统，简称 DDNS) 是一种方法、概念，这个方法用来动态更新 DNS 中名称对应的 IP。通常情况下，域名都是解析到一个固定的 IP，但 DDNS 系统为动态网域提供一个固定的名称服务器（Name server），透过即时更新，使外界用户能够连上动态用户的网址。
比如家庭宽带，获取到的 IP 地址是实时变化的，要想通过域名访问当家庭宽带内部的服务，则必须使用 DDNS。
GitHub 项目，jeessy2/ddns-go 是一个使用 Go 写的，带有 Web 管理页面的 DDNS 工具</description></item><item><title>Debian 包管理</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Debian-%E5%8C%85%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Debian-%E5%8C%85%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
Ubuntu 官方文档，软件 - 包管理 Ubuntu 具有一个全面的包管理系统，用于安装、升级、配置和删除软件。除了为我们的 Ubuntu 系统提供超过 60k 个软件包的有组织访问之外，软件包管理工具还具有依赖性解析功能和软件更新检查功能。
Ubuntu 的包管理系统源自使用 Debian GUN/Linux 发行版的系统。Debian 软件包文件通常具有 .deb 扩展名，并且可以存储于 Repositories(存储库) 中，存储库是网络上或物理媒体(e.g.CD-ROM 光盘)上的软件包集合。软件包通常是预编译的二进制格式。
许多包使用依赖项。依赖项是主包为了正常运行而需要的附加包。例如，语音合成包 Festival 依赖于包 alsa-utils，该包提供了音频播放所需的 ALSA 声音库工具。为了让节日正常运行，必须安装它及其所有依赖项。 Ubuntu 中的软件管理工具会自动执行此操作。
DPKG 工具集 参考：
Wiki, Dpkg Debian Package(Debian 包，简称 dpkg) 是 Debian 及其衍生的 Linux 发行版的软件包管理程序，用于安装、删除 .deb 软件包，以及查看.deb 软件包的信息。
Dpkg 包含一系列的包管理工具：
dpkg-deb dpkg-split dpkg-query dpkg-statoverride dpkg-divert dpkg-trigger DPKG 关联文件与配置 /etc/alternatives/ # 很多程序的替代方案的文件将会保存在这里. e.g. iptables 被 nftables 替代了, 但是 Ubuntu 保留了很多 iptables 时代的操作习惯和命令, 会把这些命令、服务 相关的文件, 通过符号连接的方式连接到 alternatvies/ 目录中, 然后在该目录中再执行一次链接, 链接到 其他地方, 效果如下:</description></item><item><title>Debian 与 Ubuntu</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/Debian-%E4%B8%8E-Ubuntu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/Debian-%E4%B8%8E-Ubuntu/</guid><description>概述 参考：
Debian 官方 Manual(手册) Debian 与 Ubuntu 是 Unix-like OS 发行版
groupadd wheel usermod -G wheel desistdaydream tee /etc/sudoers.d/desistdaydream &amp;gt; /dev/null &amp;lt;&amp;lt;EOF %wheel ALL=(ALL) NOPASSWD: ALL EOF ~/.bashrc
if [ &amp;#34;$color_prompt&amp;#34; = yes ]; then # PS1=&amp;#39;${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ &amp;#39; PS1=&amp;#39;${debian_chroot:+($debian_chroot)}[\[\e[34;1m\]\u@\[\e[0m\]\[\e[32;1m\]\H\[\e[0m\] \[\e[31;1m\]\w\[\e[0m\]]\\$ &amp;#39; else # PS1=&amp;#39;${debian_chroot:+($debian_chroot)}\u@\h:\w\$ &amp;#39; PS1=&amp;#39;${debian_chroot:+($debian_chroot)}[\[\e[34;1m\]\u@\[\e[0m\]\[\e[32;1m\]\H\[\e[0m\] \[\e[31;1m\]\w\[\e[0m\]]\\$ &amp;#39; fi Ubuntu 参考：
官网 Wiki, Ubuntu Ubuntu Manual(手册) Ubuntu 是一个基于 Debian 的 Linux 发行版，主要由 FOSS 组成。
Ubuntu 由英国公司 Canonical 和其他开发者社区共同开发的，采用了一种精英治理模式。Canonical为每个Ubuntu版本提供安全更新和支持，从发布日期开始，直到该版本达到其指定的寿命终点(EOL)日期为止。Canonical 通过销售与 Ubuntu 相关的高级服务以及下载 Ubuntu 软件的人的捐赠来获得收入。</description></item><item><title>Device 命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Device-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Device-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方 Manual(手册)，DEVICE COMMANDS 注意：由于 Libvirt 适用于多种虚拟化后端，所以每个选项可用的值会分别适用于多种虚拟化后端，但是个人一般只用 QEMU/KVM，所以笔记中的选项一般也只记录 QEMU/KVM 相关的值。
这部分命令主要是用来为虚拟机添加/移除各种设备，比如 网卡、硬盘 等等。这些添加/移除的命令有一些通用的选项可用，为了记笔记方便，在开头这统一记录一下，添加设备的命令通常以 attach 开头，移除设备的命令通常以 detach 开头。
生效策略配置选项，用于配置添加/移除的行为在什么时候生效：
&amp;ndash;config # 影响已关机的 Domain，将会在下一次启动时添加/移除设备 &amp;ndash;live # 影响运行中的 Domain，立刻为虚拟机添加/移除设备 &amp;ndash;current # 等效于 &amp;ndash;live 或 &amp;ndash;config，具体取决于虚拟机当前的状态 &amp;ndash;persistent # 处于兼容的目的，该命令对关机或者开机状态的虚拟机都有效，相当于为当前运行中的虚拟机以及以后启动后的虚拟机都添加/移除设备。 attach-device - attach device from an XML file 添加与移除磁盘设备 在 Libvirt 的最佳实践中有命令使用示例
attach-disk 将一个新的磁盘设备添加到 domian 中
https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#attach-disk
Syntax(语法) virsh attach-disk DOMAIN SOURCE TARGET [OPTIONS]
将 SOURCE 添加到 DOMAIN 中，作为 TARGET 磁盘设备。
SOURCE 是本地的 qcow2、raw 这种格式的文件。如果指定了 &amp;ndash;source-protocol 选项，则 SOURCE 可以是网络磁盘。 TARGET 是虚拟机中的设备，比如 vdb、vdc 这种。 可以使用 &amp;ndash;target 选项指定 TARGET OPTIONS</description></item><item><title>DNS</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DNS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DNS/</guid><description>概述 参考：
Wiki, DNS Wiki, Name Server 《DNS 与 BIND》(第 5 版) Domain Name System(域名系统，简称 DNS) 是一个分层的和去中心化的命名系统，以便人们可以更方便得访问互联网。DNS 主要用来将更容易让人类记忆的 域名 与 IP地址 互相映射，以便可以通过域名定位和访问互联网上的服务。自 1985 年以来，域名系统通过提供全球性、分布式的域名服务，已成为 Internet 功能的重要组成部分。
从另一个方面说，DNS(域名系统) 其实是一个分布式的数据库。这种结构允许对整体数据库的各个部分进行本地控制，并且在各个部分中的数据通过 C/S 模式变得对整个网络都可用。通过复制和缓存等机制，DNS 将会拥有健壮性和充足的性能。
注：这段描述不好理解，需要看完后面才能体会。所谓的分布式，其实就是指 DNS 的模式，每个 Name Server 都可以是分布式数据库的一个节点。
当我们访问一个网站时，在浏览器上输入 https://www.baidu.com/ 时，www.baidu.com 就是域名。而管理 域名与 IP 对应关系的系统，就是域名系统。
DNS 其实是一个规范、概念，具体想要让 DNS 在世界上应用起来，则至少要保证两个方面
其一是服务端，通过 NameServer 为大家提供解析服务、存储域名与 IP 的对应关系， 其二是客户端，客户端上的应用程序将会调用符合 DNS 标准的库以便向 NameServer 发起域名查询请求，程序收到解析后的 IP 后将会发起请求。 背景 网络诞生之初并没有 DNS，那时候访问对方只需要 IP 地址就可以了，但是后来接入互联网的主机太多了，IP 没法记，所以研究了 DNS。
Internet Assigned Numbers Authority(互联网数字分配机构，简称 IANA) 是负责协调一些使 Internet 正常运作的机构。同时，由于 Internet 已经成为一个全球范围的不受集权控制的全球网络，为了使网络在全球范围内协调，存在对互联网一些关键的部分达成技术共识的需要，而这就是 IANA 的任务</description></item><item><title>DNS 管理与优化</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/</guid><description>优化方法
禁用 ipv6 解析，以提高解析速度
参考文章：https://yuerblog.cc/2019/09/13/k8s-coredns%E7%A6%81%E7%94%A8ipv6%E8%A7%A3%E6%9E%90/
如果 K8S 集群宿主机没有关闭 IPV6 内核模块的话，容器请求 coredns 时的默认行为是同时发起 IPV4 和 IPV6 解析。
由于我们通常只使用 IPV4 地址，所以此时如果我们仅仅在 coredns 中配置 DOMAIN -&amp;gt; IPV4 地址的解析的话，当 coredns 收到 IPV6 解析请求的时候就会因为本地找不到配置而 foward 到 upstream DNS 服务器解析，从而导致容器的 DNS 解析请求变慢。
coredns 提供了一种 plugin 叫做 template，经过配置后可以给所有的 IPV6 请求立即返回一个空结果的应答，避免请求 forward 到上游 DNS。
使用方法
template 插件的官方文档地址：https://github.com/coredns/coredns/tree/master/plugin/template，coredns 默认已携带此插件，大家只需要配置即可。
template ANY AAAA { rcode NXDOMAIN } 该配置添加到 forward 下面即可
AAAA 表示 IPV6 解析请求，rcode 控制应答返回 NXDOMAIN，即表示没有解析结果。
修改每个 pod 中 /etc/resolv.conf 中 ndots 的值</description></item><item><title>DNSmasq</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DNSmasq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/DNSmasq/</guid><description>概述 参考：
Manual(手册) https://cloud.tencent.com/developer/article/1534150 DNSmasq 是一个轻量的 DHCP 和 DNS 缓存 服务。
DNS 泛解析实例 最近遇到一个问题，需要在服务器上对域名进行泛解析，比如访问百度的域名统统解析到 6.6.6.6，然而发现 hosts 文件根本就不支持类似 *.baidu.com 的这种写法。
于是乎就在网上找了下资料，发现可以通过 Dnsmasq 来解决这个问题，原理其实就是本机的 DNS 指向 Dnsmasq 服务器，然后 Dnsmasq 通过类似通配符 (*) 的方式进行匹配，凡是匹配到 *.baidu.com 的都解析到 6.6.6.6。 利用 Dnsmasq 实现 hosts 泛解析
环境介绍
$ uname -a Linux ansheng 3.10.0-957.1.3.el7.x86_64 #1 SMP Thu Nov 29 14:49:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux $ whoami root $ cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) 安装 Dnsmasq 安装非常简单，通过 yum 即可。</description></item><item><title>docker 的 MountFlags=slave 与 live-restore 冲突问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/docker-%E7%9A%84-MountFlagsslave-%E4%B8%8E-live-restore-%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/docker-%E7%9A%84-MountFlagsslave-%E4%B8%8E-live-restore-%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/</guid><description>Pod 一直停留在 Terminating 状态，我等得花儿都谢了~
1.背景 近期，弹性云线上集群发生了几起特殊的容器漂移失败事件，其特殊之处在于容器处于 Pod Terminating 状态，而宿主则处于 Ready 状态。
宿主状态为 Ready 说明其能够正常处理 Pod 事件，但是 Pod 却卡在了退出阶段，说明此问题并非由 kubelet 引起，那么 docker 就是 1 号犯罪嫌疑人了。
下文将详细介绍问题的排查与分析全过程。
2.抽丝剥茧 Pod 状态如下：
[stupig@master ~]$ kubectl get pod -owide pod-976a0-5 0/1 Terminating 0 112m 尽管 kubelet 的犯罪嫌疑已经很小，但是我们还是需要排查 kubelet 日志进一步确认。截取 kubelet 关键日志片段如下：
I1014 10:56:46.492682 34976 kubelet_pods.go:1017] Pod &amp;#34;pod-976a0-5_default(f1e03a3d-0dc7-11eb-b4b1-246e967c4efc)&amp;#34; is terminated, but some containers have not been cleaned up: {ID:{Type:docker ID:41020461ed4d801afa8d10847a16907e65f6e8ca34d1704edf15b0d0e72bf4ef} Name:stupig State:exited CreatedAt:2020-10-14 10:49:57.859913657 +0800 CST StartedAt:2020-10-14 10:49:57.</description></item><item><title>Docker 获取 parent 逻辑</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%8E%B7%E5%8F%96-parent-%E9%80%BB%E8%BE%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%8E%B7%E5%8F%96-parent-%E9%80%BB%E8%BE%91/</guid><description>每次 kubelet 获取镜像列表时，docker 都会获取一遍镜像的 parent
具体逻辑在这里 image/store.go</description></item><item><title>Docker 架构的演变</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E4%BB%8B%E7%BB%8D/Docker-%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E4%BB%8B%E7%BB%8D/Docker-%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98/</guid><description>原文链接：https://blog.csdn.net/csdnnews/article/details/90746002
Docker 是如何工作的？这是一个简单的问题，但答案却是出乎意料的复杂。你可能很多次地听说过“守护进程(daemon)”和“运行时(runtime)”这两个术语，但可能从未真正理解它们的含义以及它们是如何配合在一起的。如果你像我一样，涉过源头去发现真相，那么，在你沉溺于代码之海时，你并不孤单。让我们面对现实吧，假想 Docker 的源代码是一顿意式大餐，而你正在狼吞虎咽你的美味意面。
就像一把叉子可以把面条送到你的口中，这篇文章会将 Docker 的技术的方方面面组织在一起并导入你饥饿的大脑。
为了更好地理解现在，我们首先需要回顾过去。2013 年，dotCloud 公司的 Solomon Hykes 在那年的 Python 大会上发表了 Linux 容器的未来的演讲（https://www.youtube.com/watch?v=wW9CAH9nSLs，需科学上网），第一次将 Docker 带入了公众的视线。让我们将他的 git 代码库回溯到 2013 年 1 月，这个 Docker 开发更轻松的时间。
Docker 2013 是如何工作的？
Docker 由两个主要组件组成，一个供用户使用的命令行应用程序和一个管理容器的守护进程。这个守护进程依赖两个子组件来执行它的任务：在宿主主机文件系统上用来存储镜像和容器数据的存储组件；以及用于抽象原始内核调用来构建 Linux 容器的 LXC 接口。
命令行应用程序
Docker 命令行应用程序是管理你的 Docker 运行副本已知的所有镜像和容器的人工界面。它相对简单，因为所有的管理都是由守护进程完成的。应用程序开始于一个 main 函数：
funcmain() { var err error ... // Example: &amp;#34;/var/run/docker.sock&amp;#34;, &amp;#34;run&amp;#34; conn, err := rcli.CallTCP(os.Getenv(&amp;#34;DOCKER&amp;#34;), os.Args[1:]...) ... receive_stdout := future.Go(func()error { _, err := io.Copy(os.Stdout, conn) return err }) .</description></item><item><title>Docker 资源泄露系列</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%B5%84%E6%BA%90%E6%B3%84%E9%9C%B2%E7%B3%BB%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Docker-%E8%B5%84%E6%BA%90%E6%B3%84%E9%9C%B2%E7%B3%BB%E5%88%97/</guid><description>原文连接：
博客
微信公众号</description></item><item><title>docker-shim 何去何从</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E4%BB%8B%E7%BB%8D/docker-shim-%E4%BD%95%E5%8E%BB%E4%BD%95%E4%BB%8E/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Docker/Docker-%E4%BB%8B%E7%BB%8D/docker-shim-%E4%BD%95%E5%8E%BB%E4%BD%95%E4%BB%8E/</guid><description>概述 关于 dockershim 即将灭亡的传言无疑存在严重夸大。如果一直有关注 Kubernetes 生态系统，很多朋友一时之间可能确实被 Kubernetes 1.20 版本的发布公告弄得有点不知所措。从公告内容来看，自 1.20 版本开始 dockershim 将被全面弃用。但请不要恐慌，调整呼吸，一切都会好起来。
更重要的是，Mirantis 现已同意与 Docker 开展合作，在 Kubernetes 之外独立维护 shim 代码并将其作为 Docker Engine API 的统一 CRI 接口。对于 Mirantis 客户而言，这意味着 Docker Engine 的商业支持版本 Mirantis Container Runtime（MCR）也将提供 CRI 兼容能力。我们将从https://github.com/dims/cri-d...，并逐步将其转化为开源项目https://github.com/Mirantis/c...。换句话说，你可以像之前一样继续基于 Docker Engine 构建 Kubernetes，唯一的区别就是 dockershim 由内置方案变成了外部方案。我们将共同努力，保证它在保持原有功能的同时，顺利通过各类一致性测试并提供与此前内置版本相同的使用体验。Mirantis 将在 Mirantis Kubernetes Engine 中使用 dockershim，Docker 方面也将在 Docker Desktop 中继续提供 dockershim。
从头说起……
用过 Kubernetes 的朋友都清楚，它的最大作用就是编排各类容器。对不少用户来说，容器已经与 Docker 完全统一了起来。但这种说法并不准确，Docker 本身只是彻底改变了容器技术并将其推向了通用舞台，因此 Docker Engine 也成为 Kubernetes 所支持的第一种（也是最初唯一一种）容器运行时。
但 Kubernetes 社区并不打算长期保持这样的状态。
从长远来看，社区希望能够使用多种不同类型的容器，因此参与者们创建了容器运行时接口（CRI），也就是容器引擎与 Kubernetes 间进行通信的标准方式。如果容器引擎与 CRI 相兼容，即可轻松在 Kubernetes 当中运行。</description></item><item><title>Dockerfile 样例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/Dockerfile-%E6%A0%B7%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E6%9E%84%E5%BB%BA-OCI-Image/Dockerfile-%E6%A0%B7%E4%BE%8B/</guid><description>生成一个具有基本网络工具的容器，可以用来测试
FROM centos:centos7.8.2003 ENV LANG=zh_CN.UTF-8 \ LANGUAGE=zh_CN:zh \ LC_ALL=zh_CN.UTF-8 RUN yum install -y epel-release.noarch &amp;amp;&amp;amp; \ yum install -y iproute bind-utils nginx glibc-common tcpdump telnet &amp;amp;&amp;amp; \ yum clean all &amp;amp;&amp;amp; \ rm -rf /tmp/* rm -rf /var/cache/yum/* &amp;amp;&amp;amp; \ localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8 &amp;amp;&amp;amp; \ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime COPY index.html /usr/share/nginx/html EXPOSE 80/tcp CMD [&amp;#34;/usr/sbin/nginx&amp;#34;,&amp;#34;-g&amp;#34;,&amp;#34;daemon off;&amp;#34;] ~]# cat index.html &amp;lt;meta charset=&amp;#34;utf-8&amp;#34;/&amp;gt; &amp;lt;h1&amp;gt;网络测试容器 desist-daydream 1&amp;lt;/h1&amp;gt; 使用 alpine 版本让镜像更小</description></item><item><title>Docker私有仓库</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Repository%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/Docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Repository%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/Docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/</guid><description>私有仓库 有时候使用 Docker Hub 这样的公共仓库可能不方便，用户可以创建一个本地仓库供私人使用。
本节介绍如何使用本地仓库。
docker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。本文内容基于 docker-registry v2.x 版本。
安装运行 docker-registry 容器运行 你可以通过获取官方 registry 镜像来运行。
$ docker run -d -p 5000:5000 &amp;ndash;restart=always &amp;ndash;name registry registry
这将使用官方的 registry 镜像来启动私有仓库。默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下。你可以通过 -v 参数来将镜像文件存放在本地的指定路径。例如下面的例子将上传的镜像放到本地的 /opt/data/registry 目录。
$ docker run -d \ -p 5000:5000 \ -v /opt/data/registry:/var/lib/registry \ registry
在私有仓库上传、搜索、下载镜像 创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库。例如私有仓库地址为 127.0.0.1:5000。
先在本机查看已有的镜像。
$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest ba5877dc9bec 6 weeks ago 192.</description></item><item><title>DOM</title><link>https://desistdaydream.github.io/docs/Web/WebAPIs/DOM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/WebAPIs/DOM/</guid><description>概述 参考：
WHATWG，DOM 标准 MDN，参考-WebAPIs-DOM Document Ojbect Model(文档对象模型，简称 DOM) 是 Web 文档(i.e. HTML 和 XML)的编程接口(通常描述为 WebAPI 中的 DOM 接口)。应用程序可以通过该接口更改 Web 文档的 结构、样式、内容 等。DOM 将 Web 文档抽象为 Node(节点) 和 Ojbect(对象，包含属性和方法的对象) 组成的结构集合。
一个 Web 页面即是一个文档，这个文档可以在浏览器中作为 HTML 源码展示出来。DOM 则可以将文档表示为另一种形式，以便 JavaScript 等编程语言可以对其进行修改。
比如：
// 我们通过 document.querySelectorAll() 获取 Web 文档中所有 &amp;lt;p&amp;gt; 元素的列表 // 将所有 &amp;lt;p&amp;gt; 元素实例化为 paragraphs 变量 var paragraphs = document.querySelectorAll(&amp;#34;p&amp;#34;) // 之后，通过代码对 paragraphs 的所有操作都会直接反应到前端 Web 页面上 // 这里表示将将会弹出提示框，并将其中第一个 &amp;lt;p&amp;gt; 元素的名称显示在提示框中 alert(paragraphs[0].nodeName) 从上面的示例中可以看到，JavaScript 中使用 Document 类型的对象 表示 Web 文档本身；document 对象里包含了非常多的方法来控制 Web 文档中的元素，在 MDN 官方文档，WebAPIs-Document 中可以看到所有 document 对象下的属性、方法、事件。示例中的 querySelectorAll() 方法将会返回匹配到的元素列表。</description></item><item><title>Domain 命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Domain-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Domain-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#domain-commands 可以为虚拟机重命名、查看虚拟机信息，状态、等等
简单的子命令 autostart # 指定 Domain 是否在开机后自启动，可以使用 &amp;ndash;disable 选项关闭 Domain 的开机自启功能。
console - 连接到 VM 的终端 console 用于把虚拟机屏幕上的信息投射到宿主机上，可以直接在宿主机的终端上操作虚拟机。 注意：如果无法通过 console 连接到 VM，则需要在 VM 上启动 serial-getty@.service 服务并在开启服务的时候指定一个终端。e.g.systemctl enable serial-getty@ttyS0.service &amp;ndash;now
cpu-stats - 显示 Domain 的 CPU 统计信息 默认显示所有 CPU 的统计信息和总数。仅使用 &amp;ndash;total 获取总统计信息，仅使用 start 获取从 &amp;ndash;start 开始的 CPU 的 per-cpu 统计信息，仅使用 &amp;ndash;count CPU 的统计信息。
create - 从一个 XML 文件里创建一个 domain 通过 XML 直接启动一台 VM，VM 关闭后，virsh list 列表中该 VM 会消失。</description></item><item><title>Drone</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Drone/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Drone/</guid><description>概述 参考：
GitHub 项目，drone/drone Drone 是一个比 Jenkins 更简单易用的现代化 CI/CD 平台。使用 Go 语言编写，基于 Docker 构建，使用简单的 yaml 配置文件来定义和执行 Docker 容器中定义的 Pipeline。
Drone 由两个部分组成：
Server # 用于对接 SCM，负责身份认证，SCM 配置，用户、Secrets 以及 webhook 相关的配置。当 Server 收到 SCM 的 webhook 消息后，会通知 Runner 执行 Pipeline。 可以启动多个 Server 来对接不同的 SCM。 Runners # 用于接收任务和运行 Pipeline。如果没有 Runner，那么在触发 Webhook，Drone 在开始 Pipeline 后，会处于 pending 状态并卡住。并且在 Drone Server 的日志中会看到如下报错： &amp;ldquo;error&amp;rdquo;: &amp;ldquo;Cannot transition status via :enqueue from :pending (Reason(s): 状态 cannot transition via &amp;ldquo;enqueue&amp;rdquo;)&amp;rdquo;, &amp;ldquo;msg&amp;rdquo;: &amp;ldquo;manager: cannot publish status&amp;rdquo;, Note：</description></item><item><title>Drone Pipelines 详解</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Drone-Pipelines-%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Drone-Pipelines-%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档：https://docs.drone.io/pipeline/overview/ Drone 默认通过 yaml 格式的名为 .drone.yml 的文件来指定 Pipelines 的行为。yaml 语法易于阅读和表达，将 .drone.yml 提交到代码仓库的根目录后，如果代码仓库配置了 webhook 并指定 Drone Server，那么当代码更改并触发 webhook 后，Drone Server 首先就会 clone 该仓库，并根据其中的 .drone.yml 文件中的内容，来执行后续 pipeline 动作。
Note:Pipelines 从逻辑上看，就是一个或多个 Drone Plugins 的合集，每一个步骤都使用一个插件。具体原因详见下文 Pipeline 插件
.drone.yml 文件基本样例 kind: pipeline type: docker name: default steps: - name: greeting image: alpine commands: - echo hello - echo world kind # 指定本次任务的种类，该示例任务为 pipeline 种类。还有 secret 与 signature 种类 type # 指定 pipeline 的类型，不同的类型调用不同的 Runner 来执行任务。如果不填 type，则默认为 docker 类型。该示例任务为 docker 类型(docker 类型意味着后续的所有步骤都会启动一个容器，然后再容器中执行步骤的内容)。 name # The name attribute defines a name for your pipeline.</description></item><item><title>drone 命令行工具</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/drone-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/drone-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description/></item><item><title>Drone 任务示例</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Drone-%E4%BB%BB%E5%8A%A1%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Drone-%E4%BB%BB%E5%8A%A1%E7%A4%BA%E4%BE%8B/</guid><description>说明：
Drone 无法通过手动来触发任务，需要在代码仓库开启 webhook，并配置该 webhook 的地址指向 Drone。
这样在提交代码时，会自动通过 webhook 通知 Drone，有新的代码更改，可以触发任务。
Drone 的基本示例演示 在 git 仓库中的根目录中，需要创建一个名为 .drone.yml 的文件(该文件也可以使用别的名字，如果要使用别的名字，那么在 Drone 的配置中也要进行相应修改)
kind: pipeline type: docker name: default steps: - name: greeting image: alpine commands: - echo hello - echo world 项目的根目录下创建好该文件后，由于有 webhook 的存在，GitLab 会自动通知 Dreon 开始任务，如果没通知，那么可以通过下图的方式来手动触发 Webhook(在一个项目的 webhook 设置，手动测试 push)。
Drone 收到 Webhook 的通知后，开始任务，首先会 clone 该仓库，然后启动 alpine 容器，并在容器中，执行 commands 中执行的命令。
至此，一套最简单的 CI/CD 流程就算完成了
通过 Drone 运行 go 语言的 hello world .drone.yaml 文件内容如下</description></item><item><title>EBNF</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/EBNF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/EBNF/</guid><description>概述 参考：
Wiki, EBNF Wiki, Metasyntax Extended Backus-Naur Form(扩展的 Backus-Naur 格式，简称 EBNF) 是一组 Metasyntax(元语法) 表示法。EBNF 用于对计算机编程语言等形式语言进行形式化描述。EBNF 是基于 BNF 的扩展。
EBNF 是一种表达形式语言语法的代码。EBNF 由两部分组成
Terminal Symbols(终结符号) non-terminal production rules(非终结表达式规则) # 其实就相当于一个表达式 这两部分组合起来，其实就是一句话，最后跟一个句号~~~一行内容就是一个 EBNF 表示法，比如：
digit excluding zero = &amp;quot;1&amp;quot; | &amp;quot;2&amp;quot; | &amp;quot;3&amp;quot; | &amp;quot;4&amp;quot; | &amp;quot;5&amp;quot; | &amp;quot;6&amp;quot; | &amp;quot;7&amp;quot; | &amp;quot;8&amp;quot; | &amp;quot;9&amp;quot; ; digit = &amp;quot;0&amp;quot; | digit excluding zero ; Symbols(符号) 下面定义的符号意义中，... 仅仅用来表示符号中可以是任意内容，不属于被定义的符号的一部分。 = # Definition(定义) , # Concatenation(串接) ; # Termination(终止) | # Alternation(交替)，就是“或者”的意思。 [.</description></item><item><title>EFK 部署</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/ELK-_-EFK/EFK-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/ELK-_-EFK/EFK-%E9%83%A8%E7%BD%B2/</guid><description>在 Kubernetes 中部署 EFK 套件 官方 addons：https://github.com/kubernetes/kubernetes/tree/release-1.18/cluster/addons/fluentd-elasticsearch
官方 addons 问题：https://github.com/kubernetes/kubernetes/issues/94429
参考：https://www.qikqiak.com/post/install-efk-stack-on-k8s/
es-service.yaml
kind: Service apiVersion: v1 metadata: name: elasticsearch namespace: logging labels: app: elasticsearch spec: selector: app: elasticsearch clusterIP: None ports: - port: 9200 name: rest - port: 9300 name: inter-node es-statefulset.yaml
apiVersion: apps/v1 kind: StatefulSet metadata: name: es namespace: logging spec: serviceName: elasticsearch replicas: 3 selector: matchLabels: app: elasticsearch template: metadata: labels: app: elasticsearch spec: containers: - name: elasticsearch image: docker.</description></item><item><title>emptyDir、hostPath、local</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Volume/emptyDirhostPathlocal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Volume/emptyDirhostPathlocal/</guid><description>emptyDir # 在 Pod 的生命周期中的空目录 该类型的 Volume 会随着 Pod 的摧毁重建而自动还原成初始状态。Pod 会创建一个逻辑上的 volume，把该 volum 挂载到一个 Pod 中每个 container 所定义的目录，所有 container 对自己挂载 volume 的目录进行的操作都会在其余 container 挂载该 volume 的目录中看到(每个 container 用于挂载的目录可以不一样，但是用到的 volume 都是同一个)。
medium：指定 volum 的存储媒介(即 volum 使用的存储资源)，默认使用 memory，这样两个容器的数据交互速度会非常快
sizeLimit：容量大小限制，限制 volume 的最大存储空间，如果不做限制，那么对于设备来说，用户数据交互的 volume 会非常浪费资源
获取 emptyDir 类型的 volume 在宿主机的路径的方式：
首先通过 kubectl get pod PODNAME -o yaml | grep uid 来获取 pod 的标识符
然后在目录/var/lib/kubelet/pods/PodID/volumes/kubernets.io~empty-dir/下面找到所有该 pod 所挂载的 empty 类型的 volume，该目录与 pod 中的目录是同步的，在该目录增删改的信息同样也会影响到 pod 对应的目录中。
hostPath # Node 上的文件或目录</description></item><item><title>Etcd API 文档</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-API-%E6%96%87%E6%A1%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-API-%E6%96%87%E6%A1%A3/</guid><description>https://github.com/etcd-io/website/blob/master/static/apispec/swagger/rpc.swagger.json</description></item><item><title>Etcd 备份与恢复</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Etcd-%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Etcd-%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</guid><description>系统环境：
Etcd 版本：3.4.3 Kubernetes 版本：1.18.8 Kubernetes 安装方式：Kubeadm 备份 Etcd 数据 本人采用的是 Kubeadm 安装的 Kubernetes 集群，采用镜像方式部署的 Etcd，所以操作 Etcd 需要使用 Etcd 镜像提供的 Etcdctl 工具。如果是非镜像方式部署 Etcd，可以直接使用 Etcdctl 命令备份数据。
# 备份现有 Etcd 数据和manifests mkdir -p /root/backup/kubernetes/ cp -r /var/lib/etcd/member /root/backup/kubernetes/member-$(date +%F) cp -r /etc/kubernetes/manifests /root/backup/kubernetes/manifests-$(date +%F) # 通过运行 Etcd 镜像，并且使用镜像内部的 etcdctl 工具连接 etcd 集群，执行数据快照备份： docker run --rm --name etcdctl \ -v /root/backup/kubernetes:/backup \ -v /etc/kubernetes/pki/etcd:/etc/kubernetes/pki/etcd:ro \ --env ETCDCTL_API=3 \ registry.aliyuncs.com/k8sxio/etcd:3.4.13-0 \ /bin/sh -c &amp;#34;etcdctl --endpoints=https://172.</description></item><item><title>Etcd 部署</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档 Etcd 可以通过多种方式部署。如果要启动 etcd 集群，则每种部署方式，都需要配置最基本标志为以下几个：
&amp;ndash;name # etcd 集群中的节点名，这里可以随意，可区分且不重复就行 &amp;ndash;listen-peer-urls # 监听的用于节点之间通信的 url，可监听多个，集群内部将通过这些 url 进行数据交互(如选举，数据同步等) &amp;ndash;initial-advertise-peer-urls # 建议用于节点之间通信的 url，节点间将以该值进行通信。 &amp;ndash;listen-client-urls # 监听的用于客户端通信的 url，同样可以监听多个。 &amp;ndash;advertise-client-urls # 建议使用的客户端通信 url，该值用于 etcd 代理或 etcd 成员与 etcd 节点通信。 &amp;ndash;initial-cluster-token etcd-cluster-1 # 节点的 token 值，设置该值后集群将生成唯一 id，并为每个节点也生成唯一 id，当使用相同配置文件再启动一个集群时，只要该 token 值不一样，etcd 集群就不会相互影响。 &amp;ndash;initial-cluster # 也就是集群中所有的 initial-advertise-peer-urls 的合集。 &amp;ndash;initial-cluster-state new # 新建集群的标志 如果是单节点部署，则直接启动即可。
使用二进制文件部署 etcd 直接使用 yum install etcd -y 命令即可安装
在容器内运行 etcd 运行一个单节点的 etcd
export NODE1=192.168.1.21 # 配置Docker卷以存储etcd数据： docker volume create --name etcd-data export DATA_DIR=&amp;#34;etcd-data&amp;#34; # 运行最新版本的etcd： REGISTRY=quay.</description></item><item><title>Etcd 调优</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/Etcd-%E8%B0%83%E4%BC%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/Etcd-%E8%B0%83%E4%BC%98/</guid><description>Etcd Tuning(调优)概述 参考：
官方文档 官方文档译文 决定 etcd 性能的关键因素，包括：
延迟 (latency)：延迟是完成操作的时间。 吞吐量 (throughput)：吞吐量是在某个时间期间之内完成操作的总数量。当 etcd 接收并发客户端请求时，通常平均延迟随着总体吞吐量增加而增加。 在通常的云环境，比如 Google Compute Engine (GCE) 标准的 n-4 或者 AWS 上相当的机器类型，一个三成员 etcd 集群在轻负载下可以在低于 1 毫秒内完成一个请求，并在重负载下可以每秒完成超过 30000 个请求。
etcd 使用 Raft 一致性算法来在成员之间复制请求并达成一致。一致性性能，特别是提交延迟，受限于两个物理约束：网络 IO 延迟和磁盘 IO 延迟。完成一个 etcd 请求的最小时间是成员之间的网络往返时延 (Round Trip Time / RTT)，加需要提交数据到持久化存储的 fdatasync 时间。在一个数据中心内的 RTT 可能有数百毫秒。在美国典型的 RTT 是大概 50ms, 而在大陆之间可以慢到 400ms。旋转硬盘(注：指传统机械硬盘) 的典型 fdatasync 延迟是大概 10ms。对于 SSD 硬盘, 延迟通常低于 1ms。为了提高吞吐量, etcd 将多个请求打包在一起并提交给 Raft。这个批量策略让 etcd 在重负载试获得高吞吐量。也有其他子系统影响到 etcd 的整体性能。每个序列化的 etcd 请求必须通过 etcd 的 boltdb 支持的(boltdb-backed) MVCC 存储引擎, 它通常需要 10 微秒来完成。etcd 定期递增快照它最近实施的请求，将他们和之前在磁盘上的快照合并。这个过程可能导致延迟尖峰(latency spike)。虽然在 SSD 上这通常不是问题，在 HDD 上它可能加倍可观察到的延迟。而且，进行中的压缩可以影响 etcd 的性能。幸运的是，压缩通常无足轻重，因为压缩是错开的，因此它不和常规请求竞争资源。RPC 系统，gRPC，为 etcd 提供定义良好，可扩展的 API，但是它也引入了额外的延迟，尤其是本地读取。</description></item><item><title>Etcd 高可用</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E9%AB%98%E5%8F%AF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E9%AB%98%E5%8F%AF%E7%94%A8/</guid><description>Etcd 集群介绍 官方文档：https://etcd.io/docs/latest/op-guide/clustering/</description></item><item><title>Etcd 管理</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/Etcd-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/Etcd-%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
GitHub https://github.com/etcd-io/website/blob/main/content/en/docs/v3.5/op-guide/maintenance.md 官方文档，-运维指南-维护 Etcd 集群需要定期 Maintenacne(维护) 才能保持可靠性。根据 etcd 应用程序的需求，通常可以自动执行该维护，而无需停机或性能显着降低。
所有 etcd 维护都管理 etcd 键空间消耗的存储资源。存储空间配额可以防止无法充分控制键空间大小；如果 etcd 成员的空间不足，则配额将触发群集范围的警报，这将使系统进入有限操作维护模式。为了避免空间不足以写入键空间，必须压缩 etcd 键空间历史记录。可以通过对 etcd 成员进行碎片整理来回收存储空间本身。最后，etcd 成员状态的定期快照备份使恢复由于操作错误引起的意外逻辑数据丢失或损坏成为可能。
Raft Log Retention(Raft 日志保留) https://etcd.io/docs/v3.5/op-guide/maintenance/#raft-log-retention
Auto Compaction(自动压缩) https://etcd.io/docs/v3.5/op-guide/maintenance/#auto-compaction
Defragmentation(碎片整理) https://etcd.io/docs/v3.5/op-guide/maintenance/#defragmentation
在压缩 keyspace 之后，Etcd 数据库可能会出现内部 Fragmentation(碎片)。任何内部碎片都是后端可以免费使用但仍会占用存储空间的空间。通过在后端数据库中留下空白来在内部压缩旧修订版碎片 etcd。碎片空间可供 etcd 使用，但主机文件系统不可用。换句话说，删除应用程序数据不会回收磁盘空间。
碎片整理过程将此存储空间释放回文件系统。碎片整理是针对每个成员进行的，因此可以避免集群范围内的延迟峰值。
在 kube-prometheus-stack 项目中，会自带碎片所占空间的告警，告警名称为 etcdDatabaseHighFragmentationRatio，当出现该告警时，即可执行碎片整理操作。
具体用法详见 etcdctl
Etcd Space Quota(Etcd 空间配额) 参考：
官方文档，运维指南-维护-空间配额 etcd 通过 Space Quota(空间配额) 确保集群以可靠的方式运行，空间配额指的是 etcd 可以储存的数据量上限。没有空间配额，如果密钥空间过大，etcd 可能会遭受性能不佳的影响，或者它可能只是用尽了存储空间，从而导致了不可预测的集群行为。
默认情况下，etcd 的空间配额适合大多数应用程序的使用情况。不过，可以通过 quota-backend-bytes 命令行参数修改配额的值
注意如果 etcd 中的数据超过了配额的值，则无法再写入新数据。并且 etcd 会在集群中发出一个 alarm(警报)，该警报会告诉各节点，并且集群将会变为 maintenance mode(维护模式)，处于维护模式的集群仅接受 key 的读取和删除操作。并且如果想让集群恢复正常运行，需要进行如下操作</description></item><item><title>Etcd 基于 RAFT 的一致性</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E5%9F%BA%E4%BA%8E-RAFT-%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E5%9F%BA%E4%BA%8E-RAFT-%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</guid><description>Etcd 基于 RAFT 的一致性 选举方法
初始启动时，节点处于 follower 状态并被设定一个 election timeout，如果在这一时间周期内没有收到来自 leader 的 heartbeat，节点将发起选举：将自己切换为 candidate 之后，向集群中其它 follower 节点发送请求，询问其是否选举自己成为 leader。 当收到来自集群中过半数节点的接受投票后，节点即成为 leader，开始接收保存 client 的数据并向其它的 follower 节点同步日志。如果没有达成一致，则 candidate 随机选择一个等待间隔（150ms ~ 300ms）再次发起投票，得到集群中半数以上 follower 接受的 candidate 将成为 leader leader 节点依靠定时向 follower 发送 heartbeat 来保持其地位。 任何时候如果其它 follower 在 election timeout 期间都没有收到来自 leader 的 heartbeat，同样会将自己的状态切换为 candidate 并发起选举。每成功选举一次，新 leader 的任期（Term）都会比之前 leader 的任期大 1。 日志复制
当前 Leader 收到客户端的日志（事务请求）后先把该日志追加到本地的 Log 中，然后通过 heartbeat 把该 Entry 同步给其他 Follower，Follower 接收到日志后记录日志然后向 Leader 发送 ACK，当 Leader 收到大多数（n/2+1）Follower 的 ACK 信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个 heartbeat 中 Leader 将通知所有的 Follower 将该日志存储在自己的本地磁盘中。</description></item><item><title>Etcd 配置详解</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档 Etcd 运行时的行为可以通过三种方式进行配置
配置文件 命令行标志 环境变量 而一般情况，配置文件中的关键字 与 命令行标志 和 环境变量 是 一一对应的。比如：
配置文件中关键字：ETCD_DATA_DIR 对应的环境变量中的变量名：ETCD_DATA_DIR 对应的 flag： &amp;ndash;data-dir 优先级：配置文件 &amp;gt; 命令行标志 &amp;gt; 环境变量
Member 成员相关标志 &amp;ndash;name # member 的名称。默认值：default &amp;ndash;data-dir # etcd 数据存储路径。默认值：${name}.etcd。一般大家都修改到 /var/lib/etcd 下。 &amp;ndash;wal-dir &amp;ndash;snapshot-count &amp;ndash;heartbeat-interval # 心跳检测的间隔时间，时间单位是 milliseconds(毫秒)。默认值：100
注意：修改心跳值的同时要修改 election-timeout 标志。因为 选举超时 时间至少需要是 心跳检测间隔的 5 倍，如果达不到 5 倍，则 etcd 启动失败 &amp;ndash;election-timeout # 选举超时时间，时间单位是 milliseconds(毫秒)。默认值：1000 &amp;ndash;listen-peer-urls # 监听的用于节点之间通信的 url，可监听多个，集群内部将通过这些 url 进行数据交互(如选举，数据同步等) &amp;ndash;listen-client-urls # 监听的用于客户端通信的 url，同样可以监听多个。 &amp;ndash;max-snapshots &amp;ndash;max-wals &amp;ndash;cors &amp;ndash;quota-backend-bytes # etcd 可储存的数据配额上限。默认值：0。</description></item><item><title>Etcd 数据模型</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考：
官方文档 WAL 数据库通常使用 WAL； etcd 也使用它。有关预写日志记录的详细信息不在本文讨论范围之内，但是出于此目的，我们需要知道的是-每个 etcd 集群成员都在持久性存储上保留一个预写日志（WAL）。 etcd 在将某些操作（例如更新）写入键值存储之前，将其写入 WAL。如果成员崩溃并在快照之间重新启动，则可以通过查看 WAL 的内容在本地恢复自上次快照以来完成的事务。
因此，每当客户将密钥添加到键值存储或更新现有密钥的值时，客户端都会 etcd 在 WAL 上附加一个记录操作的条目，WAL 是持久性存储上的普通文件。在继续进行之前， etcd 必须 100％确信 WAL 条目已被实际保留。要在 Linux 上实现此目的，仅使用 write 系统调用是不够的， 因为实际写入物理存储的时间可能会延迟。例如，Linux 可能会将写入的 WAL 条目在内核内存高速缓存（例如页面高速缓存）中保留一段时间。为了确保将数据写入持久性存储中，您必须在“”之后调用 fdatasync 系统调用，write 这正是该 etcd 操作（如以下 strace 所示） 输出，其中 8 是 WAL 文件的文件描述符）：
21:23:09.894875 lseek(8, 0, SEEK_CUR) = 12808 &amp;lt;0.000012&amp;gt; 21:23:09.894911 write(8, &amp;#34;.\0\0\0\0\0\0\202\10\2\20\361\223\255\266\6\32$\10\0\20\10\30\26\&amp;#34;\34\&amp;#34;\r\n\3fo&amp;#34;..., 2296) = 2296 &amp;lt;0.000130&amp;gt; 21:23:09.895041 fdatasync(8) = 0 &amp;lt;0.008314&amp;gt; 不幸的是，写入持久性存储需要时间。如果 fdatasync 花费太长时间，则 etcd 系统性能会降低。 etcd 文档建议 为了使存储足够快，fdatasync 写入 WAL 文件时调用的第 99 个百分点 必须小于 10ms。还有其他与存储相关的指标，但这是本文的重点。</description></item><item><title>etcd 问题处理案例</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/etcd-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/</guid><description>What does the etcd warning “apply entries took too long” mean? 官方文档：
https://etcd.io/docs/v3.4.0/faq/#what-does-the-etcd-warning-apply-entries-took-too-long-mean
https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md#what-does-the-etcd-warning-apply-entries-took-too-long-mean
What does the etcd warning “failed to send out heartbeat on time” mean? 官方文档：
https://etcd.io/docs/v3.4.0/faq/#what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean
https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md#what-does-the-etcd-warning-failed-to-send-out-heartbeat-on-time-mean
其他 http://blog.itpub.net/31559758/viewspace-2704804/
etcdserver: read-only range request took too long to execute 问题原因：
有可能是磁盘性能导致，当磁盘性能只有 2，3 十兆的读写速度，那么有很大机率会出现此错误。
参考：https://github.com/kubernetes/kubernetes/issues/70082</description></item><item><title>Etcd 性能测试</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/Etcd-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E7%AE%A1%E7%90%86/Etcd-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</guid><description>概述 参考：
官方文档，运维指南-性能 安装 etcd 压测工具 benchmark：
$ go get go.etcd.io/etcd/tools/benchmark # GOPATH should be set $ ls $GOPATH/bin benchmark 官方推荐的 etcd 性能数据 其中官方使用的设备信息为：
Google Cloud Compute Engine 3 machines of 8 vCPUs + 16GB Memory + 50GB SSD 1 machine(client) of 16 vCPUs + 30GB Memory + 50GB SSD Ubuntu 17.04 etcd 3.2.0, go 1.8.3 etcd 写性能 Key 数量 每个 Key 的大小 每个值的大小 连接数量 客户端数量 目标 etcd 节点数 写性能的平均 QPS 每个请求的平均延迟 服务器 RRS 的平均值 10,000 8 bytes 256 bytes 1 1 只有一个 leader 583 1.</description></item><item><title>Etcd 中存储的数据之探究</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Etcd/Etcd-%E4%B8%AD%E5%AD%98%E5%82%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%8E%A2%E7%A9%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Etcd/Etcd-%E4%B8%AD%E5%AD%98%E5%82%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%8E%A2%E7%A9%B6/</guid><description>概述 原文: https://jingwei.link/2018/11/25/kubernetes-etcd-data-save-specification.html#default%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E4%B8%ADendpoint%E5%AE%9E%E4%BE%8Bkubernetes%E7%9A%84%E5%80%BC
K8s 的架构复杂，涉及到概念非常多，其基础组件包含 ETCD、kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy 等，其运行时环境为 docker 或 Rkt，当然还包含很多插件。在我看来，k8s 是 DevOps 的未来，因此不禁想写一些它的故事。
ETCD 在 k8s 技术栈的地位，就仿佛数据库（Mysql、Postgresql 或 oracle 等）在 Web 应用中的地位，它存储了 k8s 集群中所有的元数据（以 key-value 的方式）。那么很现实的一个问题是：这些元数据是如何组织并保存的呢？本文就对此问题探究一番。
相关环境
两台 2 个核 4G 内存（2C4G）的虚拟机，ip 分别为 192.168.205.137 和 192.168.205.139 k8s 相关控件-1.8.6 etcd-3.3.10 docker-18.06.1-ce k8s 中 ETCD 数据的增删改查 首先应该明确，K8s 中所有元数据的增删改查都是由 kube-apiserver 来执行的，那么这些数据在 ETCD 中必然有一套存储规范，这样才能保证在集群中部署成千上万的应用时不会出差错。在此基础上可以认为，只要掌握了 k8s 在 ETCD 中存储数据的规范，便可以像 k8s 一样手动来操作 ETCD 了（虽然不建议这么做）。不过更大的价值是能对 k8s 的理解更进一步，便于以后 debug 或者二次开发 k8s 的某些功能时更有底气。
初探 ETCD 中的数据 本文对 ETCD 的操作主要使用了其官方客户端工具 etcdctl，这里不对 etcdctl 进行详解了（需要用一整篇博客来介绍它才行），只就用到的一些命令进行阐释。</description></item><item><title>etcdctl user 命令</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl-user-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/Etcd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/etcdctl-user-%E5%91%BD%E4%BB%A4/</guid><description>etcdctl user COMMAND [OPTIONS] [Arguments&amp;hellip;] # 用户添加，授予和撤消子命令 SubCommand 包括
add # add a new user for the etcd cluster get # get details for a user list # list all current users remove # remove a user for the etcd cluster grant # grant roles to an etcd user revoke # revoke roles for an etcd user passwd # change password for a user etcdctl user add USER # 为 etcd 集群添加用户</description></item><item><title>Event 资源</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E6%97%A5%E5%BF%97/Event-%E8%B5%84%E6%BA%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E6%97%A5%E5%BF%97/Event-%E8%B5%84%E6%BA%90/</guid><description>概述 参考：
公众号，张晋涛-彻底搞懂 Kubernetes 中的 Events 之前我写了一篇《更优雅的 Kubernetes 集群事件度量方案》，利用 Jaeger 利用 tracing 的方式来采集 Kubernetes 集群中的 events 并进行展示。最终效果如下：
写那篇文章的时候，立了个 flag 要详细介绍下其中的原理，鸽了很久，现在年底了，也该发出来了。
Eents 概览 我们先来做个简单的示例，来看看 Kubernetes 集群中的 events 是什么。 创建一个新的名叫 moelove 的 namespace ，然后在其中创建一个叫做 redis 的 deployment。接下来查看这个 namespace 中的所有 events。 (MoeLove) ➜ kubectl create ns moelove namespace/moelove created (MoeLove) ➜ kubectl -n moelove create deployment redis &amp;ndash;image=ghcr.io/moelove/redis:alpine deployment.apps/redis created (MoeLove) ➜ kubectl -n moelove get deploy NAME READY UP-TO-DATE AVAILABLE AGE redis 1/1 1 1 11s (MoeLove) ➜ kubectl -n moelove get events LAST SEEN TYPE REASON OBJECT MESSAGE 21s Normal Scheduled pod/redis-687967dbc5-27vmr Successfully assigned moelove/redis-687967dbc5-27vmr to kind-worker3 21s Normal Pulling pod/redis-687967dbc5-27vmr Pulling image &amp;ldquo;ghcr.</description></item><item><title>EvictionManager 模块</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/EvictionManager-%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/EvictionManager-%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
公众号-云原生实验室，Kubernetes 单机侧的驱逐策略总结 本文转自 Edwardesire 的博客，原文：https://edwardesire.com/posts/process-eviction-under-k8s/ 进程驱逐：当机器存在资源压力时，可能是由于有恶意程序在消耗系统资源，或者是 overcommit 导致。系统通过控制机器上的进程存活来减少单个程序对系统的整体影响。驱逐阶段最关键的就是选择合适的进程，通过最小代价来保证系统的稳定。在执行层面上可以分为两种驱逐方式：
用户空间驱逐：通过守护进程之类的机制，触发式主动清理进程。 内核空间驱逐：内核在无法分配内存时，通过 oom_killer 选择进程终止来释放资源。 本文从 k8s 出发，总结不同层次下的驱逐流程和进程选择策略。
Kubelet 驱逐策略 k8s 除了支持 API 发起的主动驱逐，还支持用户空间的 pod 驱逐（将资源大户的进程终止）。对于不可压缩资源：内存、disk（nodefs）、pid，kubelet 会监控相应的指标来触发 pod 驱逐。K8S 依据 pod 的资源消耗和优先级来驱逐 pod 来回收资源：
如果 pod 资源使用量超过资源请求值，则优先驱逐 依据 pod priority 驱逐 pod 真实资源使用量越高则越优先驱逐 我们可以得出：
当 BestEffort 和 Burstable pod 的资源使用量超过请求值时，会依据 pod priority 和超过请求多少来判断驱逐顺序。也不会有特例的 pod 能够不被驱逐的风险。当 Guaranteed 和 Busrtable pod 的使用量低于请求值时，基于 pod priority 确定驱逐顺序。 这一切的逻辑都在 kubelet 的 eviction manager 实现。
Eviction manager Manager 的接口定义包含主流程的启动函数以及提供给 kubelet 上报节点状态的：</description></item><item><title>Exemplars</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Observability/Exemplars/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Observability/Exemplars/</guid><description>概述 参考；
https://prometheus.io/docs/prometheus/latest/feature_flags/#exemplars-storage https://grafana.com/docs/grafana/latest/basics/exemplars/ 这是啥？CNCF 可观测性白皮书最后提到了这个
Trace ID 实际应用 我们讨论了在多个信号之间相互跳转的方法，但是它真的是有用的吗？让我们简单的看两个基本案例:
我们收到了一个关于超出 SLO (service level objectives) 的意外高错误率的告警。告警来源于错误的计数器值，我们看到请求暴增导致 501 errors。我们使用_exemplar_ 跳转到事例的 logs 以了解准确的可供人类阅读的错误消息中。错误似乎来自于依赖深层次的内部微服务系统，由于存在与 trace ID 匹配的 request ID，所以可以跳转到 traces。多亏了这一点，我们确切的了解到哪个 service/process 导致了这个问题，并进一步挖掘更多的信息。 我们去 debug 慢请求，我们使用 trace 采样手动触发请求并获得 trace ID。多亏了 tracing view，我们可以在请求方式的几个进程中看到，对于基本操作而说，ABC-1 请求的速度非常的慢。由于目标元数据和时间，我们选择了相关的 CPU 使用率 metrics。我们看到 CPU 使用率很高，接近了机器的限制值，表明 CPU 已经饱和。为了了解 CPU 使用率高的原因 (特别是当它是容器中仅存的进程)，我们使用相同的 目标元数据 和 time 选择跳转到 CPU profile。 总结一下，好像是通过一个 ID 可以在 Metrics、Log、Trace 数据之间相互跳转。即一个 ID 关联了一个或多个应用所有的可观测性数据</description></item><item><title>Exporter 开发实践</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting-%E5%BC%80%E5%8F%91/Exporter-%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting-%E5%BC%80%E5%8F%91/Exporter-%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
GitHub 自学代码 默认自带的 Metrics 的实现方式 公众号，k8s 技术圈-使用 Go 开发 Prometheus Exporter https://medium.com/teamzerolabs/15-steps-to-write-an-application-prometheus-exporter-in-go-9746b4520e26 在 Instrumenting 原理解析 中，逐一了解了实现 Exporter 的方法
首先，定义了一个包含 Metrics 描述符的结构体。以及实例化结构体的函数(也就是自定义一些 Metrics 的基本信息) 然后让该 结构体 实现 Collector 接口(i.e.为这个结构体添加 Describe() 与 Collect() 方法) 该 结构体 实现了 Collector 之后，就需要注册该 Metric，注册之后即可让 Prometheus 库通过 Collector 接口直接操作这个 Metric 而想要注册，首先需要一个新的注册器 创建完新的注册器之后，即可使用该注册器，将实现了 Collector 的 Metric 注册给 Prometheus 库。 最后，使用 HandlerFor() 将注册器作为参数传递进去，并返回一个 http.Handler，指定 访问路径，并设置监听端口 启动后，通过指定的访问路径，请求将会进入到 返回的 http.Handler 中，开始执行代码，最后获取完 Metric 信息，再响应给客户端 现在我将前面学习过程中零散的代码合并起来
// HelloWorldMetrics 用来保存所有 Metrics type HelloWorldMetrics struct { HelloWorldDesc *prometheus.</description></item><item><title>Exporter 开发问题</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting-%E5%BC%80%E5%8F%91/Exporter-%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting-%E5%BC%80%E5%8F%91/Exporter-%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98/</guid><description>collected before with the same name and label values time=&amp;ldquo;2021-03-25 12:17:30&amp;rdquo; level=info msg=&amp;ldquo;error gathering metrics: 3 error(s) occurred:\n*
collected metric &amp;ldquo;consoler_gdas_node_changer_status&amp;rdquo; { label:&amp;lt;name:&amp;ldquo;changer_serial&amp;rdquo; value:&amp;ldquo;Mcc01327 A&amp;rdquo; &amp;gt; label:&amp;lt;name:&amp;ldquo;ip&amp;rdquo; value:&amp;ldquo;192.168.10.139&amp;rdquo; &amp;gt; label:&amp;lt;name:&amp;ldquo;name&amp;rdquo; value:&amp;ldquo;DA-BH7&amp;rdquo; &amp;gt; gauge:&amp;lt;value:0 &amp;gt; } was collected before with the same name and label values\n*
collected metric &amp;ldquo;consoler_gdas_node_drive_status&amp;rdquo; { label:&amp;lt;name:&amp;ldquo;drive_serial&amp;rdquo; value:&amp;ldquo;Mcc01327 B&amp;rdquo; &amp;gt; label:&amp;lt;name:&amp;ldquo;ip&amp;rdquo; value:&amp;ldquo;192.168.10.139&amp;rdquo; &amp;gt; label:&amp;lt;name:&amp;ldquo;name&amp;rdquo; value:&amp;ldquo;DA-BH7&amp;rdquo; &amp;gt; gauge:&amp;lt;value:0 &amp;gt; } was collected before with the same name and label values\n*</description></item><item><title>Failed to get system container stats、failed to get cgroup stats</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/Failed-to-get-system-container-statsfailed-to-get-cgroup-stats/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/Failed-to-get-system-container-statsfailed-to-get-cgroup-stats/</guid><description>Failed to get system container stats for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: failed to get cgroup stats for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: failed to get cgroup stats for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: failed to get container info for &amp;ldquo;/system.slice/docker.service&amp;rdquo;: unknown container &amp;ldquo;/system.slice/docker.service&amp;rdquo;
参考：Stackoverflow
这个问题大概就是因为 kubelet 在 docker 之前就启动了。</description></item><item><title>FIFO与FILO</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/FIFO%E4%B8%8EFILO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/FIFO%E4%B8%8EFILO/</guid><description>概述 参考：
Wiki, FIFO(先进先出) Wiki, Heap(堆) Wiki, LIFO(后进先出) 与 Wiki,Stack(栈) 两个概念被 Wiki 合并了 知乎，https://www.zhihu.com/question/438782731 first in,first out(先进先出，简称 FIFO) 与 last in,firtst out(后进先出，简称 LIFO) 在计算机科学中，是两种有组织得操作结构化数据的方法。很多时候，FIFO 也称为 Stack(栈)，LIFO 也称为 Queue(队列)。
注意：也可以说是是两种抽象的数据类型。但是这里的抽象数据类型，并不是指编程语言中的抽象数据类型。而是一种设计理念、设计思路。
FIFO
考虑火车票购票系统，我们假设系统同时只能处理 40 个买票请求。那么当系统在处理 40 个请求时，来了第 41 个请求，系统就需要把这个请求缓存起来。同样，在这一过程中如果来了第 42、第 43、……第 1000 个请求，系统也需要把这些请求缓存起来。 当系统处理完毕一个请求后，有 39 个请求尚在处理，系统能够处理一个新的请求。于是系统就需要从自己的缓存里挑一个请求来处理。而此时缓存里有第 41 至第 1000 个请求，系统应该挑选哪一个请求来处理呢？按照先到先得的朴素排队的想法，系统理应挑选并处理第 41 个请求。 在这种情况下，如果将系统的缓存设计为 FIFO，就能够很方便地实现上述调度策略。 LIFO
就好像你拿了十页论文，看完一页放桌子上一页，最后一页自然的就在最上面，也就是说你从桌子上拿到的第一张就是最后放在桌子上的一页。 也可以用叠牌子类比，把盘子叠一摞，那么当需要拿盘子的时候，最后叠上去的盘子是被先拿到的。</description></item><item><title>Files 类模块</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/Files-%E5%A4%84%E7%90%86%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Ansible/Ansible-Modules/ansible.builtin%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/Files-%E5%A4%84%E7%90%86%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
官方文档 2.9，用户指南 - 使用模块 - 模块索引 - 文件模块 Files 类别模块用来处理文件、文本
acl – Set and retrieve file ACL information archive – Creates a compressed archive of one or more files or trees assemble – Assemble configuration files from fragments blockinfile # 添加、更新、删除指定的多行文本。Insert/update/remove a text block surrounded by marker lines copy # 用于将文件从本地或远程设备上复制到远程设备上的某个位置。Copy files to remote locations fetch – Fetch files from remote nodes file # 管理文件和文件熟悉，用于创建文件、目录等。Manage files and file properties find – Return a list of files based on specific criteria ini_file – Tweak settings in INI files iso_extract – Extract files from an ISO image lineinfile # 与 sed 命令类似，修改指定文件中匹配到的行或添加行。Manage lines in text files patch – Apply patch files using the GNU patch tool read_csv – Read a CSV file replace – Replace all instances of a particular string in a file using a back-referenced regular expression stat # 获取文件或文件系统状态 Retrieve file or file system status synchronize – A wrapper around rsync to make common tasks in your playbooks quick and easy tempfile – Creates temporary files and directories template # 根据文件模板，在远程主机上生成新文件。Template a file out to a remote server unarchive # 解压缩一个归档文件。就是 tar 命。Unpacks an archive after (optionally) copying it from the local machine xattr – Manage user defined extended attributes xml – Manage bits and pieces of XML files or strings blockinfile - 添加、更新、删除指定的多行文本 官方文档：https://docs.</description></item><item><title>fio 参数详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/fio-%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</guid><description>fio Job file 参数详解 官方文档：https://fio.readthedocs.io/en/latest/fio_doc.html#job-file-parameters
参数类型： Job file 的参数有多种类型，每种类型的参数的值可用的类型各不相同，比如时间类型的参数的值就需要填写时间相关的值。
str # 字符串类型。值为字符数字字符序列
time # 时间类型。值为带时间后缀的整数。时间的默认单位是秒(seconds)。可以指定其他单位： 天(d)、小时(h)、分钟(m)、毫秒(ms 或 msec)、微秒(us 或 usec)。e.g.使用 10m 表示 10 分钟。
int # 整数类型。整数值，可以包含整数前缀和整数后缀：
bool # 布尔类型。通常解析为整数，但是仅定义为 true 和 false（1 和 0）
irange # 范围类型。带后缀的整数范围。允许给出值范围，例如 1024-4096。冒号也可以用作分隔符，例如。 1k：4k。如果该选项允许两组范围，则可以使用“，”或“ /”定界符来指定它们：1k-4k / 8k-32k。另请参见 int.
float_list # 浮点列表类型。浮点数列表，以&amp;rsquo;：&amp;lsquo;字符分隔。
描述 JOB 的相关参数 name=STR # 这可以用来覆盖由 fio 为该作业打印的名称。否则，使用作业名称。在命令行上，此参数的特殊目的还用于发信号通知新作业的开始。
时间相关参数 官方文档：https://fio.readthedocs.io/en/latest/fio_doc.html#time-related-parameters
runtime=TIME # 指定 Job 运行的时间(默认单位：秒)。到时间后，不管指定的 size 大小有没有读写完。
time_based # 如果设置，则 fio 将在 runtime 的值这个时间内内运行，即使已完全读取或写入文件。它会在运行时允许的情况下简单地循环相同的工作负载。</description></item><item><title>firewalld 命令行工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/firewalld/firewalld-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/firewalld/firewalld-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>firewall-cmd 参考：
Manual, firewall-cmd 所有命令都是对当前默认 ZONE(通过 firewall-cmd &amp;ndash;get-default-zone 命令获得当前默认 zone)进行操作，如果想要对指定 ZONE 操作，需要使用 &amp;ndash;zone=XXX
OPTIONS 状态选项 &amp;ndash;reload # 重新加载防火墙规则并保留连接状态信息。注意：reload 会删除所有 runtime 模式的配置并应用 permanent 模式的配置。但是已经建立的连接不受影响(e.g.已经在对本机长 ping 的设备不会断开连接) &amp;ndash;complete-reload # 重新加载防火墙规则并丢弃连接状态信息。注意：与 reload 不同，已经建立的连接会被丢弃(e.g.已经在对本机长 ping 的设备会断开连接) Log Denied Options Permanent Options &amp;ndash;permanent # 开启永久模式，在该模式的配置都会永久保留 Zone Options 查询 &amp;ndash;get-default-zone # 打印出当前默认的 ZONE &amp;ndash;list-all # 列出所有已添加或已启用的内容 &amp;ndash;list-services # 列出一个 ZONE 中已经添加了的 service &amp;ndash;list-interfaces # 列出一个 ZONE 中已经绑定的网络设备 &amp;ndash;list-rich-rules # 列出一个 ZONE 中已经添加的丰富语言规则 TODO
&amp;ndash;add-source= # 绑定 SOURCE 到一个 ZONE。SOURCE 可以使 MASK、MAC、ipset EXAMPLE firewall-cmd &amp;ndash;zone=drop &amp;ndash;change-interface=eth1 # 将经由 eth1 网卡的所有流量放在 drop 区域中进行处理 firewall-cmd &amp;ndash;zone=public &amp;ndash;add-service=cockpit &amp;ndash;permanent # 在永久模式下，允许 cockpit 服务的流量通过 public 这个 ZONE 内的网络设备 增 firewall-cmd &amp;ndash;add-source=10.</description></item><item><title>Flame Graphs(火焰图)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Flame-Graphs%E7%81%AB%E7%84%B0%E5%9B%BE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Flame-Graphs%E7%81%AB%E7%84%B0%E5%9B%BE/</guid><description>概述 参考：
GitHub 项目，brendangregg/FlameGraph 官方文档 论文 https://www.ruanyifeng.com/blog/2017/09/flame-graph.html
https://zhuanlan.zhihu.com/p/73385693
可以生成火焰图的工具：
perf 性能分析工具 前言 在没有读《性能之巅》这本书之前，就听说过火焰图。当时学习同事用 go 写的项目代码，发现里边有个文件夹叫火焰图，觉得名字很好玩，就百度了一下，惊叹还有这种操作。不过当时并没有听过 Brendan Gregg 的大名，因为懒也没有深入学习。这次找到了 Brendan Gregg 的 blog，也了解了一点动态追踪技术的知识，决心要好好学习一下。
于是就找到了一切开始的地方： Brendan Gregg 写的论文《The Flame Graph 》
作为一个英语菜鸡，从来都没有读过英文论文。正好借这次机会尝试一下，看能不能点个新的技能点。结果尝试才发现，真的好难～～刚开始，读一小段就开始犯困。于是坚持每天强迫自己从头开始重读一遍。花了差不多一周时间，总算能集中注意力的读完。
然后我就想，老是吐槽各种汉化的国外优秀的技术书籍生涩难懂，何不亲自试一试呢？于是就有了今天的这篇学习笔记。
火焰图 让软件执行情况可视化，是性能分析、调试的利器 Brendan Gregg, Netflix
日常工作中，我们需要理解软件对系统资源的使用情况。比如对于 cpu，我们想知道当前软件究竟使用了多少 cpu？软件更新以后又变化了多少？剖析器(profilers)可以用来分析这样的问题，帮助软件开发者优化代码，指导软件使用者调优运行环境。但是 profile 通常都很长，太长的输出分析和理解起来都很不方便。火焰图作为一种新的 profile 可视化方式，可以让我们更直观，更方便的理解、分析问题。
在像“Netflix 云微服务架构”这种软件升级迭代迅速的环境中，快速理解 profiles 尤为重要。同时，对 profile 的快速的理解也有助于我们更好的研究其他人编写的软件。
火焰图可以用多种 profilers（包括资源和系统事件）的输出生成，本文以 cpu 为例，介绍了火焰图的用法以及其可以解决的各种实际问题。
profile 的理解 profile 有 剖面、剖面图 的含义，对于医学角度来说，如果不解剖看剖面图，也就无法看到一个生物内部的运行情况。同理，在性能分析领域，想要理解一个程序，也需要解剖它，看看它的剖面图。所以，profile 就可以理解为一个应用程序的 剖面图。只有看到剖面图，才能深入程序内部一探究竟
CPU Profiling CPU 分析的一种常用技术是，使用像 Linux perf_events 和 DTrace 之类系统追踪工具的对 stack traces 进行采样。stack trace 显示了代码的调用关系，比如下面的 stack trace ,每个方法作为一行并按照父子关系从下到上排序。</description></item><item><title>Flannel</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Flannel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Flannel/</guid><description>概述 参考：
GitHub 项目，flannel-io/flannel Flannel 是一种专为 Kubernetes 设计的，简单、易于配置的 3 层网络结构，并且为 Kubernetes 提供了 CNI 插件。
支持多种后端：即使用什么方法进行进行数据的接收与发送
vxlan host-gw：host gateway UDP Flannel 在每台主机上运行一个名为 flanneld 的小型二进制程序作为代理，负责从更大的预配置地址空间中为每个主机分配 subnet lease(子网租期)。Flannel 直接使用 Kubernetes API 或 etcd 来存储网络配置、已分配的子网、以及任何辅助数据(比如主机的 IP)
子网获取逻辑 代码：./main.go —— WriteSubnetFile()
Flannel 启动时，在 ./main.go 中调用 WriteSubnetFile() 函数，用来生成 subnet 配置文件(默认在 /run/flannel/subnet.env)。
func main() { ...... if err := WriteSubnetFile(opts.subnetFile, config, opts.ipMasq, bn); err != nil { // Continue, even though it failed. log.Warningf(&amp;#34;Failed to write subnet file: %s&amp;#34;, err) } else { log.</description></item><item><title>Garbage Collection(垃圾回收)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/Garbage-Collection%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/Garbage-Collection%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</guid><description>kubelet Garbage Collection 介绍 参考：
官方文档：https://kubernetes.io/docs/concepts/cluster-administration/kubelet-garbage-collection/ 垃圾回收是 kubelet 的一个有用功能，它将清理未使用的镜像和容器。 Kubelet 将每分钟对容器执行一次垃圾回收，每五分钟对镜像执行一次垃圾回收。
注意！！不建议使用外部垃圾收集工具，因为这些工具可能会删除原本期望存在的容器进而破坏 kubelet 的行为。
比如： 使用 docker container prune -f 命令，清理了节点上不再使用的容器，这时候，在 /var/log/pods/ContainerNAME/* 目录下的日志软链接是不会清除的，因为这个软连接由 kubelet 管理，并且只有在日志关联的容器被 kubelet 清理时，才会清理该软链接。所以容器没了，软连接 kubelet 也就不管了~
解决办法： find -L /var/log/pods -type l -delete 直接直接该命令即可
代码路径：./pkg/kubelet/kuberuntime/kuberuntime_gc
镜像回收 Kubernetes 借助于 cadvisor 通过 imageManager 来管理所有镜像的生命周期。
镜像垃圾回收策略只考虑两个因素：HighThresholdPercent 和 LowThresholdPercent。 磁盘使用率超过上限阈值（HighThresholdPercent）将触发垃圾回收。 垃圾回收将删除最近最少使用的镜像，直到磁盘使用率满足下限阈值（LowThresholdPercent）。
容器回收 容器垃圾回收策略考虑三个用户定义变量。 MinAge 是容器可以被执行垃圾回收的最小生命周期。 MaxPerPodContainer 是每个 pod 内允许存在的死亡容器的最大数量。 MaxContainers 是全部死亡容器的最大数量。 可以分别独立地通过将 MinAge 设置为 0，以及将 MaxPerPodContainer 和 MaxContainers 设置为小于 0 来禁用这些变量。</description></item><item><title>Gateway API</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Gateway-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Gateway-API/</guid><description>概述 参考：
GitHub 项目，kubernetes-sigs/gateway-api 云原生资料库-Kubernetes 基础教程，服务发现与路由-GatewayAPI 公众号-MoeLove，Gateway API： 在Kubernetes网络中掀起一场革命</description></item><item><title>geo/geoip 模块指令</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/geo_geoip-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/geo_geoip-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
http 模块下的 geo 模块、geoip 模块 stream 模块下的 geo 模块、geoip 模块 geo 与 geoip 模块实现了 GeoIP 的能力，可以根据 客户端的 IP 地址 来创建新的变量。这些变量用来表示 IP 地址所属国际、所属城市、所在经/纬度 等等。
不同之处在于：
geo 手动设置变量及其值 geoip 根据 MaxMind 数据库中的信息，创建一系列的变量 通过 geo/geoip 模块，我们可以根据客户端的 IP 地址，获取这些 IP 的一些信息，比如 IP 所属城市、所属国家，所在经/纬度 等等。我们常常可以根据这些分类的信息，进行 IP 过滤、或日志记录。说白了，geo/geoip 模块就是为每个 IP 地址添加一系列的 Label(标签)，以便后续可以根据这些 标签 进行 记录 和 筛选。
v2ray 中的测试，有很多 geosite 相关的设置，就是这个道理，每个 IP 地址都可以具有很多标签、甚至连这个 IP 所属的公司都会记录，以便可以根据这些进行来决定一个请求是 直连 还是 代理。
http 模块下的 geo 模块指令 geo [ADDRESS] $VARIABLE {} # 根据 ADDRESS 定义新的变量</description></item><item><title>geoip2 模块</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/geoip2-%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/geoip2-%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
GitHub 项目，leev/ngx_http_geoip2_module 从这个页面可以下载 GeoIP2 和 旧版的 GeoIP 数据库
geoip2 模块与 geo/geoip 模块的功能类似。geoip2 模块根据 客户端的 IP 信息，使用 MaxMind 的 geoip2 数据库中的值创建变量。只不过指令用法稍有不同。
用法示例 首先通过 mmdblookup 工具查看数据库中的内容 ~]# mmdblookup --file ./GeoLite2-City.mmdb --ip 59.46.138.226 { &amp;#34;city&amp;#34;: { &amp;#34;geoname_id&amp;#34;: 1814087 &amp;lt;uint32&amp;gt; &amp;#34;names&amp;#34;: { &amp;#34;en&amp;#34;: &amp;#34;Dalian&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;ja&amp;#34;: &amp;#34;大連市&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;ru&amp;#34;: &amp;#34;Далянь&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;zh-CN&amp;#34;: &amp;#34;大连&amp;#34; &amp;lt;utf8_string&amp;gt; } } &amp;#34;continent&amp;#34;: { &amp;#34;code&amp;#34;: &amp;#34;AS&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;geoname_id&amp;#34;: 6255147 &amp;lt;uint32&amp;gt; &amp;#34;names&amp;#34;: { &amp;#34;de&amp;#34;: &amp;#34;Asien&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;en&amp;#34;: &amp;#34;Asia&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;es&amp;#34;: &amp;#34;Asia&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;fr&amp;#34;: &amp;#34;Asie&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;ja&amp;#34;: &amp;#34;アジア&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;pt-BR&amp;#34;: &amp;#34;Ásia&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;ru&amp;#34;: &amp;#34;Азия&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;zh-CN&amp;#34;: &amp;#34;亚洲&amp;#34; &amp;lt;utf8_string&amp;gt; } } &amp;#34;country&amp;#34;: { &amp;#34;geoname_id&amp;#34;: 1814991 &amp;lt;uint32&amp;gt; &amp;#34;iso_code&amp;#34;: &amp;#34;CN&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;names&amp;#34;: { &amp;#34;de&amp;#34;: &amp;#34;China&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;en&amp;#34;: &amp;#34;China&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;es&amp;#34;: &amp;#34;China&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;fr&amp;#34;: &amp;#34;Chine&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;ja&amp;#34;: &amp;#34;中国&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;pt-BR&amp;#34;: &amp;#34;China&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;ru&amp;#34;: &amp;#34;Китай&amp;#34; &amp;lt;utf8_string&amp;gt; &amp;#34;zh-CN&amp;#34;: &amp;#34;中国&amp;#34; &amp;lt;utf8_string&amp;gt; } } &amp;#34;location&amp;#34;: { &amp;#34;accuracy_radius&amp;#34;: 1000 &amp;lt;uint16&amp;gt; &amp;#34;latitude&amp;#34;: 38.</description></item><item><title>get 子命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/get-%E5%AD%90%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/get-%E5%AD%90%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
5 个冷门但非常实用的 Kubectl 使用技巧 展示对象的信息，get 获得的是该对象的个性信息，describe 获得的是该对象的集群信息
Syntax(语法) kubectl get (TYPE[.VERSION][.GROUP] [NAME | -l label] | TYPE[.VERSION][.GROUP]/NAME &amp;hellip;) [FLAGS]
FLAGS Note：在 kubectl 命令中的 全局 flags 中还有很多有用的 flags 可以用于 get 子命令。比如 -v 指定 debug 等级，-n 指定要操作的 namespace，等等
-A, &amp;ndash;all-namespaces # 列出在所有名称空间中的对象。 &amp;ndash;allow-missing-template-keys=true: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats. &amp;ndash;field-selector=STRING # 使用字段选择器根据一个或多个资源字段的值筛选 Kubernetes 对象。支持 =, ==, and !</description></item><item><title>Gin</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Gin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Gin/</guid><description>概述 参考：
GitHub 项目，gin-gonic/gin https://youngxhui.top/categories/gin/</description></item><item><title>Git常见问题</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/Git/Git-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid><description>warning LF will be replaced by CRLF 发现问题 windows 平台下使用 git add，git deploy 文件时经常出现“warning: LF will be replaced by CRLF” 的提示。
网上很多解决办法提到：
设置 core.autocrlf=false，windows 也用 LF 换行。
除了记事本，其他编辑器都可以正常编辑。
而没有给出具体原因和分析，现在加以补充。
分析问题 格式化与多余的空白字符，特别是在跨平台情况下，有时候是一个令人发指的问题。由于编辑器的不同或者文件行尾的换行符在 Windows 下被替换了，一些细微的空格变化会不经意地混入提交，造成麻烦。虽然这是小问题，但它会极大地扰乱跨平台协作。
其实，这是因为在文本处理中，CR（CarriageReturn），LF（LineFeed），CR/LF 是不同操作系统上使用的换行符，具体如下：
换行符‘\n’和回车符‘\r’
回车符就是回到一行的开头，用符号 r 表示，十进制 ASCII 代码是 13，十六进制代码为 0x0D，回车（return）；
换行符就是另起一行，用 n 符号表示，ASCII 代码是 10，十六制为 0x0A， 换行（newline）。
所以我们平时编写文件的回车符应该确切来说叫做回车换行符。
应用情况 Dos 和 Windows 平台： 使用回车（CR）和换行（LF）两个字符来结束一行，回车+换行(CR+LF)，即“\r\n”；
Mac 和 Linux 平台：只使用换行（LF）一个字符来结束一行，即“\n”；
最早 Mac 每行结尾是回车 CR 即&amp;rsquo;\r&amp;rsquo;，后 mac os x 也投奔了 unix。</description></item><item><title>Glossary</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Glossary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Glossary/</guid><description>部署环境 Proof of Concept(概念验证，简称 poc) Development(开发，简称 dev) Test(测试，简称 test) (灰度，简称 pre) Production(生产，简称 pro) 服务器命名规范 参考：
https://codeantenna.com/a/VDpjUR86Hx RFC-1178，为你的计算机选择一个名字 推荐小规模集群 hostname 命名规范 规则: UN/LOCODE 码-机房标记(可选)-随机字符-系统和版本(可选)-云服务商缩写(可选)-环境(可选)-域名(可选)
简洁示例: suz-ba91 lxa-4f97
完整示例: gzu-spe-a904-rhel7-ecs-ctyun.prd.21cn.com can-4th-b69d-win2012-bms-ctyun.tst.21cn.com
过程:
查询 UN/LOCODE 城市代码, https://service.unece.org/trade/locode/cn.htm ; 查询操作系统发行版本, 执行命令: hostnamectl ; 截取 uuid.online 生成的 ID 4 位字符, http://www.uuid.online/ ; 根据上述规则和数据, 组成 hostname 名称 ; 执行命令: hostnamectl set-hostname . 说明: bms 代表物理机，ecs 代表虚拟机；系统和版本参见附录 3；环境缩写参见附录 4.
hostname 命名规则总结 公有云服务器 规则: 云服务商缩写-IATA 城市代码-系统和版本-随机字符-域名 示例: aws-tko-ctos7-44rr4.colinleefish.com 标准化别名结构(Standardized CNAME Structure) 规则: OrenTirosh 记忆编码项目特定选择的 1633 个词之一(只有 4-7 个字母), 示例：crimson melody verona banjo DNS A Records 和 CNAME Records 示例： melody.</description></item><item><title>GlusterFS 的部署与使用</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/GlusterFS/GlusterFS-%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/GlusterFS/GlusterFS-%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>GlusterFS 的部署与使用 初始化 yum 源配置
yum install centos-release-gluster6 -y
分区、格式化、挂载使用 bricks 的磁盘
Assuming you have a brick at /dev/sdb:
fdisk /dev/sdb
Create a single partition on the brick that uses the whole capacity.
格式化分区
mkfs.xfs -i size=512 /dev/sdb
将分区挂载为 gluster 的 brick
mkdir -p /data/brick1 &amp;amp;&amp;amp; mount /dev/sdb /data/brick1 &amp;amp;&amp;amp; mkdir -p /data/brick1brick
在/etc/fstab 文件中添加条目使得目录自动挂载
echo &amp;ldquo;/dev/sdb /data/brick1 xfs defaults 0 0&amp;rdquo; &amp;raquo; /etc/fstab
在所有节点安装 glusterfs 所用的包
yum install glusterfs{,-server,-fuse,-geo-replication,-client} -y</description></item><item><title>Go Client</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/Go-Client/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/Go-Client/</guid><description>概述 参考：
GitHub 项目，kubernetes/client-go Danielhu 博客 公众号-KubeSphere 云原生，Client-go 源码分析之 SharedInformer Go Client 就是 Kubernetes 针对 Go 编程语言 而言的 Client Library。Go Client 项目名称为 client-go，是用来与 Kubernetes 对话的 Go 编程语言 的第三方库。
安装 client-go 版本控制策略：k8s 版本 1.18.8 对应 client-go 版本 0.18.8，其他版本以此类推。
使用前注意事项： 使用 client-go 之前，需要手动获取对应版本的的 client-go 库。
如果使用的 Kubernetes 版本&amp;gt; = v1.17.0，请使用相应的 v0.x.y标签。例如，k8s.io/client-go@v0.17.0对应于 Kubernetes v1.17.0
根据版本控制策略，使用如下命令进行初始化:
# 初始化项目 go mod init github.com/DesistDaydream/kubernetes-development # 为 go.mod 文件添加 require k8s.io/client-go v0.19.2 // indirect 信息 go get k8s.</description></item><item><title>Go OpenAPI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E6%89%A9%E5%B1%95/Go-OpenAPI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E6%89%A9%E5%B1%95/Go-OpenAPI/</guid><description>自动为 Go 代码生成 OpenAPI 格式文档 可选项目：go-swagger、swaggo
go-swagger 参考:
腾讯云社区 CSDN go 语言中文网</description></item><item><title>Go 常见问题</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid><description>goroutines 与 os.Chdir 参考：
GitHub 项目,golang/go-issue-27658 简而言之，错误报告是，如果两种不同的 Goroutines 同时调用 OS.Chdir，则这将生效是不可预测的。
那是真实的。 OS.Chdir 是一个流程范围的属性，而不是每个 goroutine 或 per-thread 属性。即使我们能够弄清楚改变的方式 - 没有什么意思 - 没有什么想到的 - 我们现在无法改变它，因为它会破坏一个大峡谷中调用 OS.Chdir 的现有 Go 程序，并期望它会影响另一个大花序。 Closing as unfortunate. 关闭不幸。</description></item><item><title>Go 第三方库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</guid><description>概述 参考：
第三方库一般属于由个人开发，实现更多丰富功能的库。在 Go.dev 可以搜索自己想要使用的所有库。
日志 logrus 参考：
GitHub 项目，sirupsen/logrus https://pkg.go.dev/github.com/sirupsen/logrus Logrus 是一种结构化得用于 Go 语言的日志处理器，完全与 Go 标准库中的 log 库。这名字来源于吉祥物 Walrus(海象)，所以在官方文档中，所有示例都与 Walrus 相关。
package main import ( &amp;#34;github.com/sirupsen/logrus&amp;#34; ) func main() { // Logrus 共有七个日志级别，由高到底分别为：Trace、Debug、Info、Warning、Error、Fatal、Panic // 默认情况下，只有 Info 及以下级别可以正常输出。如果想要输出高级别日志，通过 SetLevel() 函数设置日志级别即可 // SetLevel() 函数的实参可以通过 ParseLevel() 函数将字符串解析为对应级别 // logrus.SetLevel(logrus.InfoLevel) // 输出 Info 级别的日志内容 logrus.Info(&amp;#34;Hello World&amp;#34;) } // 输出内容如下： // time=&amp;#34;2021-09-20T11:58:36+08:00&amp;#34; level=info msg=&amp;#34;Hello World&amp;#34; 文件处理 Excel 文件处理 Excelize 参考：
GitHub 项目，xuri/excelize 官方文档 网络相关 https://pkg.</description></item><item><title>Go 接口设计原则</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/Go-%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/Go-%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</guid><description>Go 接口设计原则 参考：原文链接
1.1 平铺式的模块设计 那么作为interface数据类型，他存在的意义在哪呢？ 实际上是为了满足一些面向对象的编程思想。我们知道，软件设计的最高目标就是高内聚，低耦合。那么其中有一个设计原则叫开闭原则。什么是开闭原则呢，接下来我们看一个例子：
package main import &amp;#34;fmt&amp;#34; // 我们要写一个结构体,Banker 银行业务员 type Banker struct { } // 存款业务 func (this *Banker) Save() { fmt.Println( &amp;#34;进行了 存款业务...&amp;#34;) } // 转账业务 func (this *Banker) Transfer() { fmt.Println( &amp;#34;进行了 转账业务...&amp;#34;) } // 支付业务 func (this *Banker) Pay() { fmt.Println( &amp;#34;进行了 支付业务...&amp;#34;) } func main() { banker := &amp;amp;Banker{} banker.Save() banker.Transfer() banker.Pay() } 代码很简单，就是一个银行业务员，他可能拥有很多的业务，比如Save()存款、Transfer()转账、Pay()支付等。那么如果这个业务员模块只有这几个方法还好，但是随着我们的程序写的越来越复杂，银行业务员可能就要增加方法，会导致业务员模块越来越臃肿。
这样的设计会导致，当我们去给 Banker 添加新的业务的时候，会直接修改原有的 Banker 代码，那么 Banker 模块的功能会越来越多，出现问题的几率也就越来越大，假如此时 Banker 已经有 99 个业务了，现在我们要添加第 100 个业务，可能由于一次的不小心，导致之前 99 个业务也一起崩溃，因为所有的业务都在一个 Banker 类里，他们的耦合度太高，Banker 的职责也不够单一，代码的维护成本随着业务的复杂正比成倍增大。</description></item><item><title>Go 网络编程</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</guid><description>概述 参考：
Go 标准库 ，net 公众号，开发内功修炼-在 golang 中是如何对 epoll 进行封装的？(关于 go 实现 net 的底层逻辑分析) Go 标准库，net/url(URL 解析与转译) 公众号-马哥 Linux 运维，go 标准库 net/url 学习笔记 在协程没有流行以前，传统的网络编程中，同步阻塞是性能低下的代名词，一次切换就得是 3 us 左右的 CPU 开销。各种基于 epoll 的异步非阻塞的模型虽然提高了性能，但是基于回调函数的编程方式却非常不符合人的的直线思维模式。开发出来的代码的也不那么容易被人理解。
Golang 的出现，可以说是将协程编程模式推向了一个高潮。这种新的编程方式既兼顾了同步编程方式的简单易用，也在底层通过协程和 epoll 的配合避免了线程切换的性能高损耗。换句话说就是既简单易用，性能又还不挺错。
net 包 net 包中包含如下几个包
http # http 包提供 HTTP 客户端和服务端的实现。 mail # Package mail implements parsing of mail messages. netip # Package netip defines an IP address type that&amp;rsquo;s a small value type. rpc # Package rpc provides access to the exported methods of an object across a network or other I/O connection.</description></item><item><title>Go 在容器运行时要注意的细节</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/Go-%E5%9C%A8%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%BB%86%E8%8A%82/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/Go-%E5%9C%A8%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%BB%86%E8%8A%82/</guid><description>在云原生时代，Go语言由于在部署时只需要一个二进制文件就能够运行起来而备受青睐。
但有一个细节问题，如果不妥善处理，则很可能导致Go程序出现明显的性能下降和延迟。
1 问题描述
在Go语言中，Go scheduler的P数量非常重要，因为它会极大地影响Go在运行时的表现。在目前的Go语言中，P的数量默认是系统的CPU核数。
在容器化的环境中，Go程序所获取的CPU核数是错误的，它所获取的是宿主机的CPU核数。
即使容器和宿主机的CPU核数是共享的，但在集群中我们会针对每个Pod分配指定的核数，因此实际上我们需要的是Pod的核数，而不是宿主机的CPU核数。
2 会造成什么后果
前文曾提到Go的M: N调度模型，其要求M必须与P进行绑定，然后才能不断地在M上循环寻找可运行的G来执行相应的任务。
注意，M必须与P进行绑定，其绑定的这个P，要求必须是空闲状态。但在容器化的部署环境中，P的数量由于被“错误”设置，因此拥有大量空闲的P。可以这样理解，只要有足够多的M，那么P就可以都被绑定。
这时又产生了另外一个问题，M的数量是否会不断增加呢？答案是会的。在程序运行过程中，由于产生了网络I/O阻塞，导致M会随着程序的不断执行而不断增加，，即能够达到前面假设的情况。最终导致Go程序的延迟加大，程序响应缓慢。
3 解决方法
产生这个问题的本质原因是Go程序没有正确地获得我们所期望的CPU核数（应当获取具体分配给Pod的配额），因此解决方案有两种：
结合部署情况，主动设置正确的GOMAXPROCS核数。 通过cgroup信息，读取容器内的正确GOMAXPROCS核数。 目前，Go尚没有非常完美的办法来解决这个问题，因此这里推荐使用Uber公司推出的 uber-go/automaxprocs开源库，它会在Go程序运行时根据cgroup的挂载信息来修改 GOMAXPROCS核数，并基于一定规则选择一个最合适的数值。
使用方式如下：
import _ &amp;quot;go.uber.org/automaxprocs&amp;quot; func main() {...} 我们只需在Go程序启动时进行引用即可，如果有特殊的需求，那么主动设置GOMAXPROCS也是可以的。</description></item><item><title>GO中间件(Middleware )</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Middleware/GO%E4%B8%AD%E9%97%B4%E4%BB%B6Middleware/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Middleware/GO%E4%B8%AD%E9%97%B4%E4%BB%B6Middleware/</guid><description>原文链接：GO 中间件 (Middleware) - SegmentFault 思否
中间件是一种计算机软件，可为操作系统提供的软件应用程序提供服务，以便于各个软件之间的沟通，特别是系统软件和应用软件。广泛用于 web 应用和面向服务的体系结构等。
纵观 GO 语言，中间件应用比较普遍，主要应用：
记录对服务器发送的请求（request） 处理服务器响应（response ） 请求和处理之间做一个权限认证工作 远程调用 安全 等等 中间件处理程序是简单的http.Handler，它包装另一个http.Handler做请求的一些预处理和 / 或后处理。它被称为 “中间件”，因为它位于 Go Web 服务器和实际处理程序之间的中间位置。
下面是一些中间件例子
记录日志中间件 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; ) func logging(f http.HandlerFunc) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { log.Println(r.URL.Path) f(w, r) } } func foo(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, &amp;#34;foo&amp;#34;) } func bar(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, &amp;#34;bar&amp;#34;) } func main() { http.</description></item><item><title>Grafana数据模型</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Grafana-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>概述 参考：
官方文档，开发者-构建插件-数据框架 Data Frames(数据框架) Grafana 支持各种不同的数据源，每个数据源都有自己的数据模型。为了实现这一点，Grafana 将来自每个数据源的查询结果合并为一个统一的数据结构，称为 Data Frames(数据框架)。 数据框架结构是从 R 编程语言和 Pandas 等数据分析工具中借用的概念。
数据帧在 Grafana 7.0+中可用，并且用更通用的数据结构代替了时间序列和表结构，该数据结构可以支持更大范围的数据类型。
本文档概述了数据框架结构以及如何在 Grafana 中处理数据。
数据框 数据框是面向列的表结构，这意味着它按列而不是按行存储数据。要了解这意味着什么，让我们看一下 Grafana 使用的 TypeScript 定义：
interface DataFrame { name?: string; // reference to query that create the frame refId?: string; fields: []Field; } 本质上，数据框是 Fields(字段)_ _的集合，其中每个字段对应于一列。每个字段又由值的集合以及元信息（例如这些值的数据类型）组成。
interface Field { name: string; // Prometheus like Labels / Tags labels?: Record&amp;lt;string, string&amp;gt;; // For example string, number, time (or more specific primitives in the backend) type: FieldType; // Array of values all of the same type values: Vector&amp;lt;T&amp;gt;; // Optional display data for the field (e.</description></item><item><title>gRPC</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/RPC/gRPC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Process/Inter-Process-Communication/RPC/gRPC/</guid><description>概述 参考：
GitHub 组织，grpc 官网 Google Remote Procedure Calls(谷歌远程过程调用，简称 gRPC) 是一个开源的 RPC 系统，最初于 2015 年在 Google 开发，作为下一代 RPC 基础设施 Stubby。它使用 HTTP/2 进行传输，Protocol Buffers 作为接口描述语言，并提供身份验证、双向流和流量控制、阻塞或非阻塞绑定以及取消和超时等功能。它为多种语言生成跨平台的客户端和服务器绑定。最常见的使用场景包括在微服务风格架构中连接服务，或将移动设备客户端连接到后端服务。
gRPC 对 HTTP/2 的复杂使用使得无法在浏览器中实现 gRPC 客户端，而是需要代理。
其他文章 gRPC 长连接在微服务业务系统中的实践
公众号-Apifox，找不到好用的 gRPC 调试工具？Apifox 表示我可以！</description></item><item><title>GSettings 与 Dconf</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/GSettings-%E4%B8%8E-Dconf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/GSettings-%E4%B8%8E-Dconf/</guid><description>概述 参考：
gsetting 命令行工具 应用示例 关闭 Ubuntu 20.04 的桌面动画效果
gsettings set org.gnome.desktop.interface enable-animations false</description></item><item><title>GUI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/GUI/GUI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/GUI/GUI/</guid><description>概述 参考：
Go OpenCV 参考：
http://www.codebaoku.com/it-go/it-go-146781.html https://github.com/go-opencv/go-opencv https://github.com/hybridgroup/gocv</description></item><item><title>GUI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/GUI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/GUI/</guid><description>概述 PySimpleGUI 参考：
GitHub 项目，PySimpleGUI/PySimpleGUI 官网 PySimpleGUI 是一个 Python 的 GUI 库，旨在将 tkinter、Qt、Temi、WxPython 转换为可移植的对人友好的 Python 式接口。</description></item><item><title>HAProxy</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/HAProxy/HAProxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/HAProxy/HAProxy/</guid><description>HAProxy 可以实现四层以及七层负载均衡
多用于七层负载均衡
http 层代理
tcp 层的负载均衡
目前，有两种主流的代理模式：tcp 代理(即所谓的 4 层代理)和 http 代理(即所谓的 7 层代理)。在 4 层代理模式下，haproxy 简单的在两端进行双向转发。在 7 层代理模式下，haproxy 会对协议进行分析，可以根据协议来允许、阻塞、切换、增加、修改和移除 request 或 response 中的属性内容。
haproxy 工作逻辑 比如 client 为 114.114.114.114，haproyx 为 192.168.1.2，Server 为 192.168.1.3
client 发送数据包给 haproxy 所在服务器 192.168.1.2 192.168.1.2 发现这个数据包是给自己的 haproxy 的，则剥离 IP 与 PORT，并把数据包发送给用户空间的 haproxy haproxy 由于在用户空间，所以收到的数据包已经被内核剥离了 IP 与 PORT，此时 haproxy 会根据自身的配置以及数据包内的相关信息来进行匹配选择一个合适的 Server，然后发送给内核，告诉内核这个数据包要发送给某 Server。这是 haproxy 与 Server 建立的一个新 TCP 连接。 内核根据 Server 这个目的 IP，再封装上 mac 地址从网卡中发送出去。 这时候 Server 就会收到请求，处理完成后把响应报文发送给 haproxy 由于 haproxy 与 Client 和 Server 分别建立的两个 TCP 连接，这会生成两个 Socket，所以发送给 client 的响应数据以及之后的数据交互就直接通过两个相连的 socket 来进行。 socket 介绍详解 TCPIP，UDP，端口 Port，Socket，API.</description></item><item><title>Harbor 云原生注册中心</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Repository%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/Harbor-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Repository%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/Harbor-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/</guid><description>概述 参考：
GitHub 项目，goharbor/harbor 官网 一个开源可信的云原生注册中心项目，用于存储、签名、扫描内容。项目地址：https://github.com/goharbor/harbor
云原生注册表：Harbor 支持容器图像和Helm图表，可作为容器原生运行时和编排平台等云原生环境的注册表。 基于角色的访问控制：用户和存储库通过“项目”进行组织，并且用户可以对项目下的图像或 Helm 图表具有不同的权限。 基于策略的复制：可以基于具有多个过滤器（存储库，标签和标签）的策略在多个注册表实例之间复制（同步）图像和图表。如果遇到任何错误，Harbor 会自动重试复制。非常适合负载平衡，高可用性，多数据中心，混合和多云场景。 漏洞扫描：Harbor 会定期扫描图像并警告用户存在漏洞。 LDAP / AD 支持：Harbor 与现有企业 LDAP / AD 集成以进行用户身份验证和管理，并支持将 LDAP 组导入 Harbor 并为其分配适当的项目角色。 OIDC 支持：Harbor 利用 OpenID Connect（OIDC）来验证由外部授权服务器或身份提供者认证的用户的身份。可以启用单点登录以登录 Harbor 门户。 图像删除和垃 00000000000000000000000000000000000 圾回收：可以删除图像，并可以回收其空间。 公证员：可以确保图像的真实性。 图形用户门户：用户可以轻松浏览，搜索存储库和管理项目。 审核：跟踪对存储库的所有操作。 RESTful API：用于大多数管理操作的 RESTful API，易于与外部系统集成。嵌入式 Swagger UI 可用于探索和测试 API。 易于部署：提供在线和离线安装程序。另外，可以使用 Helm Chart 在 Kubernetes 上部署 Harbor。 Harbor 组件 官方网址：https://github.com/goharbor/harbor/wiki/Architecture-Overview-of-Harbor
如上图所示，Harbor 一般具有三层结构
数据访问层
k-v storage：键值存储。一般由 redis 实现，提供数据缓存功能并支持为作业服务临时保留作业元数据。 所需镜像：redis-photon data storage：支持多个数据持久存储，作为 chart 和 registry 的后端存储 Database：存储 Harbor 的相关元数据，e.</description></item><item><title>Helm Template</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Helm-Template/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Helm-Template/</guid><description>概述 参考：
官方文档，Chart 模板指南 Helm 的 Template(模板) 可以生成 manifests 文件，这些文件是 kuberntes 用于描述资源的 yaml 。
Template 背景 helm 作为 kuberntes 的包管理器，用来在 k8s 集群中安装应用程序。众所周知，对于 k8s 来说，一个应用不应该是一个简单的 pod，应该包含该 pod 的运行方式(比如 deployment)、pod 的配置文件(configmip)、这个程序如何对外提供服务(service、ingress)等等等一系列的信息。这些信息都是通过 yaml 来描述如何工作的。可以想象，如果一个应用程序，其实是一堆 yaml 文件的话，那么 helm 本质上就是管理这些 yaml 文件的。而一个应用程序想要让用户来使用，必然还涉及到自定义的问题。比如应用程序的名字、配置文件中的内容、对外提供服务所要暴露的端口等等信息。
既然有这样的需求，那么为了让一个应用程序可以自定义，template 就应运而生。template 就是可以将这些 yaml 文件中的 value 变成一种变量的形式，然后通过其他方式(helm 命令行 &amp;ndash;set 标志或者 value.yaml 文件等)来对这些变量进行赋值，来实现应用程序自定义的效果。
helm templete 使用 Go 语言的 Template 来实现。而 go template 具有丰富的功能，除了可以普通赋值以外，还可以使用控制结构(比如 if&amp;hellip;else、range 等)来将赋值的过程更具体和多次赋值。
注意： 当我们谈论“ Helm 模板语言”时，就好像它是特定于 Helm 一样，但它实际上是 Go 模板语言，一些额外功能以及各种包装程序的组合，以将某些对象暴露给模板。当您了解模板时，Go 模板上的许多资源可能会有所帮助。</description></item><item><title>helm 查询相关命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/helm-%E6%9F%A5%E8%AF%A2%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/helm-%E6%9F%A5%E8%AF%A2%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/</guid><description>helm get - 获取指定 release 的信息 该命令由多个子命令组成，这些子命令可用于获取有关 release 的扩展信息，包括：
用于生成 release 的值 生成 release 的 manifest 文件 生成 release 的 chart 的注释信息 与 release 相关的 hooks。 helm get [COMMAND]
该命令与 kubectl get XXX XXX -o yaml 效果类似，可用的 COMMAND 为二级标题
all - download all information for a named release hooks - 获取指定 release 的所有 hooks helm get hooks RELEASE_NAME [FLAGS]
manifest - 获取指定 release 的 manifest 文件 helm get manifest RELEASE_NAME [FLAGS]</description></item><item><title>HPA(Horizontal Pod Autoscaler)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/HPAHorizontal-Pod-Autoscaler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/HPAHorizontal-Pod-Autoscaler/</guid><description>概述 参考：
官方文档：https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ https://www.qikqiak.com/post/k8s-hpa-usage/ Pod 水平自动扩缩（Horizontal Pod Autoscaler） 可以基于 CPU 利用率自动扩缩 ReplicationController、Deployment 和 ReplicaSet 中的 Pod 数量。 除了 CPU 利用率，也可以基于其他应程序提供的自定义度量指标 来执行自动扩缩。 Pod 自动扩缩不适用于无法扩缩的对象，比如 DaemonSet。
Pod 水平自动扩缩特性由 Kubernetes API 资源和控制器实现。资源决定了控制器的行为。 控制器会周期性的调整副本控制器或 Deployment 中的副本数量，以使得 Pod 的平均 CPU 利用率与用户所设定的目标值匹配。
我们可以简单的通过 kubectl autoscale 命令来创建一个 HPA 资源对象， HPAController 默认 30s 轮询一次（可通过 kube-controller-manager 的 &amp;ndash;horizontal-pod-autoscaler-sync-period 参数进行设置），查询指定的资源中的 Pod 资源使用率，并且与创建时设定的值和指标做对比，从而实现自动伸缩的功能。
Metrics Server 在 HPA 的第一个版本中，我们需要 Heapster 提供 CPU 和内存指标，在 HPA v2 过后就需要安装 Metrcis Server 了，Metrics Server 可以通过标准的 Kubernetes API 把监控数据暴露出来，有了 Metrics Server 之后，我们就完全可以通过标准的 Kubernetes API 来访问我们想要获取的监控数据了：</description></item><item><title>HTTP Header</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-Header/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-Header/</guid><description>概述 参考：
RFC 2616-Message Headers RFC 7231，第五章-请求头字段 RFC 7231，第七章-响应头字段 MDN，参考-HTTP-HTTP 头 这是一个全部可用的标准 Header 列表 Wiki, List of HTTP header fields 一般情况下，在打开浏览器按的开发者工具（一般为 F12 键）后，查看到的首部大部分都是请求和响应首部,这俩首部的信息通常包含了通用首部中的信息
HTTP 请求和响应报文的 Header(头) 基本都是 Key/Value Pair(键/值对) 格式的 Field(字段)，每个字段都是以冒号分割的 键/值对。此外，除了标准的 Header 字段之外，还可以添加自定义 Header，这就给 HTTP 带来了无限的扩展可能。注意，Key 不区分大小写。
自定义 Header 历来以 X- 开头，但是该约定在 2012 年 6 月被弃用，因为它在非标准字段成为标准字段时会造成不必要的麻烦，详见 RFC 6648。IANA 维护了一个通用的 HTTP Header 列表，其中包括 RFC 中定义的标准头以及不在 RFC 中定义的扩展头；并且在同一个页面还有新的提议增加的 HTTP Header 列表。
HTTP(RFC 2616 版本) 规定了非常多的 Header 字段，可以实现各种各样的功能，但基本上可以分为以下几类
General Header(通用头) # 在请求头和响应头里都可以出现； Request Header(请求头) # 仅能出现在请求头里，进一步说明请求信息或者额外的附加条件； Response Header(响应头) # 仅能出现在响应头里，补充说明响应报文的信息； Entity Header(实体头) # 它实际上属于通用字段，但专门描述 body 的额外信息。 Extension Header(扩展头) # 不在标准规范中，可以通过自定义头实现更多定制化需求的 Header 信息。 对 HTTP 报文的解析和处理其实本质上就是对头字段的处理，HTTP 的连接管理，缓存控制，内容协商等都是通过头字段来处理的，理解了头字段，基本上也就理解了 HTTP，所以理解头字段非常重要。</description></item><item><title>HTTP Status Codes</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-Status-Codes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-Status-Codes/</guid><description>概述 参考：
RFC 7231,第六章-响应状态码 HTTP 的 Status 状态码和 Reason-Phrase 原因短语 常用 200,301,302,304,401,403,404,500,502
HTTP 常见的状态码 五大类 HTTP 状态码 1xx
1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。
2xx
2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。
「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。
「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。
3xx
3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。
「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。
「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。
4xx
4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。</description></item><item><title>HTTP 的实现</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%9A%84%E5%AE%9E%E7%8E%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid><description>HTTP 服务器的程序(想提供 web 服务必须要安装一下程序中的一个)
httpd(apache) nginx lighttpd 应用程序服务器：上面的程序如果不附加插件则只支持静态的网页，装上下面的程序还能解析 PHP 等动态界面 IIS tomcat，jetty，就 boss，resin webshpere,weblogic,oc4j httpd apache(a patchy server)的特性
高度模块化：core+modules DSO：Dynamic Shared Object MPM：Multipath Processing Modules 多路处理模块，不同的工作方式，可以切换，使用不同模块可以满足不同需求 prefork：多进程模型，每个进程响应一个请求 一个主进程：负责生成 n 个子近侧很难过，子进程也成为工作进程，每个子进程处理一个用户请求，即便没有用户请求，也会预先生成多个空闲进程，随时等待请求到达，最大不超过 1024 个 worker：多线程模型 一个主进程：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 多个子进程：每个子进程负责生成多个线程； 每个线程：负责响应用户请求； 并发响应数量：m*n m：子进程数量 n：每个子进程所能创建的最大线程数量； event：事件驱动模型，多进程模型，每个进程响应多个请求（老版本系统不支持，systemd 系统支持） 一个主进程 ：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 子进程：基于事件驱动机制直接响应多个请求； Httpd 配置 程序环境(.init 系统下)
配置文件 /etc/httpd/conf/httpd.conf /etc/httpd/conf.d/*.conf 服务脚本 /etc/rc.d/init.d/httpd 配置文件/etc/sysconfig/httpd 主程序文件 /usr/sbin/httpd /usr/sbin/httpd.event /usr/sbin/httpd.worker 日志文件目录 /var/log/httpd access_log:访问日志 error_log:错误日志 站点文档目录 /var/www/html</description></item><item><title>HTTP 缓存</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%BC%93%E5%AD%98/HTTP-%E7%BC%93%E5%AD%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%BC%93%E5%AD%98/HTTP-%E7%BC%93%E5%AD%98/</guid><description>概述 参考：
公众号-小林 coding，硬核！30 张图解 HTTP 常见的面试题 公众号-小林 coding，告别 HTTP HTTP 缓存有哪些实现方式？ 对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都缓存在本地，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。
所以，避免发送 HTTP 请求的方法就是通过缓存技术，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。
HTTP 缓存有两种实现方式，分别是强制缓存和协商缓存。
什么是强制缓存？ 强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。
如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。
强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：
Cache-Control， 是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control 的优先级高于 Expires 。
Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：
当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 什么是协商缓存？ 当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。</description></item><item><title>HTTP 优化</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%AE%A1%E7%90%86/HTTP-%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%AE%A1%E7%90%86/HTTP-%E4%BC%98%E5%8C%96/</guid><description>概述 参考：原文链接
问你一句：「** 你知道 HTTP/1.1 该如何优化吗？**」
我想你第一时间想到的是，使用 KeepAlive 将 HTTP/1.1 从短连接改成长链接。
这个确实是一个优化的手段，它是从底层的传输层这一方向入手的，通过减少 TCP 连接建立和断开的次数，来减少了网络传输的延迟，从而提高 HTTP/1.1 协议的传输效率。
但其实还可以从其他方向来优化 HTTP/1.1 协议，比如有如下 3 种优化思路：
尽量避免发送 HTTP 请求； 在需要发送 HTTP 请求时，考虑如何减少请求次数； 减少服务器的 HTTP 响应的数据大小； 下面，就针对这三种思路具体看看有哪些优化方法。
1 如何避免发送 HTTP 请求？ 这个思路你看到是不是觉得很奇怪，不发送 HTTP 请求，那还客户端还怎么和服务器交互数据？小林你这不是耍流氓嘛？
冷静冷静，你说的没错，客户端当然要向服务器发送请求的。
但是，对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求 - 响应」的数据都缓存在本地，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。
所以，避免发送 HTTP 请求的方法就是通过缓存技术，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。
那缓存是如何做到的呢？
客户端会把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，两者形成映射关系。
这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本次磁盘的速度肯定比网络请求快得多，如下图：
聪明的你可能想到了，万一缓存的响应不是最新的，而客户端并不知情，那么该怎么办呢？
放心，这个问题 HTTP 设计者早已考虑到。
所以，服务器在发送 HTTP 响应时，会估算一个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，一旦发现缓存的响应是过期的，则就会重新发送网络请求。HTTP 关于缓说明会的头部字段很多，这部分内容留在下次文章，这次暂时不具体说明。</description></item><item><title>HTTP 重试</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/net-%E5%8C%85%E4%B8%AD%E7%9A%84-HTTP/HTTP-%E9%87%8D%E8%AF%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/net-%E5%8C%85%E4%B8%AD%E7%9A%84-HTTP/HTTP-%E9%87%8D%E8%AF%95/</guid><description>概述 参考：
公众号-luozhiyun，在 Go 中如何正确重试请求(原文) https://www.luozhiyun.com/archives/677 我们平时在开发中肯定避不开的一个问题是如何在不可靠的网络服务中实现可靠的网络通信，其中 http 请求重试是经常用的技术。但是 Go 标准库 net/http 实际上是没有重试这个功能的，所以本篇文章主要讲解如何在 Go 中实现请求重试。
概述 一般而言，对于网络通信失败的处理分为以下几步：
感知错误。通过不同的错误码来识别不同的错误，在 HTTP 中 status code 可以用来识别不同类型的错误； 重试决策。这一步主要用来减少不必要的重试，比如 HTTP 的 4xx 的错误，通常 4xx 表示的是客户端的错误，这时候客户端不应该进行重试操作，或者在业务中自定义的一些错误也不应该被重试。根据这些规则的判断可以有效的减少不必要的重试次数，提升响应速度； 重试策略。重试策略就包含了重试间隔时间，重试次数等。如果次数不够，可能并不能有效的覆盖这个短时间故障的时间段，如果重试次数过多，或者重试间隔太小，又可能造成大量的资源(CPU、内存、线程、网络)浪费。这个我们下面再说； 对冲策略。对冲是指在不等待响应的情况主动发送单次调用的多个请求，然后取首个返回的回包。这个概念是 grpc 中的概念，我把它也借用过来； 熔断降级；如果重试之后还是不行，说明这个故障不是短时间的故障，而是长时间的故障。那么可以对服务进行熔断降级，后面的请求不再重试，这段时间做降级处理，减少没必要的请求，等服务端恢复了之后再进行请求，这方面的实现很多 go-zero 、 sentinel 、hystrix-go，也蛮有意思的； 重试策略 重试策略可以分为很多种，一方面要考虑到本次请求时长过长而影响到的业务忍受度，另一方面要考虑到重试会对下游服务产生过多的请求而带来的影响，总之就是一个 trade-off 的问题。
所以对于重试算法，一般是在重试之间加一个 gap 时间，感兴趣的朋友也可以去看看这篇文章。结合我们自己平时的实践加上这篇文章的算法一般可以总结出以下几条规则：
线性间隔（Linear Backoff）：每次重试间隔时间是固定的进行重试，如每 1s 重试一次； 线性间隔+随机时间（Linear Jitter Backoff）：有时候每次重试间隔时间一致可能会导致多个请求在同一时间请求，那么我们可以加入一个随机时间，在线性间隔时间的基础上波动一个百分比的时间； 指数间隔（Exponential Backoff）：每次间隔时间是 2 指数型的递增，如等 3s 9s 27s 后重试； 指数间隔+随机时间（Exponential Jitter Backoff）：这个就和第二个类似了，在指数递增的基础上添加一个波动时间； 上面有两种策略都加入了扰动（jitter），目的是防止**惊群问题 （Thundering Herd Problem）**的发生。
In computer science, the thundering herd problem occurs when a large number of processes or threads waiting for an event are awoken when that event occurs, but only one process is able to handle the event.</description></item><item><title>Httperf</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/Httperf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/Httperf/</guid><description>概述 Web 压力测试 - Httperf
Httperf 比 ab 更强大，能测试出 web 服务能承载的最大服务量及发现潜在问题；比如：内存使用、稳定性。最大优势：可以指定规律进行压力测试，模拟真实环境。
下载：http://code.google.com/p/httperf/downloads/list
[root@localhost ~]# tar zxvf httperf-0.9.0.tar.gz [root@localhost ~]# cd httperf-0.9.0 [root@localhost httperf-0.9.0]# ./configure [root@localhost httperf-0.9.0]# make &amp;amp;&amp;amp; make install [root@localhost ~]# httperf &amp;ndash;hog &amp;ndash;server=192.168.0.202 &amp;ndash;uri=/index.html &amp;ndash;num-conns=10000 &amp;ndash;wsess=10,10,0.1 参数说明：
&amp;ndash;hog：让 httperf 尽可能多产生连接，httperf 会根据硬件配置，有规律的产生访问连接 &amp;ndash;num-conns：连接数量，总发起 10000 请求 &amp;ndash;wsess：用户打开网页时间规律模拟，第一个 10 表示产生 10 个会话连接，第二个 10 表示每个会话连接进行 10 次请求，0.1 表示每个会话连接请求之间的间隔时间 / s</description></item><item><title>HTTPS</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTPS/HTTPS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTPS/HTTPS/</guid><description>概述 **Hyper Text Transfer Protocol over Secure Socket Layer(简称 HTTPS) **是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版。即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。 它是一个 URI scheme（抽象标识符体系），句法类同 http:体系。用于安全的 HTTP 数据传输。https://URL 表明它使用了 HTTP，但 HTTPS 存在不同于 HTTP 的默认端口及一个加密/身份验证层（在 HTTP 与 TCP 之间）。这个系统的最初研发由网景公司(Netscape)进行，并内置于其浏览器 Netscape Navigator 中，提供了身份验证与加密通讯方法。现在它被广泛用于万维网上安全敏感的通讯，例如交易支付方面。
HTTP 和 HTTPS 区别 https 本质是 http 与 ssl 结合的协议，并没有绝对意义上的 https 协议。需要到 ca 申请证书，一般免费证书很少，需要交费。
http 是超文本传输协议，信息是明文传输，https 则是具有安全性的 ssl 加密传输协议 http 和 https 使用的是完全不同的连接方式用的端口也不一样：前者是 80，后者是 443。
http 的连接很简单，是无状态的 HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议 要比 http 协议安全</description></item><item><title>HTTPS 交互流程(ECDHE 算法)</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTPS/HTTPS-%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8BECDHE-%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTPS/HTTPS-%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8BECDHE-%E7%AE%97%E6%B3%95/</guid><description>概述 参考：
公众号-小林 coding，这 HTTPS，真滴牛逼！ HTTPS 常用的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。
其中，RSA 是比较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使用的。而 ECDHE 算法具有前向安全，所以被广泛使用。
我在上一篇已经介绍了 RSA 握手的过程，今天这一篇就「从理论再到实战抓包」介绍 ECDHE 算法。
离散对数 ECDHE 密钥协商算法是 DH 算法演进过来的，所以我们先从 DH 算法说起。
DH 算法是非对称加密算法， 因此它可以用于密钥交换，该算法的核心数学思想是离散对数。
是不是听到这个数学概念就怂了？不怕，这次不会说离散对数推到的过程，只简单提一下它的数学公式。
离散对数是「离散 + 对数」的两个数学概念的组合，所以我们先来复习一遍对数。
要说起对数，必然要说指数，因为它们是互为反函数，指数就是幂运算，对数是指数的逆运算。
举个栗子，如果以 2 作为底数，那么指数和对数运算公式，如下图所示：
那么对于底数为 2 的时候， 32 的对数是 5，64 的对数是 6，计算过程如下：
对数运算的取值是可以连续的，而离散对数的取值是不能连续的，因此也以「离散」得名，
离散对数是在对数运算的基础上加了「模运算」，也就说取余数，对应编程语言的操作符是「%」，也可以用 mod 表示。离散对数的概念如下图：
上图的，底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以用上面的公式计算出真数。但反过来，知道真数却很难推算出对数。
特别是当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数的，这就是 DH 算法的数学基础。
DH 算法 认识了离散对数，我们来看看 DH 算法是如何密钥交换的。</description></item><item><title>HTTPS 交互流程(RSA 算法)</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTPS/HTTPS-%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8BRSA-%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTPS/HTTPS-%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8BRSA-%E7%AE%97%E6%B3%95/</guid><description>概述 参考：
公众号-小林 coding，几幅图，拿下 HTTPS 对于还不知道对称加密和非对称加密的同学，你先复习我以前的这篇文章「硬核！30 张图解 HTTP 常见的面试题」，本篇文章默认大家已经具备了这些知识。
TLS 握手过程 HTTP 由于是明文传输，所谓的明文，就是说客户端与服务端通信的信息都是肉眼可见的，随意使用一个抓包工具都可以截获通信的内容。
所以安全上存在以下三个风险：
窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 HTTPS 在 HTTP 与 TCP 层之间加入了 TLS 协议，来解决上述的风险。
TLS 协议是如何解决 HTTP 的风险的呢？
信息加密：HTTP 交互信息是被加密的，第三方就无法被窃取； 校验机制：校验信息传输过程中是否有被第三方篡改过，如果被篡改过，则会有警告提示； 身份证书：证明淘宝是真的淘宝网； 可见，有了 TLS 协议，能保证 HTTP 通信是安全的了，那么在进行 HTTP 通信前，需要先进行 TLS 握手。TLS 的握手过程，如下图：
上图简要概述来 TLS 的握手过程，其中每一个「框」都是一个记录（record），记录是 TLS 收发数据的基本单位，类似于 TCP 里的 segment。多个记录可以组合成一个 TCP 包发送，所以通常经过「四个消息」就可以完成 TLS 握手，也就是需要 2 个 RTT 的时延，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议。
所以可以发现，HTTPS 是应用层协议，需要先完成 TCP 连接建立，然后走 TLS 握手过程后，才能建立通信安全的连接。
事实上，不同的密钥交换算法，TLS 的握手过程可能会有一些区别。</description></item><item><title>I/O Multiplexing(输入/输出多路复用)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/I_O/I_O-Multiplexing%E8%BE%93%E5%85%A5_%E8%BE%93%E5%87%BA%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/I_O/I_O-Multiplexing%E8%BE%93%E5%85%A5_%E8%BE%93%E5%87%BA%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</guid><description>概述 参考：
原文链接 知乎问答 这是高性能、高并发系列的第三篇，承接上文《读取文件时程序经历了什么》
背景 文件描述符太多了怎么办 经过了这么多的铺垫，终于到高性能、高并发这一主题了。
从前几节我们知道，所有 I/O 操作都可以通过文件样的概念来进行，这当然包括网络通信。
如果你是一个 web 服务器，当三次握手成功以后，我们通过调用 accept 同样会得到一个文件描述符，只不过这个文件描述符是用来进行网络通信的，通过读写该文件描述符你就可以同客户端通信。在这里为了概念上好理解，我们称之为链接描述符，通过这个描述符我们就可以读写客户端的数据了。
int conn_fd = accept(...); server 的处理逻辑通常是读取客户端请求数据，然后执行某些特定逻辑：
if(read(conn_fd, request_buff) &amp;gt; 0) { do_something(request_buff); } 是不是非常简单，然而世界终归是复杂的，也不是这么简单的。
接下来就是比较复杂的了。
既然我们的主题是高并发，那么 server 端就不可能只和一个客户端通信，而是成千上万个客户端。这时你需要处理不再是一个描述符这么简单，而是有可能要处理成千上万个描述符。
为了不让问题一上来就过于复杂，我们先简单化，假设只同时处理两个客户端的请求。
有的同学可能会说，这还不简单，这样写不就行了：
if(read(socket_fd1, buff) &amp;gt; 0) { // 处理第一个 do_something(); } if(read(socket_fd2, buff) &amp;gt; 0) { do_something(); 在本篇第二节中我们讨论过这是非常典型的阻塞式 I/O，如果读取第一个请求进程被阻塞而暂停运行，那么这时我们就无法处理第二个请求了，即使第二个请求的数据已经就位，这也就意味着所有其它客户端必须等待，而且通常情况下也不会只有两个客户端而是成千上万个，上万个连接也要这样串行处理吗。
聪明的你一定会想到使用多线程，为每个请求开启一个线程，这样一个线程被阻塞不会影响到其它线程了，注意，既然是高并发，那么我们要为成千上万个请求开启成千上万个线程吗，大量创建销毁线程会严重影响系统性能。
那么这个问题该怎么解决呢？
这里的关键点在于在进行 I/O 时，我们并不知道该文件描述对应的 I/O 设备是否是可读的、是否是可写的，在外设的不可读或不可写的状态下进行 I/O 只会导致进程阻塞被暂停运行。
因此要优雅的解决这个问题，就要从其它角度来思考这个问题了。
不要打电话给我，有需要我会打给你 大家生活中肯定会接到过推销电话，而且不止一个，一天下来接上十个八个推销电话你的身体会被掏空的。
这个场景的关键点在于打电话的人并不知道你是不是要买东西，只能来一遍遍问你，因此一种更好的策略是不要让他们打电话给你，记下他们的电话，有需要的话打给他们。
也就是不要打电话给我，有需要我会打给你。
在这个例子中，你，就好比内核，推销者就好比应用程序，电话号码就好比文件描述符，和你用电话沟通就好比 I/O。
现在你应该明白了吧，处理多个文件描述符的更好方法其实就存在于推销电话中。</description></item><item><title>IETF</title><link>https://desistdaydream.github.io/docs/Standard/Internet/IETF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/Internet/IETF/</guid><description>概述 参考：
WIki, IETF 官网 IETF 存储库搜索页 Internet Engineering Task Force(互联网工程工作组，简称 IETF) 是一个开放标准组织，其开发和促进自愿互联网标准，特别是包括互联网协议套件(TCP/IP)的标准。它没有正式的会员名单或会员要求。所有参与者和经理都是志愿者，尽管他们的工作通常由雇主或赞助商资助。
IETF 是首屈一指的互联网标准组织。它遵循设置这些标准的开放且有据可查的流程。一旦发布，这些标准将免费提供。
互联网标准 https://www.ietf.org/standards/
RFCs(征求意见稿) IANA(互联网号码分配机构) Standards process(标准流程) Internet Drafts(互联网草案) Intellectual Property Rights(知识产权)</description></item><item><title>INI</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/INI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/INI/</guid><description>概述 参考：
Wiki, INI INI 格式规范 ; 分号表示注释 INI 原语 Key/Value pair(键/值对) INI 格式的文件主要结构是 Key/Value pair(键/值对) 格式。Key 与 Value 以 = 符号分割。有的地方也称为 Properties(属性)。
Sections(部分) Selections(部分) 是 键/值对 的集合，也称为 Hash Tables(哈希表) 或 Dictionaries(字典)，以 [] 符号表示。从 Table 的 [] 符号开始到下一个 [] 符号为止，所有键值对都属于该 Sections。
人们日常生活中描述的 第一部分、第二部分、我这部分 等等，这就是 部分的意思，表示一个整体的其中一部分。一个 INI 有很多部分，比如可以说：有 main 部分、logging 部分 等等。
Sections 也有章节的意思，但是不如 Chapter 这个词用来表示章节更合适。</description></item><item><title>install、upgrade 子命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/installupgrade-%E5%AD%90%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-CLI/installupgrade-%E5%AD%90%E5%91%BD%E4%BB%A4/</guid><description>Syntax(语法) helm install [NAME] [CHART] [FLAGS]
CHART 可以是 chart(格式是 repo_name/chart)、已经打包的 chart 文件、未打包的 chart 目录、可用的 URL。 要覆盖图表中的值，请使用&amp;rsquo;&amp;ndash;values&amp;rsquo;标志并传递文件，或者使用&amp;rsquo;&amp;ndash;set&amp;rsquo;标志并通过命令行传递配置，以强制使用&amp;rsquo;&amp;ndash;set-string &amp;lsquo;。 如果值很大，因此不想使用“ &amp;ndash;values”或“ &amp;ndash;set”，请使用“ &amp;ndash;set-file”从文件中读取单个大值。
FLAGS &amp;ndash;atomic if set, the installation process deletes the installation on failure. The &amp;ndash;wait flag will be set automatically if &amp;ndash;atomic is used &amp;ndash;ca-file string verify certificates of HTTPS-enabled servers using this CA bundle &amp;ndash;cert-file string identify HTTPS client using this SSL certificate file &amp;ndash;create-namespace create the release namespace if not present &amp;ndash;dependency-update run helm dependency update before installing the chart &amp;ndash;description string add a custom description &amp;ndash;devel # use development versions, too.</description></item><item><title>Instrumenting 原理解析</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting-%E5%BC%80%E5%8F%91/Instrumenting-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Instrumenting-%E5%BC%80%E5%8F%91/Instrumenting-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</guid><description>概述 参考：
根据源码一步一步推到自学 prometheus 默认自带的 Metrics 的实现方式 Go 语言 Library prometheus/promhttp 库 Instrumenting 的实现主要依靠以下几种类型：
Desc(描述符) # 结构体。定义一个 Metric Registerer(注册器) # 接口。根据 Metrics 注册一个 Collector(采集器) Collector(采集器) # 接口。采集 Metrics 的具体实现 Gatherer(聚集器) # 接口。将采集到的 Metrics 聚集在一起 其中 Collector(采集器) 就像其名字一样，是定义采集 Metrics 的主要行为。在代码中，Collector(采集器) 表现为一个接口。这个接口有两个方法，Describe() 与 Collect()，其中在 Collect() 这个方法中，定义主要的采集 Metrics 行为
Desc(描述符) - 用来描述 Metric 的结构体 https://pkg.go.dev/github.com/prometheus/client_golang/prometheus#Desc
在 Prometheus 中，使用 Desc 结构体 来描述一个 Metric。Desc 是所有事物的基础，没有 Desc 也就无从采集 Metric，同时管理 Metric 也是通过 Desc
type Desc struct { // 完全限定名称。也就是 Metric 的名字，fqName 由 Namespace、Subsystem、Name 三部分组成 fqName string // Metric 的帮助信息 help string // constLabelPairs(常量标签对) 包含基于常量标签的预先计算的 DTO标签对。 constLabelPairs []*dto.</description></item><item><title>Interface 命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Interface-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Interface-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
iface-begin create a snapshot of current interfaces settings, which can be later committed (iface-commit) or restored (iface-rollback) iface-bridge create a bridge device and attach an existing network device to it iface-commit commit changes made since iface-begin and free restore point iface-define define an inactive persistent physical host interface or modify an existing persistent one from an XML file iface-destroy destroy a physical host interface (disable it / &amp;ldquo;if-down&amp;rdquo;) iface-dumpxml interface information in XML iface-edit edit XML configuration for a physical host interface</description></item><item><title>IPMI</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/IPMI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Motherboard/IPMI/</guid><description>概述 参考： Wiki, IPMI Wiki, BMC
IntelligentPlatformManagement Interface(智能平台管理接口，简称 IPMI) 是一组自动计算机子系统的计算机接口规范，可提供管理和监视功能，独立于主机系统的 CPU，固件（BIOS 或 UEFI）和操作系统。
IPMI 定义了系统管理员使用的一组接口，用于计算机系统的带外管理和监控其操作。例如，IPMI 提供了一种方法来管理可以通过使用与硬件的网络连接而不是对操作系统或登录外部关闭或以其他方式无响应的方式。另一个用例可以远程安装自定义操作系统。如果没有 IPMI，安装自定义操作系统可能需要管理员在计算机附近物理存在，请插入 DVD 或包含 OS 安装程序的 USB 闪存驱动器，并使用监视器和键盘完成安装过程。使用 IPMI，管理员可以安装 ISO 映像，模拟安装程序 DVD，并远程执行安装。
BMC Baseboard Management Controller(主板管理控制器) 提供 IPMI 架构中的智能。它是一个专门的微控制器，嵌入计算机主板上 - 通常是服务器。 BMC 管理系统管理软件和平台硬件之间的接口。 BMC 有自己的固件和 RAM。
计算机系统内置的不同类型的传感器对 BMC 的参数，如温度，冷却风扇速度，电源状态，操作系统（OS）状态等。 BMC 监视传感器，如果任何参数在预设限制内，则可以通过网络向系统管理员发送警报，指示系统的潜在故障。管理员还可以远程与 BMC 通信，采取一些纠正措施 - 例如重置或电源循环系统以获得再次运行的挂起操作系统。这些能力降低了系统的总体拥有成本。
符合 IPMI 版本 2.0 的系统也可以通过串行通信 LAN，从而可以通过 LAN 远程查看串行控制台输出。实现 IPMI 2.0 的系统通常还包括 KVM OVER IP，远程虚拟媒体和带外嵌入式 Web 服务器界面功能，虽然严格来说，这些位于 IPMI 接口标准的范围之外。
IMPI 的实现 Dell iDrac</description></item><item><title>iptables 源码解析</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/iptables-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/Netfilter/iptables/iptables-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</guid><description>原文链接：https://mp.weixin.qq.com/s/O084fYzUFk7jAzJ2DDeADg
大家好，我是飞哥！
现在 iptables 这个工具的应用似乎是越来越广了。不仅仅是在传统的防火墙、NAT 等功能出现，在今天流行的的 Docker、Kubernets、Istio 项目中也经常能见着对它的身影。正因为如此，所以深入理解 iptables 工作原理是非常有价值的事情。
Linux 内核网络栈是一个纯内核态的东西，和用户层功能是天然隔离。但为了迎合各种各样用户层不同的需求，内核开放了一些口子出来供用户干预。使得用户层可以通过一些配置，改变内核的工作方式，从而实现特殊的需求。
Linux 在内核网络组件中很多关键位置布置了 netfilter 过滤器。Iptables 就是基于 netfilter 来实现的。所以本文中 iptables 和 netfilter 这两个名词有时候就混着用了。
飞哥也在网上看过很多关于 netfilter 技术文章，但是我觉得都写的不够清晰。所以咱们撸起袖子，自己写一篇。Netfilter 的实现可以简单地归纳为四表五链。我们来详细看看四表、五链究竟是啥意思。
一、Iptables 中的五链 Linux 下的 netfilter 在内核协议栈的各个重要关卡埋下了五个钩子。每一个钩子都对应是一系列规则，以链表的形式存在，所以俗称五链。当网络包在协议栈中流转到这些关卡的时候，就会依次执行在这些钩子上注册的各种规则，进而实现对网络包的各种处理。
要想把五链理解好，飞哥认为最关键是要把内核接收、发送、转发三个过程分开来看。
1.1 接收过程 Linux 在网络包接收在 IP 层的入口函数是 ip_rcv。网络在这里包碰到的第一个 HOOK 就是 PREROUTING。当该钩子上的规则都处理完后，会进行路由选择。如果发现是本设备的网络包，进入 ip_local_deliver 中，在这里又会遇到 INPUT 钩子。
我们来看下详细的代码，先看 ip_rcv。
`//file: net/ipv4/ip_input.c
int ip_rcv(struct sk_buff *skb, &amp;hellip;&amp;hellip;){
&amp;hellip;&amp;hellip;
return NF_HOOK(NFPROTO_IPV4, NF_INET_PRE_ROUTING, skb, dev, NULL,
ip_rcv_finish);
}
`
NF_HOOK 这个函数会执行到 iptables 中 pre_routing 里的各种表注册的各种规则。当处理完后，进入 ip_rcv_finish。在这里函数里将进行路由选择。这也就是 PREROUTING 这一链名字得来的原因，因为是在路由前执行的。</description></item><item><title>IPv6</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/IPv6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/IP/IPv6/</guid><description>概述 参考：
Wiki, IPv6 RFC,8200 IANA,IPv6 地址空间分配情况 GitHub 项目，IPv6-CN/ipv6cn.github.io(这个资料。。。怎么说呢。。。) https://www.bilibili.com/video/BV1J7411c7ae https://www.bilibili.com/video/BV1aF411v7hU https://www.zhihu.com/question/361275417 https://cloud.tencent.com/developer/article/1468099 Internet Protocol version 6(互联网协议版本 6，简称 IPv6) 是 Internet Protocol(互联网协议，简称 IP) 的最新版本(截止 2022 年 1 月 28 日)，该协议为网络上的计算机提供识别和定位系统并通过 Internet 路由流量。IPv6 由 Internet Engineering Task Force(互联网工程任务组，简称 IETF) 开发，旨在解决 IPv4 地址耗尽的问题。1998 年 12 月，IPv6 成为 IETF 的标准草案，2017 年 7 月 14 日将其批准为互联网标准。 困扰 1. IPv4 和 IPv6 只有地址格式不同吗 除了地址格式不同，IPv4 与 IPv6 协议栈也不同，他们在逻辑上是完全不同的 2 个世界 以下实践中经常会遇到的 4 个不同之处： ▷ 基本通讯过程：ND 替代 ARP、多播替代广播、fe80 地址成为标配、ICMP 成为通讯核心 ▷ IP 配置方式：客户端以无状态自动配置 IP 成为主流，弱化 DHCP ▷ DNS域名解析：AAAA 记录替代 IPv4 的 A 记录、对应用存在优先级问题（优先解析 AAAA 还是 A） ▷ 应用层适应性：socket 编程中 AF_INET 仅支持 IPv4，AF_INET6 仅支持 IPv6</description></item><item><title>IPVS 模式原理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/IPVS-%E6%A8%A1%E5%BC%8F%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/IPVS-%E6%A8%A1%E5%BC%8F%E5%8E%9F%E7%90%86/</guid><description>原文链接：https://mp.weixin.qq.com/s/X6EL8GwWoi9_DyvhHL6Mlw Kubernetes 中的 Service 就是一组同 label 类型 Pod 的服务抽象，为服务提供了负载均衡和反向代理能力，在集群中表示一个微服务的概念。kube-proxy 组件则是 Service 的具体实现，了解了 kube-proxy 的工作原理，才能洞悉服务之间的通信流程，再遇到网络不通时也不会一脸懵逼。 kube-proxy 有三种模式：userspace、iptables 和 IPVS，其中 userspace 模式不太常用。iptables 模式最主要的问题是在服务多的时候产生太多的 iptables 规则，非增量式更新会引入一定的时延，大规模情况下有明显的性能问题。为解决 iptables 模式的性能问题，v1.11 新增了 IPVS 模式（v1.8 开始支持测试版，并在 v1.11 GA），采用增量式更新，并可以保证 service 更新期间连接保持不断开。 目前网络上关于 kube-proxy 工作原理的文档几乎都是以 iptables 模式为例，很少提及 IPVS，本文就来破例解读 kube-proxy IPVS 模式的工作原理。为了理解地更加彻底，本文不会使用 Docker 和 Kubernetes，而是使用更加底层的工具来演示。 我们都知道，Kubernetes 会为每个 Pod 创建一个单独的网络命名空间 (Network Namespace) ，本文将会通过手动创建网络命名空间并启动 HTTP 服务来模拟 Kubernetes 中的 Pod。 本文的目标是通过模拟以下的 Service 来探究 kube-proxy 的 IPVS 和 ipset 的工作原理：
apiVersion: v1 kind: Service metadata: name: app-service spec: clusterIP: 10.</description></item><item><title>Istio</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Istio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Istio/</guid><description>Istio 提供的 Ingress Controller 功能详见 Isito 介绍.note 中的 《Istio Ingress 入口流量路由功能介绍》 章节</description></item><item><title>Jenkins</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins/</guid><description>概述 参考：
官方文档：https://jenkins.io/zh/ Jenkins 是一款开源 CI&amp;amp;CD 软件，用于自动化各种任务，包括构建、测试和部署软件。Jenkins 支持各种运行方式，可通过系统包、Docker 或者通过一个独立的 Java 程序。
Jenkins 自己本身并没有什么功能，仅提供一个基本的 web 页面和监听端口(用来接收 webhook 等)，CI/CD 功能的实现依赖于 Jenkins 的各种插件来实现。
Jenkins 说白了就是一个运行在系统上的程序，通过编写各种 Jenkins Pipelines(流水线)，来在系统中进行代码构建、拷贝文件、执行 shell 命令等等。使用的是系统上环境，比如系统有 go 编译器，那么 Jenkins 就可以执行 go 的相关命令；如果系统上没有安装 docker ，那么 Jenkins 也就没法执行 docker 相关的命令。可以把 Jenkins 当作一个复杂的、可以执行更多功能的 shell 脚本。
当然，既然系统上无法满足各类要求的话，那么 Pipeline 还可以通过使用容器的方式来运行，以便规避环境影响。
Pipe-line(流水线) 介绍 官方文档：https://www.jenkins.io/doc/book/pipeline/
Pipe-line 是 Jenkins 实现 CI/CD 的必备程序。在部署完 Jenkins 之后，一般情况都会首先安装 Pipe-line 插件，而日常使用中，最常用的也是 Pipeline。
顾名思义，Pipeline 流水线，就好像工厂中的流水线一样，第一步应该做什么，第二步应该做什么&amp;hellip;&amp;hellip;都是有明确规定的，这是一个自动化，明确的任务线。
Jenkinsfile Pipeline 通过一个文本文件(称为 Jenkinsfile)来决定其每一步应该执行什么样的操作(比如第一步下载代码、第二步构建、第三步部署&amp;hellip;等等)。这个 Jenkinsfile 文件可以提交到项目的代码存储库中，这是 Pipeline as code(流水线即代码) 的基础。</description></item><item><title>Jenkins 任务示例</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins-%E4%BB%BB%E5%8A%A1%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins-%E4%BB%BB%E5%8A%A1%E7%A4%BA%E4%BE%8B/</guid><description>通过 Jenkins 执行 shell 命令
通过 Jenkins 流水线功能 构建 go 项目 hello world
通过 Jenkins 执行 shell 命令
在 Jenkins 首页点击新建任务，选择构建一个自由风格的软件项目，并输入名称，点击确定
选择构建标签，增加执行 shell 步骤，
在命令框中，输入想要执行的 shell 命令(类似于 shell 脚本)，点击保存
点击立即构建后，Jenkins 就会根据配置的 shell 命令执行任务。
点击下面红框中内容可以查看该次任务的详细信息，点击控制台输出，可以观察任务执行过程以及结果
至此，一次简单的 Jenkins 任务就执行完成了。
Note：
本示例是使用 docker 运行的 Jenkins。并且本机器为 k8s 集群的 master 节点
由于 Jenkins 运行在 docker 环境中，是获取不到 docker 外部的 kubectl 命令的
所以本示例是将 kubectl 命令以及配置文件拷贝到 Jenkins 的容器中，才让该任务成功执行，否则该任务执行失败，并提示无法找到 kubectl 命令。
通过 Jenkins 流水线功能 构建 go 项目 hello world</description></item><item><title>Jenkins 页面详解</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins-%E9%A1%B5%E9%9D%A2%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins-%E9%A1%B5%E9%9D%A2%E8%AF%A6%E8%A7%A3/</guid><description>流水线任务
General
GitHub 项目 #
This build requires lockable resources #
Throttle builds #
丢弃旧的构建 #
参数化构建过程 # 指定各种参数以便在脚本或者 pipeline 中使用。
字符参数 # 指定变量，名称为变量名，默认值为变量值。可以直接在脚本中引用。 关闭构建
在必要的时候
构建触发器
用来指定触发本次任务的方式，比如提交代码时触发，或者定时触发等等。
流水线
用来指定 Jenkinsfile 的内容。
定义 # 指定 Jenkinsfile 的获取方式。
Pipeline script # 直接在网页编写 Jenkinsfile 内容。
Pipeline script from SCM # 从项目根目录中查找 Jenkinsfile 文件
SCM # 指定获取 Jenkinsfile 的 SCM 及其 URL、认证、分支。
脚本路径 # 指定 Jenkinsfile 所在位置的绝对路径
自由风格的软件项目
General
GitHub 项目 #</description></item><item><title>Jenkins 与 skaffold 示例</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins-%E4%B8%8E-skaffold-%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins-%E4%B8%8E-skaffold-%E7%A4%BA%E4%BE%8B/</guid><description>概述 准备操作
配置 webhook
配置 Jenkins Pipeline 自动 clone 代码并获取 Jenkinsfile 文件
代码示例
Jenkinsfile
skaffold.yaml
main.go
Dockerfile
k8s-pod.yaml
运行结果：
准备操作 配置 webhook 从 jenkins 项目中，获取 webhook 的 URL 和 TOKEN，填到 gitlab 指定项目的 webhooks 中。
Jenkins 项目的 TOKEN 需要在构建触发器栏目中，点击 高级，然后点击 Generate 来生成。
在 GitLab 中填写 URL 和 TOKEN ，并点击 Add Webhook 即可，添加完成后，可以在最下方点击 Test 来测试连通性。
配置 Jenkins Pipeline 自动 clone 代码并获取 Jenkinsfile 文件
使用如下配置，开始构建前，让 Jenkins 自动获取代码仓库中的 Jenkinsfile 文件，并根据该文件执行 pipeline
在流水线类型的任务中，进行如下配置
代码示例 Jenkinsfile pipeline { agent any stages { stage('build') { steps { sh 'export TAG=1.</description></item><item><title>JenkinsX</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/JenkinsX/JenkinsX/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/JenkinsX/JenkinsX/</guid><description>概述 参考：
官网 GitHub 项目 Jenkins X 为 Kubernetes 提供自动化 CI+CD，并使用来自 Tekton 的云原生管道在拉取请求上提供预览环境</description></item><item><title>Jenkins基于k8s的 CICD平台部署</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins%E5%9F%BA%E4%BA%8Ek8s%E7%9A%84-CICD%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Jenkins/Jenkins%E5%9F%BA%E4%BA%8Ek8s%E7%9A%84-CICD%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/</guid><description>jenkins 基于 k8s 的 CICD 平台部署</description></item><item><title>Jinja</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Jinja/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Jinja/</guid><description>概述 参考：
GitHub 项目，pallets/jinja 官网 国人翻译官网 Wiki, Jinja 骏马金龙博客，9. 如虎添翼的力量：解锁强大的 Jinja2 模板 Jinja 是一个用于 Python 变成语言中的 Template Engine(模板引擎)。Jinja 通常被用来作为 Python 的 Web 框架(e.g.Flask、Django)的数据渲染的底层调用。
Django 其实自带模板引擎(DTL)，只不过由于 Jinja 的流行，通常都让 Django 的模板引擎使用 Jinja2
Jinja 模板引擎允许定制标签、过滤器、测试和全局变量。此外，与 Django 模板引擎不同，Jinja 允许模板设计器调用带有对象参数的函数。Jinja 是 Flask 的默认模板引擎，同时，也被 Ansible、Trac、Salt 使用。
Jinja 是什么？模板是什么？ 何为模板？举个例子就知道了。
假设要发送一个文件给一个或多个目标节点，要发送的文件内容如下：
hello, __NAME__ 其中 __NAME__ 部分想要根据目标节点的主机名来确定，比如发送给 www 节点时内容应该为 hello, www，发送给 wwww 节点时，内容应该为hello, wwww。换句话说，__NAME__ 是一个能够根据不同场景动态生成不同字符串的代码小片段。而根据特殊的代码片段动态生成字符串便是模板要实现的功能。
现在解释模板便容易了：所谓 Template(模板)，只是文本文件，可以在文本字符串中嵌入一些 Expressions(表达式)，然后使用模板引擎去解析整个模板，将其中嵌入的表达式替换成对应的结果。其中，解析并替换模板表达式的过程，称为渲染。从编程语言的角度说，表达式就是代码中的 function。
当模板引擎解析表达式时，每个表达式都有返回值。
为了让模板引擎只替换表达式而不操作普通字符串，所以模板引擎需要能够区分模板表达式和普通字符串，所以模板表达式通常会使用 Delimiters(分隔符) 包围起来。例如上面示例中，__NAME__使用了前后两个下划线包围，表示这部分是模板表达式，它是需要进行替换的，而”hello” 是普通字符串，模板引擎不会去管它。
Jinja 模板引擎提供了三种** Delimiters(分隔符) **来包围 模板表达式：</description></item><item><title>JSON</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/JSON/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/JSON/</guid><description>概述 参考：
官方文档 Wiki, JSON RFC 8259 JavaScript Object Notation(JS 对象表示法，简称 JSON) 是一种轻量级的数据交换格式。易于人阅读和编写。同时也易于机器解析和生成。 它基于 JavaScript Programming Language, Standard ECMA-262 3rd Edition - December 1999 的一个子集。 JSON 采用完全独立于语言的文本格式，但是也使用了类似于 C 语言家族的习惯（包括 C, C++, C#, Java, JavaScript, Perl, Python 等）。 这些特性使 JSON 成为理想的数据交换语言。
JavaScript Object Notation(简称 JSON) 是一种简单的数据交换格式。从句法上讲，它类似于 JavaScript 的对象和列表。它最常用于Web后端与浏览器中运行的 JavaScript 程序之间的通信，但它也用于许多其他地方。它的主页 json.org 提供了一个清晰，简洁的标准定义。
JSON 建构于两种结构：
“名称/值”对的集合（A collection of name/value pairs） # 不同的语言中，它被理解为对象（object），映射（mapping），纪录（record），结构（struct），字典（dictionary），哈希表（hash table），有键列表（keyed list），或者关联数组 （associative array）。 值的有序列表（An ordered list of values） # 在大部分语言中，它被理解为数组（array）。 JSON 具有以下这些形式：</description></item><item><title>K3S 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/K3S/K3S-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，安装-配置选项 官方文档，CLI 工具-server 官方文档，CLI 工具-agent k3s 可以通过如下如下几种方式配置运行时行为
命令行标志 环境变量 配置文件 k3s 运行时默认读取 /etc/rancher/k3s/config.yaml 文件中的值。 配置文件与命令行标志之间的对应关系 直接使用 k3s server 命令并配置如下配置文件：
write-kubeconfig-mode: &amp;#34;0644&amp;#34; tls-san: - &amp;#34;foo.local&amp;#34; node-label: - &amp;#34;foo=bar&amp;#34; - &amp;#34;something=amazing&amp;#34; cluster-init: true 等效于：
k3s server \ --write-kubeconfig-mode &amp;#34;0644&amp;#34; \ --tls-san &amp;#34;foo.local&amp;#34; \ --node-label &amp;#34;foo=bar&amp;#34; \ --node-label &amp;#34;something=amazing&amp;#34; \ --cluster-init 其他配置文件说明 一、/etc/rancher/k3s/registries.yaml 文件
k3s 通过 containerd 来控制容器，在 pull 镜像时，会默认指定 docker.io 为 registry 且不可改。
该配置用于将 docker.io 这个域名解析到指定的 私有镜像仓库地址，这样在使用 crictl pull IMAGE 时，会去私有镜像仓库拉取镜像。这其中需要指定登录私有镜像仓库的用户名和密码。</description></item><item><title>K6</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/K6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/K6/</guid><description>概述 参考：
GitHub 项目，grafana/k6 官网 公众号，MoeLove-Grafana k6 的上手实践 使用 Go 和 JavaScript 语言实现的现代负载测试工具。
背景 2016 年 8 月，k6 在 GitHub 上发布了第一个版本，至此，一个出色的开源负载压测工具进入了人们的视野。
2021 年的 6 月，对于 Grafana 和 k6 来讲是个大日子，Grafana Labs 收购了 k6 。
而事实上， Grafana 与 k6 的缘分还要追溯到更早的 2 年前。
2019 年，在进行 Grafana 6.0 的短期令牌刷新行为的压测时，Grafana Labs 进行了一系列的技术选型。
由于 Grafana Labs 的大部分后端软件是使用 Go 来实现的，恰巧 k6 满足 OSS 和 Go 需求，并且负载测试是使用 JS 编写（Grafana 前端框架及 UI 都在使用）。这使得 k6 自 Grafana 6.0 版本开始，不断地为 Grafana 开发者及测试者完成追踪 bug 的使命。</description></item><item><title>k8s DNS 中的 search 和 ndots 起源</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/k8s-DNS-%E4%B8%AD%E7%9A%84-search-%E5%92%8C-ndots-%E8%B5%B7%E6%BA%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Kubernetes-DNS/DNS-%E7%AE%A1%E7%90%86%E4%B8%8E%E4%BC%98%E5%8C%96/k8s-DNS-%E4%B8%AD%E7%9A%84-search-%E5%92%8C-ndots-%E8%B5%B7%E6%BA%90/</guid><description>多余的 DNS 查询 一些需要解析外部 DNS 域名的应用，当运行在容器中时，如果我们在容器的 network namespace 中对 dns 报文（udp port 53）进行抓包，可能会发现在正确解析之前，还经过了若干次多余的尝试。
下面是我在容器中ping google.com，同时在容器的 network namespace 中抓到的包。
sudo nsenter -t 3885 -n tcpdump -i eth0 udp port 53 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 10:09:11.917900 IP 10.244.2.202.38697 &amp;gt; 10.96.0.10.domain: 11858+ A? google.com.default.svc.cluster.local. (54) 10:09:11.918847 IP 10.96.0.10.domain &amp;gt; 10.244.2.202.38697: 11858 NXDomain*- 0/1/0 (147) 10:09:11.922468 IP 10.</description></item><item><title>K8s 集群稳定性：LIST 请求源码分析、性能评估与大规模基础服务部署调优</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/kubernetes%E4%BC%98%E5%8C%96/K8s-%E9%9B%86%E7%BE%A4%E7%A8%B3%E5%AE%9A%E6%80%A7LIST-%E8%AF%B7%E6%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E8%B0%83%E4%BC%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/kubernetes%E4%BC%98%E5%8C%96/K8s-%E9%9B%86%E7%BE%A4%E7%A8%B3%E5%AE%9A%E6%80%A7LIST-%E8%AF%B7%E6%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E8%B0%83%E4%BC%98/</guid><description>概述 参考：
原文链接：https://mp.weixin.qq.com/s/fcytXp2skFIjbYBLs5VzSQ https://arthurchiao.art/blog/k8s-reliability-list-data-zh/ Published at 2022-05-19 | Last Update 2022-05-19
对于非结构化的数据存储系统来说，LIST 操作通常都是非常重量级的，不仅占用大量的 磁盘 IO、网络带宽和 CPU，而且会影响同时间段的其他请求（尤其是响应延迟要求极高的 选主请求），是集群稳定性的一大杀手。
例如，对于 Ceph 对象存储来说，每个 LIST bucket 请求都需要去多个磁盘中捞出这个 bucket 的全部数据；不仅自身很慢，还影响了同一时间段内的其他普通读写请求，因为 IO 是共享的，导致响应延迟上升乃至超时。如果 bucket 内的对象非常多（例如用作 harbor/docker-registry 的存储后端），LIST 操作甚至都无法在常规时间内完成（ 因而依赖 LIST bucket 操作的 registry GC 也就跑不起来）。
又如 KV 存储 etcd。相比于 Ceph，一个实际 etcd 集群存储的数据量可能很小（几个 ~ 几十个 GB），甚至足够缓存到内存中。但与 Ceph 不同的是，它的并发请求数量可能会高 几个量级，比如它是一个 ~4000 nodes 的 k8s 集群的 etcd。单个 LIST 请求可能只需要 返回几十 MB 到上 GB 的流量，但并发请求一多，etcd 显然也扛不住，所以最好在前面有 一层缓存，这就是 apiserver 的功能（之一）。K8s 的 LIST 请求大部分都应该被 apiserver 挡住，从它的本地缓存提供服务，但如果使用不当，就会跳过缓存直接到达 etcd，有很大的稳定性风险。</description></item><item><title>Keepalived 介绍</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/1.1.Keepalived-%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/1.1.Keepalived-%E4%BB%8B%E7%BB%8D/</guid><description>概述 参考：
官网 Keepalived 特点：
Active/passive 模式 Keepalived 是 vrrp 协议在 Linux 主机上以守护进程方式的实现 能够根据配置文件自动生成 ipvs 规则 对各 RS 做健康状态检测 万字长文带你从 0 学习 Keepalived 负载均衡器（Load Balancer, LB ）是一组能够将 IP 数据流以负载均衡形式转发到多台物理服务器的集成软件。有硬件负载均衡器和软件负载均衡器之分，硬件负载均衡器主要是在访问网络和服务器之间配置物理负载均衡设备，客户端对物理服务器的访问请求首先会抵达负载均衡设备，然后再由负载均衡设备根据一定的负载算法转发到后端服务器。相比而言，软件负载均衡器不需要特定的物理设备，只需在相应的操作系统上部署具有负载均衡功能的软件即可。
在 Openstack 高可用集群部署中，服务的负载均衡和高可用主要有两种主流的实现方案，即 HAProxy+ Keepalived 和 Pacemaker+HAProxy 方案。由于 OpenStack 服务组件多样，不同服务均需要进行特定的高可用设计，并且从集群资源统一调度和集群稳定性的角度考虑，后一种方案是多数 OpenStack 厂商的高可用部署方案首选，但是选用后一方案并不意味着 Keepalived 在 OpenStack 高可用集群部署中不被使用。由于 Keepalived 的主要作用之一是进行虚拟路由的故障切换，其在 Neutron 的 L3 高可用设计与实现中起着举足轻重的作用。
1.1 keepalived 及 LVS 概述 Keepalived 的项目实现的主要目标是简化 LVS 项目的配置并增强其稳定性，即 Keepalived 是对 LVS 项目的扩展增强。
Keepalived 为 Linux 系统和基于 Linux 的架构提供了负载均衡和高可用能力，其负载均衡功能主要源自集成在 Linux 内核中的 LVS 项目模块 IPVS( IP Virtual Server ），基于 IPVS 提供的 4 层 TCP/IP 协议负载均衡， Keepalived 也具备负载均衡的功能，此外， Keepalived 还实现了基于多层 TCP/IP 协议（ 3 层、4 层、5/7 层）的健康检查机制，因此， Keepalived 在 LVS 负载均衡功能的基础上，还提供了 LVS 集群物理服务器池健康检查和故障节点隔离的功能。</description></item><item><title>Keepalived 配置示例</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/10.1.Keepalived-%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/10.1.Keepalived-%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</guid><description>满足基本 HA 功能的配置 global_defs { notification_email { root@localhost } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL script_user root } vrrp_script chk_haproxy { script “killall -0 haproxy” interval 1 weight -2 } vrrp_instance VI_1 { state MASTER #备节点改成BACKUP interface ens33 virtual_router_id 51 priority 101 #倍节点改成100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.0.75 } track_script { chk_haproxy } notify_master &amp;quot;/etc/keepalived/notify master&amp;quot; root notify_backup &amp;quot;/etc/keepalived/notify backup&amp;quot; root notify_fault &amp;quot;/etc/keepalived/notify fault&amp;quot; root } include /etc/keepalived/include/* 基本 LVS 的配置</description></item><item><title>Keepalived 配置详解</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/1.2.Keepalived-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/1.2.Keepalived-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>Keepalived 使用 keepalived 启动流程：
启动三个进程（主进程、healthcheck 进程、vrrp 进程）之后，先进入 backup 状态，运行一次 vrrp_script 成功后发现没有主，这时候会进入 master 状态，拉起 VIP，完成启动。 切换的流程： 原 keepalived master 节点，运行检查脚本异常，则 keepalived 进入 FAULT 状态，释放 vip，原 backup 的 keepalived 会接管 VIP。 注意事项：VIP 必须在 master 上。为了这个要求，需要在主库上先启动 keepalived。 Keepalived 配置 /etc/sysconfig/keepalived # keepalived 运行时参数配置
/etc/keepalived/keepalived.conf # keepalived 基本配置文件
Note：keepalived 配置文件的运行时加载功能，可以通过命令 kill -HUP $(cat /var/run/keepalived.pid) 实现。该功能需要在 1.2.20 及以上版本才能实现
下面是一个基本的 keepalived.conf 文件的配置示例
! Configuration File for keepalived global_defs { #全局配置段 notification_email { admin@example. com } notification_email_from noreply@example.</description></item><item><title>keepalived+nginx 配置示例</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/10.2.keepalived+nginx-%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/10.2.keepalived+nginx-%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</guid><description>适用于 keepalived 的 node 节点的前端负载均衡的配置 keepalived.conf 主节点配置内容 cat &amp;gt; /etc/keepalived/keepalived.conf &amp;lt;&amp;lt; EOF global_defs { router_id k8s-master-dr script_user root enable_script_security } vrrp_script check_nginx { script &amp;#34;/etc/keepalived/check_nginx.sh&amp;#34; interval 3 weight -2 fall 2 rise 2 } vrrp_instance VI_K8S { state BACKUP interface eth0 virtual_router_id 60 priority 101 nopreempt authentication { auth_type PASS auth_pass 4be37dc3b4c90194d1600c483e10ad1d } virtual_ipaddress { 172.40.0.60 } track_script { check_nginx } } EOF keepalived.conf 备节点配置内容 cat &amp;gt; /etc/keepalived/keepalived.conf &amp;lt;&amp;lt; EOF global_defs { router_id k8s-master-dr script_user root enable_script_security } vrrp_script check_nginx { script &amp;#34;/etc/keepalived/check_nginx.</description></item><item><title>Kernel 的安装与卸载</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/</guid><description>概述 参考：
https://mp.weixin.qq.com/s/1xRc4DzyG4c8e2XYGk28Vg Ubuntu 参考：
https://kernel.ubuntu.com/~kernel-ppa/mainline/ 更换内核 awk -F' '$1==&amp;quot;\tmenuentry &amp;quot; {print i++ &amp;quot; : &amp;quot; $2}' /boot/grub/grub.cfg
CentOS 参考：
ELRepo 安装文档 elrepo 的内核 rpm 包不全，暂时也不知道去哪找，先把能找到的网址都记下来 https://buildlogs.centos.org/c7-kernels.x86_64/kernel/ https://buildlogs.centos.org/c7-kernels.x86_64/kernel/20200330213326/4.19.113-300.el8.x86_64/?C=N;O=A 安装 linux 内核的存储库 rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org yum install -y https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm 安装 linux 内核 查看可用的 linux 内核版本
版本性质：主分支 ml(mainline)，稳定版(stable)，长期维护版 lt(longterm)
yum --disablerepo=&amp;#34;*&amp;#34; --enablerepo=&amp;#34;elrepo-kernel&amp;#34; list available 安装指定版本的 Linux 内核
yum --enablerepo=elrepo-kernel install kernel-lt-devel kernel-lt kernel-lt-headers -y (可选)安装新内核工具
yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 yum --disablerepo=* --enablerepo=elrepo-kernel install kernel-lt-tools kernel-tools-libs kernel-lt-headers -y 更换默认内核 CentOS7 # 查找需要设为默认启动的内核名称 grep &amp;#34;^menuentry&amp;#34; /boot/grub2/grub.</description></item><item><title>kickstart 介绍</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/kickstart-%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/Cobbler/kickstart-%E4%BB%8B%E7%BB%8D/</guid><description>概述 参考：
官方文档 Kickstart 语法参考 参考：
官方文档：https://docs.centos.org/en-US/centos/install-guide/Kickstart2/#sect-kickstart-syntax 磁盘配置 bootloader [OPTIONS] # 引导程序(boot loader)的相关配置。
&amp;ndash;location=VALUE # 指定引导程序的安装位置为 VALUE
mbr # 默认值。取决于磁盘格式是 MBR 还是 GUID partition # 将引导程序安装在包含内核的分区的第一个扇区中 none # 不安装引导程序 boot # 未知，待更新 磁盘分区相关配置
part MntPoint [OPTIONS] # 创建一个分区，挂载点为 MntPoint，
MntPoint # 可用的挂载点有如下几种。
/PATH # 指定挂载点到具体路径下 swap # 指定该分区为 swap raid.ID pv.ID # 指定该分区用于 lvm，即创建一个 pv(物理卷) biosboot # 指定该分区用于 BIOS 引导,建议大小为 2MiB /boot/efi # 指定该分区用于 UEFI 引导，建议大小为 200MiB. OPTIONS
&amp;ndash;size=NUM # 指定该分区的大小，单位为 MiB。Note：NUM 为一个正整数(不包含单位) &amp;ndash;grow # 将该分区大小设置为所有剩余可用的空间。如果指定了 &amp;ndash;maximum 选项，则将该分区设置为该选项值的大小。 &amp;ndash;asprimary # 指定该分区为主分区。Note：对于 GUID 分区表(GPT),该选项没有任何意义。 &amp;ndash;fstype=TYPE # 指定该分区的文件系统类型。可用类型有 xfs、ext2、ext3、ext4、swap、vfat、efi、biosboot &amp;ndash;ondisk= # 指定要使用的磁盘名称 volgroup Name PartName # 创建名为 NAME 卷组，使用名为 PartName 分区</description></item><item><title>kube-prometheus 项目</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/kube-prometheus-%E9%A1%B9%E7%9B%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/kube-prometheus-%E9%A1%B9%E7%9B%AE/</guid><description>概述 参考:
GitHub 项目，prometheus-operator/kube-prometheus 部署文件 https://github.com/coreos/kube-prometheus/tree/master/manifests https://github.com/prometheus-operator/kube-prometheus/tree/main/manifests GitHub 项目，prometheus-community/helm-charts（kube-prometheus 项目的 Helm Chart） 背景 该项目曾经属于 prometheus operator 项目的一部分，后来挪到 coreos 社区中，再后来又挪回 prometheus operator 社区中，并作为一个单独的 repo 存在。
kube-prometheus 在 prometheus-operator 基础上，给用户提供了一套完整的 yaml 文件，这样就不用让用户在创建完 operator 之后，还要自己写一大堆 prometheus 相关的 yaml 才能把监控系统用起来。
这套完整的 yaml 文件就在上面所写的‘部署文件’链接中,其中包括 prometheus 部署所用的各种 yaml 文件以及配置生成文件、RBAC、告警文件、grafana 还有 grafna 模板等等
兼容矩阵 部署</description></item><item><title>kubectl port-forward 工作原理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/kubectl-port-forward-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/kubectl-port-forward-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</guid><description>原文链接：公众号-CNCF，源码解析 kubectl port-forward 工作原理
本文的源码基于 Kubernetes v1.24.0，容器运行时使用 Containerd 1.5，从源码来分析 kubectl port-forward 的工作原理。
通过 port-forward 流程的分析，梳理出 kubectl -&amp;gt; api-server -&amp;gt; kubelet -&amp;gt; 容器运行时 的交互，了解 cri 的工作方式。
kubectl 简单创建个 pod：
kubectl run pipy --image flomesh/pipy:latest -n default
在执行 kubectl forward 时添加参数 -v 9 打印日志。
kubectl port-forward pipy 8080 -v 9 ... I0807 21:45:58.457986 14495 round_trippers.go:466] curl -v -XPOST -H &amp;#34;User-Agent: kubectl/v1.24.3 (darwin/arm64) kubernetes/aef86a9&amp;#34; -H &amp;#34;X-Stream-Protocol-Version: portforward.k8s.io&amp;#34; &amp;#39;https://192.168.1.12:6443/api/v1/namespaces/default/pods/pipy/portforward&amp;#39; I0807 21:45:58.484013 14495 round_trippers.go:553] POST https://192.</description></item><item><title>kubectl top 命令解析</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/kubectl-top-%E5%91%BD%E4%BB%A4%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/kubectl-top-%E5%91%BD%E4%BB%A4%E8%A7%A3%E6%9E%90/</guid><description>原文链接：http://www.xuyasong.com/?p=1781
一. 前言 kubectl top 可以很方便地查看 node、pod 的实时资源使用情况：如 CPU、内存。这篇文章会介绍其数据链路和实现原理，同时借 kubectl top 阐述 k8s 中的监控体系，窥一斑而知全豹。最后会解释常见的一些问题：
kubectl top 为什么会报错？
kubectl top node 怎么计算，和节点上直接 top 有什么区别？
kubectl top pod 怎么计算，包含 pause 吗？
kubectl top pod 和 exec 进入 pod 后看到的 top 不一样？
kubectl top pod 和 docker stats 得到的值为什么不同？
以下命令的运行环境为：
k8s 1.8
k8s 1.13
二. 使用
kubectl top 是基础命令，但是需要部署配套的组件才能获取到监控值
1.8 以下：部署 heapter
1.8 以上：部署 metric-server
kubectl top node: 查看 node 的使用情况
kubectl top pod: 查看 pod 的使用情况</description></item><item><title>kubectl 扩展</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubectl-%E6%89%A9%E5%B1%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/kubectl-%E6%89%A9%E5%B1%95/</guid><description>概述 参考：
官方文档 kubectl 有一个称为 Plugins(插件) 机制，可以扩展 kubectl 工具的能力。通过插件，就相当于为 kubectl 添加了子命令。
安装 kubectl 插件 插件是一个独立的可执行文件，名称以 kubectl- 开头。 要安装插件，只需将此可执行文件移动到 $PATH 中的任何位置。
Kubernetes SIG 研发了一款名为 Krew 的插件，这是一个可以管理插件的插件，Krew 之于 Kubectl，就好像 yum/apt 之于 CentOS/Ubuntu。可以使用 Krew 来发现和安装开源的 kubectl 插件。
注意： Krew 插件索引 所维护的 kubectl 插件并未经过安全性审查。 你要了解安装和运行第三方插件的安全风险，因为它们本质上时是一些在你的机器上 运行的程序。
Krew 参考：
GitHub 项目 Krew 配置 ~/.krew/ # Krew 配置文件与存储路径。
./bin/ # Krew 安装的插件的软连接 ./index/default/plugins/ # Krew 发现的插件元数据，想要安装插件，就会通过这里面的元数据信息进行。 ./receipts/ # 已安装的插件的元数据。 ./store/ # Krew 存储路径，所有安装的插件的二进制文件都会在该目录下。 常见 kubectl 插件 kubectl 插件管理工具，项目地址：https://github.</description></item><item><title>Kubelet 启动流程</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/Kubelet-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/Kubelet-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</guid><description>概述 启动 首先从 kubelet 的 main() 函数开始，调用 app.NewKubeletCommand() 方法以获取配置文件中的参数、校验参数、为参数设置默认值。主要逻辑为：
解析命令行参数； 为 kubelet 初始化 feature gates 参数； 加载 kubelet 配置文件； 校验配置文件中的参数； 检查 kubelet 是否启用动态配置功能； 初始化 kubeletDeps，kubeletDeps 包含 kubelet 运行所必须的配置，是为了实现 dependency injection，其目的是为了把 kubelet 依赖的组件对象作为参数传进来，这样可以控制 kubelet 的行为； 调用 Run() 函数； main() - 入口 源码：[cmd/kubelet/kubelet.go](https://github.com/kubernetes/kubernetes/blob/master/cmd/kubelet/kubelet.go)
func main() { command := app.NewKubeletCommand() // kubelet 使用一个配置文件，并对标志和该配置文件进行自己的特殊解析。 // 完成后，它会初始化日志记录。因此，它不像其他更简单的命令那样使用 cli.Run() code := run(command) os.Exit(code) } func run(command *cobra.Command) int { defer logs.FlushLogs() rand.Seed(time.Now().UnixNano()) command.SetGlobalNormalizationFunc(cliflag.WordSepNormalizeFunc) if err := command.</description></item><item><title>kubernetes 二进制方式安装说明</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/kubernetes-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85%E8%AF%B4%E6%98%8E/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/kubernetes-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85%E8%AF%B4%E6%98%8E/</guid><description>首先需要明确几个概念，kubelet负责本节点容器的生命周期管理，那么在master节点上，如果只通过二进制文件运行 apiserver、controller-manager、scheduler，则无需部署 kubelet
所以，按照大体可以划分这么几块：
etcd节点：etcd(可部署在master节点上)。高可用至少需要3台设备
master节点：apiserver、controller-manager、scheduler。高可用至少需要2台设备。apiserver 需要与 etcd 进行交互
node节点：kubelet、CNI插件、kube-proxy</description></item><item><title>Kubernetes 管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86/</guid><description>概述 Telepresence 参考：
GitHub 项目，telepresenceio/telepresence 公众号-马哥 Linux 运维，K8S 运维开发调试神器 Telepresence 实践及踩坑记</description></item><item><title>Kubernetes 网络疑难杂症排查分享</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/Kubernetes-%E7%BD%91%E7%BB%9C%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E6%8E%92%E6%9F%A5%E5%88%86%E4%BA%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/Kubernetes-%E7%BD%91%E7%BB%9C%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E6%8E%92%E6%9F%A5%E5%88%86%E4%BA%AB/</guid><description>原文链接：https://zhuanlan.zhihu.com/p/77808615
大家好，我是 roc，来自腾讯云容器服务(TKE)团队，经常帮助用户解决各种 K8S 的疑难杂症，积累了比较丰富的经验，本文分享几个比较复杂的网络方面的问题排查和解决思路，深入分析并展开相关知识，信息量巨大，相关经验不足的同学可能需要细细品味才能消化，我建议收藏本文反复研读，当完全看懂后我相信你的功底会更加扎实，解决问题的能力会大大提升。 本文发现的问题是在使用 TKE 时遇到的，不同厂商的网络环境可能不一样，文中会对不同的问题的网络环境进行说明
跨 VPC 访问 NodePort 经常超时 现象: 从 VPC a 访问 VPC b 的 TKE 集群的某个节点的 NodePort，有时候正常，有时候会卡住直到超时。 原因怎么查？
当然是先抓包看看啦，抓 server 端 NodePort 的包，发现异常时 server 能收到 SYN，但没响应 ACK: 反复执行 netstat -s | grep LISTEN 发现 SYN 被丢弃数量不断增加: 分析：
两个 VPC 之间使用对等连接打通的，CVM 之间通信应该就跟在一个内网一样可以互通。 为什么同一 VPC 下访问没问题，跨 VPC 有问题? 两者访问的区别是什么? 再仔细看下 client 所在环境，发现 client 是 VPC a 的 TKE 集群节点，捋一下:
client 在 VPC a 的 TKE 集群的节点 server 在 VPC b 的 TKE 集群的节点 因为 TKE 集群中有个叫 ip-masq-agent 的 daemonset，它会给 node 写 iptables 规则，默认 SNAT 目的 IP 是 VPC 之外的报文，所以 client 访问 server 会做 SNAT，也就是这里跨 VPC 相比同 VPC 访问 NodePort 多了一次 SNAT，如果是因为多了一次 SNAT 导致的这个问题，直觉告诉我这个应该跟内核参数有关，因为是 server 收到包没回包，所以应该是 server 所在 node 的内核参数问题，对比这个 node 和 普通 TKE node 的默认内核参数，发现这个 node net.</description></item><item><title>Kubernetes 衍生品</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/</guid><description>ClusterAPI 概述 参考：
官方文档 为什么要建立集群 API？ Kubernetes 是一个复杂的系统，它依赖于正确配置的几个组件才能具有正常运行的集群。社区意识到这是用户的潜在绊脚石，因此专注于简化引导过程。如今，已经创建了100 多个 Kubernetes 发行版和安装程序，每个发行版和安装程序都为集群和受支持的基础架构提供程序提供了不同的默认配置。SIG 集群生命周期发现需要一种工具来解决一系列常见的重叠安装问题，因此开始使用 kubeadm。
Kubeadm被设计为引导最佳实践 Kubernetes 集群的重点工具。kubeadm 项目背后的核心宗旨是创建其他安装程序可以利用的工具，并最终减轻单个安装程序需要维护的配置量。自开始以来，kubeadm 已成为其他多个应用程序（包括 Kubespray，Minikube，kind 等）的基础自举工具。
但是，尽管 kubeadm 和其他引导程序提供程序降低了安装复杂性，但它们并未解决如何长期管理日常群集或 Kubernetes 环境的问题。在设置生产环境时，您仍然面临几个问题，包括
如何在多个基础架构提供商和位置之间一致地配置计算机，负载平衡器，VPC 等？ 如何实现集群生命周期管理的自动化，包括升级和集群删除等操作？ 如何扩展这些过程以管理任意数量的集群？ SIG 集群生命周期开始了 ClusterAPI 项目，以此作为通过构建声明性的 Kubernetes 风格的 API 来解决这些差距的方法，该 API 使集群的创建，配置和管理自动化。使用此模型，还可以扩展集群 API，以支持所需的任何基础结构提供程序（AWS，Azure，vSphere 等）或引导程序提供程序（默认为 kubeadm）。请参阅越来越多的可用提供程序列表。
CNCF 的 Software conformance(软件一致性) 参考：
官方文档 Certified Kubernetes(经过认证的 Kubernetes)
对于使用 Kubernetes 的组织，一致性可以实现从一个 Kubernetes 安装到下一个 Kubernetes 安装的互操作性。它使他们可以灵活地在供应商之间进行选择。
CNCF 运行 Kubernetes 认证合格计划。大多数全球领先的企业软件供应商和云计算提供商都拥有 经过认证的 Kubernetes 产品。
有超过 90 种经过认证的 Kubernetes 产品。邀请所有供应商提交一致性测试结果，以供 CNCF 审核和认证。如果您的公司提供基于 Kubernetes 的软件，我们建议您立即获得认证。</description></item><item><title>Kubernetes并发控制和资源变更</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/API-Server/Kubernetes%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%92%8C%E8%B5%84%E6%BA%90%E5%8F%98%E6%9B%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/API-Server/Kubernetes%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%92%8C%E8%B5%84%E6%BA%90%E5%8F%98%E6%9B%B4/</guid><description>概述 参考：
公众号，云原生实验室，Kubernetes 是如何控制并发和资源变更的 原文，简书，Kubernetes 并发控制和资源变更 并发控制 并发控制指的是当多个用户同时更新运行时，用于保护数据库完整性的各种技术。并发机制不正确可能导致脏读、幻读和不可重复读等此类问题。并发控制的目的是保证一个用户的工作不会对另一个用户的工作产生不合理的影响。
悲观锁 悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。
悲观锁主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。
优点
是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。 缺点
在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会； 在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载； 会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数据。 乐观锁 乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。
乐观并发控制多数用于数据争用不大、冲突较少的环境中，这种环境中，偶尔回滚事务的成本会低于读取数据时锁定数据的成本，因此可以获得比其他并发控制方法更高的吞吐量。
优点
不会产生任何锁和死锁 有更高的吞吐量 缺点
ABA 问题是乐观锁一个常见的问题 循环时间长开销大 乐观锁一般会使用版本号机制或 CAS 算法实现：
版本号机制 一般是在数据表中加上一个数据版本号 version 字段，表示数据被修改的次数，当数据被修改时，version 值会加一。当线程 A 要更新数据值时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值为当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功。
CAS 算法 即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS 算法涉及到三个操作数
需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。
Kubernetes 并发控制 在 Kubernetes 集群中，外部用户及内部组件频繁的数据更新操作，导致系统的数据并发读写量非常大。假设采用悲观并行的控制方法，将严重损耗集群性能，因此 Kubernetes 采用乐观并行的控制方法。</description></item><item><title>Kubernetes不再在kubelet中维护docker-shim代码</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/Kubernetes-%E4%B8%8D%E5%86%8D%E5%9C%A8-kubelet-%E4%B8%AD%E7%BB%B4%E6%8A%A4-docker-shim-%E4%BB%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/Kubernetes-%E4%B8%8D%E5%86%8D%E5%9C%A8-kubelet-%E4%B8%AD%E7%BB%B4%E6%8A%A4-docker-shim-%E4%BB%A3%E7%A0%81/</guid><description>大事件：Kubernetes 不再在 kubelet 中维护 docker-shim 代码
原文链接
Don&amp;rsquo;t Panic: Kubernetes and Docker
Wednesday, December 02, 2020
Authors: Jorge Castro, Duffie Cooley, Kat Cosgrove, Justin Garrison, Noah Kantrowitz, Bob Killen, Rey Lejano, Dan “POP” Papandrea, Jeffrey Sica, Davanum “Dims” Srinivas
Kubernetes is deprecating Docker as a container runtime after v1.20.
You do not need to panic. It’s not as dramatic as it sounds.
tl;dr Docker as an underlying runtime is being deprecated in favor of runtimes that use the Container Runtime Interface(CRI) created for Kubernetes.</description></item><item><title>Kubernetes排障图谱</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/Kubernetes%E6%8E%92%E9%9A%9C%E5%9B%BE%E8%B0%B1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/Kubernetes%E6%8E%92%E9%9A%9C%E5%9B%BE%E8%B0%B1/</guid><description>自从用上这张图解指南后， Kubernetes 故障排除不再难！
TonyBai
与技术博客 tonybai.com 同源。近期关注 Kubernetes、Docker、Golang、儿童编程、DevOps、云计算平台和机器学习。
下面是一个示意图，可帮助你调试 Kubernetes Deployment。
（如需此图解中文版或 PDF 版 ，请在公众号对话框回复关键字：「K8s 排障图解」，进行获取。）
当你希望在 Kubernetes 中部署应用程序时，你通常会定义三个组件：
•一个 Deployment - 这是一份用于创建你的应用程序的 Pod 副本的&amp;quot;食谱&amp;quot;；•一个 Service - 一个内部负载均衡器，用于将流量路由到内部的 Pod 上；•一个 Ingress - 描述如何流量应该如何从集群外部流入到集群内部的你的服务上。
下面让我们用示意图快速总结一下要点。
在 Kubernetes 中，你的应用程序通过两层负载均衡器暴露服务：内部的和外部的
内部的负载均衡器称为 Service，而外部的负载均衡器称为 Ingress
Pod 不会直接部署。Deployment 会负责创建 Pod 并管理它们
假设你要部署一个简单的 &amp;ldquo;HelloWorld&amp;rdquo; 应用，该应用的 YAML 文件的内容应该类似下面这样：
// hello-world.yaml
apiVersion: apps/v1kind: Deploymentmetadata: name: my-deployment labels: track: canaryspec: selector: matchLabels: any-name: my-app template: metadata: labels: any-name: my-app spec: containers: - name: cont1 image: learnk8s/app:1.</description></item><item><title>kubernetes优化</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/kubernetes%E4%BC%98%E5%8C%96/kubernetes%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/kubernetes%E4%BC%98%E5%8C%96/kubernetes%E4%BC%98%E5%8C%96/</guid><description>概述 参考：
增加可以打开的文件数与线程数,防止 pod 无故无法启动
cat &amp;gt;&amp;gt; /etc/security/limits.conf &amp;lt;&amp;lt; EOF * soft nproc 1000000 * hard nproc 1000000 * soft nofile 1000000 * hard nofile 1000000 EOF 馆长推荐的优化参数 https://github.com/moby/moby/issues/31208 # ipvsadm -l &amp;ndash;timout # 修复 ipvs 模式下长连接 timeout 问题 小于 900 即可 {% if proxy.mode is defined and proxy.mode == &amp;lsquo;ipvs&amp;rsquo; %} net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 {% endif %} net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_max_tw_buckets = 5000 net.</description></item><item><title>Kubesphere</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Kubesphere/Kubesphere/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Kubesphere/Kubesphere/</guid><description>kubekey 部署工具小问题
kubeadm 文件无法完全自定义，在 apis/kubekey/v1alpha1/kubernetes_types.go 中的 kubernetes 结构体只有很少的几个属性，pkg/kubernetes/tmpl/kubeadm.go 中的 kubeadm 模板文件很多都是写死的。
问题总结 总结于 3.1
该 产品定位是集群管理，应用管理功能非常弱。
企业空间下的项目=k8s 中的 namespace
应用仓库没法使用认证添加
应用信息加载不出来
监控套件输入内嵌，自定义非常弱，不太懂为啥要自己实现 Grafana
有的代理转发的头不支持
总结，用开源的东西，又想要实现生态闭环，抽象概念太多，用上的人就离不开，离开了也没法理解 k8s。
该产品目标猜测：面向企业，对企业的基础设施以上的设备及应用的全生命周期管理。
已经无人维护了~~~</description></item><item><title>Kubesphere 部署与清理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Kubesphere/Kubesphere-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Kubesphere/Kubesphere-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</guid><description>概述 参考：
官方文档，从 Kubernetes 上卸载 KubeSphere 从 Kubernetes 中卸载 KubeSphere</description></item><item><title>Kustomization Manifest 详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Kustomize/Kustomization-Manifest-%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Kustomize/Kustomization-Manifest-%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，任务 - 管理 Kubernetes 对象 - 使用 Kustomize 声明式得管理 Kubernetes 对象 - Kustomize 字段列表 apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization bases([]STRING) 此列表中的每个条目都应该是一个包含 kustomization.yaml 文件的目录
commonLabels(map[STRING]STRING) 为所有对象和选择器添加的标签
commonAnnotations(map[STRING]STRING) 为所有对象添加的注释
configurations([]STRING) 列表中每个条目都应能解析为一个包含 Kustomize 转换器配置 的文件
images: &amp;lt;[]Image&amp;gt; name(STRING) # 需要修改的 image 字段的名称。需要通过这个找到可供修改的字段。
newName(STRING) # 用于替换原始镜像名称的值。
newTag(STRING) # 用于替换原始镜像 Tag 的值。
crds([]STRING) 列表中每个条目都赢能够解析为 Kubernetes 类别的 OpenAPI 定义文件
namesapce(STRING) 为所有资源添加名称空间
namePrefix(STRING) 为所有对象的名称添加前缀
nameSuffix(STRING) 为所有对象的名称添加后缀
resources([]STRING) 列表中的每个条目都代表一个 Manifests 文件
patchesStrategicMerge([]STRING) 列表中每个条目都能解析为某 Kubernetes 对象的策略性合并补丁
patchesJson6902([]Patch) 列表中每个条目都能解析为一个 Kubernetes 对象和一个 JSON 补丁</description></item><item><title>LabelSelector</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/LabelSelector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/LabelSelector/</guid><description>概述 参考：
官方文档，参考 - KubernetesAPI - 通用定义 - LabelSelector LabelSelector 用来实现标签和选择器功能。通过 LabelSelector，我们可以根据标签匹配到想要的对象
LabelSelector 通常是其他资源对象的内嵌字段，包含 matchLabels 和 matchExpressions 两个字段，这两个字段的匹配逻辑为 AND。假如现在有如下匹配规则：
selector: matchLabels: app.kubernetes.io/instance: monitor-hw-cloud app.kubernetes.io/name: grafana 这个表示，匹配具有 app.kubernetes.io/instance: monitor-hw-cloud 和 app.kubernetes.io/name: grafana 这两个标签的对象。
顶层字段 matchExpressions([]matchExpressions) # 基于给定的表达式匹配对象 matchLabels(matchLabels) # 基于给定的标签匹配对象 matchExpressions key(STRING) # 必须的。指定要匹配的标签的键。
operator(STRING) # 必须的。key 与 values 两个字段之间的关系。可以有 In、NotIn、Exists、DoesNotExist 四种关系
In，NotIn # 匹配 key 中是否包含指定的 values。values 字段的值必须为非空列表 Exists，DoesNotExist # 匹配 key 是否存在。values 字段的值必须为空列表 values([]STRING) # 指定要匹配的标签的值。如果 operator 字段为 In 或 NotIn，则必须指定 values 字段。如果 operator 字段为 Exists 或 NotExists，则必须不指定 values 字段。</description></item><item><title>Leader Election(领导人选举)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Leader-Election%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%89%B9%E6%80%A7/Leader-Election%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE/</guid><description>概述 参考：
官方博客, Kubernetes 的简单领导人选举 zhengyinyong 用法： 公众号-云原生实验室，巧用 Kubernetes 中的 Leader 选举机制来实现自己的 HA 应用 为什么需要 Pod 之间的 Leader Election 一般来说，由 Deployment 创建的 1 个或多个 Pod 都是对等关系，彼此之间提供一样的服务。但是在某些场合，多个 Pod 之间需要有一个 Leader 的角色，即：
Pod 之间有且只有一个 Leader； Leader 在一定周期不可用时，其他 Pod 会再选出一个 Leader； 由处于 Leader 身份的 Pod 来完成某些特殊的业务逻辑（通常是写操作）； 比如，当多个 Pod 之间只需要一个写者时，如果不采用 Leader Election，那么就必须在 Pod 启动之初人为地配置一个 Leader。如果配置的 Leader 在后续的服务中失效且没有对应机制来生成新的 Leader，那么对应 Pod 服务就可能处于不可用状态，违背高可用原则。
典型地，Kubernetes 的核心组件 kube-controller-manager 和 scheduler 就需要一个需要 Leader 的场景。当 kube-controller-manager 的启动参数设置 --leader-elect=true 时，对应节点的 kube-controller-manager 在启动时会执行选主操作。当选出一个 Leader 之后，由 Leader 来启动所有的控制器。如果 Leader Pod 不可用，将会自动选出新的 Leader Pod，从而保障控制器仍处于运行状态。</description></item><item><title>libguestfs</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/libguestfs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/libguestfs/</guid><description>概述 参考：
GitHub 项目，libguestfs/libguestfs 官网 Libguestfs 是用于访问和修改虚拟机磁盘映像的库和工具。
常见问题 参考：
https://access.redhat.com/solutions/4073061 https://wandering-wolf.tistory.com/entry/Centos-7-KVM-%EC%97%90%EC%84%9C-rhel-8-vm-virt-sysperp-error https://dovangiang.wordpress.com/2021/08/06/errorcentos-mount-mount-exited-with-status-32-mount-wrong-fs-type-bad-option-bad-superblock/ 注意：CentOS7 宿主机上想要挂载 Ubuntu 20.04 虚拟机的 xfs 格式的文件系统是不行的，内核版本低不支持，报错如下：
~]# guestmount --rw -a /var/lib/libvirt/images/common-ubuntu-test.bj-test.qcow2 -m /dev/ubuntu-vg/lv-0 /mnt/test libguestfs: error: mount_options: mount exited with status 32: mount: wrong fs type, bad option, bad superblock on /dev/mapper/ubuntu--vg-lv--0, missing codepage or helper program, or other error In some cases useful info is found in syslog - try dmesg | tail or so. guestmount: ‘/dev/ubuntu-vg/lv-0’ could not be mounted.</description></item><item><title>Libvirt 客户端库</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/Libvirt-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/Libvirt-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BA%93/</guid><description>概述 参考：
官方文档，binding Libvirt 直接支持 C 和 C++，并且具有可用于其他语言的绑定：
C#：Arnaud Champion 开发C# 绑定。 Go：Daniel Berrange 开发了 Go 绑定。 Java：Daniel Veillard 开发 Java 绑定。 OCaml：Richard Jones 开发 OCaml 绑定。 Perl：Daniel Berrange 开发 Perl 绑定。 PHP：Radek Hladik 于 2010 年开始开发 PHP 绑定。2011 年 2 月，绑定开发已作为 libvirt-php 项目移至 libvirt.org 网站。该项目现在由 Michal Novotny 维护，并且很大程度上基于 Radek 的版本。有关更多信息，包括发布补丁到 libvirt-php 的信息，请参阅PHP 绑定站点。 Python：Libvirt 的 python 绑定从 1.2.0 版本开始被拆分为一个单独的 包，旧版本直接支持 Python 语言。如果您的 libvirt 是作为软件包安装的，而不是由您从源代码编译的，请确保您安装了适当的软件包。这在 RHEL/Fedora 上被命名为 libvirt-python ，在 Ubuntu 上被命名为 python-libvirt ，并且在其他人上可能有不同的命名。有关使用信息，请参阅Python API 绑定 页面。 Ruby：Chris Lalancette 开发Ruby 绑定。 集成 API 模块：</description></item><item><title>Libvirt 配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
/etc/libvirt/libvirt.conf
# 设置别名 uri_aliases = [ &amp;#34;vs-1=qemu+ssh://10.10.100.201/system&amp;#34;, ] # 可以对 10.10.100.201 使用 virsh 命令 virsh -c vs-1 list log_level(INT) # 程序运行日志的输出级别。默认值: 2。1 debug, 2 information, 3 warnings, 4 errors</description></item><item><title>Linux Cgroup 系列（二）：玩转 CPU</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/2.CGroup/Linux-Cgroup-%E7%B3%BB%E5%88%97%E4%BA%8C%E7%8E%A9%E8%BD%AC-CPU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/2.CGroup/Linux-Cgroup-%E7%B3%BB%E5%88%97%E4%BA%8C%E7%8E%A9%E8%BD%AC-CPU/</guid><description>上篇文章主要介绍了 cgroup 的一些基本概念，包括其在 CentOS 系统中的默认设置和控制工具，并以 CPU 为例阐述 cgroup 如何对资源进行控制。这篇文章将会通过具体的示例来演示如何通过 cgroup 来限制 CPU 的使用以及不同的 cgroup 设置对性能的影响。
1. 查看当前 cgroup 信息 有两种方法来查看系统的当前 cgroup 信息。第一种方法是通过 systemd-cgls 命令来查看，它会返回系统的整体 cgroup 层级，cgroup 树的最高层由 slice 构成，如下所示：
$ systemd-cgls --no-page ├─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 22 ├─user.slice │ ├─user-1000.slice │ │ └─session-11.scope │ │ ├─9507 sshd: tom [priv] │ │ ├─9509 sshd: tom@pts/3 │ │ └─9510 -bash │ └─user-0.slice │ └─session-1.scope │ ├─ 6239 sshd: root@pts/0 │ ├─ 6241 -zsh │ └─11537 systemd-cgls --no-page └─system.</description></item><item><title>Linux Torvalds 采访</title><link>https://desistdaydream.github.io/blog/copy/mVo3S_F0RoxCToawrTCnlA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/mVo3S_F0RoxCToawrTCnlA/</guid><description>https://mp.weixin.qq.com/s/mVo3S_F0RoxCToawrTCnlA
作者丨 Jeremy Andrews
译者丨屠灵
策划丨蔡芳芳
Linux 诞生于 1991 年，距今已经 30 年了。虽然它一开始只是 Linus 的一个个人项目，而非出于要开发一个新操作系统的伟大梦想，但如今的 Linux 早已无处不在。
30 年前，当 Linus Torvalds 第一次发布 Linux 内核时，他还是赫尔辛基大学的一名 21 岁的学生。他宣布说：“我正在开发一个（免费的）操作系统（这只是个爱好，不会做得很大，也不会很专业……）”。30 年后，500 强超级计算机和 70% 以上的智能手机都在运行 Linux。很显然，Linux 不仅大，而且很专业。
30 年来，Linus Torvalds 一直在领导着 Linux 内核的开发，启发了无数开发者和开源项目。2005 年，Linus 开发了 Git，用来管理内核开发过程。Git 现在已经成为最流行的版本控制系统，受到无数开源和私有项目的信任。
正值 Linux 诞生 30 周年之际，Linus Torvalds 通过电子邮件回复了 Tag 1 咨询公司的创始合伙人 / 首席执行官 Jeremy Andrews 的访谈问题（《An Interview With Linus Torvalds: Linux and Git - Part 1》），回顾并总结了过去这些年他在领导大型开源项目过程中得到的真知灼见。本文着重介绍 Linux 内核开发和 Git。InfoQ 对访谈内容进行了翻译，以飨读者。</description></item><item><title>Linux 代理配置</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Linux-%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/Linux-%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</guid><description>概述 在 Unix-like OS 中，很多程序都会读取 Terminal 与 Shell 中的某些变量来读取代理信息
TODO: 这些变量到底应该大写还是小写？wget 命令无法识别到大写的变量。
http_proxy | https_proxy | ftp_proxy | all_proxy # 此变量值用于所有 http、https、ftp 或者所有流量 socks_proxy # 在大多数情况下，它用于 TCP 和 UDP 流量。其值通常采用 socks：// address：port 格式。 rsync_proxy # 这用于 rsync 流量，尤其是在 Gentoo 和 Arch 等发行版中。 no_proxy # 以逗号分隔的域名或 IP 列表，应绕过代理。该本地主机就是一个很好的例子。一个例子是 localhost，127.0.0.1。 TODO: 但是这些变量却不是 Bash 的自带变量，但是这些程序却无一例外得统一使用这些变量，具体为什么暂时不知道
语法格式
XXXX_proxy=&amp;ldquo;http://[USER:PASSWORD@]ServerIP:PORT/&amp;rdquo; # 需要设置用户名，密码，代理服务器的 IP 和端口，用户名和密码可省
EXAMPLE
http_proxy=&amp;ldquo;http://tom:secret@10.23.42.11:8080/&amp;rdquo; # 设置本机的 http 代理服务器为 10.23.42.11:8080，用户名是 tom，密码是 secret
同时设置 3 种类型代理，没有用户名和密码，代理服务器是 192.</description></item><item><title>Linux 网络包发送过程</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E5%8C%85%E5%8F%91%E9%80%81%E8%BF%87%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E5%8C%85%E5%8F%91%E9%80%81%E8%BF%87%E7%A8%8B/</guid><description>25 张图，一万字，拆解 Linux 网络包发送过程
大家好，我是飞哥!
半年前我以源码的方式描述了网络包的接收过程。之后不断有粉丝提醒我还没聊发送过程呢。好，安排！
在开始今天的文章之前，我先来请大家思考几个小问题。
问 1：我们在查看内核发送数据消耗的 CPU 时，是应该看 sy 还是 si ？ 问 2：为什么你服务器上的 /proc/softirqs 里 NET_RX 要比 NET_TX 大的多的多？ 问 3：发送网络数据的时候都涉及到哪些内存拷贝操作？ 这些问题虽然在线上经常看到，但我们似乎很少去深究。如果真的能透彻地把这些问题理解到位，我们对性能的掌控能力将会变得更强。
带着这三个问题，我们开始今天对 Linux 内核网络发送过程的深度剖析。还是按照我们之前的传统，先从一段简单的代码作为切入。如下代码是一个典型服务器程序的典型的缩微代码：
int main(){ fd = socket(AF_INET, SOCK_STREAM, 0); bind(fd, ...); listen(fd, ...); cfd = accept(fd, ...); // 接收用户请求 read(cfd, ...); // 用户请求处理 dosometing(); // 给用户返回结果 send(cfd, buf, sizeof(buf), 0); } 今天我们来讨论上述代码中，调用 send 之后内核是怎么样把数据包发送出去的。本文基于 Linux 3.10，网卡驱动采用 Intel 的 igb 网卡举例。
预警：本文共有一万多字，25 张图，长文慎入！
开发内功修炼</description></item><item><title>Linux 系统安装问题</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/</guid><description>使用 U 盘安装 CentOS7 卡在”Starting dracut initqueue hook…”
使用 U 盘安装系统的过程中遇到卡在 Starting dracut initqueue hook 这里的情况，过一会会报 timeout 的错误。这是因为安装程序没有找到安装文件的位置。
安装程序是按照卷标寻找分区的，可以在开机过程选择 Install CentOS 7 后按 tab 编辑开机选项，uefi 启动模式按 e 编辑。
问题原因：在安装 centos 时，设备无法找到 U 盘来启动安装程序
在 ios 安装程序，找到/isolinux/isolinux.cfg(uefi 模式的配置文件路径为：/EFI/BOOT/grub.cfg)这个文件，效果如图
此处 inst.stage2=hd:LABEL=CentOS\x207\x20x86_64。这就是造成超时的原因，inst.stage2 这里应该是指向一个具体的路径，如果是 DVD，它的标签就是“CentOS 7 x86_64”，而 U 盘则可能是你自己定义的标签。 这就造成了 DVD 能正常安装，U 盘就不行了。
而为什么 U 盘的标签不是默认的 CentOS 7 x86_64 呢，是因为标签(LABEL)长度超出了 windows 的卷标长度限制(主要是因为这个 U 盘是在 windos 下制作的。。。)，并且 Windows 限制卷标只能使用大写字母，就算输入的是小写，实际上也是大写。
解决方式：
解决方式 1 直接修改 /isolinux/isolinux.cfg 文件中的内容，将 CentOS\x207\x20x86_64 修改为 CENTOS7</description></item><item><title>Load 高/CPU 使用率 问题及实用脚本</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Load-%E9%AB%98_CPU-%E4%BD%BF%E7%94%A8%E7%8E%87-%E9%97%AE%E9%A2%98%E5%8F%8A%E5%AE%9E%E7%94%A8%E8%84%9A%E6%9C%AC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Load-%E9%AB%98_CPU-%E4%BD%BF%E7%94%A8%E7%8E%87-%E9%97%AE%E9%A2%98%E5%8F%8A%E5%AE%9E%E7%94%A8%E8%84%9A%E6%9C%AC/</guid><description>Linux 资源&amp;amp;瓶颈分析概述 参考：
公众号,CPU 飙高，系统性能问题如何排查？ 阿里云,ECS 运维指南之 LInux 系统诊断-找到 Linux 虚机 Load 高的元凶 Load Average 和 CPU 使用率 可被细分为不同的子域指标，指向不同的资源瓶颈。总体来说，指标与资源瓶颈的对应关系基本如下图所示。
注意：Load 与 CPU 使用率 之间没有必然的联系。有可能 Load 很高，而 CPU 使用率很低；也有可能 Load 很低而 CPU 使用率很高。具体原因详见 CPU 管理 与 Process 进程管理 章节中关于 Load 与 CPU 使用率的概念。简单说就是因为 Load Average 在计算时，包含了对 I/O 的统计
Load 高 &amp;amp; CPU 高 这是我们最常遇到的一类情况，即 load 上涨是 CPU 负载上升导致。根据 CPU 具体资源分配表现，可分为以下几类：
CPU sys 高
这种情况 CPU 主要开销在于系统内核，可进一步查看上下文切换情况。
如果非自愿上下文切换较多，说明 CPU 抢占较为激烈，大量进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。 如果自愿上下文切换较多，说明可能存在 I/O、内存等系统资源瓶颈，大量进程无法获取所需资源，导致的上下文切换。 CPU si 高</description></item><item><title>logcli 命令行工具</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E7%AE%A1%E7%90%86/logcli-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E7%AE%A1%E7%90%86/logcli-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
export LOKI_ADDR=http://localhost:3100
在 https://github.com/grafana/loki/releases 该界面下载 logcli 工具的二进制文件，并放到系统 $PATH 下。
二进制文件有了之后，配置一下 logcli 所需要的环境变量 export LOKI_ADDR=http://localhost:3100 然后就可以使用了
下面是一些命令使用示例
[root@master-1 bin]# logcli labels job http://172.38.40.212:31000/loki/api/v1/label/job/values?end=1600402177427090944&amp;amp;start=1600398577427090944 varlogs [root@master-1 bin]# logcli query &amp;#39;{job=&amp;#34;varlogs&amp;#34;}&amp;#39; | more http://172.38.40.212:31000/loki/api/v1/query_range?direction=BACKWARD&amp;amp;end=1600402187037107678&amp;amp;limit=30&amp;amp;query=%7Bjob%3D%22varlogs%22%7D&amp;amp;start=1600398587037107678 Common labels: {job=&amp;#34;varlogs&amp;#34;} 2020-09-18T11:48:50+08:00 {filename=&amp;#34;/var/log/host/messages&amp;#34;} Sep 18 11:48:50 master-1 kubelet: W0918 11:48:50.468511 30889 container.go:526] Failed to update stats for container &amp;#34;/system .slice/docker-f326688c0b9b38fb8190bba72eb12d55e2017a9624889948ac118e6b9eb1199b.scope&amp;#34;: unable to determine device info for dir: /var/lib/docker/overlay2/51f0b901d76af9efd801abb473d0b7d5b27a193ccb990 d3db1cac1799a2a0432/diff: stat failed on /var/lib/docker/overlay2/51f0b901d76af9efd801abb473d0b7d5b27a193ccb990d3db1cac1799a2a0432/diff with error: no such file or directory, continuing to push stat s .</description></item><item><title>Loki 源码分析之日志写入</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E5%BC%80%E5%8F%91/Loki-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E5%BC%80%E5%8F%91/Loki-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5/</guid><description>原文链接：https://mp.weixin.qq.com/s/9BKZvNANqGJwziygytJ1ag 前面我们介绍了 Loki 的一些基本使用配置，但是对 Loki 还是了解不够深入，官方文档写得较为凌乱，而且没有跟上新版本，为了能够对 Loki 有一个更深入的认识，做到有的放矢，这里面我们尝试对 Loki 的源码进行一些简单的分析，由于有很多模块和实现细节，这里我们主要是对核心功能进行分析，希望对大家有所帮助。本文首先对日志的写入过程进行简单分析。
Distributor Push API Promtail 通过 Loki 的 Push API 接口推送日志数据，该接口在初始化 Distributor 的时候进行初始化，在控制器基础上包装了两个中间件，其中的 HTTPAuthMiddleware 就是获取租户 ID，如果开启了认证配置，则从 X-Scope-OrgID 这个请求 Header 头里面获取，如果没有配置则用默认的 fake 代替。
// pkg/loki/modules.go func (t *Loki) initDistributor() (services.Service, error) { ...... if t.cfg.Target != All { logproto.RegisterPusherServer(t.Server.GRPC, t.distributor) } pushHandler := middleware.Merge( serverutil.RecoveryHTTPMiddleware, t.HTTPAuthMiddleware, ).Wrap(http.HandlerFunc(t.distributor.PushHandler)) t.Server.HTTP.Handle(&amp;#34;/api/prom/push&amp;#34;, pushHandler) t.Server.HTTP.Handle(&amp;#34;/loki/api/v1/push&amp;#34;, pushHandler) return t.distributor, nil } Push API 处理器实现如下所示，首先通过 ParseRequest 函数将 Http 请求转换成 logproto.</description></item><item><title>longhorn</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/longhorn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/longhorn/</guid><description>Longhorn 介绍 官方文档：https://longhorn.io/docs
Longhorn 是一个用于 Kubernetes 的轻量、可靠且功能强大的分布式 block storage(块存储) 系统</description></item><item><title>lsof 列出打开的文件</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/lsof-%E5%88%97%E5%87%BA%E6%89%93%E5%BC%80%E7%9A%84%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/lsof-%E5%88%97%E5%87%BA%E6%89%93%E5%BC%80%E7%9A%84%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
Manual(手册)，lsof(8) 该工具以文件为主体，用于列出打开文件的进程，进程打开的端口(TCP、UDP)等、找回/恢复删除的文件。是十分方便的系统监视工具，因为 lsof 需要访问核心内存和各种文件，所以需要 root 用户执行。
~]# lsof | more COMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 253,0 238 64 / systemd 1 root rtd DIR 253,0 238 64 / systemd 1 root txt REG 253,0 1612152 17149941 /usr/lib/systemd/systemd ...... kthreadd 2 root cwd DIR 253,0 238 64 / kthreadd 2 root rtd DIR 253,0 238 64 / kthreadd 2 root txt unknown /proc/2/exe .</description></item><item><title>Make 命令教程</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Make/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/Make/</guid><description>概述 参考：
Manual(手册)，make(1) Wiki, Make(software) 阮一峰博客，Make 命令教程 Make 代码变成可执行文件，叫做编译（compile）；先编译这个，还是先编译那个（即编译的安排），叫做构建（build）。
Make是最常用的构建工具，诞生于 1977 年，主要用于 C 语言的项目。但是实际上 ，任何只要某个文件有变化，就要重新构建的项目，都可以用 Make 构建。
本文介绍 Make 命令的用法，从简单的讲起，不需要任何基础，只要会使用命令行，就能看懂。我的参考资料主要是 Isaac Schlueter 的《Makefile 文件教程》和《GNU Make 手册》。
一、Make 的概念 Make 这个词，英语的意思是&amp;quot;制作&amp;quot;。Make 命令直接用了这个意思，就是要做出某个文件。比如，要做出文件 a.txt，就可以执行下面的命令。
$ make a.txt 但是，如果你真的输入这条命令，它并不会起作用。因为 Make 命令本身并不知道，如何做出 a.txt，需要有人告诉它，如何调用其他命令完成这个目标。
比如，假设文件 a.txt 依赖于 b.txt 和 c.txt ，是后面两个文件连接（cat 命令）的产物。那么，make 需要知道下面的规则。
a.txt: b.txt c.txt cat b.txt c.txt &amp;gt; a.txt 也就是说，make a.txt 这条命令的背后，实际上分成两步：第一步，确认 b.txt 和 c.txt 必须已经存在，第二步使用 cat 命令 将这个两个文件合并，输出为新文件。
像这样的规则，都写在一个叫做 Makefile 的文件中，Make 命令依赖这个文件进行构建。Makefile 文件也可以写为 makefile， 或者用命令行参数指定为其他文件名。</description></item><item><title>mc 工具</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/MinIO/mc-%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/MinIO/mc-%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档，MinIO 客户端 配置 ~/.mc/config.json # mc 从该文件中获取将要操作的 host 信息。可以通过 mc config host 命令管理该文件，也可以直接手动编辑。
~]# cat ~/.mc/config.json { &amp;#34;version&amp;#34;: &amp;#34;10&amp;#34;, &amp;#34;aliases&amp;#34;: { &amp;#34;gcs&amp;#34;: { &amp;#34;url&amp;#34;: &amp;#34;https://storage.googleapis.com&amp;#34;, &amp;#34;accessKey&amp;#34;: &amp;#34;YOUR-ACCESS-KEY-HERE&amp;#34;, &amp;#34;secretKey&amp;#34;: &amp;#34;YOUR-SECRET-KEY-HERE&amp;#34;, &amp;#34;api&amp;#34;: &amp;#34;S3v2&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;dns&amp;#34; }, &amp;#34;local&amp;#34;: { &amp;#34;url&amp;#34;: &amp;#34;http://0.0.0.0:9000&amp;#34;, &amp;#34;accessKey&amp;#34;: &amp;#34;minioadmin&amp;#34;, &amp;#34;secretKey&amp;#34;: &amp;#34;ehl@1234&amp;#34;, &amp;#34;api&amp;#34;: &amp;#34;S3v4&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;auto&amp;#34; }, &amp;#34;play&amp;#34;: { &amp;#34;url&amp;#34;: &amp;#34;https://play.min.io&amp;#34;, &amp;#34;accessKey&amp;#34;: &amp;#34;Q3AM3UQ867SPQQA43P2F&amp;#34;, &amp;#34;secretKey&amp;#34;: &amp;#34;zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG&amp;#34;, &amp;#34;api&amp;#34;: &amp;#34;S3v4&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;auto&amp;#34; }, &amp;#34;s3&amp;#34;: { &amp;#34;url&amp;#34;: &amp;#34;https://s3.amazonaws.com&amp;#34;, &amp;#34;accessKey&amp;#34;: &amp;#34;YOUR-ACCESS-KEY-HERE&amp;#34;, &amp;#34;secretKey&amp;#34;: &amp;#34;YOUR-SECRET-KEY-HERE&amp;#34;, &amp;#34;api&amp;#34;: &amp;#34;S3v4&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;dns&amp;#34; } } } Syntax(语法) mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS&amp;hellip;]</description></item><item><title>Memroy 的 Over Commit 与 OOM</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memroy-%E7%9A%84-Over-Commit-%E4%B8%8E-OOM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/Memroy-%E7%9A%84-Over-Commit-%E4%B8%8E-OOM/</guid><description>概述 over commit memory 机制与 out of memory 机制
over-commit memory 机制 Linux 内核根据应用程序的要求分配内存，通常来说应用程序分配了内存但是并没有实际全部使用，为了提高性能，这部分没用的内存可以留作它用，这部分内存是属于每个进程的，内核直接回收利用的话比较麻烦，所以内核采用一种过度分配内存（over-commit memory）的办法来间接利用这部分 “空闲” 的内存，提高整体内存的使用效率。一般来说这样做没有问题，但当大多数应用程序都消耗完自己的内存的时候麻烦就来了，因为这些应用程序的内存需求加起来超出了物理内存（包括 swap）的容量，内核（OOM killer）必须杀掉一些进程才能腾出空间保障系统正常运行。用银行的例子来讲可能更容易懂一些，部分人取钱的时候银行不怕，银行有足够的存款应付，当全国人民（或者绝大多数）都取钱而且每个人都想把自己钱取完的时候银行的麻烦就来了，银行实际上是没有这么多钱给大家取的。
out of memory 机制(OOM) 某时刻应用程序大量请求内存导致系统内存不足造成的，这通常会触发 Linux 内核里的 Out of Memory (OOM) killer，OOM killer 会杀掉某个进程以腾出内存留给系统用，不致于让系统立刻崩溃
内核检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码 linux/mm/oom_kill.c，当系统内存不足的时候，out_of_memory() 被触发，然后调用 select_bad_process() 选择一个 “bad” 进程杀掉，如何判断和选择一个 “bad” 进程呢，总不能随机选吧？挑选的过程由 oom_badness() 决定，挑选的算法和想法都很简单很朴实：最 bad 的那个进程就是那个最占用内存的进程。
OOM 触发后的 Message 信息 Nov 24 19:52:22 dr-2 kernel: dsm_sa_datamgrd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0 Nov 24 19:52:22 dr-2 kernel: dsm_sa_datamgrd cpuset=/ mems_allowed=0-1 Nov 24 19:52:22 dr-2 kernel: Pid: 4917, comm: dsm_sa_datamgrd Not tainted 2.</description></item><item><title>Middleware</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Middleware/Middleware/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Middleware/Middleware/</guid><description>概述 参考：
原文链接：https://chai2010.gitbooks.io/advanced-go-programming-book/content/ch5-web/ch5-03-middleware.html 本章将对现在流行的 Web 框架中的中间件(middleware)技术原理进行分析，并介绍如何使用中间件技术将业务和非业务代码功能进行解耦。
代码泥潭 先来看一段代码：
// middleware/hello.go package main func hello(wr http.ResponseWriter, r *http.Request) { wr.Write([]byte(&amp;#34;hello&amp;#34;)) } func main() { http.HandleFunc(&amp;#34;/&amp;#34;, hello) err := http.ListenAndServe(&amp;#34;:8080&amp;#34;, nil) ... } 这是一个典型的 Web 服务，挂载了一个简单的路由。我们的线上服务一般也是从这样简单的服务开始逐渐拓展开去的。 现在突然来了一个新的需求，我们想要统计之前写的 hello 服务的处理耗时，需求很简单，我们对上面的程序进行少量修改：
// middleware/hello_with_time_elapse.go var logger = log.New(os.Stdout, &amp;#34;&amp;#34;, 0) func hello(wr http.ResponseWriter, r *http.Request) { timeStart := time.Now() wr.Write([]byte(&amp;#34;hello&amp;#34;)) timeElapsed := time.Since(timeStart) logger.Println(timeElapsed) } 这样便可以在每次接收到 http 请求时，打印出当前请求所消耗的时间。 完成了这个需求之后，我们继续进行业务开发，提供的 API 逐渐增加，现在我们的路由看起来是这个样子：
// middleware/hello_with_more_routes.go // 省略了一些相同的代码 package main func helloHandler(wr http.</description></item><item><title>Mimir</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Mimir/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Mimir/</guid><description>概述 参考：
GitHub 项目，grafana/mimir 官网 Mimir 由 Grafana 团队开发，为 Prometheus 提供了水平可扩展的、高可用、多租户、长期存储 等功能</description></item><item><title>MIT 开源许可证</title><link>https://desistdaydream.github.io/docs/Standard/MIT-%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E8%AF%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/MIT-%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E8%AF%81/</guid><description>这一回终于把 MIT 协议讲明白了
以下文章来源于微月人话 ，作者卫 sir
微月人话
简单而深入
以前看到过李笑来讲的发生在他身上的故事，说他当年 ( 2001 年 ) 住在双榆树，经常去双安商场的地下超市买东西，有一次买了个什么东西觉得不好，要退，超市服务员说按规定，该类商品售出一概不能退，李笑来大怒，说你把书面规定拿出来，有的话我就不退了，如果没有，那我就一定要退，最后叫来了超市经理，经理一看这来者不善啊，也吵不过李笑来，就给退了。
讲这个故事想说明什么呢，其实我们都明白，20 多年前的中国超市，很多管理规定都是口头上的，怎么会写成白纸黑字呢。
从超市服务员的角度看，李笑来这行为就是捣乱，是胡搅蛮缠；李笑来则肯定觉得是在维护自己正当的消费者权益；最受震动的应该是超市管理层，如果是我，我会立刻要求起草一个关于退换货的规定，我可真不想再遇到下一个这样的人。
这就是契约精神，说好的，都写下来，写下来的，我都认。
现在说 MIT 协议。
MIT 协议就是大名鼎鼎的开源软件许可协议 The MIT License，又称 MIT 许可证。
有人在两年前专门做过分析 1，MIT 是 Github 上使用率最高的许可证，第二名到第五名是 Apache 2.0、GPL 2.0、GPL 3.0 和 bsd-3-clause。
注：本文中，“MIT 协议”和“MIT 许可证”等同。
什么是开源许可证？
开源许可证是这样的，我把源码放网上了，如果还不错，就有很多人问我了，说你那个代码能不能让我用用？你那个代码我能不能放在我的产品里啊？你那个代码我用了，怎么那么多 Bug 啊？你那个代码我想当作教学案例使用，请问是不是可以啊？还有，你那个代码我用了，感觉不错，而且我还改了很多地方，我也把它放网上了，而且我还改了个名，你没有意见吧？你有意见我也准备改名了，因为现在这个软件中，我写的代码，比你写的多多了！
（这都是比较有版权意识的，怕不问你就用以后惹上官司。）
我可懒得回答这么多问题，我把这些可能问到的问题，都写成一段话，放在我的代码里，意思就是说：
我允许你们 XXX，我许可你们 XXXX，你们可以 XXXX，但是，你们必须 XXXX，如果你们 XXXX 了，你们就必须 XXXX，对了，对于 XXXX 这些情况，我可不负责。
你要同意，就用，不同意就别用。如果你用了，但违反了许可证的要求，我可能会告你啊！
这就是许可证。
你可以自己写一个许可证，但是如果你很懒的话 ( 一般人都很懒 ) ，你可以用别人写的比较好的许可证。
写的比较好的开源许可证有很多种，比如 GPL、BSD、MIT、Apache 等等，MIT 只是其中的一个。
你可以挑一个合你胃口的，这些许可证模版都是免费的，毕竟也没人指望这个卖钱。</description></item><item><title>mmap可以让程序员解锁哪些骚操作？</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/mmap%E5%8F%AF%E4%BB%A5%E8%AE%A9%E7%A8%8B%E5%BA%8F%E5%91%98%E8%A7%A3%E9%94%81%E5%93%AA%E4%BA%9B%E9%AA%9A%E6%93%8D%E4%BD%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/mmap%E5%8F%AF%E4%BB%A5%E8%AE%A9%E7%A8%8B%E5%BA%8F%E5%91%98%E8%A7%A3%E9%94%81%E5%93%AA%E4%BA%9B%E9%AA%9A%E6%93%8D%E4%BD%9C/</guid><description>mmap 可以让程序员解锁哪些骚操作？
大家好，我是小风哥！
今天这篇文章带你讲解下稍显神秘的 mmap 到底是怎么一回事。
简单的与麻烦的
用代码读写内存对程序员来说是非常方便非常自然的，但用代码读写磁盘对程序员来说就不那么方便不那么自然了。
回想一下，你在代码中读写内存有多简单：
定义一个数组：
int a[100]; a[0] = 2; 看到了吧，这时你就在写内存，甚至你可能在写这段代码时下意识里都没有去想读内存这件事。
再想想你是怎样读磁盘文件的？
char buf[1024]; int fd = open(&amp;#34;/filepath/abc.txt&amp;#34;); read(fd, buf, 1024); 看到了吧，读写磁盘文件其实是一件很麻烦的事情，你需要 open 一个文件，意思是告诉操作系统 “Hey，操作系统，我要开始读 abc.txt 这个文件了，把这个文件的所有信息准备好，然后给我一个代号”。这个代号就是所谓的文件描述符，拿到文件描述符后你才能继续接下来的读写操作。
为什么麻烦
现在你应该看到了，操作磁盘文件要比操作内存复杂很多，根本原因就在于寻址方式不同。
对内存来说我们可以直接按照字节粒度去寻址，但对磁盘上保存的文件来说则不是这样的，磁盘上保存的文件是按照块 (block) 的粒度来寻址的，因此你必须先把磁盘中的文件读取到内存中，然后再按照字节粒度来操作文件内容。
你可能会想既然直接操作内存很简单，那么我们有没有办法像读写内存那样去直接读写磁盘文件呢？
答案是肯定的。
要开脑洞了
对于像我们这样在用户态编程的程序员来说，内存在我们眼里就是一段连续的空间。啊哈，巧了，磁盘上保存的文件在程序员眼里也存放在一段连续的空间中（有的同学可能会说文件其实是在磁盘上离散存放的，请注意，我们在这里只从文件使用者的角度来讲）。
那么这两段空间有没有办法关联起来呢？
答案是肯定的，怎么关联呢？
答案就是。。。。。。你猜对了吗？答案是通过虚拟内存。
关于虚拟内存我们已经讲解过很多次了，虚拟内存就是假的地址空间，是进程看到的幻象，其目的是让每个进程都认为自己独占内存，关于虚拟内存完整的详细讲解请参考博主的深入理解操作系统，关注公众号码农的荒岛求生并回复操作系统即可。
既然进程看到地址空间是假的那么一切都好办了。
既然是假的，那么就有做手脚的操作空间，怎么做手脚呢？
从普通程序员眼里看文件不是保存在一段连续的磁盘空间上吗？我们可以直接把这段空间映射到进程的内存中，就像这样：
假设文件长度是 100 字节，我们把该文件映射到了进程的内存中，地址是从 600 ~ 800，那么当你直接读写 600 ~ 800 这段内存时，实际上就是在直接操作磁盘文件。
这一切是怎么做到呢？
魔术师操作系统
原来这一切背后的功劳是操作系统。
当我们首次读取 600~800 这段地址空间时，操作系统会检测的这一操作，因为此时这段内存中什么内容都还没有，此时操作系统自己读取磁盘文件填充到这段内存空间中，此后程序就可以像读内存一样直接读取磁盘内容了。
写操作也很简单，用户程序依然可以直接修改这块内存，此后操作系统会在背后将修改内容写回磁盘。
现在你应该看到了，其实采用 mmap 这种方法磁盘依然还是按照块的粒度来寻址的，只不过在操作系统的一番骚操作下对于用户态的程序来说 “看起来” 我们能像读写内存那样直接读写磁盘文件了，从按块粒度寻址到按照字节粒度寻址，这中间的差异就是操作系统来填补的。</description></item><item><title>Mock API</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Mock-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Mock-API/</guid><description>API 文档虽然满足了阅读者对接接口的需求，但是在 API 起初设计的过程中，通常需要等待几天、甚至数周时间才能实时调用接口，从而真正开始接口调试工作。
而通过创建 Mock API，您即可提前交付模拟真实 API 响应的沙盒环境，以便 API 使用者提前开始调试工作，同时您也可以并行开发接口实现。
此外，您也可以在设计过程中得到 API 使用者对 API 设计的及时反馈，并进行迭代以得到更好的 API。
什么是 Mock API Mock API Server 通过提供真实 API 响应的范例数据来模拟真实的 API 服务，它将部署在 CODING 提供的公网服务器上，并且支持路由及参数校验，且在此基础上可限制访问的 IP 或 Token 授权方式。
目前 Mock API 支持静态模拟，即基于 API 响应范例的 Mock，暂不支持动态模拟（自定义数据模拟规则）。
功能特性 基于 API 文件数据生成 Mock API。您仅需完善 API 规则及范例，无需额外设置即可使用 Mock API。
Mock API 支持参数校验，并可在请求有误时返回响应错误信息。大大降低 API 使用者在对接 API 时的错误率，方便调试及跟踪。
自定义 Mock API 响应数据。通过修改 API 范例数据，可让每个 API 的模拟数据趋于完美。
每篇文档 Mock API 均有独立域名，并支持 HTTPS / HTTP 双协议。方便统一配置，也方便记忆，地址参考：http://c3wfvv32.</description></item><item><title>mount Unit</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/mount-Unit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/mount-Unit/</guid><description>概述 参考：
Manual(手册)，systemd-mount(5) 张馆长博客,fstab 与 systemd.mount 自动挂载的一点研究和见解 所有以 .mount 结尾的 Unit 都是由 Systemd 控制和监督的文件系统挂载功能。该功能可以代替传统的 /etc/fstab 文件。
张馆长文章 x-systemd.automount 属于 systemd.mount，systemd 造了好多轮子，什么 crontab、网络管理器、日志服务 它都想给接替了。fstab 也是这样，systemd 引入了 .mount 单元这么个东西，用于控制文件系统挂载。
defaults下有auto会被开机挂载，noauto一般是和x-systemd.automount配合使用。而x-systemd.automount属于 systemd.mount，systemd 造了好多轮子，什么 crontab、网络管理器、日志服务 它都想给接替了。fstab 也是这样，systemd 引入了 .mount 单元这么个东西，用于控制文件系统挂载。
其实现在很多发行版都开始慢慢抛弃 fstab 了，先看一个 centos6 在 init 下的 fstab
[root@APP-SRV-001 ~]# cat /etc/fstab # # /etc/fstab # Created by anaconda on Mon Nov 26 22:13:02 2018 # # Accessible filesystems, by reference, are maintained under &amp;#39;/dev/disk&amp;#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # UUID=19698973-561a-4b5b-aded-f6092bd1f341 / ext4 defaults 1 1 UUID=1f808272-972d-416a-af7f-d3c88b16f434 /boot ext4 defaults 1 2 UUID=C6D4-B036 /boot/efi vfat umask=0077,shortname=winnt 0 0 UUID=7877eff3-a174-4cb5-9024-43be4fab35b2 swap swap defaults 0 0 tmpfs /dev/shm tmpfs defaults 0 0 devpts /dev/pts devpts gid=5,mode=620 0 0 sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 下面是 centos7 在 systemd 下的 fstab</description></item><item><title>MySQL 命令行工具</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
mysql 参考：
官方文档，MySQL 程序-客户端程序-mysql mysql 是一个简单的 SQL Shell。 它支持交互和非交互使用。 交互使用时，查询结果以 ASCII 表格式显示。 非交互使用（例如，用作过滤器）时，结果以制表符分隔的格式显示。 可以使用命令选项更改输出格式。
Syntax(语法) mysql [OPTIONS] [DATABASE]
DATABASE # 指定连接 mysql 后要操作的数据库。若不指定，则需要在交互模式下使用 use 指令选择数据库，否则对数据库的操作将会报 No database selected 错误：
mysql&amp;gt; show tables; ERROR 1046 (3D000): No database selected OPTIONS：
-h, &amp;ndash;host &amp;lt;HostName&amp;gt; # 指定要连接的 mysql 主机。如果链接本机 mysql，可以省略。 -P, &amp;ndash;port &amp;lt;PORT&amp;gt; # 指定要连接的 mysql 的端口。默认值：3306 -u, &amp;ndash;user &amp;lt;UserName&amp;gt; # 指定要登录 mysql 的用户名 -p, &amp;ndash;password &amp;lt;PASSWORD&amp;gt; # 使用密码来登录。如果指定要登录 mysql 的用户密码为空，则该选项可省 命令行模式 我们可以通过 mysql db_name &amp;lt;FILE.</description></item><item><title>MySQL 配置文件详解</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
my.cnf [mysqld] skip-grant-tables # 登录时跳过权限检查 设置时区 default-time_zone=&amp;#39;+8:00&amp;#39; ========================== # 开启 binlog log-bin=mysql-bin binlog-format=Row server-id=1 expire_logs_days=7 max_binlog_size=10m binlog https://dev.mysql.com/doc/refman/5.7/en/replication-howto-masterbaseconfig.html</description></item><item><title>MySQL 批量SQL插入性能优化</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E6%89%B9%E9%87%8FSQL%E6%8F%92%E5%85%A5%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/MySQL-%E6%89%B9%E9%87%8FSQL%E6%8F%92%E5%85%A5%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid><description>对于一些数据量较大的系统，数据库面临的问题除了查询效率低下，还有就是数据入库时间长。特别像报表系统，每天花费在数据导入上的时间可能会长达几个小时或十几个小时之久。因此，优化数据库插入性能是很有意义的。
经过对 MySQL InnoDB 的一些性能测试，发现一些可以提高 insert 效率的方法，供大家参考参考。
1、一条 SQL 语句插入多条数据 常用的插入语句如：
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES (&amp;#39;0&amp;#39;, &amp;#39;userid_0&amp;#39;, &amp;#39;content_0&amp;#39;, 0); INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES (&amp;#39;1&amp;#39;, &amp;#39;userid_1&amp;#39;, &amp;#39;content_1&amp;#39;, 1); 修改成：
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES (&amp;#39;0&amp;#39;, &amp;#39;userid_0&amp;#39;, &amp;#39;content_0&amp;#39;, 0), (&amp;#39;1&amp;#39;, &amp;#39;userid_1&amp;#39;, &amp;#39;content_1&amp;#39;, 1); 修改后的插入操作能够提高程序的插入效率。这里第二种 SQL 执行效率高的主要原因是合并后日志量（MySQL 的 binlog 和 innodb 的事务让日志）减少了，降低日志刷盘的数据量和频率，从而提高效率。通过合并 SQL 语句，同时也能减少 SQL 语句解析的次数，减少网络传输的 IO。
这里提供一些测试对比数据，分别是进行单条数据的导入与转化成一条 SQL 语句进行导入，分别测试 1 百、1 千、1 万条数据记录。</description></item><item><title>nerdctl</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/nerdctl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Containerd/Containerd-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/nerdctl/</guid><description>概述 参考：
GitHub 项目，containerd/nerdctl 官方文档，命令参考 https://github.com/containerd/nerdctl/blob/main/docs/command-reference.md Network nerdctl 本身没有像 docker 的 /etc/docker/daemon.json 这种配置文件，而是使用 CNI 的包 netutil 来执行网络相关的请求， CNI 默认有一个名为 nerdctl0 的 bridge 网络设备，都是常量：
pkg/netutil/netutil_unix.go
package netutil const ( DefaultNetworkName = &amp;#34;bridge&amp;#34; DefaultID = 0 DefaultCIDR = &amp;#34;10.4.0.0/24&amp;#34; ) // basicPlugins is used by ConfigListTemplate var basicPlugins = []string{&amp;#34;bridge&amp;#34;, &amp;#34;portmap&amp;#34;, &amp;#34;firewall&amp;#34;, &amp;#34;tuning&amp;#34;} 如果想要像 docker 一样配置网络，则需依赖于 CNI 默认的 /etc/cni/net.d/ 目录中创建配置文件，通常 Containerd 自带的 CNI 配置文件可以在其发布的 Release 中带 cni 名称的包中找到。效果如下：
~]# tee /etc/cni/net.d/10-containerd-net.conflist &amp;lt;&amp;lt;-&amp;#34;EOF&amp;#34; { &amp;#34;cniVersion&amp;#34;: &amp;#34;0.</description></item><item><title>net 包中的 HTTP</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/net-%E5%8C%85%E4%B8%AD%E7%9A%84-HTTP/net-%E5%8C%85%E4%B8%AD%E7%9A%84-HTTP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/net-%E5%8C%85%E4%B8%AD%E7%9A%84-HTTP/net-%E5%8C%85%E4%B8%AD%E7%9A%84-HTTP/</guid><description>概述 参考：
GitHub 项目，DesistDaydream/go-net(学习代码) GoWeb 编程 看云，GoWeb 编程 go 使用 net/http 标准库来实现基本的 web 功能
form(表单) # 描述网页表单的处理 middleware(中间件) # 常用来处理认证等行为 一般的上网过程概述 浏览器本身是一个客户端，当你输入 URL 的时候，首先浏览器会去请求 DNS 服务器，通过 DNS 获取相应的域名对应的 IP，然后通过 IP 地址找到 IP 对应的服务器后，要求建立 TCP 连接，等浏览器发送完 HTTP Request（请求）包后，服务器接收到请求包之后才开始处理请求包，服务器调用自身服务，返回 HTTP Response（响应）包；客户端收到来自服务器的响应后开始渲染这个 Response 包里的主体（body），等收到全部的内容随后断开与该服务器之间的 TCP 连接
Hello World package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net/http&amp;#34; ) // HelloWorld 处理客户端请求 /hello 时的具体逻辑 func HelloWorld(w http.ResponseWriter, req *http.Request) { // 将 Hello DesistDaydream! 这一串字符写入到 Response 中，并响应给客户端 fmt.</description></item><item><title>net 包中的 TCP</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/net-%E5%8C%85%E4%B8%AD%E7%9A%84-TCP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/net-%E5%8C%85%E4%B8%AD%E7%9A%84-TCP/</guid><description>概述 参考：
知乎，TCP 漫谈之 keepalive 和 time_wait TCP 是一个有状态通讯协议，所谓的有状态是指通信过程中通信的双方各自维护连接的状态。
一、TCP keepalive
先简单回顾一下 TCP 连接建立和断开的整个过程。（这里主要考虑主流程，关于丢包、拥塞、窗口、失败重试等情况后面详细讨论。） 首先是客户端发送 syn（Synchronize Sequence Numbers：同步序列编号）包给服务端，告诉服务端我要连接你，syn 包里面主要携带了客户端的 seq 序列号；服务端回发一个 syn+ack，其中 syn 包和客户端原理类似，只不过携带的是服务端的 seq 序列号，ack 包则是确认客户端允许连接；最后客户端再次发送一个 ack 确认接收到服务端的 syn 包。这样客户端和服务端就可以建立连接了。整个流程称为“三次握手”。
建立连接后，客户端或者服务端便可以通过已建立的 socket 连接发送数据，对端接收数据后，便可以通过 ack 确认已经收到数据。数据交换完毕后，通常是客户端便可以发送 FIN 包，告诉另一端我要断开了；另一端先通过 ack 确认收到 FIN 包，然后发送 FIN 包告诉客户端我也关闭了；最后客户端回应 ack 确认连接终止。整个流程成为“四次挥手”。TCP 的性能经常为大家所诟病，除了 TCP+IP 额外的 header 以外，它建立连接需要三次握手，关闭连接需要四次挥手。如果只是发送很少的数据，那么传输的有效数据是非常少的。是不是建立一次连接后续可以继续复用呢？的确可以这样做，但这又带来另一个问题，如果连接一直不释放，端口被占满了咋办。为此引入了今天讨论的第一个话题 TCP keepalive。所谓的 TCP keepalive 是指 TCP 连接建立后会通过 keepalive 的方式一直保持，不会在数据传输完成后立刻中断，而是通过 keepalive 机制检测连接状态。Linux 控制 keepalive 有三个参数：保活时间 net.ipv4.tcp_keepalive_time、保活时间间隔 net.ipv4.tcp_keepalive_intvl、保活探测次数 net.ipv4.tcp_keepalive_probes，默认值分别是 7200 秒（2 小时）、75 秒和 9 次探测。如果使用 TCP 自身的 keepalive 机制，在 Linux 系统中，最少需要经过 2 小时 + 9*75 秒后断开。譬如我们 SSH 登录一台服务器后可以看到这个 TCP 的 keepalive 时间是 2 个小时，并且会在 2 个小时后发送探测包，确认对端是否处于连接状态。 之所以会讨论 TCP 的 keepalive，是因为发现服器上有泄露的 TCP 连接：</description></item><item><title>Netlink</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Netlink/Netlink/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Netlink/Netlink/</guid><description>概述 参考：
Manual(手册), netlink Manual(手册), rtnetlink Wiki, Netlink 内核官方文档，Linux 网络文档 - 通用 Netlink https://wiki.linuxfoundation.org/networking/generic_netlink_howto Netlink 是一个 Linux 内核接口，用于在 内核 与 用户空间进程 之间传输信息。还可以用作两个用户空间进程之间、甚至内核子系统之间的数据通信。说白了，就是一个通过 Socket 实现 IPC 的方式。
Iproute 工具包、keepalived、ethtool 等等 应用程序，很多功能都是基于 Netlink 开发的。
Netlink 由两部分组成：
Rtnetlink 概述 rtnetlink 是 Linux 路由套接字
RTNETLINK 允许读取和更改内核的路由表。它在内核中使用以在各种子系统之间进行通信，尽管此处未记录此使用，并且与用户空间程序通信。可以通过 NetLink_Route 套接字来控制网络路由，IP 地址，链接参数，邻居设置，排队学科，流量类和数据包分类器。它基于NetLink 消息;有关更多信息。
用户空间和内核空间通讯 - netlink 参考：
原文链接：https://e-mailky.github.io/2017-02-14-netlink-user-kernel1 Alan Cox 在内核 1.3 版本的开发阶段最先引入了 Netlink，刚开始时 Netlink 是以 字符驱动接口的方式提供内核与用户空间的双向数据通信；随后，在 2.1 内核开发过程中，Alexey Kuznetsov 将 Netlink 改写成一个更加灵活、且易于扩展的基于消息通信接口，并将其应用到高级路由子系统的基础框架里。 自那时起，Netlink 就成了 Linux 内核子系统和用户态的应用程序通信的主要手段之一。 2001 年，ForCES IETF 委员会正式对 Netlink 进行了标准化的工作。Jamal Hadi Salim 提议将 Netlink 定义成一种用于网络设备的路由引擎组件和其控制管理组件之间通信的协议。不过他的建议 最终没有被采纳，取而代之的是我们今天所看到的格局：Netlink 被设计成一个新的协议域，domain。 Linux 之父托瓦斯曾说过“Linux is evolution, not intelligent design”。 什么意思？就是说，Netlink 也同样遵循了 Linux 的某些设计理念，即没有完整的规范文档，亦没有设计文档。 只有什么？你懂得—“Read the f**king source code”。 当然，本文不是分析 Netlink 在 Linux 上的实现机制，而是就“什么是 Netlink”以及 “如何用好 Netlink”的话题和大家做个分享，只有在遇到问题时才需要去阅读内核源码弄清个所以然。</description></item><item><title>Netlink</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E7%BD%91%E7%BB%9C%E6%A0%88%E6%8E%A7%E5%88%B6/Netlink/Netlink/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E7%BD%91%E7%BB%9C%E6%A0%88%E6%8E%A7%E5%88%B6/Netlink/Netlink/</guid><description>概述 参考：
GitHub 项目，vishvananda/netlink netlink 包为 go 提供了一个简单的 netlink 库。
Netlink 是 Linux 中的用户空间程序用来与内核进行通信的界面。它可以用于添加和删除接口，设置 ip 地址和路由以及配置 ipsec。
Netlink 通信需要提升的权限，因此在大多数情况下，此代码需要以 root 用户身份运行。由于低级 netlink 消息充其量是难以理解的，因此该库试图提供一个以 iproute2 提供的 CLI 为松散建模的 api。ip 链接添加之类的操作将通过类似名称的函数 (例如 AddLink()) 来完成。该库的生命开始于 docker/libcontainer 中的 netlink 功能分支，但经过大量重写以提高可测试性，性能并添加 ipsec xfrm 处理等新功能。
Hello World package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/vishvananda/netlink&amp;#34; ) func main() { // 实例化一个 LinkAttrs,LinkAttrs 包含一个网络设备的绝大部分属性 linkAttrs := netlink.NewLinkAttrs() // 设定 link 的名称 linkAttrs.Name = &amp;#34;br0&amp;#34; // 将实例化的 LinkAttrs 信息赋值给 Bridge 结构体 mybridge := &amp;amp;netlink.</description></item><item><title>Netplan 配置详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Netplan/Netplan-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/Netplan/Netplan-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官网，参考 Netplan 的配置文件使用 YAML 格式。/{lib,etc,run}/netplan/*.yaml 都是 Netplan 程序读取配置文件的路径。
配置文件详解 该 YAML 文件只有一个顶级节点：network: &amp;lt;Object&amp;gt;，其中包括 version、设备类型(例如 ethernets、modems、wifis、birdge 等)、renderer。
version(INT) renderere(STRING) ethernetes(OBJECT) 以太网设备的专用属性
bridge(OBJECT) 桥设备的专用属性
所有设备的通用属性 addresses([]OBJECT) #
dtcp4(BOOL) # 为 IPv4 启用 DHCP。默认值：false
dhcp6(BOOL) # 为 IPv6 启用 DHCP。默认值：false
gateway4 | gateway6(STRING) # 已弃用。使用 routes 字段。
nameservers(OBJECT) # 设置 DNS 服务器和搜索域，用于手动地址配置
routes([]OBJECT) # 为设备配置静态路由；请参阅下面的路由部分。
配置示例 参考：
官网，示例 # This is the network config written by &amp;#39;subiquity&amp;#39; network: ethernets: ens3: addresses: - 172.</description></item><item><title>Network File System</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Network-File-System/Network-File-System/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Network-File-System/Network-File-System/</guid><description>概述 参考：
Wiki, Nework_File_System Network File System(网络文件系统，简称 NFS) 是让客户端通过网络访问不同主机上磁盘里的数据，主要用在类 Unix 系统上实现文件共享的一种方法。 本例演示 CentOS 7 下安装和配置 NFS 的基本步骤。
nfs-ganesha 参考：
GitHub 项目，nfs-ganesha/nfs-ganesha NFS-Ganesha 是一个 NFSv3、v4、v4.1 文件服务器，在大多数 UNIX/Linux 系统上以用户模式运行。
常见用法：
把 Ceph 对象存储转成符合 POSIX 规范的文件系统挂载到 Linux 里 已知问题：
麒麟系统+长城服务器挂载 ceph rgw 后，系统严重卡顿</description></item><item><title>Network Namespace</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/Network-Namespace/Network-Namespace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/Network-Namespace/Network-Namespace/</guid><description>概述 Linux 容器能看见的“网络栈”，实际上是被隔离。在它自己的 Network Namespace 当中的。
而所谓“网络栈”，就包括了：网卡（Network Interface）、回环设备（LoopbackDevice）、路由表(Routing Table)和 iptables 规则。对于一个进程来说，这些要素，其实就构成了它发起和响应网络请求的基本环境。
需要指出的是，作为一个容器，它可以声明直接使用宿主机的网络栈(也就是使用 PID 为 1 进程的网络名称空间)，在这种情况下，这个容器启动后，直接监听的就是宿主机的 80 端口。
像这样直接使用宿主机网络栈的方式，虽然可以为容器提供良好的网络性能，但也会不可避免地引入共享网络资源的问题，比如端口冲突。所以，在大多数情况下，我们都希望容器进程能使用自己 Network Namespace 里的网络栈，即：拥有属于自己的 IP 地址和端口。
这时候，一个显而易见的问题就是：这个被隔离的容器进程，该如何跟其他 Network Namespace 里的容器进程进行交互呢？
为了理解这个问题，其实可以把每一个容器看做一台主机，它们都有一套独立的特殊“网络栈”。
如果想要实现两台主机之间的通信，最直接的办法，就是把它们用一根网线连接起来；而如果你想要实现多台主机之间的通信，那就需要用网线，把它们连接在一台交换机上。
在 Linux 中，能够起到虚拟交换机作用的网络设备，是网桥（Bridge）。它是一个工作在数据链路层（Data Link）的设备，主要功能是根据 MAC 地址学习来将数据包转发到网桥的不同端口（Port）上。
而为了实现上述目的，Docker 项目会默认在宿主机上创建一个名叫 docker0 的网桥，凡是连接在 docker0 网桥上的容器，就可以通过它来进行通信。
可是，我们又该如何把这些容器“连接”到 docker0 网桥上呢？
这时候，我们就需要使用一种名叫 Veth Pair 的虚拟设备了。
Veth Pair 设备的特点是：它被创建出来后，总是以两张虚拟网卡（Veth Peer）的形式成对出现的。并且，从其中一个“网卡”发出的数据包，可以直接出现在与它对应的另一张“网卡”上，哪怕这两个“网卡”在不同的 Network Namespace 里。
这就使得 Veth Pair 常常被用作连接不同 Network Namespace 的“网线”
Network Namespace 介绍 grep -l xxxx /proc/*/mountinfo # 可以查到哪个进程在使用指定的 netns。XXX 为 ip netns 命令查看到的 netns</description></item><item><title>network-scripts</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/network-scripts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/network-scripts/</guid><description>概述 参考：
RedHat 官方文档，生产文档-RedHatEnterpriseLinux-6-部署指南-11.2.接口配置文件 /usr/share/doc/initscripts-XX/sysconfig.txt中的 ifcfg-&amp;lt;interface-name&amp;gt; 部分 Manual(手册),nm-settings-ifcfg-rh(5) RedHad 相关发行版的网络配置通过一系列脚本实现，随着时代的发展，已经逐渐启用，并由 NetworkManager 取代，NetworkManager 还单独出了一个适用于 RedHad 发行版的插件，名为 nm-setting-ifcfg-rh。这样，NetworkManager 可以将原本的配置目录中文件的格式，转变为适应 RedHad 的格式，并将配置文件保存到 /etc/sysconfig/network-scripts/ 目录下。
关联文件 /etc/sysconfig/ # 全局
./network # 全局网络配置 ./network-scripts/ # 曾经是网络配置脚本文件所在目录。CentOS 8 以后，移除了所有脚本，只用来为网络配置程序提供网络设备的配置文件 ./ifcfg-INTERFACE # 名为 INTERFACE 网络设备配置文件。通常情况下，INTERFACE 的值通常与配置文件中 DEVICE 指令的值相同。 ./route-INTERFACE # IPv4 静态路由配置文件。INTERFACE 为网络设备名称，该路由条目仅对名为 INTERFACE 的网络设备起作用 ./route6-INTERFACE # IPv6 静态路由配置文件。INTERFACE 为网络设备名称，该路由条目仅对名为 INTERFACE 的网络设备起作用 ./rule-INTERFACE # 定义内核将流量路由到特定路由表的 IPv4 源网络规则。 ./rule6-INTERFACE # 定义内核将流量路由到特定路由表的 IPv6 源网络规则。 ./networking/* # 注意：在 RedHat 6 文档中表示，/etc/sysconfig/networking/ 目录由现在已经弃用的网络管理工具(system-config-network) 管理，这个内容不应该手动编辑。推荐使用 NetworkManager。并且在后续的版本中， NetworkManager 也接管了这些文件 /etc/iproute2/rt_tables # 如果您想要使用名称而不是数字来引用特定的路由表，这个文件会定义映射映射。</description></item><item><title>NetworkManager 配置详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/NetworkManager-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/NetworkManager-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
Manual(手册),NetworkManager.conf(5) 在 GNOME 开发者中心官网中，也可以查到 Manual https://wiki.gnome.org/Projects/NetworkManager/DNS https://cloud.tencent.com/developer/article/1710514 NetworkManager 的配置文件是 INI 格式的，由 Sections(部分) 和 Key/Value Pairs(键/值对) 组成。
可用的 Sections 有如下几种：
main # keyfile # 用于配置 keyfile 插件。通常只在不使用任何特定 Linux 发行版的插件时才进行配置。 ifupdown # logging # 控制 NetworkManager 的日志记录。此处的任何设置都被 &amp;ndash;log-level 和 &amp;ndash;log-domains 命令行选项覆盖。 connection # device # connectivity # global-dns # global-dns-domain # .config # main 部分 dns=&amp;lt;MODE&amp;gt; # 设置 DNS 处理模式。 可用的模式有如下几种：
default # dnsmasq # systemd-resolved # unbound # none # NetworkManager 程序不会修改 resovl.</description></item><item><title>NetworkPolicy 网络策略</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/NetworkPolicy-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/NetworkPolicy-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</guid><description>如果想要正常使用 NetworkPolicy 对象，则集群的网路插件必须要支持该功能
使用 NetworkPolicy 对象来定义网络策略(注意：该定义的网络策略只能适用于某个 namesapce 下的 Pod，可以在 metadata 中定义生效的 namespace)
一个网络策略中包含两中类型的规则，规则用于控制数据流量(Traffic)，
ingress # 入口(入站)规则，列出所选择的 Pod，把入口规则应用其上
port，定义允许还是拒绝哪些端口，ingress 规则中为，从外面来的可以从自己哪个端口进来 from # ingress 定义 from(目标过来的规则，即从哪来的可以入)
ipBlock # 定义从哪来的 IP 段可以进来
except # 定义完 ipBlock 后，定义 IP 段内的某些事不能进来 namespaceSelector # 定义来自哪些 namesapce 的可以进来
podSelector # 定义来自哪些 Pod 的可以进来
egress # 出口(出站)规则，列出所选择的 Pod，把出口规则应用其上
port，定义允许还是拒绝哪些端口，egress 规则中，到哪的端口可以出去 to # egress 定义 to(到目标的规则，即到哪的可以出)
ipBlock # 定义到哪的 IP 段可以出去
except # 定义完 ipBlock 后，定义 IP 段内的某些事不能出去 namespaceSelector # 定义到哪些 namesapce 的可以出去</description></item><item><title>Neutron 工作原理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/Neutron-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/Neutron-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</guid><description>概述 neutron 是 openstack 的一个重要模块，也是比较难以理解和 debug 的模块之一。
我这里安装如图安装了经典的三个节点的 Havana 的 Openstack
图 1
分三个网络：
External Network/API Network，这个网络是连接外网的，无论是用户调用 Openstack 的 API，还是创建出来的虚拟机要访问外网，或者外网要 ssh 到虚拟机，都需要通过这个网络
Data Network，数据网络，虚拟机之间的数据传输通过这个网络来进行，比如一个虚拟机要连接另一个虚拟机，虚拟机要连接虚拟的路由都是通过这个网络来进行
Management Network，管理网络，Openstack 各个模块之间的交互，连接数据库，连接 Message Queue 都是通过这个网络来。
将这三个网络隔离，一方面是安全的原因，在虚拟机里面，无论采取什么手段，干扰的都紧紧是 Data Network，都不可能访问到我的数据库，一方面是流量分离，Management Network 的流量不是很大的，而且一般都会比较优雅的使用，而 Data network 和 External Network 就需要进行流量控制的策略。
我的这个网络结构有些奇怪，除了 Controller 节点是两张网卡之外，其他的都多了一张网卡连接到 external network，这个网卡是用来做 apt-get 的，因为 Compute Node 按说是没有网卡连接到外网的，为了 apt-get 添加了 eth0，Network Node 虽然有一个网卡 eth1 是连接外网的，然而在 neutron 配置好之前，这个网卡通常是没有 IP 的，为了 apt-get 也添加了 eth0，有人说可以通过添加 route 规则都通过 Controller 连接外网，但是对于初学的人，这个样比较容易操作。
neutron 是用来创建虚拟网络的，所谓虚拟网络，就是虚拟机启动的时候会有一个虚拟网卡，虚拟网卡会连接到虚拟的 switch 上，虚拟的 switch 连接到虚拟的 router 上，虚拟的 router 最终和物理网卡联通，从而虚拟网络和物理网络联通起来。</description></item><item><title>Neutron 架构</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/Neutron-%E6%9E%B6%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/Neutron-%E6%9E%B6%E6%9E%84/</guid><description>概述 参考：
官方文档：https://docs.openstack.org/neutron/latest/admin/intro-os-networking.html Neutron Server 接收请求。对外提供 OpenStack 网络 API，接收请求，并调用 Plugin 处理请求。 Plugins 插件/Agent 代理 实现请求。 实现 OpenStack 网络的主要组件。用来创建各种网络设备和配置规则 Plugins 用来处理 Neutron Server 发来的请求，维护 OpenStack 逻辑网络状态， 并调用 Agent 处理请求。 Agent 用来处理对应 Plugin 的请求，并在宿主机上创建相应的网络设备以及生成网络规则。 Plugins 与 Agent 一般都是配套使用。比如 OVS Plugin 需要 OVS Agent。 Queue 队列 组件间通信。Neutron Server，Plugin 和 Agent 之间通过 Messaging Queue 通信和调用。 Database 数据库 保存网络状态。接收 Plugins 的信息，保存 OpenStack 的网络状态信息，包括 Network, Subnet, Port, Router 等。 额外说明：
plugin 解决的是 What 的问题，即网络要配置成什么样子？而至于如何配置 How 的工作则交由 agent 完成。 plugin 的一个主要的职责是在数据库中维护 Neutron 网络的状态信息，这就造成一个问题：所有 network provider 的 plugin 都要编写一套非常类似的数据库访问代码。为了解决这个问题，Neutron 在 H 版本实现了一个 ML2（Modular Layer 2）plugin，对 plugin 的功能进行抽象和封装。有了 ML2 plugin，各种 network provider 无需开发自己的 plugin，只需要针对 ML2 开发相应的 driver 就可以了，工作量和难度都大大减少。 Neutron Server Neutron Server 提供了一个公开 Neutron API 的 Web 服务器，并将所有 Web 服务调用传递给 Neutron 插件进行处理。</description></item><item><title>NFS 部署</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Network-File-System/NFS-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Network-File-System/NFS-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
Ubuntu 官方文档 服务端部署 安装 NFS Server 通过 Linux 的包管理器部署 CentOS
yum install -y nfs-utils Ubuntu
sudo apt install nfs-kernel-server 配置并启动 NFS 服务 配置共享目录 服务启动之后，我们在服务端配置一个共享目录
mkdir /data chmod 755 /data 为 NFS 配置共享目录
export NETWORK=&amp;#34;172.38.180.218/24&amp;#34; cat &amp;gt; /etc/exports &amp;lt;&amp;lt;EOF /data/ ${NETWORK}(rw,sync,no_root_squash,no_all_squash) EOF /data # 共享目录位置。 172.19.42.0/24 # 客户端 IP 范围，* 代表所有，即没有限制。 rw # 权限设置，可读可写。 sync # 同步共享目录。 no_root_squash # 可以使用 root 授权。 no_all_squash # 可以使用普通用户授权。 启动 nfs CentOS
systemctl enable nfs --now Ubuntu</description></item><item><title>Nginx</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Nginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/Nginx/</guid><description>概述 分为两个版本
K8S 社区版 Nginx Ingress Controller # https://github.com/kubernetes/ingress-nginx Nginx 官网版 Nginx Ingress Controller # https://github.com/nginxinc/kubernetes-ingress 部署 版本支持矩阵: https://github.com/kubernetes/ingress-nginx#supported-versions-table
k8s 社区版部署方式 参考：
官方文档，部署-安装指南-裸金属集群(就是通过纯 Manifests 文件部署) 官方文档，部署-安装指南-快速开始(直接就是 Helm 安装) 注意：
从 v1.0.0 版本开始，仅支持 Kubernetes 版本 &amp;gt;= v1.19 ，因为从 v1.0.0 版本开始，删除了对 networking.k8s.io/v1beta 资源的支持。 详见：公众号-CNCF，更新 NGINX-Ingress 以使用稳定的 Ingress API 从 v1.3.0 版本开始，仅支持 Kubernetes 版本 &amp;gt;= v1.20。 详见：公众号-MoeLove，K8S 生态周报| Kubernetes Ingress-NGINX 功能冻结前最后一个版本发布 为了能兼容 Kubernetes 的更高版本，所以我们将 controller 中用于选举的机制修改成了使用 Lease API 的方式，而不再是原先的 configmap 的方式。其实在 Kubernetes Ingress-NGINX v1.</description></item><item><title>Nginx 优化</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E4%BC%98%E5%8C%96/</guid><description>性能优化的相关配置 work_processes NUM; # 常用，指定 work 线程个数，通常应该少于 cpu 物理核心数，设为 auto 为自动判断 work_cpu_affinity CpuMask; # 常用，设定 cpu 掩码，用于绑定给 nginx 专用的 cpu 数 timer_resolution Num; # 计时器解析度，降低此值，可提高性能 worker_priority NUM; # 设定优先级，即 worker 线程的 nice 值 事件相关配置 worker_connections NUM; # 常用，指定每个 worker 线程所能处理的最大并发连接数 accept_mutex on|off; # 调度用户请求至 worker 线程时使用的负载均衡锁。on 是让多个 worker 轮流的，序列化地响应新请求 lock_file /PATH/FILE; # 指定 accept_mutex 开启后用到的锁文件路径 用于调试、定位问题的配置 daemon on|off； # 是否以守护进程方式运行 nginx，调试时设置为 off master_process on|off； # 是否以 master/worker 模式来运行 ngins，调试时可以设置为 off 优化 Nginx 数据包头缓存 1）优化前，使用脚本测试长头部请求是否能获得响应</description></item><item><title>Nginx 作为静态资源服务器配置示例</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/Nginx-%E4%BD%9C%E4%B8%BA%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/Nginx-%E4%BD%9C%E4%B8%BA%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/</guid><description>Nginx 的 location 里面的 root、alias 的使用技巧与区别 知乎：https://zhuanlan.zhihu.com/p/379076598
location Nginx 里面的 location，可以针对一个特殊的 URI 路径进行单独的设置。
location / { root /tongfu.net/web/static; } 在 location 块里面可以单独设置映射目录、重写逻辑、默认文档等等。
location / { root /tongfu.net/web/download; index index.htm; } location ~ ^\/download\/.*\.(zip|rar|tgz|gz)$ { rewrite ^\/download\/(.*)$ /downloadValidation.php?$1; } root Nginx 里面的 root 参数用来指定映射根目录，末尾不加“/”。
主机默认目录 直接在 server 里面设置 root 就是设置主机的根目录。
server { root /tongfu.net/web/static; } 匹配 URI 目录 在 location 里面设置 root 就是设置匹配 URI 的根目录。
下面的例子里如果访问 http://localhost/icon/abc.png 网址，映射到的服务器路径是 /tongfu.net/web/icons**/icon/abc.png**。
location /icon/ { root /tongfu.</description></item><item><title>nmcli connection 子命令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/nmcli-connection-%E5%AD%90%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/nmcli-connection-%E5%AD%90%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
Manual(手册)，nmcli(1) - Connection Management Commands 红帽官方文档，RedHat7 - 网络指南 - 使用 nmcli 创建带有 VLAN 的 bond 并作为 Bridge 的从设备 nmcli connection {show | up | down | modify | add | edit | clone | delete | monitor | reload | load | import | export} [ARGUMENTS&amp;hellip;]
up | down # 启动 | 停止连接 nmcli connection up [[id | uuid | path] &amp;lt;ID&amp;gt;] [ifname &amp;lt;ifname&amp;gt;] [ap &amp;lt;BSSID&amp;gt;] [passwd-file &amp;lt;file with passwords&amp;gt;] # 启动连接</description></item><item><title>nmcli 命令行工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/nmcli-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/NetworkManager/nmcli-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
RedHat7官方文档，网络指南-使用 nmcli 配置 IP 网络 Manual(手册)，nmcli(1) nmcli 用于 NetworkManager 的命令行工具
Syntax(语法) nmcli [OPTIONS] OBJECT { COMMAND | help }
OBJECT 和 COMMAND 可以用全称也可以用简称，最少可以只用一个字母
OPTIONS
-a, &amp;ndash;ask ask for missing parameters -c, &amp;ndash;colors auto|yes|no whether to use colors in output -e, &amp;ndash;escape yes|no escape columns separators in values -f, &amp;ndash;fields &amp;lt;FIELD,&amp;hellip;&amp;gt;|all|common # 指定要输出的字段，FIELD 可以是 任意 setting -g, &amp;ndash;get-values &amp;lt;field,&amp;hellip;&amp;gt;|all|common shortcut for -m tabular -t -f -h, &amp;ndash;help print this help -m, &amp;ndash;mode &amp;lt;tabular|multiline&amp;gt; # 指定输出模式,tabular 输出为表格样式，multiline 是多行样式。 nmcli con show # 默认为表格样式 nmcli con show DEV # 默认为多行样式 -o, &amp;ndash;overview overview mode -p, &amp;ndash;pretty # 美化输出，以连接中的 setting 分段落展示 -s, &amp;ndash;show-secrets allow displaying passwords -t, &amp;ndash;terse # 简洁的输出 -v, &amp;ndash;version show program version -w, &amp;ndash;wait &amp;lt;seconds&amp;gt; set timeout waiting for finishing operations OBJECT</description></item><item><title>Node Exporter</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Node-Exporter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Node-Exporter/</guid><description>概述 参考：
GitHub 项目，prometheus/node_exporter Node Exporter 用于收集服务器的 metrics，比如 内存、cpu、磁盘、I/O、电源、etc. 。Node Exporter 将采集各种指标的代码逻辑抽象称为 Node 的 Collector(采集器)。每类指标都对应一个 Collector，比如 cpu 采集器、meminfo 采集器、etc. 这些名称通常都能直观得看到想要采集的指标是什么
node_exporter 默认监听在 9100 端口上。
Prometheus Server 抓取 metrics 的位置 http://IP:9100/metrics # 获取 node_exporter 所在主机的 metrics 信息
Node Exporter 部署 二进制文件安装 node_exporter 为监控服务器 CPU、内存、磁盘、I/O 等信息，首先需要安装 node_exporter。node_exporter 的作用是服务器数据收集。
下载 node_exporter，过程基本与使用 prometheus 程序一样。下载页面在此 export VERSION=&amp;#34;1.6.0&amp;#34; wget https://github.com/prometheus/node_exporter/releases/download/v${VERSION}/node_exporter-${VERSION}.linux-amd64.tar.gz # 解压 mkdir -p /usr/local/prometheus/node_exporter tar -zxvf node_exporter-${VERSION}.linux-amd64.tar.gz -C /usr/local/prometheus/node_exporter --strip-components=1 创建 node_exporter 的 systemd 服务，在这里可以看到官方提供的 systemd 样例 tee /usr/lib/systemd/system/node-exporter.</description></item><item><title>Node 资源预留与 Pod 驱逐</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/Node-%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99%E4%B8%8E-Pod-%E9%A9%B1%E9%80%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/Node-%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99%E4%B8%8E-Pod-%E9%A9%B1%E9%80%90/</guid><description>概述 参考：
原文：SegmentFault(思否)，k8s 节点资源预留与 pod 驱逐 节点资源管理 为什么 K8S 的节点上的资源会被 pod 和系统进程所使用，如果默认什么都不配置，那么节点上的全部资源都是可以分配给 pod 使用的，系统进程本身没有保障，这样做很危险：
集群雪崩：如果节点上调度了大量 pod，且 pod 没有合理的 limit 限制，节点资源将被耗尽，sshd、kubelet 等进程 OOM，节点变成 not ready 状态，pod 重新继续调度到其他节点，新节点也被打挂，引起集群雪崩。 系统进程异常：就算 pod 设置了 limit，但如果机器遇到资源不足，系统进程如 docker 没有资源保障，会频繁 OOM，或者进程 hang 住无响应，虽然能运行，但容器会反复出问题 节点资源主要分为两类：
可压缩资源：如 CPU，即使 cpu 超配，也可以划分时间片运行，只是运行变慢，进程不会挂。 不可压缩资源：Memory/Storage，内存不同于 CPU，系统内存不足时，会触发 OOM 杀死进程，按照 oom score 来确定先 kill 谁，oom_score_adj 值越高，被 kill 的优先级越高。 oom 分数： 所以，OOM 的优先级如下：
BestEffort Pod &amp;gt; Burstable Pod &amp;gt; 其它进程 &amp;gt; Guaranteed Pod &amp;gt; kubelet/docker 等 &amp;gt; sshd 等进程 因此需要对节点的内存等资源进行配置，以保证节点核心进程运行正常。</description></item><item><title>NSQ 消息队列</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/NSQ-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/NSQ-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid><description>概述 参考：
GitHub 项目，nsqio/nsq 官网</description></item><item><title>ObjectMeta</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/ObjectMeta/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/Common-Definitions%E9%80%9A%E7%94%A8%E5%AE%9A%E4%B9%89/ObjectMeta/</guid><description>概述 参考：
官方文档，参考-KubernetesAPI-通用定义-ObjectMeta ObjectMeta 是所有持久化资源必须具有的元数据信息，也就是每个对象所具有的元数据信息。
基本字段 name(STRING) Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names
generateName (string) GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided.</description></item><item><title>OCI Image 规范</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/OCI-Image-%E8%A7%84%E8%8C%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/OCI-Image-%E8%A7%84%E8%8C%83/</guid><description>概述 参考：
GitHub 项目，opencontainers/image-spec/spec.md 思否大佬 https://mp.weixin.qq.com/s/8wAv87DkJjE6fVEEmoQ60Q https://blog.k8s.li/Exploring-container-image.html OCI Image 规范的目的，是为了让其他人按照规范创建交互工具，这个工具应该可以 building(构建)、transporting(传输)、running(运行) 一个容器镜像。
一个 OCI Image 应该由一个 Image Manifest、一个 Image Index(可选)、一组文件系统层、一个配置文件 组成。
本质上，镜像的每一层就是一个一个的 tar.gz 的文件，当各种容器工具 pull 镜像时，会根据各种元数据文件，获取到这些 tar.gz 文件，下载到本地，并根据自身的实现解压他们。
OCI Image 规范的组件 前文所描述的组成 OCI Image 规范的多个组成部分，又被细分为如下 Components(组件)：
Image Layout # 镜像内容的文件系统布局。说白了，镜像的主要内容就在这里。 Image Manifest # 描述构成容器镜像所具有的组件的文件。比如这个镜像有哪些 layer，额外的 annotation 信息。manifest 文件中保存了很多和当前平台有关的信息 Image Configuration # 一个文档，该文档确定适用于转换为 runtime bundle 运行时包的映像的层顺序和配置。保存了文件系统的层级信息（每个层级的 hash 值，以及历史信息），以及容器运行时需要的一些信息（比如环境变量、工作目录、命令参数、mount 列表），指定了镜像在某个特定平台和系统的配置。比较接近我们使用 docker inspect 看到的内容 Image Index # 带注释的图像清单索引。指向不同平台的 manifest 文件，这个文件能保证一个镜像可以跨平台使用，每个平台拥有不同的 manifest 文件，使用 index 作为索引 Filesystem Layer changeset # 描述容器文件系统的变更集。以 layer 保存的文件系统，每个 layer 保存了和上层之间变化的部分，layer 应该保存哪些文件，怎么表示增加、修改和删除的文件等 Conversion # 描述此翻译应如何发生。a document describing how this translation should occur Descriptor # 描述所引用内容的类型，元数据和内容地址的引用。a reference that describes the type, metadata and content address of referenced content Future versions of this specification may include the following OPTIONAL features:</description></item><item><title>OCI Runtime 规范</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/OCI-Runtime-%E8%A7%84%E8%8C%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/OCI-Runtime-%E8%A7%84%E8%8C%83/</guid><description>概述 参考：
GitHub 项目，opencontainers/runtime-spec/spec.md GitHub 项目，opencontainers/runtime-tools 思否大佬 OCI Runtime 规范用来指定一个 Container 的配置、执行环境和生命周期。
容器的配置被指定为 config.json ，并详细说明了可以创建容器的字段。指定执行环境是为了确保容器内运行的应用程序在运行时之间具有一致的环境，以及为容器的生命周期定义的常见操作。
由于容器运行起来，需要一个运行环境，比如是运行在 linux 上、还是 windows 上；所以，OCI Runtime 标准，会根据不同的平台，制定不同的规范。现阶段有 4 中平台规范。这点是根 OCI Image 规范不太一样的地方。
linux：runtime.md，config.md，config-linux.md 和 runtime-linux.md。 solaris：runtime.md，config.md 和 config-solaris.md。 windows：runtime.md，config.md 和 config-windows.md。 vm：runtime.md，config.md 和 config-vm.md。 由于我们日常使用 linux，所以下面就只研究 linux 平台的 OCI Runtime 规范
runtime 规范有如下几个，所有人必须遵守该规范来使用 runtime ：
Filesystem Bundle # 文件系统捆绑。bundle 是以某种方式组织的一组文件，包含了容器所需要的所有信息，有了这个 bundle 后，符合 runtime 标准的程序(e.g.runc)就可以根据 bundle 启动容器了(哪怕没有 docker，也可以启动一个容器)。 Runtime and Lifecycle # 使用一个 runtime 创建的容器实体必须能够对同一容器使用本规范中定义的操作。 Linux-specific Runtime and Lifecycle # 这是关于 linux 平台的 Runtime 与 Lifecycle Configuration # Configuration 包含对容器执行标准操作(比如 create、start、stop 等)所必须的元数据。这包括要运行的过程、要注入的环境变量、要使用的沙盒功能等等。不同平台(linux、window 等)，有不同的规范。 Linux-specific configuration # 这是关于 linux 平台的 Configuration Filesystem Bundle 官方详解：https://github.</description></item><item><title>Open Containers Initiative(开放容器倡议)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/Open-Containers-Initiative%E5%BC%80%E6%94%BE%E5%AE%B9%E5%99%A8%E5%80%A1%E8%AE%AE/</guid><description>概述 参考：
OCI 官网 GitHub 组织，OpenContainers segmentfault，《走进 docker》系列文章 Open Containers Initiative(开放容器倡议，简称 OCI) 是一个轻量级的，开放的治理结构（项目），由 Linux Foundation 主持成立，其明确目的是围绕 Container 镜像格式和运行时创建开放的行业标准。OCI 由 Docker，CoreOS 和其他容器行业领导者于 2015 年 6 月 22 日启动。
OCI 公有如下几个个规范：
一开始有两个
Image-spec(镜像规范) # 容器镜像所包含的内容以及格式都遵循统一的格式标准，由 OCI 负责维护 OCI Image 规范 Runtime-spec(运行时规范) # 容器运行时的内容以及格式都遵循统一的格式标准，由 OCI 负责维护 OCI Runtime 规范 后来新加的一个
Distribution-spec(分发规范) # 在所有企业、各人在构建镜像、运行容器时，都应该遵守 OCI 标准，比如想用 docker 工具构建一个镜像，那么构建出来的镜像规范，必须符合 OCI 标准。其他类似 docker 的工具同理。如果想自己开发一个构建镜像的工具或者运行容器的运行时，都需要符合 OCI 的标准。这样大家都遵守同一套规范，才有利于技术的发展。</description></item><item><title>OpenAPI Tools</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/OpenAPI-Tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/OpenAPI-Tools/</guid><description>参考：OpenAPI Generator</description></item><item><title>OpenAPI 格式</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/OpenAPI-%E6%A0%BC%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/OpenAPI-%E6%A0%BC%E5%BC%8F/</guid><description>参考：官方 v3.0.3 版本文档
根字段 参考：官方文档
openapi: &amp;lt;STRING&amp;gt; # 必须的。This string MUST be the semantic version number of the OpenAPI Specification version that the OpenAPI document uses. The openapi field SHOULD be used by tooling specifications and clients to interpret the OpenAPI document. This is not related to the API info.version string. info: &amp;lt;Object&amp;gt; # 必须的。Provides metadata about the API. The metadata MAY be used by tooling as required. servers([]Object) # 一组可用的服务器，用于提供到目标服务器的连接信息。当我们测试 API 时，将会连接其中一个。如果未提供 servers 属性或为空数组，则默认值为 URL 值为/的服务器对象。 paths: &amp;lt;Object&amp;gt; # 必须的。API 的可用路径及其操作。文档中内容最多的字段 components: &amp;lt;Object&amp;gt; # An element to hold various schemas for the specification.</description></item><item><title>OpenCV-Python</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/OpenCV-Python/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/OpenCV-Python/</guid><description>概述 参考：
GitHub 项目，opencv/opencv-python OpenCV-Python 4.x 官方教程 OpenCV-Python 是一个旨在解决计算机视觉问题的 Python 库。
OpenCV-Python 利用高度优化的 NumPy 库进行数值操作，其语法类似于 MATLAB。所有的 OpenCV 数组结构都会被转换为 Numpy 数组。这也使得集成其他使用 Numpy 的库，如 SciPy 和 Matplotlib 更容易。
安装 参考：
OpenCV-Python 4.x 官方文档，在 Windows 上安装 OpenCV-Python pip install opencv-python 图像处理 参考：
官方文档，OpenCV-Python 教程-核心业务-图像的基本操作 官方文档，OpenCV-Python 教程-OpenCV 中的图像处理 Hello World 参考：
官方文档，OpenCV-Python 教程-OpenCV 中的 Gui 功能-图像入门 import sys import cv2 if __name__ == &amp;#34;__main__&amp;#34;: # imread() 读取图片，并将图片实例化为一个 Mat 对象 # 可以接收参数以指定我们想要的图像格式 # - IMREAD_COLOR 以 BGR 8 位格式加载图像。这是此处使用的默认值。 # - IMREAD_UNCHANGED 按原样加载图像（包括 alpha 通道，如果存在）。其实就是将图片变为黑白的了 # - IMREAD_GRAYSCALE 将图像作为强度加载 # image = cv2.</description></item><item><title>OpenStack Networking 介绍</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/OpenStack-Networking-%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/OpenStack-Networking-%E4%BB%8B%E7%BB%8D/</guid><description>概述 参考：
传统的网络管理方式很大程度上依赖于管理员手工配置和维护各种网络硬件设备；而云环境下的网络已经变得非常复杂，特别是在多租户场景里，用户随时都可能需要创建、修改和删除网络，网络的连通性和隔离不已经太可能通过手工配置来保证了。
如何快速响应业务的需求对网络管理提出了更高的要求。传统的网络管理方式已经很难胜任这项工作，而“软件定义网络（software-defined networking, SDN）”所具有的灵活性和自动化优势使其成为云时代网络管理的主流。
Neutron 的设计目标是实现“网络即服务（Networking as a Service）”。为了达到这一目标，在设计上遵循了基于 SDN 实现网络虚拟化的原则，在实现上充分利用了 Linux 系统上的各种网络相关的技术。
所以！在学习和理解 OpenStack Network 的概念时，要与虚拟机的概念分开。Neutron 仅仅负责 SDN，也就是创建网络拓扑，拓扑中有多少交换机、路由器、都是怎么连接的。网络拓扑构建完毕后，再决定 VM 如何接入该 SDN 网络中，以及使用什么方式来接入。
OpenStack Networking 介绍 参考：
官方文档：https://docs.openstack.org/neutron/latest/admin/index.html 名为 Neutron 的服务套件实现了 OpenStack 的网络功能。可以通过 Neutron 创建和管理其他 OpenStack 组件可以使用的 Network Object(网路对象)。例如 networks、subnets、ports 等。
Neutron 管理的 Network 对象 openstack 网络管理着以下几个核心对象。这几个对象在 web 界面创建网络时也会用到。这些对象从上到下是包含的概念，Network 包含 subnet，subnet 里包含 port
Network # 网络。是一个隔离的二层广播域，不同的 network 之间在二层上是隔离的。network 必须属于某个 Project(有时候也叫租户 tenant)。network 支持多种类型每种网络类型，由 ML2 中的 Type Drivers 管理。 local # local 网络中的实例智能与同一节点上同一网络中的实例通信 flat # flat 网络中的实例能与位于同一网络的实例通信，并且可以跨越多个节点 vlan # vlan 是一个二层的广播域，同一 vlan 中的实例可以通信，不同 vlan 种的实例需要通过 router 通信。vlan 中的实例可以跨节点通信、 vxlan # 比 vlan 更好的技术 gre # 与 vxlan 类似的一种 overlay 网络。主要区别在于使用 IP 包而非 UDP 进行封装。 SubNet # 子网。是一个 IPv4 或者 IPv6 地址段，创建的 instance 就从 subnet 中获取 IP，每个 subnet 需要定义 IP 地址范围和掩码 注意： 在不同 network 中的 subnet 可以一样 在相同 network 中的 subnet 不可以一样 DHCP # 子网中可以创建 DHCP 服务，当启用 DHCP 服务时，会创建一个 tap 设备连接到某 bridge 上，来与子网所在的网络通信 Port # 端口 可以当做虚拟交换机的一个端口，创建 port 时，会给 port 分配 MAC 和 IP，当 instance 绑定到 port 时，会自动在 instance 上创建一个网卡，并获取 port 的 MAC 和 IP。如果不启用 DHCP 服务，则仅能获取 MAC，而无法获取 IP，instace 中的网卡 ip 还需要手动添加 注意：openstack 创建的 instance 本身并没有网卡，instance 中的网卡是通过 neutron 来添加的，而添加方式就是绑定某个 network 中 subnet 里的 port。绑定成功后，在 instance 中即可看到网卡设备。 Project，Network，Subnet，Port 和 VIF 之间关系。(VIF 指的是 instance 的网卡)</description></item><item><title>Operator API</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/Operator-API/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/Operator-API/</guid><description>参考：GitHub 文档</description></item><item><title>ORM</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/ORM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/ORM/</guid><description>概述 参考：
Wiki, Object–relational mapping C 语言中文网，ORM 是什么 B 站-哔哩哔哩技术，如何用 go 实现一个 ORM（为什么需要 ORM） Object Relational Mapping(对象关系映射，简称 ORM) 是一种用于在关系数据库和面向对象变成语言之间转换数据的编程技术。解决了代码和关系型数据库之间的数据交互问题。这实际上创建了一个可以在编程语言中使用的虚拟对象数据库。
为什么需要 ORM 直接使用 database/sql 的痛点：
首先看看用 database/sql 如何查询数据库。
我们用 user 表来做例子，一般的工作流程是先做技术方案，其中排在比较前面的是数据库表的设计，大部分公司应该有严格的数据库权限控制，不会给线上程序使用比较危险的操作权限，比如创建删除数据库，表，删除数据等。
表结构如下：
CREATE TABLE `user` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &amp;#39;id&amp;#39;, `name` varchar(100) NOT NULL COMMENT &amp;#39;名称&amp;#39;, `age` int(11) NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;年龄&amp;#39;, `ctime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &amp;#39;创建时间&amp;#39;, `mtime` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &amp;#39;更新时间&amp;#39;, PRIMARY KEY (`id`), ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 首先我们要写出和表结构对应的结构体 User，如果你足够勤奋和努力，相应的 json tag 和注释都可以写上，这个过程无聊且重复，因为在设计表结构的时候你已经写过一遍了。</description></item><item><title>Other Exporter</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Other-Exporter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Other-Exporter/</guid><description>概述 官方推荐的一些第三方 exporter: https://prometheus.io/docs/instrumenting/exporters/
process-exporter: 采集进程指标
https://github.com/ncabatoff/process-exporter Process Exporter 参考：
GitHub 项目，ncabatoff/process-exporter https://mp.weixin.qq.com/s/sbnTByKJYFKQrvnU_iPnZA process_names 下的数组定义进程组名称及该进程组的匹配条件，一共 3 个匹配方式
comm # 与 /proc/${pid}/stat 中第二个字段进行匹配 exe # cmdline # 与进程的所有参数进行匹配 process_names: # comm is the second field of /proc/&amp;lt;pid&amp;gt;/stat minus parens. # It is the base executable name, truncated at 15 chars. # It cannot be modified by the program, unlike exe. - comm: - bash # exe is argv[0]. If no slashes, only basename of argv[0] need match.</description></item><item><title>panic: send on closed channel 解法</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/panic_-send-on-closed-channel-%E8%A7%A3%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/panic_-send-on-closed-channel-%E8%A7%A3%E6%B3%95/</guid><description>golang 为什么没有判断 close 的接口？ - 知乎
更多干货，关注公众号：奇伢云存储。原创不易，谢谢大家支持。
golang 为什么没有判断 close 的接口？ 关闭 channel 究竟做了什么？ closechan 一个判断 chan 是否 close 的函数 思考方法一：通过 “写”chan 实现 思考方法二：通过 “读”chan 实现 chan close 原则 其实并不需要 isChanClose 函数 !!! 怎么优雅关闭 chan ？ 方法一：panic-recover 方法二：sync.Once 方法三：事件同步来解决 总结 golang 为什么没有判断 close 的接口？ 相信大家初学 golang chan 的时候应该都遇到过 &amp;ldquo;send on closed channel&amp;rdquo; 的 panic 。这个 panic 是当你意图往一个已经 close 的 channel 里面投递元素的时候触发。那么你当你第一次遇到这个问题是否想过 channel 是否能提供一个接口方法来判断是否已经 close 了？我想过这个问题，但是把 chan 的源代码翻了个遍没有找到。为什么？
我先 hold 这个问题，我们捋一下跟 channel close 相关的事情，主要思考到 3 个问题：</description></item><item><title>PID Namespace</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/PID-Namespace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/PID-Namespace/</guid><description>概述 PID namespace 用来隔离进程的 PID 空间，使得不同 PID namespace 里的进程 PID 可以重复且互不影响。PID namesapce 对容器类应用特别重要， 可以实现容器内进程的暂停/恢复等功能，还可以支持容器在跨主机的迁移前后保持内部进程的 PID 不发生变化。
说明：本文的演示环境为 ubuntu 16.04。
PID namesapce 与 /proc Linux 下的每个进程都有一个对应的 /proc/PID 目录，该目录包含了大量的有关当前进程的信息。 对一个 PID namespace 而言，/proc 目录只包含当前 namespace 和它所有子孙后代 namespace 里的进程的信息。
创建一个新的 PID namespace 后，如果想让子进程中的 top、ps 等依赖 /proc 文件系统的命令工作，还需要挂载 /proc 文件系统。下面的例子演示了挂载 /proc 文件系统的重要性。先输出当前进程的 PID，然后查看其 PID namespace，接着通过 unshare 命令创建新的 PID namespace：
$ sudo unshare &amp;ndash;pid &amp;ndash;mount &amp;ndash;fork /bin/bash
该命令会同时创建新的 PID 和 mount namespace，然后再查看此时的 PID namespace：
上图中的结果似乎不是我们想要的，因为显示的 PID namespace 并没有变化。让我们接着做实验：</description></item><item><title>Pipeline 与 Function</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Pipeline-%E4%B8%8E-Function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Pipeline-%E4%B8%8E-Function/</guid><description>概述 参考：
官方文档：https://helm.sh/docs/chart_template_guide/functions_and_pipelines/ 将 .Values 对象中的字符串注入模板时，应引用这些字符串。我们可以通过在 **Template Directive(模板指令)**中调用 quota 函数来实现，比如下面这个示例，会将引入的指转换为字符串类型：
apiVersion: v1 kind: ConfigMap metadata: name: {{.Release.Name}}-configmap data: myvalue: &amp;#34;Hello World&amp;#34; drink: {{quote .Values.favorite.drink}} food: {{quote .Values.favorite.food}} 模板函数遵循语法 functionName arg1 arg2...。在上面的代码片段中，quote .Values.favorite.drink 调用 quote 函数并将一个参数传递给它。
Helm 拥有超过 60 种可用函数。其中一些是由 Go template language(Go 模板语言) 本身定义的。其他大多数都是 Sprig template library(Sprig 模板库) 的一部分。随着示例的进行，我们将看到其中的许多例子。
注意：虽然我们将 Helm template language(Helm 模板语言) 视为 Helm 特有的，但它实际上是 Go 模板语言，一些额外函数和各种包装器的组合，以将某些对象暴露给模板。Go 模板上的许多资源在了解模板时可能会有所帮助。
Pipeline 管道 在 Helm 的 Template 中，**Pipeline(管道)**的概念与 Go Template 中 Pipeline 的概念不同，并不是指产生数据的操作。</description></item><item><title>pktgen 内核自带的高性能网络测试工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/pktgen-%E5%86%85%E6%A0%B8%E8%87%AA%E5%B8%A6%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/pktgen-%E5%86%85%E6%A0%B8%E8%87%AA%E5%B8%A6%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</guid><description>pktgen 内核自带的高性能网络测试工具 modprobe pktgen cat &amp;gt; /usr/local/bin/pgset &amp;lt;&amp;lt;EOF local result echo $1 &amp;gt; $PGDEV result=`cat $PGDEV | fgrep &amp;#34;Result: OK:&amp;#34;` if [ &amp;#34;$result&amp;#34; = &amp;#34;&amp;#34; ]; then cat $PGDEV | fgrep Result: fi EOF chmod 755 /usr/local/bin/pgset # 为0号线程绑定 eth0 网卡 export PGDEV=/proc/net/pktgen/kpktgend_0 pgset &amp;#34;rem_device_all&amp;#34; # 清空网卡绑定 pgset &amp;#34;add_device eth0&amp;#34; # 添加 eth0 网卡 # 配置 eth0 网卡的测试选项 export PGDEV=/proc/net/pktgen/eth0 pgset &amp;#34;count 1000000&amp;#34; # 总发包数量 pgset &amp;#34;delay 5000&amp;#34; # 不同包之间的发送延迟 (单位纳秒) pgset &amp;#34;clone_skb 0&amp;#34; # SKB 包复制 pgset &amp;#34;pkt_size 64&amp;#34; # 网络包大小 pgset &amp;#34;dst 192.</description></item><item><title>PLEG</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/PLEG/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubelet/Kubelet-%E7%89%B9%E6%80%A7/PLEG/</guid><description>概述 参考：
公众号,运维开发故事-PLEG is not healthy？幕后黑手居然是它！ 公众号,云原生实验室-Kubelet 中的 “PLEG is not healthy” 到底是个什么鬼？ https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes# https://mp.weixin.qq.com/s/lPYd9tNQyjidJ-sLt2sDLg
问题描述 环境 ：ubuntu18.04，自建集群 k8s 1.18 ，容器运行时 docker。
现象：某个 Node 频繁 NotReady，kubectl describe 该 Node，出现如下报错日志：
PLEG is not healthy: pleg was last seen active 3m46.752815514s ago; threshold is 3m0s 频率在 5-10 分钟就会出现一次。
我们首先要明白 PLEG 是什么？ Pod Lifecycle Event Generator(Pod 生命周期事件生成器，简称 PLEG) 是 Kubelet 中的一个模块，主要职责就是通过每个匹配的 Pod 级别事件来调整容器运行时的状态，并将调整的结果写入缓存，使 Pod 的缓存保持最新状态。先来聊聊 PLEG 的出现背景。在 Kubernetes 中，每个节点上都运行着一个守护进程 Kubelet 来管理节点上的容器，调整容器的实际状态以匹配 spec 中定义的状态。具体来说，Kubelet 需要对两个地方的更改做出及时的回应：</description></item><item><title>Pod Monitor</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Pod-Monitor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Pod-Monitor/</guid><description>概述 参考：
官方文档：https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/design.md#podmonitor Pod Monitor 与 Service Monitor 一样，都是用来生成 Prometheus 配置文件中 scrape 配置段中的内容。
不同点在于 PM 直接与 pod 关联，根据标签选择来定义要监控的 pod，而不再需要通过 service 来暴露 pod 中的端口。
PodMonitor yaml 详解 apiVersion: monitoring.coreos.com/v1 kind: PodMonitor metadata: name: rabbitmq spec: # 指定从 pod 中哪个端口采集指标，需要在 pod 的 .spec.containers.ports 字段中指定 containerPort 和 name。 podMetricsEndpoints: - interval: 15s port: prometheus # 需要与 .spec.containers.ports.name 相同，则会将端口加入 scrape 配置中 # 指定要匹配的 pod 的 label，具有相同 label 的将会加入监控配置。 selector: matchLabels: app.kubernetes.io/component: rabbitmq # 指定要从哪个 namespace 中关联 pod。any: true 为匹配所有 ns 下的 pod namespaceSelector: any: true Pod Monitor 样例 apiVersion: monitoring.</description></item><item><title>Pod 生命周期与探针</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/Pod-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%B8%8E%E6%8E%A2%E9%92%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/Pod-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%B8%8E%E6%8E%A2%E9%92%88/</guid><description>概述 参考：
官方文档，概念 - 工作负载 - Pods - Pod 的生命周期 官方文档，任务 - 配置 Pods 与 容器 - 配置 Liveness、Readiness、Startup Probes 公众号, YP 小站-怎么使用 Pod 的 liveness 和 readiness 与 startupProbe Pod 从开始到结束，会有以下几个 phase(阶段) Pending：调度尚未完成。Pod 已经在 apiserver 中创建，但还没有调度到 Node 上面 Running：运行中。od 已经调度到 Node 上面，所有容器都已经创建，并且至少有一个容器还在运行或者正在启动 Failed：失败。 Pod 调度到 Node 上面后至少有一个容器运行失败（即退出码不为 0 或者被系统终止） Succeeded：已经成功。Pod 调度到 Node 上面后成功运行结束，并且不会重启。使用 kubectl 命令看到的就是 Completed Unkown：得不到该 Pod 的信息。 状态未知，通常是由于 apiserver 无法与 kubelet 通信导致 Completed：已完成。主要用于 Job 模式的 Pod，表示该 Job 正常执行结束 容器生命周期钩子(Container Lifecycle Hooks) Pod 启动的时候，先运行多个 Container 的初始化程序，然后运行 Container 的主程序(主程序中可以在开始 postStart 和结尾 postStop 处执行一些用户自定义“钩子”，这个钩子类似于 awk 命令的 START 和 STOP 功能)。以下是两种钩子的描述。</description></item><item><title>Podman</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Podman/Podman/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/Podman/Podman/</guid><description>概述 alias docker=podman
podman 与 cri-o 同属 libpod 项目，https://github.com/containers/podman
项目地址：https://github.com/containers/libpod
podman 命令行工具 podman [OPTIONS] COMMAND
OPTIONS
COMMAND
attach Attach to a running container
build Build an image using instructions from Dockerfiles
commit Create new image based on the changed container
container Manage Containers
cp Copy files/folders between a container and the local filesystem
create Create but do not start a container
diff Inspect changes on container&amp;rsquo;s file systems
events Show podman events</description></item><item><title>PodWorker 模块</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/PodWorker-%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/PodWorker-%E6%A8%A1%E5%9D%97/</guid><description>概述 PodWorkers 子模块主要的作用就是处理针对每一个的 Pod 的更新事件，比如 Pod 的创建，删除，更新。而 podWorkers 采取的基本思路是：为每一个 Pod 都单独创建一个 goroutine 和更新事件的 channel，goroutine 会阻塞式的等待 channel 中的事件，并且对获取的事件进行处理。而 podWorkers 对象自身则主要负责对更新事件进行下发。
准备运行 Pod podWorkers.UpdatePod() - 更新事件的 channel updatePod 将配置更改或终止状态传递到 POD。 POD 可以是可变的，终止或终止，并且如果在 APIServer 上删除，则将转换为终止，它被发现具有终端阶段（成功或失败），或者如果它被 kubelet 驱逐。
为每一个 Pod 都单独创建一个 goroutine 和更新事件的 channel，goroutine 会阻塞式的等待 channel 中的事件，并且对获取的事件进行处理。而 podWorkers 对象自身则主要负责对更新事件进行下发。
源码：pkg/kubelet/pod_workers.go
func (p *podWorkers) UpdatePod(options UpdatePodOptions) { // 处理当 Pod 是孤儿(无配置)并且我们仅通过仅运行生命周期的终止部分来获得运行时状态 pod := options.Pod var isRuntimePod bool if options.RunningPod != nil { if options.Pod == nil { pod = options.</description></item><item><title>Pointer(指针)</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Pointer%E6%8C%87%E9%92%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Pointer%E6%8C%87%E9%92%88/</guid><description>概述 参考：
Wiki, Pointer 公众号,码农的荒岛求生-彻底理解 C 语言中的指针 Pointer(指针) 在计算机科学中，是许多编程语言中存储内存地址的对象。这可以是位于计算机内存中的另一个值，或者在某些情况下，是内存映射计算机硬件的值。指针引用内存中的某个位置，获取存储在该位置的值称为取消引用该指针。打个比方，一本书索引中的页码可以被认为是指向相应页面的指针；将通过翻到具有给定页码的页面并阅读在该页面上找到的文本来取消引用这样的指针。指针变量的实际格式和内容取决于底层计算机体系结构。
彻底理解 C 语言中的指针 大家好，我是小风哥。
假定给你一块非常小的内存，这块内存只有 8 字节，这里也没有高级语言，没有操作系统，你操作的数据单位是单个字节，你该怎样读写这块内存呢？
注意这里的限定，再读一遍，没有高级语言，没有操作系统，在这样的限制之下，你必须直面内存读写的本质。
这个本质是什么呢？
本质是你需要意识到内存就是一个一个装有字节的小盒子，这些小盒子从 0 到 N 编好了序号。
这时如果你想计算 1+2，那么你必须先把 1 和 2 分别放到两个小盒子中，假设我们使用 Store 指令，把数字 1 放到第 6 号小盒子，那么用指令表示就是这样：
store 1 6 注意看这条指令，这里出现了两个数字：1 和 6，虽然都是数字，但这两个数字的含义是不同的，一个代表数值，一个代表内存地址。
与写对应的是读，假设我们使用 load 指令，就像这样：
load r1 6 现在依然有一个问题，这条指令到底是数字 6 写入 r1 寄存器还是把第 6 号小盒子中装的数字写入 r1 寄存器？
可以看到，数字在这里是有歧义的，它既可以表示数值也可以表示地址，为加以区分我们需要给数字添加一个标识，比如对于前面加上$符号的就表示数值，否则就是地址：
store $1 6 load r1 6 这样就不会有歧义了。
现在第 6 号内存中装入了数值 1：
即地址 6 代表数字 1：</description></item><item><title>printf 与 echo 文本输出命令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/printf-%E4%B8%8E-echo-%E6%96%87%E6%9C%AC%E8%BE%93%E5%87%BA%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/printf-%E4%B8%8E-echo-%E6%96%87%E6%9C%AC%E8%BE%93%E5%87%BA%E5%91%BD%E4%BB%A4/</guid><description>概述 printf, fprintf, sprintf, snprintf, vprintf, vfprintf, vsprintf, vsnprintf - 格式化输出转换
printf 命令：格式化并且打印数据 format and print data 主要用于对 ARGUMENTs 进行格式化输出，ARGUMENTs 可以是字符串、数值等等，甚至可以通过变量引用；FORMAT 主要是对 ARGUMENTs 里的各种数据进行格式化输出，e.g.每个 ARGUMENT 是什么类型的(字符、整数、2 进制、16 进制等等)，各个 ARGUMENT 中间使用什么分隔符、是否换行等等。
语法格式：printf FORMAT [ARGUMENT&amp;hellip;] 主要用于按照 FORMAT 定义的格式来输出 ARGUMENT&amp;hellip;给出的内容
FORMAT 包括：格式替代符，自定义内容，格式控制符，这 3 个在使用的时候没有先后顺序 格式替代符 # 用于控制输出的每个 Argument 的类型。一个“格式替代符”对应后面一个 Argument，如果想要输出的类型与 Argument 给定的类型不符，则进行类型转换后输出 e.g.Argument 给了一个整数 100，而格式替代符使用的是%X,则会输出 64；若 Argument 不够 FORMAT 的个数，则以空白补充。一般情况格式替代符使用双引号引起来
%b # 相对应的参数被视为含有要被处理的转义序列之字符串。 %c # ASCII 字符。显示相对应参数的第一个字符 %d, %i # 十进制整数 %e, %E, %f # 浮点格式 %g #%e 或%f 转换，看哪一个较短，则删除结尾的零 %G #%E 或%f 转换，看哪一个较短，则删除结尾的零 %o # 不带正负号的八进制值 %s # 字符串 %u # 不带正负号的十进制值 %x # 不带正负号的十六进制值，使用 a 至 f 表示 10 至 15 %X # 不带正负号的十六进制值，使用 A 至 F 表示 10 至 15 %% # 字面意义的% 自定义内容 # 在输出内容的格式中，可以自己添加任务字符串</description></item><item><title>procps 工具集</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/procps-%E5%B7%A5%E5%85%B7%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/procps-%E5%B7%A5%E5%85%B7%E9%9B%86/</guid><description>概述 参考：
https://sourceforge.net/projects/procps-ng/ GitLab 项目，procps-ng/procps GitHub 项目，uutils/procps # 有人用 Rust 重写了 procps 项目 procps 是一组命令行和全屏实用程序，它们主要从 Proc 文件系统 中获取信心，该文件系统为内核数据结构提供了一个简单的接口。procps 程序通常集中在描述系统上运行的进程的结构上。包括以下程序(每个标题都是一个程序)
Note：该工具集就算是最小化安装的 linux 发行版系统也是默认包含的~
free - 显示系统中可用和已用的内存量 详见 Memory 管理工具
kill - 向指定PID的进程发送信号 可用的信号详见 Signal(信号)
kill 命令将指定的信号发送到指定的进程或进程组。 如果未指定信号，则发送 TERM 信号。 TERM 信号将杀死不捕获该信号的进程。对于其他过程，由于无法捕获该信号，可能需要使用 KILL（9）信号。
大多数现代 Shell 具有内置的 kill 函数，其用法与此处描述的命令非常相似。&amp;rsquo;-a&amp;rsquo; 和 &amp;lsquo;-p&amp;rsquo; 选项以及通过命令名称指定进程的可能性是 本地扩展。
如果 sig 为 0，则不发送信号，但仍执行错误检查。
“信号 0” 有点像精神上的 “ping”。在 shell 程序脚本中使用 kill -0 PID 是判断 PID 是否有效的好方法。信号 0 仅用于检查进程是否存在。
Syntax(语法) sysstat 工具集</description></item><item><title>Prometheus Manifest 详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Prometheus/Prometheus-Manifest-%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Prometheus/Prometheus-Manifest-%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata spec additionalScrapeConfigs(Object) # 额外的抓取配置 该字段可以通过 additional 功能 为 Prometheus Server 创建额外的 Scrape 配置。这种方式常用来为 Prometheus Server 创建静态的 Scrape 配置。
key(STRING) # 要引用的 secret 对象中 .data 字段下，指定的 key 的值 name(STRING) # 要使用的 secret 对象名称 containers([]Object) # 注入其他容器或修改 Operator 生成的容器 这可用于允许将身份验证代理添加到 Prometheus pod 或更改 Operator 生成的容器的行为。 如果此处描述的容器共享相同的名称，则它们将修改操作员生成的容器，并且通过战略合并补丁进行修改。 当前的容器名称为：“ prometheus”，“ config-reloader”和“ thanos-sidecar”。 覆盖容器完全不在维护人员支持的范围之内，因此，您接受此行为可能随时中断，恕不另行通知。
name(STRING) # 指定要修改的容器名。支持的容器名为：prometheus、config-reloader、thanos-sidecar。若指定的名称不存在，则创建新的容器 externalUrl(STRING) # 为 prometheus Server 指定 &amp;ndash;web.external-url 命令行标志的值 logFormat(STRING) # 为 Prometheus Server 指定 &amp;ndash;log.</description></item><item><title>Prometheus Operator</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/Prometheus-Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/Prometheus-Operator/</guid><description>概述 参考：
官网 GitHub 项目 该项目曾经在 coreos/prometheus-operator 仓库中，后来移动到 prometheus-operator/prometheus-operator
背景 为什么会需要 prometheus-operator(后文简称 operator)
当 prometheus 需要监控 kubernetes 集群时，要手动修改配置文件中的 scrape 配置段是非常复杂且繁琐的。每启动一个新 pod 就要新加配置，并手动更新 prometheus 配置文件，有没有一种办法可以在新增 pod 时，让 prometheus 自动更新其配置文件呢？这就是 operator 的作用。
Prometheus Operator 通过数个 CRD 资源来控制 Prometheus 监控套件的运行，并作为这几个 CRD 的 controller(类似于 kube-controller-manager，只不过这个 Controller 只维护几个自定义的资源)来维护其正常运行，这些 CRD 就可以实现这样的功能：自动添加配置文件中 scrape 配置段的 job，并且自动执行热更新来加载配置文件等等。下面是这几个 CRD 的简介
CRD 介绍 参考：
官方文档 https://github.com/coreos/prometheus-operator/blob/master/Documentation/design.md Prometheus Operator 现阶段引入了如下几种自定义资源：
Prometheus # 它定义了所需的 Prometheus 主程序。Operator 始终确保正在运行与资源定义匹配的 prometheus 主程序。 Alertmanager # 它定义了所需的 Alertmanager 主程序。Operator 始终确保正在运行与资源定义匹配的 Alertmanager 主程序。 ThanosRuler # ServiceMonitor # 为 Prometheus Server 配置文件中的 scrape_config 配置段生成配置内容。以声明方式指定应如何监控服务组。 PodMonitor # 为 Prome theus Server 配置文件中的 scrape_config 配置段生成配置内容。与 ServiceMonitor 类型类似，只不过是从指定的 pod 中，发现待抓去的目标。 Probe # 为 Prometheus Server 配置文件中的 scrape_config 配置段生成配置内容。只会生成 blackbox-exporter 程序所需的配置。 PrometheusRule # 它定义了一个所需的 Prometheus 规则文件，该文件可以由包含 Prometheus 警报和记录规则的 Prometheus 实例加载。 AlertmanagerConfig # 随着发展，也许还会有其他的 CR 产生</description></item><item><title>Prometheus 大量读操作</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Prometheus-%E5%A4%A7%E9%87%8F%E8%AF%BB%E6%93%8D%E4%BD%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/Prometheus-%E5%A4%A7%E9%87%8F%E8%AF%BB%E6%93%8D%E4%BD%9C/</guid><description>故障现象
Prometheus 的读请求无故瞬间激增。
故障排查 重启 Prometheus 后解决，后续需要跟进看是否还会继续发生
当使用 Grafana 查询 30 天的指标时，Prometheus 的读请求就会激增：
怀疑可能是 Grafana 与 Prometheus 之间的连接没有中断，持续查询导致，但是暂无证据
1 月 20 日早晨进行 30 天查询后再次出现该问题，添加 netfilter 规则，阻断 grafana 与 prometheus 问题依旧；使用 docker 重启 prometheus 容器问题依旧；删除 grafana 问题依旧。
故障处理
实际上是由于每次评估规则时，有很多条规则的表达式是 30 天的范围表达式导致的。</description></item><item><title>Prometheus 配置自动管理</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-%E9%85%8D%E7%BD%AE%E8%87%AA%E5%8A%A8%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-%E9%85%8D%E7%BD%AE%E8%87%AA%E5%8A%A8%E7%AE%A1%E7%90%86/</guid><description>概述 jimmidyson/configmap-reload prometheus-operator 的 prometheus-config-reloader
Prometheus Configmanager 参考：
GitHub 项目，facebookincubator/prometheus-configmanager Prometheus-Configmanager 将规则配置文件抽象成 tenant(租户)，每个 tenant 都会有对应唯一的文件名(格式为：TenantID_rules.yml)。每当修改这些规则配置文件时，都会对 http://PrometheusIP:PORT/-/reload 发送 POST 请求以便让 Prometheus Server 重新加载配置文件。
一般情况，一个文件只有一个规则组，组名与 tenant 名称保持一致
基本示例 curl -X POST &amp;#34;http://localhost:9100/v1/desistdaydream/alert&amp;#34; -H &amp;#34;accept: application/json&amp;#34; -H &amp;#34;Content-Type: application/json&amp;#34; -d &amp;#39; { &amp;#34;alert&amp;#34;: &amp;#34;test&amp;#34;, &amp;#34;expr&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;labels&amp;#34;: { &amp;#34;additionalProp1&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;additionalProp2&amp;#34;: &amp;#34;string&amp;#34; }, &amp;#34;for&amp;#34;: &amp;#34;1m&amp;#34;, &amp;#34;annotations&amp;#34;: { &amp;#34;additionalProp1&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;additionalProp2&amp;#34;: &amp;#34;string&amp;#34; } }&amp;#39; 上面的 curl 请求会生成如下文件
/ # cat desistdaydream_rules.yml groups: - name: desistdaydream rules: - alert: test expr: string for: 1m labels: additionalProp1: string additionalProp2: string tenant: desistdaydream annotations: additionalProp1: string additionalProp2: string 部署 构建 docker build -t prometheus-configurer -f Dockerfile.</description></item><item><title>Prometheus 衍生品</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/</guid><description>概述 Prometheus 高可用 参考：
官方文档，存储 Prometheus 本身没有集群的概念，也就没有主备，也就没有互相备份，并且，Prometheus 是主动 pull 数据的，所以 如果 Prometheus 想要高可用就需要多个 Prometheus Server 共享存储，那么如果要共享存储，则无法保持数据一致性，因为共享存储内的数据会收到两份数据。官方给出了一个办法，就是使用 remote 配置，将数据保存到第三方存储中，而不是通过 Prometheus 自己的数据系统进行保存。
如果多个 Prometheus 分别保存自己的数据，那么当一个节点 down 掉后，另一个节点就算数据没丢失，也没法保证两边的数据一致性。所以，Prometheus 通过远程存储的功能，来实现基本的数据高可用功能。
高可用实践文章：
使用 Thanos+Prometheus+Grafana 打造监控系统：https://mp.weixin.qq.com/s/8Ws2po_oT5sSKLD3nGYwMw 高科用方案推荐 Cortex 项目地址：https://github.com/cortexproject/cortex
Thanos 具有长期存储功能的高可用 Prometheus 项目地址：https://github.com/thanos-io/thanos https://www.qikqiak.com/k8strain/monitor/thanos/
Victoria Metrics 快速，经济高效且可扩展的时间序列数据库 项目地址：https://github.com/VictoriaMetrics/VictoriaMetrics
m3db 项目地址：https://github.com/m3db/m3
高科用方案对比 Victoria Metrics 与 Thanos 对比 参考：
Thanos 与 VictoriaMetrics，谁才是打造大型 Prometheus 监控系统的王者？ 这篇文章对比有误差，并没有用 Thanos 的 Receiver 架构模式进行对比，实际上，Thanos 的 Receiver 模式与 VM 是类似的，也是通过 Remote Write 来实现数据转存。
Thanos 与 Cortex 对比 发展现状 Thanos 项目创建于 2017 年 12 月份。在 2019 年 8 月份成为 CNCF 沙盒项目。目前的维护成员主要来自于 Red Hat。 Cortex 项目创建于 2016 年 2 月份。在 2018 年 8 月成为 CNCF 沙盒项目。项目维护成员主要来自于 Weavework。</description></item><item><title>Promtail 部署</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Promtail-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Promtail/Promtail-%E9%83%A8%E7%BD%B2/</guid><description>使用 docker 运行 Promtail 注意：使用 docker 运行 promtail 的时候，需要注意日志挂载路径及 scrape_configs 配置，因为在容器中运行，所以抓取路径是在容器中，而不是宿主机上，注意这点，否则会抓不到任何日志。
为了解决上面的问题，并且不影响容器内 /var/log 目录，所以启动时指定 -v /var/log:/var/log/host:ro 参数，并修改默认配置文件中 path: 的值为 /var/log/host/*
docker run -d --rm --name promtail \ --network host \ -v /opt/logging/config/promtail:/etc/promtail \ -v /var/log:/var/log/host:ro \ -v /etc/localtime:/etc/localtime:ro \ grafana/promtail</description></item><item><title>Protobuf</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/Protobuf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E6%97%A0%E6%B3%95%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%AD%E8%A8%80/Protobuf/</guid><description>概述 参考：
Wiki, Protocol Buffers 公众号 - 码农的荒岛求生，神奇的 Google 二进制编解码技术：Protobuf 计算机网络编程中一个非常基本的问题：该怎样表示client与server之间交互的数据，在往下看之前先想一想这个问题。
共识与协议 这个问题可不像看上去的那样简单，因为client进程和server进程运行在不同的机器上，这些机器可能运行在不同的处理器平台、可能运行在不同的操作系统、可能是由不同的编程语言编写的，server要怎样才能识别出client发送的是什么数据呢？就像这样： client给server发送了一段数据：
0101000100100001 server怎么能知道该怎样“解读”这段数据呢？
显然，client和server在发送数据之前必须首先达成某种关于怎样解读数据的共识，这就是所谓的协议。
这里的协议可以是这样的：“将每8个比特为一个单位解释为无符号数字”，如果协议是这样的，那么server接收到这串二进制后就会将其解析为81(01010001)与33(00100001)。
当然，这里的协议也可以是这样的：“将每8个比特为一个单位解释为ASCII字符”，那么server接收到这串二进制后就将其解析为“Q!”。
可见，同样一串二进制在不同的“上下文/协议”下有完全不一样的解读，这也是为什么计算机明明只认知0和1但是却能处理非常复杂任务的根本原因，因为一切都可以编码为0和1，同样的我们也可以从0和1中解析出我们想要的信息，这就是所谓的编解码技术。
实际上不止0和1，我们也可以将信息编码为摩斯密码(Morse code)等，只不过计算机擅长处理0和1而已。
扯远了，回到本文的主题。
远程过程调用：RPC 作为程序员我们知道，client以及server之间不会简单传递一串数字以及字符这样简单，尤其在互联网大厂后端服务这种场景下。
当我们在电商App搜索商品、打车App呼叫出租车以及刷短视频时，每一次请求的背后在后端都涉及大量服务之间的交互，就像这样：
完成一次客户端请求gateway这个服务要调用N多个下游服务，所谓调用是说A服务向B服务发送一段数据（请求），B服务接收到这段数据后执行相应的函数，并将结果返回给A服务。
只不过对于服务A来说并不想关心网络传输这样的底层细节，如果能像调用本地函数一样调用远程服务就好了，这就是所谓的RPC，经典的实现方式是这样的：
RPC对上层提供和普通函数一样的接口，只不过在实现上封装了底层复杂的网络通信，RPC框架是当前互联网后端的基石之一，很多所谓互联网后端的职位无非就是在此基础之上堆业务逻辑。
本文我们不关心其中的细节，这里我们只关心在网络层client是怎样对请求参数进行编码、server怎样对请求参数进行解码的，也就是本文开头提出的问题。
信息的编解码 在思考怎样进行编解码之前我们必须意识到：
client和server可能是用不同语言编写的，你的编解码方案必须通用且不能和语言绑定 编解码方法的性能问题，尤其是对时间要求苛刻的服务 首先，我们最应该能想到的就是以纯文本的形式来表示。
纯文本从来都是一种非常有友好的信息载体，为什么？很简单，因为人类(我们)可以直接看懂，就像这段：
{ &amp;#34;widget&amp;#34;: { &amp;#34;window&amp;#34;: { &amp;#34;title&amp;#34;: &amp;#34;Sample Konfabulator Widget&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;main_window&amp;#34;, &amp;#34;width&amp;#34;: 500, &amp;#34;height&amp;#34;: 500 }, &amp;#34;image&amp;#34;: { &amp;#34;src&amp;#34;: &amp;#34;Images/Sun.png&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;sun1&amp;#34;, &amp;#34;hOffset&amp;#34;: 250, &amp;#34;vOffset&amp;#34;: 250, }, }} 是不是很清晰，一目了然，只要我们实现约定好文本的结构(也就是语法)，那么client和server就能利用这种文本进行信息的编码以及解码，不管client和server是运行在x86还是Arm、是32位的还是64位的、运行在Linux上还是windows上、是大端还是小端，都可以无障碍交流。
因此在这里，文本的语法就是一种协议。 顺便说一句，你都规定好了文本的语法，实际上就相当于发明了一种语言。
这里用来举例用的语言就是所谓的Json，只不过json这种语言不是用来表示逻辑(代码)而是用来存储数据的。
Json就是这个老头提出来的：
除了Json，另一种利用文本存储数据的表示方法是XML，来一段感受下：</description></item><item><title>psmisc 工具集</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/psmisc-%E5%B7%A5%E5%85%B7%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/psmisc-%E5%B7%A5%E5%85%B7%E9%9B%86/</guid><description>概述 参考：
项目地址：https://gitlab.com/psmisc/psmisc psmisc 是一个小型的应用程序集合，与 procps-ng 工具集类似，都是使用伪文件系统(/proc)内的信息来展示系统信息
该工具集包含包含以下程序(每个标题都是一个)
fuser - 显示正在使用指定 文件 或 sockets 的进程 fuser 使用指定的文件或文件系统显示进程的 PID。 在默认的显示模式下，每个文件名后都有一个字母，表示访问类型：
c # 当前目录。 e # 一个可执行文件正在运行。 f # 打开文件。 在默认显示模式下省略 f。 F # 打开文件进行写入。 默认显示模式下省略 F。 r # 根目录。 m # 映射文件或共享库。 fuser [OPTIONS] OPTIONS
-m # 显示使用命名文件系统或块设备的所有进程 killall - 通过进程名称向指定进程发送信号 与 kill 命令类似，但是不像 kill 只能指定进程的 PID，而是可以通过进程的名称来发送信号
EXAMPLE：
killall -0 nginx # 向名为 nginx 的进程发送 0 信号 peekfd - shows the data travelling over a file descriptor prtstat - 输出一个进程的统计信息 pslog - prints log path(s) of a process pstree - 以树状显示当前正在运行的进程 该命令与 ps 类似，但是不会像 ps -ef 一样显示内核态进程</description></item><item><title>pt-ioprofile</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/pt-ioprofile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/pt-ioprofile/</guid><description>概述 参考：
官方文档 pt-ioprofile 是 Percona 出的 IO 查看工具。Percona 用来监视进程 IO 并打印文件和 I/O 活动表。
pt-ioprofile 本质上就是一个 shell 脚本，只做两件事：
通过 lsof 和 strace 两个工具获取指定进程的一段时间的数据，并保存到文件中 使用 awk 等工具聚合两个文件的内容。 pt-ioprofile 使用 strace 和 lsof 工具监视进程的 IO 并打印出一个文件和 I/O 活动表。默认情况下，它监视 mysqld 进程 30 秒。输出如下：
Tue Dec 27 15:33:57 PST 2011 Tracing process ID 1833 total read write lseek ftruncate filename 0.000150 0.000029 0.000068 0.000038 0.000015 /tmp/ibBE5opS read：从文件中读出数据。要读取的文件用文件描述符标识，数据读入一个事先定义好的缓冲区。 write：把缓冲区的数据写入文件中。 pread：由于 lseek 和 read 调用之间，内核可能会临时挂起进程，所以对同步问题造成了问题，调用 pread 相当于顺序调用了 lseek 和 read，这两个操作相当于一个捆绑的原子操作。 pwrite：由于 lseek 和 write 调用之间，内核可能会临时挂起进程，所以对同步问题造成了问题，调用 pwrite 相当于顺序调用了 lseek 和 write，这两个操作相当于一个捆绑的原子操作。 fsync：确保文件所有已修改的内容已经正确同步到硬盘上，该调用会阻塞等待直到设备报告 IO 完成。 open：打开一个文件，并返回这个文件的描述符。 close：close 系统调用用于“关闭”一个文件，close 调用终止一个文件描述符以其文件之间的关联。文件描述符被释放，并能够重新使用。 lseek：对文件描述符指定文件的读写指针进行设置，也就是说，它可以设置文件的下一个读写位置。 fcntl：针对(文件)描述符提供控制。 pt-ioprofile 通过使用 附加strace到进程来工作ptrace()，这将使其运行非常缓慢，直到strace分离。除了冻结服务器之外，还有一些风险，即进程在与服务器strace分离后崩溃或性能不佳，或者strace没有完全分离并使进程处于睡眠状态。因此，这应该被视为一种侵入性工具，除非您对此感到满意，否则不应在生产服务器上使用。</description></item><item><title>Pub/Sub(发布/订阅)</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Pub_Sub%E5%8F%91%E5%B8%83_%E8%AE%A2%E9%98%85/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Pub_Sub%E5%8F%91%E5%B8%83_%E8%AE%A2%E9%98%85/</guid><description>概述 参考：
官方文档 https://redis.io/docs/latest/develop/interact/pubsub/ Wiki, 发布/订阅 模式 Redis 可以通过 SUBSCRIBE、UNSUBSCRIBE、PUBLISH 这类命令实现 Publish/Subscribe(发布/订阅)模式。
Redis 的 发布/订阅模式中，Messages(消息) 的发送者称为 Publishers(发布者)、消息的接收者称为 Subscribers(订阅者)。而发送者和接收者之间传递消息的途径称为 Channels(频道)。
订阅者可以订阅自己感兴趣的 Channels，并随时等待接收发布到这些 Channels 中的消息，并不需要知道有哪些发布者。
发布者可以向任何 Channels 中发布消息，而不需要知道有哪些订阅者
这种将 发布者 与 订阅者 解耦的模式，可以实现更大的可扩展性和更动态的网络拓扑结构。
Redis 中并没有默认已经存在的 Channels(频道)。 只要执行了 SUBSCRIBE 命令，并指定 Channel 名称，Redis 就会创建一个频道，并且执行该命令的客户端就称为 Subscriber。比如，现在执行如下命令：
127.0.0.1:6379&amp;gt; SUBSCRIBE test1 test2 Reading messages... (press Ctrl-C to quit) 1) &amp;#34;subscribe&amp;#34; 2) &amp;#34;test1&amp;#34; 3) (integer) 1 1) &amp;#34;subscribe&amp;#34; 2) &amp;#34;test2&amp;#34; 3) (integer) 2 此时，创建了两个 Channels，test1 和 test2，其他客户端发送到这些 Channels 的消息，将被推送到订阅了这俩通道的 Subscriber，也就是订阅者的客户端。效果如下：</description></item><item><title>Push Gateway</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Push-Gateway/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/Push-Gateway/</guid><description>概述 参考：
GitHub 项目，prometheus/pushgateway 官方文档，最佳实践 - 合时使用 Pushgateway Pushgateway 是 Prometheus 生态中一个重要工具，使用它的原因主要是：
Prometheus 采用 pull 模式，可能由于不在一个子网或者防火墙原因，导致 Prometheus 无法直接拉取各个 target 数据。 在监控业务数据的时候，需要将不同数据汇总, 由 Prometheus 统一收集。 由于以上原因，不得不使用 pushgateway，但在使用之前，有必要了解一下它的一些弊端：
将多个节点数据汇总到 pushgateway, 如果 pushgateway 挂了，受影响比多个 target 大。 Prometheus 拉取状态 up 只针对 pushgateway, 无法做到对每个节点有效。 Pushgateway 可以持久化推送给它的所有监控数据。 Pushgateway 对不推送的指标没有超时设计，并且在讨论中也不打算实现，因为各种提案都是不好的模式 https://github.com/prometheus/pushgateway/issues/19 https://groups.google.com/forum/#!topic/prometheus-developers/9IyUxRvhY7w 因此，即使你的监控已经下线，prometheus 还会拉取到旧的监控数据，需要手动清理 pushgateway 不要的数据。
Note：pushgateway 无法主动获取获取目标 metrics。目标需要通过脚本、daemon 程序、手动(e.g.通过 curl 获取 metrics 再发送给 pushgateway)等等方式，主动推送自己的 metrics 到 pushgateway 上。
PushGateway 部署 docker run -d -p 9091:9091 prom/pushgateway 在 Prometheus Server 的配置文件中加入配置以便让 Prometheus Server 获取 pushgateway 中的 metrics</description></item><item><title>PV 与 PVC 的状态变化示例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/PV-%E4%B8%8E-PVC-%E7%9A%84%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Persistent-Volume%E6%8C%81%E4%B9%85%E5%8D%B7/PV-%E4%B8%8E-PVC-%E7%9A%84%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E7%A4%BA%E4%BE%8B/</guid><description>我们对 PV 和 PVC 的几种状态应该不算陌生，但是在使用过程中可能也会产生一些疑问，比如为什么 PV 变成 Failed 状态了，新创建的 PVC 如何能够绑定之前的 PV，我可以恢复之前的 PV 吗？这里我们就来对 PV 和 PVC 中的几种状态变化再次进行说明。
在不同的情况下，PV 和 PVC 的状态变化我们用如下所示的表格来进行说明：
创建 PV 正常情况下 PV 被创建成功后是 Available 状态：
apiVersion: v1 kind: PersistentVolume metadata: name: nfs-pv spec: storageClassName: manual capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain nfs: path: /data/k8s # 指定nfs的挂载点 server: 10.151.30.1 # 指定nfs服务地址 直接创建上面的 PV 对象，就可以看到状态是 Available 状态，表示可以用于 PVC 绑定：
$ kubectl get pv nfs-pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE nfs-pv 1Gi RWO Retain Available manual 7s 新建 PVC</description></item><item><title>PXE</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/PXE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AE%89%E8%A3%85%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/PXE/</guid><description>概述 Preboot eXecution Environment(预启动执行环境，简称 PXE) 提供了一种使用网络接口（Network Interface）启动计算机的机制。这种机制让计算机的启动可以不依赖本地数据存储设备（如硬盘）或本地已安装的操作系统。
在服务器开机时，可以使用 PXE 进行启动，该设备的 PXE 作为一个客户端，首先请求 DHCP，在获取到网络参数后，再在广播域里请求 PXE 类型的服务，来引导安装操作系统。一般来说都是通过 TFTP 来进行远程系统文件传输，然后再自动通过传输过来的文件自动进行系统安装</description></item><item><title>Python 类</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Class/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/Python-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Class/</guid><description>概述 参考：
官方文档，教程-9.类 廖雪峰 Python 教程，面向对象编程 Classes(类) 提供了一种将数据与功能捆绑到一起的手段。创建一个新的 class(类) 就意味着创造了一个新的 object 的类型，进而可以使用这个新的类型创建多个 instances(实例)。每个类实例都可以添加 attributes(属性) 以维护其自身的状态，同时还可以有 methods(方法) 用于修改其状态(方法在类中定义)。
与其他编程语言相比，Python 的类机制增加了包含最少新语法和语义的类。它是 C ++和 Modula-3 中发现的类机制的混合物。 Python 类提供面向对象编程的所有标准功能：类继承机制允许多个基类，派生类可以覆盖其基类或类的任何方法，方法可以调用具有相同名称的基类的方法。对象可以包含任意数量和类型的数据。正如模块所面临的那样，类 Python 的动态性质的课程：它们是在运行时创建的，并且可以在创建后进一步修改。
struct 格式的 class 从 3.7 版本开始，可以使用 dataclass 装饰器让 class 声明中不再写 __init__ 方法，就像这样
from dataclasses import dataclass @dataclass class Employee: name: str dept: str salary: int john = Employee(&amp;#39;john&amp;#39;, &amp;#39;computer lab&amp;#39;, 1000) print(john.dept) print(john.salary) 运行结果：
&amp;#39;computer lab&amp;#39; 1000</description></item><item><title>QEMU Guest Agent</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/QEMU-Guest-Agent/QEMU-Guest-Agent/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/QEMU-Guest-Agent/QEMU-Guest-Agent/</guid><description>概述 参考：
官方文档，系统模拟管理和互操作性-QEMU 客户机代理 官方文档，系统模拟管理和互操作性-QEMU 客户机代理协议参考(i.e.QGA 的 QMP API 参考文档) https://wiki.qemu.org/Features/GuestAgent https://www.toutiao.com/i6646012291059810823/ https://www.shuzhiduo.com/A/QV5ZgK76dy/ QEMU Guest Agent(QEMU 虚拟机代理，简称 QGA) 是一个类似于 VMware Tools 的工具，用来辅助 Hypervisor 实现对 VM 的管理。
QEMU Guest Agent 旨在通过标准的 **QEMU Monitor Protocol(QEMU 监控协议，简称 QMP)**命令，实现 VM 与 宿主机 之间数据交互的功能。(比如可以在不登陆 VM 的情况下，让 VM 执行某些命令或者直接获取 VM 的信息)
QEMU Guest Agent 架构 QGA 功能的实现与 虚拟化 I/O 的实现，是相同的原理。KVM/QEMU 会在 VM 中模拟一个 I/O 设备，并通过 ID 关联到宿主机的某个文件或设备上，这样就可以实现宿主机与虚拟机之间的交互。其实说白了，这个年代基本都是半虚拟化设备的实现方式，通过两部分来实现完整的功能：
Host Device # 宿主机设备 **socket(套接字)是宿主机中实现 QGA 的设备。**也可以是其他未来待发明的东西。 Guest Driver # 虚拟机驱动 **virtio-serial(半虚拟化的串口设备)是 VM 中实现 QGA 的设备。**也可以是 isa-serial 等模拟设备。 除了基本的半虚拟化设备，VM 中还需要一个程序来处理宿主机发来的 QMP 命令：</description></item><item><title>QMP 命令参考</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/QEMU-Guest-Agent/QMP-%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/QEMU-Guest-Agent/QMP-%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/</guid><description>概述 参考：
官方文档，系统模拟管理与交互-QEMU Guest Agent 协议参考 简书，qemu-agent-command 命令含义 通过指令
virsh qemu-agent-command 虚拟机 --cmd '{&amp;quot;execute&amp;quot;:&amp;quot;guest-info&amp;quot;}' 可以查看其所有支持的命令，返回的数据如下
{&amp;quot;return&amp;quot;:{&amp;quot;version&amp;quot;:&amp;quot;2.8.0&amp;quot;, &amp;quot;supported_commands&amp;quot;: [ {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-sync-delimited&amp;quot;,&amp;quot;success-response&amp;quot;:true},{&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-sync&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-suspend-ram&amp;quot;,&amp;quot;success-response&amp;quot;:false}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-suspend-hybrid&amp;quot;,&amp;quot;success-response&amp;quot;:false}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-suspend-disk&amp;quot;,&amp;quot;success-response&amp;quot;:false}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-shutdown&amp;quot;,&amp;quot;success-response&amp;quot;:false}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-set-vcpus&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-set-user-password&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-set-time&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-set-memory-blocks&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-ping&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-network-get-interfaces&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-info&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-get-vcpus&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-get-time&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-get-memory-blocks&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-get-memory-block-info&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-get-fsinfo&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-fstrim&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-fsfreeze-thaw&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-fsfreeze-status&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-fsfreeze-freeze-list&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:true,&amp;quot;name&amp;quot;:&amp;quot;guest-fsfreeze-freeze&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-file-write&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-file-seek&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-file-read&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-file-open&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-file-flush&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-file-close&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-exec-status&amp;quot;,&amp;quot;success-response&amp;quot;:true}, {&amp;quot;enabled&amp;quot;:false,&amp;quot;name&amp;quot;:&amp;quot;guest-exec&amp;quot;,&amp;quot;success-response&amp;quot;:true} ]}} 返回为数据，其中 supported_command 为所有命令的数组
其官方地址为：QEMU Guest Agent Protocol Reference
各命令含义如下： 1. guest-sync-delimited
宿主机发送一个 int 数字给 qga，qga 返回这个数字，并且在后续返回字符串响应中加入 ascii 码为 0xff 的字符。 2. guest-sync</description></item><item><title>qryn</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E8%A1%8D%E7%94%9F%E5%93%81/qryn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/Loki-%E8%A1%8D%E7%94%9F%E5%93%81/qryn/</guid><description>概述 参考：
GitHub 项目，metrico/qryn 源项目：https://github.com/lmangani/cLoki qryn 是一个灵活的 Loki 与 Tempo 兼容的 LogQL API，构建在 ClickHouse 之上。
内置 Explore UI 和 LogQL CLI 用于查询数据 原生支持 Grafana 和任何 LogQL 客户端，用于 查询、处理、摄取、跟踪 和 警报</description></item><item><title>Query(查询)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Panel/Query%E6%9F%A5%E8%AF%A2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Panel/Query%E6%9F%A5%E8%AF%A2/</guid><description>概述 参考：
官方文档，面板 - 查询 新 URL https://grafana.com/docs/grafana/latest/panels-visualizations/query-transform-data/ Query 标签由如下几个元素组成
Data source selector(数据源选择器) Query options(查询选项) Query inspector button() Query editor list Expressions Data source(数据源) # 数据源选择器 这部分是一个下拉列表，通过这里选择要使用的数据源，Query editor 中的查询语句，必须要是此数据源可以可以识别的。
Query options(查询选项) https://grafana.com/docs/grafana/latest/panels-visualizations/query-transform-data/#query-options
Max data points(最大数据点) Min interval(最小间隔) Interval(间隔) Interval 是一个，通过时间来聚合或分组的一些数据点时，使用的 time span(时间跨度)。该选项也可以实现查询编辑器中的 Min step 和 Resolution 类似的效果。但是，更多的是用在 Prometheus 范围向量查询语句中，比如 rate(http_requests_total[$__interval])。interval 选项可以为两个 Grafana 的内置变量提供值，$__interval 与 $__interval_ms。
也就是说，Interval 常用来计算 总和、平均值、速率 等一段时间范围的变化量。
除了在这里可以定义 Interval，还可以通过 Variable 定义。
Relative time(相对时间) 为 Panel 配置独立时间范围选择器。利用 Relative time 的配置，可以为 Panel 配置独立于 Dashboard 时间选择器（i.</description></item><item><title>Quota(配额)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Quota%E9%85%8D%E9%A2%9D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Quota%E9%85%8D%E9%A2%9D/</guid><description>概述 参考：
官方文档，概念-策略-LimitRange 官方文档，概念-策略-ResourceQuotas namespace 中的资源配额 官方文档：https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/
当多个团队或者用户共用同一个集群的时候难免会有资源竞争的情况发生，这时候就需要对不同团队或用户的资源使用配额做出限制。比如，不同团队使用不同的 namespace，然后给该 namespace 进行资源限制即可
目前有两种 k8s 对象分配管理相关的控制策略
LimitRange(限制范围) 设定 pod 等对象的默认资源消耗以及可以消耗的资源范围
官方文档：
概念：https://kubernetes.io/docs/concepts/policy/limit-range/ 用法： https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/ https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/ https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/ https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/ &amp;hellip;..等等 ResourceQuota(资源配额) 基于 namespace，限制该 namesapce 下的总体资源的创建和消耗
官方文档：
概念：https://kubernetes.io/docs/concepts/policy/resource-quotas/ 用法： https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/ https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/quota-pod-namespace/ https://kubernetes.io/docs/tasks/administer-cluster/quota-api-object/ # 为指定的 API 对象设置 resourceQuota 资源配额分为三种类型：
计算资源配额 存储资源配额 对象数量配额 总结 仅设置 ResourceQuota 时，如果不再 pod 上设置资源的需求和限制，则无法成功创建 pod，需要配合 LimitRange 设置 pod 的默认需求和限制，才可成功创建 pod 两种控制策略的作用范围都是对于某一 namespace ResourceQuota 用来限制 namespace 中所有的 Pod 占用的总的资源 request 和 limit LimitRange 是用来设置 namespace 中 Pod 的默认的资源 request 和 limit 值，还有，Pod 的可用资源的 request 和 limit 值的最大与最小值。 简单的应用示例 Note：polinux/stress 这是一个非常好用的压测容器，可以对容器指定其所使用的内存和 cpu 等资源的大小。当创建完资源配合等资源限制的对象后，可以通过该容器来测试资源限制是否生效。</description></item><item><title>RabbitMQ Operator</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-Operator/</guid><description>概述 参考：
官方文档， https://www.rabbitmq.com/kubernetes/operator/operator-overview.html https://www.rabbitmq.com/kubernetes/operator/using-operator.html#override 通过 Operator 部署一套生产可用的 RabbitMQ 集群 创建 namespace kubectl create ns rabbitmq 部署 operator kubectl apply -f &amp;quot;https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml&amp;quot; 创建 PV cat &amp;gt; rabbitmq-pv.yaml &amp;lt;&amp;lt; EOF apiVersion: v1 kind: PersistentVolume metadata: name: rabbitmq-node-1 spec: accessModes: - ReadWriteOnce capacity: storage: 10Gi local: path: /opt/rabbitmq nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node-1.tj-test --- apiVersion: v1 kind: PersistentVolume metadata: name: rabbitmq-node-2 spec: accessModes: - ReadWriteOnce capacity: storage: 10Gi local: path: /opt/rabbitmq nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.</description></item><item><title>RabbitMQ 部署</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档，安装与配置 使用 docker 启动单节点 RabbitMQ docker run -d --hostname my-rabbit --name rabbit \ -p 15672:15672 -p 5672:5672 \ rabbitmq:3-management 在 kubernetes 集群中使用 Operator 部署 RabbitMQ 参考：
官方文档，安装和配置-Kubernetes Operator 安装 通过 Operator 使用 RabbitMQ 集群 注意：RabbitMQ Operator 会为每一个被其创建的 rabbitmqclusters.rabbitmq.com 资源的对象添加 finalizers 字段，效果如下：
apiVersion: rabbitmq.com/v1beta1 kind: RabbitmqCluster metadata: finalizers: - deletion.finalizers.rabbitmqclusters.rabbitmq.com 基于此，若删除 RabbitmqCluster 对象前删除了 RabbitMQ Operator，那么 RabbitmqCluster 将无法被删除，除非手动删除 finalizers 字段。
部署 operator 这里会自动创建 rabbitmq-system 名称空间
kubectl apply -f &amp;#34;https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml&amp;#34; 创建 pv cat &amp;gt; rabbitmq-pv.</description></item><item><title>RabbitMQ 集群</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E9%9B%86%E7%BE%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E9%9B%86%E7%BE%A4/</guid><description>概述 参考：
官方文档：https://www.rabbitmq.com/clustering.html RabbitMQ 这款消息队列中间件产品本身是基于 Erlang 语言编写，Erlang 语言天生具备分布式特性（通过同步 Erlang 集群各节点的 magic cookie 来实现）。
因此，RabbitMQ 天然支持 Clustering。这使得 RabbitMQ 本身不需要像 ActiveMQ、Kafka 那样通过 ZooKeeper 分别来实现 HA 方案和保存集群的元数据。集群是保证可靠性的一种方式，同时可以通过水平扩展以达到增加消息吞吐量能力的目的。下面先来看下 RabbitMQ 集群的整体方案：
上面图中采用三个节点组成了一个 RabbitMQ 的集群，Exchange A 的元数据信息在所有节点上是一致的，而 Queue 的完整数据则只会存在于它所创建的那个节点上。其他节点只知道这个 queue 的 metadata 信息和一个指向 queue 的 owner node 的指针。
RabbitMQ 集群中各节点关系 RabbitMQ 集群各节点同步的数据
RabbitMQ 集群的各节点会始终同步四种类型的内部元数据（类似索引）
队列元数据：队列名称和它的属性 交换器元数据：交换器名称、类型和属性 绑定元数据：一张简单的表格展示了如何将消息路由到队列 vhost 元数据：为 vhost 内的队列、交换器和绑定提供命名空间和安全属性 因此，当用户访问其中任何一个 RabbitMQ 节点时，通过 rabbitmqctl 查询到的 queue/user/exchange/vhost 等信息都是相同的。
默认情况下，队列中的数据(消息) 是不在各节点互相同步的。如果想要各节点数据保持一致，查看 《RabbitMQ 基于集群的高可用性》章节
Nodes Equal Peers(节点对等)
在某些分布式系统中，节点是具有领导者和追随者概念的。对于 RabbitMQ，通常情况并不是这样的。RabbitMQ 集群中所有节点都是 equal peers(对等的)。</description></item><item><title>RabbitMQ 命令行工具</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 RabbitMQ 主要有四个命令行工具 Commend Line Tools，不同的命令行适用不用的场景
rabbitmqctl：负责服务管理和进行操作 rabbitmq-diagnostics：负责系统诊断和健康检查 rabbitmq-plugins：负责插件管理 rabbitmqadmin：用来操作 HTTP API rabbitmqctl 管理 RabbitMQ 节点 详见此处
rabbitmq-diagnostics 负责系统诊断和健康检查 rabbitmq-plugins 负责插件管理 rabbitmq-plugins [&amp;ndash;node ] [&amp;ndash;timeout ] [&amp;ndash;longnames] [&amp;ndash;quiet] []
Available commands:
Help:
autocomplete Provides command name autocomplete variants
help Displays usage information for a command
version Displays CLI tools version
Monitoring, observability and health checks:
directories Displays plugin directory and enabled plugin file paths
is_enabled Health check that exits with a non-zero code if provided plugins are not enabled on target node</description></item><item><title>RabbitMQ 性能与优化</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E6%80%A7%E8%83%BD%E4%B8%8E%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/RabbitMQ-%E6%80%A7%E8%83%BD%E4%B8%8E%E4%BC%98%E5%8C%96/</guid><description>RabbitMQ性能评估，第2部分
https://www.rabbitmq.com/blog/2012/04/25/rabbitmq-performance-measurements-part-2/</description></item><item><title>rabbitmqctl 命令行工具详解</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/rabbitmqctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/rabbitmqctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E8%AF%A6%E8%A7%A3/</guid><description>rabbitmqctl 官方文档：https://www.rabbitmq.com/rabbitmqctl.8.html
管理 RabbitMQ 节点的工具
rabbitmqctl 是用于管理 RabbitMQ 服务器节点的命令行工具。它通过连接到专用 CLI 工具通信端口上的目标 RabbitMQ 节点并使用共享密钥（称为 cookie 文件）进行身份验证来执行所有操作。该命令主要的功能包括以下几点：
停止节点运行 获取节点状态、有效配置、健康检查 Virtual Hosts 管理 用户和权限管理 Policy 管理 查看 queues、connections、channels、exchanges 和 consumers 列表信息 集群会员身份管理 rabbitmqctl [OPTIONS] COMMAND [COMMAND_OPTIONS]
OPTIONS
-q.&amp;ndash;quiet # 安静模式输出，输出的信息减少 COMMAND 包括如下几大类：
Nodes # 节点管理 Cluster Managerment # 集群管理 Replication Users Management # 用户管理 Access Control # 访问控制 Monitoring, observability and health checks Parameters Policies Virtual hosts Configuration and Environment Definitions Feature flags Operations Queues Deprecated COMMAND_OPTIONS 中有几个通用的</description></item><item><title>Raid</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Disk/Raid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Disk/Raid/</guid><description>概述 参考：
Wiki, Raid Wiki 中文，Raid Wiki, Erasure code(纠删码) Wiki, Parity bit(奇偶校验) https://support.huawei.com/enterprise/zh/doc/EDOC1000163568/26751928 Redundant array of independent disks(独立磁盘冗余阵列，简称 RAID) 是一种存储虚拟化技术，可以将多个 Disk(物理磁盘) 组合成一个或多个 Logical unit(逻辑单元) 以达到数据冗余、提高性能或两者兼得的目的。
数据以多种方式之一分布在驱动器上，称为 RAID 级别，具体取决于所需的冗余和性能级别。不同的方案或数据分布布局由单词“RAID”命名，后跟一个数字，例如 RAID 0 或 RAID 1。每个方案或 RAID 级别在关键目标之间提供不同的平衡：可靠性、可用性、性能和容量。高于 RAID 0 的 RAID 级别可针对不可恢复的扇区读取错误以及整个物理驱动器的故障提供保护。
Raid 5 等的奇偶校验机制，是纠删码的最佳实践
虚拟磁盘的读写策略 在创建虚拟磁盘时，会需要对其数据读写策略进行定义，以规范后续虚拟磁盘运行过程中数据的读写方式。
数据读策略 在配置界面中一般体现为“Read Policy”。RAID 卡支持如下两种数据读策略：
Read-ahead(预读取) # 在配置界面中一般有“Always Read Ahead”、“Read Ahead”、“Ahead”等配置选项。使用此策略后，从虚拟磁盘中读取所需数据时，会把后续数据同时读出放在 Cache 中，用户随后访问这些数据时可以直接在 Cache 中命中，将减少磁盘寻道操作，节省响应时间，提高了数据读取速度。要使用该策略，要求 RAID 控制卡支持数据掉电保护功能，但如果此时超级电容异常，可能导致数据丢失。 No-Read-Ahead(非预读取) # 使用此策略后，RAID 卡接收到数据读取命令时，才从虚拟磁盘读取数据，不会做预读取的操作。 数据写策略 在配置界面中一般体现为“Write Policy”。RAID 卡支持如下三种数据写策略：
Write Back(回写) # 在配置界面中一般体现为“Write Back”等字样。使用此策略后，需要向虚拟磁盘写数据时，会直接写入 Cache 中，当写入的数据积累到一定程度，RAID 卡才将数据刷新到虚拟磁盘，这样不但实现了批量写入，而且提升了数据写入的速度。当控制器 Cache 收到所有的传输数据后，将给主机返回数据传输完成信号。要使用该策略，要求 RAID 卡支持数据掉电保护功能，但如果此时超级电容异常，可能导致数据丢失。 Write Through(直写) # 在配置界面中一般有“Write Through”等选项。使用此策略后，RAID 卡向虚拟磁盘直接写入数据，不经过 Cache。当磁盘子系统接收到所有传输数据后，控制器将给主机返回数据传输完成信号。此种方式不要求 RAID 卡支持数据掉电保护功能，即使超级电容故障，也无影响。该写策略的缺点是写入速度较低。。 与 BBU 相关的回写 # 在配置界面中一般有“Write Back with BBU”等选项。使用此策略后，当 RAID 卡 BBU 在位且状态正常时，RAID 卡到虚拟磁盘的写操作会经过 Cache 中转（即回写方式）；当 RAID 卡 BBU 不在位或 BBU 故障时，RAID 卡到虚拟磁盘的写操作会自动切换为不经过 Cache 的直接写入（即写通方式）。 阵列卡 JBOD 参考：</description></item><item><title>RBAC 相关 Manifests 详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authorization%E6%8E%88%E6%9D%83/RBAC-%E7%9B%B8%E5%85%B3-Manifests-%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Authorization%E6%8E%88%E6%9D%83/RBAC-%E7%9B%B8%E5%85%B3-Manifests-%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，参考 - Kubernetes API - 认证资源 Role apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata (ObjectMeta) Standard object&amp;rsquo;s metadata. rules([]PolicyRule)Rules holds all the PolicyRules for this Role_PolicyRule holds information that describes a policy rule, but does not contain information about who the rule applies to or which namespace the rule applies to._ rules.apiGroups ([]string) APIGroups is the name of the APIGroup that contains the resources. If multiple API groups are specified, any action requested against one of the enumerated resources in any API group will be allowed.</description></item><item><title>Redhat 优化</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/Redhat-%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/Redhat-%E4%BC%98%E5%8C%96/</guid><description>概述 Redhat 官方文档：https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Performance_Tuning_Guide/
参考文章：https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/index
Tuned 概述 Tuned 是一项服务，可监视您的系统并在某些工作负载下优化性能。Tuned 的核心是配置文件，它们可以针对不同的用例调整您的系统。
针对许多用例，已分发 Tuned 并附带了许多预定义的配置文件：
High throughput
Low latency
Saving power
可以修改为每个配置文件定义的规则，并自定义如何调整特定设备。当您切换到另一个配置文件或停用 Tuned 时，以前的配置文件对系统设置所做的所有更改都将恢复为原始状态。
您还可以配置“Tuned”以对设备使用情况的变化做出反应，并调整设置以提高活动设备的性能并降低非活动设备的功耗。
配置文件 /usr/lib/tuned/# 特定于发行版的概要文件存储在目录中。每个配置文件都有其自己的目录。该配置文件由名为 tuned.conf 的主要配置文件以及其他文件（例如帮助程序脚本）组成。 /etc/tuned/ # 如果需要定制概要文件，请将概要文件目录复制到用于定制概要文件的目录中。如果有两个同名的配置文件，则使用 /etc/tuned/ 中的自定义配置文件。
tuned-adm 命令行工具
usage: tuned-adm [-h] [&amp;ndash;version] [&amp;ndash;debug] [&amp;ndash;async] [&amp;ndash;timeout TIMEOUT]
[--loglevel LOGLEVEL] {list,active,off,profile,profile_info,recommend,verify,auto_profile,profile_mode} ... positional arguments:
{list,active,off,profile,profile_info,recommend,verify,auto_profile,profile_mode}
list list available profiles or plugins (by default profiles)
active show active profile
off switch off all tunings
profile switch to a given profile, or list available profiles if no profile is given</description></item><item><title>RedHat 与 CentOS</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/RedHat-%E4%B8%8E-CentOS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Operating-system/Unix-like-OS/RedHat-%E4%B8%8E-CentOS/</guid><description>概述 参考：
RedHat 官方文档(在这里点击 Product Documentation) RedHat7 生产环境文档 RedHat8 生产环境文档 CentOS 官方，法律 CentOS: 永远有多远就离它多远 CentOS7 好日子到头了，如何优雅的抛弃 CentOS7？ CentOS 8 退役倒计时，开发者们又吵起来了
CentOS 居然还用 python2
装 Python3 很费劲
装 python-libvirt 很费劲
安装 CentOS 参考：
GitHub 项目，rhinstaller/anaconda(RedHat 相关发行版的操作系统安装器) RedHat 系列的 .iso 安装文件中包含了 Anaconda 安装器。
注意事项 /bin,/dev,/sbin,/etc,/lib,/root, /mnt, lost+found, /proc 这些目录不能创建单独的分区并挂载，只能创建一个 / 以包含这些目录
https://unix.stackexchange.com/questions/121318/this-mount-point-is-invalid-the-root-directory-must-be-on-file-system 代码：https://github.com/rhinstaller/anaconda/blob/rhel6-branch/storage/init.py#L1084 高于 6 版本的分之代码将这个行为封装了 https://github.com/rhinstaller/anaconda/blob/rhel-9/pyanaconda/modules/storage/checker/utils.py#L31 关联文件与配置 /etc/sysconfig/ # Red Hat Linux 发行版的各种系统配置文件
CentOS 史 CentOS 法律 Centos 变为上游项目 Centos 的创始人新建了一个 Rocky 项目，旨在作为 RedHat 下游 Linux 发行版</description></item><item><title>Redis Operator</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-Operator/</guid><description>通过 Operator 部署一套生产可用的 Redis 集群 该部署方式基于 spotahome 的 redis-operator 项目
这里是 crd 可用字段的信息
创建名称空间 kubectl create ns redis 创建 operator curl -LO https://raw.githubusercontent.com/spotahome/redis-operator/master/example/operator/all-redis-operator-resources.yaml # 修改 ClusterRoleBinding 的 namespace 为 redis sed -i &amp;#39;s/namespace: default/namespace: redis/g&amp;#39; all-redis-operator-resources.yaml # 添加 ServiceAccount namespace 为 redis sed -i &amp;#39;/^kind: ServiceAccount/{N;a\ namespace: redis }&amp;#39; all-redis-operator-resources.yaml # 添加 Deployment namespace 为 redis sed -i &amp;#39;/^kind: Deployment/{N;a\ namespace: redis }&amp;#39; all-redis-operator-resources.yaml kubectl apply -f all-redis-operator-resources.yaml 配置 redis 密码认证 # “密码”修改为自己想设置的密码 echo -n &amp;quot;密码&amp;quot; &amp;gt; password kubectl create -n redis secret generic redis-auth --from-file=password 部署 redis cat &amp;gt; redis.</description></item><item><title>Redis 高可用部署</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/</guid><description>Docker 部署 Redis 高可用 Docker 部署 Redis Sentinel 模式
Sentinel 模式至少需要 3 个节点，所以这里假设有如下三个节点
172.19.42.231
172.19.42.232
172.19.42.233
创建配置文件与存储所在路径 mkdir -p /opt/redis/config mkdir -p /opt/redis/data chmod 777 /opt/redis/data 启动 Redis master 节点配置
cat &amp;gt; /opt/redis/config/redis.conf &amp;lt;&amp;lt;EOF save 900 1 maxmemory 1G EOF chmod 666 /opt/redis/config/redis.conf replica 节点配置
cat &amp;gt; /opt/redis/config/redis.conf &amp;lt;&amp;lt;EOF save 900 1 maxmemory 1G replicaof 172.19.42.231 6379 EOF chmod 666 /opt/redis/config/redis.conf 启动 Redis
docker run -d --name redis \ --network=host \ -v /opt/redis/config:/etc/redis \ -v /opt/redis/data:/data \ redis:5.</description></item><item><title>Redis 基础、高级特性与性能调优</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E7%AE%A1%E7%90%86/Redis-%E5%9F%BA%E7%A1%80%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E7%AE%A1%E7%90%86/Redis-%E5%9F%BA%E7%A1%80%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</guid><description>概述 参考：
公众号，Redis 基础、高级特性与性能调优 公众号，万字总结，Redis 性能问题排查解决手册 本文将从Redis的基本特性入手，通过讲述Redis的数据结构和主要命令对Redis的基本能力进行直观介绍。之后概览Redis提供的高级能力，并在部署、维护、性能调优等多个方面进行更深入的介绍和指导。
本文适合使用Redis的普通开发人员，以及对Redis进行选型、架构设计和性能调优的架构设计人员。
Redis是一个开源的，基于内存的结构化数据存储媒介，可以作为数据库、缓存服务或消息服务使用。
Redis支持多种数据结构，包括字符串、哈希表、链表、集合、有序集合、位图、Hyperloglogs等。
Redis具备LRU淘汰、事务实现、以及不同级别的硬盘持久化等能力，并且支持副本集和通过Redis Sentinel实现的高可用方案，同时还支持通过Redis Cluster实现的数据自动分片能力。
Redis的主要功能都基于单线程模型实现，也就是说Redis使用一个线程来服务所有的客户端请求，同时Redis采用了非阻塞式IO，并精细地优化各种命令的算法时间复杂度，这些信息意味着：
Redis是线程安全的（因为只有一个线程），其所有操作都是原子的，不会因并发产生数据异常 Redis的速度非常快（因为使用非阻塞式IO，且大部分命令的算法时间复杂度都是O(1)) 使用高耗时的Redis命令是很危险的，会占用唯一的一个线程的大量处理时间，导致所有的请求都被拖慢。（例如时间复杂度为O(N)的KEYS命令，严格禁止在生产环境中使用） Redis的数据结构和相关常用命令 本节中将介绍Redis支持的主要数据结构，以及相关的常用Redis命令。本节只对Redis命令进行扼要的介绍，且只列出了较常用的命令。如果想要了解完整的Redis命令集，或了解某个命令的详细使用方法，请参考官方文档：https://redis.io/commands
Key Redis采用Key-Value型的基本数据结构，任何二进制序列都可以作为Redis的Key使用（例如普通的字符串或一张JPEG图片）
关于Key的一些注意事项：
不要使用过长的Key。例如使用一个1024字节的key就不是一个好主意，不仅会消耗更多的内存，还会导致查找的效率降低 Key短到缺失了可读性也是不好的，例如&amp;quot;u1000flw&amp;quot;比起&amp;quot;user:1000:followers&amp;quot;来说，节省了寥寥的存储空间，却引发了可读性和可维护性上的麻烦 最好使用统一的规范来设计Key，比如&amp;quot;object-type:id:attr&amp;quot;，以这一规范设计出的Key可能是&amp;quot;user:1000&amp;quot;或&amp;quot;comment:1234:reply-to&amp;quot; Redis允许的最大Key长度是512MB（对Value的长度限制也是512MB） String String是Redis的基础数据类型，Redis没有Int、Float、Boolean等数据类型的概念，所有的基本类型在Redis中都以String体现。
与String相关的常用命令：
SET：为一个key设置value，可以配合EX/PX参数指定key的有效期，通过NX/XX参数针对key是否存在的情况进行区别操作，时间复杂度O(1) GET：获取某个key对应的value，时间复杂度O(1) GETSET：为一个key设置value，并返回该key的原value，时间复杂度O(1) MSET：为多个key设置value，时间复杂度O(N) MSETNX：同MSET，如果指定的key中有任意一个已存在，则不进行任何操作，时间复杂度O(N) MGET：获取多个key对应的value，时间复杂度O(N) 上文提到过，Redis的基本数据类型只有String，但Redis可以把String作为整型或浮点型数字来使用，主要体现在INCR、DECR类的命令上：
INCR：将key对应的value值自增1，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1) INCRBY：将key对应的value值自增指定的整型数值，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1) DECR/DECRBY：同INCR/INCRBY，自增改为自减。 INCR/DECR系列命令要求操作的value类型为String，并可以转换为64位带符号的整型数字，否则会返回错误。
也就是说，进行INCR/DECR系列命令的value，必须在[-2^63 ~ 2^63 - 1]范围内。
前文提到过，Redis采用单线程模型，天然是线程安全的，这使得INCR/DECR命令可以非常便利的实现高并发场景下的精确控制。
例1：库存控制 在高并发场景下实现库存余量的精准校验，确保不出现超卖的情况。
设置库存总量：
SET inv:remain &amp;#34;100&amp;#34; 库存扣减+余量校验：
DECR inv:remain 当DECR命令返回值大于等于0时，说明库存余量校验通过，如果返回小于0的值，则说明库存已耗尽。
假设同时有300个并发请求进行库存扣减，Redis能够确保这300个请求分别得到99到-200的返回值，每个请求得到的返回值都是唯一的，绝对不会找出现两个请求得到一样的返回值的情况。
例2：自增序列生成 实现类似于RDBMS的Sequence功能，生成一系列唯一的序列号
设置序列起始值：
SET sequence &amp;#34;10000&amp;#34; 获取一个序列值：
INCR sequence 直接将返回值作为序列使用即可。
获取一批（如100个）序列值：
INCRBY sequence 100 假设返回值为N，那么[N - 99 ~ N]的数值都是可用的序列值。</description></item><item><title>Redis 配置详解</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考:
官方文档 https://redis.io/docs/latest/operate/oss_and_stack/management/config/ Redis 可以在不使用配置文件的情况下使用内置的默认配置启动。但是一般情况，都会使用一个 Redis 的配置文件(文件名通常是 redis.conf)来启动 Redis。Redis 启动后，会将 redis.conf 文件的内容加载到内存中，通过 Redis 客户端的 config get * 命令，即可获取当前已经加载到内存中的配置。
127.0.0.1:6379&amp;gt; config get * 1) &amp;#34;dbfilename&amp;#34; 2) &amp;#34;dump.rdb&amp;#34; 3) &amp;#34;requirepass&amp;#34; 4) &amp;#34;&amp;#34; 5) &amp;#34;masterauth&amp;#34; 6) &amp;#34;&amp;#34; ....... 后略 配置文件的写法非常简单。redis.conf 由 Directives(指令) 组成，每条指令一行。而 Directives 分为两部分
Keyword(关键字) # 该指令的含义 Arguments(参数) # Redis 执行该指令时的行为 格式如下：
# 关键字 参数(多个参数以空格分隔) Keyword Argument1 Argument2 ... ArugmentN 通过命令函参数传递配置 通过命令行传递参数的格式与 redis.conf 文件中配置格式完全相同，只不过关键字前面有个 -- 前缀。比如：
redis-server --port 6380 --replicaof 127.0.0.1 6379 生成的内存中配置如下：</description></item><item><title>Replication(复制) 模式</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Replication%E5%A4%8D%E5%88%B6-%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Replication%E5%A4%8D%E5%88%B6-%E6%A8%A1%E5%BC%8F/</guid><description>概述 参考：
官方文档 基本原理 主从复制模式中包含 一个主数据库实例(master) 与 一个或多个从数据库实例(slave)，如下图
客户端可对主数据库进行读写操作，对从数据库进行读操作，主数据库写入的数据会实时自动同步给从数据库。
具体工作机制为：
slave 启动后，向 master 发送 SYNC 命令，master 接收到 SYNC 命令后通过 bgsave 保存快照(即上文所介绍的 RDB 持久化)，并使用缓冲区记录保存快照这段时间内执行的写命令
master 将保存的快照文件发送给 slave，并继续记录执行的写命令
slave 接收到快照文件后，加载快照文件，载入数据
master 快照发送完后开始向 slave 发送缓冲区的写命令，slave 接收命令并执行，完成复制初始化
此后 master 每次执行一个写命令都会同步发送给 slave，保持 master 与 slave 之间数据的一致性
2. 部署示例
redis.conf 的主要配置
###网络相关### # bind 127.0.0.1 # 绑定监听的网卡IP，注释掉或配置成0.0.0.0可使任意IP均可访问 protected-mode no # 关闭保护模式，使用密码访问 port 6379 # 设置监听端口，建议生产环境均使用自定义端口 timeout 30 # 客户端连接空闲多久后断开连接，单位秒，0表示禁用 ###通用配置### daemonize yes # 在后台运行 pidfile /var/run/redis_6379.pid # pid进程文件名 logfile /usr/local/redis/logs/redis.</description></item><item><title>Resource Record(资源记录)</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/Resource-Record%E8%B5%84%E6%BA%90%E8%AE%B0%E5%BD%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/Resource-Record%E8%B5%84%E6%BA%90%E8%AE%B0%E5%BD%95/</guid><description>概述 参考：
RR 定义的格式：NAME [TTL] CLASS RR-TYPE VALUE（注意：格式中的域名都要带根域名，即域名最后都要加一个 . ）
NAME 和 VALUE # 不同的 RR-TYPE 有不同的格式 CLASS：IN TYPE 资源记录类型：A，AAAA，PTR，SOA，NS，CNAME，MX 等： SRV 格式：域名系统中用于指定服务器提供服务的位置（如主机名和端口） name：_服务._协议.名称. value：优先级 权重 端口 主机. SOA 格式：Start Of Authority：起始授权记录，一个区域解析库有且只能有一个 SOA 记录，而且必须为解析库第一条记录 name：当前区域的名字，例如”baidu.com.“ value (属性) 当前区域的主 DNS 服务器的 FQDN，也可以使用当前区域的名字 当前区域管理员的邮箱地址，但是地址中不能用@符号，@符号用.替换 （主从服务协调属性的定义以及否定结果的统一的 TTL） NS 格式：Name Server：专用于标明当前区域的 DNS 服务器 name：当前区域的名字 value：当前区域的某 DNS 服务器的名字，例如 ns.baidu.com.;(一个区域可以有多个 NS 记录) MX 格式：Mail eXchanger：邮件交换器 TTL 可以从全局继承 A/AAAA 格式：Address，A 格式用于实现将 FQDN 解析为 IPv4(AAAA 格式用于将 FQDN 解析为 IPv6) name: value: PTR 格式：PoinTeR，用于将 IP 解析为 FQDN name：IP，特殊格式，反写 IP，比如 1.</description></item><item><title>revision概念</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/revision-%E6%A6%82%E5%BF%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Etcd/revision-%E6%A6%82%E5%BF%B5/</guid><description>每次 key 的 value 改变，version 都会+1
revision 概念
Etcd 存储数据时，并不是像其他的 KV 存储那样，存放数据的键做为 key，而是以数据的 revision 做为 key，键值做为数据来存放。如何理解 revision 这个概念，以下面的例子来说明。
比如通过批量接口两次更新两对键值，第一次写入数据时，写入和，在 Etcd 这边的存储看来，存放的数据就是这样的：
revision={1,0}, key=key1, value=value1 revision={1,1}, key=key2, value=value2 而在第二次更新写入数据和后，存储中又记录（注意不是覆盖前面的数据）了以下数据：
revision={2,0}, key=key1, value=update1 revision={2,1}, key=key2, value=update2 其中 revision 有两部分组成，第一部分成为 main revision，每次事务递增 1；第二部分称为 sub revision，一个事务内的一次操作递增 1。 两者结合，就能保证每次 key 唯一而且是递增的。
但是，就客户端看来，每次操作的时候是根据 Key 来进行操作的，所以这里就需要一个 Key 映射到当前 revision 的操作了，为了做到这个映射关系，Etcd 引入了一个内存中的 Btree 索引，整个操作过程如下面的流程所示。
查询时，先通过内存中的 btree 索引来查询该 key 对应的 keyIndex 结构体，然后再根据这个结构体才能去 boltdb 中查询真实的数据返回。
所以，下面先展开讨论这个 keyIndex 结构体和 btree 索引。</description></item><item><title>Rook+Ceph 部署与清理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook+Ceph-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook+Ceph-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/</guid><description>Rook+Ceph 部署 官方文档：https://rook.github.io/docs/rook/master/ceph-quickstart.html
部署环境准备 kubernetes 集群准备
在集群中至少有三个节点可用，满足 ceph 高可用要求，这里已配置 master 节点使其支持运行 pod。
rook 使用存储方式
rook 默认使用所有节点的所有资源，rook operator 自动在所有节点上启动 OSD 设备，Rook 会用如下标准监控并发现可用设备：
设备没有分区
设备没有格式化的文件系统
Rook 不会使用不满足以上标准的设备。另外也可以通过修改配置文件，指定哪些节点或者设备会被使用。
添加新磁盘
这里在所有节点添加 1 块 50GB 的新磁盘：/dev/sdb，作为 OSD 盘，提供存储空间，添加完成后扫描磁盘，确保主机能够正常识别到：
#扫描 SCSI 总线并添加 SCSI 设备
for host in $(ls /sys/class/scsi_host) ; do echo &amp;ldquo;- - -&amp;rdquo; &amp;gt; /sys/class/scsi_host/$host/scan; done
#重新扫描 SCSI 总线
for scsi_device in $(ls /sys/class/scsi_device/); do echo 1 &amp;gt; /sys/class/scsi_device/$scsi_device/device/rescan; done
#查看已添加的磁盘，能够看到 sdb 说明添加成功</description></item><item><title>Rook+Ceph 的 osd 管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook+Ceph-%E7%9A%84-osd-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook+Ceph-%E7%9A%84-osd-%E7%AE%A1%E7%90%86/</guid><description>官方文档：https://rook.github.io/docs/rook/master/ceph-osd-mgmt.html</description></item><item><title>Rook+Ceph 现存问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook+Ceph-%E7%8E%B0%E5%AD%98%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/CSI/Rook/Rook+Ceph-%E7%8E%B0%E5%AD%98%E9%97%AE%E9%A2%98/</guid><description>k8s 版本：1.18.8
rook-ceph 的问题 使用 pvc 后出现 Failed to list *v1beta1.VolumeSnapshotContent: the server could not find the requested resource (get volumesnapshotcontents.snapshot.storage.k8s.io)
解决方式：暂无
清理 rook-ceph 后出现 Operation for &amp;ldquo;/var/lib/kubelet/plugins/rbd.csi.ceph.com/csi.sock&amp;rdquo; failed.&amp;quot;
问题跟踪：https://github.com/rook/rook/issues/4359
Failed to list *v1.PartialObjectMetadata: the server could not find the requested resource 问题跟踪：https://github.com/kubernetes/kubernetes/issues/79610
CRD 删除后，controller-manager 依然会持续跟踪，并报告错误
解决方式：
暂无</description></item><item><title>rp_filter</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/rp_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/net%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/rp_filter/</guid><description>rp_filter 参数应用实例
rp_filter 参数示例
假设机器有 2 个网口:
eth0: 192.168.1.100
eth1：200.153.1.122
数据包源 IP：10.75.153.98，目的 IP：200.153.1.122
系统路由表配置为：
[root@localhost ~]# route -n
Kernel IP routing table
Destination Gateway Genmask Flags Metric Ref Use Iface
default 192.168.1.234 0.0.0.0 UG 0 0 0 eth0
192.168.120.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0
10.75.153.98 0.0.0.0 255.255.255.0 U 0 0 0 eth0
系统 rp_filter 参数的配置为：
[root@localhost ~]# sysctl -a | grep rp_filter
net.ipv4.conf.all.rp_filter=1
net.ipv4.conf.default.rp_filter=1
如上所示，数据包发到了 eth1 网卡，如果这时候开启了 rp_filter 参数，并配置为 1，则系统会严格校验数据包的反向路径。从路由表中可以看出，返回响应时数据包要从 eth0 网卡出，即请求数据包进的网卡和响应数据包出的网卡不是同一个网卡，这时候系统会判断该反向路径不是最佳路径，而直接丢弃该请求数据包。（业务进程也收不到该请求数据包）</description></item><item><title>RSA 密钥生成的步骤</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/RSA/RSA-%E5%AF%86%E9%92%A5%E7%94%9F%E6%88%90%E7%9A%84%E6%AD%A5%E9%AA%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Cryptography/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86/RSA/RSA-%E5%AF%86%E9%92%A5%E7%94%9F%E6%88%90%E7%9A%84%E6%AD%A5%E9%AA%A4/</guid><description>参考：阮一峰
六、密钥生成的步骤
我们通过一个例子，来理解 RSA 算法。假设爱丽丝要与鲍勃进行加密通信，她该怎么生成公钥和私钥呢？
第一步，随机选择两个不相等的质数 p 和 q。
爱丽丝选择了 61 和 53。（实际应用中，这两个质数越大，就越难破解。）
第二步，计算 p 和 q 的乘积 n。
爱丽丝就把 61 和 53 相乘。
n = 61×53 = 3233
n 的长度就是密钥长度。3233 写成二进制是 110010100001，一共有 12 位，所以这个密钥就是 12 位。实际应用中，RSA 密钥一般是 1024 位，重要场合则为 2048 位。
第三步，计算 n 的欧拉函数 φ(n)。
根据公式：
φ(n) = (p-1)(q-1)
爱丽丝算出 φ(3233)等于 60×52，即 3120。
第四步，随机选择一个整数 e，条件是 1&amp;lt; e &amp;lt; φ(n)，且 e 与 φ(n) 互质。
爱丽丝就在 1 到 3120 之间，随机选择了 17。（实际应用中，常常选择 65537。）</description></item><item><title>Rsyslog</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Rsyslog/Rsyslog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Rsyslog/Rsyslog/</guid><description>概述 参考：
官网 官方文档，配置 - 模块 GitHub 项目，rsyslog/rsyslog Wiki, Rsyslog Manual(手册), syslog(3) Manual(手册), rsyslogd(8) Arch 文档，Systemd-Journal-配合 syslog 使用 Rocket-fast system for log processing(像火箭一样快的日志处理系统，简称 rsyslog) 是一款开源应用程序，用于 Unix-like OS，可以在 IP 网络中转发日志消息。Rsyslog 实现了基本的 Syslog 协议，并扩展了丰富的功能，比如基于内容的过滤、排队处理离线输出、支持模块、灵活的配置、使用 TCP 传输 等等.
RsysLog 是一个日志统一管理的程序。通过 rsyslogd 这个守护进程提供服务，rsyslogd 程序是对 syslogd 的扩展，提供了更多的功能和可靠性。
Rsyslog 提供了一个符合 RFC 5424 标准的日志消息系统。
RsysLog 的特点：
可以监听在某个端口上作为日志服务器，来收集多个主机的日志 RsysLog 自带多个模块，可以通过模块来实现更多的功能。以 im 开头的是在收集日志时候所用到的，以 om 开头的是在输出日志时用到的(比如把收集到的日志保存在某一文件中)。 Rsyslog 项目始于 2004 年，当时 rsyslog 的主要作者 Rainer Gerhards 决定编写一个新的强大的 syslog 守护进程来与 syslog-ng 竞争，因为根据作者的说法，“一个新的主要参与者将防止单一文化并提供丰富的选择自由。”
Moules(模块) Rsyslog 采用模块化设计，可以通过加载模块来动态加载功能，模块也可以由任何第三方编写，只要符合 Rsyslog 规范即可。</description></item><item><title>rule 与 route</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ip/rule-%E4%B8%8E-route/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Iproute-%E5%B7%A5%E5%85%B7%E5%8C%85/ip/rule-%E4%B8%8E-route/</guid><description>概述 参考：
Manual(手册)，ip-route(8) Manual(手册)，ip-rule(8) route - 路由条目管理 route 可以操作内核路由表中的条目。直接使用命令可以列出 main 路由表中的条目：
~]# ip route default via 172.19.42.1 dev ens3 proto static 172.19.42.0/24 dev ens3 proto kernel scope link src 172.19.42.248 注意：如果默认网关已由 DHCP 分配，并且配置文件中指定了具有相同度量的同一网关，则在启动或启动接口时将发生错误。可能会显示以下错误消息：RTNETLINK answers:File exists。可以忽略此错误。
目的地址 via
下一跳 dev
网络设备 proto
生成路由条目的方式 scope
覆盖范围 源地址 default 172.19.42.1 ens3 static 172.19.42.0/24 ens3 kernel link 172.19.42.248 Route Type(路由类型)
unicast unreachable blackhole prohibit local broadcast throw nat anycast multicast Route Tables(路由表)
Linux-2.x 版本内核以后，可以根据 SELECTOR(选择器) 将数据包交给不同的路由表进行路由处理。这些路由表由 1 到 232 范围内的数字表示(/etc/iproute2/rt_tables 文件中可以为数字起一个别名)。默认情况下，所有普通路由规则都会插入名为 main 的路由表中(main 路由表的 ID 为 254)。ip rule 命令可以对路由表进行控制。</description></item><item><title>Rust</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Rust/Rust/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Rust/Rust/</guid><description>概述 参考：
GitHub 项目，rust-lang/rust 官网 官方文档 学习资料 B 站-软件工艺师，Rust 编程语言入门教程（Rust 语言/Rust 权威指南配套）
公众号 - 张晋涛，我的 Rust 之旅，以及如何学习 Rust
Hello World 代码：hello_world.rs
fn main() { println!(&amp;#34;Hello, world!&amp;#34;); } $ rustc main.rs $ ./main Hello, world! Rust 语言关键字 参考：
官方文档 as - perform primitive casting, disambiguate the specific trait containing an item, or rename items in use and extern crate statements async - return a Future instead of blocking the current thread await - suspend execution until the result of a Future is ready break - exit a loop immediately const - define constant items or constant raw pointers continue - continue to the next loop iteration crate - link an external crate or a macro variable representing the crate in which the macro is defined dyn - dynamic dispatch to a trait object else - fallback for if and if let control flow constructs enum - define an enumeration extern - link an external crate, function, or variable false - Boolean false literal fn - define a function or the function pointer type for - loop over items from an iterator, implement a trait, or specify a higher-ranked lifetime if - branch based on the result of a conditional expression impl - implement inherent or trait functionality in - part of for loop syntax let - bind a variable loop - loop unconditionally match - match a value to patterns mod - define a module move - make a closure take ownership of all its captures mut - denote mutability in references, raw pointers, or pattern bindings pub - denote public visibility in struct fields, impl blocks, or modules ref - bind by reference return - return from function Self - a type alias for the type we are defining or implementing self - method subject or current module static - global variable or lifetime lasting the entire program execution struct - define a structure super - parent module of the current module trait - define a trait true - Boolean true literal type - define a type alias or associated type union - define a union and is only a keyword when used in a union declaration unsafe - denote unsafe code, functions, traits, or implementations use - bring symbols into scope where - denote clauses that constrain a type while - loop conditionally based on the result of an expression Rust 语言规范 参考：</description></item><item><title>RustDesk</title><link>https://desistdaydream.github.io/docs/Utils/%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/RustDesk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/RustDesk/</guid><description>概述 参考：
GitHub 项目，rustdesk/rustdesk 官网 部署中继器 sudo docker run -it --name hbbs --net=host --rm \ -p 21115:21115 -p 21116:21116 -p 21116:21116/udp -p 21118:21118 \ -v `pwd`:/root \ rustdesk/rustdesk-server hbbs -r &amp;lt;relay-server-ip[:port]&amp;gt; sudo docker run -it --net=host --rm --name hbbr \ -p 21117:21117 -p 21119:21119 \ -v `pwd`:/root \ rustdesk/rustdesk-server hbbr docker compose version: &amp;#39;3&amp;#39; networks: rustdesk-net: external: false services: hbbs: container_name: hbbs ports: - 21115:21115 - 21116:21116 - 21116:21116/udp - 21118:21118 image: rustdesk/rustdesk-server:latest command: hbbs -r rustdesk.</description></item><item><title>Samba</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Samba/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Samba/</guid><description>概述 参考：Wiki, Samba
Samba 是 SMB 协议的实现工具。
Samba 部署 Samba 关联文件 /etc/samba/smb.conf # samba 程序运行时加载的配置文件</description></item><item><title>Samba 部署</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Samba-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Samba-%E9%83%A8%E7%BD%B2/</guid><description>Linux 下部署 Samba 服务环境的操作记录 关于 Linux 和 Windows 系统之间的文件传输，很多人选择使用 FTP，相对较安全，但是有时还是会出现一些问题，比如上传文件时，文件名莫名出现乱码，文件大小改变等问题。相比较来说，使用 Samba 作为文件共享，就省事简洁多了。Samba 服务器通信协议（Server Messages Block）就是是为了解决局域网内的文件或打印机等资源的共享服务问题，让多个主机之间共享文件变成越来越简单。下面简单介绍下，在 Centos7 下部署 Samba 服务的操作记录（测试机 192.168.10.204）：
1）安装 Samba [root@samba-server ~]# cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) [root@samba-server ~]# rpm -qa|grep samba [root@samba-server ~]# yum install -y samba 2）安全角度考虑，需要设置防火墙策略（不要关闭防火墙） 添加samba服务到防火墙策略中 [root@samba-server ~]# firewall-cmd --add-service samba --permanent success 重启防火墙 [root@samba-server ~]# firewall-cmd --reload success 查看samba服务是否添加到防火墙中： [root@samba-server ~]# firewall-cmd --list-all|grep samba services: ssh dhcpv6-client samba 记住：一定要关闭selinux（否则会造成windows客户机连接Samba失败） [root@samba-server ~]# vim /etc/sysconfig/selinux .</description></item><item><title>Samba 配置详解</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Samba-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Samba-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考： Manual(手册)
Samba 通过配置文件来配置运行时行为。
文件格式 Samba 的配置文件格式类似于 INI 格式的配置，由 Sections(部分) 和 **Parameters(参数)**组成。参数是以 = 分割的 键/值对。
配置文件中的每个 Sections(部分) 用于描述共享资源(Note：global 部分除外)。Section 的名称就是共享资源的名称，Section 中的 Parameters 定义共享资源的属性。
用白话说就是，加入有一个名为 share_dir 的 Section，则 Windows 中兴就会看到一个名为 share_dir 的目录
有 3 个特殊的 Sections，global、homes、printers，这 3 个特殊部分，是配置文件预留的，用于定义一些通用的运行时配置。
注意：其他的 Sections 不能以这 3 个特殊的 Sections 的名字命名。
配置文件详解 global 部分 homes 部分 printers 部分 其他部分</description></item><item><title>SDK 开发</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/SDK-%E5%BC%80%E5%8F%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/SDK-%E5%BC%80%E5%8F%91/</guid><description>概述 参考：
经典的 SDK 设计方式 https://github.com/huaweicloud/huaweicloud-sdk-go-v3 https://github.com/wujiyu115/yuqueg 目录结构示例
pkg/my_sdk/ ├── README.md ├── core │ ├── v1 │ │ └── client.go │ └── v2 │ ├── client.go │ └── log.go ├── index.go ├── services │ ├── v1 │ │ ├── book.go │ │ └── models │ │ ├── model_request.go │ │ └── model_response.go │ └── v2 │ ├── doc.go │ ├── group.go │ ├── models │ │ ├── model_request.go │ │ └── model_response.</description></item><item><title>SDN(软件定义网路)</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/SDN%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E7%BD%91%E8%B7%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/SDN%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E7%BD%91%E8%B7%AF/</guid><description>概述 参考：
Wiki, Software-defined networking Software Defined Networking(软件定义网络，简称 SDN) 技术是一种网络管理方法，它支持动态的、以编程方式高效的网络配置，以提高网络性能和监控，使其更像云计算，而不是传统的网络管理。[1] SDN 旨在解决传统网络的静态架构分散且复杂的事实，而当前网络需要更多的灵活性和易于故障排除。SDN 试图通过将网络数据包的转发过程（数据平面）与路由过程（控制平面）分离，将网络智能集中在一个网络组件中。[2]该控制平面由一个或多个控制器组成，这些控制器被认为是包含整个智能的 SDN 网络的大脑。然而，智能中心化在安全性、[1]可扩展性和弹性[1]方面有其自身的缺点，这是 SDN 的主要问题。
自OpenFlow协议于 2011 年出现以来，SDN 通常与OpenFlow协议（用于与网络平面元素进行远程通信，以确定网络数据包通过网络交换机的路径）相关联。然而，自 2012 年[3] [4] OpenFlow 对于许多公司不再是独家解决方案，他们增加了专有技术。其中包括Cisco Systems的开放网络环境和Nicira的网络虚拟化平台。 SD-WAN将类似技术应用于广域网(WAN)。[5]
SDN 技术目前可用于需要极快故障转移的工业控制应用，称为操作技术 (OT) 软件定义网络 (SDN)。OT SDN 技术是一种在关键基础设施网络的环境强化硬件上管理网络访问控制和以太网数据包交付的方法。OT SDN 将控制平面的管理从集中在流控制器中的交换机抽象出来，并将 SDN 应用为交换机中的底层控制平面。去除了传统控制平面，简化了交换机，同时集中控制平面管理。OT SDN 中使用的通用控制平面标准是 OpenFlow，使其可与其他 SDN 解决方案互操作，不同之处在于 OpenFlow 是交换机中唯一的控制平面，并且交换机在电源循环期间保留流量，并且所有流量和冗余都经过主动流量工程设计因此交换机可以执行转发，它们被配置为在有或没有在线流量控制器的情况下执行。OT SDN 在性能、网络安全和态势感知方面为工业网络提供了优势。性能优势是通过使用 OpenFlow 中的快速故障转移组的主动流量工程意外事件实现的，从而在微秒内从链路或交换机故障中恢复网络，而不是像生成树技术那样的毫秒级。另一个性能优势是环路缓解是通过流量工程路径规划完成的，而不是阻塞端口，允许系统所有者主动使用所有端口。OT SDN 的网络安全优势在于交换机默认拒绝，流是允许流量转发的规则。这提供了强大的网络访问控制，可以在每一跳从 OSI 模型的第 1 层到第 4 层检查数据包。由于旧控制平面不再存在，因此移除了旧控制平面安全漏洞。MAC 表欺骗和 BPDU 欺骗不再可能，因为两者都不存在于 OT SDN 交换机中。旋转和网络侦察不再适用于适当的流编程，因为仅允许转发结合物理位置和路径与虚拟数据包过滤的流量。OT SDN 的态势感知优势使网络所有者能够了解其网络上有哪些设备，哪些对话可以和正在发生，以及这些对话可以在谁之间发生。OT SDN 网络技术允许以太网满足关键基础设施测量和控制的苛刻通信消息交换要求，并简单地为系统所有者提供对哪些设备可以连接到网络、这些设备可以连接到哪里以及每个设备可以进行哪些对话的控制有。OT SDN 的态势感知优势使网络所有者能够了解其网络上有哪些设备，哪些对话可以和正在发生，以及这些对话可以在谁之间发生。OT SDN 网络技术允许以太网满足关键基础设施测量和控制的苛刻通信消息交换要求，并简单地为系统所有者提供对哪些设备可以连接到网络、这些设备可以连接到哪里以及每个设备可以进行哪些对话的控制有。OT SDN 的态势感知优势使网络所有者能够了解其网络上有哪些设备，哪些对话可以和正在发生，以及这些对话可以在谁之间发生。OT SDN 网络技术允许以太网满足关键基础设施测量和控制的苛刻通信消息交换要求，并简单地为系统所有者提供对哪些设备可以连接到网络、这些设备可以连接到哪里以及每个设备可以进行哪些对话的控制有。</description></item><item><title>Sealer</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/SealOS/Sealer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/SealOS/Sealer/</guid><description>概述 参考：
GitHub 项目，sealerio/sealer 由 sealos 作者进入阿里后开源的一款工具，用于将应用程序的所以依赖和 Kubernetes 打包成 ClusterImage。然后通过 ClusterImage 将此应用程序分发到任何位置。
问题 尴尬。。。快速开始都报错了。。。
镜像目录结构
. ├── bin │ ├── conntrack │ ├── containerd-rootless-setuptool.sh │ ├── containerd-rootless.sh │ ├── crictl │ ├── kubeadm │ ├── kubectl │ ├── kubelet │ ├── nerdctl │ └── seautil ├── cni │ └── calico │ └── calico.yaml.tmpl ├── cri │ ├── containerd │ ├── containerd-shim │ ├── containerd-shim-runc-v2 │ ├── ctr │ ├── docker │ ├── dockerd │ ├── docker-init │ ├── docker-proxy │ ├── rootlesskit │ ├── rootlesskit-docker-proxy │ ├── runc │ └── vpnkit ├── etc │ ├── 10-kubeadm.</description></item><item><title>Security Context(安全环境)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%AE%A1%E7%90%86/Security-Context%E5%AE%89%E5%85%A8%E7%8E%AF%E5%A2%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%AE%A1%E7%90%86/Security-Context%E5%AE%89%E5%85%A8%E7%8E%AF%E5%A2%83/</guid><description>概述 参考：
官方文档，任务-配置 Pod 和 Containers 公众号-阳明 Security Context(安全环境) 用来定义 Pod 或 Container 的特权与访问控制设置。 安全上下文包括但不限于：
自主访问控制（Discretionary Access Control）：基于 用户 ID（UID）和组 ID（GID）. 来判定对对象（例如文件）的访问权限。 安全性增强的 Linux（SELinux）： 为对象赋予安全性标签。 以特权模式或者非特权模式运行。 Linux 权能: 为进程赋予 root 用户的部分特权而非全部特权。 AppArmor：使用程序框架来限制个别程序的权能。 Seccomp：过滤进程的系统调用。 AllowPrivilegeEscalation：控制进程是否可以获得超出其父进程的特权。 此布尔值直接控制是否为容器进程设置 [no_new_privs](https://www.kernel.org/doc/Documentation/prctl/no_new_privs.txt)标志。 当容器以特权模式运行或者具有 CAP_SYS_ADMIN 权能时，AllowPrivilegeEscalation 总是为 true。 readOnlyRootFilesystem：以只读方式加载容器的根文件系统。 以上条目不是安全上下文设置的完整列表 &amp;ndash; 请参阅 SecurityContext 了解其完整列表。 关于在 Linux 系统中的安全机制的更多信息，可参阅 Linux 内核安全性能力概述。
特别注意：限制自由，会产生很多问题，比如：
使用 hostPath 类型的 volume 时，如果容器不以 root 用户运行，则无法对 hostPath 所在目录执行操作，任何写操作将会提示权限不够。因为目录权限 755 应该了解的 10 个 Kubernetes 安全上下文配置 在 Kubernetes 中安全地运行工作负载是很困难的，有很多配置都可能会影响到整个 Kubernetes API 的安全性，这需要我们有大量的知识积累来正确的实施。Kubernetes 在安全方面提供了一个强大的工具 securityContext，每个 Pod 和容器清单都可以使用这个属性。在本文中我们将了解各种 securityContext 的配置，探讨它们的含义，以及我们应该如何使用它们。 securityContext 设置在 PodSpec 和 ContainerSpec 规范中都有定义，这里我们分别用[P]和[C]来表示。需要注意的是，如果一个设置在两个作用域中都可以使用和配置，那么我们应该优先考虑设置容器级别的。</description></item><item><title>sed</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed/</guid><description>概述 参考：
官方文档：https://www.gnu.org/software/sed/ 官方手册：https://www.gnu.org/software/sed/manual/sed.html 官方文档：https://www.gnu.org/software/sed/manual/sed.html#Execution-Cycle https://opus.konghy.cn/sed-refer/ https://github.com/liquanzhou/ops_doc/blob/master/shell%E5%AE%9E%E4%BE%8B%E6%89%8B%E5%86%8C.sh#L2925 https://mp.weixin.qq.com/s/tKvg69WvAFLJSfHsgRe1Yw sed 是一种新型的，非交互式的编辑器。它能执行与编辑器 vi 相同的编辑任务。
sed 是一种 stream editor(流编辑器)，逐行处理文件(或输入)，并将结果发送到标准输出。处理时，把当前处理的行存储在临时缓冲区中，称为 pattern space( 模式空间)，接着用 sed 命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行，执行下一个循环。如果没有使诸如‘D’的特殊命令，那会在两个循环之间清空模式空间，但不会清空保留空间。这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。
功能：主要用来自动编辑一个或多个文件,简化对文件的反复操作,编写转换程序等。 sed 工作原理 sed 实际上是一个循环结构，该循环用来对输入给 sed 文本的每一行执行下列操作：
sed 从输入内容中读取一行，删除任何尾随的换行符，并将该行保存到 模式空间 中。 对模式空间中的内容，执行 COMMAND。执行之前需要根据 ADDR(行定位)，验证模式空间中的行是否符合 ADDR 中给定的条件。 只有符合条件的，COMMAND 才会执行 上一步完成后，模式空间中的内容会打印到标准输出中。如果删除了末尾的换行符，则会添加回去。(如果使用了 -n 选项，则不会将模式空间中的行输出) 然后回到循环体的开头，继续处理输入内容的下一行 除非有特殊命令（例如“d 使用&amp;rsquo;），则在两个循环之间删除模式空间。另一方面，保持空间可在周期之间保持其数据（请参见命令&amp;rsquo;H&amp;rsquo;，&amp;lsquo;H&amp;rsquo;，&amp;lsquo;X&amp;rsquo;，&amp;lsquo;G&amp;rsquo;，&amp;lsquo;G&amp;rsquo;在两个缓冲区之间移动数据）
Syntax(语法) sed [OPTIONS] SCRIPT FILE(s)
OPTIONS -e, &amp;ndash;expression=&amp;lt;SCRIPT&amp;gt; # 以选项中的指定的 SCRIPT 来处理输入的文本文件，常用来在一行命令中，执行两个 sed SCRIPT -f, &amp;ndash;file=&amp;lt;SCRIPT&amp;gt; # 以选项中指定的 SCRIPT 文件来处理输入的文本文件,把 sed 相关命令写进文件里，直接引用该文件中的命令进行操作 -i # 直接编辑原文件，sed 操作的内容不输出到屏幕，直接更改文件内容 -n, &amp;ndash;quiet, -silent # 禁止模式空间中的内容在标准输出中打印 通常与 p 命令一同使用，用来仅显示 sed 操作的行。 -r, &amp;ndash;regexp-extended # 允许在 SCRIPT 中使用扩展的正则表达式。如果在 SCRIPT 中使用正则，且不使用该选项，运行就会报错 SCRIPT SCRIPT 是 sed 在处理文本时主要依赖的部分，脚本包含多个部分，至少要具有一个 COMMAND</description></item><item><title>SELinux</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/SELinux/SELinux/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/SELinux/SELinux/</guid><description>概述 参考：
Wiki, Security-Enhanced Linux Security Enhanced Linux(安全强化的 Linux，简称 SELinux) 是由美国国家安全局 (NSA) 开发的，当初开发这玩意儿的目的是因为很多企业界发现， 通常系统出现问题的原因大部分都在于『内部员工的资源误用』所导致的，实际由外部发动的攻击反而没有这么严重。 那么什么是『员工资源误用』呢？举例来说，如果有个不是很懂系统的系统管理员为了自己设定的方便，将网页所在目录 /var/www/html/ 的权限设定为 drwxrwxrwx 时，你觉得会有什么事情发生？
当初设计的目标：避免资源的误用
现在我们知道所有的系统资源都是透过进程来进行存取的，那么 /var/www/html/ 如果设定为 777 ，代表所有进程均可对该目录存取，万一你真的有启动 WWW 服务器软件，那么该软件所触发的进程将可以写入该目录， 而该进程却是对整个 Internet 提供服务的！只要有心人接触到这支进程，而且该进程刚好又有提供用户进行写入的功能， 那么外部的人很可能就会对你的系统写入些莫名其妙的东西！那可真是不得了！一个小小的 777 问题可是大大的！
为了控管这方面的权限与进程的问题，所以美国国家安全局就着手处理操作系统这方面的控管。 由于 Linux 是自由软件，程序代码都是公开的，因此她们便使用 Linux 来作为研究的目标， 最后更将研究的结果整合到 Linux 核心里面去，那就是 SELinux 啦！所以说， SELinux 是整合到核心的一个模块喔！ 更多的 SELinux 相关说明可以参考：
这也就是说：其实 SELinux 是在进行进程、文件等细部权限设定依据的一个核心模块！ 由于启动网络服务的也是进程，因此刚好也能够控制网络服务能否存取系统资源的一道关卡！ 所以，在讲到 SELinux 对系统的访问控制之前，我们得先来回顾一下之前谈到的系统文件权限与用户之间的关系。因为先谈完这个你才会知道为何需要 SELinux 的啦！
目前 SELinux 依据启动与否，共有三种模式，分别如下：
enforcing：强制模式，代表 SELinux 运作中，且已经正确的开始限制 domain/type 了； permissive：宽容模式：代表 SELinux 运作中，不过仅会有警告讯息并不会实际限制 domain/type 的存取。这种模式可以运来作为 SELinux 的 debug 之用 disabled：关闭，SELinux 并没有实际运作。 SELinux 关联文件与配置 /etc/selinux/config #</description></item><item><title>Sentinel 配置详解</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Sentinel-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Sentinel-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>参考：官方文档 1、
Sentinel 的配置与 Redis 配置用法相同，当使用 &amp;ndash;sentinel 参数启动 redis 时，则 redis 程序加载配置文件时，将只会特定的配置信息
Sentinel 配置环境 port &amp;lt;INT&amp;gt; # Sentinel 监听的端口，Sentinel 之间使用该端口通讯 sentinel monitor &amp;lt;master-group-name&amp;gt; &amp;lt;IP&amp;gt; &amp;lt;PORT&amp;gt; &amp;lt;QUORUM&amp;gt; # 指定 Sentinel 要监听的 MASTER sentinel montior mymaster 192.168.50.101 6379 1 这个配置意味着，Sentinel 监控的目标 master 节点的 IP 为 192.168.50.101、端口为 6379，最后一个数字表示投票需要的&amp;quot;最少法定人数&amp;quot;。
最少法定人数的理解：比如有 10 个 sentinal 哨兵都在监控某一个 master 节点，如果需要至少 6 个哨兵发现 master 挂掉后，才认为 master 真正 down 掉，那么这里就配置为 6，最小配置 1 台 master，1 台 slave，在二个机器上都启动 sentinal 的情况下，哨兵数只有 2 个，如果一台机器物理挂掉，只剩一个 sentinal 能发现该问题，所以这里配置成 1。</description></item><item><title>Sentinel(哨兵) 模式</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Sentinel%E5%93%A8%E5%85%B5-%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/Redis/Redis-%E9%AB%98%E5%8F%AF%E7%94%A8/Sentinel%E5%93%A8%E5%85%B5-%E6%A8%A1%E5%BC%8F/</guid><description>概述 参考：
官方文档 中文文档 博客园大佬 博客园大佬 2 Redis Sentinel(哨兵) 基于 Redis 的 Replication(复制) 模式，增加了一个名为 Sentinel 的管理程序，用来保存 Redis Replication 模式的架构信息，以及对外提供该信息。同时 sentinel 程序监控多台 Redis 状态，当 Redis 不可用时，Sentinel 将自动下线该 Redis。
注意：Sentinel(哨兵) 模式必须基于 Replication 模式，否则没有任何意义。
注意：一套 Sentinel 是可以监听多套 Replication 模式的 Redis 的组合，这样可以有效节省资源，其中每套 Replication 模式的 Redis 会使用一个 master-name 作为一个标识。
客户端操作 Redis 原理
client 访问 sentinel 集群，获取 redis 集群 master 的 ip
client 连接 redis 集群的 master 对数据进行读写操作。
Redis Sentinel 为 Redis 提供了高可用性。这意味着，可以使用 Sentinel 程序部署 Redis，这种部署可以在无需人工干预的情况下抵抗某些类型的故障。Sentinel 具有以下特性：</description></item><item><title>Server Message Block</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Server-Message-Block/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/Server-Message-Block/Server-Message-Block/</guid><description>概述 参考：
Wiki, SMB Wiki, Samba Techtarget Server Message Block(服务器消息块，简称 SMB) 是一个通信协议，该协议可以让网络中的各个节点可以共享访问 文件、打印机、串行端口，还可以提供经过身份验证的 Inter Process Communication 机制。
现在，SMB 协议主要用来让 Windows 和 Linux 之间可以互相传输文件。
CIFS</description></item><item><title>Server 与 Runner 部署</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Server-%E4%B8%8E-Runner-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Drone/Server-%E4%B8%8E-Runner-%E9%83%A8%E7%BD%B2/</guid><description>GitHub Server 官方文档：https://docs.drone.io/server/provider/github/
在 GitHub 上创建 OAuth Application，通过此连接创建。也可以点击 头像—Settings—Developer settings—OAuth Apps 来进入创建页面
在创建页面需要指明该 OAuth Application 的 name、URL、callback URL 这三个信息。下面是三个信息的例子：
Application name：Grone
Homepage URL：http://10.10.100.150 # 这个 URL 指的是将要运行 Drone 的 GitHub Server 端设备 IP。也可以使用域名来表示。
Authorization callback URL：http://10.10.100.150/login
创建完成后，会生成两个信息 Client ID 与 Client Secret。下面是这两个信息的例子
Client ID：df6dd0a1d49a4a26a151
Client Secret：26507ea48eab7612f0bd8865f9d6091608baa7f3
OAuth Application 的相关信息在安装 Drone 的 GitHub Server 端时会用到
创建一个共享密钥，该密钥用来在 Server 与 Runner 两端进行通信时进行验证。使用如下命令即可
openssl rand -hex 16 #
生成字符串为：3de4792f96c2aa9e483b36a54b23d70a
使用 docker 镜像运行 Drone 的 GitHub Server 端</description></item><item><title>Service Catalog 服务目录</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Service-Catalog-%E6%9C%8D%E5%8A%A1%E7%9B%AE%E5%BD%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E6%89%A9%E5%B1%95/Service-Catalog-%E6%9C%8D%E5%8A%A1%E7%9B%AE%E5%BD%95/</guid><description/></item><item><title>Service Monitor</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Service-Monitor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/Service-Monitor/</guid><description>Service Monitor 介绍 注意：ServiceMonitor 资源本身无法直接为目标 job 添加 label，所有 label 只能从关联的 Service 中获取，然后再通过 ServiceMonitor 资源的 spec.endpoints.relabelings 字段(就是使用 Prometheus 的 relabel 功能)，将获取到的 label 改为自己想要的
operator 根据 ServiceMonitor 的定义自动生成 Prometheus 配置文件中的 scrape 配置段中的内容。创建一个 SM，就代表要给 prometheus 配置中 scrape 配置段中加入内容。
ServiceMonitor 资源描述了 Prometheus Server 的 Target 列表，Operator 会监听这个资源的变化来动态的更新 Prometheus Server 的 Scrape Targets 并让 Prometheus Server 去 reload 配置。而该资源主要通过 Selector 根据 Labels 选取对应 Service 的 endpoints，并让 Prometheus Server 通过 Service 进行拉取 Metrics,Metrics 信息要在 http 的 url 输出符合 metrics 格式的信息,ServiceMonitor 也可以定义目标的 metrics 的 url.</description></item><item><title>service Unit</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/service-Unit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/service-Unit/</guid><description>概述 参考：
Manual(手册)，systemd.service(5) 金步国 systemd.unit 中文手册，systemd.service 中文手册 所有名称以 .service 结尾的 Unit 都是由 Systemd 控制和监督的进程。说白了，就是一个一个的“服务”，这些“服务”就是一个一个的进程。
service Unit 是 systemd 使用数量最多，使用频率最高的单元。
service 指令 ExecStart=STRING # 启动 Unit 所使用的命令。可以使用 ${VarName} 引用环境变量
ExecStartPre=STRING # 启动 Unit 之前执行的命令
ExecStartPost=STRING # 启动 Unit 之后执行的命令
ExecReload=STRING # 重启 Unit 时执行的命令
ExecStop=STRING # 停止 Unit 时执行的命令
ExecStopPost=STRING # 停止 Unit 之后执行的命令
RemainAfterExit= # 即是 Service 启动的所有进程都退出了，该 Service 是否应该被视为活动状态。默认值：no
RestartSec=INT # 自动重启当前服务间隔的时间，单位为秒（也可以用 5min 20s 这种写法）。默认值：100ms
Restart=STRING # 定义何种情况 Systemd 会自动重启当前服务。默认值：no</description></item><item><title>Service(服务)</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Service%E6%9C%8D%E5%8A%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Service%E6%9C%8D%E5%8A%A1/</guid><description>概述 参考：
官方文档，概念-服务，负载均衡，网络-服务 Service 资源可以将一组运行在 Pods 上的应用程序暴露为网络服务，这是一种抽象的功能，说白了 Service 资源实现 服务发现，执行访问 POD 的任务、4 层代理 等功能
为什么要使用 Service？
Deployment 可以部署多个副本，每个 Pod 都有自己的 IP，外界如何访问这些副本呢？通过 Pod 的 IP 吗？要知道 Pod 很可能会被频繁地销毁和重启，它们的 IP 会发生变化，用 IP 来访问不太现实。答案是 Service。Service 作为访问 Pod 的接入层来使用。service 就像 lvs 的 director 一样，充当一个调度器的作用。
Service 定义了外界访问一组特定 Pod 的方式。Service 有自己的 IP 和 PORT ，Service 为 Pod 提供了负载均衡。
可以把 Service 想象成负载均衡功能的前端，该 Service 下的 Pod 是负载均衡功能的后端。通过其自动创建的 ipvs 或者 iptables 的规则，访问 Service 的 IP:PORT，然后转发数据到后端的 Pod
Endpoints 注意：在 service 与 pod 中间，还有一个中间层，这个中间层就是 Endpoints 资源。</description></item><item><title>set 命令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/set-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/set-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
GNU 文档，Bash 参考手册-Shell 内置命令-修改 Shell 行为-Set 内置命令 https://morven.life/posts/how-to-write-robust-shell-script/ 前言 Shell 脚本会有各种坑，经常导致 Shell 脚本因为各种原因不能正常执行成功。实际上，编写健壮可靠的 Shell 脚本也是有一定的技巧的。
# 在执行Shell脚本的时候，通常都会创建一个新的Shell，比如，当我们执行： bash script.sh Bash 会创建一个新的 Shell 来执行 script.sh，同时也默认给定了这个执行环境的各种参数。set 命令可以用来修改 Shell 环境的运行参数，不带任何参数的 set 命令，会显示所有的环境变量和 Shell 函数。我们重点介绍其中最常用的四个。
set -euxo pipefail
set -x 默认情况下，Shell 脚本执行后只显示运行结果，不会展示结果是哪一行代码的输出，如果多个命令连续执行，它们的运行结果就会连续输出，导致很难分清一串结果是什么命令产生的。 set -x 用来在运行结果之前，先输出执行的那一行命令，行首以+表示是命令而非命令输出，同时，每个命令的参数也会展开，我们可以清晰地看到每个命令的运行实参，这对于 Shell 的 debug 来说非常友好。
#!/bin/bash set -x v=5 echo $v echo &amp;#34;hello&amp;#34; # output: # + v=5 # + echo 5 # 5 # + echo hello # hello 实际上，set -x 还有另一种写法 set -o xtrace。</description></item><item><title>set 与 rollout 更新资源命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/set-%E4%B8%8E-rollout-%E6%9B%B4%E6%96%B0%E8%B5%84%E6%BA%90%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/set-%E4%B8%8E-rollout-%E6%9B%B4%E6%96%B0%E8%B5%84%E6%BA%90%E5%91%BD%E4%BB%A4/</guid><description>set # 在对象上设定特定的特性 kubectl set COMMAND [OPTIONS] COMMAND
env # Update environment variables on a pod template image # 更新一个 Pod 模板的镜像 resources # Update resource requests/limits on objects with pod templates selector # Set the selector on a resource serviceaccount # Update ServiceAccount of a resource subject # Update User, Group or ServiceAccount in a RoleBinding/ClusterRoleBinding kubectl set image # 更新资源 更新资源的现有容器映像。可能的资源包括(不区分大小写)pod (po), replicationcontroller (rc), deployment (deploy), daemonset (ds), replicaset (rs)</description></item><item><title>Skaffold</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Skaffold/Skaffold/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Skaffold/Skaffold/</guid><description>概述 参考：
官方文档 Skaffold(脚手架) 是一个命令行工具，可以使得 kubernetes 原生应用的持续开发(CI/CD)变得更加简单。skaffold 可以处理构建(代码与 docker 镜像)、推送到仓库、部署到本地或者远程 kubernetes 集群中这一工作流程。使用一个简单的 yaml 配置文件来定义和执行 Pipeline。
Skaffold 特性
Skaffold 更轻量。与 Drone 和 Jenkins 等工具不同，它仅是一个命令行工具，并没有任何附加的组件。所以 Skaffold 也就无法与 SCM 对接来接收 webhook 消息。 不过也正是因为这种轻量的特性，可以将 Skaffold 集成在 Jenkins 或 Drone 中，作为 shell 命令来执行 CI/CD 的过程，使得整个流水线更加简洁明了。 在本地进行 Kubernetes 的快速开发。在 skaffold 运行之后，当在本地修改完代码之后，skaffold 可以自动触发流水线将应用程序部署到本地或者远程的 kubernetes 集群。 Skaffold 部署 下载 skaffold 命令行工具的二进制文件，并将其放在$PATH 目录中
curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 chmod +x skaffold mv skaffold /usr/local/bin 完成后，直接使用 skaffold 命令即可
Skaffold 配置 skaffold.yaml # Skaffold 通过该文件定义来定义 Pipeline 任务。</description></item><item><title>Skaffold Pipeline 详解</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Skaffold/Skaffold-Pipeline-%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Skaffold/Skaffold-Pipeline-%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档 Skaffold 默认通过 yaml 格式的名为 skaffold.yaml 的文件来指定 Pipelines 的行为。该文件应存放在项目目录的根目录中。当在项目的根目录中运行 skaffold 命令时，skaffold 将尝试从当前目录读取 skaffold.yaml 文件，来执行其内定义的 pipeline 任务。对于官方来说，skaffold.yaml 也称为 skaffold 的配置文件。
Skaffold Pipeline 的工作流程 参考：官方文档，pipeline 阶段
Skafflod 在执行 Pipeline 时，会经过 5 个 stages(阶段)。
artifacts(工件) 大意就是指工具、物品等。比如 build artifacts(构建工件)，泛指可以执行构建功能的工具，比如 docker、Jib、Bazel 等等
运行 skaffold 时，skaffold 会在项目中收集源代码并使用配置文件中指定的构建工件来进行构建。构建成功后使用标记工件为镜像设置 tag，并推送到指定的镜像仓库中。在最后，skaffold 哈可以使用指定的部署工具(kubectl、helm 等)来将构建好的代码部署到 kubernetes 集群中。下面是各个阶段的详细介绍：
Init # generate a starting point for Skaffold configuration
Build # 根据指定的构建器来构建镜像
Tag # 根据指定的策略来为镜像设置 tag
Test # test images with structure tests</description></item><item><title>Skaffold 命令行工具</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Skaffold/Skaffold-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/DevOps/Skaffold/Skaffold-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
官方文档 Skaffold 命令行工具提供以下命令
End-to-end pipelines:
skaffold run # 构建并运行一次 skaffold dev # 进入dev模式，Skaffold 将监视应用程序的源文件，并在检测到更改时将重建您的映像（或将文件同步到正在运行的容器中），推送所有新映像并将该应用程序重新部署到群集中。 skaffold debug - to run a pipeline in debug mode Pipeline building blocks for CI/CD:
skaffold build - to just build and tag your image(s) skaffold deploy - to deploy the given image(s) skaffold delete - to cleanup the deployed artifacts skaffold render - build and tag images, and output templated Kubernetes manifests Getting started with a new project:</description></item><item><title>SLI/SLO</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/SLI_SLO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/SLI_SLO/</guid><description>概述 参考：
公众号，通过 Prometheus 来做 SLI/SLO 监控展示 什么是 SLI/SLO SLI，全名 Service Level Indicator，是服务等级指标的简称，它是衡定系统稳定性的指标。
SLO，全名 Sevice Level Objective，是服务等级目标的简称，也就是我们设定的稳定性目标，比如&amp;quot;4 个 9&amp;quot;，&amp;ldquo;5 个 9&amp;quot;等。
SRE 通常通过这两个指标来衡量系统的稳定性，其主要思路就是通过 SLI 来判断 SLO，也就是通过一系列的指标来衡量我们的目标是否达到了&amp;quot;几个 9&amp;rdquo;。
如何选择 SLI 在系统中，常见的指标有很多种，比如：
系统层面：CPU 使用率、内存使用率、磁盘使用率等 应用服务器层面：端口存活状态、JVM 的状态等 应用运行层面：状态码、时延、QPS 等 中间件层面：QPS、TPS、时延等 业务层面：成功率、增长速度等 这么多指标，应该如何选择呢？只要遵从两个原则就可以：
选择能够标识一个主体是否稳定的指标，如果不是这个主体本身的指标，或者不能标识主体稳定性的，就要排除在外。 优先选择与用户体验强相关或用户可以明显感知的指标。 通常情况下，可以直接使用谷歌的 VALET 指标方法。
V：Volume，容量，服务承诺的最大容量 A：Availability，可用性，服务是否正常 L：Latency，延迟，服务的响应时间 E：Error，错误率，请求错误率是多少 T：Ticket，人工介入，是否需要人工介入 这就是谷歌使用 VALET 方法给的样例。
上面仅仅是简单的介绍了一下 SLI/SLO，更多的知识可以学习《SRE：Google 运维解密》和赵成老师的极客时间课程《SRE 实践手册》。下面来简单介绍如何使用 Prometheus 来进行 SLI/SLO 监控。
service-level-operator Service level operator 是为了 Kubernetes 中的应用 SLI/SLO 指标来衡量应用的服务指标，并可以通过 Grafana 来进行展示。</description></item><item><title>Snap</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Snap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Package-%E7%AE%A1%E7%90%86/Snap/</guid><description>概述 参考：
官网 Wiki, Sanp Snap 是 Canonical 为使用 Linux 内核的操作系统开发的用于软件打包、部署的程序
snap 既是命令行界面又是应用程序包格式 snapd 是管理和维护快照的后台服务 snapcraft 是用于构建您自己的快照的命令和框架 Snap Store 提供了一个上传 sanp 软件包的地方，供用户浏览和安装</description></item><item><title>Snapshot 命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Snapshot-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Snapshot-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方 Manual(手册)，SNAPSHOT COMMANDS snapshot-create - 从 XML 文件中创建一个 domain 的快照 https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#snapshot-create
这个命令可以在虚拟机迁移时为虚拟机还原快照的元数据。
Syntax(语法) snapshot-create DOMAIN [OPTIONS]
OPTIONS
为虚拟机还原名为 base 快照的元数据
virsh snapshot-create &amp;ndash;redefine &amp;ndash;xmlfile /var/lib/libvirt/qemu/snapshot/tj-test-spst-node-1/base.xml tj-test-spst-node-1 EXAMPLE 使用 base.xml 文件，为虚拟机 master 创建一个快照 virsh snapshot-create master base.xml snapshot-create-as - 从一组参数中创建一个 domain 的快照 https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#snapshot-create-as
EXAMPLE
为虚拟机 master 创建一个当前状态的快照，名字为 base virsh snapshot-create-as master &amp;ndash;name base snapshot-current https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#snapshot-current
snapshot-edit - 编辑指定的 domain 的快照的 XML 文件 https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#snapshot-edit
snapshot-info https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#snapshot-info
snapshot-list - 列出指定 domain 的快照 https://github.</description></item><item><title>SQLite</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/SQLite/SQLite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/SQLite/SQLite/</guid><description>概述 参考：
GitHub 项目，sqlite/sqlite 官网 Wiki, SQLite SQLite 是一种 C 语言库，实现小型，快速，自有，高可靠性，全功能，SQL 数据库引擎。 SQLite 是世界上最常用的数据库引擎。 SQLite 内置于所有移动电话和大多数计算机中，并捆绑在人们每天使用的无数其他应用程序内。更多信息&amp;hellip;
SQLite 文件格式是稳定的，跨平台和向后兼容的，开发人员承诺通过 2050 年保持这种方式。SQLite 数据库文件通常用作传输系统之间的丰富内容作为数据的长期存档格式。主动使用中有超过 1 万亿（1E12）SQLite 数据库
用白话说，SQLite 通常嵌入在其他程序中，并且 SQLite 存储的数据信息一般只在一个文件中，使用起来非常方便。
通过 sqlite 内置的 sqlite_master 表查看用户创建的表的信息
# sqlite_master 是一个隐藏的表，维护了 sqlite 数据库自身的数据信息 sqlite&amp;gt; select * from sqlite_master where type=&amp;#34;table&amp;#34;; type name tbl_name rootpage sql ---------- ---------- ---------- ---------- ------------------------------------------ table memos memos 2 CREATE TABLE memos(text, priority INTEGER) sqlite 命令行工具 参考：
Ubuntu Manual，sqlite3(1) 现阶段通常使用 sqlite3 工具，这个工具可以对接 SQLite 版本 3 的接口。sqlite3 有“交互模式”或“命令行模式”两种模式。</description></item><item><title>sshpass</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/sshpass/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Utility/OpenSSH/sshpass/</guid><description>概述 参考：
源码 manual sshpass 是一种使用 SSH 的 “交互式键盘密码身份验证” 非交互式执行密码身份验证的工具。大多数用户应该改用 SSH 更安全的公钥认证。
Syntax(语法) OPTIONS
-p &amp;lt;STRING&amp;gt; # 指定 ssh 时使用的密码 问题示例 使用 sshpass -p 密码 ssh root@ip 地址 没有任何反应，解决办法找到了 添加-o StrictHostKeyChecking=no 选项【表示远程连接时不提示是否输入 yes/no】
sshpass -p molihuacha.1 ssh -o StrictHostKeyChecking=no root@188.131.150.204
https://blog.csdn.net/weixin_41831919/article/details/109660760</description></item><item><title>ssl 模块</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/ssl-%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/ssl-%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
http 模块下的 ssl 模块 mail 模块下的 ssl 模块 stream 模块下的 ssl 模块 ssl 模块可以作用在 http、mail、stream 模块下，称为 ngx_http_ssl_module、ngx_mail_ssl_module、ngx_stream_ssl_module。
ssl 模块提供了 SSL/TLS 的必要支持，可以通过 Nginx 来为后端提供 HTTP 的服务配置 SSL、也可以为普通的 4 层服务配置 SSL。
ngx_http_ssl_module 该模块需要 OpenSSL 库的支持才可以正常使用。
ssl 模块启用后，Nginx 将可以处理 TLS/SSL 请求。当客户端发起 TLS/SSL 请求时，Nginx 中启用了 ssl 模块的 Virtual Server 作为服务端将会用配置好的证书与客户端进行认证。然后 Nginx 再作为客户端，向被代理的后端 Server 发起 TLS/SSL 请求。
注意：
如果一个 Virtual Server 代理的后端服务器是 HTTPS 的，那么就必须为 Virtual Server 启用 ssl 模块。因为客户端发起的请求，总是会被该 Virtual Server 重定向到 443 端口。 SSL 指令 ssl on | off; # 启用 ssl 策略。</description></item><item><title>Storage Class Provisioner</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/Storage-Class-Provisioner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/Storage-Class-Provisioner/</guid><description>NFS Provisioner 参考：
GitHub GitHubOld 注意：NFS Provisioner 不支持容量限制功能 NFS subdir external provisioner 是一个自动 Provisioner，它使用您现有的和已配置的 NFS 服务器来通过持久卷声明来动态供应 Kubernetes 持久卷。PV 配置为 $ {namespace}-$ {pvcName}-$ {pvName}。
部署 NFS Provisioner 參考：
arifacthub GitHub GitHubOld 创建 namespace
apiVersion: v1 kind: Namespace metadata: name: storage 创建 rbac
kind: ServiceAccount apiVersion: v1 metadata: name: nfs-client-provisioner namespace: storage --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-client-provisioner-runner rules: - apiGroups: [&amp;#34;&amp;#34;] resources: [&amp;#34;persistentvolumes&amp;#34;] verbs: [&amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;, &amp;#34;create&amp;#34;, &amp;#34;delete&amp;#34;] - apiGroups: [&amp;#34;&amp;#34;] resources: [&amp;#34;persistentvolumeclaims&amp;#34;] verbs: [&amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;, &amp;#34;update&amp;#34;] - apiGroups: [&amp;#34;storage.</description></item><item><title>StorageClass Manifest 详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/StorageClass-Manifest-%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%AD%98%E5%82%A8/Storage-Classes%E5%AD%98%E5%82%A8%E7%B1%BB/StorageClass-Manifest-%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：API 文档
其中带有 -required- 标志的为必须的字段
apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: # 该 StorageClass 的名字 provisioner: -required- # 指定要使用的 provisioner。 parameters &amp;lt;map[string]string&amp;gt; # Provisioner 的配置参数，不同的 Provisioner 具有不同的参数 NFS Parameters archiveOnDelete: false # PV 删除时，是否存档数据。如果存档数据，则会在 PV 关联的目录名前加上 archived 字符串，以便保存数据。效果如下： [root@nfs-1 test]# ll -h total 0 drwxrwxrwx 4 root input 179 Dec 2 17:02 archived-rabbitmq-persistence-test-server-0-pvc-9e1aabf2-a072-44d1-92df-9cd0864f9fda drwxrwxrwx 4 root input 179 Dec 2 17:02 archived-rabbitmq-persistence-test-server-1-pvc-0409c70e-be04-43e1-9b4c-17b96930cb26 drwxrwxrwx 4 root input 179 Dec 2 17:02 archived-rabbitmq-persistence-test-server-2-pvc-01937680-cc6c-4118-86fc-ed420fdc275b drwxrwxrwx 4 root input 231 Dec 2 21:53 rabbitmq-persistence-test-server-0-pvc-ed8e801f-2659-4829-912b-669145c8396b drwxrwxrwx 4 root input 231 Dec 2 21:53 rabbitmq-persistence-test-server-1-pvc-72c85e1c-8c06-45b2-ba46-e223fafd24d5 drwxrwxrwx 4 root input 231 Dec 2 21:53 rabbitmq-persistence-test-server-2-pvc-9157e421-7150-45ab-8432-2be935dd69ef # 可以看到，前面三个时之前层经删除过的 PV，archiveOnDelete 参数改为 true 后，数据并不会被删除 reclaimPolicy: # 回收策略 StorageClass 动态创建的 PV 的回收策略。</description></item><item><title>strace 工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/strace-%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/strace-%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
GitHub 项目，strace/strace 官网 Manual(手册)，strace(1) strace 是一个用来跟踪 system calls(系统调用) 和 signals(信号) 的工具。
在最简单的情况下，strace 会运行指定的命令，直到退出为止。 它截获并记录 由进程调用的系统调用 和 由进程接收的信号。 每个系统调用的名称，其参数及其返回值都会在 标准错误 或使用 -o 选项指定的文件上显示。
strace 是有用的诊断，说明和调试工具。系统管理员，诊断人员和疑难解答人员将发现，对于不容易获取源代码的程序而言，这是无价的，因为它们无需重新编译即可跟踪它们。学生，黑客和过于好奇的人会发现，即使跟踪普通程序，也可以学到很多有关系统及其系统调用的知识。而且程序员会发现，由于系统调用和信号是在用户/内核界面上发生的事件，因此仔细检查此边界对于错误隔离，健全性检查和尝试捕获竞争状况非常有用。
strace 输出内容介绍 追踪到系统调用时输出的信息 下面是一个最基本，最简单的追踪，strace 程序执行时，输出的每一行内容都是一个 syscall(系统调用)。基本格式如下：
SyscallName(Parameter) = ReturnValue
假如我追踪 cat /dev/null 命令，则输出中有这么一段：
# 使用了 openat 这个系统调用，参数为 &amp;#34;/dev/null&amp;#34;,O_RDONLY，返回值为 3 openat(AT_FDCWD, &amp;#34;/dev/null&amp;#34;, O_RDONLY) = 3 如果命令出现错误，通常 ReturenVale 为 -1，并附加 errno 符号和错误信息
openat(AT_FDCWD, &amp;#34;123&amp;#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 追踪到信号时输出的信息 如果追踪到信号，则输出内容的基本格式如下：
SignalName{si_signo=SignalName, si_code=SI_USER, si_pid=PID, .</description></item><item><title>stress-ng 系统压力测试工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/stress-ng-%E7%B3%BB%E7%BB%9F%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/stress-ng-%E7%B3%BB%E7%BB%9F%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</guid><description>概述 Syntax(语法) OPTIONS
-c, &amp;ndash;cpu # 指定要测试的 CPU 数量，测几个就起几个进程。 -i , &amp;ndash;io # 启动 N 个工作程序，连续调用 sync(2) 将缓冲区高速缓存提交到磁盘。 可以与 &amp;ndash;hdd 选项结合使用。 -d &amp;lt;&amp;gt;N, &amp;ndash;hdd # 开始 N 个工作人员不断写入，读取和删除临时文件。 默认模式是对顺序写入和读取进行压力测试。 如果启用了&amp;ndash;ggressive 选项，而没有任何&amp;ndash;hdd-opts 选项，则 hdd Stressor 将一个接一个地处理所有&amp;ndash;hdd-opt 选项，以涵盖一系列 I / O 选项。 &amp;ndash;timeout # 指定程序运行时间 EXAMPLE
stress-ng -c 1 &amp;ndash;timeout 600 # 模拟 CPU 使用，导致 us 升高 stress-ng -i 1 &amp;ndash;hdd 1 &amp;ndash;timeout 600 # 模拟磁盘 io，会导致 wa 升高</description></item><item><title>Subcharts 与 Global Values</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Subcharts-%E4%B8%8E-Global-Values/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/Subcharts-%E4%B8%8E-Global-Values/</guid><description>概述 参考：官方文档
假如 Chart A 依赖的 Chart B，则 Chart B 称之为 SubCharts(子图表)。
SubCharts 受以下规范约束
SubCharts 是“独立的”，这意味着 SubCharts 永远不能显式依赖其父图表。 因此，SubCharts 无法访问其父级的 Values。 父图表可以覆盖 SubCharts 的 Values。 Helm 具有可被所有图表访问的 Global Values(全局值) 的概念。</description></item><item><title>Sublime</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Sublime/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Sublime/</guid><description>概述 在使用 Git 进行提交操作中，常见需要把 CRLF 转换成 LF 的警告。
个人目前使用代码编辑器是 Sublime Text 3，可以在设置中避免这个问题。设置如下：
Perference-&amp;gt;Setting-User 中加入配置 &amp;ldquo;default_line_ending&amp;rdquo;: &amp;ldquo;unix&amp;rdquo;
这个参数有三个可用选项，system, windows, unix
注意添加逗号，效果如下：
{ &amp;#34;ignored_packages&amp;#34;: [ &amp;#34;Vintage&amp;#34; ], &amp;#34;default_line_ending&amp;#34;: &amp;#34;unix&amp;#34;, } 关联文件与配置 可以在设置中修改默认换行符
Perference-&amp;gt;Setting-User 中加入配置 &amp;ldquo;default_line_ending&amp;rdquo;: &amp;ldquo;unix&amp;rdquo;
这个参数有三个可用选项，system, windows, unix
相关问题 报错 1：There are no packages available for installation 原因：
打开如下配置
配置中红框位置为 sublime 安装包所需要的仓库内容，该连接被墙，无法打开
解决办法 通过翻墙提前把该连接下的 channel_v3.json 文件下载下来保存在本地
然后在 首选项 — Package Settings — Package Control — Settings-User 的配置中添加如下内容
{ &amp;#34;bootstrapped&amp;#34;: true, &amp;#34;channels&amp;#34;: [ &amp;#34;E:\\Tools\\channel_v3.</description></item><item><title>sudoers 配置详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/su-%E4%B8%8E-sudo/sudoers-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/su-%E4%B8%8E-sudo/sudoers-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
Manual(手册),sudoers(5)-sudoers 文件格式 使用 visudo 命令可直接进入编辑模式以编辑 /etc/sudoers 文件
sudoers 文件使用 Extended Backus-Naur Form(简称 EBNF) 格式书写。
sudoers 文件由如下几类条目组成：
Aliases(别名) # User Specifications(用户规范) # 即指定谁可以运行什么程序 Defaults # Defaults 条目的配置，可以在运行时变更 sudo 的运行行为。 比如配置日志输出路径等等。 Aliases 用户规范条目中的每个字段都可以使用别名来表示，提前设置好别名，然后在这个字段使用别名来表示
sudoers 中可以设置 4 种别名：
User_Alias(用户别名) Runas_Alias() Host_Alias(主机别名) Cmnd_Alias(命令别名) 别名语法：
在别名的设置中，可以使用 * 这种通配符来匹配所有
User_Alias 别名名称 = 用户名,&amp;hellip; Host_Alias 别名名称 = 主机名,&amp;hellip; Cmnd_Alias 别名名称 = 命令,&amp;hellip; 默认配置示例 ## 主机别名 ## 对于一组服务器，你可能会更喜欢使用主机名（可能是全域名的通配符） ## 或IP地址代替，这时可以配置主机别名 # Host_Alias FILESERVERS = fs1, fs2 # Host_Alias MAILSERVERS = smtp, smtp2 ## 用户别名 ## 这并不很常用，因为你可以通过使用组来代替一组用户的别名 # User_Alias ADMINS = jsmith, mikem ## 命令别名 ## 指定一系列相互关联的命令（当然可以是一个）的别名，通过赋予该别名sudo权限， ## 可以通过sudo调用所有别名包含的命令，下面是一些示例 ## 网络操作相关命令别名 Cmnd_Alias NETWORKING = /sbin/route, /sbin/ifconfig, /bin/ping, /sbin/dhclient, /usr/bin/net, /sbin/iptables, /usr/bin/rfcomm, /usr/bin/wvdial, /sbin/iwconfig, /sbin/mii-tool ## 软件安装管理相关命令别名 Cmnd_Alias SOFTWARE = /bin/rpm, /usr/bin/up2date, /usr/bin/yum ## 服务相关命令别名 Cmnd_Alias SERVICES = /sbin/service, /sbin/chkconfig ## 本地数据库升级命令别名 Cmnd_Alias LOCATE = /usr/sbin/updatedb ## 磁盘操作相关命令别名 Cmnd_Alias STORAGE = /sbin/fdisk, /sbin/sfdisk, /sbin/parted, /sbin/partprobe, /bin/mount, /bin/umount ## 代理权限相关命令别名 Cmnd_Alias DELEGATING = /usr/sbin/visudo, /bin/chown, /bin/chmod, /bin/chgrp ## 进程相关命令别名 Cmnd_Alias PROCESSES = /bin/nice, /bin/kill, /usr/bin/kill, /usr/bin/killall ## 驱动命令别名 Cmnd_Alias DRIVERS = /sbin/modprobe User Specifications User Specifications(用户规范) 用来指定谁可以运行什么程序，可以理解为赋权。</description></item><item><title>Swagger 工具</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Swagger-%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Swagger-%E5%B7%A5%E5%85%B7/</guid><description>参考：官方工具列表
Swagger 衍生出来的一系列项目和工具，就可以做到生成各种格式的接口文档，生成多种语言的客户端和服务端的代码，以及在线接口调试页面等等。这样，如果按照新的开发模式，在开发新版本或者迭代版本的时候，只需要更新 Swagger 描述文件，就可以自动生成接口文档和客户端服务端代码，做到调用端代码、服务端代码以及接口文档的一致性。
Swagger UI 参考：官网
Swagger UI allows anyone — be it your development team or your end consumers — to visualize and interact with the API’s resources without having any of the implementation logic in place. It’s automatically generated from your OpenAPI (formerly known as Swagger) Specification, with the visual documentation making it easy for back end implementation and client side consumption.
Swagger UI 允许任何人（无论您是开发团队还是最终用户）都可以可视化 API 资源并与之交互，而无需任何实现逻辑。它是根据您的 OpenAPI（以前称为 Swagger）规范自动生成的，具有可视化文档，可简化后端实现和客户端使用。</description></item><item><title>Swagger 介绍</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Swagger-%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/API/Swagger-%E4%BB%8B%E7%BB%8D/</guid><description>概述 参考：
官网 Swagger 相关工具 Swagger 有两种含义
Swagger Specification(规范) # 用于描述现代 API 的行业标准，已被广泛采用。 规范就是用 JSON 或 YAML 来描述的一组 API。 Swagger ToolsSet(工具集) # 实现 Swagger 规范 的一系列工具的集合。 Swagger 衍生出来的一系列工具，可以做到生成各种格式的接口文档，生成多种语言的客户端和服务端的代码，以及在线接口调试页面等等 注意：Swagger 规范已于 2015 年捐赠给 Linux 基金会后改名为 OpenAPI，并定义最新的规范为 OpenAPI 3.0。
所以，3.0 之前的规范，准确来说叫 Swagger 1.0、 Swagger 2.0，而 Swagger 3.0 就应该称为 OpenAPI 3.0 了 所以现在，Swagger 这个词语，更多的是用来描述一系列工具的合集。借助 Swagger 开源和专业工具集，为用户，团队和企业简化 API 开发。
Swagger 背景
随着互联网技术的发展，现在的网站架构基本都是由原来的后端渲染，变成了前端渲染、前后端分离的形式，而且前端技术和后端技术在各自的道路上越走越远。前后端的唯一联系，变成了 API 接口；API 文档变成了前后端开发人员联系的纽带。最早的时候，大家都是手写 API 文档的，在什么地方写的都有，有的在 confluence 上、有的直接在项目的 README.md 文件中写。并且，每个项目的写法、格式都不一样。
此时，就出现问题了，大家都需要写 API、用 API，那么何不出台一个规范，来规范所有项目的 API 文档的写法规范。这就是 Swagger 的由来。</description></item><item><title>SyncLoop 模块</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/SyncLoop-%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/Kubelet/SyncLoop-%E6%A8%A1%E5%9D%97/</guid><description>概述 参考：
SyncLoop 模块，Kubelet 同步循环
kubelet 的工作核心就是在围绕着不同的生产者生产出来的不同的有关 pod 的消息来调用相应的消费者（不同的子模块）完成不同的行为(创建和删除 pod 等)，即图中的控制循环（SyncLoop），通过不同的事件驱动这个控制循环运行。
本文仅分析新建 pod 的流程，当一个 pod 完成调度，与一个 node 绑定起来之后，这个 pod 就会触发 kubelet 在循环控制里注册的 handler，上图中的 HandlePods 部分。此时，通过检查 pod 在 kubelet 内存中的状态，kubelet 就能判断出这是一个新调度过来的 pod，从而触发 Handler 里的 ADD 事件对应的逻辑处理。然后 kubelet 会为这个 pod 生成对应的 podStatus，接着检查 pod 所声明的 volume 是不是准备好了，然后调用下层的容器运行时。如果是 update 事件的话，kubelet 就会根据 pod 对象具体的变更情况，调用下层的容器运行时进行容器的重建。
kubelet 创建 pod 的流程 Note：注意 14，,15 步，kubelet 会先将生成配置(volume 挂载、配置主机名等等)，才会去启动 pod，哪怕 pod 启动失败，挂载依然存在。
同步循环 kubelet.syncLoop() - 同步循环入口 syncLoop 中首先定义了一个 syncTicker 和 housekeepingTicker，即使没有需要更新的 pod 配置，kubelet 也会定时去做同步和清理 pod 的工作。然后在 for 循环中一直调用 syncLoopIteration，如果在每次循环过程中出现比较严重的错误，kubelet 会记录到 runtimeState 中，遇到错误就等待 5 秒中继续循环。</description></item><item><title>sysbench</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/sysbench/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/sysbench/</guid><description>概述 参考
Github,akopytov/sysbench 脚本数据库和系统性能基准
Syntax(语法) sysbench [OPTIONS] [TestName] [COMMAND]
TestName
**fileio **# 文件 I/O 测试 cpu # CPU 性能测试 memory # 内存功能速度测试 threads # 线程子系统性能测试 mutex # 互斥体性能测试 General OPTIONS &amp;ndash;threads &amp;lt;INT&amp;gt; # 要创建的工作线程总数 &amp;ndash;time &amp;lt;DURATION&amp;gt; # 运行持续时间。单位：秒。默认值：0。0 表示没有限制。 Example 以 10 个线程运行 5 分钟的线程子系统性能测试。常用来模拟多线程切换的问题 sysbench &amp;ndash;threads=10 &amp;ndash;time=300 threads run</description></item><item><title>sysctl</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/sysctl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E5%86%85%E6%A0%B8%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/sysctl/</guid><description>概述 sysctl 是 procps 工具集 中的一个用于控制内核参数的工具
Syntax(语法) sysctl [OPTIONS] [VARIABLE[=VALUE]] [&amp;hellip;]
在运行环境中配置内核参数。VARIABLE 为内核的一个变量
OPTIONS
-a # 显示所有变量 -p [/PATH/TO/FILE] # 从文件中读取值,默认文件为/etc/sysctl.conf。可以指定从哪个文件来读取参数，可使用通配符。 -w # 允许写一个值到变量中 EXAMPLE sysctl -w net.ipv4.ip_forward=1 # 开启 IP 转发模式 sysctl -p /etc/sysctl.d/* # 从 sysctl.d 目录中读取所有文件的内容加载到内核中</description></item><item><title>sysstat 工具集</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/sysstat-%E5%B7%A5%E5%85%B7%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/sysstat-%E5%B7%A5%E5%85%B7%E9%9B%86/</guid><description>概述 参考：
GitHub 项目，sysstat/sysstat 官网 Manual(手册)，pidstat(1) Manual(手册)，sar(1) sysstat 包包含很多类 UNIX 的应用程序，用以监控系统性能和使用活动。
cifsiostat iostat - 报告设备和分区的 I/O 统计数据 iostat 命令用于通过观察设备活动的时间及其平均传输速率来监视系统 I/O 设备的负载。 iostat 命令生成可用于更改系统配置的报告，以更好地平衡物理磁盘之间的输入/输出负载。
iostat 命令生成两种类型的报告，即 CPU 利用率报告和设备利用率报告。
CPU 利用率报告
Device 利用率报告
~]# iostat -xd Linux 4.18.0-193.19.1.el8_2.x86_64 (ansible.tj-test) 11/24/2020 _x86_64_ (4 CPU) Device r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util sda 0.04 0.17 1.56 11.25 0.00 0.26 0.19 60.08 10.57 54.93 0.01 40.14 65.</description></item><item><title>System Call 类别</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/System-Call/System-Call-%E7%B1%BB%E5%88%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/System-Call/System-Call-%E7%B1%BB%E5%88%AB/</guid><description>系统调用的类别 参考：http://c.biancheng.net/view/1196.html
系统调用大致可以分为六大类：
一、进程控制 执行程序应能正常（end()）或异常（abort()）停止执行。如果一个系统调用异常停止当前执行的程序，或者程序运行遇到问题并引起错误陷阱，那么有时转储内存到磁盘，并生成错误信息。内存信息转储到磁盘后，可用调试器（debugger）来确定问题原因（调试器为系统程序，用以帮助程序员发现和纠正错误（bug））。
无论是正常情况还是异常情况，操作系统都应将控制转到调用命令解释程序。命令解释程序接着读入下个命令。对于交互系统，命令解释程序只是简单读入下个命令，而假定用户会采取合适命令以处理错误。对于 GUI 系统，弹出窗口可用于提醒用户出错，并请求指引。对于批处理系统，命令解释程序通常终止整个作业，并继续下个作业。当出现错误时，有的系统可能允许特殊的恢复操作。
如果程序发现输入有错并且想要异常终止，那么它也可能需要定义错误级别。错误越严重，错误参数的级别也越高。通过将正常终止的错误级别定义为 0，可以把正常和异常终止放在一起处理。命令解释程序或后面的程序可以利用这种错误级别来自动确定下个动作。
执行一个程序的进程或作业可能需要加载（load()）和执行（execute()）另一个程序。这种功能允许命令解释程序来执行一个程序，该命令可以通过用户命令、鼠标点击或批处理命令来给定。一个有趣的问题是：加载程序终止时会将控制返回到哪里？与之相关的问题是：原有程序是否失去或保存了，或者可与新的程序一起并发执行？
如果新程序终止时控制返回到现有程序，那么必须保存现有程序的内存映像。因此，事实上创建了一个机制，以便一个程序调用另一个程序。如果两个程序并发继续，那么也就创建了一个新作业或进程，以便多道执行。通常，有一个系统调用专门用于这一目的（create_process() 或 submit_job()）。
如果创建了一个新的作业或进程或者一组作业或进程，那么我们应能控制执行。这种控制要能判定和重置进程或作业的属性，包括作业的优先级、最大允许执行时间等（get_ process_attributes() 和 set_process_attributes()）。如果发现创建的进程或作业不正确或者不再需要，那么也要能终止它（terminate_process()）。
创建了新的作业或进程后，可能要等待其执行完成，也可能要等待一定时间（wait_time()）。更有可能要等待某个事件的出现（wait_event()）。当事件出现时，作业或进程就会响应（signal_event()）。
通常，两个或多个进程会共享数据。为了确保共享数据的完整性，操作系统通常提供系统调用，以允许一个进程锁定（lock）共享数据。这样，在解锁之前，其他进程不能访问该数据。通常，这样的系统调用包括 acquire_lock() 和 release_lock()。这类系统调用用于协调并发进程，将在后续章节详细讨论。
进程和作业控制差异很大，这里通过两个例子加以说明：一个涉及单任务系统，另一个涉及多任务系统。
MS-DOS 操作系统是个单任务的系统，在计算机启动时它就运行一个命令解释程序（图 1a）。由于 MS-DOS 是单任务的，它采用了一种简单方法来执行程序而且不创建新进程。它加载程序到内存，并对自身进行改写，以便为新程序提供尽可能多的空间（图 1b）。
接着，它将指令指针设为程序的第一条指令。然后，运行程序，或者错误引起中断，或者程序执行系统调用来终止。无论如何，错误代码会保存在系统内存中以便以后使用。之后，命令解释程序中的尚未改写部分重新开始执行。它首先从磁盘中重新加载命令解释程序的其他部分。然后，命令解释程序会向用户或下个程序提供先前的错误代码。
FreeBSD（源于 Berkeley UNIX）是个多任务系统。在用户登录到系统后，用户所选的外壳就开始运行。这种外壳类似于 MS-DOS 外壳：按用户要求，接受命令并执行程序。不过，由于 FreeBSD 是多任务系统，命令解释程序在另一个程序执行，也可继续执行（图 2）。
为了启动新进程，外壳执行系统调用 fork()。接着，所选程序通过系统调用 exec() 加载到内存，程序开始执行。根据命令执行方式，外壳要么等待进程完成，要么后台执行进程。对于后一种情况，外壳可以马上接受下个命令。当进程在后台运行时，它不能直接接受键盘输入，这是因为外壳已在使用键盘。因此 I/O 可通过文件或 GUI 来完成。
同时，用户可以让外壳执行其他程序，监视运行进程状态，改变程序优先级等。当进程完成时，它执行系统调用 exit() 以终止，并将 0 或非 0 的错误代码返回到调用进程。这一状态（或错误）代码可用于外壳或其他程序。后续章节将通过一个使用系统调用 fork() 和 exec() 的程序例子来讨论进程。
二、文件管理 首先要能创建（create()）和删除（delete()）文件。这两个系统调用需要文件名称，还可能需要文件的一些属性。一旦文件创建后，就会打开（open()）并使用它，也会读(read()）、写（write()）或重定位（reposition()）（例如，重新回到文件开头，或直接跳到文件末尾）。最后，需要关闭（close()）文件，表示不再使用它了。
如果采用目录结构来组织文件系统的文件，那么也会需要同样的目录操作。另外，不管是文件还是目录，都要能对各种属性的值加以读取或设置。文件属性包括：文件名、文件类型、保护码、记账信息等。
针对这一功能，至少需要两个系统调用：获取文件属性（get_file_attributes()）和设置文件属性（set_file_attributes()）。有的操作系统还提供其他系统调用，如文件的移动（move()）和复制（copy()）。还有的操作系统通过代码或系统调用来完成这些 API 的功能。其他的操作系统可能通过系统程序来实现这些功能。如果系统程序可被其他程序调用，那么这些系统程序也就相当于 API。
三、设备管理 进程执行需要一些资源，如内存、磁盘驱动、所需文件等。如果有可用资源，那么系统可以允许请求，并将控制交给用户程序；否则，程序应等待，直到有足够可用的资源为止。
操作系统控制的各种资源可看作设备。有的设备是物理设备（如磁盘驱动），而其他的可当作抽象或虚拟的设备（如文件）。多用户系统要求先请求（request()）设备，以确保设备的专门使用。在设备用完后，要释放（release()）它。这些函数类似于文件的系统调用 open() 和 close()。其他操作系统对设备访问不加管理。这样带来的危害是潜在的设备争用以及可能发生的死锁，这将在后续章节中讨论。</description></item><item><title>systemctl 命令行工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/systemctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/systemctl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
Manual(手册)，systemctl(1) systemctl 命令用来对整个“systemd”的系统和服务进行管理
Syntax(语法) systemctl [OPTIONS] COMMAND [UNIT&amp;hellip;]
UNIT 为 Unit 名称，如果指定了 UNIT 则只对这个 Unit 执行 COMMAND，如果不指定则对全局 Unit 进行操作
OPTIONS -t # 对指定类型的 unit 进行操作 &amp;ndash;all # &amp;ndash;now # 该选项可以与 enable、disable、mask 命令一起使用。 与 enable 命令一起使用时，将同时启动该 Unit 与 disable 和 mask 命令一起使用时，将同时停止该 Unit、 注意：只有当 enable 或 disable 命令成功时，才会执行启动或停止操作。加了该选项就类似于执行了 systemctl enable UNIT &amp;amp;&amp;amp; systemctl start UNIT 命令 COMMAND 分类 Unit Command # 对 unit 执行操作的命令 Unit File Commands # 对 Unit 文件执行操作的命令 Machine Commands Job Commands Snapshot Commands Environment Commands Manager Lifecycle Commands # 生命周期管理器的命令 System Commands 注意：OBJECT 可以使用 PATTERN(模式)来进行匹配，i.</description></item><item><title>Systemd 运行流程</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Systemd-%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Systemd-%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B/</guid><description>概述 参考：
Systemd 运行 这里以 CentOS 7 版本为例
确认系统运行级别 systemd 执行的第一个目标是 /etc/systemd/system/default.target，是一个软链接，该文件决定了老版本称为 “运行级别” 的一种行为
~]# ll /etc/systemd/system/default.target lrwxrwxrwx. 1 root root 37 Oct 10 2020 /etc/systemd/system/default.target -&amp;gt; /lib/systemd/system/multi-user.target 如果想要更改系统启动级别，可以使用 systemctl set-defult XXXXX 命令来修改默认启动级别
启动 multi-user.taget multi-user.target 文件内容如下：
~]# cat /usr/lib/systemd/system/multi-user.target [Unit] Description=Multi-User System Documentation=man:systemd.special(7) Requires=basic.target Conflicts=rescue.service rescue.target After=basic.target rescue.service rescue.target AllowIsolate=yes 从 multi-user.target 中获取到下一步需要启动的服务。
根据 Requires 指令，需要先启动 basic.target 关联的服务 启动 /usr/lib/systemd/system/multi-user.target.wants/ 和 /etc/systemd/system/multi-user.target.wants/ 目录中的服务 ~]# ls /usr/lib/systemd/system/multi-user.target.wants/ dbus.service getty.target plymouth-quit.service plymouth-quit-wait.</description></item><item><title>systemd-networkd</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/systemd-networkd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/systemd-networkd/</guid><description>概述 参考：
配置 /run/systemd/network/ # 读取网络设备配置的目录</description></item><item><title>systemd-resolved.service</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-DNS-%E7%AE%A1%E7%90%86/systemd-resolved.service/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-DNS-%E7%AE%A1%E7%90%86/systemd-resolved.service/</guid><description>概述 参考：
Manual(手册)，systemd-resolved.service(8) 金步国-system 中文手册，systemd-resolved.service systemd-resolved.service 是一个类似于 DNSmasq 的域名解析服务，只不过这个服务只适用于 Linux 中，且被 systemd 所管理。
systemd-resolved 是一个为本地应用程序提供网络名称解析的系统服务。它实现了一个缓存和验证 DNS/DNSSEC 存根解析器，以及一个 LLMNR 和 MulticastDNS 解析器和响应器。
关联文件与配置 /etc/systemd/resolved.conf # 运行时配置文件。
/run/systemd/resolve/ # /etc/resolv.conf 文件将会软链接到此目录下的某个文件。通常默认链接到 stub-resolv.conf 文件。
./stub-resolv.conf # 通常只包含一个本地地址(127.0.0.53)，指向 systemd-resolved.service 提供的 DNS Stub Listener。 ./resolv.conf # 包含了系统实际使用的 DNS 服务器和搜索域的列表。systemd-resolved.service 的 DNS Stub Listener 将会读取该文件中的 DNS Server /usr/lib/systemd/resolv.conf # 代替 /etc/resolv.conf 文件
命令行工具 resolvectl 参考：
Manual(手册)，resolvectl(1) Syntax(语法) resolvectl [OPTIONS] COMMAND [NAME&amp;hellip;]
COMMAND
query HOSTNAME | ADDRESS # 解析域名以及 IPv4 和 IPv6 地址。当与 &amp;ndash;type= 或 &amp;ndash;class= （见下文）结合使用时，解析低级 DNS 资源记录。 EXAMPLE</description></item><item><title>tar与gzip</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/tar%E4%B8%8Egzip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E6%96%87%E4%BB%B6%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/tar%E4%B8%8Egzip/</guid><description>tar 参考：
Manual(手册)，tar(1) tar 是一个归档工具，用以实现 Archive File(归档文件) 的管理
tar Syntax(语法) tar [Operation mode] [OPTIONS] /PATH/FILE
Operation mode(操作模式)
-c, &amp;ndash;create # 打包文件，需要与 -f 选项搭配使用。创建一个新的 archive(归档) -x, &amp;ndash;extract, &amp;ndash;get # 解包文件，需要与 -f 选项搭配使用。从 archive(归档) 中 extract(提取) 文件。当使用该选项时，需要指定要提取的档案成员的名称。 OPTIONS:
-f # 指定被处理的文件（在所有选项里一定要放最后一个，否则会报错） -C, &amp;ndash;directory=&amp;lt;DIR&amp;gt;# 指定工作目录。打包或解包，以 -C 指定的目录作为初始目录。 Notes: 有点类似于先用 cd 命令切换到指定目录。 -v # 显示执行命令时的详细过程 -t # 查看已经打包的文件中的内容 -z # 通过 gzip 指令处理打包的文件； &amp;ndash;strip-components NUM # 去除前缀目录，i.e.默认会自动创建与压缩包同名的目录来存放压缩包内的文件，当 NUM 为 1 时，则不再创建该目录，直接将压缩包内的文件全部解压到当前目录 Local file selection(本地文件选择) &amp;ndash;exclude=PATTERN # 打包时排除指定的文件或目录。PATTERN 是通配符匹配模式。 Notes: 打包的路径使用相对路径时，排除的文件只能接相对路径；打包的目录使用绝对路径，排除的文件接相对路径或绝对路径 建议打包的目录和排除的文件使用的路径要保持一致，都是用绝对路径，或都是用相对路径。 EXAMPLE tar -zcvf xxx.</description></item><item><title>TCP Wrappers</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/TCP-Wrappers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/TCP-Wrappers/</guid><description>概述 注意：CentOS8 及 RHEL8 不再支持 TCP_Wrappers！！！！使用 firewalld 代替！！
Transmission Control ProtocolWrappers(简称 TCP_Wrappers) 是一个基于主机的网络访问控制表系统，用于过滤对类 Unix 系统（如 Linux 或 BSD）的网络访问。
其能将主机或子网 IP 地址、名称及 ident 查询回复作为筛选标记，实现访问控制。
Tcp_Wrappers 特点 工作在第四层（传输层）的 TCP 协议 对有状态连接的特定服务进行安全检测并实现访问控制 以库文件形式实现 某进程是否接受 libwrap 的控制取决于发起此进程的程序在编译时是否针对 libwrap 进行编译的 判断程序是否支持 Tcp_Wrappers 程序如果调用了 libwrap.so 库，表示支持。
ldd 程序路径|grep libwrap.so strings 程序路径|grep libwrap.so #ldd /usr/sbin/sshd|grep libwrap.so libwrap.so.0 =&amp;gt; /lib64/libwrap.so.0 (0x00007f9851678000) #ldd /usr/sbin/vsftpd |grep libwrap.so libwrap.so.0 =&amp;gt; /lib64/libwrap.so.0 (0x00007f802ef50000) #strings `which sshd`|grep libwrap.so libwrap.so.0 TCP_Wrappers 的执行处理机制了 TCP_Wrappers 只需要通过两个文件来处理，/etc/hosts.allow 和/etc/hosts.</description></item><item><title>TCP 与 HTTP</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP-%E4%B8%8E-HTTP/TCP-%E4%B8%8E-HTTP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP-%E4%B8%8E-HTTP/TCP-%E4%B8%8E-HTTP/</guid><description>TCP 与 HTTP 的 Keep-Alive 原文链接：https://mp.weixin.qq.com/s/25atTs4b-vORIx525ur_aw
大致问题是，TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是一个东西吗？ 这是个好问题，应该有不少人都会搞混，因为这两个东西看上去太像了，很容易误以为是同一个东西。 事实上，这两个完全是两样不同东西，实现的层面也不同：
HTTP 的 Keep-Alive，是由应用层（用户态） 实现的，称为 HTTP 长连接； TCP 的 Keepalive，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制； 接下来，分别说说它们。
HTTP 的 Keep-Alive HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。 请求-应答 由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。 一个 HTTP 请求 如果每次请求都要经历这样的过程：建立 TCP -&amp;gt; 请求资源 -&amp;gt; 响应资源 -&amp;gt; 释放连接，那么此方式就是 HTTP 短连接，如下图： HTTP 短连接 这样实在太累人了，一次连接只能请求一次资源。 能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接？ 当然可以，HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 HTTP 长连接。 HTTP 长连接 HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。 怎么才能使用 HTTP 的 Keep-Alive 功能？ 在 HTTP 1.</description></item><item><title>TCP/IP 管理工具</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP_IP-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP_IP-%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 获取本机公网 IP ipify https://geo.ipify.org/docs
func main() { res, _ := http.Get(&amp;#34;https://api.ipify.org&amp;#34;) ip, _ := ioutil.ReadAll(res.Body) os.Stdout.Write(ip) } 其他 https://ip.netarm.com http://ip.cip.cc http://ip.sb https://geo.ipify.org/docs</description></item><item><title>TCPDump Capture HTTP GET/POST requests</title><link>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/TCPDump/TCPDump-Capture-HTTP-GET_POST-requests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/7.%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Packet-analyzer/TCPDump/TCPDump-Capture-HTTP-GET_POST-requests/</guid><description>原文链接：https://www.middlewareinventory.com/blog/tcpdump-capture-http-get-post-requests-apache-weblogic-websphere/
概述 TCPDUMP is a swiss army knife for all the administrators and developers when it comes to troubleshooting. This post is written for the people who work in middleware technologies. Web servers such as Apache, NGINX, Oracle HTTP, IHS web servers and application servers such as Weblogic, Websphere, Tomcat, Jboss Consider yourself in any of the following scenarios
You want to monitor thetraffic inflow and outflowof Apache httpd server on any specific port like port 80 or 443 You have totrack the HTTP calls between web and application servers (or) to make sure that proxy is working fine.</description></item><item><title>Template</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Template/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Template/</guid><description>概述 参考：
Go 标准库，text/template Go 标准库，html/template 骏马金龙，Go 标准库：Go template 用法详解 本文只介绍 template 的语法和用法，关于 template 包的函数、方法、template 的结构和原理，见：深入剖析 Go template。
入门示例 以下为 test.html 文件的内容，里面使用了一个 template 语法{{.}}。
&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta http-equiv=&amp;#34;Content-Type&amp;#34; content=&amp;#34;text/html; charset=utf-8&amp;#34; /&amp;gt; &amp;lt;title&amp;gt;Go Web&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; {{ . }} &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 以下是 test.html 同目录下的一个 go web 程序：
package main import ( &amp;#34;html/template&amp;#34; &amp;#34;net/http&amp;#34; ) func tmpl(w http.ResponseWriter, r *http.Request) { t1, err := template.ParseFiles(&amp;#34;test.html&amp;#34;) if err != nil { panic(err) } t1.</description></item><item><title>Thanos 部署</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档，快速教程 通过 docker 启动 Thanos Sidecar Query Store 在 Kubernetes 集群中部署 Thanos 参考：
GitHub，thanos-io/kube-thanos-examples(Manifests) 通过 kubectl 插件 kube-thanos 部署 Store 与 Query 的 Manifests Sidecar 或 Receiver 由于 Sidecar 的工作性质，所以，Sidecar 组件最好作为 Prometheus 的 sidecar 容器，部署在同一个 Pod 中。
Query Store Compact 通过 prometheus-operator 部署 Thanos 参考：
官方文档，prometheus operator-thanos GitHub 文档，prometheus-operator-文档-thanos</description></item><item><title>Thanos 管理</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E7%AE%A1%E7%90%86/</guid><description>Thanos Store 可能产生的问题 下面报警触发的原因未知，但是在 node-exporter 的面板中，打开系统明细，并查询 90 天数据，且 receive 只保留 30 天数据时，大概率会发生这个问题。
{ &amp;#34;status&amp;#34;: &amp;#34;success&amp;#34;, &amp;#34;data&amp;#34;: { &amp;#34;resultType&amp;#34;: &amp;#34;matrix&amp;#34;, &amp;#34;result&amp;#34;: [] }, &amp;#34;warnings&amp;#34;: [ &amp;#34;No StoreAPIs matched for this query&amp;#34;, &amp;#34;No StoreAPIs matched for this query&amp;#34; ] }</description></item><item><title>Thanos 配置详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
Sidecar 配置 命令行标志 &amp;ndash;grpc-addresss=&amp;lt;STRING&amp;gt; # 暴露的 StoreAPI 端点。默认值：0.0.0.0:10901 &amp;ndash;http-address=&amp;lt;STRING&amp;gt; # 监听的 HTTP 端点。/metrics 端点暴露指标。默认值：0.0.0.0:10902 &amp;ndash;objstore.config-file=&amp;lt;FILE&amp;gt;# 对象存储的配置信息。Sidecar 根据该配置，将 Prometheus 自身保存的数据转存到配置的对象存储中。 &amp;ndash;prometheus.url=&amp;lt;STRING&amp;gt;# 与 Prometheus Server 交互的地址。默认值：http://localhost:9090 &amp;ndash;tsdb.path=&amp;lt;PATH&amp;gt; # Prometheus 存储时间序列数据的路径。默认值：./data &amp;ndash;shipper.upload-compacted # 开启已压缩数据转存功能。该标志对迁移数据很有用。
配置文件 Receiver 配置 命令行标志 &amp;ndash;grpc-address=&amp;lt;STRING&amp;gt; # 暴露的 StoreAPI 端点。默认值：0.0.0.0:10901 &amp;ndash;http-address=&amp;lt;STRING&amp;gt; # 监听的 HTTP 端点。/metrics 端点暴露指标。默认值：0.0.0.0:10902 &amp;ndash;label=&amp;lt;KEY=&amp;ldquo;VALUE&amp;rdquo;&amp;gt; # 为所有序列创建的标签，多个标签指定多个 &amp;ndash;label 标志。与 prometheus 配置 external_labels 字段效果一样 &amp;ndash;objstore.config-file=&amp;lt;FILE&amp;gt;# 对象存储的配置信息。Receiver 根据该配置，将时序数据转存到对象存储中。 &amp;ndash;receive.hashrings-file=/etc/thanos/receiver-hashring.json # &amp;ndash;receive.local-endpoint=127.0.0.1:10901 # &amp;ndash;receive.replication-factor=1 # &amp;ndash;remote-write.address=&amp;lt;STRING&amp;gt; # 处理 Prometheus 的 Remote Write 请求的地址和端口。默认值：0.</description></item><item><title>timer Unit</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/timer-Unit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/timer-Unit/</guid><description>概述 参考：
Manual(手册),systemd.timer(5) 阮一峰博客,Systemd 定时器教程 所有以 .timer 结尾的 Unit 都是由 Systemd 控制和监督的定时器任务。这是一个替代 Linux 中的 Crontab 程序的功能。通过 timer 单元，可以通过 systemd 来管理所有定时任务。
timer 指令 阮一峰文章 一、定时任务 所谓定时任务，就是未来的某个或多个时点，预定要执行的任务，比如每五分钟收一次邮件、每天半夜两点分析一下日志等等。
Linux 系统通常都使用 cron 设置定时任务，但是 Systemd 也有这个功能，而且优点显著。
自动生成日志，配合 Systemd 的日志工具，很方便除错 可以设置内存和 CPU 的使用额度，比如最多使用 50% 的 CPU 任务可以拆分，依赖其他 Systemd 单元，完成非常复杂的任务 下面，我就来演示一个 Systemd 定时任务：每小时发送一封电子邮件。
二、邮件脚本 先写一个发邮件的脚本mail.sh。
echo &amp;quot;This is the body&amp;quot; | /usr/bin/mail -s &amp;quot;Subject&amp;quot; [someone@example](mailto:someone@example).com 上面代码的someone@example.com，请替换成你的邮箱地址。
然后，执行这个脚本。
bash mail.sh 执行后，你应该就会收到一封邮件，标题为Subject。
如果你的 Linux 系统不能发邮件，建议安装 ssmtp 或者 msmtp。另外，mail命令的用法，可以参考这里。
三、Systemd 单元 学习 Systemd 的第一步，就是搞懂 &amp;ldquo;单元&amp;rdquo;（unit）是什么。</description></item><item><title>Timer 与 Ticker</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/Timer-%E4%B8%8E-Ticker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/Timer-%E4%B8%8E-Ticker/</guid><description>我们经常需要在未来某个时间点运行代码、或者每隔一定时间重复运行代码。Go 内置的 Timer 与 Ticker 特性让就可以实现这些功能。
Timer
Timer(定时器)，用来在当前时间之后的某一个时刻运行 Go 代码
Timer 应用示例
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) func main() { // NewTimer会创建一个定时器，在最少过去时间段`参数内定义的时间`后到期 // 返回值为名为Timer的结构体指针，其中时间会被发送给一个通道C timer1 := time.NewTimer(time.Second * 5) // 直到定时器的通道C明确的发送了定时器失效的值之前，将一直阻塞 &amp;lt;-timer1.C fmt.Println(&amp;#34;Timer 1 expired&amp;#34;) // 由于以协程方式启动，还没等到失效，就运行了 Stop() timer2 := time.NewTimer(time.Second) go func() { &amp;lt;-timer2.C fmt.Println(&amp;#34;Timer 2 expired&amp;#34;) }() stop2 := timer2.Stop() if stop2 { fmt.Println(&amp;#34;Timer 2 stopped&amp;#34;) } } // 第一个定时器将在程序开始后~5秒后失效，但是第二个在他没失效之前就停止了 Ticker
Ticker(打点器)，用于在固定的时间间隔重复执行代码。所谓 Ticker，就是 滴答、滴答、滴答，这种，一滴，一答，就是一个 Ticker
Ticker 应用示例</description></item><item><title>Token 与 JWT</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/Token-%E4%B8%8E-JWT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E4%BC%9A%E8%AF%9D%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/Token-%E4%B8%8E-JWT/</guid><description>概述 参考：
JWT 官网 RFC 7519 阮一峰，JSON Web Token 入门教程 JWT JSON Web Token(简称 JWT) 是目前最流行的跨域认证解决方案。JWT 是一个开放标准(RFC 7519)，定义了一种紧凑且子包含的方式，用于在各方之间以 JSON 对象的形式安全地传输信息。该信息可以被验证和信任，因为它是经过数字签名的。可以通过 RSA 或 ECDSA 这种公钥/私钥对进行签名、也可以使用 HMAC 进行签名。
背景 跨域认证的问题 互联网服务离不开用户认证。一般流程是下面这样。
用户向服务器发送用户名和密码。 服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。 服务器向用户返回一个 session_id，写入用户的 Cookie。 用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。 服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。 这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。
举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？
一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。
另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。
JWT 的原理 JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。
{ &amp;#34;姓名&amp;#34;: &amp;#34;张三&amp;#34;, &amp;#34;角色&amp;#34;: &amp;#34;管理员&amp;#34;, &amp;#34;到期时间&amp;#34;: &amp;#34;2018年7月1日0点0分&amp;#34; } 以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名（详见后文）。</description></item><item><title>trace 子命令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/trace-%E5%AD%90%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/trace-%E5%AD%90%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
Manual(手册)，perf-trace(1) perf trace 是类似 strace 的追踪工具，可以追踪系统调用。
Syntax(语法) perf trace [OPTIONS]
OPTIONS
-e, &amp;ndash;expr, &amp;ndash;event &amp;lt;SYSCALL&amp;gt; # 显示指定的系统调用 -s # 统计每一次系统调用的执行时间、次数、错误次数 -F,&amp;ndash;pf={all | min | maj} #</description></item><item><title>Traefik</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Traefik/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Traefik/</guid><description>Traefik 介绍 traefik 在 2.0 之后的版本，不再使用 ingress 资源作为入口，而是一个名为 IngressRoute 的 CRD 资源来作为入口
Traefik 安装 k8s 的 yaml 文件：https://docs.traefik.io/user-guides/crd-acme/
Yaml 样例 apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: simpleingressroute spec: entryPoints: - web routes: - match: Host(`your.example.com`) &amp;amp;&amp;amp; PathPrefix(`/notls`) # Host可省略，这样就跟ingress的host字段省略、istio的VirtualService资源的hosts字段写*，是一个效果 kind: Rule services: - name: whoami port: 80 https 的 yaml 配置
apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: ingressroutetls spec: entryPoints: - websecure routes: - match: Host(`your.example.com`) &amp;amp;&amp;amp; PathPrefix(`/tls`) kind: Rule services: - name: whoami port: 80 tls: certResolver: myresolver</description></item><item><title>Transformations(转换)</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Panel/Transformations%E8%BD%AC%E6%8D%A2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Grafana/Dashboard/Panel/Transformations%E8%BD%AC%E6%8D%A2/</guid><description>概述 参考：
官方文档，面板 - 转换 官方文档，面板 - 转换 - 转换类型和选项(这里就是详解了每一种转换类型) Transformations(转换) 经常用在 Table 面板中，我先以一个 Table 作为基础例子来说明 Transformations 的功能
转换顺序 如果同时存在多个转换, 则从上往下一次执行它们，这就有点像 Linux 中的管道，每一个转换会产生一个新的结果，这个结果将会传递给下一个转换继续进行处理。直到所有转换执行完成，在面板展示最终数据。
转换顺序的特性可以在这个例子中可以得到充分体现
Add field from calculation 添加一个新的字段，新字段的值可以通过计算得出。每个使用一次该转换即可添加一个新字段。
Filter by name(根据字段名称进行过滤) 使用 regex pattern(正则表达式模式) 删除部分查询结果，模式可以是包含或者排除。过滤的对象是 Field(字段)。
下图经过过滤后，我们仅显示 instance、pod、Value 这几个字段
Filter data by query Filter data by query. This is useful if you are sharing the results from a different panel that has many queries and you want to only visualize a subset of that in this panel.</description></item><item><title>Tree Data Structure(树型数据结构)</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Tree-Data-Structure%E6%A0%91%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Tree-Data-Structure%E6%A0%91%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid><description>概述 参考：Wiki-TreeDataStructure
在计算机科学中，Tree 是一种广泛使用的抽象数据类型，它模拟分层树结构，其根值和具有父节点的子级子树表示为一组链接节点。
可以将树数据结构递归定义为节点的集合（从根节点开始），其中每个节点都是由值组成的数据结构，以及对节点（“子级”）的引用列表，其中约束，即没有重复的引用，也没有指向根的约束。或者，可以将树抽象为一个整体（全局地）定义为有序树，并为每个节点分配一个值。这两种观点都很有用：虽然一棵树可以作为一个整体进行数学分析，但是当实际上表示为数据结构时，它通常由节点表示和使用（而不是作为一组节点和节点之间的邻接表），例如表示一个有向图）。例如，从整体上看一棵树，可以谈论给定节点的“父节点”，但是通常，给定节点作为数据结构仅包含其子节点列表，但不包含引用。给它的父母（如果有的话）。
术语 1、结点(Node)：表示树中的数据元素，由数据项和数据元素之间的关系组成。在图 1 中，共有 10 个结点。 2、结点的度(Degree of Node)：结点所拥有的子树的个数，在图 1 中，结点 A 的度为 3。 3、树的度(Degree of Tree)：树中各结点度的最大值。在图 1 中，树的度为 3。 4、叶子结点(Leaf Node)：度为 0 的结点，也叫终端结点。在图 1 中，结点 E、F、G、H、I、J 都是叶子结点。 5、分支结点(Branch Node)：度不为 0 的结点，也叫非终端结点或内部结点。在图 1 中，结点 A、B、C、D 是分支结点。 6、孩子(Child)：结点子树的根。在图 1 中，结点 B、C、D 是结点 A 的孩子。 7、双亲(Parent)：结点的上层结点叫该结点的双亲。在图 1 中，结点 B、C、D 的双亲是结点 A。 8、祖先(Ancestor)：从根到该结点所经分支上的所有结点。在图 1 中，结点 E 的祖先是 A 和 B。 9、子孙(Descendant)：以某结点为根的子树中的任一结点。在图 1 中，除 A 之外的所有结点都是 A 的子孙。 10、兄弟(Brother)：同一双亲的孩子。在图 1 中，结点 B、C、D 互为兄弟。 11、结点的层次(Level of Node)：从根结点到树中某结点所经路径上的分支数称为该结点的层次。根结点的层次规定为 1，其余结点的层次等于其双亲结点的层次加 1。 12、堂兄弟(Sibling)：同一层的双亲不同的结点。在图 1 中，G 和 H 互为堂兄弟。 13、树的深度(Depth of Tree)：树中结点的最大层次数。在图 1 中，树的深度为 3。 14、无序树(Unordered Tree)：树中任意一个结点的各孩子结点之间的次序构成无关紧要的树。通常树指无序树。 15、有序树(Ordered Tree)：树中任意一个结点的各孩子结点有严格排列次序的树。二叉树是有序树，因为二叉树中每个孩子结点都确切定义为是该结点的左孩子结点还是右孩子结点。 16、森林(Forest)：m(m≥0)棵树的集合。自然界中的树和森林的概念差别很大，但在数据结构中树和森林的概念差别很小。从定义可知，一棵树有根结点和 m 个子树构成，若把树的根结点删除，则树变成了包含 m 棵树的森林。当然，根据定义，一棵树也可以称为森林。</description></item><item><title>Unit File 指令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/Unit-File-%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Systemd/Unit-File/Unit-File-%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
Manual(手册)，systemd.unit(5) # Unit 的介绍 Manual(手册)，systemd.directives(7) # Unit File 中全部的指令列表 一个 Unit File 具有多个 Sections(部分)，大体可以分为 2 类
通用 Sections # 与 Unit 类型无关的部分 [Unit] 与 [Install] 特殊 Sections # 特定于 Unit 类型的部分 [Service]、[Socket]、[Timer]、[Mount]、[Path] 等等 除了 Unit 和 Install 以外的其余每个 Sections(部分) 都有其特定的 Directives(指令)，同时，也有一些通用的 Directives(指令) 可以用在多个 Sections(部分) 中。
通用部分的指令 [Unit] 部分的指令 https://man7.org/linux/man-pages/man5/systemd.unit.5.html#[UNIT]_SECTIONOPTIONS
unit 本身的说明，以及与其他相依赖的 daemon 的设置，包括在什么服务之前或之后启动等设置
Description=&amp;lt;STRING&amp;gt; # Unit 描述，用 systemctl list-units 和 systemctl status 查看服务时候的描述内容就是这里定义的
Documentation=&amp;lt;STRING&amp;gt; # 提供该 Unit 可以进一步文件查询的地址或者位置</description></item><item><title>Unit test(单元测试)</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Unit-test%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Unit-test%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</guid><description>概述 参考：
官方文档，教程-添加一个测试 https://geektutu.com/post/quick-go-test.html 1 如何写好单元测试 单元测试(Unit Tests, UT) 是一个优秀项目不可或缺的一部分，特别是在一些频繁变动和多人合作开发的项目中尤为重要。你或多或少都会有因为自己的提交，导致应用挂掉或服务宕机的经历。如果这个时候你的修改导致测试用例失败，你再重新审视自己的修改，发现之前的修改还有一些特殊场景没有包含，恭喜你减少了一次上库失误。也会有这样的情况，项目很大，启动环境很复杂，你优化了一个函数的性能，或是添加了某个新的特性，如果部署在正式环境上之后再进行测试，成本太高。对于这种场景，几个小小的测试用例或许就能够覆盖大部分的测试场景。而且在开发过程中，效率最高的莫过于所见即所得了，单元测试也能够帮助你做到这一点，试想一下，假如你一口气写完一千行代码，debug 的过程也不会轻松，如果在这个过程中，对于一些逻辑较为复杂的函数，同时添加一些测试用例，即时确保正确性，最后集成的时候，会是另外一番体验。
如何写好单元测试呢？
首先，学会写测试用例。比如如何测试单个函数/方法；比如如何做基准测试；比如如何写出简洁精炼的测试代码；再比如遇到数据库访问等的方法调用时，如何 mock。
然后，写可测试的代码。高内聚，低耦合是软件工程的原则，同样，对测试而言，函数/方法写法不同，测试难度也是不一样的。职责单一，参数类型简单，与其他函数耦合度低的函数往往更容易测试。我们经常会说，“这种代码没法测试”，这种时候，就得思考函数的写法可不可以改得更好一些。为了代码可测试而重构是值得的。
接下来将介绍如何使用 Go 语言的标准库 testing 进行单元测试。
2 一个简单例子 Go 语言推荐测试文件和源代码文件放在一块，测试文件以 _test.go 结尾。比如，当前 package 有 calc.go 一个文件，我们想测试 calc.go 中的 Add 和 Mul 函数，那么应该新建 calc_test.go 作为测试文件。
example/ |--calc.go |--calc_test.go 假如 calc.go 的代码如下：
package main func Add(a int, b int) int { return a + b } func Mul(a int, b int) int { return a * b } 那么 calc_test.</description></item><item><title>upstream 模块指令</title><link>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/upstream-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Web/Nginx/Nginx-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/%E5%A4%9A%E7%94%A8%E9%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E6%8C%87%E4%BB%A4/upstream-%E6%A8%A1%E5%9D%97%E6%8C%87%E4%BB%A4/</guid><description>概述 参考：
http 模块下的 upstream 模块 stream 模块下的 upstream 模块 http 和 stream 模块下的 upstream 模块都是用来定义一组可以处理流量的后端服务器，称为 Server Group(服务器组)。
Nginx 中有一个 Server Group(服务器组) 的概念，Server Group 表示一组可以处理流量的后端服务器，proxy_pass 等指令可以直接引用 服务器组的名称，以便将流量转发到这一组后端服务器上去。并且，可以根据规则，来决定给组内每个服务器分配多少流量，还可以根据规则如何判断 服务器是否掉线，掉线如何处理 等等。
Server Group 功能通过 upstream 模块实现。而 upstream NAME {} 指令是一个非常通用的指令，可以作用在顶级的 http{} 和 stream{} 配置环境中。因为 ServerGroup 就是定义一组服务器以便被 Nginx 的流量处理相关指令引用，故而属于通用配置，只不过定义在 http{} 配置环境中的 ServerGroup 不能被 stream{} 配置环境中的指令引用，反之亦然。
注意：虽然 upstream 比较通用，但也是逻辑意义上的通用，对于 http{} 与 stream{} 来说，它们都有各自的 upstream{} 模块
upstream NAME {} 定义的名为 NAME 的一组服务器，可以被 proxy_pass 、fastcgi_pass、uwsgi_pass、scgi_pass、memcached_pass、grpc_pass 这些指令直接引用，以便将流量直接代理到这组服务器上，并且可以根据一定的算法，轮流调度。</description></item><item><title>UTS Namespace</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/UTS-Namespace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/UTS-Namespace/</guid><description>概述 UTS(UNIX Time-Sharing System) Namespace 可隔离 hostname 和 NIS Domain name 资源，使得一个宿主机可拥有多个主机名或 Domain Name。换句话说，可让不同 namespace 中的进程看到不同的主机名。
例如，使用 unshare 命令(较新版本 Linux 内核还支持 nscreate 命令)创建一个新的 uts namespace：
# -u或--uts表示创建一个uts namespace # 这个namespace中运行/bin/bash程序 $ hostname longshuai-vm # 当前root namespace的主机名为longshuai-vm $ sudo unshare -u /bin/bash root@longshuai-vm:/home/longshuai# # 进入了新的namespace中的shell # 其主机名初始时也是longshuai-vm， # 其拷贝自上级namespace资源 上面指定运行的是/bin/bash 程序，这会进入交互式模式，当执行 exit 时，bash 退出，回到当前的 namespace 中。也可以指定在 namespace 中运行其他程序，例如 unshare -u sleep 3 表示在 uts namespace 中睡眠 3 秒后退出并回到当前 namespace。
因为是 uts namespace，所以可在此 namespace 中修改主机名：</description></item><item><title>UUID 与 ULID</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/UUID-%E4%B8%8E-ULID/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/UUID-%E4%B8%8E-ULID/</guid><description>概述 参考：
RFC 4122 RFC 9562 Wiki, UUID GitHub 项目，ulid/spec UUID universally unique identifier(通用唯一标识符，简称 UUID) 是一个128 位的 标签用于在计算机系统中的信息。还使用术语全局唯一标识符( GUID )，通常在 Microsoft 创建的软件中使用。
根据标准方法生成时，UUID 出于实用目的是唯一的。与大多数其他编号方案不同，它们的唯一性不依赖于中央注册机构或生成它们的各方之间的协调。虽然 UUID 被复制的概率不是零，但它足够接近零，可以忽略不计。
因此，任何人都可以创建一个 UUID 并使用它来识别某些东西，几乎可以肯定的是，该标识符不会与已经或将要创建的标识符重复以识别其他东西。因此，独立方标有 UUID 的信息稍后可以合并到单个数据库中或在同一频道上传输，重复的可能性可以忽略不计。
UUID 的采用很普遍，许多计算平台为生成它们和解析它们的文本表示提供支持。
ULID Universally Unique Lexicographically Sortable Identifier(通用唯一的字典可排序标识符，简称 ULID)</description></item><item><title>VictoriaMetrics</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/VictoriaMetrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/VictoriaMetrics/</guid><description>概述 参考：
GitHub 项目，VictoriaMetrics/VictoriaMetrics 官网 MetricsQL https://docs.victoriametrics.com/MetricsQL.html#count_ne_over_time</description></item><item><title>virt-manager</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/virt-manager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/Libvirt-API/virt-manager/</guid><description>概述 参考
GitHub 项目，virt-manager/virt-manager 官网 virt-manager 是一个图形化的应用程序，通过 libvirt 管理虚拟机。
virt-manager 提供了多个配套的工具
virt-manager # GUI 模式的 VM 管理程序 virt-viewer # 是一个轻量级的 UI 界面，用于与虚拟客户操作系统的图形显示进行交互。它可以显示 VNC 或 SPICE，并使用 libvirt 查找图形连接详细信息。 virt-install # 是一个命令行工具，它提供了一种将操作系统配置到虚拟机中的简单方法。 virt-clone # 是一个用于克隆现有非活动客户的命令行工具。它复制磁盘映像，并使用指向复制磁盘的新名称、UUID 和 MAC 地址定义配置。 virt-xml # 是一个命令行工具，用于使用 virt-install 的命令行选项轻松编辑 libvirt 域 XML。 virt-bootstrap # 是一个命令行工具，提供了一种简单的方法来为基于 libvirt 的容器设置根文件系统。 virt-clone、virt-xml、virt-install 属于安装虚拟机的工具，通常都在 virtinst 包中。
virt-manager、virt-viewer 属于图形化管理虚拟机的工具，通常都在 virt-manager 包中。
virt-manager 使用 virt-manager 管理多台虚拟机 在一台机器上的 virt-manager 可以通过 add connection 管理其它宿主机上的虚拟机，但是前提是建立 ssh 的密钥认证，因为在 virt-manager 在通过 ssh 连接的时候，需要使用窗口模式输入密码，而一般情况下 ssh 是默认不装该组件的。如果不想添加密钥认证，那么安装 ssh-askpass-gnome 组件即可。</description></item><item><title>Virtual Network 命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Virtual-Network-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/Virtual-Network-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方 Manual(手册)，VIRTUAL NETWORK COMMANDS net-autostart net-create net-define # 定义一个非活动的持久虚拟网络或从 XML 文件中修改一个现有的持久虚拟网络 net-destroy # 摧毁一个网络 net-dumpxml net-edit net-event net-info net-list net-name net-start net-undefine net-uuid net-update net-dhcp-leases</description></item><item><title>Vite</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/Vite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/Vite/</guid><description>概述 参考：
GitHub 组织，vite GitHub 项目，vitejs/vite Vue 作者主导的打包与编译工具，启动项目开发模式速度非常快、下载依赖非常快、编译非常快。
在 GitHub 项目，vitejs/awesom-vite 这里有很多使用 Vite 打包的很棒的项目示例
安装 Vite Vite 关联文件与配置 vite.config.js # 每个项目的根目录通常都会有一个 vite.config.js 文件，以定义打包项目代码时的行为
Vite 配置详解 参考：
官方文档，配置 常见问题 解决 Vite 打包项目代码后，使用的是绝对路径 在 vite.config.js 文件中设置 base
解决 vite 在 WSL 环境下热更新失效问题 使用 vite 的好处很多，最明显的就是热更新很快。但是在 wsl 环境的时候，由于WSL2 的限制，vite 默认配置是无法监控 windows 文件系统中文件的变化的。这就导致了 vite 的热更新失效。 解决热更新失效的方法主要有两种： 1.文件存储到 WSL 系统环境中 2.配置 vite.config.js 的 server.watch
export default defineConfig({ server: { watch: { { usePolling: true } } } }) vite Syntax(语法) vite 将会启动一个开发服务器，默认响应当前目录的 index.</description></item><item><title>Vmware</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Vmware/Vmware/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Vmware/Vmware/</guid><description>概述 参考：
官网 Vmware Workstation 的网络说明 VMware 软件里可以提供一个虚拟交换机，PC 中创建的虚拟网卡与该虚拟机交换机直连，虚拟机也与该虚拟交换机直连 一、虚拟机发出的数据包两种走向： （1）虚拟机——虚拟交换机——PC 上的虚拟网卡。到此为止，因为 PC 上的虚拟网卡和物理网卡是二层设备不在一个广播域，也无法路由 （2）虚拟机——虚拟交换机——VMware 的虚拟 NAT 设备——PC 上的物理网卡——Internet。 二、主机发出的数据包走向（通过虚拟网卡发送）主机发送的其余包，均通过本地网卡转发 （1）PC——PC 上的虚拟网卡——虚拟交换机——虚拟机。主机到虚拟机的路径仅此一条
结论：
禁用虚拟网卡后虚拟机依然可以访问外网，但是 PC 无法访问虚拟机。因为第一条中的（2）和第二条中的（1） 启用静态 IP 后，PC 可以访问虚拟机，但是虚拟机只能访问到虚拟网卡，外网不同。因为第一条中的（1）（2） 仅主机模式说明
创建一个虚拟交换机，所有 VM 连接到该虚拟交换机上，即可实现通信 Nat 模型说明：
如图所示，VM 访问外网时通过虚拟 NAT 设备来进行外网访问的，可以把虚拟 NAT 设备当做一个具备 nat 功能的路由器，所以当给 VM 配置静态 IP 的时候，如果想连接外网，需要把网关配置成这个虚拟 NAT 设备上上端口的 IP，一般为 XXX.XXX.XXX.2. 其余说明详见图中红字</description></item><item><title>Vmware虚拟机三种网络模式详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Vmware/Vmware%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%89%E7%A7%8D%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Vmware/Vmware%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%89%E7%A7%8D%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/</guid><description>概述 vmware 为我们提供了三种网络工作模式，它们分别是：Bridged（桥接模式）、NAT（网络地址转换模式）、Host-Only（仅主机模式）。
打开 vmware 虚拟机，我们可以在选项栏的“编辑”下的“虚拟网络编辑器”中看到 VMnet0（桥接模式）、VMnet1（仅主机模式）、VMnet8（NAT 模式），那么这些都是有什么作用呢？其实，我们现在看到的 VMnet0 表示的是用于桥接模式下的虚拟交换机；VMnet1 表示的是用于仅主机模式下的虚拟交换机；VMnet8 表示的是用于 NAT 模式下的虚拟交换机。 同时，在主机上对应的有 VMware Network Adapter VMnet1 和 VMware Network Adapter VMnet8 两块虚拟网卡，它们分别作用于仅主机模式与 NAT 模式下。在“网络连接”中我们可以看到这两块虚拟网卡，如果将这两块卸载了，可以在 vmware 的“编辑”下的“虚拟网络编辑器”中点击“还原默认设置”，可重新将虚拟网卡还原。 小伙伴看到这里，肯定有疑问，为什么在真机上没有 VMware Network Adapter VMnet0 虚拟网卡呢？那么接下来，我们就一起来看一下这是为什么。
一、Bridged（桥接模式）
什么是桥接模式？桥接模式就是将主机网卡与虚拟机虚拟的网卡利用虚拟网桥进行通信。在桥接的作用下，类似于把物理主机虚拟为一个交换机，所有桥接设置的虚拟机连接到这个交换机的一个接口上，物理主机也同样插在这个交换机当中，所以所有桥接下的网卡与网卡都是交换模式的，相互可以访问而不干扰。在桥接模式下，虚拟机 ip 地址需要与主机在同一个网段，如果需要联网，则网关与 DNS 需要与主机网卡一致。其网络结构如下图所示：
接下来，我们就来实际操作，如何设置桥接模式。
首先，安装完系统之后，在开启系统之前，点击“编辑虚拟机设置”来设置网卡模式。
点击“网络适配器”，选择“桥接模式”，然后“确定”
在进入系统之前，我们先确认一下主机的 ip 地址、网关、DNS 等信息。
然后，进入系统编辑网卡配置文件，命令为 vi /etc/sysconfig/network-scripts/ifcfg-eth0
添加内容如下：
编辑完成，保存退出，然后重启虚拟机网卡，使用 ping 命令 ping 外网 ip，测试能否联网。
能 ping 通外网 ip，证明桥接模式设置成功。
那主机与虚拟机之间的通信是否正常呢？我们就用远程工具来测试一下。
主机与虚拟机通信正常。
这就是桥接模式的设置步骤，相信大家应该学会了如何去设置桥接模式了。桥接模式配置简单，但如果你的网络环境是 ip 资源很缺少或对 ip 管理比较严格的话，那桥接模式就不太适用了。如果真是这种情况的话，我们该如何解决呢？接下来，我们就来认识 vmware 的另一种网络模式：NAT 模式。</description></item><item><title>VNC</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/VNC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/VNC/</guid><description>概述 参考：
Wiki, VNC GitHub 项目，rfbproto/rfbproto(RFB 协议规范) Virtual Network Computing(虚拟网络计算，简称 VNC) 是一种图形桌面共享系统，VNC 使用 RFB Protocol(远程帧缓冲协议) 以控制另一台计算机；它将键盘和鼠标输入从一台计算机传输到另一台计算机，通过网络中继更新显示器上的信息。
VNC 是独立于平台的——有许多基于 GUI 的操作系统和 Java 的客户端和服务器。多个客户端可以同时连接到 VNC 服务器。该技术的流行用途包括远程技术支持和从家庭计算机访问工作计算机上的文件，反之亦然。
为什么没法通过 VNC 连接物理机的 CLI，但是可以连接虚拟机的 CLI 呢？！在 rfbproto/rfbproto 的 #18 issue 中倒是说了 QEMU 中内置了 VNC/RFB，并对该协议进行了一些修改以支持一些额外的功能
TigerVNC 参考：
GitHub 项目，TigerVNC/tigernvc 官网 TigerVNC 是 VNC 的高性能、平台无关的实现，是一个 C/S 架构应用程序，允许用户在远程机器上启动图形应用程序并与之交互。
安装 TigerVNC CentOS
yum install tigervnc-server Ubuntu
RealVNC 参考：
官网</description></item><item><title>VS Code 快捷键</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/VS-Code-%E5%BF%AB%E6%8D%B7%E9%94%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/VS-Code-%E5%BF%AB%E6%8D%B7%E9%94%AE/</guid><description>概述 参考：
官方文档,pdf 官方文档 https://docs.microsoft.com/zh-cn/visualstudio/ide/productivity-shortcuts 多个组合按键表示需要连续按
全局快捷键 Ctrl+q 搜索 Visual Studio。主要用于快速切换 VS Code 本身的功能
Ctrl+k,Ctrl+s 打开键盘快捷方式列表
视图 Ctrl+Shift+e # 显示资源管理器
Ctrl+Shift+g # 显示源代码管理
Ctrl+k,Ctrl+F5 # (自定义)Git 刷新
Ctrl+Shift+f # 显示搜索
Ctrl+Alt+→ 将编辑器拆分到新组
Ctrl+Alt+→ 将编辑器合并到前一个组
Ctrl+PageUp 选中上一个编辑器
Ctrl+PageDown 选中下一个编辑器
Ctrl+k,Ctrl+→ 选中右侧编辑器组
Ctrl+k,Ctrl+← 选中左侧编辑器组
组内操作 Alt+NUM 选中组中第 NUM 号编辑器
编辑时操作 操作光标所在代码
折叠 Ctrl+k,Ctrl+[ 递归折叠光标所在代码块所有层 Ctrl+Shift+[ 折叠光标所在代码代码 1 层 展开 Ctrl+k,Ctrl+] 递归展开光标所在代码块所有层 Ctrl+Shift+] 展开光标所在代码代码 1 层 操作文件所有代码
折叠 Ctrl+k,Ctrl+0 折叠所有代码全部层 Ctrl+k,Ctrl+${NUM} 折叠所有代码的 NUM 层 Ctrl+k,Ctrl+/ 折叠所有代码的注释 展开 Ctrl+k,Ctrl+j 展开所有代码的全部层 Alt+Shift+a 添加代码块注释</description></item><item><title>VS Code 配置详解</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/VS-Code-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/VS-Code-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 配置详解 { // 通用配置 // 资源管理器自动展开功能。即.追踪代码时，是否自动展开资源管理器中的目录。 // 该配置在前端代码中，最好关闭，因为前端的依赖都在本地目录中，展开之后太乱了 &amp;#34;explorer.autoReveal&amp;#34;: true, // 启用后，将不会显示扩展建议的通知。 &amp;#34;extensions.ignoreRecommendations&amp;#34;: true, // 终端在 Windows 上使用的 shell 的路径(默认: C:\WINDOWS\System32\WindowsPowerShell\v1.0\powershell.exe)。 // [详细了解如何配置 shell](https://code.visualstudio.com/docs/editor/integrated-terminal#_configuration)。 // &amp;#34;terminal.integrated.shell.windows&amp;#34;: &amp;#34;D:\\Tools\\Git\\bin\\bash.exe&amp;#34;, // 上面的指令已弃用，使用下面的方式来配置 shell &amp;#34;terminal.integrated.profiles.windows&amp;#34;: { &amp;#34;PowerShell&amp;#34;: { &amp;#34;source&amp;#34;: &amp;#34;PowerShell&amp;#34;, &amp;#34;icon&amp;#34;: &amp;#34;terminal-powershell&amp;#34; }, &amp;#34;bash&amp;#34;: { &amp;#34;path&amp;#34;: &amp;#34;D:\\Tools\\Git\\bin\\bash.exe&amp;#34; } }, &amp;#34;terminal.integrated.defaultProfile.windows&amp;#34;: &amp;#34;Ubuntu-20.04 (WSL)&amp;#34;, &amp;#34;terminal.integrated.automationShell.linux&amp;#34;: &amp;#34;&amp;#34;, // 控制侧边栏和活动栏的位置。它们可以显示在工作台的左侧或右侧。 &amp;#34;workbench.sideBar.location&amp;#34;: &amp;#34;left&amp;#34;, // 默认行尾字符，可用的值有如下几个： // \n # 表示 LF // \r\n # 表示 CRLF // auto # 表示 使用具体操作系统规定的行末字符。 &amp;#34;files.</description></item><item><title>VS Code 中的 WSL</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/VS-Code-%E4%B8%AD%E7%9A%84-WSL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-environment/IDE/Visual-Studio-Code/VS-Code-%E4%B8%AD%E7%9A%84-WSL/</guid><description>概述 参考：
官方文档，远程-WSL 使用指定发行版的 WSL
使用第一个的话，go 环境始终无法获取环境变量
WSL 代理 VS Code 中的 WSL 将会继承 VS Code 的代理配置。
若启动 VS Code 之前，已启动系统代理(比如 Clash for windows)，则 VS Code 中的 WSL 也会使用代理，而此时 VS Code 的默认代理是 127.0.0.1:7890，此时 WSL 继承了这个配置，那么访问 WSL 中的这个地址是有问题的（此时 Ubuntu 中可并没有运行 Clash，也自然不会监听本地 7890 端口）
所以，若想让插件使用本地连接，启动 VS Code 之前不要开启系统代理。
VS Code 部分扩展联网失败的问题 https://kawnnor.com/wsl-vscode-proxy
在 VS Code 中，通过 Remote - WSL 打开 Ubuntu 子系统中的项目
IntelliCode 扩展无法下载模型，WakaTime 扩展无法上传统计数据 ChatGPT 无法访问 猜测原因 Clash for Windows + TUN Mode 对 Ubuntu 子系统中的 vscode-server 没有起到代理的作用，但是 IntelliCode 和 WakaTime 在没有代理的情况下应该也可以正常工作，所以怀疑 vscode-server 被配置了错误的代理。</description></item><item><title>Vue 环境安装与使用</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>概述 参考：
官方文档，应用规模化-工具链 Vue3 早期使用 Vue CLI，创建 Vue 项目，后来 Vue 作者尤雨溪开了一个新的工具 Vite，Vite 通过 vuejs/create-vue 项目，基于 Vite 创建 Vue 项目。
Vite 参考：
GitHub 项目，vitejs/vite 官网 Vite 是一种新型前端构建工具，可显着改善前端开发体验。它由两个主要部分组成：
一个开发服务器，通过原生 ES 模块为您的源文件提供服务，具有丰富的内置功能和惊人的快速热模块替换 (HMR)。 一个构建命令，将你的代码与Rollup捆绑在一起，预先配置为输出高度优化的生产静态资产。 此外，Vite 通过其插件 API和JavaScript API具有高度的可扩展性，具有完整的类型支持。
基于 Vite 创建 Vue 项目 参考：
官方文档，快速上手-创建一个 Vue 应用 GitHub 项目，vitejs/awesome-vite（一些使用 vite 创建的应用模板，可以直接拿来用） Vue Naive - 管理模板，基于 Vue 3 + Pinia + Naive UI。 npm init vue@latest 注意：通过 npm 将 vite 作为模块安装到 node_modules/ 目录下，然后执行 npm run dev、npm build 等命令时，可以直接调用。但是想在 CLI 直接调用 vite 命令是需要通过 npm install -g vite 单独安装 vite 命令行工具的 注意：如果不在全局安装 vite，那也可以直接使用 node .</description></item><item><title>Vue 响应式</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E5%93%8D%E5%BA%94%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E5%93%8D%E5%BA%94%E5%BC%8F/</guid><description>概述 参考：
官方文档，API 参考 官方文档，API 参考-组合式 API-响应式：核心 ref 与 reactive 是响应式的基础
响应式: 核心 ref() https://cn.vuejs.org/api/reactivity-core.html#ref
ref() 函数返回一个 Ref&amp;lt;T = any&amp;gt; 接口类型的对象，该接口中只有一个名为 value 的属性，用以指向该对象的值。 Ref&amp;lt;T&amp;gt; 接口对象是 响应式、可更改 的。
let number = ref &amp;lt; number &amp;gt; 0 number 是 Ref&amp;lt;number&amp;gt; 类型的实例，Ref.value 则是该实例的值，即 0。 Ref 对象是可更改的，也就是说你可以为 .value 赋予新的值。它也是响应式的，即所有对 .value 的操作都将被追踪，并且写操作会触发与之相关的副作用。 如果将一个对象赋值给 ref，那么这个对象将通过 reactive() 转为具有深层次响应式的对象。这也意味着如果对象中包含了嵌套的 ref，它们将被深层地解包。 若要避免这种深层次的转换，使用 shallowRef() 来替代。
computed () https://cn.vuejs.org/api/reactivity-core.html#computed
reactive() https://cn.vuejs.org/api/reactivity-core.html#reactive
readonly() watchEffect() watchPostEffect() watchSyncEffect() watch() 响应式: 工具 isRef() unref() toRef() toRefs() isProxy() isReactive() isReadonly() 响应式: 进阶 shallowRef() triggerRef() customRef() shallowReactive() shallowReadonly() toRaw() markRaw() effectScope() getCurrentScope() onScopeDispose() 生命周期钩子 onMounted() onUpdated() onUnmounted() onBeforeMount() onBeforeUpdate() onBeforeUnmount() onErrorCaptured() onRenderTracked() onRenderTriggered() onActivated() onDeactivated() onServerPrefetch()</description></item><item><title>Vue 组件</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E7%BB%84%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Framework/Vue/Vue-%E7%BB%84%E4%BB%B6/</guid><description>概述 参考：
官方文档，基础-组件基础 组件间数据传递 在 Vue 中，组件之间可以传递多种类型的数据
变量，通过 Props。 关键字：v-bind 模板，通过 Slots 关键字：&amp;lt;template&amp;gt;、v-slot 事件，通过 Event 关键字：v-model、v-on、emit Props Slots Slot Content(插槽内容) 与 Slot Outlet(插槽出口)
&amp;lt;slot&amp;gt; 元素是一个 Slot Outlet(插槽出口)，标示了父元素提供的 Slot Content(插槽内容) 将在哪里被渲染。
Event Event(事件)</description></item><item><title>WireGuard 部署</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/WireGuard-%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/WireGuard-%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
原文链接：https://mp.weixin.qq.com/s/vbt30eEGcp5JP5sHAPkwhw 英文原文链接: https://github.com/pirate/wireguard-docs 安装 WireGuard Unix-like OS 安装 WireGuard 本质是安装如下几个程序：
wireguard # WireGuard 的实现。wireguard 程序有两种实现方式，分为是用户态的实现与内核态的实现。 CLI wg # 管理 WireGuard 网络。生成密钥、设置网络设备信息、查看状态、etc. wg-quick # 用户友好的命令行工具，可以通过配置文件管理调用 wg 程序以启动或停止 WireGuard [!Tip] wireguard 用户态与内核态的实现
绝大多数 Unix-like OS 发行版的内核版本（Linux Kernel 5.6 版本开始）通常都内置了 wireguard 模块。
有些设备内核没有 wireguard 模块，使用 modprob wireguard 命令加载模块时报错 modprobe: FATAL: Module wireguard not found in directory /lib/modules/$(uanme -r)，此时可以利用用户态的 Wireguard 程序实现 Wireguard 互联。
https://github.com/WireGuard/wireguard-go 是使用 Go 语言在用户态实现的 Wireguard https://github.com/cloudflare/boringtun 是使用 Rust 语言在用户态实现的 Wireguard etc.</description></item><item><title>Wireguard配置详解</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/Wireguard-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/Wireguard-%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
https://zhangguanzhang.github.io/2020/08/05/wireguard-for-personal/ https://fuckcloudnative.io/posts/wireguard-docs-practice/#peer WireGuard 使用 INI 作为其配置文件格式。配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/*.conf。
配置文件的命名形式必须为 ${WireGuard_Interface_Name}.conf。通常情况下 WireGuard 接口名称以 wg 为前缀，并从 0 开始编号，但你也可以使用其他名称，只要符合正则表达式 ^[a-zA-Z0-9_=+.-]{1,15}$ 就行。当启动时，如果配置文件中有 wg0.conf 文件，则会创建一个名为 wg0 的网络设备。效果如下
注意：${WireGuard_Interface_Name} 不能过长，否则将会报错：wg-quick: The config file must be a valid interface name, followed by .conf
基本配置示例 [Interface] # Name = node1.example.tld Address = 192.0.2.3/32 ListenPort = 51820 PrivateKey = localPrivateKeyAbcAbcAbc= DNS = 1.1.1.1,8.8.8.8 Table = 12345 MTU = 1500 PreUp = /bin/example arg1 arg2 %i PostUp = /bin/example arg1 arg2 %i PreDown = /bin/example arg1 arg2 %i PostDown = /bin/example arg1 arg2 %i [Peer] # Name = node2-node.</description></item><item><title>Workflow 命令</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Workflow-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Workflow-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Workflow-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Workflow-%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方文档，使用 Workflow-Workflow 命令 我们可以在 Workflow 中执行 Shell 命令时，使用 GitHub Action Workflow 的特殊命令。这些 Workflow 命令可以与运行机器通信以 设置环境变量、输出值、添加 debug 消息到 输出日志 等等。
大多数 Workflow 命令以特定格式通过 echo 命令使用，语法为：
echo &amp;quot;::WorkflowCommand Parameter1={DATA},Parameter2={DATA},...::{COMMAND|VALUE}&amp;quot;
下面是一个设置步骤的输出内容的示例：
jobs: test-workflow-command: runs-on: ubuntu-latest steps: - name: 设置 ARCH 变量的值为 uname -m 命令执行的结果 run: echo &amp;#39;::set-output name=ARCH::$(uname -m)&amp;#39; id: arch-generator - name: 从 id 为 arch-generator 步骤的输出中，获取 ARCH 的值 run: echo &amp;#34;The selected color is ${{ steps.arch-generator.outputs.ARCH }}&amp;#34;</description></item><item><title>Workflow 文件详解</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Workflow-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Workflow-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-tools/SCM/GitHub/GitHub-Actions/Workflow-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/Workflow-%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，使用工作流-触发工作流 官方文档，使用工作流-触发工作流的事件 官方文档，使用工作流-Workflow 语法 GitHub 的 Actions 通过 YAML 格式的文件来定义运行方式。工作流文件必须保存在项目根目录下的 .github/workflows/ 目录下
顶层字段 name(STRING) # Workflow 的名称。默认值：当前 Workflow 的文件名。 run-name # on(on) # 指定触发 Workflow 的条件 permissions env defaults concurrency jobs(jobs) # Workflow 文件的主体，用于定义要执行的一项或多项任务 on https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#on
这个字段用来定义触发工作流的事件，在这里可以看到 GitHub 支持的所有事件，通常包含如下字段
&amp;lt;EVENT_NAME&amp;gt;.types # 根据指定 EVENT_NAME(事件名称) 事件的活动，触发 Workflow EVENT_NAME 指事件的名称，所有可用的事件详见 Events that trigger workflows types 就是指事件的 Activity types(活动类型) 比如名为 release 的事件是指一个项目的 Releases，release 有 published、created、edited、etc. 很多活动类型。 下面的示例就是指当项目的 Release 发布时（创建后点击 Publish release 按钮），开始执行 Workflow on: release: types: [published] push(push) # 当上传代码时，触发 Workflow pull_request(pull_request) # 当发生 PR 时，触发 orkflow schedule([]schedule) # 定时触发 Worlkflow workflow_dispatch(workflow_dispatch) # 手动触发 Workflow &amp;hellip;&amp;hellip; push branches: &amp;lt;[]STRING&amp;gt; # 指定出发条件，当上传代码到该字段指定的分支时，触发 Workflow</description></item><item><title>wrk</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/wrk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/wrk/</guid><description>概述 参考：
GitHub 项目,wrk wrk 是一种现代 HTTP 基准测试小型工具，当在单个多核 CPU 上运行时，能够产生大量负载。它结合了多线程设计和可扩展的事件通知系统，例如 epoll 和 kqueue。
可选的 LuaJIT 脚本可以执行 HTTP 请求生成，响应处理和自定义报告。详细信息可在 SCRIPTING 中找到，几个示例位于 scripts /中
Wrk2 参考
GitHub 项目,wrk2 https://www.wangbo.im/posts/usage-of-benchmarking-tool-wrk-and-wrk2/ Wrk 的安装 安装 wrk 需要从项目上 clone 项目然后编译获取二进制文件
yum groupinstall &amp;lsquo;Development Tools&amp;rsquo; -y yum install openssl-devel git -y git clone https://github.com/wg/wrk cd wrk make cp wrk /usr/local/bin clone 和编译时间较长，这里给一个编译好的文件
Wrk 命令行工具使用方法 wrk [OPTIONS] URL OPTIONS
-c,&amp;ndash;connections NUM # 指定总的 http 并发数。默认 10 个并发连接 -d,&amp;ndash;duration NUM # 指定压测的持续时间。默认 10s -H,&amp;ndash;header STRING # 使用指定的头信息作为请求 header -t,&amp;ndash;threads NUM # 指定总线程数。默认 2 个线程 &amp;ndash;latency # 输出延迟统计情况 EXAMPLE</description></item><item><title>X Window</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/X-Window/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/X-Window/</guid><description>概述 参考：
Wiki, X Window 系统协议和架构 Wiki, X Window 管理器 鸟哥的 Linux 私房菜,第二十三章、X Window Unix Like 操作系统不是只能进行服务器的架设而已，在美编、排版、制图、多媒体应用上也是有其需要的。 这些需求都需要用到图形介面 (Graphical User Interface, GUI) 的操作的， 所以后来才有所谓的 X Window System 这玩意儿。那么为啥图形窗口介面要称为 X 呢？因为就英文字母来看 X 是在 W(indow) 后面，因此，人们就戏称这一版的窗口介面为 X (有下一版的新窗口之意)！
事实上， X Window System 是个非常大的架构，他还用到网络功能呢！也就是说，其实 X 窗口系统是能够跨网络与跨操作系统平台的！
X Window 的发展简史 X Window 系统最早是由 MIT (Massachusetts Institute of Technology, 麻省理工学院) 在 1984 年发展出来的， 当初 X 就是在 Unix 的 System V 这个操作系统版本上面开发出来的。在开发 X 时，开发者就希望这个窗口介面不要与硬件有强烈的相关性，这是因为如果与硬件的相关性高，那就等於是一个操作系统了， 如此一来的应用性会比较局限。因此 X 在当初就是以应用程序的概念来开发的，而非以操作系统来开发。</description></item><item><title>XDP eBPF 与 TC eBPF</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/XDP-eBPF-%E4%B8%8E-TC-eBPF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/BPF/BPF-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6/XDP-eBPF-%E4%B8%8E-TC-eBPF/</guid><description>概述 参考：
Wiki, Express_Data_Path eXpress Data Path(特快数据路径，简称 XDP) 是从 4.8 版开始在 Linux 内核中合并的基于 eBPF 的高性能数据路径。
XDP 背后的想法是在内核的 RX 路径中添加一个早期钩子，然后让用户提供的 eBPF 程序来决定数据包的命运。该挂钩刚好在中断处理之后，在网络堆栈本身需要的任何内存分配之前放置在 NIC 驱动程序中，因为内存分配可能是一项昂贵的操作。由于这种设计，使用商用硬件，XDP 可以每秒每核心丢弃 2 千 6 百万个数据包。
eBPF 程序在加载之前必须通过预验证器测试，以避免在内核空间中执行恶意代码。预验证器检查程序是否不包含越界访问，循环或全局变量。
Linux 内核中的数据包流路径。XDP 绕过了网络堆栈和数据包元数据的内存分配。
允许程序编辑数据包数据，并且在 eBPF 程序返回后，操作代码确定如何处理数据包：
XDP_PASS：让数据包继续通过网络堆栈 XDP_DROP：静默丢弃数据包 XDP_ABORTED：丢弃具有跟踪点异常的数据包 XDP_TX：将数据包弹回到达的同一网卡 XDP_REDIRECT：通过 AF_XDP 地址族将数据包重定向到另一个 NIC 或用户空间套接字 XDP 需要 NIC 驱动程序的支持，但由于并非所有驱动程序都支持 XDP，因此它可以回退到通用实现，该通用实现在网络堆栈中执行 eBPF 处理，但性能较慢。
XDP 具有将 eBPF 程序卸载到支持它的 NIC 卡的基础结构，从而减少了 CPU 负载。当时只有 Netronome 卡支持它，[5]由 Intel 和 Mellanox 共同开发。
AF_XDP
与 XDP 一起，从 4.</description></item><item><title>Xen</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Xen/Xen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/Xen/Xen/</guid><description>在 Xen 使用的方法中，没有指令翻译。这是通过两种方法之一实现的。第一，使用一个能理解和翻译虚拟操作系统发出的未修改指令的 CPU（此方法称作完全虚拟化或 full virtualization）。另一种，修改操作系统，从而使它发出的指令最优化，便于在虚拟化环境中执行（此方法称作准虚拟化或 paravirtualization）。
在 Xen 环境中，主要有两个组成部分。一个是虚拟机监控器（VMM），也叫 hypervisor。Hypervisor 层在硬件与虚拟机之间，是必须最先载入到硬件的第一层。Hypervisor 载入后，就可以部署虚拟机了。在 Xen 中，虚拟机叫做“domain”。在这些虚拟机中，其中一个扮演着很重要的角色，就是 domain0，具有很高的特权。通常，在任何虚拟机之前安装的操作系统才有这种特权。
Domain0 要负责一些专门的工作。由于 hypervisor 中不包含任何与硬件对话的驱动，也没有与管理员对话的接口，这些驱动就由 domain0 来提供了。通过 domain0，管理员可以利用一些 Xen 工具来创建其它虚拟机（Xen 术语叫 domainU）。这些 domainU 也叫无特权 domain。这是因为在基于 i386 的 CPU 架构中，它们绝不会享有最高优先级，只有 domain0 才可以。
在 domain0 中，还会载入一个 xend 进程。这个进程会管理所有其它虚拟机，并提供这些虚拟机控制台的访问。在创建虚拟机时，管理员使用配置程序与 domain0 直接对话。
Xen 的组成部分： Xen Hypervisor：分配 CPU、Memory、Interrupt Domain0：特权域，安装完 Hypervisor 后，自动生成的一个特权 Virtual Machine，负责管理整个 Xen 的 VM，可以直接访问硬件 IO 资源，修改 Linux Kernel 以实现半虚拟化功能 提供管理 DomainU 的工具栈，用于实现对虚拟机进行添加，启动，快照，停止，删除等操作 DomainU：非特权域，U 是各个虚拟机的编号 1,2,3,4,&amp;hellip;..，受 Domain0 管理 PV：不依赖于 CPU 的 HVM 特性，但要求 GusetOS 的内核做出修改以直销自己运行于 PV 环境 HVM：依赖于 Intel VT 或 AMD AMD-V，还要依赖于 Qemu 来模拟 IO 设备 PV on HVM：CPU 为 HVM 模式运行，IO 设备为 PV 模式运行 Xen 的工具栈</description></item><item><title>Xmanager power suit7</title><link>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/X-Manager/Xmanager-power-suit7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/X-Manager/Xmanager-power-suit7/</guid><description>097b37d09ade8de763f9473b0cc065299e88e6f23e7f67cf8b3761ec62f5a250ba79acbf59f85115c4a5ca7e5a4e47dee59fbd7581f50a1b6dd61ec988ceaa1a
https://github.com/woytu/tool-gin
Xshell / Xftp 激活下载 支持 Xshell、Xftp、Xshell Plus、Xmanager Power Suite 各版本激活下载 nginx-format navicat
官方网址： https://www.netsarang.com/zh/all-downloads
注意： 安装新版本之前请把老版本先卸载！！！
屏蔽版本升级方式一： 127.0.0.1 transact.netsarang.com 127.0.0.1 update.netsarang.com 127.0.0.1 www.netsarang.com 127.0.0.1 www.netsarang.co.kr 127.0.0.1 sales.netsarang.com
屏蔽版本升级方式二： 把以下几行保存到文件reg.ini，然后在 cmd 中执行REGINI reg.ini HKEY_CURRENT_USER\Software\NetSarang\Xshell\6\LiveUpdate [19] HKEY_CURRENT_USER\Software\NetSarang\Xftp\6\LiveUpdate [19] HKEY_CURRENT_USER\Software\NetSarang\Xmanager\6\LiveUpdate [19] HKEY_CURRENT_USER\Software\NetSarang\Xlpd\6\LiveUpdate [19] **</description></item><item><title>Xrdp</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Xrdp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Xrdp/</guid><description>概述 参考：
GitHub 项目，neutrinolabs/xrdp https://tecadmin.net/how-to-install-xrdp-on-ubuntu-20-04/ XRDP 使用 Microsoft 的 Remote Desktop Protocol(远程桌面协议，简称 RDP) 提供了一个图形界面以登录到计算机。XRDP 接受来自各种 RDP 客户端的连接。比如：
FreeRDP rdesktop KRDC NeutrinoRDP Windows MSTSC (Microsoft Terminal Services Client, aka mstsc.exe) Microsoft Remote Desktop (found on Microsoft Store, which is distinct from MSTSC) XRDP 主要针对 Linux 操作系统，可以让 Windows，使用其自带的远程桌面，通过 RDP 协议，远程控制装有 XRDP 的 Linux 系统，以实现远程图形化控制。
为 Ubuntu 安装 Xrdp 远程桌面协议允许用户访问远程系统桌面。 XRDP 服务向您提供使用 Microsoft RDP（远程桌面协议）的远程计算机的图形登录。 XRDP 还支持双向剪贴板传输（文本，位图，文件），音频重定向和驱动器重定向（在远程计算机上安装本地客户端驱动器）。 XRDP 是 Ubuntu 系统的易于安装和可配置的服务。但您还可以使用 VNC Server 访问 Ubuntu 系统的远程桌面。在 Ubuntu 20.</description></item><item><title>Xshell 脚本</title><link>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/X-Manager/Xshell-%E8%84%9A%E6%9C%AC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/X-Manager/Xshell-%E8%84%9A%E6%9C%AC/</guid><description>概述 http://www.cxyzjd.com/article/qq_34347375/113464381
脚本示例 vbs Sub Main xsh.Screen.WaitForString(&amp;#34;请选择资源编号：&amp;#34;) xsh.Screen.Send(&amp;#34;i&amp;#34;) xsh.Screen.Send(VbCr) xsh.Screen.WaitForString(&amp;#34;请输入IP地址：&amp;#34;) xsh.Screen.Send(&amp;#34;10.213.30.1&amp;#34;) xsh.Screen.Send(VbCr) xsh.Screen.WaitForString(&amp;#34;请选择资源编号：&amp;#34;) xsh.Screen.Send(&amp;#34;4&amp;#34;) xsh.Screen.Send(VbCr) xsh.Screen.WaitForString(&amp;#34;需自学习从账号请按回车鍵继续：&amp;#34;) xsh.Screen.Send(VbCr) xsh.Screen.WaitForString(&amp;#34;请输入资源从账号：&amp;#34;) xsh.Screen.Send(&amp;#34;root&amp;#34;) xsh.Screen.Send(VbCr) xsh.Screen.WaitForString(&amp;#34;请输入从账号密码：&amp;#34;) xsh.Screen.Send(&amp;#34;!SgXmdz!4m&amp;#34;) xsh.Screen.Send(VbCr) End Sub 注意：若 vbs 无法识别中文，则将文件保存时，选择编码为ANSI。
python def Main(): xsh.Screen.WaitForString(&amp;#34;请选择资源编号：&amp;#34;) xsh.Screen.Send(&amp;#34;i\r&amp;#34;) xsh.Screen.Send(&amp;#34;\r&amp;#34;) xsh.Screen.WaitForString(&amp;#34;请输入IP地址：&amp;#34;) xsh.Screen.Send(&amp;#34;10.213.30.1&amp;#34;) xsh.Screen.Send(&amp;#34;\r&amp;#34;) xsh.Screen.WaitForString(&amp;#34;请选择资源编号：&amp;#34;) xsh.Screen.Send(&amp;#34;4&amp;#34;) xsh.Screen.Send(&amp;#34;\r&amp;#34;) xsh.Screen.WaitForString(&amp;#34;需自学习从账号请按回车鍵继续：&amp;#34;) xsh.Screen.Send(&amp;#34;\r&amp;#34;) xsh.Screen.WaitForString(&amp;#34;请输入资源从账号：&amp;#34;) xsh.Screen.Send(&amp;#34;root&amp;#34;) xsh.Screen.Send(&amp;#34;\r&amp;#34;) xsh.Screen.WaitForString(&amp;#34;请输入从账号密码：&amp;#34;) xsh.Screen.Send(&amp;#34;!SgXmdz!4m&amp;#34;) xsh.Screen.Send(&amp;#34;\r&amp;#34;)</description></item><item><title>Xshell+Xftp SSH隧道代理</title><link>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/X-Manager/Xshell+Xftp-SSH%E9%9A%A7%E9%81%93%E4%BB%A3%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/Terminal%E7%BB%88%E7%AB%AF/X-Manager/Xshell+Xftp-SSH%E9%9A%A7%E9%81%93%E4%BB%A3%E7%90%86/</guid><description>概述 出于安全考虑，公司的一组应用服务器仅允许特定 P 远程 SSH 访问，带来安全防护的同时也增加了进行 SSH 登录和 SFTP 上传维护的繁琐，在授权的 IP 服务器上搭建 VPN 作为跳板是一种解决方案，本文阐述的，是另一种更加简单的安全访问方式，主要是基于日常维护所使用的 Xshell 和 Xftp 工具来配置（这两个工具实在是太方便了）。
为了方便阐述，先上一张网络结构示意图，如下: 如上图所示，服务器组 C 仅允许授权的服务器 B 访问，计算机 A 无法直接访问维护服务器组 C，本文就是要通过 SSH 隧道代理配置，实现计算机 A 可以直接通过安全隧道代理访问服务器组 C。
1、打开 Xshell，新建管理维护机 A 到授权 IP 服务器 B 的正常连接。
配置此连接的登录帐号和密码，如下图： 点击左侧的“隧道”，在右侧点击“添加”，添加 SSH 隧道。 在“转移规则”配置窗口，选择 SOCKS4/5，侦听端口默认为 1080，如果此端口不可用，则需要修改。
确定后点击连接到代理服务器，连接后在下方的转移规则里如果出现下图所示的信息，则代理服务器配置成功完成。
2、在 Xshell 新建到服务器组 C 的连接
点击左侧的“代理”，在右侧点击代理服务器后的“浏览”按钮
在弹出的代理服务器设置窗口，输入名称（自己定义），类型选择“SOCKS5”，主机填写&amp;quot;localhost&amp;quot;，端口 1080（如果第一步配置时修改了端口，此处也需要对应一致）
点击确定后列表代理里会出现刚刚配置的代理
确定后返回刚才的连接窗口，在代理服务器下拉列表中选择刚才建立的代理
确定后，即可如同直连一样使用计算机 A 远程连接维护服务器组 C 了。
在此处配置成功之后，Xftp 无需配置，只需要在新建到服务器组 C 的连接属性里选择刚才建立的代理服务器即可。
xshell 通过堡垒机登录服务器 参考：原文链接</description></item><item><title>Zone 与 Domain</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/Zone-%E4%B8%8E-Domain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/Zone-%E4%B8%8E-Domain/</guid><description>Delegation(授权) Zone 是通过授权实现的，而授权，主要授予的就是 Domain 的管理权。
管理域的组织可以将域进一步划分成子域。每个子域都可以被授权给其他组织来管理，这意味着这些被授权的组织得负责维护子域中所有的数据。他们可以自由地 改变域中的数据，甚至将子域进一步划分成更多的子域，然后再授权给其他组织管理。父域仅仅保留指向子域数据来源的指针，这样父域便可将查询者引到该处。例如，stanford.edu 域被授权给在斯坦福大学的人，由他们负责管理校园网络。
比如，我想买一个域名 desistdaydream.com，我就需要去找管理 com 域的组织购买，我付给他们钱后，他们就给我授权，让我可以管理 desistdaydream.com 域。此时，该域的管理权则由我全权负责，而我还可以对 desistdaydream.com 域再次划分，比如 a.desistdaydream.com、b.desistdaydream.com、c.desistdaydream.com 等等，然后将这些域授权出去。
同时，我还可以只授权一个域，比如我只授权某人管理 a.b.desistdaydream.com 域，那么某人则无法将 a.b.desistdaydream.com 域再进行子域划分。
所以，授权就是指将管理子域的责任交给另一个组织的行为。
**zone **和 **domain **的区别
zone 是同 Delegation(授权) 联系在一起的，为了管理上的方便，我们把域的某部分授权出去让别人代为管理，这部分就是一个 zone 。为什么说是为了管理上的方便呢？因为这样一个很大的域就可以实现分散管理，而不是集中由一两台服务器来管理。而 zone 的划分就是通过 “授权机制”来实现的。这也是 设计 DNS 系统得初衷。 并不能说 domain 就比 zone 大，反过来也一样。例如 edu 域可以包含多个 zone ：berkeley.edu 、purdue.edu 。但 edu 也可以看成是根域 &amp;ldquo;.&amp;rdquo; 下的一个被授权出去的 zone ，它含有 berkeley.edu 、purdue.edu 等几个域。 域是以域名进行分界的，而 zone 是以授权范围来定界的。一个 zone 有可能跨域多个域名。例如 berkeley 域是所有以 berkeley.edu 结尾的域名空间；而 edu zone 可以包括 berkey 和 purdue 这两个域，都统一归 edu 这个 zone 管理。 一个域和一个 zone 可能具有相同的域名，但包含的节点却不同。例如使用了授权的域 Name Server 在加载数据时是以 zone 为单位，而不是以 Domain 为单位。 总结： domain 这是从逻辑上进行划分，体现域名的树性结构，根域、com 域、edu 域等；</description></item><item><title>按键精灵，后台脚本键盘代码对照一览！</title><link>https://desistdaydream.github.io/docs/12.AI/Automation/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5%E5%90%8E%E5%8F%B0%E8%84%9A%E6%9C%AC%E9%94%AE%E7%9B%98%E4%BB%A3%E7%A0%81%E5%AF%B9%E7%85%A7%E4%B8%80%E8%A7%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Automation/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5%E5%90%8E%E5%8F%B0%E8%84%9A%E6%9C%AC%E9%94%AE%E7%9B%98%E4%BB%A3%E7%A0%81%E5%AF%B9%E7%85%A7%E4%B8%80%E8%A7%88/</guid><description>按键精灵，后台脚本键盘代码对照一览！
104 键键盘按键码对照
★ 主键盘区
A → 65
B → 66
C → 67
D → 68
E → 69
F → 70
G → 71
H → 72
I → 73
J → 74
K → 75
L → 76
M → 77
N → 78
O → 79
P → 80
Q → 81
R → 82
S → 83
T → 84
U → 85
V → 86</description></item><item><title>按键精灵后台程序</title><link>https://desistdaydream.github.io/docs/12.AI/Automation/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5%E5%90%8E%E5%8F%B0%E7%A8%8B%E5%BA%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/12.AI/Automation/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5/%E6%8C%89%E9%94%AE%E7%B2%BE%E7%81%B5%E5%90%8E%E5%8F%B0%E7%A8%8B%E5%BA%8F/</guid><description>Hwnd = Plugin.Window.MousePoint() // 获得鼠标所在的窗口句柄
Rem xxx1 // 标记，从这里开始重 copy 复按“1”
Call Plugin.Bkgnd.KeyPress(Hwnd, 49) // 后台执行按“1”的操作
Delay 200 // 延时 200 毫秒（时间自己定）
Goto xxx1 // 回到标记处，重复执行
运行脚本前鼠标要在游戏的窗口里，运行之后可 zhidao 以最小化窗口</description></item><item><title>把喜马拉雅音频下载到电脑</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/%E6%8A%8A%E5%96%9C%E9%A9%AC%E6%8B%89%E9%9B%85%E9%9F%B3%E9%A2%91%E4%B8%8B%E8%BD%BD%E5%88%B0%E7%94%B5%E8%84%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/%E6%8A%8A%E5%96%9C%E9%A9%AC%E6%8B%89%E9%9B%85%E9%9F%B3%E9%A2%91%E4%B8%8B%E8%BD%BD%E5%88%B0%E7%94%B5%E8%84%91/</guid><description>原文：简书，【教程】如何把喜马拉雅音频下载到电脑
前段时间上下班都是在和别人拼车，一方面是为了节能减排，另一方面是为了节省自己的油费开支。
看起来一箭双雕的事情，其实不然，任何事情都有两面性，黑帽子思考让我考虑的更细致，和别人拼车时自己开车的话，在某些方面就要考虑到别人的需求，比如吃饭地点啊，出发时间啊，再细致一点的就是音频播放了，你不能只播放你想听的东西，不然，只顾着自己听，同伴会显得很尴尬的。
直到最近新换了岗位，上下班只能自己开车了，一箭双雕的美事没了，但黄帽思考不允许我这么悲观，自己开车的自由来了，自己可以合理的安排上下班驾驶的时间了。
开车时唯一解放的是自己的耳朵，那只好在音频上让自己吸收点新的营养了。鉴于自己的车子相对比较 low，连车载蓝牙都没有，aux 线虽然有但还是觉得不怎么实用，买个蓝牙转接器又太丑，于是就想到了在喜马拉雅平台下载 MP3 音频来给自己充充电。
以上看起来是废话，但却是能够判断出来你到底需不需要看这篇文章，如果对于上面的废话你没有感同身受的话，我想你也不需要在这篇文章里浪费多少时间了，出门随便往哪儿拐。另外，这篇文章只适合与技术小白。 下面是正文：
这是一篇教你如何将喜马拉雅上的音频下载到电脑上转换成 MP3 格式的教程，付费的要想下载，你得先付费。
这篇文章的三种方法结构图
如图所示，这篇教程有三种下载方式，前面两种可以应付简单的网页音频的下载，但喜马拉雅有个特点，就算付过费的内容你也只能在手机 app 上下载听，这个就很有局限性，比如你手机在导航的时候，边听音频边听导航声音是件很恼人的事情，当然你有两个手机是最方便的。付费的在网页上根本就没有播放权限，前两种方法就被 pass 掉了，这个时候就需要第三种方法了，具体操作方法请看下文：
1、首先你电脑里得有个谷歌浏览器对吧，没有也没关系，这里给你个下载链接：谷歌浏览器官方下载
2、下载好之后，在谷歌浏览器里面打开喜马拉雅官方网站，找到你想下载的音频，拿《吴晓波频道》举例来说：
打开网页之后，在任意空白处右键单击鼠标键就会出现下面这个页面的情况，然后左键单击 “检查”
第一步
3、接下来注意选择 “Network” 栏目下面的“Media”。此时没有音频没有播放的话，你看到的就是下图所示情况；
第二步
4、接着点击想要下载的音频，在网页上播放，播放成功后就会出现下面这个页面的情况，注意对比与上一张图的不同；
第三步
5、这个时候选中红色标记框里面的选项，单击鼠标右键，在菜单里面选择最后一项，如下图所示：
第四步
6、接着就会进入到最后一个页面，直接点击下载按钮就可以了，这是从网页下载到电脑的最后一步；
第五步
7、到了这一步就可以在电脑上看到下载的音频文件了，不过，这里的音频是. m4a 格式的，想要 MP3 格式的需要进一步格式转换。
文件夹
1、同上面一种一样，首先得有个 360 浏览器在你电脑上：360 浏览器官方下载
2、下载好之后，在谷歌浏览器里面打开喜马拉雅官方网站，找到你想下载的音频，拿《新东方俞敏洪》栏目举例来说：
第一步
3、在浏览器右上角的扩展程序处点击上图所示的图标，页面自然就会进入上图的画面，然后找到”fvd download“扩展程序，点击安装；
第二步
4、刚下载好这个扩展程序的时候，这个图标是灰色状态的，这个时候是因为网页上没有可以下载的多媒体文件，如上图所示；
第三步
5、此时打开喜马拉雅官网，找到想要下载的音频，点击播放按钮，当网页上面有播放的多媒体时，右上角的扩展程序图标就变成蓝色了，然后就可以点击下载了，如上图所示；
第四步
6、点击扩展程序之后便会跳出上图的页面，点击下载即可；
文件夹
7、最后下载成功后，找到文件夹里面的文件，格式也是. m4a 格式的，这个时候仍然需要一个格式转换的步骤去转成 MP3 格式的。
上面这两种方法就可以完美的解决从喜马拉雅官网上下载音频到电脑了，但是，喜马拉雅付费内容，就算你花钱买了，在网页上也是不能播放的，只能在 app 上才可以播放和下载，如下图：
付费提醒
这怎么办呢，想听付费内容？前提你得付费才行哈！然后再用下面这个方法。
1、当然你的电脑得是 windows10 系统版本才可以走这一步，然后到应用商店去下载” 喜马拉雅 “的 app；</description></item><item><title>编译 kubeadm 修改证书过期时间</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%AF%91-kubeadm-%E4%BF%AE%E6%94%B9%E8%AF%81%E4%B9%A6%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%AF%91-kubeadm-%E4%BF%AE%E6%94%B9%E8%AF%81%E4%B9%A6%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4/</guid><description>Makefile 文件位置：https://github.com/kubernetes/kubernetes/blob/master/build/root/Makefile
这里以 kubernetes 1.18.8 为例。
安装golang, 这里使用v1.13.15
根据上步版本下载源码，下列下载方式任选其一
git clone --branch v1.19.2 https://github.com/kubernetes/kubernetes.git wget https://github.com/kubernetes/kubernetes/archive/v1.19.0.tar.gz 修改 ca 证书的有效期
# 将 const duration365d = time.Hour * 24 * 365 改为 const duration365d = time.Hour * 24 * 365 * 10 sed -i &amp;#39;s/\(const duration365d.*365\)/\1* 10/&amp;#39; staging/src/k8s.io/client-go/util/cert/cert.go 修改 ca 生成的其余证书的有效期
cat cmd/kubeadm/app/util/pkiutil/pki_helpers.go # 找到代码NotAfter: time.Now().Add(kubeadmconstants.CertificateValidity).UTC(), # 根据 import 部分找到调用该变量的文件 import ( ...... kubeadmconstants &amp;#34;k8s.io/kubernetes/cmd/kubeadm/app/constants&amp;#34; ...... ) vim cmd/kubeadm/app/constants/constants.go # 将 CertificateValidity = time.</description></item><item><title>并发控制</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</guid><description>概述 参考：
Go 包，标准库-context Go 包，标准库-sync-WaitGroup 类型 https://blog.wu-boy.com/2020/05/understant-golang-context-in-10-minutes/ context 是在Go 语言1.7 版才正式被纳入官方标准库内，为什么今天要介绍 context 使用方式呢？原因很简单，在初学 Go 时，写 API 时，常常不时就会看到在 http handler 的第一个参数就会是ctx context.Context，而这个 context 在这边使用的目的及含义到底是什么呢，本篇就是带大家了解什么是 context，以及使用的场景及方式，内容不会提到 context 的原始码，而是用几个实际例子来了解。
如果对于课程内容有兴趣，可以参考底下课程。
Go 语言基础实战(开发, 测试及部署) 一天学会 DevOps 自动化测试及部署 DOCKER 容器开发部署实战(课程刚启动，限时特价$900 TWD) 如果需要搭配购买请直接透过FB 联络我，直接汇款（价格再减100）
使用 WaitGroup 学 Go 时肯定要学习如何使用并发(goroutine)，而开发者该如何控制并发呢？其实有两种方式，一种是WaitGroup，另一种就是 context，而什么时候需要用到 WaitGroup 呢？很简单，就是当我们需要将同一件事情拆成不同的 Job 下去执行，最后需要等到全部的 Job 都执行完毕才继续执行主程式，这时候就需要用到 WaitGroup，看个实际例子
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) func main() { var wg sync.WaitGroup wg.Add(2) go func() { time.</description></item><item><title>并发问题</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Goroutine-AND-Channel/%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98/</guid><description>概述 常见并发报错：
fatal error:concurrent map read and map write Go 并发操作变量 常见错误使用 goroutine func goroutineRun(values []int) { for value := range values { go value.test() } } func goroutineRun(values []int) { for value := range values { go func() { fmt.Println(value) }() } } 这两段代码实际上是遍历数组的所有变量。由于闭包只是绑定到这个 value 变量上，并没有被保存到 goroutine 栈中，所以以上代码极有可能运行的结构都输出为切片的最后一个元素。因为这样写会导致 for 循环结束后才执行 goroutine 多线程操作，这时候 v alue 值只指向了最后一个元素。这样的结果不是我们所希望的，而且还会产生并发的资源抢占冲突所以是非常不推荐这样写的。
解决方法 for val := range values { go func(val interface{}) { fmt.Println(val) }(val) } 在这里将 val 作为一个参数传入 goroutine 中，每个 val 都会被独立计算并保存到 goroutine 的栈中，从而得到预期的结果。 另一种方法是在循环内定义新的变量，由于在循环内定义的变量在循环遍历的过程中是不共享的，因此也可以达到同样的效果：</description></item><item><title>部署</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Cilium/%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Cilium/%E9%83%A8%E7%BD%B2/</guid><description>概述 参考：
官方文档 官方文档，系统要求 在不同的环境中部署 Cilium 的方式不同，官方现在支持多种环境
Creating a Sandbox environment(沙盒环境) Minikube、MicorK8S、K3S、Kind Self-Managed Kubernetes(自己管理的 Kubernetes 集群) 二进制 或者 kubeadm 安装的、红帽的 OpenShift Managed Kubernetes(托管的 Kubernetes) AWS 的 EKS、Google 的 GKE、Azure 的 AKS Installer Integrations(集成在某些 k8s 的安装工具中) Kops、Kubespray、Kubeadm、Rancer CNI Chaining(将 Cilium 集成在其他 CNI 中) Setting up Support for External Workloads (beta) 系统要求 Linux 内核 &amp;gt;= 4.9.17
自己管理的 Kubernetes 中部署 Cilium 参考：
官方文档，入门指南-安装-快速安装 官方文档，入门指南-安装-使用 Helm 安装 注意：官方从 master 分支中删除了用于部署 Cilium 的 manifests 文件，详见：这次 Commit</description></item><item><title>查找隐藏进程(设备中病毒)</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%9F%A5%E6%89%BE%E9%9A%90%E8%97%8F%E8%BF%9B%E7%A8%8B%E8%AE%BE%E5%A4%87%E4%B8%AD%E7%97%85%E6%AF%92/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E6%9F%A5%E6%89%BE%E9%9A%90%E8%97%8F%E8%BF%9B%E7%A8%8B%E8%AE%BE%E5%A4%87%E4%B8%AD%E7%97%85%E6%AF%92/</guid><description>上个星期，群里出现一个神秘的案例，他的服务器 CPU 使用率飙的老高，但是无论使用 top 命令，还是 pidstate 等其他命令都查不出是哪个进程占用的，感觉这个进程「神秘消失」了一样。
奈何，小林功力不够，我对自己认知也很明确，我承认案例我破不了。不过没关系，好在我朋友多，立马@出了轩辕，轩辕（公众号：编程技术宇宙）是专门搞网络安全的，果然他一进场，就在偷笑，因为我给他送素材来了。。。
来，接下来我们就把这个「病毒式」的进程给扒出来。
CPU 起飞了 服务器的 CPU 一直处于高占用状态，但用top、ps等命令却一直找不到是哪个进程在占用，怀疑中了挖矿病毒，急的团团转。 根据经验，我赶紧让他看一下当前服务器的网络连接，看看有没有可疑连接，果然发现了有点东西：
上Shodan查一下这 IP 地址：
反向查找，发现有诸多域名曾经解析到这个 IP 地址：
这是一个位于德国的 IP 地址，开放了4444,5555,7777等数个特殊的服务端口：
其中这位朋友服务器上发现的连接到的是 7777 端口，钟馗之眼显示，这是一个 HTTP 服务的端口，直接访问返回的信息如下：
mining pool!，服务器正在挖矿实锤了！
但神奇的是，这个进程像是隐身了一般，找不到存在的任何痕迹。
进程如何隐藏 现在说回到本文的正题：Linux 操作系统上，进程要隐藏起来，有哪些招数？
要回答这个问题，先来知道 ps、top 等命令枚举系统的进程列表的原理。
Linux 的设计哲学是：一切皆文件！
进程也不例外， Linux 系统中有一个特殊的目录：/proc/，这个目录下的内容，不是硬盘上的文件系统，而是操作系统内核暴露出的内核中进程、线程相关的数据接口，也就是procfs，里面记录了系统上正在运行的进程和线程信息，来查看一下：
这些以数字命名的目录，就是一个进程的 PID，里面记录了该进程的详细信息。
而 ps、top 等命令的工作原理，实质上就是遍历这个目录。
知道了原理，想实现隐藏就有以下几个思路：
命令替换 直接替换系统中的 ps、top 命令工具。可以从 GitHub 上下载它们的源码，加入对应的过滤逻辑，在遍历进程的时候，剔除挖矿进程，实现隐藏的目的。
模块注入 编写一个动态链接库 so 文件，在 so 中，HOOK 遍历相关的函数（readdir/readdir64），遍历的时候，过滤挖矿进程。
通过修改LD_PRELOAD环境变量或/etc/ld.so.preload 文件，配置动态链接库，实现将其注入到目标进程中。
内核级隐藏 模块注入的方式是在应用层执行函数 HOOK，隐藏挖矿进程，更进一步，可以通过加载驱动程序的方式在内核空间 HOOK 相应的系统调用来实现隐藏。不过这对攻击者的技术要求也更高，遇到这样的病毒清理起来挑战也更大了。
揪出挖矿进程 通过上面的进程隐藏原理看得住来，都是想尽办法隐藏/proc 目录下的内容，类似于“障眼法”，所以包含ps、top、ls等等在内的命令，都没办法看到挖矿进程的存在。</description></item><item><title>常见 TCP 端口号</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/%E5%B8%B8%E8%A7%81-TCP-%E7%AB%AF%E5%8F%A3%E5%8F%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/%E5%B8%B8%E8%A7%81-TCP-%E7%AB%AF%E5%8F%A3%E5%8F%B7/</guid><description>Socket 网络端口含义 参考：
Wiki, TCP 与 UDP 端口号列表 IANA，分配-服务名和端口号注册列表 分类情况：
WellKnownPorts(公认端口) 从 0 到 1023，它们紧密绑定（binding）于一些服务。通常这些端口的通讯明确表明了某种服务的协议。这些端口由 IANA 分配管理，IANA(The Internet Assigned Numbers Authority，互联网数字分配机构)是负责协调一些使 Internet 正常运作的机构 RegisteredPorts(注册端口) 从 1024 到 49151。是公司和其他用户向互联网名称与数字地址分配机构（ICANN）登记的端口号，利用因特网的传输控制协议（TCP）和用户数据报协议（UDP）进行通信的应用软件需要使用这些端口。在大多数情况下，这些应用软件和普通程序一样可以被非特权用户打开。 Dynamicand/orPrivatePorts(动态和/或私有端口) 从 49152 到 65535。这类端口号仅在客户进程运行时才动态选择，因此又叫做短暂端口号。被保留给客户端进程选择暂时使用的。也可以理解为，客户端启动的时候操作系统随机分配一个端口用来和服务器通信，客户端进程关闭下次打开时，又重新分配一个新的端口。 TCP/UDP 端口列表 计算机之间依照互联网传输层TCP/IP 协议的协议通信，不同的协议都对应不同的端口。并且，利用数据报文的UDP也不一定和TCP采用相同的端口号码。以下为两种通信协议的端口列表链接
众所周知的端口 0 到 1023 号端口
0 到 1023（0 到 2^10 − 1）范围内的端口号是众所周知的端口或系统端口。 它们由提供广泛使用的网络服务类型的系统进程使用。在类 Unix 操作系统上，进程必须以超级用户权限执行才能使用众所周知的端口之一将网络套接字绑定到 IP 地址。
以下列表仅列出常用端口，详细的列表请参阅 IANA 网站。
注册端口 https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers#Registered_ports
1024 - 49151 号端口
从1024 到 49151 (210到214 215-1) 的端口号范围是注册的端口。IANA在请求实体申请时将它们分配给特定服务。[2] 在大多数系统上，注册端口可以在没有超级用户特权的情况下使用。</description></item><item><title>常见问题排查与解决方案</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid><description>原文链接：https://mp.weixin.qq.com/s/URU5jz8oFi-jQhWR4snGWQ https://kubesphere.com.cn/forum/d/5152-kubernetes
XXX:10250 connect: no route to host 网络问题，API Server 与 Kubelet 通信失败，将会导致很多很多问题
CRD spec.versions: Invalid value 原因: CRD yaml 文件中 apiVersion 与 versions 中的版本不对应 参考: https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/
删除 namespaces 时 Terminating，无法强制删除且无法在该 ns 下创建对象 原因: ns 处于 terminating 时 hang 住了，使用 &amp;ndash;grace-period=0 &amp;ndash;force 强制删除也无效 解决: # 导出 K8s 访问密钥 echo $(kubectl config view &amp;ndash;raw -oyaml | grep client-cert |cut -d &amp;rsquo; &amp;rsquo; -f 6) |base64 -d &amp;gt; /tmp/client.pem echo $(kubectl config view &amp;ndash;raw -oyaml | grep client-key-data |cut -d &amp;rsquo; &amp;rsquo; -f 6 ) |base64 -d &amp;gt; /tmp/client-key.</description></item><item><title>常用编程技巧</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/%E5%B8%B8%E7%94%A8%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/%E5%B8%B8%E7%94%A8%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/</guid><description>概述 参考：
B 站，【JavaScript】前端超有用的 10 个 JS 工具函数 防抖与节流 本质上是优化高频率执行代码的一种手段
如：浏览器的 resize、scroll、keypress、mousemove 等事件在触发时，会不断地调用绑定在事件上的回调函数，极大地浪费资源，降低前端性能
为了优化体验，需要对这类事件进行调用次数的限制，对此我们就可以采用 防抖（debounce） 和 节流（throttle） 的方式来减少调用频率
定义 节流: n 秒内只运行一次，若在 n 秒内重复触发，只有一次生效 防抖: n 秒后在执行该事件，若在 n 秒内被重复触发，则重新计时 一个经典的比喻:
想象每天上班大厦底下的电梯。把电梯完成一次运送，类比为一次函数的执行和响应
假设电梯有两种运行策略 debounce 和 throttle，超时设定为 15 秒，不考虑容量限制
电梯第一个人进来后，15 秒后准时运送一次，这是节流
电梯第一个人进来后，等待 15 秒。如果过程中又有人进来，15 秒等待重新计时，直到 15 秒后开始运送，这是防抖
大小写转换 数组中对象类型的元素去重 校验数据类型 滚动到页面顶部 滚动到对应元素的位置 获取当前时间 获取当月的第一天和最后一天 模糊查询</description></item><item><title>常用指标</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/%E5%B8%B8%E7%94%A8%E6%8C%87%E6%A0%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%9B%91%E6%8E%A7/%E5%B8%B8%E7%94%A8%E6%8C%87%E6%A0%87/</guid><description>Prometheus Operator 安装完成后会有很多默认的监控指标，一不注意就大量的报警产生，所以我们非常有必要了解下这些常用的监控指标，有部分指标很有可能对于我们自己的业务可有可无，所以可以适当的进行修改，这里我们就来对常用的几个指标进行简单的说明。
Kubernetes 资源相关 CPUThrottlingHigh sum(increase(container_cpu_cfs_throttled_periods_total{container!=&amp;#34;&amp;#34;, }[5m])) by (container, pod, namespace) / sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace) &amp;gt; ( 25 / 100 ) sum(increase(container_cpu_cfs_throttled_periods_total{container!=&amp;quot;&amp;quot;, }[5m])) by (container, pod, namespace) / sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace) &amp;gt; ( 25 / 100 )
关于 CPU 的 limit 合理性指标。查出最近 5 分钟，超过 25%的 CPU 执行周期受到限制的容器。表达式：
相关指标：
container_cpu_cfs_periods_total：容器生命周期中度过的 cpu 周期总数 container_cpu_cfs_throttled_periods_total：容器生命周期中度过的受限的 cpu 周期总数 Note：比如我设置一个 pod 的 cpu limit 为 2，当这个容器的进程申请 3 个 CPU 核心的用量，就会触发这个告警。</description></item><item><title>程序员的酒后真言</title><link>https://desistdaydream.github.io/blog/copy/s_QacAHM9ELc9_jkrxL2cw/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/s_QacAHM9ELc9_jkrxL2cw/</guid><description>原文链接：https://mp.weixin.qq.com/s/s_QacAHM9ELc9_jkrxL2cw
美国最大的论坛 Reddit，最近有一个热帖[1]。 一个程序员说自己喝醉了，软件工程师已经当了 10 年，心里有好多话想说，“我可能会后悔今天说了这些话。”
他洋洋洒洒写了一大堆，获得 9700 多个赞。内容很有意思，值得一读，下面是节选。 （1）职业发展的最好方法是换公司。
（2）技术栈不重要。技术领域有大约 10-20 条核心原则，重要的是这些原则，技术栈只是落实它们的方法。你如果不熟悉某个技术栈，不需要过度担心。
（3）工作和人际关系是两回事。有一些公司，我交到了好朋友，但是工作得并不开心；另一些公司，我没有与任何同事建立友谊，但是工作得很开心。
（4）我总是对经理实话实说。怕什么？他开除我？我会在两周内找到一份新工作。
（5）如果一家公司的工程师超过 100 人，它的期权可能在未来十年内变得很有价值。对于工程师人数很少的公司，期权一般都是毫无价值。
（6）好的代码是初级工程师可以理解的代码。伟大的代码可以被第一年的 CS 专业的新生理解。
（7）作为一名工程师，最被低估的技能是记录。说真的，如果有人可以教我怎么写文档，我会付钱，也许是 1000 美元。
（8）网上的口水战，几乎都无关紧要，别去参与。
（9）如果我发现自己是公司里面最厉害的工程师，那就该离开了。
（10）我们应该雇佣更多的实习生，他们很棒。那些精力充沛的小家伙用他们的想法乱搞。如果他们公开质疑或批评某事，那就更好了。我喜欢实习生。
（11）技术栈很重要。如果你使用 Python 或 C++ 语言，就会忍不住想做一些非常不同的事情。因为某些工具确实擅长某些工作。
（12）如果你不确定自己想做什么东西，请使用 Java。这是一种糟糕的编程语言，但几乎无所不能。
（13）对于初学者来说，最赚钱的编程语言是 SQL，干翻所有其他语言。你只了解 SQL 而不会做其他事情，照样赚钱。人力资源专家的年薪？也许 5 万美元。懂 SQL 的人力资源专家？9 万美元。
（14）测试很重要，但 TDD （测试驱动的开发）几乎变成了一个邪教。
（15） 政府单位很轻松，但并不像人们说的那样好。对于职业生涯早期到中期的工程师，12 万美元的年薪 + 各种福利 + 养老金听起来不错，但是你将被禁锢在深奥的专用工具里面，离开政府单位以后，这些知识就没用了。我非常尊重政府工作人员，但说真的，这些地方的工程师，年龄中位数在 50 岁以上是有原因的。
（16）再倒一杯酒。
（17）大多数头衔都无关紧要，随便什么公司都可以有首席工程师。
（18）手腕和背部的健康问题可不是开玩笑的，好的设备值得花钱。
（19）当一个软件工程师，最好的事情是什么？你可以结识很多想法相同的人，大家互相交流，不一定有相同的兴趣，但是对方会用跟你相同的方式思考问题，这很酷。
（20）有些技术太流行，我不得不用它。我心里就会很讨厌这种技术，但会把它推荐给客户，比如我恨 Jenkins，但把它推荐给新客户，我不觉得做错了。
（21）成为一名优秀的工程师意味着了解最佳实践，成为高级工程师意味着知道何时打破最佳实践。
（22）发生事故时，如果周围的人试图将责任归咎于外部错误或底层服务中断，那么是时候离开这家公司，继续前进了。
（23）我遇到的最好的领导，同意我的一部分观点，同时耐心跟我解释，为什么不同意我的另一部分观点。我正在努力成为像他们一样的人。
（24）算法和数据结构确实重要，但不应该无限夸大，尤其是面试的时候。我没见过药剂师面试时，还要测试有机化学的细节。这个行业的面试过程有时候很糟糕。
（25）做自己喜欢的事情并不重要，不要让我做讨厌的事情更重要。
（26）越接近产品，就越接近推动收入增长。无论工作的技术性如何，只要它接近产品，我都感到越有价值。
（27）即使我平时用 Windows 工作，Linux 也很重要。为什么？因为服务器是 Linux 系统，你最终在 Linux 系统上工作。</description></item><item><title>程序员应如何理解内存：上篇</title><link>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%8A%E7%AF%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%8A%E7%AF%87/</guid><description>https://mp.weixin.qq.com/s/U7F5LyzZ07KVOFYJF74LtQ 本节是操作系统系列教程的第三篇文章，属于操作系统第一章即基础篇，在真正开始操作系统相关章节前在这一部分回顾一些重要的主题，算是温故知新吧，以下是目录，由于本文篇幅较多因此接下来会分三次发布，目录中黑体为本篇内容。
什么是内存
C/C++ 内存模型
堆区与栈区的本质
Java、Python 等内存模型
Java 内存模型
Jave 中的堆区与栈区是如何实现的
Python 内存模型
指针与引用
进程的内存模型
幻想大师 - 操作系统
总结
什么是内存 0 和 1 这两个简单的数字能做什么？在其它学科中也许什么都做不了，但是在计算机科学中这就是全部。精彩纷呈的计算机世界正是构筑在这样两个简单数字之上。
内存本身其实非常简单，内存的作用就是用来装数字 0 和数字 1 的，如图所示，图中的一个盒子就是内存的一个基本单元，装的不是 0 就是装的 1。
内存由一大堆的 “盒子” 组成，每个盒子中要么是 0 要么是 1，其中 8 个盒子被称之为一个“字节”，每 8 个盒子也就是一个字节都有一个编号，这些编号就是简单的从 0 开始依次累加的，这个编号就被称之为“内存地址”。如图所示，你可以把内存理解为下面这张图，其中左边的数字是内存地址，每一排是一个字节，图中展示的就是一个 8 字节大小的内存。
而对于我们平时使用的比如 2G、4G 甚至 8G 大小的内存来说，只不过就是 “盒子” 多一点能装的 01 多一点而已，本质上和我们在这里展示的 8 字节大小的内存没有任何区别。
在后面的章节中我将用右图来表示内存，但是你的大脑里一定要有左图这样一个概念。当计算机在执行我们的程序时，无论是我们的机器指令还是机器指令操作的数据，都需要存放在这些小盒子中 (内存)。
以上就是从硬件角度来看内存，那么从编程语言上来看，程序员应该如何理解内存呢？
C/C++ 内存模型 对于 C/C++ 程序员来说，常用的 int，char 等变量都被装在盒子中，char 值只需要一排盒子就能装下 (8bit)，一个 int 值一般需要四排盒子才能装得下。连续几排装有同样类型变量的盒子就是数组 (array)，连续几排装有不同类型变量的盒子就是结构体 (struct)，C/C++ 语言中不管多么复杂的数据结构都是在此基础上构建出来的，都需要装在这些盒子里，没什么大不了的。</description></item><item><title>程序员应如何理解内存：下篇</title><link>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%8B%E7%AF%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%8B%E7%AF%87/</guid><description>https://mp.weixin.qq.com/s/Uu8z7GIiPnrfRhDTj93UZQ 本节是操作系统系列教程的第三篇文章，属于操作系统第一章即基础篇，在真正开始操作系统相关章节前在这一部分回顾一些重要的主题，以下是目录，由于本文篇幅较多因此按上篇、中篇、下篇三次发布，目录中黑体为本篇内容，本文为该主题最后一篇。
什么是内存
C/C++ 内存模型
堆区与栈区的本质
Java、Python 等内存模型
Java 内存模型
Jave 中的堆区与栈区是如何实现的
Python 内存模型
指针与引用
进程的内存模型
幻想大师 - 操作系统
总结
指针与引用
在各种编程语言中我们应该经常听到两个词，那就是引用或者指针。这两个词都是和内存相关的，指针和引用的作用都是 “如何找到存放在内存上的数据”。
C/C++ 中有 “指针” 这样一个概念，而其它语言比如 Java、Python 有的只是 “引用” 这样一个概念。这两者有什么区别呢？我们打个比方你就能理解了。
“引用”就好比一个人的外号一样，就好有个程序员叫令狐冲，但是令狐冲同学在 A 公司的英文名可能是 “Tom”，在 B 公司中可能又叫“Jerry”，那么在 A 公司中你只需要喊一声“Tom” 就能找到令狐冲同学。
而 “指针” 强调的是位置，比如令狐冲在 A 公司的工位是“10 排第二个”，在 B 公司中的工位是“8 排第六个”，下班后回的位置在“中关村”。
这个例子当中的令狐冲同学就好比程序语言中的对象，令狐冲的各种外号就好比对象的引用，令狐冲当前所在的位置就好比对象的指针。
虽然通过 “引用” 和“指针”都能找到令狐冲同学，但是寻找的方式是不一样的。
只有 C/C++ 这样的编译型语言才会有 “指针” 这样一个概念，指的是当前的对象放在了内存中的哪个位置上了。在比如 Java、Python 等语言中只有 “引用” 这样一个概念。在 C/C++ 语言中，我们可以通过指针直接找到一个对象，因为你知道这个对象就在内存中指针所指向的位置，但在 Java、Python 等语言中，当你利用引用找到对象时基本上是冲着解释器喊一句“Hey，解释器，帮我找到令狐冲这个对象”，解释器通过记录查找到这个对象，注意解释器是知道对象在内存中的真正位置的，由于直接管理内存是一项非常繁琐容易出错的事情(C/C++ 程序员一定对此有深刻体会)，因此解释器就接手了对内存直接管理，Java、Python 等程序员是没有必要知道对象在内存中的真正位置的，没有指针也可以开心的写程序而且程序更加健壮，何乐不为呢，因此这些语言中是没有指针这样一个概念。
Sun 的一篇论文中提到了为什么 Java 里没有指针。</description></item><item><title>程序员应如何理解内存：中篇</title><link>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%AD%E7%AF%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BA%94%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%AD%E7%AF%87/</guid><description>https://mp.weixin.qq.com/s/x52e0aGl0fC1KhXhai6MPg 本节是操作系统系列教程的第三篇文章，属于操作系统第一章即基础篇，在真正开始操作系统相关章节前在这一部分回顾一些重要的主题，以下是目录，由于本文篇幅较多因此会按上篇、中篇、下篇三次发布，目录中黑体为本篇内容。
什么是内存
C/C++ 内存模型
堆区与栈区的本质
Java、Python 等内存模型
Java 内存模型
Jave 中的堆区与栈区是如何实现的
Python 内存模型
指针与引用
进程的内存模型
幻想大师 - 操作系统
总结
堆与栈的本质是什么 在编程语言中，堆区和栈区本质上都是内存，因此二者在本质上没有任何区别，只不过这两块内存的使用方式是不一样的。
在数据结构与算法中，我们也有堆和栈的概念，但那里指的不是内存，而是两种数据结构。
你可能会想，我们为什么要费尽心力的提出堆和栈这两个概念呢？之所以需要区分两种内存用法，根源在于：内存是有限的。
如果计算机内存是无限的，那么我们根本就不用这么麻烦的给内存划分两个区域，在其中的一个区域中这样使用内存，另一区域那样使用内存，这些都是不需要的。即使在今天 PC 内存普遍都在 8G、16G，这依然是不够的，因此我们需要合理的来安排内存的使用，堆和栈就是为达到这一目的而采用的技术。
你会发现栈其实是一种非常巧妙的内存使用方法。函数调用完成后，函数运行过程中占用的内存就会被释放掉，这样，只要程序员代码写的合理 (栈帧不至于过大)，那我们程序就可以一直运行下去，而不会出现内存不足的现象。程序员在栈区不需要担心内存分配释放问题，因为这一切都是自动进行的。而如果程序员想自己控制内存，那么可以选择在堆上进行内存分配。因此这里提供了两种选择，一种是 “自动的”，一种是 “手动的”，目的都是在合理使用内存的同时提供给程序员最大的灵活性。
堆和栈是计算机科学中很优秀的设计思想，这种设计思想充分的体现了计算机如何合理且灵活的使用有限资源。
堆区和栈区对 C/C++ 程序员来说就是实实在在的内存，而对于 Java、Python 等语言的程序员来说又该如何理解内存呢?
Java、Python 等内存模型 当 Java、Python 等语言的程序在执行时其解释器的内存布局同样如下图所示，我们之前讲过，解释器也是一个 C/C++ 程序，因此这里的代码段包含的是解释器的实现代码而不是 Java、Python 等代码，这一点大家一定要注意。
&amp;ldquo;C/C++ 程序员面对的是实实在在的物理内存，Java、Python 等程序面对的是解释器。&amp;rdquo;
C/C++ 分配内存是直接在物理内存中进行的，而 Java、Python 等程序是将内存分配请求交给解释器，解释器再去物理内存上进行分配。希望大家务必理解这一点。
Java、Python 等程序员是看不到如下图所示的内存布局的，因为这一切都是解释器才能看到的，解释器对 Java、Python 等程序员屏蔽了这些。Java、Python 等程序员也无需关心解释器的内存布局。
Java、Python 等程序的一大优点就是内存的自动化管理，而 C/C++ 程序员需要自己来管理从堆上分配的内存。内存管理这一项工作在 Java、Python 等程序中被解释器接管了，解释器的这项功能被称为 “垃圾回收器”。
在非 C/C++ 语言中，我们来看两个有代表性的语言，首先我们看一下 Java。</description></item><item><title>初识 Operator</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E5%88%9D%E8%AF%86-Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E5%88%9D%E8%AF%86-Operator/</guid><description>Kubebuilder 代码示例详见 GitHub 上我的 kubernetesAPI 仓库
本文我们将首先了解到 Operator 是什么，之后逐步了解到 Operator 的生态建设，Operator 的关键组件及其基本的工作原理。
介绍 基于 Kubernetes 平台，我们可以轻松的搭建一些简单的无状态应用，比如对于一些常见的 web apps 或是移动端后台程序，开发者甚至不用十分了解 Kubernetes 就可以利用 Deployment，Service 这些基本单元模型构建出自己的应用拓扑并暴露相应的服务。由于无状态应用的特性支持其在任意时刻进行部署、迁移、升级等操作，Kubernetes 现有的 ReplicaSets、Deployment、Services 等资源对象已经足够支撑起无状态应用对于自动扩缩容、实例间负载均衡等基本需求。
在管理简单的有状态应用时，我们可以利用社区原生的 StatefulSet 和 PV 模型来构建基础的应用拓扑，帮助实现相应的持久化存储，按顺序部署、顺序扩容、顺序滚动更新等特性。
而随着 Kubernetes 的蓬勃发展，在数据分析，机器学习等领域相继出现了一些场景更为复杂的分布式应用系统，也给社区和相关应用的开发运维人员提出了新的挑战：
不同场景下的分布式系统中通常维护了一套自身的模型定义规范，如何在 Kubernetes 平台中表达或兼容出应用原先的模型定义？
当应用系统发生扩缩容或升级时，如何保证当前已有实例服务的可用性？如何保证它们之间的可连通性？
如何去重新配置或定义复杂的分布式应用？是否需要大量的专业模板定义和复杂的命令操作？是否可以向无状态应用那样用一条 kubectl 命令就完成应用的更新？
如何备份和管理系统状态和应用数据？如何协调系统集群各成员间在不同生命周期的应用状态？
而所有的这些正是 Operator 希望解决的问题，本文我们将首先了解到 Operator 是什么，之后逐步了解到 Operator 的生态建设，Operator 的关键组件及其基本的工作原理，下面让我们来一探究竟吧。
初识 Operator 首先让我们一起来看下什么是 Operator 以及它的诞生和发展历程。
1. 什么是 Operator CoreOS 在 2016 年底提出了 Operator 的概念，当时的一段官方定义如下：
“An Operator represents human operational knowledge in software, to reliably manage an application.</description></item><item><title>创建高可用 Kubernetes 集群</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8-Kubernetes-%E9%9B%86%E7%BE%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B8%85%E7%90%86/%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8-Kubernetes-%E9%9B%86%E7%BE%A4/</guid><description>概述 参考：
官方文档，入门-生产环境-使用部署工具安装 Kubernetes-使用 kubeadm 引导集群-使用 kubeadm 创建高可用集群 https://kubernetes.io/docs/setup/independent/high-availability/ Kubeadm GitHub 项目,高科用性注意事项 keepalived 和 haproxy kube-vip kube-vip 官网 想要让 Kubernets 的 Master 可以高可用，本质上就是让 API Server 高可用，也就是为 API Server 创建负载均衡，通过 VIP 来访问 API Server。
有多种方式可以实现 Kubernetes Master 节点的高可用
在各个 Master 上负载均衡各个 Master Keepalived kube-vip 在每个 Node 上负载均衡各个 Master sealos 创建负载均衡 Keepalived 方式 官方推荐版本的 keepalived 的配置
/etc/keepalived/keepalived.conf 在所有主节点上创建以下配置文件： ! Configuration File for keepalived global_defs { router_id k8s-master-dr script_user root enable_script_security } vrrp_script check_apiserver { script &amp;#34;/etc/keepalived/check_apiserver.</description></item><item><title>磁盘与文件系统管理工具</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>概述 参考：
磁盘分区管理工具 Parted 参考：
GNU 官网-软件-parted Manual(手册)，parted(8) Parted 是一个 partition(分区) 操作程序，支持对 2T 以上硬盘的分区，支持 GTP 分区表，如果直接输入 parted 命令则进入 parted 工具，以交互式方式对 DEVICE 进行操作。
Parted 程序在 CentOS 和 Ubuntu 中都属于 parted 包，这个包中有两个程序，parted 与 partprobe
parted 程序可以在交互模式中运行，当 parted 运行在交互模式中时，对磁盘进行的操作，只有在执行 quit 命令后，才会将更新通知给 Linux 内核
Syntax(语法) parted [OPTIONS] [DEVICE [COMMAND [ARGUMENT&amp;hellip;]&amp;hellip;]]
OPTIONS
-a, &amp;ndash;align=[none|cyl|min|opt] # alignment for new partitions -l, &amp;ndash;list # 列出所有块设备上的分区布局，i.e.列出所有磁盘的分区 -m, &amp;ndash;machine # 与 -l 选项配合， 显示出机器可以解析的输出内容 -s, &amp;ndash;script # never prompts for user intervention COMMAND align-check &amp;lt;ALIGN-TYPE&amp;gt; &amp;lt;DEVICE&amp;gt; # 检查指定分区是否对齐</description></item><item><title>从配置文件入手寻找代码逻辑</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/Rule/%E4%BB%8E%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%85%A5%E6%89%8B%E5%AF%BB%E6%89%BE%E4%BB%A3%E7%A0%81%E9%80%BB%E8%BE%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-Development/Rule/%E4%BB%8E%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%85%A5%E6%89%8B%E5%AF%BB%E6%89%BE%E4%BB%A3%E7%A0%81%E9%80%BB%E8%BE%91/</guid><description>告警通知逻辑解析 解析起因：告警在触发后，每隔一定时间，就会重新发送一次，在 rule 配置文件的 interval 字段是配置的其中一个，但是通过抓包分析，应该还有另一个参数的时间，与之相加，才是总体的告警重发送间隔
首先找到 interval 字段的配置，由于该字段的默认值是 PrometheusServer 配置文件中的 .global.evaluation_interval 字段的值，所以从此处开始找起。
配置文件及其关联的结构体 在 ./config/config.go 文件中，找到了与该配置关联的结构体
// ./config/config.go type GlobalConfig struct { // 其他结构体中的属性省略 // How frequently to evaluate rules by default. EvaluationInterval model.Duration `yaml:&amp;#34;evaluation_interval,omitempty&amp;#34;` } 通过查找引用，找到引用该属性的位置
为什么我就确定是这里呢？因为 main.go 文件中的另俩个引用是这样的：
// ./cmdg/prometheus/main.go noStepSubqueryInterval.Set(config.DefaultGlobalConfig.EvaluationInterval) // ./cmd/prometheus/main.go noStepSuqueryInterval.Set(conf.GlobalConfig.EvaluationInterval) 而该属性在 config.go 文件中的调用是用来确定该字段的值的。比如，如果配置文件没有该字段，则默认 如何如何
所以，EvaluationInterval 真正被使用的地方，应该就是 Updata() 方法中的调用
找到使用该配置的函数 接下来跳转过来，这是一个作用在 ruleManager 上的 Update() 方法，第一个参数就是评估间隔
// ./cmd/prometheus/main.go return ruleManager.Update( time.Duration(cfg.GlobalConfig.EvaluationInterval), // 评估间隔 files, cfg.GlobalConfig.ExternalLabels, ) 接下来查看 Update() 的逻辑，重点是 LoadGroups() 方法，使用到了 评估间隔 ，就是该方法的第一个参数 interval。</description></item><item><title>存储的基础设施架构</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/</guid><description>概述 参考：
简书 知乎原文 随着企业网络应用数据量的加大，企业已经感觉到存储容量和性能落后于网络应用发展需求。在这种应用条件下满足用户的存储需求的技术应运而生，DAS、NAS、SAN 三种存储架构成为当时主流的存储技术。
并且，在很长很长的一段时间里，这三种架构几乎统治了数据存储市场。所有行业用户的数据存储需求，都是在这三者中进行选择。然而，随着时代的发展，传统的存储开始暴露出他们的问题，价格昂贵、不易扩展、等等。这时 DS(分布式存储) 粉墨登场。
分布式存储 不但可以提供 DAS、NAS、SAN 三种架构可以提供的能力，比如 块存储 和 文件存储 能力，还可以提供一种新兴的 对象存储 的能力
存储架构分类 一、集中式存储又称为 传统的存储。从名字上可以看出来，就是把存储集中起来，统一管理。
Direct Attached Storage(直连式存储，简称 DAS) 基本都是商业解决方案，直接买硬件。其实，IDE、SATA、SCSI、SAS，甚至 USB，都可以算是 DAS。 Fabric Attached Storage(网络化存储) Network Attached Storage(网络附加存储，简称 NAS) 以 NFS 和 SMB 协议的实现程序为代表 Stoarge Area Network(存储区域网络，简称 SAN) 基本都是商业解决方案，直接买硬件 二、分布式存储 又称为 新型的存储。
中间控制节点架构 以 HDFS 为代表 完全无中心架构-计算模式 以 Ceph 为代表 完全无中心架构-一致性哈希 以 Swift 为代表 DAS 存储一般应用在中小企业，与计算机采用直连方式，NAS 存储则通过以太网添加到计算机上，SAN 存储则使用 FC 接口，提供性能更加的存储。NAS 与 SAN 的主要区别体现在操作系统在什么位置，如下图所示。 Direct-AttachedStorage(直连式存储，简称 DAS) 存储设备是通过电缆（通常是 SCSI 接口电缆）直接挂到服务器总线上。 DAS 方案中外接式存储设备目前主要是指 RAID、JBOD 等。 DAS 存储在我们生活中是非常常见的，尤其是在中小企业应用中，DAS 是最主要的应用模式，存储系统被直连到应用的服务器中，在中小企业中，许多的数据应用是必须安装在直连的 DAS 存储器上。</description></item><item><title>代码格式化</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/ECMAScript-%E5%B7%A5%E5%85%B7/%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%E5%8C%96/</guid><description>概述 参考：
Prettier 关联文件与配置 .prettierrc.json # 通常保存在项目根目录下
配置详解 tabWidth(INT) # 一个制表符相当于几个空格
semi(BOOLEAN) # 行尾是否添加分号
htmlWhitespaceSensitivity(STRING) # 使用 ignore 解决尖括号右侧被换行问题
bracketSameLine(BOOLEAN&amp;gt; # 不要给 ) 另起一行
&amp;#34;prettier.printWidth&amp;#34;: 100, // 超过最大值换行 &amp;#34;prettier.tabWidth&amp;#34;: 4, // 缩进字节数 &amp;#34;prettier.useTabs&amp;#34;: false, // 缩进不使用tab，使用空格 &amp;#34;prettier.semi&amp;#34;: true, // 句尾添加分号 &amp;#34;prettier.singleQuote&amp;#34;: true, // 使用单引号代替双引号 &amp;#34;prettier.proseWrap&amp;#34;: &amp;#34;preserve&amp;#34;, // 默认值。因为使用了一些折行敏感型的渲染器（如GitHub comment）而按照markdown文本样式进行折行 &amp;#34;prettier.arrowParens&amp;#34;: &amp;#34;avoid&amp;#34;, // (x) =&amp;gt; {} 箭头函数参数只有一个时是否要有小括号。avoid：省略括号 &amp;#34;prettier.bracketSpacing&amp;#34;: true, // 在对象，数组括号与文字之间加空格 &amp;#34;{ foo: bar }&amp;#34; &amp;#34;prettier.disableLanguages&amp;#34;: [&amp;#34;vue&amp;#34;], // 不格式化vue文件，vue文件的格式化单独设置 &amp;#34;prettier.endOfLine&amp;#34;: &amp;#34;auto&amp;#34;, // 结尾是 \n \r \n\r auto &amp;#34;prettier.</description></item><item><title>代码提交规范</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E4%BB%A3%E7%A0%81%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/Programming-technology/%E4%BB%A3%E7%A0%81%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/</guid><description>概述 参考：
GitHub 项目，conventional-commits/conventionalcommits.org https://www.conventionalcommits.org/zh-hans/v1.0.0/ 约定式提交规范是一种基于提交信息的轻量级约定。 它提供了一组简单规则来创建清晰的提交历史； 这更有利于编写自动化工具。 通过在提交信息中描述功能、修复和破坏性变更， 使这种惯例与 SemVer 相互对应。</description></item><item><title>当master丢失一个节点后，如何恢复</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%BD%93master%E4%B8%A2%E5%A4%B1%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E5%90%8E%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E5%BD%93master%E4%B8%A2%E5%A4%B1%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E5%90%8E%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/</guid><description>故障现象 在日常维护中，如果三台 master 节点的其中一个节点故障，并不可恢复，我们如何重新建建立一个 master 节点并重新加入进去呢？
假设曾经有三个节点
master-1.tj-test master-2.tj-test master-3.tj-test 其中一个节点丢失后，想要新建一个节点并重新加入集群，但是失败了
故障排查 当 master-3 挂掉并不可恢复时，首先需要通过 kubectl delete node master-3.tj-test 命令来删除该节点。然后使用一台新的设备初始化环境，并通过 kubeadm join 命令来加入集群，但是这时候，加入集群是失败的。
因为虽然使用命令删除了 master-3 节点，但是 etcd 集群的 master-3 这个 member 还存在
~]# etcdv3 member list 13b7460f0eebe6ea, started, master-1.tj-test, https://172.38.40.212:2380, https://172.38.40.212:2379 fdddf32d7b4d4498, started, master-3.tj-test, https://172.38.40.214:2380, https://172.38.40.214:2379 fed9f57af62ba6a0, started, master-2.tj-test, https://172.38.40.213:2380, https://172.38.40.213:2379 故障处理 这时候需要通过 etcdctl 命令 etcdv3 member remove fdddf32d7b4d4498 将该 member 移除，再重新让 master-3 加入集群，就可以了。</description></item><item><title>第三方库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%8A%A0%E5%AF%86%E4%B8%8E%E8%A7%A3%E5%AF%86/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/</guid><description>gorsa 项目地址：https://github.com/wenzhenxi/gorsa
gorsa 项目地址：https://github.com/wenzhenxi/gorsa package main import ( &amp;#34;log&amp;#34; &amp;#34;errors&amp;#34; &amp;#34;github.com/wenzhenxi/gorsa&amp;#34; ) var Pubkey = `-----BEGIN 公钥----- MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAk+89V7vpOj1rG6bTAKYM 56qmFLwNCBVDJ3MltVVtxVUUByqc5b6u909MmmrLBqS//PWC6zc3wZzU1+ayh8xb UAEZuA3EjlPHIaFIVIz04RaW10+1xnby/RQE23tDqsv9a2jv/axjE/27b62nzvCW eItu1kNQ3MGdcuqKjke+LKhQ7nWPRCOd/ffVqSuRvG0YfUEkOz/6UpsPr6vrI331 hWRB4DlYy8qFUmDsyvvExe4NjZWblXCqkEXRRAhi2SQRCl3teGuIHtDUxCskRIDi aMD+Qt2Yp+Vvbz6hUiqIWSIH1BoHJer/JOq2/O6X3cmuppU4AdVNgy8Bq236iXvr MQIDAQAB -----END 公钥----- ` var Pirvatekey = `-----BEGIN 私钥----- MIIEpAIBAAKCAQEAk+89V7vpOj1rG6bTAKYM56qmFLwNCBVDJ3MltVVtxVUUByqc 5b6u909MmmrLBqS//PWC6zc3wZzU1+ayh8xbUAEZuA3EjlPHIaFIVIz04RaW10+1 xnby/RQE23tDqsv9a2jv/axjE/27b62nzvCWeItu1kNQ3MGdcuqKjke+LKhQ7nWP RCOd/ffVqSuRvG0YfUEkOz/6UpsPr6vrI331hWRB4DlYy8qFUmDsyvvExe4NjZWb lXCqkEXRRAhi2SQRCl3teGuIHtDUxCskRIDiaMD+Qt2Yp+Vvbz6hUiqIWSIH1BoH Jer/JOq2/O6X3cmuppU4AdVNgy8Bq236iXvrMQIDAQABAoIBAQCCbxZvHMfvCeg+ YUD5+W63dMcq0QPMdLLZPbWpxMEclH8sMm5UQ2SRueGY5UBNg0WkC/R64BzRIS6p jkcrZQu95rp+heUgeM3C4SmdIwtmyzwEa8uiSY7Fhbkiq/Rly6aN5eB0kmJpZfa1 6S9kTszdTFNVp9TMUAo7IIE6IheT1x0WcX7aOWVqp9MDXBHV5T0Tvt8vFrPTldFg IuK45t3tr83tDcx53uC8cL5Ui8leWQjPh4BgdhJ3/MGTDWg+LW2vlAb4x+aLcDJM CH6Rcb1b8hs9iLTDkdVw9KirYQH5mbACXZyDEaqj1I2KamJIU2qDuTnKxNoc96HY 2XMuSndhAoGBAMPwJuPuZqioJfNyS99x++ZTcVVwGRAbEvTvh6jPSGA0k3cYKgWR NnssMkHBzZa0p3/NmSwWc7LiL8whEFUDAp2ntvfPVJ19Xvm71gNUyCQ/hojqIAXy tsNT1gBUTCMtFZmAkUsjqdM/hUnJMM9zH+w4lt5QM2y/YkCThoI65BVbAoGBAMFI GsIbnJDNhVap7HfWcYmGOlWgEEEchG6Uq6Lbai9T8c7xMSFc6DQiNMmQUAlgDaMV b6izPK4KGQaXMFt5h7hekZgkbxCKBd9xsLM72bWhM/nd/HkZdHQqrNAPFhY6/S8C IjRnRfdhsjBIA8K73yiUCsQlHAauGfPzdHET8ktjAoGAQdxeZi1DapuirhMUN9Zr kr8nkE1uz0AafiRpmC+cp2Hk05pWvapTAtIXTo0jWu38g3QLcYtWdqGa6WWPxNOP NIkkcmXJjmqO2yjtRg9gevazdSAlhXpRPpTWkSPEt+o2oXNa40PomK54UhYDhyeu akuXQsD4mCw4jXZJN0suUZMCgYAgzpBcKjulCH19fFI69RdIdJQqPIUFyEViT7Hi bsPTTLham+3u78oqLzQukmRDcx5ddCIDzIicMfKVf8whertivAqSfHytnf/pMW8A vUPy5G3iF5/nHj76CNRUbHsfQtv+wqnzoyPpHZgVQeQBhcoXJSm+qV3cdGjLU6OM HgqeaQKBgQCnmL5SX7GSAeB0rSNugPp2GezAQj0H4OCc8kNrHK8RUvXIU9B2zKA2 z/QUKFb1gIGcKxYr+LqQ25/+TGvINjuf6P3fVkHL0U8jOG0IqpPJXO3Vl9B8ewWL cFQVB/nQfmaMa4ChK0QEUe+Mqi++MwgYbRHx1lIOXEfUJO+PXrMekw== -----END 私钥----- ` func main() { // 公钥加密私钥解密 if err := applyPubEPriD(); err !</description></item><item><title>调度算法</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/</guid><description>概述 调度类型 由于任务有优先级之分，Linux 系统为了保障高优先级的任务能够尽可能早的被执行，于是分为了这几种调度类型，如下图：
Deadline 和 Realtime 调度类型，应用于实时任务。这两个调度类型的调度策略合起来共有这三种，它们的作用如下：
SCHED_DEADLINE：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度； SCHED_FIFO：对于相同优先级的任务，按先来先服务的原则，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」； SCHED_RR：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务； Fair 调度类型，应用于普通任务。都是由 CFS 调度器管理的，分为两种调度策略：
SCHED_NORMAL：普通任务使用的调度策略； SCHED_BATCH：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。 Deadline 调度器 RT 调度器 CFS 调度器 参考：
官方文档: https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt https://blog.csdn.net/dog250/article/details/95729830 https://blog.csdn.net/armlinuxww/article/details/97242063 https://www.jianshu.com/p/673c9e4817a8 https://zhuanlan.zhihu.com/p/83795639 https://blog.csdn.net/cloudvtech/article/details/107634785 CFS 调度器的前身是 O(1) 调度器
CFS 彻底抛弃了 时间片轮转 的策略，而是改之为 在任意的调度周期内公平分享 CPU 时间 的问题。
我们平日里遇到的基本都是普通任务，对于普通任务来说，公平性最重要，在 Linux 里面，实现了一个基于 CFS 的调度算法，也就是完全公平调度（Completely Fair Scheduling）。
Completely Fair Scheduler(完全公平的调度器，简称 CFS)。由 Ingo Molnar 实现并在 Linux Kernel 2.6.23 之后开始引入，并逐步替代老式的 (O)1 调度器。
CFS 使用 vruntime(虚拟运行时间) 的概念，来指定任务的下一个时间片何时开始在 CPU 上执行。</description></item><item><title>动手实验+源码分析，彻底弄懂 Linux 网络命名空间</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/Network-Namespace/%E5%8A%A8%E6%89%8B%E5%AE%9E%E9%AA%8C+%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%BD%BB%E5%BA%95%E5%BC%84%E6%87%82-Linux-%E7%BD%91%E7%BB%9C%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/1.Namespaces/Network-Namespace/%E5%8A%A8%E6%89%8B%E5%AE%9E%E9%AA%8C+%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%BD%BB%E5%BA%95%E5%BC%84%E6%87%82-Linux-%E7%BD%91%E7%BB%9C%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/</guid><description>动手实验 + 源码分析，彻底弄懂 Linux 网络命名空间
大家好，我是飞哥！
在 Linux 上通过 veth 我们可以创建出许多的虚拟设备。通过 Bridge 模拟以太网交换机的方式可以让这些网络设备之间进行通信。不过虚拟化中还有很重要的一步，那就是隔离。借用 Docker 的概念来说，那就是不能让 A 容器用到 B 容器的设备，甚至连看一眼都不可以。只有这样才能保证不同的容器之间复用硬件资源的同时，还不会影响其它容器的正常运行。
在 Linux 上实现隔离的技术手段就是 namespace。通过 namespace 可以隔离容器的进程 PID、文件系统挂载点、主机名等多种资源。不过我们今天重点要介绍的是网络 namespace，简称 netns。它可以为不同的命名空间从逻辑上提供独立的网络协议栈，具体包括网络设备、路由表、arp 表、iptables、以及套接字（socket）等。使得不同的网络空间就都好像运行在独立的网络中一样。
你是不是和飞哥一样，也很好奇 Linux 底层到底是如何实现网络隔离的？我们今天来好好挖一挖 netns 的内部实现。
一、如何使用 netns 由于我们平时的开发工作很少涉及网络空间，所以我们先来看一下网络空间是如何使用的吧。我们来创建一个新的命名空间 net1。再创建一对儿 veth，将 veth 的一头放到 net1 中。分别查看一下母机和 net1 空间内的 iptable、设备等。最后让两个命名空间之间进行通信。
下面是详细的使用过程。首先我们先来创建一个新的网络命名空间 - net1。
# ip netns add net1 来查看一下它的 iptable、路由表、以及网络设备
# ip netns exec net1 routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface# ip netns exec net1 iptables -Lip netns exec net1 iptables -LChain INPUT (policy ACCEPT)target prot opt source destination.</description></item><item><title>动态追踪</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Traces/%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Traces/%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/</guid><description>概述 参考：
Wiki, Tacking https://zhuanlan.zhihu.com/p/24124082 Dynamic Tracing(动态追踪)
DTrace DTrace 是动态追踪技术的鼻祖，源自 Solaris 操作系统</description></item><item><title>读写数据的方式</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E5%BC%8F/</guid><description>原文：小林的《你不好奇 CPU 是如何执行任务的？》
前言
你清楚下面这几个问题吗？
有了内存，为什么还需要 CPU Cache？ CPU 是怎么读写数据的？ 如何让 CPU 能读取数据更快一些？ CPU 伪共享是如何发生的？又该如何避免？ CPU 是如何调度任务的？如果你的任务对响应要求很高，你希望它总是能被先调度，这该怎么办？ … CPU 如何读写数据的？ 先来认识 CPU 的架构，只有理解了 CPU 的 架构，才能更好地理解 CPU 是如何读写数据的，对于现代 CPU 的架构图如下：
可以看到，一个 CPU 里通常会有多个 CPU 核心，比如上图中的 1 号和 2 号 CPU 核心，并且每个 CPU 核心都有自己的 L1 Cache 和 L2 Cache，而 L1 Cache 通常分为 dCache（数据缓存） 和 iCache（指令缓存），L3 Cache 则是多个核心共享的，这就是 CPU 典型的缓存层次。
上面提到的都是 CPU 内部的 Cache，放眼外部的话，还会有内存和硬盘，这些存储设备共同构成了金字塔存储层次。如下图所示：
从上图也可以看到，从上往下，存储设备的容量会越大，而访问速度会越慢。至于每个存储设备的访问延时，你可以看下图的表格：
你可以看到， CPU 访问 L1 Cache 速度比访问内存快 100 倍，这就是为什么 CPU 里会有 L1~L3 Cache 的原因，目的就是把 Cache 作为 CPU 与内存之间的缓存层，以减少对内存的访问频率。</description></item><item><title>堆区与栈区</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/%E5%A0%86%E5%8C%BA%E4%B8%8E%E6%A0%88%E5%8C%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/%E5%A0%86%E5%8C%BA%E4%B8%8E%E6%A0%88%E5%8C%BA/</guid><description>Heap(堆) 与 Stack(栈) 参考：
StackOverflow 公众号-码农的荒岛求生，程序员应如何理解内存：中篇 堆与栈的本质是什么 在编程语言中，堆区和栈区本质上都是内存，因此二者在本质上没有任何区别，只不过这两块内存的使用方式是不一样的。
在数据结构与算法中，我们也有堆和栈的概念，但那里指的不是内存，而是两种数据结构。
你可能会想，我们为什么要费尽心力的提出堆和栈这两个概念呢？之所以需要区分两种内存用法，根源在于：内存是有限的。
如果计算机内存是无限的，那么我们根本就不用这么麻烦的给内存划分两个区域，在其中的一个区域中这样使用内存，另一区域那样使用内存，这些都是不需要的。即使在今天 PC 内存普遍都在 8G、16G，这依然是不够的，因此我们需要合理的来安排内存的使用，堆和栈就是为达到这一目的而采用的技术。
你会发现栈其实是一种非常巧妙的内存使用方法。函数调用完成后，函数运行过程中占用的内存就会被释放掉，这样，只要程序员代码写的合理 (栈帧不至于过大)，那我们程序就可以一直运行下去，而不会出现内存不足的现象。程序员在栈区不需要担心内存分配释放问题，因为这一切都是自动进行的。而如果程序员想自己控制内存，那么可以选择在堆上进行内存分配。因此这里提供了两种选择，一种是 “自动的”，一种是 “手动的”，目的都是在合理使用内存的同时提供给程序员最大的灵活性。
堆和栈是计算机科学中很优秀的设计思想，这种设计思想充分的体现了计算机如何合理且灵活的使用有限资源。
堆区和栈区对 C/C++ 程序员来说就是实实在在的内存，而对于 Java、Python 等语言的程序员来说又该如何理解内存呢?
Rust 中的 Stack 与 Heap 参考：
英文 非官方中文 在很多语言中，你并不需要经常考虑到栈与堆。不过在像 Rust 这样的系统编程语言中，值是位于栈上还是堆上在更大程度上影响了语言的行为以及为何必须做出这样的抉择。我们会在本章的稍后部分描述所有权与栈和堆相关的内容，所以这里只是一个用来预热的简要解释。
栈和堆都是代码在运行时可供使用的内存，但是它们的结构不同。栈以放入值的顺序存储值并以相反顺序取出值。这也被称作 后进先出（last in, first out）。想象一下一叠盘子：当增加更多盘子时，把它们放在盘子堆的顶部，当需要盘子时，也从顶部拿走。不能从中间也不能从底部增加或拿走盘子！增加数据叫做 进栈（pushing onto the stack），而移出数据叫做 出栈（popping off the stack）。
栈中的所有数据都必须占用已知且固定的大小。在编译时大小未知或大小可能变化的数据，要改为存储在堆上。堆是缺乏组织的：当向堆放入数据时，你要请求一定大小的空间。操作系统在堆的某处找到一块足够大的空位，把它标记为已使用，并返回一个表示该位置地址的 指针（pointer）。这个过程称作 在堆上分配内存（allocating on the heap），有时简称为 “分配”（allocating）。将数据推入栈中并不被认为是分配。因为指针的大小是已知并且固定的，你可以将指针存储在栈上，不过当需要实际数据时，必须访问指针。
想象一下去餐馆就座吃饭。当进入时，你说明有几个人，餐馆员工会找到一个够大的空桌子并领你们过去。如果有人来迟了，他们也可以通过询问来找到你们坐在哪。
入栈比在堆上分配内存要快，因为（入栈时）操作系统无需为存储新数据去搜索内存空间；其位置总是在栈顶。相比之下，在堆上分配内存则需要更多的工作，这是因为操作系统必须首先找到一块足够存放数据的内存空间，并接着做一些记录为下一次分配做准备。
访问堆上的数据比访问栈上的数据慢，因为必须通过指针来访问。现代处理器在内存中跳转越少就越快（缓存）。继续类比，假设有一个服务员在餐厅里处理多个桌子的点菜。在一个桌子报完所有菜后再移动到下一个桌子是最有效率的。从桌子 A 听一个菜，接着桌子 B 听一个菜，然后再桌子 A，然后再桌子 B 这样的流程会更加缓慢。出于同样原因，处理器在处理的数据彼此较近的时候（比如在栈上）比较远的时候（比如可能在堆上）能更好的工作。在堆上分配大量的空间也可能消耗时间。
当你的代码调用一个函数时，传递给函数的值（包括可能指向堆上数据的指针）和函数的局部变量被压入栈中。当函数结束时，这些值被移出栈。
跟踪哪部分代码正在使用堆上的哪些数据，最大限度的减少堆上的重复数据的数量，以及清理堆上不再使用的数据确保不会耗尽空间，这些问题正是所有权系统要处理的。一旦理解了所有权，你就不需要经常考虑栈和堆了，不过明白了所有权的存在就是为了管理堆数据，能够帮助解释为什么所有权要以这种方式工作。
知乎文章 原文连接: https://zhuanlan.zhihu.com/p/58191270 - 已失效</description></item><item><title>对象存储，为什么那么火？</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E9%82%A3%E4%B9%88%E7%81%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E8%83%BD%E5%8A%9B/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E9%82%A3%E4%B9%88%E7%81%AB/</guid><description>参考：知乎原文
小枣君给大家详细介绍了数据存储技术的基本知识，其中重点对 DAS、SAN 和 NAS 技术进行了对比分析。
我们知道，在很长的一段时间里，这三种架构几乎统治了数据存储市场。所有行业用户的数据存储需求，都是在这三者中进行选择。
然而，随着时代的发展，一种新的数据存储形态诞生，开始挑战前面三者的垄断地位。
没错，它就是云计算时代存储技术的新网红——对象存储。(这里描述有问题，对象存储和 SAN、NAS、DAS 不是一个级别的，准确说，应该用 分布式存储与 这三个对比)
对象存储，也称为“面向对象的存储”，英文是 Object-based Storage。现在很多云厂商，也直接称之为“云存储”。
不同的云厂商对它有不同的英文缩写命名。例如阿里云把自家的对象存储服务叫做 OSS，华为云叫 OBS，腾讯云叫 COS，七牛叫 Kodo，百度叫 BOS，网易叫 NOS……五花八门，反正都是一个技术。
之前小枣君介绍过，DAS 和 SAN 是基于物理块的存储方式，而 NAS 是基于文件的存储方式。
在 DAS 和 SAN 中，存储资源就像一块一块的硬盘，直接挂载在主机上，我们称之为块存储。
而在 NAS 中，呈现出来的是一个基于文件系统的目录架构，有目录、子目录、孙目录、文件，我们称之为文件存储。
文件存储的最大特点，就是所有存储资源都是多级路径方式进行访问的。例如：
C:\Program Files (x86)\Tencent\WeChat\WeChat.exe \\NJUST-Server\学习资料\通信原理\第一章作业.doc 20 世纪末，随着互联网的爆发，数据存储需求发生了两个重大的变化。
第一，就是数据量爆炸式增长。
原因我就不用说了吧？大家可以瞅瞅自己的硬盘，都藏了些什么。
Web 应用的崛起、社交需求的刺激，极大地推动了多媒体内容的创作和分享。人们开始上传大量的照片、音乐、视频，加剧了数据量的爆发。
此外，信息技术的发展、企业数字化的落地，也产生了大量的数据，不断吞食着存储资源。
第二，是非结构化数据的占比显著增加。
什么是非结构化数据？
举个例子大家就明白了。我们经常做的 excel 表格，姓名、身高、体重、年龄、性别，这种用二维表结构可以进行逻辑表达的数据，就是结构化数据。
结构化数据
而图像、音频、视频、word 文章、演示胶片这样的数据，就是非结构化数据。
根据此前的预测，到 2020 年（也就是今年），全球数据总量的 80%，将是非结构化数据。
面对这两大趋势，因为本身技术和架构的限制，DAS、SAN 和 NAS 无法进行有效应对。
于是，专家们就搞出了对象存储。
虽然我们说对象存储是新网红，但实际上它诞生的时间并不算短。早在 1996 年，美国卡内基梅隆大学就将对象存储作为一个研究项目提出来。随后，加州大学伯克利分校也有推出类似的项目。
2002 年，Filepool 公司推出了基于内容可寻址技术的 Centera 系统，算是比较早期的对象存储系统。</description></item><item><title>对象的创建与修改命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BF%AE%E6%94%B9%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubectl-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BF%AE%E6%94%B9%E5%91%BD%E4%BB%A4/</guid><description>kubectl apply # 声明对象 通过文件或 STDIN(标准输入)声明配置到一个资源中，如果该资源不存在，则会根据所声明的内容自动创建。
有时候我们在使用 apply 应用一个对象时，会遇上类似如下的提示：
The CustomResourceDefinition &amp;#34;XXXXX&amp;#34; is invalid: metadata.annotations: Too long: must have at most 262144 bytes 一个 Manifests 文件太大导致无法 apply，才是就需要使用 replace 来修改对象。或者为 apply 子命令添加 --server-side 标志。
Syntax(语法) kubectl apply -f FILENAME [OPTIONS]
OPTIONS
&amp;ndash;record # 在资源注释中记录当前 kubectl 命令。 如果设置为 false，请不要记录该命令。 如果设置为 true，则记录该命令。 如果未设置，则默认仅在已存在的情况下更新现有注释值。 &amp;ndash;server-side # kubectl edit # 修改对象 kubectl edit (RESOURCE/NAME | -f FILENAME) [OPTIONS]
OPTIONS：
&amp;ndash;save-config=false|true # EXAMPLE
kubectl edit -n service kube-system kubernetes-dashboard kubectl replace # 替换。使用文件或标准输入替换一个资源 Syntax(语法) kubectl replace -f FILENAME [options]</description></item><item><title>多路径multipath</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%85%B6%E4%BB%96/%E5%A4%9A%E8%B7%AF%E5%BE%84multipath/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%85%B6%E4%BB%96/%E5%A4%9A%E8%B7%AF%E5%BE%84multipath/</guid><description>所需安装的组件：
device-mapper-multipath-libs-XXXX device-mapper-multipath-XXXX 配置说明详见官方文档：https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/dm_multipath/mpio_description
配置示例：
# This is a basic configuration file with some examples, for device mapper # multipath. # # For a complete list of the default configuration values, run either # multipath -t # or # multipathd show config # # For a list of configuration options with descriptions, see the multipath.conf # man page ## By default, devices with vendor = &amp;#34;IBM&amp;#34; and product = &amp;#34;S/390.*&amp;#34; are ## blacklisted.</description></item><item><title>二十年老程序员的二十条心得：面试几乎没用，警惕很久没写过代码的“大牛”</title><link>https://desistdaydream.github.io/blog/copy/bHdkIkWCNZPmO-Hz-HQreQ/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/bHdkIkWCNZPmO-Hz-HQreQ/</guid><description>原文链接：https://mp.weixin.qq.com/s/bHdkIkWCNZPmO-Hz-HQreQ
作者 | Justin Etheredge
译者 | 核子可乐
务必警惕那些已经很久没写过代码、也没设计过系统的所谓“大牛”。
站在巨人的肩膀上当然更容易成功，所以我们才会希望行业前辈能给出一些有意义的建议。今天这些建议来自一位有二十年行业经验的软件工程师，他的总结在 Hacker News 上引发了大量的讨论，帖子多天来一直占据“热榜”第一。
Justin Etheredge 最初在各类小型和初创企业中担任软件工程师，之后进入了咨询行业并开始为大型企业服务。Justin Etheredge 表示过去二十年以来的经历塑造了他对于软件的理解，并产生出一些坚定的信念。他把这些信念整理成一份明确的清单，希望能为大家带来一点帮助与启发。
引起网友激烈讨论的二十条建议：
我懂的并不多 “你怎么会不知道什么是 BGP？”“你难道没听说过 Rust？”
类似的问题可能每天都会出现在我们面前。没错，投身于软件行业的很多人之所以热爱这份工作，就是因为它敦促着我们终身学习。
在软件领域，无论我们朝哪个方向前进，都有着广阔的知识空间不断延伸而且每一天都有所变化。换句话说，这是一份能够承载我们度过几十年的职业生涯，而两位在类似岗位上分别工作了几十年的人之间也 很可能存在巨大的知识差距。我们越早意识到这一点，就能越快摆脱“冒充者综合症”，成为一个乐于向他人学习、也乐于教导他人的积极分子。
软件里最难的部分，是构建正确的东西 我知道这种话大家肯定听过无数遍了，但大多数软件工程师仍拒不承认，理由是这种说法似乎在贬低他们的工作成果。我个人觉得这样的心态大可不必，这类表达其实是在突出软件开发环境中的复杂性与非理性因素，而这些都会加剧我们面临的挑战。我们当然可以设计出在技术上最令人印象深刻的东西，但却没人愿意用——这类困境随时都会出现。
软件设计主要是一种聆听活动，开发者往往身兼软件工程师、通灵师乃至人类学家等多重角色。而我们对这种设计能力的每一点投资，无论是引入专业的用户体验师还是接受更进一步的自我教育，都能给开发成果带来巨大提升。毕竟与打磨设计能力相比，开发一款“没人用”的软件成本还是太高了、太高太高。
顶尖软件工程师会像设计师那样思考 伟大的软件工程师会深入思考代码成果的用户体验。虽然使用的术语或者切入点不同，但无论是对于外部 API、编程 API、用户界面、协议还是其他接口，优秀的工程师都会考虑由谁来使用、为什么要使用、如何使用以及对用户来说哪些因素真正重要等。总之，牢记用户需求才是实现良好体验的核心所在。
最好的代码就是没有代码，或者说不需要维护的代码 “程序员就是管编程的”，而且跟其他专业人士一样，我们也会在自己最擅长的方面犯错。这是人的本性，没办法。大多数软件工程师编写出的代码总是有点错误，而且往往无法用非技术方案来解决。
另外有一种很神奇的现象，越是有大量相当成熟的解决方案存在，工程团队就越是想“重新发明轮子”。想表达自我、加快专业成长当然是好事，但还请大家分清场合与需求，过度泛滥的发明欲望恐怕不利于编写出无需维护的代码。
软件是达成目的的手段 任何一位软件工程师的主要工作都是交付价值。但我发现大部分软件开发者并不理解这一点，能够将这个理念内化进日常工作的开发者就更少了。但只要能够完成内化，我们解决问题的方式、看待工具的角度都会有所变化。如果您真心相信软件要服从于结果，那就一定能找到“真正适合工作的工具”，而这种工具也许压根就不是软件。
有时候，你压根没时间磨刀 都说“磨刀不误砍柴工”，但刀磨久了反而让人心浮气躁、难以投入真正的工作。代码编写也是一样，研究多了容易让人陷入“分析瘫痪”。
一旦出现这种状况，请马上给自己设定一个截止日期，之后再探索解决方案。在着手解决问题时，我们很快就能找到思路与线索、引导自己一步步迭代向更好的产出。
如果没法理解所有可能性，就设计不出优秀的系统 这也是我个人一直在努力解决的问题。我的职责变化导致自己距离常规软件工程任务越来越远，我发现跟上开发者生态的发展速度越来越难，有时候自己甚至不理解哪些趋势真正重要。总之，如果不能理解特定生态当中的那些可行性与可用选项，那么我们根本没办法为所有问题找到合理的解决方案。
总而言之，务必警惕那些已经很久没写过代码、也没设计过系统的所谓“大牛”。
每套系统最终都很差劲，要勇于接受这一点 Bjarne Stroustrup 有句名言，“世界上只有两种语言，人们抱怨的语言和没人用的语言。”大型系统也是同理。并不存在“正确”的架构，我们永远无法偿还所有技术债务、设计不出完美的界面、也不可能永远拥有迅如闪电的测试速度。但做不到不代表什么都不做，这只是一种参考视角。优雅和完美本身就是种终极目标，我们当下的任务就是不断改进并创造一个更友好的系统环境，保证团队至少还用得下去、并以可持续的方式交付价值。
通于探索，不断追问 相信大家都听过“我们向来这么处理”之类的鬼话。这时候请关注那些新加入的成员，看看他们在哪里遇到了问题、又提出了哪些质疑。这些质疑中，是否存在某种有意义的功能诉求？请保证您明确理解他们提出的目标，以及驱动这种功能诉求的原因。如果得不到明确答案，就不断追问下去、直到弄明白为止。
相比于寻找 10 倍程序员，最好是消除 0.1 倍程序员 10 倍程序员就是个愚蠢的笑话。
没有任何一个人能在一天之内搞定另一位同样有能力、工作态度端正而且经验丰富的程序员需要两个礼拜才能做完的工作。我只见过 10 倍代码量程序员，他们写出来的 bug 也是 10 倍。或者说，10 倍程序员唯一的存在可能性，就是身边有个 0.1 倍程序员——就是那种浪费时间、不关注反馈、不测试代码也不考虑极端情况的家伙……所以相较于寻找神话中的 10 倍程序员，及时清除团队中的 0.1 倍程序员才是正道。</description></item><item><title>访问 Pod</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%AE%A1%E7%90%86/%E8%AE%BF%E9%97%AE-Pod/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%AE%A1%E7%90%86/%E8%AE%BF%E9%97%AE-Pod/</guid><description>概述 参考：
原文，jimmysong.io kubernetes 手书，指南-从集群外部访问 Pod 本文主要讲解访问 kubenretes 中的 Pod 和 Serivce 的集中方式，包括如下几种：
hostNetwork hostPort NodePort LoadBalancer Ingress 说是暴露 Pod 其实跟暴露 Service 是一回事，因为 Pod 就是 Service 的 backend。
hostNetwork: true 这是一种直接定义 Pod 网络的方式。
如果在 Pod 中使用 hostNetwork:true 配置的话，在这种 pod 中运行的应用程序可以直接看到 pod 启动的主机的网络接口。在主机的所有网络接口上都可以访问到该应用程序。以下是使用主机网络的 pod 的示例定义：
apiVersion: v1 kind: Pod metadata: name: influxdb spec: hostNetwork: true containers: - name: influxdb image: influxdb 部署该 Pod：
$ kubectl create -f influxdb-hostnetwork.yml 访问该 pod 所在主机的 8086 端口：</description></item><item><title>分布式存储</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/</guid><description>概述 参考：
Wiki, GFS Distributed Storage(分布式存储) 最早可追溯到 Google File System(谷歌文件系统，GFS)，GFS 是由 Google 开发，旨在使用大型低廉的商用硬件集群提供高效、可靠的数据访问。在不可追溯的年月，Google 发布了这种文件系统的论文，其中就有公司，基于这个论文所描述的设计架构，使用 Java 实现了 HDFS，也就是红极一时的 Hadoop 所使用的文件系统。但是随着时代的发展，Hadoop 臃肿的设计，并不适用于云原生的环境而被逐渐淘汰了，但是基于 GFS 的设计理念，一直延续至今。
分布式存储首先需要解决的就是文件路由问题，在一个分布式存储中，数据分散到各个节点，客户端想要读取时，如何快速得找到数据所在位置呢？这就需要一个元数据服务器，来记录数据存放位置。但是数据存储位置的规则，一直是分布式存储的热门话题之一。一般来说，系统中所有角色（Clients、Servers）需要有一个统一的数据寻址算法 Locator，满足：Locator(ID) -&amp;gt; [Device_1, Device_2, Device_3, ...]
其中输入 ID 是数据的唯一标识符，输出 Device 列表是一系列存储设备（多设备冗余以达到多份数据保护或切分提高并发等效果）。早期的直观方案是维护一张全局的 Key-Value 表，任何角色操作数据时查询该表即可。显然，随着数据量的增多和集群规模的扩大，要在整个系统中维护这么一张不断扩大的表变得越来越困难。Ceph 的 CRUSH(Controlled Replication Under Scalable Hashing) 算法即为解决此问题而生，她仅需要一份描述集群物理架构的信息和预定义的规则（均包含在CRUSH map中），便可实现确定数据存储位置的功能。
分布式基础学习 详见：集群与分布式
所谓分布式，在这里，很狭义的指代以 Google 的三驾马车，GFS、Map/Reduce、BigTable 为框架核心的分布式存储和计算系统。通常如我一样初学的人，会以 Google 这几份经典的论文作为开端的。它们勾勒出了分布式存储和计算的一个基本蓝图，已可窥见其几分风韵，但终究还是由于缺少一些实现的代码和示例，色彩有些斑驳，缺少了点感性。幸好我们还有 Open Source，还有 Hadoop。Hadoop 是一个基于 Java 实现的，开源的，分布式存储和计算的项目。作为这个领域最富盛名的开源项目之一，它的使用者也是大牌如云，包括了 Yahoo，Amazon，Facebook 等等（好吧，还可能有校内，不过这真的没啥分量&amp;hellip;）。Hadoop 本身，实现的是分布式的文件系统 HDFS，和分布式的计算（Map/Reduce）框架，此外，它还不是一个人在战斗，Hadoop 包含一系列扩展项目，包括了分布式文件数据库 HBase（对应 Google 的 BigTable），分布式协同服务 ZooKeeper（对应 Google 的 Chubby），等等。。。</description></item><item><title>分享Linux内存占用几个案例</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/%E5%88%86%E4%BA%ABLinux%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E5%87%A0%E4%B8%AA%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Memory/%E5%88%86%E4%BA%ABLinux%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E5%87%A0%E4%B8%AA%E6%A1%88%E4%BE%8B/</guid><description>案例一 问题 最近一台 CentOS 服务器，发现内存无端损失了许多，free 和 ps 统计的结果相差十几个 G，非常奇怪，后来 Google 了许久才搞明白。
分析 1、linux 系统内存消耗主要有三个地方：
进程 slab pagecacge 用 free 命令查看到的是系统整体的内容使用情况，而使用 ps 和 top 看到的内存使用情况都是以进程维度来看的，因此看不到 slabcache 和 pagecache 的内存占用信息。
2、判断应用程序是否有内存泄露问题，只根据进程的内存使用或机器的内存变化来判定都不太准确，如果单凭进程的内存变化可能会疏忽一些小对象的内存泄露问题。
同时对于机器的内存的使用也要做是否合理的判断。对于不同语言的应用都有相应的神器可以辅助定位内存泄露问题，同时结合 linux 内存的监控工具进行分析， 除了 top，free还有 pmap，/proc/meminfo 和 /slabinfo，slaptop等。
3、通过这个问题，有一点比较重要的是，在使用监控工具进行监控和分析时，对其值的具体含义还是要了解的很清楚，否则会造成误判，使问题变得更加复杂。
4、此外 page cache，dentries和inodes cache，系统是会自动回收的。
可以通过以下几种方式加速其回收，不过实际并不需要这么做。
手工清除内存 缓存
echo 1 &amp;gt; /proc/sys/vm/drop_caches 清除 page cache echo 2 &amp;gt; /proc/sys/vm/drop_caches 清除 denries 和 inodes echo 3 &amp;gt; /proc/sys/vm/drop_caches 清除 page cache ，dentries 及 inodes 调整 vm.</description></item><item><title>服务资源</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90/</guid><description>概述 参考：
官方文档，参考-KubernetesAPI-服务资源 Services Resources(服务资源)
Service Service Manifests
Service is a named abstraction of software service (for example, mysql) consisting of local port (for example 3306) that the proxy listens on, and the selector that determines which pods will answer requests sent through the proxy.
Endpoints Endpoints is a collection of endpoints that implement the actual service.
EndpointSlice EndpointSlice represents a subset of the endpoints that implement a service.
Ingress Ingress Manifest</description></item><item><title>改变运行状态的容器配置</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/%E6%94%B9%E5%8F%98%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81%E7%9A%84%E5%AE%B9%E5%99%A8%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/%E6%94%B9%E5%8F%98%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81%E7%9A%84%E5%AE%B9%E5%99%A8%E9%85%8D%E7%BD%AE/</guid><description>修改已创建容器的端口映射 参考：
公众号-进击云原生，骚操作！居然能修改已运行的 Docker 容器端口映射？ 其实吧。。。还是直接用 docker-compose 省事。
在 /var/lib/docker/containers/$(docker inspect ${容器名称} --format '{{.Id}}')/hostconfig.json 文件中找到 &amp;quot;PortBindings&amp;quot;:{} 字段 比如：
{ &amp;#34;PortBindings&amp;#34;: { &amp;#34;8502/tcp&amp;#34;: [ { &amp;#34;HostIp&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;HostPort&amp;#34;: &amp;#34;8502&amp;#34; } ], &amp;#34;8505/tcp&amp;#34;: [ { &amp;#34;HostIp&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;HostPort&amp;#34;: &amp;#34;8505&amp;#34; } ] } } 如果 config.v2.json 配置文件或者 config.json 文件也有关于端口的字段，也需要同步修改。只需要修改 &amp;quot;ExposedPorts&amp;quot;: {} 相关之处。 比如：
{ &amp;#34;Args&amp;#34;: [], &amp;#34;Config&amp;#34;: { &amp;#34;ExposedPorts&amp;#34;: { &amp;#34;8502/tcp&amp;#34;: {}, &amp;#34;8505/tcp&amp;#34;: {} }, &amp;#34;Entrypoint&amp;#34;: [&amp;#34;/bin/sh&amp;#34;] } } 修改完成后启动容器即可，这样就不用删除容器了。</description></item><item><title>各 CRD 的 yaml 样例</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/%E5%90%84-CRD-%E7%9A%84-yaml-%E6%A0%B7%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Prometheus-Operator/CR-%E8%AF%A6%E8%A7%A3/%E5%90%84-CRD-%E7%9A%84-yaml-%E6%A0%B7%E4%BE%8B/</guid><description>应用实例 prometheus 使用 storageclass 实现持久存储 可以在 prometheus 这个 CRD 的定义中找到关于 storage 的字段https://github.com/coreos/kube-prometheus/blob/master/manifests/0prometheus-operator-0prometheusCustomResourceDefinition.yaml#L3633
注解中写到如果不指定 storage 的话，则默认使用 emptydir 类型作为存放监控数据的 volume 类型
如果想要修改成持久存储，则只需要在声明 prometheus 资源的 yaml 文件中加入如下 storage 字段即可，下面的实例是让 prometheus 使用名为 managed-nfs-storage 的 StorageClass
storage: volumeClaimTemplate: spec: storageClassName: managed-nfs-storage resources: requests: storage: 10Gi 当加入该字段后，prometheus 资源生成的 statefulset 就会多出来一个字段，如图所示。 prometheus 使用 hostPath 实现持久存储 如下示例，使用本地 pod 所在节点的本地目录/root/prometheus-k8s-db 来作为数据存储目录
注意，最好使用 nodeSelector 让 pod 始终调度到同一个节点。
apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: test spec: replicas: 2 containers: - name: prometheus volumeMounts: - mountPath: /prometheus name: prometheus-k8s-db volumes: - name: prometheus-k8s-db hostPath: path: /root/prometheus-k8s-db nodeSelector: monitor: prometheus 修改 prometheus 的启动参数 可以在 prometheus 这个 CRD 的定义中找到关于 container 的字段https://github.</description></item><item><title>各种 Network Type 的实现方式</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/%E5%90%84%E7%A7%8D-Network-Type-%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/Neutron/%E5%90%84%E7%A7%8D-Network-Type-%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</guid><description>Linux Bridge 可用的网络类型详解 Linux bridge 技术非常成熟，而且高效，所以业界很多 OpenStack 方案选择 linux bridge，比如 Rackspace 的 private cloud。
open vswitch 实现的 Neutron 虚拟网络较为复杂，不易理解；而 linux bridge 方案更直观。先理解 linux bridge 方案后再学习 open vswitch 方案会更容易。并且可以通过两种方案的对比更加深入地理解 Neutron 网络。
所谓的 Linux Bridge Provider 就是 Neutron 直接利用 Linux 中的 Bridge 来实现自身的网络功能，而没有任何额外的功能。就是类似直接在系统中使用 ip bridge、brctl 之类的命令。
Linux Bridge 环境中，一个数据包从 instance 发送到物理网卡会经过下面几个网络设备：
tap interface 命名为 tapN (N 为 0, 1, 2, 3&amp;hellip;&amp;hellip;) linux bridge 命名为 brqXXXX。 vlan interface 命名为 ethX.Y（X 为 interface 的序号，Y 为 vlan id） vxlan interface 命名为 vxlan-Z（z 是 VNI） 物理 interface 命名为 ethX（X 为 interface 的序号） Local Network 本地网络，无法与宿主机之外通信 Flat Network 平面网络，通过桥接与宿主机之外通信 VM——Bridge——网卡(纯二层实现，适合私有云)</description></item><item><title>各种类型的 object(对象) 的常见方法</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%90%84%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84-object%E5%AF%B9%E8%B1%A1-%E7%9A%84%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%90%84%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84-object%E5%AF%B9%E8%B1%A1-%E7%9A%84%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95/</guid><description>概述 参考：
MDN 官方文档，参考-JavaScript-JavaScript-标准内置对象 MDN 官方文档，参考-WebAPIs String 对象 常用 String 对象的方法
toLowerCase() # 将字符串内的字母全部转换成小写 toUpperCase() 将字符串内的字母全部转换成大写 replace(&amp;ldquo;D&amp;rdquo;, 1) # replace(searchValue,replaceValue) 将字符串内第一个满足 searchValue 条件的字符替换为 replaceValue。注意：只能替换第一个 trim() # 去除首尾所有空白字符 split(&amp;quot; &amp;ldquo;) # 按照分隔符将字符串切割为一个数组。注意：只有字符串中有指定的分隔符，才会生效。否则切割后的元素只有一个。 截取字符串 substr(5, 8) # 第一个参数是开始截取的索引号，第二个参数是截取数量 substring(5, 8) # 第一个参数是开始截取的索引号，第二个参数是结束截取的索引号 slice(5, 8) # 第一个参数是开始截取的索引号，第二个参数是结束截取的索引号 Array 对象 常用 Array 对象的方法
会改变原始数组的内容 push() # 从后面追加 pop() # 从后面删除 unshift() # 从前面添加 shift() # 从前面删除 reverse() # 反转数组 splice() # 截取并添加 sort() # 数组排序 不会改变原始数组的内容 join() # 数组连接为字符串 concat() # 拼接数组 slice() # 截取数组 indexOf() # 查找元素在数组中的索引 forEach() # 遍历数组 map() # 映射数组 filter() # 过滤数组 every() # 判断是否全部满足条件 some() # 判断是否有满足条件的项</description></item><item><title>更新 APIServer 证书</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E6%9B%B4%E6%96%B0-APIServer-%E8%AF%81%E4%B9%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E6%9B%B4%E6%96%B0-APIServer-%E8%AF%81%E4%B9%A6/</guid><description>概述 参考：
原文链接：https://mp.weixin.qq.com/s/bs0urFxOG71nq9K34H1b6Q 本文我们将了解如何将一个新的 DNS 名称或者 IP 地址添加到 Kubernetes APIServer 使用的 TLS 证书中。在某些情况下默认的证书包含的名称可能不能满足我们的要求，又或者是 APIServer 地址有所变化，都需要重新更新证书。
我们这里的集群是使用 kubeadm 搭建的单 master 集群，使用的也是 kubeadm 在启动集群时创建的默认证书授权 CA，对于其他环境的集群不保证本文也同样适用。
Kubernetes APIServer 使用数字证书来加密 APIServer 的相关流量以及验证到 APIServer 的连接。所以如果我们想使用命令行客户端（比如 kubectl）连接到 APIServer，并且使用的主机名或者 IP 地址不包括在证书的 subject 的备选名称（SAN）列表中的话，访问的时候可能会出错，会提示对指定的 IP 地址或者主机名访问证书无效。要解决这个问题就需要更新证书，使 SAN 列表中包含所有你将用来访问 APIServer 的 IP 地址或者主机名。
步骤 生成 kubeadm 配置文件 因为集群是使用 kubeadm 搭建的，所以我们可以直接使用 kubeadm 来更新 APIServer 的证书，来保证在 SAN 列表中包含额外的名称。
首页我们一个 kubeadm 的配置文件，如果一开始安装集群的时候你就是使用的配置文件，那么我们可以直接更新这个配置文件，但是如果你没有使用配置文件，直接使用的 kubeadm init 来安装的集群，那么我们可以从集群中获取 kubeadm 的配置信息来创建一个配置文件，因为 kubeadm 会将其配置写入到 kube-system 命名空间下面一个名为 kubeadm-config 的 ConfigMap 中。可以直接执行如下所示的命令将该配置导出：</description></item><item><title>工作负载资源</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E8%B5%84%E6%BA%90/</guid><description>概述 参考：
官方文档，参考-KubernetesAPI-工作负载资源 Workloads Resources(工作负载资源)
Pod Pod 是在服务器上运行的容器的集合
EphemeralContainers A list of ephemeral containers used with the Pod ephemeralcontainers subresource.
PodTemplate PodTemplate describes a template for creating copies of a predefined pod.
ReplicationController ReplicationController represents the configuration of a replication controller.
ReplicaSet ReplicaSet ensures that a specified number of pod replicas are running at any given time.
Deployment Deployment enables declarative updates for Pods and ReplicaSets.
StatefulSet StatefulSet represents a set of pods with consistent identities.</description></item><item><title>共识算法</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/</guid><description>概述 参考：
知乎大佬 分布式系统中，如何保证集群中所有节点中的数据完全相同并且能够对某个提案(Proposal)达成一致，是分布式系统正常工作的核心问题，而 共识算法 就是用来保证分布式系统一致性的方法。有时候，共识算法也称为“一致性算法”。
Note： 提案(Proposal) # 在分布式系统中，Proposal 指分布式系统的修改请求，比如当一个客户端将一个数据写入到分布式系统中，负责接收数据的节点就会发起提案，让集群中其余节点写入该数据。
共识算法的实现：
Paxos # ZAB(muti-paxos) # Raft(muti-paxos) # Paxos 算法不易实现，Raft 算法是对 Paxos 算法的简化和改进 Gossip # 这是一个协议，与 Raft 等公式算法不太一样 由于共识算法的特点(下文会详细介绍，可以看完算法介绍再来看这段描述)，所以一般保证一致性的分布式系统的节点数都是都是奇数个。
Raft 算法 参考：
动画演示 一个节点一般具有三种状态：
Leader # 领导者，负责发出提案 Candidate # 候选人，负责争夺 Leader Follower # 追随者，负责同意 Leader 发出的提案 名词解释：
voted # 投票 term # 期限、任期。用来代指 Leader 产生到结束这一时间段 Leader 的产生
所有节点的初始状态都是以 Follower，并且持有一个定时器(各节点定时器时间随机，以保证不会同时触发选举)。 该定时器被随机分配在 150ms 和 300ms 之间 如果 Followers 在定时器时间到了，而没有收到 Leader 信息的话。那么 Follower 则声明自己是 Candidate 并参与 Leader 选举(此时为自己投票)，同时将请求发给其他节点来争取他们的投票，若其他节点长时间没有响应 Candidate，将重新发送选举信息。 如果接收投票信息的节点在这个 term 中还没有投过票，那么该节点将对发起该请求的 Candidate 投票，并且该节点重置定时器。 Candidate 计算总票数(自己+其他节点)，得票数大于 (n+1)/2 时(n 为节点数，除不开向下取整)，则该 Candidate 将称为第 M 任 Leader (M 任是最新的 term) Note：这里面所谓的投票与现实意义中的投票不太一样，没有投同意或者不同意这种说法。 值要对目标投票，目标就会计算一份得票数 Leader 在 term 内会不断发送心跳信息给集群内其他节点证明自己还活着，其他节点在收到心跳后会清空自己的定时器并回复 Leader 的心跳。这个机制保证其他节点不会在 Leader 任期内参加 Leader 选举。 当 Leader 节点出现故障而导致 Leader 失联，没有接收到心跳的 Follower 节点将准备成为 Candidate 进入下一轮 Leader 选举(回到步骤 1)。 若出现两个 Candidate 同时选举并获得了相同的票数，那么这两个 Candidate 将随机推迟一段时间后再向其他节点发出投票请求，这保证了再次发送投票请求以后不冲突。 状态复制</description></item><item><title>故障处理</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-MGMT/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/</guid><description>概述 公众号-CNCF，记一次远程写性能问题引发的Prometheus版本升级事件
compaction failed compaction failed 是一个 Prometheus 在压缩数据时产生的错误，导致该问题的因素多种多样，最常见的就是使用 NFS 作为 Prometehus 时序数据库的后端存储。
官方文档中曾明确表明不支持 NFS 文件系统
该问题的表现形式通常为文件丢失，比如，某个 Block 中的 meta.json 文件丢失
msg=&amp;#34;compaction failed&amp;#34; err=&amp;#34;plan compaction: open /prometheus/01FHHPS3NR7M2E8MAV37S61ME6/meta.json: no such file or directory&amp;#34; msg=&amp;#34;Failed to read meta.json for a block during reloadBlocks. Skipping&amp;#34; dir=/prometheus/01FHHPS3NR7M2E8MAV37S61ME6 err=&amp;#34;open /prometheus/01FHHPS3NR7M2E8MAV37S61ME6/meta.json: no such file or directory&amp;#34; 经过日志筛选，该问题起源于一次 Deleting obsolete block 操作之后的 compact blocks，也就是删除过期块后压缩块。 失败操作源于：
msg=&amp;#34;compaction failed&amp;#34; err=&amp;#34;delete compacted block after failed db reloadBlocks:01FHHPS3NR7M2E8MAV37S61ME6: unlinkat /prometheus/01FHHPS3NR7M2E8MAV37S61ME6/chunks: directory not empty&amp;#34; 这些报错日志信息，可以在 .</description></item><item><title>故障处理技巧</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%8A%80%E5%B7%A7/</guid><description>概述 参考:
官方文档，监控、日志和调试-调试运行中的 Pods 公众号 - k8s技术圈，解读Kubernetes常见退出码 Kubernetes 作为分布式容器调度系统荣，难免出现问题。
Kubernetes 让运维管理设备的方式发生了根本的转变，从一台一台设备登录，变为统一管理。在 1.19 版本官方文档的 debug 章节中，提到了这么一句话：
If none of these approaches work, you can find the host machine that the pod is running on and SSH into that host, but this should generally not be necessary given tools in the Kubernetes API. Therefore, if you find yourself needing to ssh into a machine, please file a feature request on GitHub describing your use case and why these tools are insufficient.</description></item><item><title>故障恢复测试</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/GlusterFS/%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%E6%B5%8B%E8%AF%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/GlusterFS/%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%E6%B5%8B%E8%AF%95/</guid><description>故障恢复测试 两台设备 212 213
2 乘 2 rep
212
more /var/lib/glusterd/glusterd.info
more /var/lib/glusterd/glusterd.info
UUID=48fb8476-16b1-4595-a0bd-02d34583e728
operating-version=30712
213
more /var/lib/glusterd/glusterd.info
UUID=a6fcec73-80d1-4d94-85cf-8b7623774b70
operating-version=30712
关闭 213
新建 213
修改
213
重启 213gluster 服务
在 213 上 gluster peer probe 添加 212
再次重启 213 gluster
观察
212
213
在 213 上重启 test volume
执行 gluster volume heal test full</description></item><item><title>关于 Template 的其他说明</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/%E5%85%B3%E4%BA%8E-Template-%E7%9A%84%E5%85%B6%E4%BB%96%E8%AF%B4%E6%98%8E/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/%E5%85%B3%E4%BA%8E-Template-%E7%9A%84%E5%85%B6%E4%BB%96%E8%AF%B4%E6%98%8E/</guid><description>如何 Debug Templates 官方文档：https://helm.sh/docs/chart_template_guide/debugging/
调试模板可能会很棘手，因为渲染的模板已发送到 Kubernetes API 服务器，该服务器可能会出于格式化以外的其他原因而拒绝 YAML 文件。
有一些命令可以帮助您调试。
helm lint 是验证图表是否遵循最佳做法的首选工具 helm install --dry-run --debug或helm template --debug：我们已经看到了这个技巧。这是让服务器呈现模板，然后返回生成的清单文件的好方法。 helm get manifest：这是查看服务器上安装了哪些模板的好方法。 helm template ：用于调试模板渲染结果 当您的 YAML 无法解析，但您想查看生成的内容时，检索 YAML 的一种简单方法是在模板中注释掉问题部分，然后重新运行helm install --dry-run --debug：
apiVersion: v2 # some: problem section # {{ .Values.foo | quote }} 上面的内容将呈现并返回完整的注释：
apiVersion: v2 # some: problem section # &amp;#34;bar&amp;#34; 这提供了一种查看生成的内容的快速方法，而不会阻止 YAML 分析错误。
.helmignore 文件 https://helm.sh/docs/chart_template_guide/helm_ignore_file/
NOTES.txt 文件 https://helm.sh/docs/chart_template_guide/notes_files/
其他 https://helm.sh/docs/chart_template_guide/wrapping_up/
关于 YAML 与 Go 数据类型 和 Go 模板的说明 https://helm.</description></item><item><title>关于外存你需要了解的</title><link>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Disk/%E5%85%B3%E4%BA%8E%E5%A4%96%E5%AD%98%E4%BD%A0%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/0.%E8%AE%A1%E7%AE%97%E6%9C%BA/Disk/%E5%85%B3%E4%BA%8E%E5%A4%96%E5%AD%98%E4%BD%A0%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84/</guid><description>概述 原文链接：https://zhuanlan.zhihu.com/p/333965692
参考：
Wiki, Magnetic Storage(磁存储) Wiki, Optical Storage(光存储) Wiki, Tape Storage(磁带存储) 上一节对内存的物理特性进行了了解，这篇打算对上一篇提到的外存进一步讲解。 外存全称为外部存储器，它指的是除计算机内存及 CPU 缓存以外的储存器。外存是相对内存来说的。计算机不能对外存进行直接寻址，简单的说，就是给外存一个物理地址的话它是处理不了的。由于内存具有掉电后数据无法保存的特性，所以计算机通常需要配备外存来保持数据。 外部存储器按照存储介质种类可以划分为光、磁性、半导体这三大类。
光存储：比较常见的是 CD、DVD、蓝光。 磁性存储：比较常见的是磁带、软盘、硬盘。 半导体存储：这个类型的存储比较多，比如上一篇说的内存，闪存 SSD、各种 ROM 等。 下面对这三大类的外存分别都拿一个典型出来了解一下。
Optical Storage(光存储) 蓝光，英文 Blu-ray Disc，主要用于存储高清格式的音视频文件，其物理结构与 DVD 类似。为什么叫蓝光呢？因为用于刻录、读取光盘的激光是蓝紫激光，一般的 DVD 使用的激光是红激光。蓝紫激光的波长比较短，刻录的孔径就更小，所以可以刻录在光盘上的信息就更多，通常能比普通 DVD 多存储 6 到 10 倍的信息。 目前来说，每个蓝光碟片所能存储的信息比较有限，根据了解大概能到 400GB 左右。虽然蓝光碟片能存储的信息较少，但是它能保存很久，50 年往上走。不知道大家有没有了解过 GitHub 的北极代码库计划，GitHub 将优秀的代码库以二维码的形式存放到胶片中，并放到挪威的一个废弃煤矿冻土区深处进行存储。注意：它用的不是常见的磁盘，也不是用的 SSD，也不是用的蓝光 DVD，而是胶片！因为胶片的寿命可以长达 1000 年，而我们常见的磁盘也不过几年寿命而已。
Magnetic Storage(磁存储) 磁盘这种类型是我们目前最常见也用的最多的存储介质。磁盘顾名思义就是用磁性物质制作的坚硬旋转盘片，它的物理结构一般主要有磁头、盘片、电动机及主控芯片等，盘片是它的主要存储组件。盘片上覆盖着一层薄薄的磁性物质，所有数据都通过磁性物质进行存储。它的读写原理是：写数据时，由磁头通过电磁流改变盘片上的磁性材料的极性，比如由正极变负极，或者由负极变正极，而正极对应的是数据 1，负极对应的是 0，所以一串 0 或 1 的数据就这样通过磁材料的极性间接表达了出来；而读数据时，磁头经过盘片上方时会被磁性材料的极性改变电气信号，通过极性影响了电的 1 或 0 表达，所以也间接的将存储在磁盘上的数据表达出来了。 磁盘的数据接口有如下几种：
IDE：也叫 ATA，这种接口的速度不快，而且抗干扰性差，现在已逐渐淘汰。 SATA：串行的 ATA。这种接口抗干扰性强，速度较快，一般可以达到 300MB/s 以上。我们常用的台式机就是这种接口。 SCSI：小型机系统接口。一般用于个人工作站和服务器。 SAS：新一代的 SCSI 技术，可兼容 SATA，速度可达 12Gb/s。 FC：光纤通道接口，具有热插拔、速度快、价格高的特性，一般只用于高端服务器领域。 目前磁盘能存储的数据较多，而且价格便宜，在外存存储介质里占了半壁江山。但是磁盘由于它的物理特性的原因特别容易坏，一不小心摔它一下可能就会损坏里面的盘片或磁头，故障率特别高，而且即使不摔它，它的寿命也不长，一般三四年就需要换一批新磁盘。很多数据中心里面的存储服务器每隔三四年的时间就得更换一批新的磁盘，即使磁盘本身并没有什么坏道，这样看来其实磁盘也算是一种快消品。</description></item><item><title>关于微内核的对话</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/%E5%BE%AE%E5%86%85%E6%A0%B8/%E5%85%B3%E4%BA%8E%E5%BE%AE%E5%86%85%E6%A0%B8%E7%9A%84%E5%AF%B9%E8%AF%9D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/%E5%BE%AE%E5%86%85%E6%A0%B8/%E5%85%B3%E4%BA%8E%E5%BE%AE%E5%86%85%E6%A0%B8%E7%9A%84%E5%AF%B9%E8%AF%9D/</guid><description>参考：原文链接
不知怎么的，最近 “微内核 vs 宏内核” 又成了热门话题。这场争论从 1992 年开始……
前言 说实话我很久没有关心操作系统了，因为通常所谓的 “操作系统” 在我心里不过是一个 C 语言的运行时系统（run-time system），就像 JVM 是 Java 的运行时系统一样。由于 C 语言的设计缺陷，这些系统引入了各种无需有的概念（进程，线程，虚拟内存……），以及它们带来的复杂性和开销。
微内核与宏内核之争当然也包括在内，在我看来这些都是无需有的概念和争论。操作系统相关的领域有很多的 “宗教斗争”，比如“Linux vs Windows”，“自由软件 vs 不自由软件”，“RISC vs CISC”，甚至“VIM vs Emacs”…… 人们为了证明自己用的系统或者工具是世界上“最好” 的，吵得昏天黑地。遇到有人指出自己用的工具的缺点，随时可能拿枪毙了对方。这些被叫做“flame war”。
我曾经是某些宗教斗争中活跃的一员，不知道这事的人可以去查一下我的历史。等你经历了很多才发现，原来这些宗教情绪和斗争都是那么幼稚无知。
这种 “技术宗教情绪” 往往显示出参与者心理地位的低下。因为他们缺乏自信，所以他们的心理需要靠山。这个靠山可能是某种操作系统（比如 Linux），某种编程语言（比如 C++），或者某种工具（比如 VIM）。这些人以自己能熟练使用这些工具为豪，居高临下，看不起“异教徒”。
具有技术宗教情绪的人看似是为了 “技术”，“理想”，而其实跟那些以为开着豪车，穿着名牌就是“上流社会” 的人是一样低级的，因为他们依靠于这些物品，所以他们的地位在这些物品之下。
一个人需要彻底的把这些东西看成是 “东西”，不带有任何崇拜或者鄙视的情绪，他的心理才算是成熟了。
在我的理念里，一个操作系统本应该大概是这个样子。简单得很，根本不存在那么多问题。我可以利用这些思想来看透现有操作系统的绝大部分思想，管它是微内核还是宏内核。我可以把现有的操作系统看成是这个系统的 “退化版”。
操作系统是一个死知识横行的领域。很多人发现操作系统课难学，难理解。里面有些内容，比如各种同步机制，很多人上完课毕了业，工作很多年以后都还弄不明白是怎么回事，它们为什么在那里。类似的东西包括虚拟内存，进程与线程的区别，等等。
经过了很多的经验和思考，加上其他领域给我的启发，我终于明白了。原来很多这些概念都是无须有的，死掉的知识。
操作系统课程里面的概念经常是这样形成的：
很久以前，有人为了解决了一个特定的问题，提出了一个概念（比如 semaphore）。这个概念本来只有一个用途，就是解决他遇到的那个特定的问题。 因为这人太有名，这概念就被写进了教科书里。有时候连他当时的具体实现细节都给写进去了。比如 semaphore 的两个操作被叫做 P 和 V，连这两个名字都给作为 “典故” 写进去了。 教授们照本宣科，吹毛求疵，要你用这概念解决很多其它问题。很多根本就是人为造出来的变态问题，现实中遇不到的，或者是一些不该用这个概念解决的问题。 这就是为什么操作系统课学起来那么难——很多都是没道理的难。
再加上 Unix 系统里面一堆设计恶劣，无法有效组合使用的工具软件，操作系统就在学生心中产生了威慑力。死记硬背，喜欢折腾，喜欢发现奇技淫巧的人，在这个领域里茁壮成长。逐渐的，他们产生了莫名的自信。他们并不理解里面的很多概念是怎么来的，只是记住了它们，他们写的代码很难看懂。然后他们开始从心理上打压那些记不住这些概念，看不懂他们代码的人。
久而久之，这些人就成为了大家所崇拜的 “神”。
跟有些人聊操作系统是件闹心的事，因为我往往会抛弃一些术语和概念，从零开始讨论。我试图从 “计算本质” 的出发点来理解这类事物，理解它们的起因，发展，现状和可能的改进。我所关心的往往是“这个事物应该是什么样子”，“它还可以是什么（也许更好的）样子”，而不只是“它现在是什么样子”。不明白我的这一特性，又自恃懂点东西的人，往往会误以为我连基本的术语都不明白。于是天就这样被他们聊死了。</description></item><item><title>官方推荐标签用法</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/Label-and-Selector%E6%A0%87%E7%AD%BE%E5%92%8C%E9%80%89%E6%8B%A9%E5%99%A8/%E5%AE%98%E6%96%B9%E6%8E%A8%E8%8D%90%E6%A0%87%E7%AD%BE%E7%94%A8%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/Object-%E7%AE%A1%E7%90%86/Label-and-Selector%E6%A0%87%E7%AD%BE%E5%92%8C%E9%80%89%E6%8B%A9%E5%99%A8/%E5%AE%98%E6%96%B9%E6%8E%A8%E8%8D%90%E6%A0%87%E7%AD%BE%E7%94%A8%E6%B3%95/</guid><description>概述 参考：
官方文档，概念-概述-使用 Kubernetes 对象-推荐的标签 除了 kubectl 和 dashboard 之外，您可以使用其他工具来可视化和管理 Kubernetes 对象。一组通用的标签可以让多个工具之间相互操作，用所有工具都能理解的通用方式描述对象。
除了支持工具外，推荐的标签还以一种可以查询的方式描述了应用程序。
元数据围绕 应用（application） 的概念进行组织。Kubernetes 不是 平台即服务（PaaS），没有或强制执行正式的应用程序概念。 相反，应用程序是非正式的，并使用元数据进行描述。应用程序包含的定义是松散的。
说明：
这些是推荐的标签。它们使管理应用程序变得更容易但不是任何核心工具所必需的。
共享标签和注解都使用同一个前缀：app.kubernetes.io。没有前缀的标签是用户私有的。共享前缀可以确保共享标签不会干扰用户自定义的标签。
标签 为了充分利用这些标签，应该在每个资源对象上都使用它们。
键 描述 示例 类型 app.kubernetes.io/name 应用程序的名称 mysql 字符串 app.kubernetes.io/instance 用于唯一确定应用实例的名称 mysql-abcxzy 字符串 app.kubernetes.io/version 应用程序的当前版本（例如，语义版本，修订版哈希等） 5.7.21 字符串 app.kubernetes.io/component 架构中的组件 database 字符串 app.kubernetes.io/part-of 此级别的更高级别应用程序的名称 wordpress 字符串 app.kubernetes.io/managed-by 用于管理应用程序的工具 helm 字符串 为说明这些标签的实际使用情况，请看下面的 StatefulSet 对象：
apiVersion: apps/v1 kind: StatefulSet metadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: mysql-abcxzy app.kubernetes.io/version: &amp;#34;5.7.21&amp;#34; app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.</description></item><item><title>管道符等组合命令</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/%E7%AE%A1%E9%81%93%E7%AC%A6%E7%AD%89%E7%BB%84%E5%90%88%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/Bash-%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4/%E7%AE%A1%E9%81%93%E7%AC%A6%E7%AD%89%E7%BB%84%E5%90%88%E5%91%BD%E4%BB%A4/</guid><description>| (管道符) 把 | 前面的标准输出内容当作 | 后面的标准输入内容
EXAMPLE
~]# echo &amp;#34;--help&amp;#34; | cat --help echo “&amp;ndash;help” | cat # 把&amp;ndash;help 当作 cat 的标准输入输出到屏幕上，如图所示，注意与 xargs 应用实例 a 的区别 exec Syntax(语法) exec [-cl] [-a name] [COMMAND [ARGUMENTS&amp;hellip;]]
如果指定了 command，它将替换 shell。 没有创建新进程。 参数成为命令的参数。 如果提供了-l 选项，则 shell 会在传递给 command 的第 0 个参数的开头放置一个破折号。 这是 login(1) 的作用。 -c 选项导致命令在空环境中执行。 如果提供了-a，则 shell 将 name 作为第 0 个参数传递给执行的命令。 如果由于某种原因无法执行命令，则会退出非交互式 shell，除非启用了 shell 选项 execfail，在这种情况下它将返回失败。 如果无法执行文件，则交互式 shell 将返回失败。 如果未指定 command，则任何重定向在当前 shell 中生效，返回状态为 0.</description></item><item><title>函数</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E5%87%BD%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E5%87%BD%E6%95%B0/</guid><description>概述 Function(函数) 就是代码块，函数中表示了一堆代码的集合，当调用函数的时候，则会执行函数中函数体内的命令
语法格式：
function NAME(){ 函数体 } # 或者 NAME() { 函数体 } 调用方式：在 shell 脚本中，函数并不会执行，只有在调用的时候，才会执行函数体中的命令
直接使用函数名即可调用，函数名出现的地方，会被自动替换为函数体中的命令 在调用函数时，传递参数给函数体，在函数名后面以空白分隔指定的参数列表即可。e.g.FunctionName ARG1 ARG2 &amp;hellip;ARGn 每个参数可以在函数体中使用位置参数进行引用，i.e.ARG1 在函数体中就是$1 的值，ARG2 在函数体中就是$2 的值，以此类推 函数的生命周期：被调用时创建，返回时终止
使用 return 命令返回自定义状态结果
0：成功 1-255：失败 函数中的变量：在函数体内定义的变量只对该函数生效，当函数生命周期结束时，变量失效。
注意：在函数体中，可以修改全局变量的值
函数的递归：函数直接或间接调用自身 函数递归的应用实例：
阶乘：N!=N(n-1)(n-2)&amp;hellip;1 #/bin/bash fact() { if [ $1 -eq 0 -o $1 -eq 1 ]; then echo 1 else echo $[$1*$(fact $[$1-1])] fi} fact $1 步骤：比如给 fact 传递参数 5
如果 5 大于 0 或者大于 1，那么使用 5*fact 函数，且再次调用函数时参数为 5-1 再次调用函数的时候，不但有 4，还有函数，i.</description></item><item><title>函数运行时在内存中是什么样子？</title><link>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E6%97%B6%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E6%97%B6%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90/</guid><description>参考：公众号,码农的荒岛求生
在开始本篇的内容前，我们先来思考几个问题。
我们先来看一段简单的代码：
void func(int a) { if (a &amp;gt; 100000000) return; int arr[100] = {0}; func(a + 1); }
你能看出这段代码会有什么问题吗？
我们在上一篇文章《高性能高并发服务器是如何实现的》中提到了一项关键技术——协程，你知道协程的本质是什么吗？有的同学可能会说是用户态线程，那么什么是用户态线程，这是怎么实现的？
函数运行起来后在内存中是什么样子？
这几个问题看似没什么关联，但这背后都指向一样东西，这就是所谓的函数运行时栈，run time stack。
接下来我们就好好看看到底什么是函数运行时栈，为什么彻底理解函数运行时栈对程序员来说非常重要。
从进程、线程到函数调用
汽车在高速上行驶时有很多信息，像速度、位置等等，通过这些信息我们可以直观的感受汽车的运行时状态。
同样的，程序在运行时也有很多信息，像有哪些程序正在运行、这些程序执行到了哪里等等，通过这些信息我们可以直观的感受系统中程序运行的状态。
其中，我们创造了进程、线程这样的概念来记录有哪些程序正在运行，关于进程和线程的概念请参见《看完这篇还不懂进程、线程与线程池你来打我》。
进程和线程的运行体现在函数执行上，函数的执行除了函数内部执行的顺序执行还有子函数调用的控制转移以及子函数执行完毕的返回。其中函数内部的顺序执行乏善可陈，重点是函数的调用。
因此接下来我们的视角将从宏观的进程和线程拉近到微观下的函数调用，重点来讨论一下函数调用是怎样实现的。
函数执行的活动轨迹：栈
玩过游戏的同学应该知道，有时你为了完成一项主线任务不得不去打一些支线的任务，支线任务中可能还有支线任务，当一个支线任务完成后退回到前一个支线任务，这是什么意思呢，举个例子你就明白了。
假设主线任务西天取经 A 依赖支线任务收服孙悟空 B 和收服猪八戒 C，也就是说收服孙悟空 B 和收服猪八戒 C 完成后才能继续主线任务西天取经 A；
支线任务收服孙悟空 B 依赖任务拿到紧箍咒 D，只有当任务 D 完成后才能回到任务 B；
整个任务的依赖关系如图所示：
现在我们来模拟一下任务完成过程。
首先我们来到任务 A，执行主线任务：
执行任务 A 的过程中我们发现任务 A 依赖任务 B，这时我们暂停任务 A 去执行任务 B：
执行任务 B 的时候，我们又发现依赖任务 D：</description></item><item><title>好用的镜像-有特殊功能</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E5%A5%BD%E7%94%A8%E7%9A%84%E9%95%9C%E5%83%8F-%E6%9C%89%E7%89%B9%E6%AE%8A%E5%8A%9F%E8%83%BD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E5%A5%BD%E7%94%A8%E7%9A%84%E9%95%9C%E5%83%8F-%E6%9C%89%E7%89%B9%E6%AE%8A%E5%8A%9F%E8%83%BD/</guid><description>node-shell
可以通过 exec 像 ssh 一样控制节点的镜像，好像是 https://github.com/kvaps/kubectl-node-shell 这个？待确认
polinux/stress
一个非常好用的压测容器，可以对容器指定其所使用的内存和 cpu 等资源的大小。当创建完资源配合等资源限制的对象后，可以通过该容器来测试资源限制是否生效。
containous/whoami
一个 go 语言编写的 web 服务器，当请求该容器时，可以输出操作系统信息和 HTTP 请求等，信息如下所示：包括当前容器的 ip 地址，容器的主机名等等
Hostname: whoami-bd6b677dc-7tq7h IP: 127.0.0.1 IP: 10.252.131.122 RemoteAddr: 127.0.0.1:35358 GET /notls HTTP/1.1 Host: 10.10.9.51:30272 User-Agent: curl/7.29.0 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 10.10.9.51 X-Forwarded-Host: 10.10.9.51:30272 X-Forwarded-Port: 30272 X-Forwarded-Proto: http X-Forwarded-Server: traefik-6fbbb464b5-mcq99 X-Real-Ip: 10.10.9.51 kiwigrid/k8s-sidecar 参考：GitHub 项目
该容器会持续监听指定的 configmap 和 secret 资源，当 configmap 或 secret 对象被创建或更新时，会将该对象内的数据，转换成文件，并保存在容器内指定的路径中。
这个镜像常常作为 sidecar 容器使用，与主容器共享相同目录，这样，主程序就可以实时读取到新创建的 configmap 或 secret</description></item><item><title>回调函数与异步编程</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E4%B8%8E%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/ECMAScript/JavaScript-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E4%B8%8E%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</guid><description>概述 参考：
https://www.runoob.com/js/js-async.html Promise</description></item><item><title>混沌工程原理</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B%E7%B3%BB%E7%BB%9F/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B%E7%B3%BB%E7%BB%9F/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/</guid><description>参考：
原文链接 混沌工程介绍与实践 最后更新：2019 年 3 月（更改）
混沌工程学是在系统上进行实验的学科，目的是建立对系统承受生产中动荡环境能力的信心。
大规模，分布式软件系统的进步正在改变软件工程的局面。作为一个行业，我们迅速采用可以提高开发灵活性和部署速度的实践。紧随这些好处之后，紧迫的问题随之而来：我们对投入生产的复杂系统能有多少信心？
即使分布式系统中的所有单个服务都正常运行，这些服务之间的交互也会导致不可预测的结果。不可预测的结果，再加上影响生产环境的罕见但具有破坏性的现实事件，使这些分布式系统固有地混乱。
我们需要先确定弱点，然后才能在系统范围的异常行为中体现出来。系统性弱点可以表现为：当服务不可用时，回退设置不正确；重试由于超时调整不当而引起的风暴；当下游依赖项接收到过多流量时中断；单点故障崩溃时的级联故障；等。我们必须主动解决最重要的弱点，以免影响生产中的客户。我们需要一种方法来管理这些系统中固有的混乱，利用增加的灵活性和速度，并对我们的生产部署充满信心，尽管它们代表了复杂性。
一种基于经验的，基于系统的方法可以大规模解决分布式系统中的混乱情况，并增强人们对这些系统承受现实条件的能力的信心。我们通过在受控实验中观察分布式系统的行为来了解它的行为。我们称此为 混沌工程。
实践中的混乱 为了专门解决大规模分布式系统的不确定性，可以将“混沌工程”看作是发现系统弱点的实验的促进。这些实验遵循四个步骤：
首先将“稳定状态”定义为指示正常行为的系统的某些可测量输出。 假设在对照组和实验组中这种稳定状态都将持续。 引入反映真实事件的变量，例如崩溃的服务器，发生故障的硬盘驱动器，断开的网络连接等。 试图通过寻找对照组和实验组之间稳态差异来反驳这一假设。 破坏稳态越难，我们对系统行为的信心就越大。如果发现了一个弱点，那么我们现在就有一个改进的目标，那就是在整个系统中表现出来之前。
高级原则 以下原则描述了混沌工程的理想应用，该理想工程应用于上述实验过程。遵循这些原则的程度与我们对大规模分布式系统的信心密切相关。
建立关于稳态行为的假设 关注于系统的可测量输出，而不是系统的内部属性。在短时间内对该输出的测量构成了系统稳态的代理。整个系统的吞吐量，错误率，等待时间百分位数等都可以成为代表稳态行为的关注指标。通过关注实验过程中的系统行为模式，Chaos 可以验证系统是否有效，而不是试图验证其工作方式。
变化的现实世界事件 混沌变量反映了现实世界中的事件。通过潜在影响或估计频率对事件进行优先级排序。考虑与硬件故障（如服务器死机），软件故障（如格式错误的响应）和非故障事件（如流量高峰或扩展事件）相对应的事件。在混沌实验中，任何能够破坏稳态的事件都是潜在的变量。
在生产中进行实验 系统的行为取决于环境和流量模式。由于利用率的行为可以随时更改，因此对真实流量进行采样是可靠捕获请求路径的唯一方法。为了保证系统运行方式的真实性和与当前已部署系统的相关性，Chaos 强烈希望直接对生产流量进行试验。
自动化实验以连续运行 手动运行实验是劳动密集型的，最终是不可持续的。自动化实验并连续运行。Chaos Engineering 将自动化内置到系统中，以驱动业务流程和分析。
最小化爆炸半径 在生产中进行试验有可能导致不必要的客户痛苦。尽管必须考虑到一些短期的负面影响，但是混沌工程师的责任和义务是确保最大程度地减少和控制实验的后果。
混沌工程是一种强大的实践，已经在改变世界上一些最大规模的运营中软件的设计和工程方式。在其他实践涉及速度和灵活性的地方，混沌专门解决了这些分布式系统中的系统性不确定性。混沌原理为快速大规模创新提供了信心，并为客户提供了应有的高质量体验。
加入有关“混沌原理”及其在混沌社区中的应用的持续讨论。</description></item><item><title>基于 IPVS 的集群内负载平衡深入探讨</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/%E5%9F%BA%E4%BA%8E-IPVS-%E7%9A%84%E9%9B%86%E7%BE%A4%E5%86%85%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/%E5%9F%BA%E4%BA%8E-IPVS-%E7%9A%84%E9%9B%86%E7%BE%A4%E5%86%85%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/</guid><description>参考： 原文链接：https://kubernetes.io/blog/2018/07/09/ipvs-based-in-cluster-load-balancing-deep-dive/ 阳明,kubernetes 中的 ipvs：https://www.qikqiak.com/post/how-to-use-ipvs-in-kubernetes/
Introduction Per the Kubernetes 1.11 release blog post , we announced that IPVS-Based In-Cluster Service Load Balancing graduates to General Availability. In this blog, we will take you through a deep dive of the feature.
What Is IPVS? IPVS (IP Virtual Server) is built on top of the Netfilter and implements transport-layer load balancing as part of the Linux kernel. IPVS is incorporated into the LVS (Linux Virtual Server), where it runs on a host and acts as a load balancer in front of a cluster of real servers.</description></item><item><title>集群资源</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-Resource-%E4%B8%8E-Object/API-%E5%8F%82%E8%80%83/%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90/</guid><description>概述 参考：
官方文档，参考 - Kubernetes API - 集群资源 Node https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/node-v1/
Node is a worker node in Kubernetes.
Namespace https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/namespace-v1/
Namespace provides a scope for Names.
Event https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/event-v1/
Event is a report of an event somewhere in the cluster.
APIService https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/api-service-v1/
APIService represents a server for a particular GroupVersion.
Lease https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/lease-v1/
Lease defines a lease concept.
RuntimeClass https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/runtime-class-v1/
RuntimeClass defines a class of container runtime supported in the cluster.
FlowSchema v1beta2 https://kubernetes.</description></item><item><title>记一次 K8S 内部服务调用域名解析超时排坑经历</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E8%AE%B0%E4%B8%80%E6%AC%A1-K8S-%E5%86%85%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E8%B6%85%E6%97%B6%E6%8E%92%E5%9D%91%E7%BB%8F%E5%8E%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E8%AE%B0%E4%B8%80%E6%AC%A1-K8S-%E5%86%85%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E8%B6%85%E6%97%B6%E6%8E%92%E5%9D%91%E7%BB%8F%E5%8E%86/</guid><description>原文连接：https://juejin.im/post/6844904178582552590
记一次 K8S 内部服务调用域名解析超时排坑经历
前言 近期线上 k8s 时不时就会出现一些内部服务间的调用超时问题，通过日志可以得知超时的原因都是出现在域名解析上，并且都是 k8s 内部的域名解析超时，于是直接先将内部域名替换成 k8s service 的 IP，观察一段时间发现没有超时的情况发生了，但是由于使用 service IP 不是长久之计，所以还要去找解决办法。
复现 一开始运维同事在调用方 pod 中使用ab工具对目标服务进行了多次压测，并没有发现有超时的请求，我介入之后分析ab这类 http 压测工具应该都会有 dns 缓存，而我们主要是要测试 dns 服务的性能，于是直接动手撸了一个压测工具只做域名解析，代码如下：
package main import ( &amp;#34;context&amp;#34; &amp;#34;flag&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;net&amp;#34; &amp;#34;sync/atomic&amp;#34; &amp;#34;time&amp;#34; ) var host string var connections int var duration int64 var limit int64 var timeoutCount int64 func main() { // os.Args = append(os.Args, &amp;#34;-host&amp;#34;, &amp;#34;www.baidu.com&amp;#34;, &amp;#34;-c&amp;#34;, &amp;#34;200&amp;#34;, &amp;#34;-d&amp;#34;, &amp;#34;30&amp;#34;, &amp;#34;-l&amp;#34;, &amp;#34;5000&amp;#34;) flag.StringVar(&amp;amp;host, &amp;#34;host&amp;#34;, &amp;#34;&amp;#34;, &amp;#34;Resolve host&amp;#34;) flag.</description></item><item><title>键值数据</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE/</guid><description>概述 参考：
Key-Value Data(键值数据)
Key-value Stores 键值存储 Key-value stores are probably the simplest form of database management systems. They can only store pairs of keys and values, as well as retrieve values when a key is known.键值存储可能是最简单的数据库管理系统形式。它们只能存储键和值对，以及在已知键时检索值。 These simple systems are normally not adequate for complex applications. On the other hand, it is exactly this simplicity, that makes such systems attractive in certain circumstances. For example resource-efficient key-value stores are often applied in embedded systems or as high performance in-process databases.</description></item><item><title>将单 master 升级为多 master 集群</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%B0%86%E5%8D%95-master-%E5%8D%87%E7%BA%A7%E4%B8%BA%E5%A4%9A-master-%E9%9B%86%E7%BE%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/Kubernetes-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E5%B0%86%E5%8D%95-master-%E5%8D%87%E7%BA%A7%E4%B8%BA%E5%A4%9A-master-%E9%9B%86%E7%BE%A4/</guid><description>如何将单 master 升级为多 master 集群 前面我们课程中的集群是单 master 的集群，对于生产环境风险太大了，非常有必要做一个高可用的集群(https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/ha-topology/)，这里的高可用主要是针对控制面板来说的，比如 kube-apiserver、etcd、kube-controller-manager、kube-scheduler 这几个组件，其中 kube-controller-manager 于 kube-scheduler 组件是 Kubernetes 集群自己去实现的高可用，当有多个组件存在的时候，会自动选择一个作为 Leader 提供服务，所以不需要我们手动去实现高可用，apiserver 和 etcd 就需要手动去搭建高可用的集群的。
高可用的架构有很多，比如典型的 haproxy + keepalived 架构，或者使用 nginx 来做代理实现。我们这里为了说明如何将单 master 升级为高可用的集群，采用相对更简单的 nginx 模式，当然这种模式也有一些缺点，但是足以说明高可用的实现方式了。架构如下图所示：
从上面架构图上可以看出来，我们需要在所有的节点上安装一个 nginx 来代理 apiserver，这里我们准备 3 个节点作为控制平面节点：ydzs-master、ydzs-master2、ydzs-master3，这里我们默认所有节点都已经正常安装配置好了 Docker：
在开始下面的操作之前，在所有节点 hosts 中配置如下所示的信息：
$ cat /etc/hosts 127.0.0.1 api.k8s.local 10.151.30.70 ydzs-master2 10.151.30.71 ydzs-master3 10.151.30.11 ydzs-master 10.151.30.57 ydzs-node3 10.151.30.59 ydzs-node4 10.151.30.60 ydzs-node5 10.151.30.62 ydzs-node6 10.151.30.22 ydzs-node1 10.151.30.23 ydzs-node2 免责声明：本文操作已验证成功，但并不保证对集群没有任何影响，在操作之前一定做好备份，由此对集群产生的任何影响本人概不负责~
更新证书 由于我们要将集群替换成高可用的集群，那么势必会想到我们会用一个负载均衡器来代理 APIServer，也就是这个负载均衡器访问 APIServer 的时候要能正常访问，所以默认安装的 APIServer 证书就需要更新，因为里面没有包含我们需要的地址，需要保证在 SAN 列表中包含一些额外的名称。</description></item><item><title>接口设计示例 二</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E7%A4%BA%E4%BE%8B-%E4%BA%8C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E7%A4%BA%E4%BE%8B-%E4%BA%8C/</guid><description>这个示例与前文中的设计原则里的张三李四开车非常相似。只不过这里是咱自己总结的。。。不足的地方后续慢慢再改~
在下面的例子中，我们把 main() 中的代码当作外部代码，通过调用我们暴露出来的接口(这里的接口仅仅是一个函数)，来获取想要的数据。其实就等于说，除了 main() 以外，其他的代码都当作是其他 package 内的代码。然后通过 main() 调用。在网上的很多代码示例，都是这么来搞得。
只有一个 struct 现在我想要计算一个图形周长和面积。假定现在只有一个正方形，那么我定义一个正方形
// Square 正方形的属性 type Square struct { side float32 } 并且有两个方法来计算正方形的面积与周长
// Area 正方形求面积的方法，接收了正方形的结构体并使用结构体中的边长属性来计算面积 func (sq *Square) Area() float32 { return sq.side * sq.side } // Perimeter 正方形求周长的方法 func (sq *Square) Perimeter() float32 { return sq.side * 4 } 并且提供一个函数，供其他人调用以便获取图形的面积与周长，只需要调用 PrintResult() 函数，并传递参数即可。
// PrintResult 输出计算结果 func PrintResult(shape string, s*Square) { fmt.Printf(&amp;#34;%s的面积：%.2f\n&amp;#34;, shape, s.Area()) fmt.Printf(&amp;#34;%s的周长：%.2f\n&amp;#34;, shape, s.Perimeter()) } 下面这是一段完整的代码，我们可以在 main() 中调用 PrintResult() 来获取正方形的周长和面积。</description></item><item><title>接收设计示例 三</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/%E6%8E%A5%E6%94%B6%E8%AE%BE%E8%AE%A1%E7%A4%BA%E4%BE%8B-%E4%B8%89/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/Method-AND-Interface/%E6%8E%A5%E6%94%B6%E8%AE%BE%E8%AE%A1%E7%A4%BA%E4%BE%8B-%E4%B8%89/</guid><description>与 示例二 类型，只不过 示例二 的接口中包含两个方法，可以去掉一个，只计算面积或者周长，那么就与本示例类似了
package contract // Contract 临时工类型，属性有ID和基本工资 type Contract struct { EmpID int Basicpay int } // CalculateSalary 临时员工的工资只有基本工资 func (c Contract) CalculateSalary() int { return c.Basicpay } package permanent // Permanent 永久员工类型，属性有ID和基本工资与附加工资 type Permanent struct { EmpID int Basicpay int Pf int } // CalculateSalary 永久员工的工资是基本工资和附加工资的综合 func (p Permanent) CalculateSalary() int { return p.Basicpay + p.Pf } package main import ( &amp;#34;fmt&amp;#34; &amp;#34;reflect&amp;#34; ) // SalaryCalculator 薪酬计算器接口，包含一个计算薪酬的方法 type SalaryCalculator interface { CalculateSalary() int } // 在 salary/ 下定义了两个结构体及其方法，结构体实现了 SalaryCalculator 接口 // TotalExpense 通过迭代 SalaryCalculator 切片并总结各个员工的工资来计算总费用 func TotalExpense(s []SalaryCalculator) { expense := 0 // 通过接口的切片s来获取其内每个元素的值v，根据其所对应的结构体类型，来引用相应的方法。 // 虽然变量v的类型会变成不同的结构体类型，但是本质上，变量v依然是接口 for index, v := range s { fmt.</description></item><item><title>揭开Wayland的面纱（一）：X Window的前生今世</title><link>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/freedesktop/Wayland/%E6%8F%AD%E5%BC%80Wayland%E7%9A%84%E9%9D%A2%E7%BA%B1%E4%B8%80X-Window%E7%9A%84%E5%89%8D%E7%94%9F%E4%BB%8A%E4%B8%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/11.%E5%A4%9A%E5%AA%92%E4%BD%93/%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/Linux-%E5%9B%BE%E5%BD%A2%E5%A4%84%E7%90%86/freedesktop/Wayland/%E6%8F%AD%E5%BC%80Wayland%E7%9A%84%E9%9D%A2%E7%BA%B1%E4%B8%80X-Window%E7%9A%84%E5%89%8D%E7%94%9F%E4%BB%8A%E4%B8%96/</guid><description>今天大家可能在&amp;quot;Wow! Ubuntu&amp;quot;或其他地方看到了这篇文章：Ubuntu 决定未来将启用 Wayland X-Server。
Wayland 是什么呢？它是 X Window？还是要取代 X Window？它的优势在哪里？Linux 桌面/移动会因此有什么变化？在本篇中，我将回顾历史，展望未来，通过简易的文字，来先回顾一下 X Window，从而继续解答 Wayland。
注：在下对 X Window 的理解仅限于表面，文章中会有不少技术、历史方面的错误，若有大侠指出，不胜感激！
古老的 X Window 和现代的桌面技术
X Window 在 1984 年由 MIT 研发，它的设计哲学之一是：提供机制，而非策略。举个最简单的例子吧：X Window 提供了生成窗口（Window）的方法，但它没规定窗口要怎么呈现（map）或摆放（place），这个策略是由外部程序&amp;mdash;- 窗口管理器（Window Manager）所决定的。另外一个 X Window 的主要特点便是：Server/Client 网络模型。不论是本地、远程的应用程序，都统一通过 Server/Client 模型来运作，比如：让远程的应用程序跑在本地上。
X Window 在推出之后快速演化，在 1987 年时候，其核心协议已经是第 11 版本了，简称：x11。这个版本已经将&amp;quot;提供机制，而非策略&amp;quot;这个哲学贯彻地非常彻底，以致于核心协议基本稳定，不需要特别大的改动。于是乎，你看到了，现在是 2010 年，整整 23 年了，X Window 依然是 X11。
你可能会诧异，23 年了，X Window 的核心都没有特别大的变化，它能适应现代桌面的快速发展吗？这就要再次提到 X Window 的设计优势了，X Window 在核心层之外提供一个扩展层，开发者可以开发相应扩展，来实现自己的扩展协议，比方说：
标准的 Window 都是矩形的，我如何用它来画一个圆形的窗口？X Window 协议并未提供，但是通过&amp;quot;shape&amp;quot;这个扩展，X Window 可以实现不规则的窗体。</description></item><item><title>进入容器文件系统</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/%E8%BF%9B%E5%85%A5%E5%AE%B9%E5%99%A8%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/%E8%BF%9B%E5%85%A5%E5%AE%B9%E5%99%A8%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</guid><description>概述 参考：
公众号-CNCF，容器文件在哪？检查容器文件系统 如果你经常使用容器，那么你很有可能希望在某个时刻查看正在运行的容器的文件系统。也许容器无法正常运行，你想读取一些日志，也许你想检查容器内部的一些配置文件… 或者，你可能像我一样，想在该容器中的二进制文件上放置一些 eBPF 探针（稍后将详细介绍）。
不管原因是什么，在这篇文章中，我们将介绍一些可以用来检查容器中的文件的方法。
我们将从研究容器文件系统的简单和通常推荐的方法开始，并讨论为什么它们不能总是工作。接下来，我们将对 Linux 内核如何管理容器文件系统有一个基本的了解，我们将利用这一了解以不同但仍然简单的方式检查文件系统。
方法一：Exec 到容器中 如果你快速搜索如何检查容器的文件系统，你会发现一个常见的解决方案是使用 Docker 命令：
docker exec -it mycontainer /bin/bash 这是一个很好的开始。如果它能满足你的所有需求，你应该继续使用它。
然而，这种方法的一个缺点是，它需要在容器中存在一个 shell。如果容器中没有 / bin/bash、/bin/sh 或其他 shell，那么这种方法将不起作用。例如，我们为 Pixie 项目构建的许多容器都是基于无 distroless 的，并且没有包含一个 shell 来保持镜像较小。在这些情况下，这种方法不起作用。
即使 shell 可用，你也无法访问所有你习惯使用的工具。因此，如果容器中没有安装 grep，那么你也不能访问 grep。这是另一个找更好工作的理由。
方法二：使用 nsenter 如果你再深入一点，就会意识到容器进程与 Linux 主机上的其他进程一样，只是在命名空间中运行，以使它们与系统的其他部分隔离。
所以你可以使用 nsenter 命令来输入目标容器的命名空间，使用类似这样的东西：
# Get the host PID of the process in the container PID=$(docker container inspect mycontainer | jq &amp;#39;.[0].State.Pid&amp;#39;) # Use nsenter to go into the container’s mount namespace.</description></item><item><title>进制表示法</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E8%BF%9B%E5%88%B6%E8%A1%A8%E7%A4%BA%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/Data-type/%E8%BF%9B%E5%88%B6%E8%A1%A8%E7%A4%BA%E6%B3%95/</guid><description>概述 参考：
Bytes 以 十进制、十六进制、etc. 表示
e.g. WireShark 可以看到传输的 Bytes 的十六进制表示法，及这些 Bytes 对应的 ASCII、etc.
为什么十六进制数字以 0x 开头？ https://qastack.cn/programming/2670639/why-are-hexadecimal-numbers-prefixed-with-0x
为什么十六进制数字以前缀0x？我了解前缀的用法，但不了解0x选择为什么的意义。
现在，我意识到标题和文本提出了两个完全不同的问题。大多数答复都集中在标题中的问题上。文本中问题的答案很简单：“它没有任何意义，它只是一个前缀，告诉编译器整数以十六进制表示”。— Andreas Rejbrand
为了学究，可能还会以两种不同的方式解释标题中的问题：1）“为什么十六进制数字以 0x 为前缀，而不是其他任何前缀或指示符？” 2）“为什么在输入十六进制数字时需要使用前缀？即使没有前缀，编译器肯定会识别 58A 为十六进制数字吗？” 对问题的第二种解释的答案很简单。“ 123”也是十六进制数。— Andreas Rejbrand
Answers 简单地说：在0告诉它在处理一个恒定的（而不是一个标识符/保留字）的解析器。仍然需要指定数字基数：x是任意选择。
长话短说：在 60 年代，流行的编程数字系统是十进制和_八进制_ -大型机每字节有 12、24 或 36 位，可以很好地将其除以 3 = log2（8）。
BCPL 语言将语法8 1234用于八进制数字。当 Ken Thompson 从 BCPL 创建 B 时，他改用了0前缀。这很好，因为
现在，整数常量始终由单个标记组成， 解析器仍然可以立即告诉它有一个常数， 解析器可以立即告诉基准（0两个基准都相同）， 从数学上讲是理智的（00005 == 05）， 不需要珍贵的特殊字符（如中的#123）。 从 B 创建 C 时，就需要使用十六进制数字（PDP-11 具有 16 位字），并且以上所有点仍然有效。由于其他机器仍需要八进制数，0x因此可以任意选择八进制数（00可能被排除在尴尬之外）。</description></item><item><title>开源软件洞察</title><link>https://desistdaydream.github.io/docs/Utils/%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E6%B4%9E%E5%AF%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E6%B4%9E%E5%AF%9F/</guid><description>概述 OSS Insight 从 https://ossinsight.io/ 这里可以查看各种开源软件的数据，效果如下：</description></item><item><title>控制结构</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/</guid><description>概述 每一个程序如何运行，其中的数据是如何进行传递的，是通过控制结构来实现的，程序的控制结构是指以某种顺序执行的一系列动作，用于解决某个问题。无论多么复杂的算法，均可通过顺序、选择、循环 3 中基本机构构造出来。每种结构仅有一个执行开始的入口以及执行结束的出口。由着 3 中基本机构组成的多层嵌套程序称为结构化程序
控制结构中的“条件语句”详见 条件语句与运算
一：顺序结构 按照语句编写的顺序自上到下主句执行就是顺序结构
二：选择结构 if&amp;hellip;;then&amp;hellip;;fi 选择结构 对某语句进行判断，判断完成后执行某动作。i.e.如果条件语句 1 为真,那么执行分支 1 语句,否则执行条件语句 2,如果条件语句 2 为真,那么执行分支 2 语句,否则执行条件语句 3,如果条件语句 3 为真,那么执行分支 3 语句,&amp;hellip;&amp;hellip;&amp;hellip;.(可无限循环),否则执行分支 n 语句
语法结构：
###单分支：如果“条件语句”为真，则执行“分支” if 条件语句;then 分支 fi ###双分支：如果“条件语句”为真，则执行“分支1”，否则执行“分支2” if 条件语句; then 分支1 else 分支2 fi ###多分支：如果“条件语句”为真，则执行“分支1”，否则如果“条件语句2”为真，则执行“分支2”...以此类推 if 条件语句1; then 分支1 elif 条件语句2; then 分支2 elif 条件语句3; then 分支3 ... else 分支n; fi case 判断结构 给定一个变量，当变量的值为某值时，执行某程序
语法结构：
case $参数变量 in &amp;#34;变量值1&amp;#34;） # 变量值用双引号括起来，关键字用小括号括起来 程序段1 # 对应的逻辑 ;; # 每个类别结尾使用两个连续的分号来处理 &amp;#34;变量值2&amp;#34;） 程序段2 ;; &amp;#34;变量值3&amp;#34;） 程序段3 ;; *) # 最后一个位置参数值会用*来代替所有其他值 程序段4 ;; esac 三：循环控制语句 for 循环结构 持续对一个变量赋值之后并执行相关命令，直到变量使用完所有给定的值</description></item><item><title>控制结构与变量</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84%E4%B8%8E%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Helm/Helm-Template/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84%E4%B8%8E%E5%8F%98%E9%87%8F/</guid><description>Control Structures 控制结构 参考：官方文档
控制结构在模板板中被称为 actions(动作)
Helm 模板中有如下几种控制结构：
if/else # 一个条件判断的代码块 with # 用于更改当前作用域 range # 用于循环遍历数组或者 map。 除此之外，还提供了一些声明和使用命名模板的控制结构：
define # 在模板中声明一个新的命名模板 template # 导入一个命名模板 block # 声明了一种特殊的可填写模板区域 define、template、block 这三种控制结构，放在 named template(命名模板) 中进行详解，详见：Named Templates(命名模板)
在下文的各种示例中，我们使用下面这种数据，来让各种控制结构进行处理，values.yaml 文件如下：
favorite: drink: water food: sushi game: &amp;#39;WOW &amp;amp; PAL&amp;#39; sushiKinds: - sashimi - name: hot - name: handRoll rice: more - name: IF/ELSE if/else 判断语句的语法如下：
{{ if PIPELINE }} # Do something {{ else if OTHER PIPELINE }} # Do something else {{ else }} # Default case {{ end }} 当 PIPELINE 值为以下内容，判定为 false：</description></item><item><title>跨域</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%AE%A1%E7%90%86/%E8%B7%A8%E5%9F%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/HTTP/HTTP-%E7%AE%A1%E7%90%86/%E8%B7%A8%E5%9F%9F/</guid><description>什么是跨域？怎么解决跨域问题？ 原文链接：https://www.huaweicloud.com/articles/aac70d91034fc29ba92cde78f0b867f8.html
什么是跨域？ 跨域，指的是浏览器不能执行其他网站的脚本。它是由浏览器的同源策略造成的，是浏览器对JavaScript施加的安全限制。 所谓同源是指，域名，协议，端口均相同，不明白没关系，举个栗子： http://www.123.com/index.html 调用 http://www.123.com/server.PHP （非跨域） http://www.123.com/index.html 调用 http://www.456.com/server.php （主域名不同:123/456，跨域） http://abc.123.com/index.html 调用 http://def.123.com/server.php （子域名不同:abc/def，跨域） http://www.123.com:8080/index.html 调用 http://www.123.com:8081/server.php （端口不同:8080/8081，跨域） http://www.123.com/index.html 调用 https://www.123.com/server.php （协议不同:http/https，跨域） 请注意：localhost 和 127.0.0.1 虽然都指向本机，但也属于跨域。
浏览器执行javascript脚本时，会检查这个脚本属于哪个页面，如果不是同源页面，就不会被执行。
解决办法：
1、JSONP：
使用方式就不赘述了，但是要注意 JSONP 只支持 GET 请求，不支持 POST 请求。
JSONP 原理 ajax 请求受同源策略影响，不允许进行跨域请求，而 script 标签 src 属性中的链接却可以访问跨域的 js 脚本，利用这个特性，服务端不再返回 JSON 格式的数据，而是返回一段调用某个函数的 js 代码，在 src 中进行了调用，这样实现了跨域。 jsonp 其实是一种特定的格式，一般是 fun(json 格式参数)， 服务端：
header('Content-type: application/json'); //获取回调函数名 $jsoncallback = htmlspecialchars($_REQUEST ['jsoncallback']); //json数据 $json_data = '[&amp;quot;customername1&amp;quot;,&amp;quot;customername2&amp;quot;]'; //输出jsonp格式的数据 echo $jsoncallback .</description></item><item><title>命令行标志</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A0%87%E5%BF%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A0%87%E5%BF%97/</guid><description>概述 参考：
官方文档，用户指南-命令行参数 命令行标志详解 &amp;ndash;annotations-prefix(STRING) # 读取 Ingress 对象的 metadata.annotations 下的字段前缀，只有匹配到前缀的字段才会当做配置处理。默认值: nginx.ingress.kubernetes.io
&amp;ndash;controller-class(STRING) # Ingress Class Controller value this Ingress satisfies.默认值：k8s.io/ingress-nginx
想要控制器使用对应的 Ingress，该标志的值，需要与 ingressClass 资源中 spec.controller 的值相同 通常来说，在部署 Nginx ingress controller 时，都是同时部署一个 ingressClass 资源 &amp;ndash;publish-service(STRING) # 与 controller-class 功能一起来定位控制器应该使用哪个 ingressClass 的 Ingress 资源
&amp;ndash;maxmind-license-key(STRING) # 从 MaxMind 下载 GeoLite2 数据库时所需的 License Key。</description></item><item><title>命令行工具</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/BIND/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/DNS/BIND/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>注意： dig、nslookup 工具无法获取 /etc/hosts 文件内的信息。
dig 工具 dig [OPTIONS] NAME [@Server] [Query Options] # 用于测试 DNS 系统，因此不会查询 hosts 文件进行解析
OPTIONS
-t # 选择解析的资源类型 -x # 通过 ip 查找域名 Query Options:
+trace # 跟踪解析过程，在屏幕上显示解析的全部过程，包括去找哪台服务，重定向到哪台服务器等 EXAMPLE
dig -t A baidu.com @192.168.0.1 # 用 192.168.0.1 这台机器解析 baidu.com 的 A 类型的域名 nslookup 工具 nslookup [OPTIONS] [NAME| -] [SERVER] # 可以查看默认的 DNS 服务器地址，和查看该服务器解析到的域名的 IP 地址
交互式命令：
server IP # 指明使用哪个 DNS Server 进行查询 q=RR-TYPE # 指明要解析的资源记录类型 NAME # 要查询的域名 OPTIONS</description></item><item><title>南北流量和东西流量</title><link>https://desistdaydream.github.io/docs/Standard/%E5%8D%97%E5%8C%97%E6%B5%81%E9%87%8F%E5%92%8C%E4%B8%9C%E8%A5%BF%E6%B5%81%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Standard/%E5%8D%97%E5%8C%97%E6%B5%81%E9%87%8F%E5%92%8C%E4%B8%9C%E8%A5%BF%E6%B5%81%E9%87%8F/</guid><description>概述 在 Service Mesh 微服务架构中，我们常常会听到东西流量和南北流量两个术语。
南北流量（NORTH-SOUTH traffic）和东西流量（EAST-WEST traffic）是数据中心环境中的网络流量模式。下面我们通过一个例子来理解这两个术语。
假设我们尝试通过浏览器访问某些 Web 应用。Web 应用部署在位于某个数据中心的应用服务器中。在多层体系结构中，典型的数据中心不仅包含应用服务器，还包含其他服务器，如负载均衡器、数据库等，以及路由器和交换机等网络组件。假设应用服务器是负载均衡器的前端。
当我们访问 web 应用时，会发生以下类型的网络流量：
客户端（位于数据中心一侧的浏览器）与负载均衡器（位于数据中心）之间的网络流量
负载均衡器、应用服务器、数据库等之间的网络流量，它们都位于数据中心。
南北流量
在这个例子中，前者即即客户端和服务器之间的流量被称为南北流量。简而言之，南北流量是 server-client 流量。
东西流量
第二种流量即不同服务器之间的流量与数据中心或不同数据中心之间的网络流被称为东西流量。简而言之，东西流量是 server-server 流量。
当下，东西流量远超南北流量，尤其是在当今的大数据生态系统中，比如 Hadoop 生态系统（大量 server 驻留在数据中心中，用 map reduce 处理），server-server 流量远大于 server-client 流量。
大家可能会好奇，东西南北，为什么这么命名。
该命名来自于绘制典型 network diagrams 的习惯。在图表中，通常核心网络组件绘制在顶部（NORTH），客户端绘制在底部（SOUTH），而数据中心内的不同服务器水平（EAST-WEST）绘制。</description></item><item><title>内核4.18版本以下导致slab内存过高问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%86%85%E6%A0%B84.18%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8B%E5%AF%BC%E8%87%B4slab%E5%86%85%E5%AD%98%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%86%85%E6%A0%B84.18%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8B%E5%AF%BC%E8%87%B4slab%E5%86%85%E5%AD%98%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98/</guid><description>参考：原文链接
问题背景 客户的 k8s 集群环境，发现所有的 worker 节点的 kubelet 进程的 CPU 使用率长时间占用过高，通过 pidstat 可以看到 CPU 使用率高达 100%。针对此问题对 kubelet 进程的异常进行问题排查。
集群环境 软件 版本 kubernetes v1.18.8 docker 18.09.9 rancher v2.4.8-ent CentOS 7.6 kernel 4.4.227-1.el7.elrepo.x86_64 排查过程 使用 strace 工具对 kubelet 进程进行跟踪 由于 kubelet 进程 CPU 使用率异常，可以使用 strace 工具对 kubelet 进程动态跟踪进程的调用情况，首先使用strace -cp &amp;lt;PID&amp;gt;命令统计 kubelet 进程在某段时间内的每个系统调用的时间、调用和错误情况. 从上图可以看到，执行系统调用过程中，futex 抛出了五千多个 errors，这肯定是不正常的，而且这个函数占用的时间也达到了 99%，所以需要更深层次的查看 kubelet 进程相关的调用。
由于strace -cp命令只能查看进程的整体调用情况，所以我们可以通过strace -tt -p &amp;lt;PID&amp;gt;命令打印每个系统调用的时间戳，如下： 从 strace 输出的结果来看，在执行 futex 相关的系统调用时，有大量的 Connect timed out，并返回了-1 和ETIMEDOUT的 error，所以才会在strace -cp中看到了那么多的 error。</description></item><item><title>配置详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-DNS-%E7%AE%A1%E7%90%86/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-DNS-%E7%AE%A1%E7%90%86/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
Manual(手册)，resolv.conf Manual(手册)，nsswitch.conf 公众号，重新夺回 /etc/resolv.conf 的控制权 /etc/resolv.conf 详解 该文件可以手动管理，或者由某个应用程序(e.g.NetworkManager)来管理。如果由应用程序管理，则会在文件开头以 # 进行备注
配置文件格式：每行以一个关键字开头，后面接一个或多个由空格隔开的参数。
下面是一个最简单的配置文件示例
nameserver 114.114.114.114 nameserver 202.96.128.166 关键字详解 nameserver IP # 指定用来进行域名解析的服务器地址 IP 可以是 ipv4 或者 ipv6 的地址，该关键字最多配置 3 个。当配置大于 1 个的 nameserver 时，则 reslover 按列出的顺序使用。
search STRING # 指定域名的搜索列表 解析域名时，会搜索 search 关键字指定的 STRING ，并将 STRING 附加到要解析的域名后方。效果如下：
~]# cat /etc/resolv.conf nameserver 114.114.114.114 ~]# ping www ping: www: Name or service not known ~]# cat /etc/resolv.conf nameserver 114.114.114.114 search qq.com ~]# ping www PING https.</description></item><item><title>配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Cilium/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/CNI/Cilium/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档</description></item><item><title>配置详解</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/OpenStack/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，配置指南 https://docs.openstack.org/rocky/configuration/</description></item><item><title>配置详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/SNMP-Exporter/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/SNMP-Exporter/%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考:
GitHub 项目，prometheus/snmp_exporter - generator generator.yml 文件详解 generator.yml 文件提供一个模块列表。 最简单的模块只需要具有一个名称和一组要 walk 的 OID
# 配置认证信息 auths: AuthName: # 自定义的认证名称名称。用于在 curl # SNMP 版本，默认为 2。 # 版本1使用 GETNEXT 方法发送 udp 请求、2和3版本使用 GETBULK 方法发送 udp 请求 version: 2 # 用于 SNMP 的 v1 和 v2 版本的认证信息 # 设置团体名字. 默认为&amp;#34;public&amp;#34;. community: public # SNMP 的 v3 版本的认证配置与 1，2 都不同，且更为复杂 # v3 has different and more complex settings. # Which are required depends on the security_level.</description></item><item><title>其他</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/%E5%85%B6%E4%BB%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP_IP/TCP/%E5%85%B6%E4%BB%96/</guid><description>我跟面试官聊 TCP 三次握手源码，他夸我真棒！ https://mp.weixin.qq.com/s/UHuey2WKzsdw6RR4aOT8rg
TCP 的 FIN_WAIT1 状态理解|深入理解 TCP https://mp.weixin.qq.com/s/ikKSEh20gBFcVOYDOtUiaw</description></item><item><title>启动引导</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Bootloader/%E5%90%AF%E5%8A%A8%E5%BC%95%E5%AF%BC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Bootloader/%E5%90%AF%E5%8A%A8%E5%BC%95%E5%AF%BC/</guid><description>grub2 详解(翻译和整理官方手册) https://www.cnblogs.com/f-ck-need-u/p/7094693.html
翻译了 grub2 官方手册的绝大部分内容，然后自己整理了一下。因为内容有点杂，所以章节安排上可能不是太合理，敬请谅解。
本人译作集合：http://www.cnblogs.com/f-ck-need-u/p/7048359.html
本文主要介绍的是 grub2，在文末对传统 grub 进行了简述，但在 grub2 的内容部分中包含了很多 grub2 和传统 grub 的对比。
如果仅仅是想知道 grub2 中的 boot.img/core.img/diskboot.img/kernel.img 或者传统 grub 中 stage1/stage1_5/stage2 文件的作用，请直接跳至相关内容处阅读。
1.1 基础内容 1.1.1 grub2 和 grub 的区别 官方手册原文：https://www.gnu.org/software/grub/manual/html_node/Changes-from-GRUB-Legacy.html#Changes-from-GRUB-Legacy
只说明几个主要的： 1.配置文件的名称改变了。在 grub 中，配置文件为 grub.conf 或 menu.lst(grub.conf 的一个软链接)，在 grub2 中改名为 grub.cfg。 2.grub2 增添了许多语法，更接近于脚本语言了，例如支持变量、条件判断、循环。 3.grub2 中，设备分区名称从 1 开始，而在 grub 中是从 0 开始的。 4.grub2 使用 img 文件，不再使用 grub 中的 stage1、stage1.5 和 stage2。 5.支持图形界面配置 grub，但要安装 grub-customizer 包，epel 源提供该包。 6.在已进入操作系统环境下，不再提供 grub 命令，也就是不能进入 grub 交互式界面，只有在开机时才能进入，算是一大缺憾。 7.</description></item><item><title>嵌入静态文件</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%B5%8C%E5%85%A5%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E8%A7%84%E8%8C%83%E4%B8%8E%E6%A0%87%E5%87%86%E5%BA%93/%E5%B5%8C%E5%85%A5%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
Go 包，标准库-embed https://colobu.com/2021/01/17/go-embed-tutorial/ embed 包可以让我们在编译时，将各种静态文件也编译进 Go 的二进制文件中。所以称之为 embed(嵌入)。 要使用 embed 包，除了导入以外，还需要在在声明变量时，添加注释 //go:ebed /PATH/TO/FILE 以使用 go:embed 指令，embed 包将会读取所有 .go 文件中的 go:embed 指令，并将其中的文件加载到变量中，该变量将会保存需要嵌入的静态文件。
注意，注释中 // 和后面的 go:ebed 中间不能有空格
go:ebed 指令有 3 种格式导入静态文件 一、将一个文件嵌入为字符格式
package main import ( _ &amp;#34;embed&amp;#34; &amp;#34;fmt&amp;#34; ) //go:embed hello.txt var s string func main() { fmt.Println(s) } 二、将一个文件嵌入为 bytes 切片
package main import ( _ &amp;#34;embed&amp;#34; &amp;#34;fmt&amp;#34; ) //go:embed hello.txt var b []byte func main() { fmt.</description></item><item><title>让 Pod 运行在指定 Node 上</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/%E8%AE%A9-Pod-%E8%BF%90%E8%A1%8C%E5%9C%A8%E6%8C%87%E5%AE%9A-Node-%E4%B8%8A/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Scheduling/%E8%AE%A9-Pod-%E8%BF%90%E8%A1%8C%E5%9C%A8%E6%8C%87%E5%AE%9A-Node-%E4%B8%8A/</guid><description>概述 参考：
官方文档，概念 - 调度、抢占、驱逐 - 让 Pod 运行在指定节点上 官方文档，概念 - 调度、抢占、驱逐 - 污点与容忍度 Kubernetes 内置的 标签、注释、污点 CSDN, k8s 之 pod 亲和与反亲和的 topologyKey 通常情况下 Scheduler(调度器) 将自动进行合理的分配(例如，将 Pods 分散到所有节点上，以防止单独节点上资源使用率远高于其他节点)。但是在某些情况下我们需要更多控制 Pods 落在某个指定的节点上，例如确保一个 Pod 部署在装有 SSD 的机器上，或者将两个不同服务中的 Pods 共同定位到同一可用区域。
所以我们需要 constrain(约束) Pod 运行在指定的节点。可以实现该效果的方式有以下几种：
nodeName(节点名称) # nodeSelector(节点选择器) # 根据节点的标签，选择 pod 要运行在哪个节点上 这种行为定义 Pod 必须在特定节点上运行。 Affinity(亲和) 与 Anti-Affinity(反亲和) # 根据亲和原则，让 pod 更趋向于与哪些 XXX 运行在同一个节点 这种行为定义 Pod 更倾向于在特定节点上运行。 Taint(污点) 与 Toleration(容忍度) # 根据节点上的污点，以及 pod 是否可以容忍该污点来决定 pod 是否可以运行在哪些节点上 其中 nodeSelector 和 Affinity 与 Anti-Affinity 是通过 Label Selectors(标签选择器) 来实现的。而 Taint 与 Toleration 是另一套类似于标签选择器的机制。</description></item><item><title>容器镜像管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</guid><description>概述 参考:
镜像加速 参考：
https://gist.github.com/y0ngb1n/7e8f16af3242c7815e7ca2f0833d3ea6 由于众所周知的原因，国内从 Docker Hub 拉取镜像会遇到困难，此时可以配置镜像加速器。
https://dockerproxy.com https://docker.m.daocloud.io https://github.com/DaoCloud/public-image-mirror 阿里云: https://&amp;lt;你的ID&amp;gt;.mirror.aliyuncs.com https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 2024-06-06 后不再可用 科大镜像: https://docker.mirrors.ustc.edu.cn/ 网易: https://hub-mirror.c.163.com/ 七牛云加速器: https://reg-mirror.qiniu.com 2024 年 6 月 6 日，中国加大封锁力度，所有镜像源先后下架不再提供服务。
https://x.com/whyyoutouzhele/status/1798731317322133642 https://linux.do/t/topic/106872 https://mp.weixin.qq.com/s/pXrxedldKOoD97bMDYy3pQ https://docker.m.daocloud.io 还能用来 pull 到一部分主流镜像
2024 年 9 月 10 日，可以不通过代理直接从 dockerhub pull 到镜像
可用镜像站点 &amp;#34;registry-mirrors&amp;#34;: [ &amp;#34;https://docker.m.daocloud.io&amp;#34;, &amp;#34;https://dockerhub.icu&amp;#34;, &amp;#34;https://docker.1panel.live&amp;#34;, &amp;#34;https://docker.anyhub.us.kg&amp;#34;, &amp;#34;https://dhub.kubesre.xyz&amp;#34; ], https://github.com/kubesre/docker-registry-mirrors
Skopeo 参考：
GitHub 项目，containers/skopeo https://www.modb.pro/db/251368 https://blog.k8s.li/skopeo.html Skopeo 是一个命令行客户端应用程序，可以对容器镜像和镜像存储库执行各种操作。
Syntax(语法) skopeo [FLAGS] COMMAND
list-tags - 列出指定镜像的所有 Tags sync - 同步一个或多个镜像从一个位置到另一个位置 sync 子命令可以将容器镜像从一个地方拷贝到另一个地方。</description></item><item><title>容器开发</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/%E5%AE%B9%E5%99%A8%E5%BC%80%E5%8F%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization/%E5%AE%B9%E5%99%A8%E5%BC%80%E5%8F%91/</guid><description>概述 参考：
GitHub 项目，google/go-containerregistry https://pkg.go.dev/github.com/google/go-containerregistry 公众号 - 云原生实验室，从 500 行 C 代码全面解析 Linux 容器底层工作机制 原文: https://arthurchiao.art/blog/linux-container-and-runtime-zh/ go-containerregistry 是一个用于控制容器镜像的 Go 库。这个库的整体设计理念是将容器镜像抽象为 3 个接口：
Image{} # 定义了与 OCI 标准的 Image 交互的接口 Layer{} # 定义了访问 OCI Image 标准的 Layer 的交互接口 ImageIndex{} # 定义了与 OCI Image 标准的 Index 交互的接口 这三个被抽象出来的接口可以通过多种 Medium(手段) 实现：
Registry(注册中心) # 控制各种容器镜像的 Registry 中的镜像。比如 docker.io、gcr.io 等等 由 remote 包实现 Tarball(压缩文件) # 控制 docker save 之类命令生成的 tarball 的镜像。 由 tarball 包实现 Daemon(守护进程) # 控制 Docker 守护进程中的镜像。这个包还不够完善 由 daemon 包实现 &amp;hellip;&amp;hellip; 等等。随着库的扩展，可以实现三个接口的 Medium 将会越来越多 用人话说：</description></item><item><title>容器运行时管理</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E7%AE%A1%E7%90%86/</guid><description>概述 参考：
容器运行时通常都是由实现容器的工具自己管理的，如果要说真正通用的管理，可能只有 runc 了，而 runc 本质就是通过类似 unshare、nsenter 等 Util-linux Utilities 包中的工具完成容器运行时的功能。
unshare - 创建 namesapce 参考：
Manual(手册)，unshare(1) Manual(手册)，unshare(2) 这是 System call 在新的 namespace 中运行程序。unshare 命令创建新的 namespace（由下面描述的命令行选项指定），然后执行指定的程序。如果未给出程序，则运行&amp;quot;${SHELL}&amp;quot;（默认值：/bin/sh）
nsenter - 使用其他进程的名称空间运行程序 参考：
Manual(手册)，nsenter(1) 就像这个工具的名字一样，nsenter(namespace enter)。进入一个或多个其他进程的名称空间，然后运行指定的程序。如果没有给出指定的程序(语法中的 PROGRAM)，则运行默认的 ${SHELL}。
Syntax(语法) nsenter [OPTIONS] [PROGRAM[ARGUMENTS]]
OPTIONS:
-a, &amp;ndash;all # 进入所有名称空间 -t, &amp;ndash;target &amp;lt;PID&amp;gt; # 指定要进入命名空间的目标进程的 PID -m, &amp;ndash;mount[=file]：进入 mount 命令空间。如果指定了 file，则进入 file 的命令空间 -u, &amp;ndash;uts[=file]：进入 uts 命令空间。如果指定了 file，则进入 file 的命令空间 -i, &amp;ndash;ipc[=file]：进入 ipc 命令空间。如果指定了 file，则进入 file 的命令空间 -n, &amp;ndash;net[=file]：进入 net 命令空间。如果指定了 file，则进入 file 的命令空间 -p, &amp;ndash;pid[=file]：进入 pid 命令空间。如果指定了 file，则进入 file 的命令空间 -U, &amp;ndash;user[=file]：进入 user 命令空间。如果指定了 file，则进入 file 的命令空间 -G, &amp;ndash;setgid gid：设置运行程序的 gid -S, &amp;ndash;setuid uid：设置运行程序的 uid -r, &amp;ndash;root[=directory]：设置根目录 -w, &amp;ndash;wd[=directory]：设置工作目录 EXAMPLE 从普通用户进入到 root 用户空间 sudo nsenter -t 1 -n 获取到容器的 PID docker inspect &amp;ndash;format &amp;ldquo;{{.</description></item><item><title>容器重启原理-Kubelet hash计算</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/%E5%AE%B9%E5%99%A8%E9%87%8D%E5%90%AF%E5%8E%9F%E7%90%86-Kubelet-hash%E8%AE%A1%E7%AE%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/kubelet-%E7%9B%B8%E5%85%B3/%E5%AE%B9%E5%99%A8%E9%87%8D%E5%90%AF%E5%8E%9F%E7%90%86-Kubelet-hash%E8%AE%A1%E7%AE%97/</guid><description>原文链接：https://mp.weixin.qq.com/s/8Txf6naaWaetTr2-sGyptg
在日常的开发工作中相信使用 Kubernetes 的同学们一定会偶尔收到容器重启的事件告警。由于应用层面的问题导致的容器重启相对容易排查，比如看容器的内存监控我们能确定是不是内存超过配置的 limit; 又或者看是不是应用有 panic 没有 recovery。 一个正常的工作日我们突然连续收到多条容器重启告警，查看报警还是来自不同的应用。按照一般的排查思路先去查看监控，内存没有异常，使用值一直在 limit 之下；然后去看日志也没有找到任何 panic 或者其他错误。仔细一看这几个告警的应用都是来自同一个集群，这个时候猜测大概率和集群有关系，但是这个集群我们还有其他很多应用并没有发生容器重启，所以猜测应该不是集群本身的问题，那是不是和机器有关系呢？然后我把重启过的实例所在的 node ip 都筛选出来发现重启的应用都是集中在某几台机器。在这些节点上我去查看了一下 kubelet进程，发现 kubelet 在容器告警的时间段都重启了进程。在这种情况下基本就找到了容器重启的直接原因&amp;ndash;kubelet 重启了。但是我们并没有更新实例，kubelet 重启怎么会把我们的容器重启呢？下面我们就介绍一下根本原因&amp;ndash;kubelet计算容器的 hash 值。 我们知道在 Kubernetes 中的节点上运行着 kubelet 进程，这个进程负责当前节点上所有 Pod 的生命周期。在这里我们从源码层面看看 kubelet 怎么实现容器的重启。
SyncPod 我们首先看 [https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/kuberuntime_manager.go](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/kuberuntime_manager.go) 中的 SyncPod 方法, 这个方法就是保证运行中的 Pod 与我们期望的配置时刻保持一致。通过以下步骤完成
根据从 API Server 获得的 Pod Spec 以及当前 Pod 的 Status 计算所需要执行的 Actions 在需要情况下 Kill 掉当前 Pod 的 sandbox 根据需要（如重启）kill 掉 Pod 内的 containers 根据需要创建 Pod 的 sandbox 启动下一个 init container 启动 Pod 内的 containers func (m *kubeGenericRuntimeManager) SyncPod(pod *v1.</description></item><item><title>如何避免 Go 命令行执行产生“孤儿”进程？</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D-Go-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%89%A7%E8%A1%8C%E4%BA%A7%E7%94%9F%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D-Go-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%89%A7%E8%A1%8C%E4%BA%A7%E7%94%9F%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/</guid><description>原文链接：如何避免 Go 命令行执行产生 “孤儿” 进程？
在 Go 程序当中，如果我们要执行命令时，通常会使用 exec.Command ，也比较好用，通常状况下，可以达到我们的目的，如果我们逻辑当中，需要终止这个进程，则可以快速使用 cmd.Process.Kill() 方法来结束进程。但当我们要执行的命令会启动其他子进程来操作的时候，会发生什么情况？
一 孤儿进程的产生 测试小程序：
func kill(cmd *exec.Cmd) func() { return func() { if cmd != nil { cmd.Process.Kill() } } } func main() { cmd := exec.Command(&amp;#34;/bin/bash&amp;#34;, &amp;#34;-c&amp;#34;, &amp;#34;watch top &amp;gt;top.log&amp;#34;) time.AfterFunc(1*time.Second, kill(cmd)) err := cmd.Run() fmt.Printf(&amp;#34;pid=%d err=%s\n&amp;#34;, cmd.Process.Pid, err) } 执行小程序：
go run main.go pid=27326 err=signal: killed 查看进程信息：
ps -j USER PID PPID PGID SESS JOBC STAT TT TIME COMMAND king 24324 1 24303 0 0 S s012 0:00.</description></item><item><title>如何实现rsync多并发同步？</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%85%B6%E4%BB%96/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0rsync%E5%A4%9A%E5%B9%B6%E5%8F%91%E5%90%8C%E6%AD%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%85%B6%E4%BB%96/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0rsync%E5%A4%9A%E5%B9%B6%E5%8F%91%E5%90%8C%E6%AD%A5/</guid><description>原文: https://mp.weixin.qq.com/s/py_AxuJ60YhKx329j7B_KA
前言
工作中经常会遇到 数据拷贝 或者 数据同步 事情。一般情况会使用 rsync 来做数据拷贝或者数据同步等。
问题 rsync 不能做并发同步，特别是需要拷贝 上 T 数据 时，rsync 一个进程拷贝有很大的瓶颈，不能把存储设备 IO 性能发挥的最好或者说把存储设备 IO 跑满。有什么方法让 rsync 实现多进程同步，并且自动识别目录下有多少个文件或者目录，不会出现重复性同步。
解决方法 下面是作者写的一个 shell 脚本，实现 rsync 多进程同步。
#!/usr/bin/env bash # Define source, target, maxdepth and cd to source source=&amp;#34;/tmp/tmp_data&amp;#34; target=&amp;#34;/tmp/tmp_data2&amp;#34; depth=3 cd &amp;#34;${source}&amp;#34; # Set the maximum number of concurrent rsync threads maxthreads=5 # How long to wait before checking the number of rsync threads again sleeptime=5 # Find all folders in the source directory within the maxdepth level find .</description></item><item><title>如何掌握所有的程序语言</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E5%A6%82%E4%BD%95%E6%8E%8C%E6%8F%A1%E6%89%80%E6%9C%89%E7%9A%84%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%81%87%E5%A6%82%E4%BD%A0%E6%9D%A5%E5%8F%91%E6%98%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/%E5%A6%82%E4%BD%95%E6%8E%8C%E6%8F%A1%E6%89%80%E6%9C%89%E7%9A%84%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/</guid><description>原文链接：王垠，如何掌握所有的程序语言
对的，我这里要讲的不是如何掌握一种程序语言，而是所有的……
很多编程初学者至今还在给我写信请教，问我该学习什么程序语言，怎么学习。由于我知道如何掌握“所有”的程序语言，总是感觉这种该学“一种”什么语言的问题比较低级，所以一直没来得及回复他们 :P 可是逐渐的，我发现原来不只是小白们有这个问题，就连美国大公司的很多资深工程师，其实也没搞明白。
今天我有动力了，想来统一回答一下这个搁置已久的“初级问题”。类似的话题貌似曾经写过，然而现在我想把它重新写一遍。因为在跟很多人交流之后，我对自己头脑中的（未转化为语言的）想法，有了更精准的表达。
如果你存在以下的种种困惑，那么这篇文章也许会对你有所帮助：
你是编程初学者，不知道该选择什么程序语言来入门。 你是资深的程序员或者团队领导，对新出现的种种语言感到困惑，不知道该“投资”哪种语言。 你的团队为使用哪种程序语言争论不休，发生各种宗教斗争。 你追逐潮流采用了某种时髦的语言，结果两个月之后发现深陷泥潭，痛苦不堪…… 虽然我已经不再过问这些世事，然而无可置疑的现实是，程序语言仍然是很重要的话题，这个情况短时间内不会改变。程序员的岗位往往会要求熟悉某些语言，甚至某些奇葩的公司要求你“深入理解 OOP 或者 FP 设计模式”。对于在职的程序员，程序语言至今仍然是可以争得面红耳赤的宗教话题。它的宗教性之强，以至于我在批评和调侃某些语言（比如 Go 语言）的时候，有些人会本能地以为我是另外一种语言（比如 Java）的粉丝。
显然我不可能是任何一种语言的粉丝，我甚至不是 Yin 语言的粉丝 ;) 对于任何从没见过的语言，我都是直接拿起来就用，而不需要经过学习的过程。看了这篇文章，也许你会明白我为什么可以达到这个效果。理解了这里面的东西，每个程序员都应该可以做到这一点。嗯，但愿吧。
重视语言特性，而不是语言 很多人在乎自己或者别人是否“会”某种语言，对“发明”了某种语言的人倍加崇拜，为各种语言的孰优孰劣争得面红耳赤。这些问题对于我来说都是不存在的。虽然我写文章批评过不少语言的缺陷，在实际工作中我却很少跟人争论这些。如果有其它人在我身边争论，我甚至会戴上耳机，都懒得听他们说什么 ;) 为什么呢？我发现归根结底的原因，是因为我重视的是“语言特性”，而不是整个的“语言”。我能用任何语言写出不错的代码，就算再糟糕的语言也差不了多少。
任何一种“语言”，都是各种“语言特性”的组合。打个比方吧，一个程序语言就像一台电脑。它的牌子可能叫“联想”，或者“IBM”，或者“Dell”，或者“苹果”。那么，你可以说苹果一定比 IBM 好吗？你不能。你得看看它里面装的是什么型号的处理器，有多少个核，主频多少，有多少 L1 cache，L2 cache……，有多少内存和硬盘，显示器分辨率有多大，显卡是什么 GPU，网卡速度，等等各种“配置”。有时候你还得看各个组件之间的兼容性。
这些配置对应到程序语言里面，就是所谓“语言特性”。举一些语言特性的例子：
变量定义 算术运算 for 循环语句，while 循环语句 函数定义，函数调用 递归 静态类型系统 类型推导 lambda 函数 面向对象 垃圾回收 指针算术 goto 语句 这些语言特性，就像你在选择一台电脑的时候，看它里面是什么配置。选电脑的时候，没有人会说 Dell 一定是最好的，他们只会说这个型号里面装的是 Intel 的 i7 处理器，这个比 i5 的好，DDR3 的内存 比 DDR2 的快这么多，SSD 比磁盘快很多，ATI 的显卡是垃圾…… 如此等等。
程序语言也是一样的道理。对于初学者来说，其实没必要纠结到底要先学哪一种语言，再学哪一种。曾经有人给我发信问这种问题，纠结了好几个星期，结果一个语言都还没开始学。有这纠结的时间，其实都可以把他纠结过的语言全部掌握了。
初学者往往不理解，每一种语言里面必然有一套“通用”的特性。比如变量，函数，整数和浮点数运算，等等。这些是每个通用程序语言里面都必须有的，一个都不能少。你只要通过“某种语言”学会了这些特性，掌握这些特性的根本概念，就能随时把这些知识应用到任何其它语言。你为此投入的时间基本不会浪费。所以初学者纠结要“先学哪种语言”，这种时间花的很不值得，还不如随便挑一个语言，跳进去。</description></item><item><title>深入 kube-proxy ipvs 模式的 conn_reuse_mode 问题</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/%E6%B7%B1%E5%85%A5-kube-proxy-ipvs-%E6%A8%A1%E5%BC%8F%E7%9A%84-conn_reuse_mode-%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/kube-proxy/%E6%B7%B1%E5%85%A5-kube-proxy-ipvs-%E6%A8%A1%E5%BC%8F%E7%9A%84-conn_reuse_mode-%E9%97%AE%E9%A2%98/</guid><description>在高并发、短连接的场景下，kube-proxy ipvs 存在 rs 删除失败或是延迟高的问题，社区也有不少 Issue 反馈，比如kube-proxy ipvs conn_reuse_mode setting causes errors with high load from single client。文本对这些问题进行了梳理，试图介绍产生这些问题的内部原因。由于能力有限，其中涉及内核部分，只能浅尝辄止。
背景 端口重用 一切问题来源于端口重用。在 TCP 四次挥手中有个TIME_WAIT的状态，作为先发送FIN包的一端，在接收到对端发送的FIN包后进入TIME_WAIT，在经过2MSL后才会真正关闭连接。TIME_WAIT状态的存在，一来可以避免将之前连接的延迟报文，作为当前连接的报文处理；二是可以处理最后一个 ACK 丢失带来的问题。 而在短连接、高并发的场景下，会出现大量的TIME-WAIT连接，导致资源无法及时释放。Linux 中内核参数net.ipv4.tcp_tw_reuse提供了一种减少TIME-WAIT连接的方式，可以将TIME-WAIT连接的端口分配给新的 TCP 连接，来复用端口。
tcp_tw_reuse - BOOLEAN Allow to reuse TIME-WAIT sockets for new connections when it is safe from protocol viewpoint. Default value is 0. It should not be changed without advice/request of technical experts. ipvs 如何处理端口重用？ ipvs 对端口的复用策略主要由内核参数net.ipv4.vs.conn_reuse_mode决定
conn_reuse_mode - INTEGER 1 - default Controls how ipvs will deal with connections that are detected port reuse.</description></item><item><title>深入理解Kubernetes Operator</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kubernetes-Operator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Operator-%E5%BC%80%E5%8F%91/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kubernetes-Operator/</guid><description>James Laverack InfoQ 11 月 18 日
作者 | James Laverack 译者 | 王者本文要点：
Kubernetes API 为所有云资源提供了单个集成点，以此来促进云原生技术的采用。
有一些框架和库可以用来简化 Operator 的编写。支持多种语言，其中 Go 生态系统是最为成熟的。
你可以为非自有的软件创建 Operator。DevOps 团队可能会通过这种方式来管理数据库或其他外部产品。
难点不在于 Operator 本身，而是要学会理解它的行为。
多年来，Operator 一直是 Kubernetes 生态系统的重要组成部分。通过将管理界面移动到 Kubneretes API 中，带来了“单层玻璃”的体验。对于希望简化 kuberentes 原生应用程序的开发人员或者希望降低现有系统复杂性的 DevOps 工程师来说，Operator 可能是一个非常有吸引力的选择。但如何从头开始创建一个 Operator 呢？
深入理解 OperatorOperator 是什么？
如今，Operator 无处不在。数据库、云原生项目、任何需要在 Kubernetes 上部署或维护的复杂项目都用到了 Operator。CoreOS 在 2016 年首次引入了 Operator，将运维关注点转移到软件系统中。Operator 自动执行操作，例如，Operator 可以部署数据库实例、升级数据库版本或执行备份。然后，这些系统可以被测试，响应速度比人类工程师更快。
Operator 还通过使用自定义资源定义对 Kubenretes API 进行了扩展，将工具配置转移到了 API 中。这意味着 Kubenretes 本身就变成了“单层玻璃”。DevOps 工程师可以利用围绕 Kubernetes API 资源而构建的工具生态系统来管理和监控他们部署的应用程序：</description></item><item><title>什么是微内核架构设计？</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/%E5%BE%AE%E5%86%85%E6%A0%B8/%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E5%86%85%E6%A0%B8%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/%E5%BE%AE%E5%86%85%E6%A0%B8/%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E5%86%85%E6%A0%B8%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</guid><description>阿里妹导读：作为一名 Java 程序员，相信同学们都听说过微内核架构设计，也有自己的理解。那么微内核是如何被提出来的？微内核在操作系统内核的设计中又有什么作用？本文从插件化(Plug-in)架构的角度来诠释微内核架构设计，通过微内核架构和微服务架构的对比，分享其对微服务设计的参考意义。
文末福利：技术公开课《微服务实战：Service Mesh 与 Istio》。
关于微内核架构设计现在比较热，听起来好像是操作系统内核相关的，作为 Java 程序员，操作系统内核那么遥远的事情，好像和我们没有什么关系。但是如果我说微内核其实就是插件化(Plug-in)架构，你一定会一脸疑惑，“你居然向 Java 程序员解释什么是插件化架构？我每天都在用啊，Eclipse、IntelliJ IDEA、OSGi、Spring Plugin、SPI 等，哪个不是插件化架构。我的一些项目也是采用插件化设计的，如使用插件实现流程控制定制等等”。但是别着急，即便是我们每天都在使用的技术，而且大多数人也都知道，如果我们能将其阐述得更清楚，并且能从中发现一些问题，做出一些优化有助于以后的架构设计，那么大多数人在日常的设计和开发中都能受益，岂不是更好。现在我们就来聊一聊微内核架构设计。
一 微内核设计之操作系统内核
微内核设计其实就是插件体系。我们都知道，操作系统内核诞生得比较早，所以插件化最早被用在内核设计上，于是就有了微内核设计这一称呼。
微内核是这样一种内核：它只完成内核不得不完成的功能，包括时钟中断、进程创建与销毁、进程调度、进程间通信，而其他的诸如文件系统、内存管理、设备驱动等都被作为系统进程放到了用户态空间。说白了，微内核是相对于宏内核而言的，像 Linux 就是典型的宏内核，它除了时钟中断、进程创建与销毁、进程调度、进程间通信外，其他的文件系统、内存管理、输入输出、设备驱动管理都需要内核完成。
也就是说，微内核是相对宏内核而言的，宏内核是一个包含非常多功能的底层程序，也就是我们现在讲的 Monolith。它干的事情非常多，而且不是可插拔的，修改一些小的功能，都会涉及到整个程序的重新编译等，比如一个功能出现了一个小 bug，可能导致整个内核都出问题。这也是很多人将 Linux 称为 monolithic OS 的原因。而微内核只负责最核心的功能，其他功能都是通过用户态独立进程以插件方式加入进来，然后微内核负责进程的管理、调度和进程之间通讯，从而完成整个内核需要的功能。基本一个功能出现问题，但是该功能是以独立进程方式存在的，不会对其他进程有什么影响从而导致内核不可用，最多就是内核某一功能现在不可用而已。
微内核就是一个运行在最高级别的程序片段，它能完成用户态程序不能完成的一些功能。微内核通过进程间通信来协调各个系统进程间的合作，这就需要系统调用，而系统调用需要切换堆栈以及保护进程现场，比较耗费时间；而宏内核则是通过简单的函数调用来完成各个模块之间的合作，所以理论上宏内核效率要比微内核高。这个和微服务的架构设计一样，我们将 Monolith 应用划分为多个小应用后，系统的设计就变得比较复杂了，之前都是应用内部函数调用，现在要涉及网络通讯、超时等问题，同时响应时间会被拉长。
聊到这里，相信大家对微内核和宏内核已经有了一个大致的了解，看起来各有千秋。但是宏内核有一个最大的问题就是定制和维护陈本。现在的移动设备和 IoT 设备越来越多，如果要把一个庞大复杂的内核适配到某一设备上，是一件非常复杂的事情，如果很简单的话，那么把 Linux 内核适配到 Android 内核，甚至到 Tesla 等车载系统，基本上人人都可以做了。
因此我们更需要一个微内核的架构设计，方便定制，而且非常小，可以实现功能的热替换或者在线更新等，这就是微内核被提出来的核心需求。但是微内核有一个运行的效率问题，所以在微内核和宏内核之间，又有了 Hybrid 内核，主要是想拥有微内核的灵活性，同时在关键点上有宏内核的性能。微内核设计在理论上确实有效率问题，但是随着芯片设计、硬件性能提升等，这方面或许已经有了非常大的提升，已经不再是最关键的问题。
总体下来，内核设计有三个形式，如下：
二 插件化(Plug-in)架构设计
上面聊了微内核在操作系统内核设计中的作用，接下来我们就开始讨论更通用的插件化架构设计，毕竟这个词大家都明白。
插件化架构非常简单，就两个核心组件：系统核心(Core System)和插件化组件(Plug-in component)。Core System 负责管理各种插件，当然 Core System 也会包含一些重要功能，如插件注册管理、插件生命周期管理、插件之间的通讯、插件动态替换等。整体结构如下：
插件化架构对微服务架构设计帮助非常大，考虑到隔离性，插件可能是以独立进程方式运行的，那么这些进程如果扩展到网络上，分布在众多的服务器上，这个就是微服务架构的原型，所以了解微内核的同学都不屑于和你讨论微服务架构，相信你也明白了，除了 IT 传统的鄙视链因素，原理上确实就是这么回事。
回到微服务架构设计场景，我们将 Plug-in component 重新命名为服务(Service)，这个和微内核设计中的服务也差不多，这个时候微服务和微内核就差不多了，都涉及到服务注册、管理和服务之间的通讯等。那我们看一下微内核是如何解决服务之间的通讯问题的？以下摘自维基百科：
因为所有服务行程都各自在不同地址空间运行，因此在微核心架构下，不能像宏内核一样直接进行函数调用。在微核心架构下，要创建一个进程间通信机制，通过消息传递的机制来让服务进程间相互交换消息，调用彼此的服务，以及完成同步。采用主从式架构，使得它在分布式系统中有特别的优势，因为远程系统与本地进程间，可以采用同一套进程间通信机制。
也就是说，采取的是基于消息的进程间通讯机制。消息最简单，就两个接口：send 和 receive，消息发送出去，然后等着收消息，处理后再发消息就可以了，这里大家应该也知道了，这个是异步的。回到插件化架构设计中，Plug-in 组件设计包含交互规范，也就是和外界相互通讯的接口，如果是基于消息通讯的话，就是 send 和 receive 接口，可以说是非常简单的。</description></item><item><title>神秘！申请内存时底层发生了什么？</title><link>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A5%9E%E7%A7%98%E7%94%B3%E8%AF%B7%E5%86%85%E5%AD%98%E6%97%B6%E5%BA%95%E5%B1%82%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/blog/copy/%E5%85%AC%E4%BC%97%E5%8F%B7%E7%A0%81%E5%86%9C%E7%9A%84%E8%8D%92%E5%B2%9B%E6%B1%82%E7%94%9F-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%9D%E9%A2%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E7%A5%9E%E7%A7%98%E7%94%B3%E8%AF%B7%E5%86%85%E5%AD%98%E6%97%B6%E5%BA%95%E5%B1%82%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/</guid><description>参考：公众号,码农的荒岛求生
内存的申请释放对程序员来说就像空气一样自然，你几乎不怎么能意识到，有时你意识不到的东西却无比重要，申请过这么多内存，你知道申请内存时底层都发生什么了吗？
大家都喜欢听故事，我们就从神话故事开始吧。
三界 中国古代的神话故事通常有 “三界” 之说，一般指的是天、地、人三界，天界是神仙所在的地方，凡人无法企及；人界说的是就是人间；地界说的是阎罗王所在的地方，孙悟空上天入地无所不能就是说可以在这三界自由出入。
有的同学可能会问，这和计算机有什么关系呢？
原来，我们的代码也是分三六九等的，程序运行起来后也是有 “三界” 之说的，程序运行起来的 “三界” 就是这样的：
x86 CPU 提供了 “四界”：0,1,2,3，这几个数字其实就是指 CPU 的几种工作状态，数字越小表示 CPU 的特权越大，0 号状态下 CPU 特权最大，可以执行任何指令，数字越大表示 CPU 特权越小，3 号状态下 CPU 特权最小，不能执行一些特权指令。
一般情况下系统只使用 0 和 3，因此确切的说是 “两界”，这两界可不是说天、地，这两界指的是“用户态(3)” 以及“内核态(0)”，接下来我们看看什么是内核态、什么是用户态。
内核态 什么是内核态？当 CPU 执行操作系统代码时就处于内核态，在内核态下 CPU 可以执行任何机器指令、访问所有地址空间、不受限制的访问任何硬件，可以简单的认为内核态就是 “天界”，在这里的代码(操作系统代码) 无所不能。
用户态 什么是用户态？当 CPU 执行我们写的 “普通” 代码 (非操作系统、驱动程序员) 时就处于用户态，粗糙的划分方法就是除了操作系统之外的代码，就像我们写的 HelloWorld 程序。
用户态就好比 “人界”，在用户态我们的代码处处受限，不能直接访问硬件、不能访问特定地址空间，否则神仙(操作系统) 直接将你 kill 掉，这就是著名的 Segmentation fault、不能执行特权指令，等等。
关于这一部分的详细讲解，请参见《深入理解操作系统》系列文章。
跨界 孙悟空神通广大，一个跟斗就能从人间跑到天上去骂玉帝老儿，程序员就没有这个本领了。普通程序永远也去不了内核态，只能以通信的方式从用户态往内核态传递信息。
操作系统为普通程序员留了一些特定的暗号，这些暗号就和普通函数一样，程序员通过调用这些暗号就能向操作系统请求服务了，这些像普通函数一样的暗号就被称为系统调用，System Call，通过系统调用我们可以让操作系统代替我们完成一些事情，像打开文件、网络通信等等。
你可能有些疑惑，什么，还有系统调用这种东西，为什么我没调用过也可以打开文件、进行网络通信？
标准库 虽然我们可以通过系统让操作系统替我们完成一些特定任务，但这些系统调用都是和操作系统强相关的，Linux 和 Windows 的系统调用就完全不同。</description></item><item><title>实现应用灰度发布</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%94%A8%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%94%A8%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/</guid><description>概述 参考：
原文链接：公众号-运维开发故事，如何通过 ingress-nginx 实现应用灰度发布？ 在日常的工作中，我们会经常对应用进行发版升级，在互联网公司尤为频繁，主要是为了满足快速的业务发展。我们经常用到的发布方式有滚动更新、蓝绿发布、灰度发布。
滚动更新：依次进行新旧替换，直到旧的全部被替换为止。 蓝绿发布：两套独立的系统，对外提供服务的称为绿系统，待上线的服务称为蓝系统，当蓝系统里面的应用测试完成后，用户流量接入蓝系统，蓝系统将称为绿系统，以前的绿系统就可以销毁。 灰度发布：在一套集群中存在稳定和灰度两个版本，灰度版本可以限制只针对部分人员可用，待灰度版本测试完成后，可以将灰度版本升级为稳定版本，旧的稳定版本就可以下线了，我们也称之为金丝雀发布。 这里主要给大家分享如果通过 ingress-nginx controller 实现灰度发布。
本文大纲如下。
如何通过 ingress-nginx 实现灰度发布 ingress-nginx 是 Kubernetes 官方推荐的 ingress controller，它是基于 nginx 实现的，增加了一组用于实现额外功能的 Lua 插件。
为了实现灰度发布，ingress-nginx 通过定义 annotation 来实现不同场景的灰度发布，其支持的规则如下：
nginx.ingress.kubernetes.io/canary-by-header：基于 Request Header 的流量切分，适用于灰度发布以及 A/B 测试。当 Request Header 设置为 always时，请求将会被一直发送到 Canary 版本；当 Request Header 设置为 never时，请求不会被发送到 Canary 入口；对于任何其他 Header 值，将忽略 Header，并通过优先级将请求与其他金丝雀规则进行优先级的比较。 nginx.ingress.kubernetes.io/canary-by-header-value：要匹配的 Request Header 的值，用于通知 Ingress 将请求路由到 Canary Ingress 中指定的服务。当 Request Header 设置为此值时，它将被路由到 Canary 入口。该规则允许用户自定义 Request Header 的值，必须与上一个 annotation (即：canary-by-header）一起使用。 nginx.</description></item><item><title>使用 Go 构建 Kubernetes 应用</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/%E4%BD%BF%E7%94%A8-Go-%E6%9E%84%E5%BB%BA-Kubernetes-%E5%BA%94%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/%E4%BD%BF%E7%94%A8-Go-%E6%9E%84%E5%BB%BA-Kubernetes-%E5%BA%94%E7%94%A8/</guid><description>使用 Go 构建 Kubernetes 应用
Kubernetes 项目使用 Go 语言编写，对 Go api 原生支持非常便捷。本篇文章介绍了如何使用 kubernetes client-go 实践一个简单的与 K8s 交互过程。
kubernetes 的 Go Client 项目（client-go） go client 是 k8s client 中最古老的一个，具有很多特性。Client-go 没有使用 Swagger 生成器，它使用的是源于 k8s 项目中的源代码生成工具，这个工具的目的是要生成 k8s 风格的对象和序列化程序。
该项目是一组包的集合，该包能够满足从 REST 风格的原语到复杂 client 的不同的编程需求。
RESTClient 是一个基础包，它使用api-machinery库中的类型作为一组 REST 原语提供对 API 的访问。作为对RESTClient之上的抽象，_clientset_将是你创建 k8s client 工具的起点。它暴露了公开化的 API 资源及其对应的序列化。
注意：在 client-go 中还包含了如 discovery, dynamic, 和 scale 这样的包，虽然本次不介绍这些包，但是了解它们的能力还是很重要的。
一个简单的 k8s client 工具 让我们再次回顾我们将要构建的工具，来说明 go client 的用法。pvcwatch是一个简单的命令行工具，它可以监听集群中声明的 PVC 容量。当总数到达一个阈值的时候，他会采取一个 action（在这个例子中是在屏幕上通知显示）</description></item><item><title>使用 Thanos 查询前端优化查询性能</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/%E4%BD%BF%E7%94%A8-Thanos-%E6%9F%A5%E8%AF%A2%E5%89%8D%E7%AB%AF%E4%BC%98%E5%8C%96%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Prometheus/Prometheus-%E8%A1%8D%E7%94%9F%E5%93%81/Thanos/Thanos-%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/%E4%BD%BF%E7%94%A8-Thanos-%E6%9F%A5%E8%AF%A2%E5%89%8D%E7%AB%AF%E4%BC%98%E5%8C%96%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD/</guid><description>Thanos 中的 Query 组件可以提供一个统一的查询入口，但是当查询的数据规模较大的时候，对 querier 组件也会有很大的压力，为此 Thanos 也提供了一个 Query Frontend 的组件来提升性能。Thanos Query Frontend 是 Thanos Query 的前端，它的目标是将大型查询拆分为多个较小的查询，并缓存查询结果来提升性能。
概述 Thanos Query Frontend 组件通过 thanos query-frontend 命令实现了一个放在 querier 前面的服务，以改进读取路径。它基于 Cortex Query Frontend 组件，所以你可以找到一些 Cortex 常见的特性，如查询拆分和结果缓存。Thanos Query Frontend 是无状态和水平扩展的，可以使用下列命令来启动 Thanos Query Frontend：
thanos query-frontend \ --http-address &amp;quot;0.0.0.0:9090&amp;quot; \ --query-frontend.downstream-url=&amp;quot;&amp;lt;thanos-querier&amp;gt;:&amp;lt;querier-http-port&amp;gt;&amp;quot;
在接收到查询请求后 query frontend 不会立即响应，而是将查询请求放入一个查询队列中，querier 会连接到 query frontend 并消费这个队列，执行从队列中获取的查询请求并响应给 query frontend，query frontend 会对这些响应的结果进行聚合。
特性 查询队列 query frontend 的队列机制有以下用途。
确保可能导致 OOM 的大型查询在发生错误时能够得到重试。
防止多个大的查询请求打在单个 querier 上。
可以分配租户所对应的 querier，避免单个租户使用 DOS 拒绝服务攻击其他租户。</description></item><item><title>使用 Tini 清理 Docker 容器僵死进程</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E4%BD%BF%E7%94%A8-Tini-%E6%B8%85%E7%90%86-Docker-%E5%AE%B9%E5%99%A8%E5%83%B5%E6%AD%BB%E8%BF%9B%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Containerization-implementation/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/%E4%BD%BF%E7%94%A8-Tini-%E6%B8%85%E7%90%86-Docker-%E5%AE%B9%E5%99%A8%E5%83%B5%E6%AD%BB%E8%BF%9B%E7%A8%8B/</guid><description>使用 Tini 清理 Docker 容器僵死进程
最近在Tini的仓库下看到作者对Tini优势的精彩回复，搬运过来，粗糙翻译，献给拥有同样疑惑的你。
写在前面 我们在查看一些大项目的Dockerfile时经常发现，它们的ENTRYPOINT中往往都有tini的身影：
Rancher官方镜像
Jenkins官方镜像
那Tini到底是什么？为什么大家都喜欢在镜像中使用它呢？
开发者的疑问 我注意到Jenkins的官方镜像中使用了Tini，所以我很好奇它是什么。它看起来一定很有用，可能解决了一些我不知道的问题。你能用“说人话”的方式简单解释一下Tini相对于直接以CMD运行shell脚本的优势吗？
我的几个容器的ENTRYPOINT都设置了一个 docker-entrypoint.sh 脚本，里面基本上都是以“exec &amp;ldquo;$@&amp;quot;”的方式在运行，我应该使用Tini来代替吗？
来自作者的回复 问得好！但这解释可能有点长，所以请耐心听我说（我知道你要求简短，但我真的做不到，捂脸~）。
首先，我们先简单聊聊Jenkins。当您运行Docker容器时，Docker会将它与系统的其他部分隔离开来。这种隔离发生在不同的级别（例如网络、文件系统、进程）。
但Tini并不真正关注网络或文件系统，所以让我们把注意力放在Tini的一个重要概念上：进程。
每个Docker容器都是一个PID命名空间，这意味着容器中的进程与主机上的其他进程是隔离的。PID命名空间是一棵树，从PID 1开始，通常称为init。
注意：当你运行一个Docker容器时，镜像的ENTRYPOINT就是你的根进程，即PID 1（如果你没有ENTRYPOINT，那么CMD就会作为根进程，你可能配置了一个shell脚本，或其他的可执行程序，容器的根进程具体是什么，完全取决于你的配置）。
与其他进程不同的是，PID 1有一个独特的职责，那就是收割“僵尸进程”。
那何为“僵尸进程”呢？
“僵尸进程”是指：
已经退出。 没有被其父进程wait（wait是指syscall父进程用于检索其子进程的退出代码）。 父进程已丢失（也就是说，它们的父进程已经不存在了)，这意味着他们永远不会被其父进程处理。 当“僵尸进程”被创建时（也就是说，一旦它的父进程非正常退出了，它也就跟着无法正常退出了），它会继承成为PID 1的子级，最后PID 1会负责关闭它。
换句话说，有人必须在“不负责任”的父进程离开后，对这些“孤儿”进行清理，这是PID 1的作用。
请注意，创建“僵尸进程”通常是不被允许的（也就是说，理想情况下，您应该修复代码，这样就不会创建“僵尸进程”），但是对于像Jenkins这种应用来说，它们是不可避免的：因为Jenkins通常运行的代码不是由Jenkins维护者编写的（也就是您的Jenkins构建脚本），所以他们也无法“修复代码”。
这就是Jenkins使用Tini的原因：在构建了创建“僵尸进程”的脚本后进行清理。
但其实Bash实际上也做同样的事情（收割“僵尸进程”），所以你可能会想：为什么不把Bash当作PID 1呢？
第一个问题是，如果您将Bash作为PID 1运行，那么您发送到Docker容器的所有信号（例如，使用docker stop或docker kill）最终都会发送到Bash，Bash默认不会将它们转发到任何地方（除非您自己编写代码实现）。换句话说，如果你使用Bash来运行Jenkins，那么当你运行docker stop的时候，Jenkins将永远收不到停止信号！
而Tini通过“信号转发”解决了这个问题：如果你向Tini发送信号，那么它也会向你的子进程发送同样的信号（在你的例子中是Jenkins）。
第二个问题是，一旦您的进程退出，Bash也会继续退出。如果您不小心，Bash可能会退出，退出代码为0，而您的进程实际上崩溃了（但0表示“一切正常”；这将导致Docker重启策略不符合您的预期）。因为您真正想要的可能是Bash返回与您的进程相同的退出代码。
请注意，您可以通过在Bash中创建信号处理程序来实际执行转发，并返回适当的退出代码来解决这个问题。另一方面，这需要做更多的工作，而添加Tini只是文档中的几行。
其实还有另一个解决方案可以将Jenkins作为PID 1运行，即在Jenkins中添加另一个线程来负责收割“僵尸进程”。
但这也不理想，原因有二：
首先，如果将Jenkins以PID 1的身份运行，那么很难区分继承给Jenkins的进程（应该被收割）和Jenkins自己产生的进程（不应该被收割，因为还有其他代码已经在等待它们执行）。我相信你可以用代码来解决这个问题，但还是要问一遍：当你可以把Tini放进去的时候，为什么还要写呢？
其次，如果Jenkins以PID 1运行，那么它可能不会接收到您发送的信号！
这是PID 1进程中的微妙之处。与其他进程不同的是，PID 1没有默认的信号处理程序，这意味着如果Jenkins没有明确地为SIGTERM安装信号处理程序，那么该信号在发送时将被丢弃（而默认行为是终止该过程）。
Tini确实安装了显式信号处理程序（顺便说一下，是为了转发信号），所以这些信号不再被丢弃。相反，它们被发送到Jenkins，Jenkins并不像PID 1（Tini ）那样运行，因此有默认的信号处理程序（注意：这不是Jenkins使用Tini的原因，Jenkins使用它来获取信号，但在RabbitMQ的镜像中是这个作用）。
请注意，Tini中还有一些额外的功能，在Bash或Java中很难实现（例如，Tini可以注册为“子收割者”，因此它实际上不需要作为PID 1运行来完成“僵尸进程”收割工作），但是这些功能对于一些高级应用场景来说非常有用。
希望以上内容对你有所帮助！
如果您有兴趣了解更多，以下是一些可供参考的资料：
僵尸进程详解：https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/ 更简洁的解释：https://github.com/docker-library/official-images#init 最后，请注意Tini还有更多的选择（比如Phusion的基础镜像）。
Tini的主要特性是：</description></item><item><title>使用 VNC 访问虚拟机</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/%E4%BD%BF%E7%94%A8-VNC-%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/KVM_QEMU/%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/%E4%BD%BF%E7%94%A8-VNC-%E8%AE%BF%E9%97%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/</guid><description>概述 参考：
在 rfbproto/rfbproto 的 #18 issue 中，表示 QEMU 中内置了 VNC/RFB，并对该协议进行了一些修改以支持一些额外的功能。所以，我们可以使用 VNC 客户端，使用 QEMU/KVM 为虚拟机暴露的 VNC 端口，连接到虚拟机(不管是 图形界面的虚拟机 还是 命令行界面的虚拟机)。
配置 VNC 监听地址 修改 qemu.conf 配置文件
# VNC is configured to listen on 127.0.0.1 by default. # To make it listen on all public interfaces, uncomment # this next option. # # NB, strong recommendation to enable TLS + x509 certificate # verification when allowing public access # vnc_listen = &amp;#34;0.</description></item><item><title>手动管理 Kubernetes 证书</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Kubernetes-%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/%E6%89%8B%E5%8A%A8%E7%AE%A1%E7%90%86-Kubernetes-%E8%AF%81%E4%B9%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Kubernetes-%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/%E6%89%8B%E5%8A%A8%E7%AE%A1%E7%90%86-Kubernetes-%E8%AF%81%E4%B9%A6/</guid><description>概述 参考：
官方文档，任务-管理集群-证书 在使用客户端证书认证的场景下，你可以通过 easyrsa、openssl 或 cfssl 等工具以手工方式生成证书。
easyrsa easyrsa 支持以手工方式为你的集群生成证书。
下载、解压、初始化打过补丁的 easyrsa3。 curl -LO https://storage.googleapis.com/kubernetes-release/easy-rsa/easy-rsa.tar.gz tar xzf easy-rsa.tar.gz cd easy-rsa-master/easyrsa3 ./easyrsa init-pki 生成新的证书颁发机构（CA）。参数 --batch 用于设置自动模式； 参数 --req-cn 用于设置新的根证书的通用名称（CN）。
./easyrsa &amp;ndash;batch &amp;ldquo;&amp;ndash;req-cn=${MASTER_IP}@date +%s&amp;rdquo; build-ca nopass
生成服务器证书和秘钥。 参数 --subject-alt-name 设置 API 服务器的 IP 和 DNS 名称。 MASTER_CLUSTER_IP 用于 API 服务器和控制管理器，通常取 CIDR 的第一个 IP，由 --service-cluster-ip-range 的参数提供。 参数 --days 用于设置证书的过期时间。 下面的示例假定你的默认 DNS 域名为 cluster.local。
./easyrsa --subject-alt-name=&amp;#34;IP:${MASTER_IP},&amp;#34;\ &amp;#34;IP:${MASTER_CLUSTER_IP},&amp;#34;\ &amp;#34;DNS:kubernetes,&amp;#34;\ &amp;#34;DNS:kubernetes.default,&amp;#34;\ &amp;#34;DNS:kubernetes.default.svc,&amp;#34;\ &amp;#34;DNS:kubernetes.default.svc.cluster,&amp;#34;\ &amp;#34;DNS:kubernetes.default.svc.cluster.local&amp;#34; \ --days=10000 \ build-server-full server nopass 拷贝文件 pki/ca.</description></item><item><title>数据包发送过程详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%8C%85%E5%8F%91%E9%80%81%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%8C%85%E5%8F%91%E9%80%81%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3/</guid><description>[译] Linux 网络栈监控和调优：发送数据（2017） Published at 2018-12-17 | Last Update 2020-09-29
译者序 本文翻译自 2017 年的一篇英文博客 Monitoring and Tuning the Linux Networking Stack: Sending Data。如果能看懂英文，建议阅读原文，或者和本文对照看。 这篇文章写的是 “Linux networking stack”，这里的 ”stack“ 不仅仅是内核协议栈， 而是包括内核协议栈在内的，从应用程序通过系统调用写数据到 socket，到数据被组织 成一个或多个数据包最终被物理网卡发出去的整个路径。所以文章有三方面，交织在一起， 看起来非常累（但是很过瘾）：
原理及代码实现：网络各层，包括驱动、硬中断、软中断、内核协议栈、socket 等等。 监控：对代码中的重要计数进行监控，一般在/proc 或/sys 下面有对应输出。 调优：修改网络配置参数。 本文的另一个特色是，几乎所有讨论的内核代码，都在相应的地方给出了 github 上的链接， 具体到行。 网络栈非常复杂，原文太长又没有任何章节号，看起来非常累。因此本文翻译时添加了适当 的章节号，以期按图索骥。
2020 更新:
基于 Prometheus+Grafana 监控网络栈：Monitoring Network Stack。 以下是翻译。
太长不读（TL; DR） 本文介绍了运行 Linux 内核的机器是如何发包（send packets）的，包是怎样从用户程 序一步步到达硬件网卡并被发出去的，以及如何监控（monitoring）和调优（ tuning）这一路径上的各个网络栈组件。 本文的姊妹篇是 Linux 网络栈监控和调优：接收数据， 对应的原文是 Monitoring and Tuning the Linux Networking Stack: Receiving Data 。</description></item><item><title>数据包接收过程详解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8E%A5%E6%94%B6%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Network/Linux-%E7%BD%91%E7%BB%9C%E6%A0%88%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8E%A5%E6%94%B6%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3/</guid><description>[译] Linux 网络栈监控和调优：接收数据（2016） Published at 2018-12-05 | Last Update 2020-03-29
译者序 本文翻译自 2016 年的一篇英文博客 Monitoring and Tuning the Linux Networking Stack: Receiving Data。如果能看懂英文，建议阅读原文，或者和本文对照看。 这篇文章写的是 “Linux networking stack”，这里的 ”stack“ 指的不仅仅是内核协议 栈，而是包括内核协议栈在内的、从数据包到达物理网卡到最终被用户态程序收起的整个路 径。所以文章有三方面，交织在一起，看起来非常累（但是很过瘾）：
原理及代码实现：网络各层，包括驱动、硬中断、软中断、内核协议栈、socket 等等 监控：对代码中的重要计数进行监控，一般在 /proc 或 /sys 下面有对应输出 调优：修改网络配置参数 本文的另一个特色是，几乎所有讨论的内核代码，都在相应的地方给出了 github 上的链接 ，具体到行。 网络栈非常复杂，原文太长又没有任何章节号，看起来非常累。因此本文翻译时添加了适当 的章节号，以期按图索骥。
2020 更新： 基于 Prometheus+Grafana 监控网络栈：Monitoring Network Stack。 以下是翻译。
太长不读（TL; DR） 本文介绍了 Linux 内核是如何收包（receive packets）的，包是怎样从网络栈到达用 户空间程序的，以及如何监控（monitoring）和调优（tuning）这一路径上的各个 网络栈组件。 这篇文章的姊妹篇 Monitoring and Tuning the Linux Networking Stack: Sending Data。 这篇文章的图文注释版 the Illustrated Guide to Monitoring and Tuning the Linux Networking Stack: Receiving Data。 想对 Linux 网络栈进行监控或调优，必须对它的行为（what exactly is happening）和原 理有深入的理解，而这是离不开读内核源码的。希望本文可以给那些正准备投身于此的人提 供一份参考。 特别鸣谢 特别感谢 Private Internet Access 的各位同 僚。公司雇佣我们做一些包括本文主题在内的网络研究，并非常慷慨地允许我们将研究成果 以文章的形式发表。 本文基于在 Private Internet Access 时的研 究成果，最开始以 5 篇连载 的形式出现。</description></item><item><title>数据湖</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E6%B9%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E6%B9%96/</guid><description/></item><item><title>数据库</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>概述 想要通过代码来控制数据库，那么在代码中，首先需要连接到数据库，只有打开了一个连接（socket），才可以通过代码来对数据库进行操作
而一般情况下，数据库并不是通过 go 语言写的，那么如何连接呢，就需要调用数据库的 API 接口，而想要调用该接口，则需要使用第三方库才可以，这个第三方库，这个库会提供几种&amp;quot;method&amp;quot;，包括连接数据库，对数据库执行操作等。
GORM 参考：
GitHub 项目，jinzhu/gorm 该项目迁移到 go-gorm/gorm gorm模糊查询和分页查询同时查总条数 GORM 是一个出色的 ORM 库，旨在对开发人员友好。
全功能ORM（几乎） 关联（包含一个，包含多个，属于，多对多，多种包含） Callbacks（创建/保存/更新/删除/查找之前/之后） 预加载（急加载） 事务 复合主键 SQL Builder 自动迁移 日志 可扩展，编写基于GORM回调的插件 每个功能都有测试 开发人员友好 常用示例 gorm模糊查询和分页查询同时查总条数
func (u *userService) GetuserList(offset, limit int, search User) (users []User, count int, err error) { if search.Name != &amp;#34;&amp;#34; { u.mysql = u.mysql.Where(&amp;#34;name LIKE ?&amp;#34;, search.Name+&amp;#34;%&amp;#34;) } if search.Category != &amp;#34;&amp;#34; { u.mysql = u.mysql.Where(&amp;#34;age =?&amp;#34;, search.Age) } err = u.</description></item><item><title>搜索引擎简介</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/</guid><description>基础概念 搜索引擎
索引链+搜索组件，用户给搜索组件提供关键字，然后进行搜索
索引链： 原始内容-获取-创建文档-文档分析-创建索引-索引 搜索组件 UI-构建查询-运行查询-读取结果-UI 开源索引链：Lucene，自己不获取内容，不提供前段界面，ElasticSearch 基于 Lucene
Lucene ElasticSearch：简称 ES ES 是基于 Lucene 实现的开源、分布式、Restful 的全文本搜索引擎；并且还是一个分布式实时存储文档，其中每个文档的每个 field 均是被索引的数据，且可被搜索；也是一个实时分析功能的分布式搜索引擎，能够扩展至数以百计的节点实时处理 PB 级的数据
组件 基本组件 索引(index) # 文档容器。含有相同属性的文档集合，索引名必须使用小写字母 类型(type) # 索引内部的逻辑分区。一个索引内部可以定义一个或多个类型，文档必须属于一个类型 文档(document) # 文档是 Lucene 索引和搜索的原子单位，它包含一个或多个域，是域的容器：基于 JSON 格式表示，每个域的组成部分(一个名字，一个或多个值，拥有多个值得域通常称为多值域)。可以被索引的基础数据单位 映射(mapping) # 原始内容存储为文档之前需要事先进行分析，如切词、过滤掉某些词等；映射就是用于定义此分析机制该如何实现；此外，ES 为映射提供了诸如将域中的内容排序等功能 集群组件 Cluster # ES 的集群标识为集群名称：默认为“elasticsearch”，各个节点就是靠此名字来决定加入到哪个集群中。一个节点只能属于一个集群 Node # 运行了单个 ES 实例的主机即为节点，用于存储数据、参与集群索引及搜索操作。节点的标识靠节点名 shard # 分片，每个索引都会切割为多个分片，每一个 shard 都是一个完整且独立的索引，可以理解为分词，把一段文字分成多个单词。shard 有两种类型 primary shard # 主 shard，ES 默认可为其将其分割为 5 个主 shard，用户也可自定义。 replica shard # 备份 shard，每个主 shard 的备份，用户数据冗余以及查询时的负载均衡,shard 的备份数量可以自定义 数据获取组件： solr,nutch,grub,Apeture 等， 基本组件的形象比喻：</description></item><item><title>索引为什么能提高查询性能....</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/%E7%B4%A2%E5%BC%95%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E6%8F%90%E9%AB%98%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Retrieval/%E7%B4%A2%E5%BC%95%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E6%8F%90%E9%AB%98%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD/</guid><description>原文：公众号 - 小林coding
前言 昨天，有个女孩子问我提高数据库查询性能有什么立竿见影的好方法？
这简直是一道送分题，我自豪且略带鄙夷的说，当然是加「索引」了。
她又不紧不慢的问，索引为什么就能提高查询性能。
这还用问，索引就像一本书的目录，用目录查当然很快。
她失望地摇了摇头，你说的只是一个类比，可为什么通过目录就能提高查询速度呢。
唉，对啊，通过书目可以快速查询，这只是一个现象，真正原因到底是什么呢。
那女孩看着诧异且表情僵硬的我，满意而又意味深长的笑笑：原来你这个男程序员也不会，看来我还得靠自己研究了。
哎，熬夜又要憔悴了我这该死的美貌。
来自同行的羞辱，是可忍孰不可忍？！
于是，我踏上了数据库索引学习的不归路，原来数据库索引使用了一种叫 B+ 树的古老数据结构，当然也有 Hash 等类型，暂且不说，可 B+ 树 这是个什么妖魔鬼怪呢？
下面就来浅尝辄止的扒一扒树的前世今生。
正文 二叉树 由 n（ n &amp;gt; 0）个有限节点组成一个具有层次关系的集合，看起来就像一个倒挂的树，因此称这样的数据结构为树。
一个节点的子节点个数叫做度，通俗的讲就是树叉的个数。树中最大的度叫做树的度，也叫做阶。一个 2 阶树最多有 2 个子节点即最多有 2 叉，因此这样的树称为二叉树，二叉树是树家族中最简单的树。
两个叉的树就是二叉树，可这除了用来按一定结构存放数据外，跟查询性能好像也没关系，不会又是一个没用的噱头吧。
二分查找 听说二叉树的原始威力来源于一种叫做二分查找的算法。
相传在鹦鹉的原始社会，存在着森严的等级制度，每只鸟必须按高矮顺序分出等级和尊卑。
那么问题来了，如下图，怎样才能找出最高、最矮、中等高的那些鹦鹉呢、以及指定高度的那只呢?
第一种方法: 扫描法
一个一个依次测量，完毕后所有的问题都迎刃而解。
这种一个一个依次全部测量的方法叫做扫描，他的缺点很明显，最高和最矮，需要全部测量完毕才能知晓。
而对于指定高度，最好的情况是第一次就找到；最坏的情况是最后一次才找到，时间复杂度为 n，也就是说从 13 个鹦鹉中找到指定身高的那只，最坏的情况是查 13 次。
第二种方法：二分法
13 个鹦鹉全部听令，按从矮到高列队，向左看齐，报数。
报数字 1 的就是最矮的，报数字 13 的就是最高的，报数字 7 的就是中等身高的那只。
最好和最坏的情况都是一次找到。而查询性能一下子提高 13 倍，我的个乖乖，无论多个只鹦鹉，时间复杂度都是 1，好可怕。
问题：我不服，你这是偷换概念，有本事对比一个查找指定高度鹦鹉的性能。
因为鹦鹉们已经按高矮排好了队，所以指定高度的鹦鹉，要么是站中间那个只，要么就是在它的左边或右边的那群里。
如果是中间那个，一次就找到，如果不是只需要从中间左边或右边那一半中找，再在这一半中找中间那只，对比身高。
以此类推，每次都把查询的范围减半，时间复杂度log2(n)。
那么 log2(13) 就是 4，最坏的情况也才 4 次，时间复杂度确实不是 1 了，但好像也不糟，简化如下：</description></item><item><title>天津测试环境</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/WireGuard/%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/</guid><description>生成公钥与私钥 wg genkey | tee /etc/wireguard/key/company/company-privatekey | wg pubkey &amp;gt; /etc/wireguard/key/company/company-publickey Peer-client 配置，作为客户端访问各资源池 cat &amp;gt; /etc/wireguard/company/company-client.conf &amp;lt;&amp;lt;EOF [Interface] PrivateKey = $(cat /etc/wireguard/key/peer-client-privatekey) Address = 10.1.0.253/24 [Peer] PublicKey = $(cat /etc/wireguard/key/gw-publickey) AllowedIPs = 10.1.0.0/24,10.20.5.0/24,172.38.0.0/16 Endpoint = $(curl -s ip.sb):16000 PersistentKeepalive = 10 EOF 中继服务器配置 带公网的 Peer 配置文件，该 Peer 作为中继服务器，负责连通访问客户端和所有资源池
cat &amp;gt; /etc/wireguard/company-wg.conf &amp;lt;&amp;lt;EOF [Interface] ListenPort = 16000 Address = 10.1.0.254/24 PrivateKey = $(cat /etc/wireguard/key/gw-privatekey) PostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o ens3 -j MASQUERADE PostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o ens3 -j MASQUERADE [Peer] # 客户端 PublicKey = $(cat /etc/wireguard/key/peer-client-publickey) AllowedIPs = 10.</description></item><item><title>条件语句与运算</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5%E4%B8%8E%E8%BF%90%E7%AE%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5%E4%B8%8E%E8%BF%90%E7%AE%97/</guid><description>概述 参考：
Wiki, Operator(运算) https://www.tutorialspoint.com/unix/unix-basic-operators.htm 使用运算符操作一个或多个内容，然后得到另一个内容，这个过程就是运算。要操作的内容可以是一个具体的数值、字符串、变量等。
在编程中使用运算可以得到一个具体的值，或者进行一次判断以得出“真”或者“假”的结果，以这个结果作为执行某些操作的依据。
EXAMPLE：
2+3，进行算数运算，求和。2 和 3 是两个内容，+是运算符，运算后的值为 5。
[ test1 = test2 ]，进行判断运算，判断运算符两边的内容是否一样，并得出“是”或者“否”这两种结论其中一个。test1 与 test2 是两个内容，=是运算符，运算后的结果是假，i.e.test1 不等于 test2。一般情况，当结果为真或者假之后，就可以执行某些操作，详见 3.Shell 控制结构.note
判断命令运行结果：shell 中的 if 语句会运行“条件语句”中给定的命令，如果该命令的退出状态码(详见下文红字)是 0，则“分支”中给定的命令就会被执行。如果该命令的退出状态码非 0，则“分支”中给定的命令不被执行，且会继续执行该脚本中下一个命令。
比如下面这种 if ! COMMAND; then echo &amp;ldquo;command failed&amp;rdquo;; exit 1; fi 使用 test 命令进行判断：“条件语句”中除了运行命令判断退出状态码，还可以通过 test 命令来进行运算判断，然后通过运算结果得出状态码是 0 还是 1 来进行条件判断(e.g.1 是否大于 2，文件是否存在，字符串是否一样等运算)。当运算结果为真时退出码为 0，否则运算结果非假则退出码非 0。运算方式以及命令详见下文的运算
语法结构：test CONDITION EXAMPLE test 1 -gt 2 # 判断 1 是否大于 2，使用 echo $?输出结果为 1，表示判断结果为错误，非 0 在 shell 中，test 命令可以通过 [ 条件 ] 与 [[ 条件 ]] 来进行表示(e.</description></item><item><title>通过 Socket 文件找到 TCP 连接信息</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E9%80%9A%E8%BF%87-Socket-%E6%96%87%E4%BB%B6%E6%89%BE%E5%88%B0-TCP-%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/Linux-%E7%AE%A1%E7%90%86%E6%A1%88%E4%BE%8B/%E9%80%9A%E8%BF%87-Socket-%E6%96%87%E4%BB%B6%E6%89%BE%E5%88%B0-TCP-%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF/</guid><description>概述 参考：原文链接
进程的打开文件描述符表 Linux Kernel 的三个系统调用：open，socket，pipe 返回的都是一个描述符。不同的进程中，他们返回的描述符可以相同。那么，在同一个进程中，他们可以相同吗？或者说，普通文件、套接字和管道，这三者的描述符属于同一个集合吗？
在内核源码中，三个系统调用声明如下：
SYSCALL_DEFINE3(open, const char __user *, filename, int, flags, umode_t, mode); SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol); SYSCALL_DEFINE1(pipe, int __user *, fildes); 他们都会先后调用函数
get_unused_fd_flags：获取当前进程打开文件描述符表中的空闲描述符； fd_install：安装新描述符到当前进程打开文件描述符表。 内核为每个进程维护了一个结构体 struct task_struct，可称为进程表项、进程控制块（PCB: Process Control Block）或者进程描述符，定义如下：
struct task_struct { volatile long state; /* -1 unrunnable, 0 runnable,&amp;gt;0 stopped */ … pid_t pid; … struct files_struct *files; … }; 其中 files 成员成为打开文件描述符表，定义如下：
struct files_struct { … struct fdtable fdtab; … struct file __rcu * fd_array[NR_OPEN_DEFAULT]; }; 其成员 fdtab 为关键数据成员，定义如下：</description></item><item><title>通过pprof监控docker</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B7%A5%E5%85%B7/pprof/%E9%80%9A%E8%BF%87pprof%E7%9B%91%E6%8E%A7docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E5%B7%A5%E5%85%B7/pprof/%E9%80%9A%E8%BF%87pprof%E7%9B%91%E6%8E%A7docker/</guid><description>debug 模式启动 docker
$ /usr/bin/docker daemon -D -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock 通过 socat 端口转发 $ socat -d -d TCP-LISTEN:8080,fork,bind=192.168.1.137 UNIX:/var/run/docker.sock 测试 [root@reg pprof]# curl -s http://10.39.0.102:8080/debug/vars | jq . { &amp;#34;cmdline&amp;#34;: [ &amp;#34;/usr/bin/dockerd&amp;#34;, &amp;#34;-D&amp;#34; ], &amp;#34;memstats&amp;#34;: { &amp;#34;Alloc&amp;#34;: 13847856, &amp;#34;TotalAlloc&amp;#34;: 71577968, &amp;#34;Sys&amp;#34;: 27052344, &amp;#34;Lookups&amp;#34;: 7829, &amp;#34;Mallocs&amp;#34;: 891300, &amp;#34;Frees&amp;#34;: 772846, &amp;#34;HeapAlloc&amp;#34;: 13847856, &amp;#34;HeapSys&amp;#34;: 18743296, &amp;#34;HeapIdle&amp;#34;: 1941504, &amp;#34;HeapInuse&amp;#34;: 16801792, &amp;#34;HeapReleased&amp;#34;: 1810432, &amp;#34;HeapObjects&amp;#34;: 118454, &amp;#34;StackInuse&amp;#34;: 1179648, &amp;#34;StackSys&amp;#34;: 1179648, &amp;#34;MSpanInuse&amp;#34;: 225280, &amp;#34;MSpanSys&amp;#34;: 262144, &amp;#34;MCacheInuse&amp;#34;: 4800, &amp;#34;MCacheSys&amp;#34;: 16384, &amp;#34;BuckHashSys&amp;#34;: 1460436, &amp;#34;GCSys&amp;#34;: 1374208, &amp;#34;OtherSys&amp;#34;: 4016228, &amp;#34;NextGC&amp;#34;: 25872553, &amp;#34;LastGC&amp;#34;: 1512984476111075800, &amp;#34;PauseTotalNs&amp;#34;: 29246607, &amp;#34;PauseNs&amp;#34;: [ 317474, 1159328, 271770, .</description></item><item><title>通用命令</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E9%80%9A%E7%94%A8%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/virsh-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E9%80%9A%E7%94%A8%E5%91%BD%E4%BB%A4/</guid><description>概述 参考：
官方 Manual(手册)，GENERIC COMMANDS quit, exit version cd pwd connect uri hostname sysinfo nodeinfo nodecpumap nodecpustats nodememstats nodesevinfo nodesuspend node-memory-tune capabilities domcapabilities pool-capabilities inject-nmi
list # 列出所有正在运行的 domain https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#list
Syntax(语法) list [OPTIONS]
OPTIONS
&amp;ndash;all # 列出活动和非活动的所有 domain &amp;ndash;title # 显示 domain 的 title &amp;ndash;name # 仅显示虚拟机名称 EXAMPLE
virsh list # 列出所有正在运行的 domain freecell freepages allocpages
cpu-baseline https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#cpu-baseline
cpu-compare https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#cpu-compare
cpu-models https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#cpu-models
hypervisor-cpu-compare https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#hypervisor-cpu-compare
hypervisor-cpu-baseline https://github.com/libvirt/libvirt/blob/master/docs/manpages/virsh.rst#hypervisor-cpu-baseline</description></item><item><title>图解区块链工作逻辑</title><link>https://desistdaydream.github.io/docs/Blockchain/%E5%9B%BE%E8%A7%A3%E5%8C%BA%E5%9D%97%E9%93%BE%E5%B7%A5%E4%BD%9C%E9%80%BB%E8%BE%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Blockchain/%E5%9B%BE%E8%A7%A3%E5%8C%BA%E5%9D%97%E9%93%BE%E5%B7%A5%E4%BD%9C%E9%80%BB%E8%BE%91/</guid><description>最近总是能在一些网站上看到比特币大涨的消息，诺，这不都涨破 20000 美元啦。
最近比特币涨势喜人，牵动着每一位股民的心，持有的老哥后悔说当时我咋就没多买点呢，不然明天早饭又能多加个鸡蛋啦，没持有的呢，就在懊恼后悔当时为啥就没买入呢？这不我女朋友也看到新闻了，说比特币最近涨那么厉害，咱们要不买两个呀！然后这个总是听到的比特币到底是什么东西呀？
你说那个比特币呀，我也不是很懂，知道一点点，我给你讲一下我知道的吧。
注：本文和股票无关，单纯的介绍一下比特币原理，投资有风险，入场需谨慎
关键词 ：比特币，去中心化，挖矿，区块链，双重支付，最长链原则，工作量证明
我先给你说一下比特币的历史吧。
2008 年爆发全球金融危机，同年 11 月 1 日，一个自称中本聪（Satoshi Nakamoto）的人在 P2P foundation 网站上发布了比特币白皮书《比特币：一种点对点的电子现金系统》 陈述了他对电子货币的新设想——比特币就此面世。2009 年 1 月 3 日，比特币创世区块诞生。
你平时不是会把每天的收入和支出记在自己的小本本上，我们称之为记账。我们平常在消费的时候，银行也会为我们记录这条交易记录及交易后银行卡里的余额。然后我们会通过银行卡里数字来评估自己拥有的财富。所以我们拥有多少财富都通过银行的记账本来决定的。
中本聪在2008年提出，其实我们可以不需要一个中心化的记账系统，不需要以某个人或者机构为中心来帮我们记账，我们可以去中心化，每一个人的账本都是透明公开的，这就叫做去中心化电子记账系统。下面我们通过一个例子来进行描述。
1.那你说的那个区块链到底是什么东西呀，我不是很懂哎？ 我们对上图进行解析，A,B,C,D，四个小伙伴进行交易，首先 A 支付 5 个比特币给 B，那么他需要将这条交易信息发送给每位小伙伴，同理 B 和 C，C 和 D 的交易也要传送给所有的小伙伴，用户会将这些交易信息记录下来，并打包成块，我们称之为区块，（区块大小约为 1M，约 4000 条左右交易记录），当块存满时我们将这个块接到以前的交易记录上，形成一条链，过一段时间再把新的块接到它后面，我们称这条链为区块链，如下图。
好啦，我们大概了解什么是区块链了。
2.好啦我知道什么是区块链了，但是那些用户为什么要记录交易信息呢？ 记账奖励：每个用户都可以去记账，如果某个用户进行记帐则会奖励他一些手续费，比如 A 和 B 交易 10 个比特币，A 就需要多支出一点点给为其记录的人。其实现实生活中，我们使用银行卡时也会有手续费,这里的手续费是支付给银行。
打包（将交易记录打包成块）奖励：打包者只能有一位，完成打包的那一位能够获得打包奖励，
3.哦，知道了，那打包一次能获得多少奖励呢？ 2008 年刚提出这个系统时，奖励方案如下
每十分钟打一个包，最开始的时候，每打一个包会奖励打包者 50 个比特币，过了四年之后，每打一个包奖励 25 个比特币，再过四年的则奖励 12.5 个比特币，以此类推。
4.哇，那么多，那世界上一共有多少个比特币呢？ 一个包奖励 50 个比特币，一个小时 6 个包，一天 24 小时，一年 365 天 ，每隔四年减半，则计算公式如下</description></item><item><title>网络附加存储</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%9E%B6%E6%9E%84/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8/</guid><description>NAS 的实现 CIFS/SMB 和 NFS 是实现 NAS 架构的主要协议。
NBD 也可以看做是 NAS 的一种，可以通过网络提供块存储能力。
NBD 参考：
GitHub 项目，NetworkBlockDevice/nbd 项目中的文档，NBD 协议 Wiki, Network_block_device Network Block Device(网络块设备，简称 NBD) 即是一个功能，也是一种协议。这是一种 C/S 架构，可以让 Client 通过网络使用 Server 提供的块设备。
NDB Server 可以将一个 iso 文件、目录、usb、CDROM 等抽象为一个块设备，以便让 Client 通过网络使用块设备。
IANA 保留了 10809 端口作为 NDB 提供服务的默认端口。
当我们使用低版本的 nbd-server 时，可能会收到一些警告信息，比如 Warning: the oldstyle protocol is no longer supported. This method now uses the new style protocol with a default export。这些信息只是提醒我们 oldstyle protocol 已经被弃用，不一定代表有什么问题。</description></item><item><title>网络栈控制</title><link>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E7%BD%91%E7%BB%9C%E6%A0%88%E6%8E%A7%E5%88%B6/%E7%BD%91%E7%BB%9C%E6%A0%88%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/2.%E7%BC%96%E7%A8%8B/%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Go/Go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/%E7%BD%91%E7%BB%9C%E6%A0%88%E6%8E%A7%E5%88%B6/%E7%BD%91%E7%BB%9C%E6%A0%88%E6%8E%A7%E5%88%B6/</guid><description>概述 github.com/coreos/go-iptables/iptables
github.com/vishvananda/netlink
github.com/vishvananda/netns</description></item><item><title>为 Pod 注入数据</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%AE%A1%E7%90%86/%E4%B8%BA-Pod-%E6%B3%A8%E5%85%A5%E6%95%B0%E6%8D%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Pod/Pod-%E7%AE%A1%E7%90%86/%E4%B8%BA-Pod-%E6%B3%A8%E5%85%A5%E6%95%B0%E6%8D%AE/</guid><description>概述 参考：
官方文档，任务 - 给应用注入数据 将 Pod 的 Manifests 信息映射到容器中的环境变量上 用 Pod 字段作为环境变量的值 在这个练习中，你将创建一个包含一个容器的 Pod。这是该 Pod 的配置文件：
apiVersion: v1 kind: Pod metadata: name: dapi-envars-fieldref spec: containers: - name: test-container image: k8s.gcr.io/busybox command: [&amp;#34;sh&amp;#34;, &amp;#34;-c&amp;#34;] args: - while true; do echo -en &amp;#39;\n&amp;#39;; printenv MY_NODE_NAME MY_POD_NAME MY_POD_NAMESPACE; printenv MY_POD_IP MY_POD_SERVICE_ACCOUNT; sleep 10; done; env: - name: MY_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: MY_POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.</description></item><item><title>为什么集群需要 Overlay 网络</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9B%86%E7%BE%A4%E9%9C%80%E8%A6%81-Overlay-%E7%BD%91%E7%BB%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9B%86%E7%BE%A4%E9%9C%80%E8%A6%81-Overlay-%E7%BD%91%E7%BB%9C/</guid><description>原文链接：https://mp.weixin.qq.com/s/a1omUj17yNVUuymh6DYpRQ
对计算机网络或者 Kubernetes 网络稍有了解的工程师都应该听说过延展网络（Overlay Network），Overlay 网络其实并不是一门新技术，它是指构建在另一个网络上的计算机网络[^1]，这是一种网络虚拟化技术的形式，近年来云计算虚拟化技术的演进促进了网络虚拟化技术的应用。
overlay-network
图 1 - 延展网络
因为 Overlay 网络是建立在另一个计算机网络之上的虚拟网络，所以它不能独立出现，Overlay 底层依赖的网络就是 Underlay 网络，这两个概念也经常成对出现。
Underlay 网络是专门用来承载用户 IP 流量的基础架构层，它与 Overlay 网络之间的关系有点类似物理机和虚拟机。Underlay 网络和物理机都是真正存在的实体，它们分别对应着真实存在的网络设备和计算设备，而 Overlay 网络和虚拟机都是依托在下层实体使用软件虚拟出来的层级。
network-and-compute
图 2 - 网络与计算
在分析 Overlay 网络的作用之前，我们需要对它的常见实现有大概的了解，在实践中我们一般会使用虚拟局域网扩展技术（Virtual Extensible LAN，VxLAN）组建 Overlay 网络。在下图中，两个物理机可以通过三层的 IP 网络互相访问：
VxLAN-overlay-network
图 3 - VxLAN 组成的 Overlay 网络
VxLAN 使用虚拟隧道端点（Virtual Tunnel End Point、VTEP）设备对服务器发出和收到的数据包进行二次封装和解封。
上图中两个 VTEP 会相互连接并获得网络中的 MAC 地址、IP 地址等信息，例如，服务器 1 中的 VTEP 需要知道想要访问绿色网络中的 10.0.0.2 虚拟机需要先访问 IP 地址为 204.79.197.200 的服务器 2。这些配置可以被网络管理员手动配置、自动学习、也可以通过上层的管理器设置。当绿色的 10.</description></item><item><title>问题实例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E8%A1%8D%E7%94%9F%E5%93%81/Rancher/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</guid><description>待解决问题 RKE 问题
Centos 启动 RKE 集群还存在用户权限问题，无法使用 root 安装。详见：https://rancher2.docs.rancher.cn/docs/rke/os/_index#rhel%E3%80%81oel%E3%80%81centos kube-proxy、kube-scheduler、kube-controller-manager、kube-apiserver、etcd 这些集群组件，无守护，不是通过 kubelet 的静态 pod 拉起。如果容器被停掉，则无法自动恢复。 ube-scheduler、kube-controller-manager 的 https 端口无法使用，证书有问题。 K3S 问题
k3s 中的 kubelet 无法使用 systemd 后端，k3s 官方人员吐槽 k8s 官方使用 systemd 后端。详见：https://github.com/rancher/k3s/issues/797 吐槽详见：https://github.com/rancher/k3s/issues/797#issuecomment-529139150 Rancher 问题
rancher 崩溃或数据丢失，会导致的问题 通过 rancher 创建的集群无法添加节点，无法升级，所有关于 kubeadm 可以使用的东西都无法使用。就算通过 kubelet 手动添加也不行。 rancher 部署在原生 k8s 集群上入侵行太强，会创建几十个 CRD。当删除的时候，还无法正常删除，只能删除其垃圾回收机制中的 finalizers 字段才可以。 rancher 会为集群中每个 namespace 添加注释以及 finalizers，包括 kube-system，issuer 详见 #14715。如果想要自己删除 ns，则会被卡住，因为 ns 在等待 controller.cattle.io/namespace-auth 导入集群清理 rancher 不干净，留下非常非常多的 rolebing、clusterrole、clusterbinding，很多都是操作 ns 所需的。 Agent 无法连接 Rancher server https://rancher2.</description></item><item><title>问题实例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Virtualization-implementation/%E8%99%9A%E6%8B%9F%E5%8C%96%E7%AE%A1%E7%90%86/Libvirt/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</guid><description>dnsmasq: cannot read /var/lib/libvirt/dnsmasq/default.conf: Permission denied 参考连接：https://forum.level1techs.com/t/solved-virtual-network-issue-virsh-net-start-default/136141
该问题常出现在移动 /var/lib/libvirt 目录下的内容到新的磁盘上之后出现，是由于 SELinux 的策略导致的
I solved this so I figured I’d post the fix (to my specific problem) in case anybody else runs into this. This was happening due to an SELinux policy violation. Here is what I did:
$ sudo setenforce 0 # disable SELinux momentarily$ sudo virsh net-start default # this worked which meant SELinux was involved$ sudo setenforce 1 # renable SELinux$ sudo ausearch -m AVC,USER_AVC,SELINUX_ERR -ts recent # inspect the SELinux alerts if you&amp;rsquo;re interested</description></item><item><title>问题实例</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Repository%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%AE%A1%E7%90%86/Repository%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</guid><description>harbor 处在 nginx 后面时无法 push 和 从其他仓库连接上去 nginx 的配置需要添加 location /v2/
server { listen 80; server_name registry.bj-net.desistdaydream.ltd; client_body_in_file_only clean; client_body_buffer_size 64K; client_max_body_size 40M; sendfile on; send_timeout 300s; location / { proxy_pass http://172.19.42.218/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Host $host:$server_port; } location /v2/ { proxy_pass http://172.19.42.218/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } harbor 主从报错，测试连接失败 failed to ping endpoint.</description></item><item><title>问题实例</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/Message-Queue%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8B/</guid><description>Waiting for Mnesia tables 报错 另一个 issue：https://github.com/bitnami/charts/issues/3783#，这是 bitnami 上的 rabbitmq helm 的报错 issue
多个节点同时重启，出现该问题，该问题主要是因为各个节点之间无法有效得正常通信导致的</description></item><item><title>问题实例：Keepalived 非抢占模式 VIP 不漂移</title><link>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8BKeepalived-%E9%9D%9E%E6%8A%A2%E5%8D%A0%E6%A8%A1%E5%BC%8F-VIP-%E4%B8%8D%E6%BC%82%E7%A7%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/3.%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/Keepalived/%E9%97%AE%E9%A2%98%E5%AE%9E%E4%BE%8BKeepalived-%E9%9D%9E%E6%8A%A2%E5%8D%A0%E6%A8%A1%E5%BC%8F-VIP-%E4%B8%8D%E6%BC%82%E7%A7%BB/</guid><description>Keepalived 非抢占模式下 VIP 不漂移问题 Keepalived 主要是通过虚拟路由冗余来实现高可用功能。本文将不对 keepalived 的基本原理进行阐述，可参考文章 Keepalived 详细介绍简介、keepalived vip 漂移基本原理及选举算法。本文记录了在实践过程中使用 keepalived 时，在 weight 值变化的情况下 vip 不漂移的问题及解决方法。
场景
3 个 keepalived 节点, vip 为 172.31.23.6：
devops1a-zoocassa0 172.31.23.22
devops1a-zoocassa1 172.31.23.23
预期
两个节点初始都设为 BACKUP，按照优先级（priority）选举 MASTER；
在两个节点上检查 memcached 服务状态，失败则降低优先级；
如果 MASTER(假设为 devops1a-zoocassa0)上检查失败，BACKUP 上检查成功，则优先级高的 BACKUP 节点(假设为 devops1a-zoocassa1)切换为 MASTER 节点；
之前检查失败的 MASTER(devops1a-zoocassa0)上的服务恢复时, 之前的 BACKUP 节点(devops1a-zoocassa1)服务检查也成功，即使 devops1a-zoocassa0 优先级恢复到高于 devops1a-zoocassa1,也不再成为 MASTER(不抢占)。
不成功配置范例 主节点 dr-1 配置
global_defs { router_id k8s-master-dr } vrrp_script check_nginx { script &amp;quot;pidof nginx&amp;quot; interval 3 weight -2 fall 2 rise 2 } vrrp_instance VI_K8S { state BACKUP interface eth0 virtual_router_id 60 priority 101 nopreempt authentication { auth_type PASS auth_pass 4be37dc3b4c90194d1600c483e10ad1d } virtual_ipaddress { 172.</description></item><item><title>无线通信</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%97%A0%E7%BA%BF%E9%80%9A%E4%BF%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E6%97%A0%E7%BA%BF%E9%80%9A%E4%BF%A1/</guid><description>概述 参考：
Bluetooth
Wifi
Zigbee
Wi-Fi 4 = 802.11n Wi-Fi 5 = 802.11ac Wi-Fi 6 = 802.11ax
Wi-Fi Direct 参考：
Wiki, Wi-Fi_Direct Wi-Fi Direct(WiFi 直连)（以前称为 Wi-Fi Peer-to-Peer）是一种用于点对点无线连接的 Wi-Fi 标准，允许两个设备建立直接 Wi-Fi 连接，无需中间无线接入点、路由器或互联网连接。 Wi-Fi Direct 是单跳通信，而不是像无线自组织网络那样的多跳通信。
Wi-Fi Direct的工作方式如下：
设备发现： 物联网设备（比如打印机）和移动设备在 Wi-Fi Direct 模式下进行广播，以便彼此发现对方的存在。 建立连接： 一旦设备发现彼此，它们可以建立直接的Wi-Fi连接，无需通过路由器。 安全连接： Wi-Fi Direct 支持安全连接，通常包括密码或 PIN 码等认证方式，以确保只有授权用户能够连接到设备。 https://www.infobae.com/cn/2022/03/31/android-what-is-wifi-direct-and-how-to-use-it-to-send-large-files-from-the-cell-phone/</description></item><item><title>系统 UDP 丢包问题分析思路</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E7%B3%BB%E7%BB%9F-UDP-%E4%B8%A2%E5%8C%85%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E6%A1%88%E4%BE%8B/%E7%B3%BB%E7%BB%9F-UDP-%E4%B8%A2%E5%8C%85%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/</guid><description>最近工作中遇到某个服务器应用程序 UDP 丢包，在排查过程中查阅了很多资料，总结出来这篇文章，供更多人参考。
在开始之前，我们先用一张图解释 linux 系统接收网络报文的过程。
首先网络报文通过物理网线发送到网卡 网络驱动程序会把网络中的报文读出来放到 ring buffer 中，这个过程使用 DMA（Direct Memory Access），不需要 CPU 参与 内核从 ring buffer 中读取报文进行处理，执行 IP 和 TCP/UDP 层的逻辑，最后把报文放到应用程序的 socket buffer 中 应用程序从 socket buffer 中读取报文进行处理 在接收 UDP 报文的过程中，图中任何一个过程都可能会主动或者被动地把报文丢弃，因此丢包可能发生在网卡和驱动，也可能发生在系统和应用。
之所以没有分析发送数据流程，一是因为发送流程和接收类似，只是方向相反；另外发送流程报文丢失的概率比接收小，只有在应用程序发送的报文速率大于内核和网卡处理速率时才会发生。
本篇文章假定机器只有一个名字为 eth0 的 interface，如果有多个 interface 或者 interface 的名字不是 eth0，请按照实际情况进行分析。NOTE：文中出现的 RX（receive） 表示接收报文，TX（transmit） 表示发送报文。
确认有 UDP 丢包发生 要查看网卡是否有丢包，可以使用 ethtool -S eth0 查看，在输出中查找 bad 或者 drop 对应的字段是否有数据，在正常情况下，这些字段对应的数字应该都是 0。如果看到对应的数字在不断增长，就说明网卡有丢包。另外一个查看网卡丢包数据的命令是 ifconfig，它的输出中会有 RX(receive 接收报文)和 TX（transmit 发送报文）的统计数据：
~# ifconfig eth0 ... RX packets 3553389376 bytes 2599862532475 (2.</description></item><item><title>性能评估</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux-%E7%AE%A1%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/</guid><description>概述 参考：
思否，60000 毫秒内对 Linux 的性能诊断 英文原文 可以使用性能评估来概括性能诊断和性能测试。性能评估是一种系统性的方法，旨在评估软件系统在不同条件下的性能表现，以确定其性能极限、瓶颈、瓶颈原因和潜在的改进空间。性能评估可以包括多种评估方法，包括性能测试和性能诊断，以便全面评估软件系统的性能表现。
Virtual Users(虚拟用户，简称 VUs) 是在性能测试领域常见的术语。VUs Generator(虚拟用户生成器) 使得测试人员能创建虚拟用户，以增加被测试应用程序的负载。用人话说，就是发起请求的并发数。性能测试程序，其实就是一个虚拟用户生成器。
性能诊断60秒 当你为了解决一个性能问题登录到一台 Linux 服务器：在第一分钟你应该检查些什么？
在 Netflix，我们有一个巨大的 EC2 Linux 云，以及大量的性能分析工具来监控和诊断其性能。其中包括用于云监控的 Atlas，以及用于按需实例分析的 Vector。虽然这些工具可以帮助我们解决大多数问题，但我们有时仍需要登录到一个服务器实例，并运行一些标准 Linux 性能工具。
在这篇文章中，Netflix Performance Engineering 团队将会向你讲解在命令行中进行一次最佳的性能分析的前 60 秒要做的事，使用的是你应该可以得到的标准 Linux 工具。
前六十秒：总览 通过运行下面十个命令，你就能在六十秒内粗略地了解系统正在运行的进程及资源使用情况。通过查看这些命令输出的错误信息和资源饱和度（它们都很容易看懂），你可以接下来对资源进行优化。饱和是指某个资源的负载超出了其能够处理的限度。一旦出现饱和，它通常会在请求队列的长度或等待时间上暴露出来。
uptime dmesg | tail vmstat 1 mpstat -P ALL 1 pidstat 1 iostat -xz 1 free -m sar -n DEV 1 sar -n TCP,ETCP 1 top 其中某些命令需要预先安装 sysstat 软件包。这些命令展示出来的信息能够帮你实施USE 方法（一种用于定位性能瓶颈的方法），比如检查各种资源（如 CPU、内存、磁盘等）的使用率、饱和度和错误信息。另外在定位问题的过程中，你可以通过使用这些命令来排除某些导致问题的可能性，帮助你缩小检查范围，为下一步检查指明方向。
下面的章节将以在一个生产环境上执行这些命令作为例子，简单介绍这些命令。若想详细了解这些工具的使用方法，请参考它们的 man 文档。</description></item><item><title>一个 TCP 连接上面能发多少个 HTTP 请求</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP-%E4%B8%8E-HTTP/%E4%B8%80%E4%B8%AA-TCP-%E8%BF%9E%E6%8E%A5%E4%B8%8A%E9%9D%A2%E8%83%BD%E5%8F%91%E5%A4%9A%E5%B0%91%E4%B8%AA-HTTP-%E8%AF%B7%E6%B1%82/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/TCP-%E4%B8%8E-HTTP/%E4%B8%80%E4%B8%AA-TCP-%E8%BF%9E%E6%8E%A5%E4%B8%8A%E9%9D%A2%E8%83%BD%E5%8F%91%E5%A4%9A%E5%B0%91%E4%B8%AA-HTTP-%E8%AF%B7%E6%B1%82/</guid><description>你猜一个 TCP 连接上面能发多少个 HTTP 请求 - 知乎
一道经典的面试题是从 URL 在浏览器被被输入到页面展现的过程中发生了什么，大多数回答都是说请求响应之后 DOM 怎么被构建，被绘制出来。但是你有没有想过，收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？
要搞懂这个问题，我们需要先解决下面五个问题：
现代浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？ 一个 TCP 连接可以对应几个 HTTP 请求？ 一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？ 为什么有的时候刷新页面不需要重新建立 SSL 连接？ 浏览器对同一 Host 建立 TCP 连接到数量有没有限制？ 先来谈谈第一个问题：现代浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？
在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。所以虽然标准中没有设定，某些服务器对 Connection: keep-alive 的 Header 进行了支持。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免，两张图片是我短时间内两次访问 https://www.github.com 的时间统计：</description></item><item><title>已弃用模块</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/%E5%B7%B2%E5%BC%83%E7%94%A8%E6%A8%A1%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/PAM/%E5%B7%B2%E5%BC%83%E7%94%A8%E6%A8%A1%E5%9D%97/</guid><description>概述 pam_tally2.so 模块 参考：
Manual(手册)，pam_tally2(8) 弃用说明：
GitHub,linux-pam 项目 1.4.0 版本中对 pam_tall2 模块的弃用说明 最后一行 https://access.redhat.com/solutions/62949 https://github.com/dev-sec/ansible-collection-hardening/issues/377 由 pam_faillock 模块代替 登录 Tallying(计数器) 模块
应用场景：设置 Linux 用户连续 N 次输入错误密码进行登陆时，自动锁定 X 分钟或永久锁定（这里的永久锁定指除非进行手工解锁，否则会一直锁定）。
配置 /var/log/faillog #
模块参数 deny=INT # 指定认证失败 deny 次后，将执行后面参数的策略。如锁定 N 秒，如果后面没有其他策略指定时，默认永远锁定，除非手动解锁。 lock_time=INT # 认证失败时锁定 lock_time 秒 unlock_time=INT # 锁定 unlock_time 秒后，自动解锁用户； even_deny_root # root 用户在认证出错时，一样被锁定(该功能慎用) root_unlock_time # root 用户锁定后，多久会解锁。该选项一般是配合 even_deny_root 一起使用的。 magic_root # 如果用户 uid ＝ 0（即 root 账户或相当于 root 的帐户）在帐户认证时调用该模块发现失败时，不计入统计； no_lock_time # 不使用.</description></item><item><title>音频的编码与解码</title><link>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E9%9F%B3%E9%A2%91%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/8.%E9%80%9A%E7%94%A8%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/%E9%9F%B3%E9%A2%91%E7%9A%84%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81/</guid><description>声音的本质就是波，波都是有频率的，频率就是指波在一秒钟震动的次数，单位是 Hz(赫兹)。
计算机除了记录声音的频率，还要记录在不同频率上，声音的幅度大小。
而想要出现声音，其实是离不开时间的，没有时间的流逝，也就不会产生声音
所以，计算机就需要对声音进行采样，记录每时每刻声音的频率和幅度，采样频率越高，声音也就越逼真
远程同话一般是每秒8000次的采样频率，而音乐CD则是每秒44100次的采样频率
每次采样，都会将频率和幅度，然后将其转换为字符，进而编码为二进制。</description></item><item><title>应用发布</title><link>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E5%BA%94%E7%94%A8%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/9.%E8%BF%90%E7%BB%B4/%E5%BA%94%E7%94%A8%E5%8F%91%E5%B8%83/</guid><description>概述 关于蓝绿发布、金丝雀发布、和 A/B 测试
蓝绿发布 蓝绿部署中，一共有两套系统：
一套是正在提供服务系统，标记为“绿色”；
另一套是准备发布的系统，标记为“蓝色”。
两套系统都是功能完善的，并且正在运行的系统，只是系统版本和对外服务情况不同。
最初，没有任何系统，没有蓝绿之分。 然后，第一套系统开发完成，直接上线，这个过程只有一个系统，也没有蓝绿之分。 后来，开发了新版本，要用新版本替换线上的旧版本，在线上的系统之外，搭建了一个使用新版本代码的全新系统。
这时候，一共有两套系统在运行，正在对外提供服务的老系统是绿色系统，新部署的系统是蓝色系统。 蓝色系统不对外提供服务，用来做啥？ 用来做发布前测试，测试过程中发现任何问题，可以直接在蓝色系统上修改，不干扰用户正在使用的系统。（注意，两套系统没有耦合的时候才能百分百保证不干扰） 蓝色系统经过反复的测试、修改、验证，确定达到上线标准之后，直接将用户切换到蓝色系统： 切换后的一段时间内，依旧是蓝绿两套系统并存，但是用户访问的已经是蓝色系统。这段时间内观察蓝色系统（新系统）工作状态，如果出现问题，直接切换回绿色系统。 当确信对外提供服务的蓝色系统工作正常，不对外提供服务的绿色系统已经不再需要的时候，蓝色系统正式成为对外提供服务系统，成为新的绿色系统。 原先的绿色系统可以销毁，将资源释放出来，用于部署下一个蓝色系统。 蓝绿部署只是上线策略中的一种，它不是可以应对所有情况的万能方案。 蓝绿部署能够简单快捷实施的前提假设是目标系统是非常内聚的，如果目标系统相当复杂，那么如何切换、两套系统的数据是否需要以及如何同步等，都需要仔细考虑。
金丝雀发布 金丝雀发布（Canary）也是一种发布策略，和国内常说的灰度发布是同一类策略。
蓝绿部署是准备两套系统，在两套系统之间进行切换，金丝雀策略是只有一套系统，逐渐替换这套系统 譬如说，目标系统是一组无状态的 Web 服务器，但是数量非常多，假设有一万台。
这时候，蓝绿部署就不能用了，因为你不可能申请一万台服务器专门用来部署蓝色系统（在蓝绿部署的定义中，蓝色的系统要能够承接所有访问）。 可以想到的一个方法是： 只准备几台服务器，在上面部署新版本的系统并测试验证。测试通过之后，担心出现意外，还不敢立即更新所有的服务器。 先将线上的一万台服务器中的 10 台更新为最新的系统，然后观察验证。确认没有异常之后，再将剩余的所有服务器更新。 这个方法就是金丝雀发布。 实际操作中还可以做更多控制，譬如说，给最初更新的 10 台服务器设置较低的权重、控制发送给这 10 台服务器的请求数，然后逐渐提高权重、增加请求数。 这个控制叫做“流量切分”，既可以用于金丝雀发布，也可以用于后面的 A/B 测试。 蓝绿部署和金丝雀发布是两种发布策略，都不是万能的。有时候两者都可以使用，有时候只能用其中一种。
A/B 测试 首先需要明确的是，A/B 测试和蓝绿部署以及金丝雀，完全是两回事。 蓝绿部署和金丝雀是发布策略，目标是确保新上线的系统稳定，关注的是新系统的 BUG、隐患。 A/B 测试是效果测试，同一时间有多个版本的服务对外服务，这些服务都是经过足够测试，达到了上线标准的服务，有差异但是没有新旧之分（它们上线时可能采用了蓝绿部署的方式）。 A/B 测试关注的是不同版本的服务的实际效果，譬如说转化率、订单情况等。 A/B 测试时，线上同时运行多个版本的服务，这些服务通常会有一些体验上的差异，譬如说页面样式、颜色、操作流程不同。相关人员通过分析各个版本服务的实际效果，选出效果最好的版本。 在 A/B 测试中，需要能够控制流量的分配，譬如说，为 A 版本分配 10%的流量，为 B 版本分配 10%的流量，为 C 版本分配 80%的流量。</description></item><item><title>应用实例</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Linux-Kernel/Kernel-%E5%8F%82%E6%95%B0/%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B/</guid><description>TCP 相关参数: net.core.somaxconn = 65535 net.ipv4.tcp_fin_timeout = 5 net.ipv4.tcp_max_syn_backlog = 65536 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_synack_retries = 2 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 TCP keepalive 相关参数 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 net.ipv4.tcp_keepalive_time = 600 其他 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 内存相关相关 vm.drop_caches = NUM vm.swappiness = 10 vm.max_map_count = 262144 vm.overcommit_memory = 1 vm.overcommit_ration = 50 vm.</description></item><item><title>应用实例</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/SNMP-Exporter/%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Metrics/Instrumenting/SNMP-Exporter/%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B/</guid><description>generator.yml 文件示例 H3C 这是从 H3C 的 HDM 中提取到的所有序列
modules: h3c_mib: walk: - hh3cHealthInfo - hh3cPowerInfo - hh3cFansInfo - hh3cMemDetailInfoTable - hh3cTempSensorName - hh3cTempSensorReading - hh3cTempSensorSubStatus version: 2 auth: community: public if_mib: walk: [sysUpTime, interfaces, ifXTable] lookups: - source_indexes: [ifIndex] lookup: ifAlias - source_indexes: [ifIndex] # Uis OID to avoid conflict with PaloAlto PAN-COMMON-MIB. lookup: 1.3.6.1.2.1.2.2.1.2 # ifDescr - source_indexes: [ifIndex] # Use OID to avoid conflict with Netscaler NS-ROOT-MIB. lookup: 1.</description></item><item><title>优化</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%BD%91%E7%BB%9C/Ingress/Ingress-Controller/Nginx/%E4%BC%98%E5%8C%96/</guid><description>原文链接：https://mp.weixin.qq.com/s/H7nfSEswggu92myHiRqWHg
k8s 的 Nginx Ingress 调优 概述 Nginx Ingress Controller 基于 Nginx 实现了 Kubernetes Ingress API，Nginx 是公认的高性能网关，但如果不对其进行一些参数调优，就不能充分发挥出高性能的优势。Nginx Ingress 工作原理：
内核参数调优 我们先看看通过内核的哪些参数能够提高 Ingress 的性能。保证在高并发环境下，发挥 Ingress 的最大性能。
调大全连接队列的大小 TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)。在高并发环境下，如果队列过小，可能导致队列溢出，使得连接部分连接无法建立。要调大 Nginx Ingress 的连接队列，只需要调整 somaxconn 内核参数的值即可，但我想跟你分享下这背后的相关原理。Nginx 监听 socket 时没有读取 somaxconn，而是有自己单独的参数配置。在 nginx.conf 中 listen 端口的位置，还有个叫 backlog 参数可以设置，它会决定 nginx listen 的端口的连接队列大小。 server { listen 80 backlog=1024; &amp;hellip;
backlog 是 listen(int sockfd, int backlog) 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；还有 Go 程序标准库在 listen 时，默认直接读取 somaxconn 作为队列大小。就是说，即便你的 somaxconn 配的很高，nginx 所监听端口的连接队列最大却也只有 511，高并发场景下可能导致连接队列溢出。所以在这个在 Nginx Ingress 中， Nginx Ingress Controller 会自动读取 somaxconn 的值作为 backlog 参数写到生成的 nginx.</description></item><item><title>有了 HTTP 协议，为什么还要有 websocket 协议？</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/WebSocket/%E6%9C%89%E4%BA%86-HTTP-%E5%8D%8F%E8%AE%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89-websocket-%E5%8D%8F%E8%AE%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/WebSocket/%E6%9C%89%E4%BA%86-HTTP-%E5%8D%8F%E8%AE%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89-websocket-%E5%8D%8F%E8%AE%AE/</guid><description>平时我们打开网页，比如购物网站某宝。都是点一下「列表商品」，跳转一下网页就到了「商品详情」。
从 HTTP 协议的角度来看，就是点一下网页上的某个按钮， 前端发一次 HTTP请 求，网站返回一次 HTTP 响应 。这种由客户端主动请求，服务器响应的方式也满足大部分网页的功能场景。
但有没有发现，这种情况下，服务器从来就「不会主动」给客户端发一次消息。就像你喜欢的女生从来不会主动找你一样。
但如果现在，你在刷网页的时候「右下角」突然弹出一个小广告，提示你【一个人在家偷偷才能玩哦】。
求知，好学，勤奋 ，这些刻在你 DNA 里的东西都动起来了。
你点开后发现。
长相平平无奇的古某提示你&amp;quot;道士 9 条狗，全服横着走&amp;quot;。
影帝某辉老师跟你说&amp;quot;系兄弟就来砍我&amp;quot;。
来都来了，你就选了个角色进到了游戏界面里。
创建角色页面
这时候，上来就是一个小怪，从远处走来，然后疯狂拿木棒子抽你。
你全程没点任何一次鼠标 。服务器就自动将怪物的移动数据和攻击数据源源不断发给你了。
这….太暖心了。
感动之余，问题就来了，
像这种 看起来服务器主动发消息给客户端的场景 ，是怎么做到的？
在真正回答这个问题之前，我们先来聊下一些相关的知识背景。
使用 HTTP 不断轮询 其实问题的痛点在于， 怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。
最常见的解决方案是， 网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息。
这其实时一种「 伪 」服务器推的形式。
它其实并不是服务器主动发消息到客户端，而是客户端自己不断偷偷请求服务器，只是用户无感知而已。
用这种方式的场景也有很多，最常见的就是 扫码登录 。
比如，某信公众号平台，登录页面二维码出现之后， 前端 网页根本不知道用户扫没扫，于是不断去向 后端 服务器询问，看有没有人扫过这个码。而且是以大概 1 到 2 秒的间隔去不断发出请求，这样可以保证用户在扫码后能在 1 到 2 秒内得到及时的反馈，不至于 等太久 。
但这样，会有两个比较明显的问题：
当你打开 F12 页面时，你会发现满屏的 HTTP 请求。虽然很小，但这其实也消耗带宽，同时也会增加下游服务器的负担。 最坏情况下，用户在扫码后，需要等个 1~2 秒，正好才触发下一次 HTTP 请求，然后才跳转页面，用户会感到 明显的卡顿 。 使用起来的体验就是，二维码出现后，手机扫一扫，然后在手机上点个确认，这时候 卡顿等个 1~2 秒 ，页面才跳转。</description></item><item><title>预读失效与缓存污染</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%85%B6%E4%BB%96/%E9%A2%84%E8%AF%BB%E5%A4%B1%E6%95%88%E4%B8%8E%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E5%85%B6%E4%BB%96/%E9%A2%84%E8%AF%BB%E5%A4%B1%E6%95%88%E4%B8%8E%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93/</guid><description>概述 参考：
公众号-小林 coding，说两个问题 大家好，我是小林。
上周群里看到有位小伙伴面试时，被问到这两个问题： 咋一看，以为是在问操作系统的问题，其实这两个题目都是在问如何改进 LRU 算法。
因为传统的 LRU 算法存在这两个问题：
「预读失效」导致缓存命中率下降（对应第一个问题） 「缓存污染」导致缓存命中率下降（对应第二个问题） Redis 的缓存淘汰算法则是通过实现 LFU 算法来避免「缓存污染」而导致缓存命中率下降的问题（Redis 没有预读机制）。
MySQL 和 Linux 操作系统是通过改进 LRU 算法来避免「预读失效和缓存污染」而导致缓存命中率下降的问题。
这次，就重点讲讲 MySQL 和 Linux 操作系统是如何改进 LRU 算法的？
好了，开始发车，坐稳了！
Linux 和 MySQL 的缓存 Linux 操作系统的缓存 在应用程序读取文件的数据的时候，Linux 操作系统是会对读取的文件数据进行缓存的，会缓存在文件系统中的 Page Cache（如下图中的页缓存）。
Page Cache 属于内存空间里的数据，由于内存访问比磁盘访问快很多，在下一次访问相同的数据就不需要通过磁盘 I/O 了，命中缓存就直接返回数据即可。
因此，Page Cache 起到了加速访问数据的作用。
MySQL 的缓存 MySQL 的数据是存储在磁盘里的，为了提升数据库的读写性能，Innodb 存储引擎设计了一个缓冲池（Buffer Pool），Buffer Pool 属于内存空间里的数据。
有了缓冲池后：
当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。 传统 LRU 是如何管理内存数据的？ Linux 的 Page Cache 和 MySQL 的 Buffer Pool 的大小是有限的，并不能无限的缓存数据，对于一些频繁访问的数据我们希望可以一直留在内存中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证内存不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在内存中。</description></item><item><title>远程管理</title><link>https://desistdaydream.github.io/docs/Utils/%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/</guid><description>AnLink - 在电脑上操作安卓手机 https://anl.ink/
https://mp.weixin.qq.com/s/u0bdpF3H_iZd8012CpMrxw
WIFI 链接需要手机电脑处于同一个 WIFI 网络下，第一次链接先用 USB 链接上，再切换为 WIFI 链接，这样就配对上了，之后再用 WIFI 就可以直接链接了
删除远程桌面的历史记录 https://answers.microsoft.com/zh-hans/windows/forum/all/answers%E5%88%86%E4%BA%AB%E5%88%A0%E9%99%A4/cfa7982f-acf6-4544-b083-85ff9bf87d2b
打开注册表 Regedit
找到 HKEY_CURRENT_USER\Software\Microsoft\Terminal Server Client\Default 删除该字段下对应的记录即可。
修改 Windows 远程桌面端口 通过远程桌面客户端连接到计算机（Windows 客户端或 Windows Server）时，计算机上的远程桌面功能会通过定义的侦听端口（默认情况下为 3389）“侦听”连接请求。 可以通过修改注册表来更改 Windows 计算机上的侦听端口。
启动注册表编辑器。 （在“搜索”框中键入 regedit。） 导航到以下注册表子项：HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp 查找端口号 单击“编辑”&amp;gt;“修改” ，然后单击“十进制” 。 键入新端口号，然后单击“确定” 。 关闭注册表编辑器，然后重新启动计算机。 下次使用远程桌面连接连接到此计算机时，必须键入新端口。 如果正在使用防火墙，请确保将防火墙配置为允许连接到新端口号。 可运行以下 PowerShell 命令来查看当前端口：
Get-ItemProperty -Path &amp;#39;HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp&amp;#39; -name &amp;#34;PortNumber&amp;#34; 例如：
PortNumber : 3389 PSPath : Microsoft.PowerShell.Core\Registry::HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp PSParentPath : Microsoft.PowerShell.Core\Registry::HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations PSChildName : RDP-Tcp PSDrive : HKLM PSProvider : Microsoft.</description></item><item><title>云盘</title><link>https://desistdaydream.github.io/docs/Utils/%E4%BA%91%E7%9B%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/Utils/%E4%BA%91%E7%9B%98/</guid><description>概述 参考：
Alist 参考：
GitHub 项目，Xhofe/alist Alist 是一个可以浏览各种存储中文件的程序，使用 Gin 框架与 React 框架编写。同时可以对外提供 WebDav 接口，以便支持 WebDav 的客户端通过 Alist 直接操作各种存储中的数据。
Alist 可以连接 本地存储、各种网盘、S3 等存储系统，并暴露出来，以通过 浏览器浏览 这些存储系统中存储的数据，或通过 WebDav 客户端操作这些存储系统中存储的数据。
现阶段，Alist 支持如下存储：
本地存储 # i.e.将本地磁盘中的一个目录暴露出去 阿里云盘 OneDrive / Sharepoint（国际版, 世纪互联,de,us） 天翼云盘 (个人云, 家庭云) GoogleDrive 123 云盘 蓝奏云 Alist FTP PikPak 闪电盘 S3 WebDav(支持无 API 的 OneDrive/SharePoint) Teambition（中国，国际） 分秒帧 和彩云 (个人云, 家庭云) Yandex.Disk 百度网盘 夸克网盘 迅雷云盘 SFTP 一刻相册 WebDAV Alist 可以提供 WebDAV 服务，Alist 会在 https://IP:PORT/dav 端点暴露 WebDAV 访问接口，可以通过支持 WebDAV 标准的客户端连接 Alist，并操作其中的数据。</description></item><item><title>云原生应用的12要素</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%9A%8412%E8%A6%81%E7%B4%A0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E7%9A%8412%E8%A6%81%E7%B4%A0/</guid><description>概述 在云的时代，应用会更多的迁移到云端，基于云的架构设计和开发模式需要一套全新的理念去承载，于是云原生思想应运而生，而针对云原生应用开发的最佳实践原则，12-Factor 脱颖而出，同时也带来了新的解读。
12-Factor，是由 Heroku 创始人 AdamWiggins 首次提出并开源，并由众多经验丰富的开发者共同完善，这综合了他们关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准。
12-Factor 全称叫 TheTwelve-Factor App，它定义了一个优雅的互联网应用在设计过程中，需要遵循的一些基本原则，和 Cloud-Native 有异曲同工之处。
Pivotal 定义了云原生十二要素，后来又补充了三个，从而开始有了标准的样子。 I. 基准代码 一份基准代码（Codebase），多份部署（deploy）
12-Factor 应用(译者注：应该是说一个使用本文概念来设计的应用，下同)通常会使用版本控制系统加以管理，如 Git, Mercurial, Subversion。一份用来跟踪代码所有修订版本的数据库被称作 代码库（code repository, code repo, repo）。
在类似 SVN 这样的集中式版本控制系统中，基准代码 就是指控制系统中的这一份代码库；而在 Git 那样的分布式版本控制系统中，基准代码 则是指最上游的那份代码库。
一份代码库对应多份部署
基准代码和应用之间总是保持一一对应的关系：
l 一旦有多个基准代码，就不能称为一个应用，而是一个分布式系统。分布式系统中的每一个组件都是一个应用，每一个应用可以分别使用 12-Factor 进行开发。
l 多个应用共享一份基准代码是有悖于 12-Factor 原则的。解决方案是将共享的代码拆分为独立的类库，然后使用 依赖管理 策略去加载它们。
尽管每个应用只对应一份基准代码，但可以同时存在多份部署。每份 部署 相当于运行了一个应用的实例。通常会有一个生产环境，一个或多个预发布环境。此外，每个开发人员都会在自己本地环境运行一个应用实例，这些都相当于一份部署。
所有部署的基准代码相同，但每份部署可以使用其不同的版本。比如，开发人员可能有一些提交还没有同步至预发布环境；预发布环境也有一些提交没有同步至生产环境。但它们都共享一份基准代码，我们就认为它们只是相同应用的不同部署而已。
II. 依赖 显式声明依赖关系（ dependency ）
大多数编程语言都会提供一个打包系统，用来为各个类库提供打包服务，就像 Perl 的 CPAN 或是 Ruby 的 Rubygems 。通过打包系统安装的类库可以是系统级的（称之为 “site packages”），或仅供某个应用程序使用，部署在相应的目录中（称之为 “vendoring” 或 “bunding”）。</description></item><item><title>在不生成 crd client 代码的情况下通过 client-go 增删改查 k8s crd 资源</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/%E5%9C%A8%E4%B8%8D%E7%94%9F%E6%88%90-crd-client-%E4%BB%A3%E7%A0%81%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E9%80%9A%E8%BF%87-client-go-%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5-k8s-crd-%E8%B5%84%E6%BA%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E5%BC%80%E5%8F%91/Client-Libraries/%E5%9C%A8%E4%B8%8D%E7%94%9F%E6%88%90-crd-client-%E4%BB%A3%E7%A0%81%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E9%80%9A%E8%BF%87-client-go-%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5-k8s-crd-%E8%B5%84%E6%BA%90/</guid><description>原文链接：https://mozillazg.com/2020/07/k8s-kubernetes-client-go-list-get-create-update-patch-delete-crd-resource-without-generate-client-code-update-or-create-via-yaml.html 2020-07-19
k8s k8s / kubernetes / crd / client-go
前言¶ 示例 CRD¶ list 资源¶ get 资源¶ create 资源¶ update 资源¶ patch 资源¶ delete 资源¶ 总结¶ 参考资料¶ 前言 一般情况下管理 crd 资源都是通过由 code-generator 生成的 crd client 来操作，但是有时也会有只想简单的操作一下资源不想去导入或生成 crd client 相关代码的需求，这里简单的记录一下在不生成 crd client 代码的情况下通过 client-go 增删改查 k8s crd 资源的方法。
示例 CRD 先来定义一个测试用的 CRD （其实已有的 Pod 之类的也是可以的，没啥特别的不一定要自定义 CRD，这里只是展示这个能力，因为一般如果是内置的资源的话，直接用内置的 client 和内置的资源 struct 就可以了）（这个 crd 来自 官方文档 ）：
apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: # name must match the spec fields below, and be in the form: &amp;lt;plural&amp;gt;.</description></item><item><title>账户配置文件</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Account-Manager%E8%B4%A6%E6%88%B7%E7%AE%A1%E7%90%86/%E8%B4%A6%E6%88%B7%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%99%BB%E5%BD%95-Linux-%E4%B8%8E-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/Account-Manager%E8%B4%A6%E6%88%B7%E7%AE%A1%E7%90%86/%E8%B4%A6%E6%88%B7%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</guid><description>概述 参考：
passwd 参考：
Manual(手册)，passwd(5) root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin games:x:12:100:games:/usr/games:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin nobody:x:99:99:Nobody:/:/sbin/nologin systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin dbus:x:81:81:System message bus:/:/sbin/nologin polkitd:x:999:998:User for polkitd:/:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin postfix:x:89:89::/var/spool/postfix:/sbin/nologin tcpdump:x:72:72::/:/sbin/nologin chrony:x:998:996::/var/lib/chrony:/sbin/nologin shadow 参考：
Manual(手册)，shadow(5) 注意：该文件中通常是没有任何 读、写、执行 权限的，不推荐直接使用系统终端直接修改该文件(比如 vi、sed 等命令)，而是通过专用的 chage、useradd、userdel 等等工具修改本文件
shadow 是一个文件，其中包含系统帐户的密码信息和可选的老化信息。如果要维护密码安全，则普通用户不得读取此文件。该文件的每一行包含 9 个字段，以冒号 : 分隔，顺序如下：
login name(登录名称) # 操作系统中有效的账户名称 encrypted password(加密的密码) # 账户对应的密码，该字段的密码是加密后的字符串。 该字段可以为空，这种情况下，无需密码即可登录系统。不过一般默认情况，系统的 PAM 模块会阻止这种行为。 以 ! 开头的表示密码被锁定 date of last password change(上次更改密码的日期) # 上次更改密码的日期。该字段的值，是从 1970 年 1 月 1 日开始到上次修改密码时经过的天数。 minimum password age(最小密码期限) # 简称 MIN_DAYS。自从上次密码修改之后，至少需要 INT 天才可以再次被修改。 如果不满足天数要求，当使用 passwd 命令修改密码时，则会出现如下报错 You must wait longer to change your password，并且直接退出程序，终止用户的修改密码操作。 maximum password age(最大密码期限) # 简称 MAX_DAYS。 密码可以使用的最大天数。如果超过了使用天数，将会被强制更改密码，否则无法登录。值为 -1 则不再限制密码可以使用的最大天数 password warning period(密码警告期限) # 简称 WARN_DAYS。密码到期前发出警告的天数。值为 0 则表示仅在到期日发出警告，负值或不指定值表示不发出警告。 password inctivity period(密码不活动期限) # account expiration data(账户到期日) # reserved field(保留字段) # root:$6$lWEIpm976ef7vNzK$EI.</description></item><item><title>这次答应我，一举拿下 I/O 多路复用！</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/I_O/%E8%BF%99%E6%AC%A1%E7%AD%94%E5%BA%94%E6%88%91%E4%B8%80%E4%B8%BE%E6%8B%BF%E4%B8%8B-I_O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/Filesystem/I_O/%E8%BF%99%E6%AC%A1%E7%AD%94%E5%BA%94%E6%88%91%E4%B8%80%E4%B8%BE%E6%8B%BF%E4%B8%8B-I_O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</guid><description>参考：原文链接
这次，我们以最简单 socket 网络模型，一步一步的过度到 I/O 多路复用。
最基本的 Socket 模型 要想客户端和服务器能在网络中通信，那必须得使用 Socket 编程，它是进程间通信里比较特别的方式，特别之处在于它是可以跨主机间通信。 Socket 的中文名叫作插口，咋一看还挺迷惑的。事实上，双方要进行网络通信前，各自得创建一个 Socket，这相当于客户端和服务器都开了一个“口子”，双方读取和发送数据的时候，都通过这个“口子”。这样一看，是不是觉得很像弄了一根网线，一头插在客户端，一头插在服务端，然后进行通信。 创建 Socket 的时候，可以指定网络层使用的是 IPv4 还是 IPv6，传输层使用的是 TCP 还是 UDP。 UDP 的 Socket 编程相对简单些，这里我们只介绍基于 TCP 的 Socket 编程。 服务器的程序要先跑起来，然后等待客户端的连接和数据，我们先来看看服务端的 Socket 编程过程是怎样的。 服务端首先调用 socket() 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？
绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。
绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；
绑定完 IP 地址和端口后，就可以调用 listen() 函数进行监听，此时对应 TCP 状态图中的 listen，如果我们要判定服务器中一个网络程序有没有启动，可以通过 netstate 命令查看对应的端口号是否有被监听。 服务端进入了监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。 那客户端是怎么发起连接的呢？客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后万众期待的 TCP 三次握手就开始了。 在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列：</description></item><item><title>支持各种隧道协议的客户端</title><link>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/%E6%94%AF%E6%8C%81%E5%90%84%E7%A7%8D%E9%9A%A7%E9%81%93%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/4.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/Protocol/Tunneling-Protocol/%E6%94%AF%E6%8C%81%E5%90%84%E7%A7%8D%E9%9A%A7%E9%81%93%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF/</guid><description>Clash 参考：
GitHub 项目，Dreamacro/clash GitHub 项目 Wiki（官方文档） [!Attention] 据说作者已被抓，2023-11-2 仓库没了
Clash Core 删库跑路后的选择
https://github.com/MetaCubeX/Clash.Meta # Clash.Meta https://github.com/MetaCubeX/mihomo/tree/Meta # Clash.Meta Clash 是一个 Go 语言开发的代理客户端，支持多种服务端协议，比如 Vmess、Shadowsocks、Trojan、Snell 等。
Clash 特性：
支持身份验证的本地 HTTP/HTTPS/SOCKS 服务器 VMess、Shadowsocks、Trojan、Snell 协议支持远程连接 内置 DNS 服务器，旨在最大限度地减少 DNS 污染攻击的影响，支持 DoH/DoT 上游和假 IP。 基于域、GEOIP、IPCIDR 或进程的规则将数据包转发到不同的节点 远程组允许用户实施强大的规则。支持自动回退、负载平衡或基于延迟的自动选择节点 远程提供者，允许用户远程获取节点列表，而不是在配置中硬编码 Netfilter TCP 重定向。使用 .在您的 Internet 网关上部署 Clash iptables。 全面的 HTTP RESTful API 控制器 规则 DOMAIN-SUFFIX：域名后缀匹配 DOMAIN：域名匹配 DOMAIN-KEYWORD：域名关键字匹配 IP-CIDR：IP 段匹配 SRC-IP-CIDR：源 IP 段匹配 GEOIP：GEOIP 数据库（国家代码）匹配 DST-PORT：目标端口匹配 SRC-PORT：源端口匹配 PROCESS-NAME：源进程名匹配 RULE-SET：根据 Rule Provider 匹配 MATCH：全匹配 Rule Providers(规则提供器) GitHub 项目，Loyalsoldier/clash-rules 根据 Loyalsoldier/v2ray-rules-dat 项目生成了适用于 Clash 的规则集合。有点类似于 iptables 中的 ipset</description></item><item><title>中断的理解</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Interrupts%E4%B8%AD%E6%96%AD/%E4%B8%AD%E6%96%AD%E7%9A%84%E7%90%86%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Interrupts%E4%B8%AD%E6%96%AD/%E4%B8%AD%E6%96%AD%E7%9A%84%E7%90%86%E8%A7%A3/</guid><description>回到操作系统：中断 参考：https://www.junmajinlong.com/os/interrupt/
要想在任何需要的时候回到操作系统，这相当于是改变了 CPU 的正常执行流程，所以一个非常熟悉的字眼——中断（Interrupt）就出现了。通过中断，可以保证回到操作系统，从而将 CPU 的控制权交给操作系统。
中断的字面意思就是打断正常执行流程，但是注意，它表示的是打断流程而不是终止流程，这是不同的概念。中断是操作系统中非常重要的机制，正如上面所描述的：中断用于保证 CPU 控制权交给操作系统，从而让操作系统可以执行某些操作。
中断分为硬件中断和软件中断。
任何硬件，都有自己的 IRQ（中断请求），都可以在需要的时候通过总线向 CPU 发送硬件中断通知。比如时钟中断，当进程执行耗光时间片时将产生一个时钟中断，使得能够立刻进入操作系统并调度下一个要执行的进程，时钟中断是操作系统具有安全感的保证，只要时钟开始运行后，就意味着操作系统最终总能够获取到 CPU 控制权。再比如硬盘的 IO 中断，当硬盘读取所请求的数据完成后，就会发送硬盘 IO 中断，CPU 接到该中断后就会切换到操作系统，让操作系统去处理这个中断事件。
软件也可以发送中断，比如请求一个系统调用（system call），关于系统调用，后面再介绍。
无论是软中断还是硬件中断，最终的目的都是为了回到操作系统，将 CPU 交给操作系统。那么，中断是如何回到操作系统的呢？换句话说，中断时是如何进入内核态的呢？内核态又如何回到用户态呢？
当操作系统执行完相关操作后，就要回到用户态，要回到用户态也只需执行特殊的指令即可，一般称之为 return-from-trap 指令。（此处的 trap 又似乎是个名词，表示脱离陷阱，回到用户态之下。它将内核态描述为陷阱，这其实也是可以理解的，中断是事件，收到事件表示捕获到事件，什么具有捕获的能力？陷阱。在 bash 中也有一个 trap 命令，也可以理解为陷进，它用来设置信号处理程序，当捕获到信号时就做出某些处理。我们不管 trap 是陷入还是陷阱，我们关注的是作用：进入内核态和退出内核态。）
中断既然是打断 CPU 的执行流程，那么可能需要重新回到中断点继续正常的执行流程。所以，在发生中断时，需要保存好中断点以及相关的一些状态，以便能够在处理完中断后恢复执行流程继续向下执行。
所以，中断就像是突发事件，处理完成后如果恢复到断点处，那么对整个流程来说，中断就像是从未发生过的事一样，但却实实在在的被处理了。但是，中断后并不一定会恢复到断点处，因为中断处理程序可能会在恢复断点前直接退出这个执行流程，比如有些硬件中断表示一些异常现象（比如除 0 异常），这些异常可能会导致终止进程。</description></item><item><title>中断优化</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Interrupts%E4%B8%AD%E6%96%AD/%E4%B8%AD%E6%96%AD%E4%BC%98%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Kernel/CPU/Interrupts%E4%B8%AD%E6%96%AD/%E4%B8%AD%E6%96%AD%E4%BC%98%E5%8C%96/</guid><description>如何优化软中断 CPU0 过高问题 RSS(Receive Side Scaling，需网卡支持多队列)
查看网卡是否支持队列 root@geekwolf:~# lscpi -vvv 06:00.0 Ethernet controller: Broadcom Corporation BCM57840 NetXtreme II 10/20-Gigabit Ethernet (rev 11) Subsystem: Hewlett-Packard Company Device 22fa Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- DisINTx+ Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &amp;gt;TAbort- &amp;lt;tabort - &amp;lt;MAbort- &amp;gt;SERR- &amp;lt;perr - INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 32 Region 0: Memory at 93800000 (64-bit, prefetchable) [size=8M] Region 2: Memory at 93000000 (64-bit, prefetchable) [size=8M] Region 4: Memory at 95000000 (64-bit, prefetchable) [size=64K] [virtual] Expansion ROM at 95080000 [disabled] [size=512K] Capabilities: [48] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1-,D2-,D3hot+,D3cold+) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=1 PME- Capabilities: [50] Vital Product Data Product Name: HP FlexFabric 10Gb 2-port 536FLB Adapter Read-only fields: [PN] Part number: 766488-001 [EC] Engineering changes: A-5444 [MN] Manufacture ID: 31 30 33 43 [V0] Vendor specific: 12W PCIeGen3 [V1] Vendor specific: 7.</description></item><item><title>重定向</title><link>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E9%87%8D%E5%AE%9A%E5%90%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Terminal-%E4%B8%8E-Shell/Bash/%E9%87%8D%E5%AE%9A%E5%90%91/</guid><description>概述 参考：
Manual(手册)，bash(1) - 重定向 Redirection(重定向) 功能可以在执行命令之前，使用 Bash 的特殊符号来重定向其输入和输出。 重定向还可以用于打开和关闭当前 Shell 执行环境的文件。 重定向操作符可以出现在简单命令的前面，也可以出现在命令的后面。重定向按照它们出现的顺序进行处理。 重定向按照从左到右的顺序显示。
用一个简单的例子来理解一下什么是重定向
~]# ls anaconda-ks.cfg playbook scripts ~]# ls &amp;gt; dirlist ~]# cat dirlist anaconda-ks.cfg dirlist playbook scripts 这个例子就是将 ls 命令的标准输出的内容，重定向到 dirlist 文件中。(默认一个命令执行时，输出内容会打印在屏幕上，但是重定向后，将内容写入文件中)
每个程序在运行后，都会至少打开三个 文件描述符，分别是
0：标准输入 1：标准输出 2：标准错误 文件描述符介绍详见：文件描述符与打开文件之间的关系
所以，shell 可以实现重定向，就是这 3 者其中之一，或者全部三者。
重定向的种类 在下面各种重定向的语法中，n 表示文件描述符
Redirecting Input 重定向输入 输入的重定向将打开名称为 WORD 的文件，以便在文件描述符 n 下打开标准输入，n 默认为 0。
语法：COMMAND [n]&amp;lt; WORD
EXAMPLE
Redirecting Output 重定向输出 输出重定向将打开名称为 WORD 的文件，以便在文件描述符 n 上进行写操作，n 默认为 1。 如果 WORD 文件不存在，则创建该文件； 如果存在，则将其截断为零大小。</description></item><item><title>追踪系统</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Traces/%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Traces/%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F/</guid><description>概述 参考：
Jaeger
Tempo
Skywalking
Zipkin
链路追踪需要在程序码中嵌入追踪库？那如何配置程序自己的调用栈数据推送到哪里，推送间隔，推送量之类的信息？
Application Performance Management(简称 APM) 是链路追踪程序可以实现的一种能力。
产品对比 分布式跟踪系统——产品对比
产品名称 厂商 开源 OpenTracing标准 侵入性 应用策略 时效性 决策支持 可视化 低消耗 延展性 Jaeger uber 开源 完全支持 部分侵入 策略灵活 时效性高， UDP协议传输数据(在Uber任意给定的一个Jaeger安装可以很容易地每天处理几十亿spans) 决策支持较好，并且底层支持metrics指标 报表不丰富，UI比较简单 消耗低 jaeger比较复杂，使用框架较多，比如：rpc框架采用thrift协议，不支持pb协议之类。后端存储比较复杂。但经过uber大规模使用，延展性好 zipkin twitter 开源 部分支持 侵入性强 策略灵活 时效性好 决策一般(功能单一，监控维度和监控信息不够丰富。没有告警功能) 丰富的数据报表 系统开销小 延展性好 CAT 大众点评 吴其敏 开源 - 侵入性强 策略灵活 时效性较好，rpc框架采用tcp传输数据 决策好 报表丰富，满足各种需求 消耗较低 ， 国内很多大厂都在使用 - Appdash sourcegraph 开源 完全支持 侵入性较弱 采样率支持(粒度：不能根据流量采样，只能依赖于请求数量)；没有trace开关 时效性高 决策支持低 可视化太弱，无报表分析 消耗方面。不支持大规模部署, 因为appdash主要依赖于memory，虽然可以持久化到磁盘，以及内存存储支持hash存储、带有效期的map存储、以及不加限制的内存存储，前者存储量过小、后者单机内存存储无法满足 延展性差 MTrace 美团 不开源 - - - - CallGraph 京东 不开源 - Watchman sina微博 不开源 - EagleEye 淘宝 不开源 - skywalking 华为 吴晟 开源 完全支持 侵入性很低 策略灵活 时效性较好 由于调用链路的更细化， 但是作者在性能和追踪细粒度之间保持了比较好的平衡。决策好 丰富的数据报表 消耗较低 延展性非常好，水平理论上无限扩展</description></item><item><title>组件详解</title><link>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/6.%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/Logs/Loki/%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/</guid><description>概述 参考：
官方文档，架构 官方文档，架构 - 组件 公众号，Grafana Loki 架构(阳明翻译的官方文档) Grafana Loki 是一套可以组合成一个功能齐全的日志堆栈组件，与其他日志记录系统不同，Loki 是基于仅索引有关日志元数据的想法而构建的：标签（就像 Prometheus 标签一样）。日志数据本身被压缩然后并存储在对象存储（例如 S3 或 GCS）的块中，甚至存储在本地文件系统上，轻量级的索引和高度压缩的块简化了操作，并显着降低了 Loki 的成本，Loki 更适合中小团队。
Grafana Loki 主要由 3 部分组成:
loki: 日志记录引擎，负责存储日志和处理查询 promtail: 代理，负责收集日志并将其发送给 loki grafana: UI 界面 Distributor(分配器) Distributor 服务负责处理客户端写入的日志，它本质上是日志数据写入路径中的第一站，一旦 Distributor 收到日志数据，会将其拆分为多个批次，然后并行发送给多个 Ingester。
Distributor 通过 gRPC 与 Ingester 通信，它们都是无状态的，可以根据需要扩大或缩小规模。
Validation(验证) Preprocessing(预处理) Rate limiting(速率限制) Forwarding(转发) Hashing(哈希) Distributors 将一致性哈希和可配置的复制因子结合使用，以确定 Ingester 服务的哪些实例应该接收指定的流。
流是一组与租户和唯一标签集关联的日志，使用租户 ID 和标签集对流进行 hash 处理，然后使用哈希查询要发送流的 Ingesters。
存储在 Consul 中的哈希环被用来实现一致性哈希。。。所有的 ingester 都会使用自己拥有的一组 Token 注册到哈希环中，每个 Token 是一个随机的无符号 32 位数字，与一组 Token 一起，ingester 将其状态注册到哈希环中，状态 JOINING 和 ACTIVE 都可以接收写请求，而 ACTIVE 和 LEAVING 的 ingesters 可以接收读请求。在进行哈希查询时，distributors 只使用处于请求的适当状态的 ingester 的 Token。</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/API-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>创建一个超级权限 创建一个 ServiceAccount kubectl create serviceaccount -n user-sa-manage test-admin 将该 ServiceAccount 绑定到 cluster-admin 这个 clusterrole，以赋予最高权限 kubectl create clusterrolebinding test-admin &amp;ndash;clusterrole=cluster-admin &amp;ndash;serviceaccount=user-sa-manage:test-admin 此时，sa 账户就具有超级权限了，可以通过该 sa 的 token 给应用程序使用，以便可以最大化操作集群 获取 TOKEN kubectl get secrets -n user-sa-manage -o jsonpath=&amp;quot;{.items[?(@.metadata.annotations[&amp;lsquo;kubernetes.io/service-account.name&amp;rsquo;]==&amp;lsquo;test-admin&amp;rsquo;)].data.token}&amp;quot;|base64 -d 使用 Service Account 的 Token 创建非管理员用户 如果想要使用 Token 对集群进行操作，其实，并不一定要创建一个 KubeConfig 文件，在通过 Kubernetes API 获取集群信息时，直接使用 Token 认证的方式即可，比如：
kubernetes-dashboard 的 web 登录可以使用 Token 通过 REST 访问 API 可以传递 Authorization: Bearer ${TOKEN} 请求头时使用 Token。 创建 SA，并为 SA 授权 创建一个名称空间，专门用来存放 SA。然后创建一个名为 lch 的 SA。</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/10.%E4%BA%91%E5%8E%9F%E7%94%9F/Kubernetes/Kubernetes-%E7%AE%A1%E7%90%86/kubeadm-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>bj-net apiVersion: kubeadm.k8s.io/v1beta2 kind: InitConfiguration bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token ttl: 0s usages: - signing - authentication --- apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration kubernetesVersion: v1.19.2 controlPlaneEndpoint: k8s-api.bj-net.ehualu.local:6443 imageRepository: registry.aliyuncs.com/k8sxio networking: podSubnet: 10.244.0.0/16 serviceSubnet: 10.96.0.0/12 etcd: local: extraArgs: listen-metrics-urls: http://0.0.0.0:2381 apiServer: certSANs: - localhost - 127.0.0.1 - k8s-api.bj-net.ehualu.local - 172.19.42.214 - node-3.bj-net - 172.19.42.223 - node-2.bj-net - 172.19.42.222 - node-1.bj-net - 172.19.42.221 - master-3.bj-net - 172.19.42.213 - master-2.bj-net - 172.19.42.212 - master-1.bj-net - 172.</description></item><item><title>最佳实践</title><link>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://desistdaydream.github.io/docs/5.%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE/MySQL/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>概述 参考：
基础操作 显示当前存在哪些数据库
mysql&amp;gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 通常 MySQL 部署成功后，都有几个默认的数据库
information_schema mysql performance_schema sys 创建数据库
mysql&amp;gt; create database menagerie; Query OK, 1 row affected (0.00 sec) 开始使用数据库
mysql&amp;gt; use menagerie Database changed 创建表
mysql&amp;gt; create table pet (name VARCHAR(20), owner VARCHAR(20),species VARCHAR(20), sex CHAR(1), birth DATE, death DATE); Query OK, 0 rows affected (0.</description></item></channel></rss>